<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 28]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Evolutionary Gait Reconfiguration in Damaged Legged Robots](https://arxiv.org/abs/2506.19968)
*Sahand Farghdani,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出一种无需训练的快速损伤恢复算法，用于多足机器人腿部功能部分或完全丧失时的运动恢复。


<details>
  <summary>Details</summary>
Motivation: 多足机器人在复杂任务中易受腿部物理损伤影响，导致任务失败，需快速恢复运动能力。

Method: 首先生成新步态序列稳定运动，再通过差分进化算法优化步态配置，最大化前进并减少旋转和侧移。

Result: 算法在24自由度六足机器人上成功恢复运动，耗时不到一小时，高效且鲁棒。

Conclusion: 该算法高效、无需训练，能快速恢复受损多足机器人的运动能力。

Abstract: Multi-legged robots deployed in complex missions are susceptible to physical
damage in their legs, impairing task performance and potentially compromising
mission success. This letter presents a rapid, training-free damage recovery
algorithm for legged robots subject to partial or complete loss of functional
legs. The proposed method first stabilizes locomotion by generating a new gait
sequence and subsequently optimally reconfigures leg gaits via a developed
differential evolution algorithm to maximize forward progression while
minimizing body rotation and lateral drift. The algorithm successfully restores
locomotion in a 24-degree-of-freedom hexapod within one hour, demonstrating
both high efficiency and robustness to structural damage.

</details>


### [2] [Robust Embodied Self-Identification of Morphology in Damaged Multi-Legged Robots](https://arxiv.org/abs/2506.19984)
*Sahand Farghdani,Mili Patel,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种基于低成本IMU的自建模与损伤识别算法，使多足机器人能自主适应腿部损伤。


<details>
  <summary>Details</summary>
Motivation: 多足机器人在复杂任务中易受腿部损伤影响性能，需一种自主适应方法。

Method: 引入FFT滤波器处理时间不一致信号，通过比较机器人与其模型的姿态检测损伤，更新模型并集成到控制系统。

Result: 在崎岖地形实验中验证了算法的鲁棒性和计算效率。

Conclusion: 该方法有效提升了多足机器人在损伤情况下的自主适应能力。

Abstract: Multi-legged robots (MLRs) are vulnerable to leg damage during complex
missions, which can impair their performance. This paper presents a
self-modeling and damage identification algorithm that enables autonomous
adaptation to partial or complete leg loss using only data from a low-cost IMU.
A novel FFT-based filter is introduced to address time-inconsistent signals,
improving damage detection by comparing body orientation between the robot and
its model. The proposed method identifies damaged legs and updates the robot's
model for integration into its control system. Experiments on uneven terrain
validate its robustness and computational efficiency.

</details>


### [3] [Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion](https://arxiv.org/abs/2506.20036)
*Jeremiah Coholich,Muhammad Ali Murtaza,Seth Hutchinson,Zsolt Kira*

Main category: cs.RO

TL;DR: 提出了一种新颖的分层强化学习框架，用于四足机器人在复杂地形上的运动。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人在复杂地形中运动的挑战，提高其适应性和性能。

Method: 采用两层分层结构：高层策略（HLP）选择目标，低层策略（LLP）通过actor-critic RL算法训练。HLP通过在线优化LLP的价值函数运行，无需额外训练。

Result: 相比端到端RL方法，该框架在多种地形（包括训练中未见的更复杂地形）上实现了更高的奖励和更少的碰撞。

Conclusion: 分层强化学习框架显著提升了四足机器人在复杂地形中的运动性能。

Abstract: We propose a novel hierarchical reinforcement learning framework for
quadruped locomotion over challenging terrain. Our approach incorporates a
two-layer hierarchy in which a high-level policy (HLP) selects optimal goals
for a low-level policy (LLP). The LLP is trained using an on-policy
actor-critic RL algorithm and is given footstep placements as goals. We propose
an HLP that does not require any additional training or environment samples and
instead operates via an online optimization process over the learned value
function of the LLP. We demonstrate the benefits of this framework by comparing
it with an end-to-end reinforcement learning (RL) approach. We observe
improvements in its ability to achieve higher rewards with fewer collisions
across an array of different terrains, including terrains more difficult than
any encountered during training.

</details>


### [4] [Consensus-Driven Uncertainty for Robotic Grasping based on RGB Perception](https://arxiv.org/abs/2506.20045)
*Eric C. Joyce,Qianwen Zhao,Nathaniel Burgdorfer,Long Wang,Philippos Mordohai*

Main category: cs.RO

TL;DR: 提出一种轻量级深度网络方法，用于预测基于图像姿态估计的抓取成功率，避免高不确定性下的任务失败。


<details>
  <summary>Details</summary>
Motivation: 现有深度物体姿态估计器过于自信，缺乏与机器人抓取任务的不确定性量化结合，导致任务失败风险。

Method: 通过真实图像姿态估计和模拟抓取生成训练数据，训练轻量级网络预测抓取成功率。

Result: 网络能从多样物体数据中受益，联合训练提升性能。

Conclusion: 多样物体数据联合训练有助于提升抓取成功率预测的准确性。

Abstract: Deep object pose estimators are notoriously overconfident. A grasping agent
that both estimates the 6-DoF pose of a target object and predicts the
uncertainty of its own estimate could avoid task failure by choosing not to act
under high uncertainty. Even though object pose estimation improves and
uncertainty quantification research continues to make strides, few studies have
connected them to the downstream task of robotic grasping. We propose a method
for training lightweight, deep networks to predict whether a grasp guided by an
image-based pose estimate will succeed before that grasp is attempted. We
generate training data for our networks via object pose estimation on real
images and simulated grasping. We also find that, despite high object
variability in grasping trials, networks benefit from training on all objects
jointly, suggesting that a diverse variety of objects can nevertheless
contribute to the same goal.

</details>


### [5] [Robust Robotic Exploration and Mapping Using Generative Occupancy Map Synthesis](https://arxiv.org/abs/2506.20049)
*Lorin Achey,Alec Reed,Brendan Crowe,Bradley Hayes,Christoffer Heckman*

Main category: cs.RO

TL;DR: 提出了一种基于生成式占用映射的机器人探索新方法，通过SceneSense扩散模型预测3D占用图，实时融合预测结果，显著提升地图质量和可通行性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人探索中部分观测导致的占用图质量不足问题，提升地图的准确性和实用性。

Method: 使用SceneSense扩散模型预测3D占用图，并实时融合预测结果到运行中的占用图。

Result: 实验显示SceneSense显著提升地图质量（FID改进24.44%和75.59%），并增强探索的鲁棒性和可通行性。

Conclusion: SceneSense通过局部增强地图，提供比仅依赖传感器测量的地图更一致的探索结果。

Abstract: We present a novel approach for enhancing robotic exploration by using
generative occupancy mapping. We introduce SceneSense, a diffusion model
designed and trained for predicting 3D occupancy maps given partial
observations. Our proposed approach probabilistically fuses these predictions
into a running occupancy map in real-time, resulting in significant
improvements in map quality and traversability. We implement SceneSense onboard
a quadruped robot and validate its performance with real-world experiments to
demonstrate the effectiveness of the model. In these experiments, we show that
occupancy maps enhanced with SceneSense predictions better represent our fully
observed ground truth data (24.44% FID improvement around the robot and 75.59%
improvement at range). We additionally show that integrating
SceneSense-enhanced maps into our robotic exploration stack as a "drop-in" map
improvement, utilizing an existing off-the-shelf planner, results in
improvements in robustness and traversability time. Finally we show results of
full exploration evaluations with our proposed system in two dissimilar
environments and find that locally enhanced maps provide more consistent
exploration results than maps constructed only from direct sensor measurements.

</details>


### [6] [PSALM-V: Automating Symbolic Planning in Interactive Visual Environments with Large Language Models](https://arxiv.org/abs/2506.20097)
*Wang Bill Zhu,Miaosen Chai,Ishika Singh,Robin Jia,Jesse Thomason*

Main category: cs.RO

TL;DR: PSALM-V 是一种自主神经符号学习系统，通过交互在视觉环境中推断符号动作语义，无需专家定义，显著提升规划成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖文本领域或不现实的假设（如预定义问题文件或完全可观察性），PSALM-V 旨在动态推断符号语义，适应部分可观察和多智能体环境。

Method: 利用 LLM 生成启发式计划和候选符号语义，动态推断 PDDL 问题文件和动作语义，通过执行结果分析迭代优化动作语义信念。

Result: 在 ALFRED 中，规划成功率从 37% 提升至 74%；在 RTFM 和 Overcooked-AI 中，提高了步骤效率并成功实现多智能体领域归纳。

Conclusion: PSALM-V 在视觉和多智能体环境中有效推断符号动作语义，显著提升规划性能，适用于真实机器人任务。

Abstract: We propose PSALM-V, the first autonomous neuro-symbolic learning system able
to induce symbolic action semantics (i.e., pre- and post-conditions) in visual
environments through interaction. PSALM-V bootstraps reliable symbolic planning
without expert action definitions, using LLMs to generate heuristic plans and
candidate symbolic semantics. Previous work has explored using large language
models to generate action semantics for Planning Domain Definition Language
(PDDL)-based symbolic planners. However, these approaches have primarily
focused on text-based domains or relied on unrealistic assumptions, such as
access to a predefined problem file, full observability, or explicit error
messages. By contrast, PSALM-V dynamically infers PDDL problem files and domain
action semantics by analyzing execution outcomes and synthesizing possible
error explanations. The system iteratively generates and executes plans while
maintaining a tree-structured belief over possible action semantics for each
action, iteratively refining these beliefs until a goal state is reached.
Simulated experiments of task completion in ALFRED demonstrate that PSALM-V
increases the plan success rate from 37% (Claude-3.7) to 74% in partially
observed setups. Results on two 2D game environments, RTFM and Overcooked-AI,
show that PSALM-V improves step efficiency and succeeds in domain induction in
multi-agent settings. PSALM-V correctly induces PDDL pre- and post-conditions
for real-world robot BlocksWorld tasks, despite low-level manipulation failures
from the robot.

</details>


### [7] [Personalized Mental State Evaluation in Human-Robot Interaction using Federated Learning](https://arxiv.org/abs/2506.20212)
*Andrea Bussolan,Oliver Avram,Andrea Pignata,Gianvito Urgese,Stefano Baraldo,Anna Valente*

Main category: cs.RO

TL;DR: 该论文提出了一种基于联邦学习的多模态框架，用于实时评估工人压力水平并优化人机协作，同时保护隐私。


<details>
  <summary>Details</summary>
Motivation: 随着工业5.0的到来，制造商在追求大规模定制的同时，越来越重视工人的福祉。压力感知的人机协作（HRC）需要机器人根据人类心理状态调整行为，以提高协作流畅性和安全性。

Method: 通过整合联邦学习（FL），利用EEG、ECG、EDA、EMG和呼吸等生理信号，构建多模态模型预测操作员的压力水平，实现实时机器人行为调整。FL支持分布式设备端训练，保护数据隐私的同时提升模型泛化和个性化。

Result: 实验表明，FL方法的全局模型在压力预测准确性上与集中式训练相当，同时增强了个性化，优化了工业环境中的人机交互。

Conclusion: 该框架推动了隐私保护的适应性机器人技术，提升了智能制造中的劳动力福祉。

Abstract: With the advent of Industry 5.0, manufacturers are increasingly prioritizing
worker well-being alongside mass customization. Stress-aware Human-Robot
Collaboration (HRC) plays a crucial role in this paradigm, where robots must
adapt their behavior to human mental states to improve collaboration fluency
and safety. This paper presents a novel framework that integrates Federated
Learning (FL) to enable personalized mental state evaluation while preserving
user privacy. By leveraging physiological signals, including EEG, ECG, EDA,
EMG, and respiration, a multimodal model predicts an operator's stress level,
facilitating real-time robot adaptation. The FL-based approach allows
distributed on-device training, ensuring data confidentiality while improving
model generalization and individual customization. Results demonstrate that the
deployment of an FL approach results in a global model with performance in
stress prediction accuracy comparable to a centralized training approach.
Moreover, FL allows for enhancing personalization, thereby optimizing
human-robot interaction in industrial settings, while preserving data privacy.
The proposed framework advances privacy-preserving, adaptive robotics to
enhance workforce well-being in smart manufacturing.

</details>


### [8] [Generating and Customizing Robotic Arm Trajectories using Neural Networks](https://arxiv.org/abs/2506.20259)
*Andrej Lúčny,Matilde Antonj,Carlo Mazzola,Hana Hornáčková,Igor Farkaš*

Main category: cs.RO

TL;DR: 提出了一种神经网络方法，用于生成和定制机械臂的轨迹，确保精度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 提高机械臂在认知机器人实验中的可预测性和精确性，特别是在与人类交互时。

Method: 通过神经网络计算机械臂的正向运动学，并结合关节角度生成器，训练神经网络生成精确轨迹。

Result: 成功生成了可定制形状和适应不同场景的精确轨迹。

Conclusion: 该方法具有广泛适用性，能够有效提升机械臂动作的精度和可预测性。

Abstract: We introduce a neural network approach for generating and customizing the
trajectory of a robotic arm, that guarantees precision and repeatability. To
highlight the potential of this novel method, we describe the design and
implementation of the technique and show its application in an experimental
setting of cognitive robotics. In this scenario, the NICO robot was
characterized by the ability to point to specific points in space with precise
linear movements, increasing the predictability of the robotic action during
its interaction with humans. To achieve this goal, the neural network computes
the forward kinematics of the robot arm. By integrating it with a generator of
joint angles, another neural network was developed and trained on an artificial
dataset created from suitable start and end poses of the robotic arm. Through
the computation of angular velocities, the robot was characterized by its
ability to perform the movement, and the quality of its action was evaluated in
terms of shape and accuracy. Thanks to its broad applicability, our approach
successfully generates precise trajectories that could be customized in their
shape and adapted to different settings.

</details>


### [9] [Why Robots Are Bad at Detecting Their Mistakes: Limitations of Miscommunication Detection in Human-Robot Dialogue](https://arxiv.org/abs/2506.20268)
*Ruben Janssens,Jens De Bock,Sofie Labat,Eva Verhelst,Veronique Hoste,Tony Belpaeme*

Main category: cs.RO

TL;DR: 论文研究了机器学习模型在检测人机对话中沟通错误的效果，发现即使使用先进模型，识别准确率仅略高于随机猜测，揭示了用户反馈不足是根本限制。


<details>
  <summary>Details</summary>
Motivation: 人机交互中检测沟通错误对维持用户参与和信任至关重要，但机器人难以通过非语言反馈识别错误。

Method: 使用包含240段人机对话的多模态数据集，引入四种对话失败类型，评估计算机视觉模型的性能。

Result: 模型识别沟通错误的性能仅略高于随机猜测，但在情感表达更丰富的数据集上能成功识别困惑状态。

Conclusion: 用户感知到沟通错误时往往未向机器人反馈，这限制了模型的性能，提示需设计更有效的反馈机制。

Abstract: Detecting miscommunication in human-robot interaction is a critical function
for maintaining user engagement and trust. While humans effortlessly detect
communication errors in conversations through both verbal and non-verbal cues,
robots face significant challenges in interpreting non-verbal feedback, despite
advances in computer vision for recognizing affective expressions. This
research evaluates the effectiveness of machine learning models in detecting
miscommunications in robot dialogue. Using a multi-modal dataset of 240
human-robot conversations, where four distinct types of conversational failures
were systematically introduced, we assess the performance of state-of-the-art
computer vision models. After each conversational turn, users provided feedback
on whether they perceived an error, enabling an analysis of the models' ability
to accurately detect robot mistakes. Despite using state-of-the-art models, the
performance barely exceeds random chance in identifying miscommunication, while
on a dataset with more expressive emotional content, they successfully
identified confused states. To explore the underlying cause, we asked human
raters to do the same. They could also only identify around half of the induced
miscommunications, similarly to our model. These results uncover a fundamental
limitation in identifying robot miscommunications in dialogue: even when users
perceive the induced miscommunication as such, they often do not communicate
this to their robotic conversation partner. This knowledge can shape
expectations of the performance of computer vision models and can help
researchers to design better human-robot conversations by deliberately
eliciting feedback where needed.

</details>


### [10] [Real-Time Obstacle Avoidance Algorithms for Unmanned Aerial and Ground Vehicles](https://arxiv.org/abs/2506.20311)
*Jingwen Wei*

Main category: cs.RO

TL;DR: 论文探讨了无人机在复杂3D环境中的实时安全导航方法，特别是在森林火灾救援中的应用，提出了2D和3D导航策略，并整合了无人机与地面无人车的协作控制。


<details>
  <summary>Details</summary>
Motivation: 无人机在灾害救援中的应用尚未充分探索，尤其是在自主导航方面。研究旨在提升救援效率和安全性。

Method: 分阶段开发：首先设计2D融合导航策略，随后提出3D反应式导航策略，最后整合无人机与地面无人车的统一控制方法。

Result: 通过数学和仿真验证了控制模型的有效性，为无人机在自然灾害救援中的实际应用提供了支持。

Conclusion: 研究为无人机在复杂环境中的导航和协作救援提供了实用方法和学术见解。

Abstract: The growing use of mobile robots in sectors such as automotive, agriculture,
and rescue operations reflects progress in robotics and autonomy. In unmanned
aerial vehicles (UAVs), most research emphasizes visual SLAM, sensor fusion,
and path planning. However, applying UAVs to search and rescue missions in
disaster zones remains underexplored, especially for autonomous navigation.
  This report develops methods for real-time and secure UAV maneuvering in
complex 3D environments, crucial during forest fires. Building upon past
research, it focuses on designing navigation algorithms for unfamiliar and
hazardous environments, aiming to improve rescue efficiency and safety through
UAV-based early warning and rapid response.
  The work unfolds in phases. First, a 2D fusion navigation strategy is
explored, initially for mobile robots, enabling safe movement in dynamic
settings. This sets the stage for advanced features such as adaptive obstacle
handling and decision-making enhancements. Next, a novel 3D reactive navigation
strategy is introduced for collision-free movement in forest fire simulations,
addressing the unique challenges of UAV operations in such scenarios.
  Finally, the report proposes a unified control approach that integrates UAVs
and unmanned ground vehicles (UGVs) for coordinated rescue missions in forest
environments. Each phase presents challenges, proposes control models, and
validates them with mathematical and simulation-based evidence. The study
offers practical value and academic insights for improving the role of UAVs in
natural disaster rescue operations.

</details>


### [11] [Near Time-Optimal Hybrid Motion Planning for Timber Cranes](https://arxiv.org/abs/2506.20314)
*Marc-Philip Ecker,Bernhard Bischof,Minh Nhat Vu,Christoph Fröhlich,Tobias Glück,Wolfgang Kemmetmüller*

Main category: cs.RO

TL;DR: 本文提出了一种针对液压驱动木材起重机的新型混合运动规划方法，结合全局和局部规划器，解决了液压约束和被动关节的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型机械臂（如木材起重机）的运动规划面临液压驱动约束和被动关节等独特挑战，现有方法难以解决。

Method: 通过改进基于路径点的随机轨迹优化（VP-STO）算法，加入泵流量约束和新型碰撞成本公式，并结合梯度局部规划器。

Result: 增强的VP-STO作为全局规划器优于RRT*算法，结合局部规划器实现了时间最优和无碰撞运动。

Conclusion: 该方法有效解决了液压驱动木材起重机的运动规划问题，具有鲁棒性和实用性。

Abstract: Efficient, collision-free motion planning is essential for automating
large-scale manipulators like timber cranes. They come with unique challenges
such as hydraulic actuation constraints and passive joints-factors that are
seldom addressed by current motion planning methods. This paper introduces a
novel approach for time-optimal, collision-free hybrid motion planning for a
hydraulically actuated timber crane with passive joints. We enhance the
via-point-based stochastic trajectory optimization (VP-STO) algorithm to
include pump flow rate constraints and develop a novel collision cost
formulation to improve robustness. The effectiveness of the enhanced VP-STO as
an optimal single-query global planner is validated by comparison with an
informed RRT* algorithm using a time-optimal path parameterization (TOPP). The
overall hybrid motion planning is formed by combination with a gradient-based
local planner that is designed to follow the global planner's reference and to
systematically consider the passive joint dynamics for both collision avoidance
and sway damping.

</details>


### [12] [Building Forest Inventories with Autonomous Legged Robots -- System, Lessons, and Challenges Ahead](https://arxiv.org/abs/2506.20315)
*Matías Mattamala,Nived Chebrolu,Jonas Frey,Leonard Freißmuth,Haedam Oh,Benoit Casseau,Marco Hutter,Maurice Fallon*

Main category: cs.RO

TL;DR: 本文提出了一种用于自主森林调查的四足机器人系统，展示了其在自然环境中导航和测绘的能力，并总结了相关挑战与未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现代四足机器人具有鲁棒性和机动性，适合在非结构化自然环境中应用，如森林调查。

Method: 设计了一套完整的导航系统，包括状态估计、任务规划、树木检测及特征估计，并在欧洲三个国家的森林中进行了为期一年半的试验。

Result: ANYmal机器人能在30分钟内完成1公顷森林的测绘，树木直径（DBH）测量精度达2厘米。

Conclusion: 总结了硬件成熟度、状态估计限制、森林导航问题等五个挑战，为未来四足机器人及自然环境中自主系统的研究提供了方向。

Abstract: Legged robots are increasingly being adopted in industries such as oil, gas,
mining, nuclear, and agriculture. However, new challenges exist when moving
into natural, less-structured environments, such as forestry applications. This
paper presents a prototype system for autonomous, under-canopy forest inventory
with legged platforms. Motivated by the robustness and mobility of modern
legged robots, we introduce a system architecture which enabled a quadruped
platform to autonomously navigate and map forest plots. Our solution involves a
complete navigation stack for state estimation, mission planning, and tree
detection and trait estimation. We report the performance of the system from
trials executed over one and a half years in forests in three European
countries. Our results with the ANYmal robot demonstrate that we can survey
plots up to 1 ha plot under 30 min, while also identifying trees with typical
DBH accuracy of 2cm. The findings of this project are presented as five lessons
and challenges. Particularly, we discuss the maturity of hardware development,
state estimation limitations, open problems in forest navigation, future
avenues for robotic forest inventory, and more general challenges to assess
autonomous systems. By sharing these lessons and challenges, we offer insight
and new directions for future research on legged robots, navigation systems,
and applications in natural environments. Additional videos can be found in
https://dynamic.robots.ox.ac.uk/projects/legged-robots

</details>


### [13] [Finding the Easy Way Through -- the Probabilistic Gap Planner for Social Robot Navigation](https://arxiv.org/abs/2506.20320)
*Malte Probst,Raphael Wenzel,Tim Puphal,Monica Dasi,Nico A. Steinhardt,Sango Matsuzaki,Misa Komuro*

Main category: cs.RO

TL;DR: 论文提出了一种分解轨迹规划的方法，结合冲突避免和合作碰撞避免，通过Probabilistic Gap Planner (PGP)提升社交机器人导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有规划器仅关注短期交互，难以处理复杂场景中的策略选择问题。

Method: 将轨迹规划分解为冲突避免（宏观轨迹）和合作碰撞避免（微观交互），并引入PGP作为冲突避免规划器。

Result: 模拟实验表明，PGP能增加间距、减少紧张和碰撞，但路径稍长。

Conclusion: PGP结合现有规划器可显著提升导航性能，适用于实时机器人系统。

Abstract: In Social Robot Navigation, autonomous agents need to resolve many sequential
interactions with other agents. State-of-the art planners can efficiently
resolve the next, imminent interaction cooperatively and do not focus on longer
planning horizons. This makes it hard to maneuver scenarios where the agent
needs to select a good strategy to find gaps or channels in the crowd. We
propose to decompose trajectory planning into two separate steps: Conflict
avoidance for finding good, macroscopic trajectories, and cooperative collision
avoidance (CCA) for resolving the next interaction optimally. We propose the
Probabilistic Gap Planner (PGP) as a conflict avoidance planner. PGP modifies
an established probabilistic collision risk model to include a general
assumption of cooperativity. PGP biases the short-term CCA planner to head
towards gaps in the crowd. In extensive simulations with crowds of varying
density, we show that using PGP in addition to state-of-the-art CCA planners
improves the agents' performance: On average, agents keep more space to others,
create less tension, and cause fewer collisions. This typically comes at the
expense of slightly longer paths. PGP runs in real-time on WaPOCHI mobile robot
by Honda R&D.

</details>


### [14] [PIMBS: Efficient Body Schema Learning for Musculoskeletal Humanoids with Physics-Informed Neural Networks](https://arxiv.org/abs/2506.20343)
*Kento Kawaharazuka,Takahiro Hattori,Keita Yoneda,Kei Okada*

Main category: cs.RO

TL;DR: 提出了一种基于物理信息神经网络（PINN）的方法，用于学习肌肉骨骼人形机器人的身体模式，即使数据量有限也能实现高精度学习。


<details>
  <summary>Details</summary>
Motivation: 肌肉骨骼人形机器人的身体结构复杂，肌肉路径常偏离几何模型，传统方法依赖大量实际数据且学习困难。

Method: 利用物理信息神经网络（PINN），结合实际机器人数据和物理规律（如扭矩与肌肉张力关系），实现高效学习。

Result: 在仿真和实际肌肉骨骼人形机器人上验证了方法的有效性和特点。

Conclusion: 该方法在数据有限情况下仍能高精度学习身体模式，具有实际应用潜力。

Abstract: Musculoskeletal humanoids are robots that closely mimic the human
musculoskeletal system, offering various advantages such as variable stiffness
control, redundancy, and flexibility. However, their body structure is complex,
and muscle paths often significantly deviate from geometric models. To address
this, numerous studies have been conducted to learn body schema, particularly
the relationships among joint angles, muscle tension, and muscle length. These
studies typically rely solely on data collected from the actual robot, but this
data collection process is labor-intensive, and learning becomes difficult when
the amount of data is limited. Therefore, in this study, we propose a method
that applies the concept of Physics-Informed Neural Networks (PINNs) to the
learning of body schema in musculoskeletal humanoids, enabling high-accuracy
learning even with a small amount of data. By utilizing not only data obtained
from the actual robot but also the physical laws governing the relationship
between torque and muscle tension under the assumption of correct joint
structure, more efficient learning becomes possible. We apply the proposed
method to both simulation and an actual musculoskeletal humanoid and discuss
its effectiveness and characteristics.

</details>


### [15] [CARMA: Context-Aware Situational Grounding of Human-Robot Group Interactions by Combining Vision-Language Models with Object and Action Recognition](https://arxiv.org/abs/2506.20373)
*Joerg Deigmoeller,Stephan Hasler,Nakul Agarwal,Daniel Tanneberg,Anna Belardinelli,Reza Ghoddoosian,Chao Wang,Felix Ocker,Fan Zhang,Behzad Dariush,Michael Gienger*

Main category: cs.RO

TL;DR: CARMA是一个用于人机群体交互中情境感知的系统，通过唯一标识实体并组织成三元组（行为者、对象、动作）来实现协作。


<details>
  <summary>Details</summary>
Motivation: 在群体交互中，机器人需要情境感知以正确识别和跟踪行为者、对象及其交互。

Method: CARMA通过唯一标识物理实体并将其组织为三元组（行为者、对象、动作）来实现情境感知。

Result: 实验表明，CARMA能可靠生成准确的三元组，为协作场景提供结构化基础。

Conclusion: CARMA为需要时空推理和情境决策的应用提供了有效支持。

Abstract: We introduce CARMA, a system for situational grounding in human-robot group
interactions. Effective collaboration in such group settings requires
situational awareness based on a consistent representation of present persons
and objects coupled with an episodic abstraction of events regarding actors and
manipulated objects. This calls for a clear and consistent assignment of
instances, ensuring that robots correctly recognize and track actors, objects,
and their interactions over time. To achieve this, CARMA uniquely identifies
physical instances of such entities in the real world and organizes them into
grounded triplets of actors, objects, and actions.
  To validate our approach, we conducted three experiments, where multiple
humans and a robot interact: collaborative pouring, handovers, and sorting.
These scenarios allow the assessment of the system's capabilities as to role
distinction, multi-actor awareness, and consistent instance identification. Our
experiments demonstrate that the system can reliably generate accurate
actor-action-object triplets, providing a structured and robust foundation for
applications requiring spatiotemporal reasoning and situated decision-making in
collaborative settings.

</details>


### [16] [Enhanced Robotic Navigation in Deformable Environments using Learning from Demonstration and Dynamic Modulation](https://arxiv.org/abs/2506.20376)
*Lingyun Chen,Xinrui Zhao,Marcos P. S. Campanha,Alexander Wegener,Abdeldjallil Naceri,Abdalla Swikir,Sami Haddadin*

Main category: cs.RO

TL;DR: 提出了一种结合学习演示（LfD）和动态系统（DS）的新方法，用于机器人在含可变形障碍物环境中的导航。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在复杂环境中导航时，区分可变形和不可变形障碍物的挑战。

Method: 在DS框架中引入动态调制矩阵，实时区分可穿越的软区域和不可穿越的硬区域。

Result: 通过仿真和机器人实验验证了方法的有效性，实现了灵活且安全的轨迹规划。

Conclusion: 该方法不仅能够动态适应障碍物，还能在交互中控制轨迹和速度，确保导航的平滑性和可靠性。

Abstract: This paper presents a novel approach for robot navigation in environments
containing deformable obstacles. By integrating Learning from Demonstration
(LfD) with Dynamical Systems (DS), we enable adaptive and efficient navigation
in complex environments where obstacles consist of both soft and hard regions.
We introduce a dynamic modulation matrix within the DS framework, allowing the
system to distinguish between traversable soft regions and impassable hard
areas in real-time, ensuring safe and flexible trajectory planning. We validate
our method through extensive simulations and robot experiments, demonstrating
its ability to navigate deformable environments. Additionally, the approach
provides control over both trajectory and velocity when interacting with
deformable objects, including at intersections, while maintaining adherence to
the original DS trajectory and dynamically adapting to obstacles for smooth and
reliable navigation.

</details>


### [17] [SPARK: Graph-Based Online Semantic Integration System for Robot Task Planning](https://arxiv.org/abs/2506.20394)
*Mimo Shirasaka,Yuya Ikeda,Tatsuya Matsushima,Yutaka Matsuo,Yusuke Iwasawa*

Main category: cs.RO

TL;DR: 论文提出SPARK框架，用于在线更新语义信息并整合到场景图中，以增强机器人在动态环境中的任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 通用服务机器人需要在线更新几何和语义信息，但语义信息的在线更新尚未充分研究。

Method: 基于离线场景图表示的研究，提出SPARK框架，从环境线索中提取语义信息并动态更新场景图。

Result: 实验表明，场景图的空间关系表示能提升机器人在动态环境中的任务执行能力，并适应非传统空间线索（如手势）。

Conclusion: SPARK框架有效解决了语义信息在线更新的挑战，为机器人在动态环境中的任务规划提供了实用工具。

Abstract: The ability to update information acquired through various means online
during task execution is crucial for a general-purpose service robot. This
information includes geometric and semantic data. While SLAM handles geometric
updates on 2D maps or 3D point clouds, online updates of semantic information
remain unexplored. We attribute the challenge to the online scene graph
representation, for its utility and scalability. Building on previous works
regarding offline scene graph representations, we study online graph
representations of semantic information in this work. We introduce SPARK:
Spatial Perception and Robot Knowledge Integration. This framework extracts
semantic information from environment-embedded cues and updates the scene graph
accordingly, which is then used for subsequent task planning. We demonstrate
that graph representations of spatial relationships enhance the robot system's
ability to perform tasks in dynamic environments and adapt to unconventional
spatial cues, like gestures.

</details>


### [18] [Multimodal Behaviour Trees for Robotic Laboratory Task Automation](https://arxiv.org/abs/2506.20399)
*Hatem Fakhruldeen,Arvind Raveendran Nambiar,Satheeshkumar Veeramani,Bonilkumar Vijaykumar Tailor,Hadi Beyzaee Juneghani,Gabriella Pizzuto,Andrew Ian Cooper*

Main category: cs.RO

TL;DR: 论文提出了一种基于行为树和多模态感知的新方法，用于提高实验室机器人执行任务的可靠性和安全性，实验结果显示高成功率（88%的盖瓶和92%的插入）和强错误检测能力。


<details>
  <summary>Details</summary>
Motivation: 实验室机器人虽然能高效完成重复性任务，但其可靠性不足可能导致安全隐患（如毒物泄漏）。需要一种方法确保任务执行的准确性。

Method: 采用行为树结合多模态感知的方法，自动化任务执行并验证任务完成情况。

Result: 实验验证了高成功率（盖瓶88%，插入92%）和强错误检测能力。

Conclusion: 该方法证明了其鲁棒性和可靠性，为下一代机器人化学家的发展奠定了基础。

Abstract: Laboratory robotics offer the capability to conduct experiments with a high
degree of precision and reproducibility, with the potential to transform
scientific research. Trivial and repeatable tasks; e.g., sample transportation
for analysis and vial capping are well-suited for robots; if done successfully
and reliably, chemists could contribute their efforts towards more critical
research activities. Currently, robots can perform these tasks faster than
chemists, but how reliable are they? Improper capping could result in human
exposure to toxic chemicals which could be fatal. To ensure that robots perform
these tasks as accurately as humans, sensory feedback is required to assess the
progress of task execution. To address this, we propose a novel methodology
based on behaviour trees with multimodal perception. Along with automating
robotic tasks, this methodology also verifies the successful execution of the
task, a fundamental requirement in safety-critical environments. The
experimental evaluation was conducted on two lab tasks: sample vial capping and
laboratory rack insertion. The results show high success rate, i.e., 88% for
capping and 92% for insertion, along with strong error detection capabilities.
This ultimately proves the robustness and reliability of our approach and that
using multimodal behaviour trees should pave the way towards the next
generation of robotic chemists.

</details>


### [19] [Learn to Position -- A Novel Meta Method for Robotic Positioning](https://arxiv.org/abs/2506.20445)
*Dongkun Wang,Junkai Zhao,Yunfei Teng,Jieyang Peng,Wenjing Xue,Xiaoming Tao*

Main category: cs.RO

TL;DR: 提出了一种基于交互反馈的无视觉、模型无关的元方法，用于补偿机器人定位误差，并通过自学习和自适应能力提高定位精度。


<details>
  <summary>Details</summary>
Motivation: 机器人绝对定位精度至关重要，但误差来源复杂且随机，视觉方法易受遮挡和光照影响。

Method: 采用无视觉、模型无关的元方法，通过交互反馈最大化定位精度概率，并赋予机器人学习和适应误差的能力。

Result: 实证研究验证了方法的有效性，并已在电子元件装配线中实现应用。

Conclusion: 该方法通过自学习和自适应显著提升了机器人定位精度，适用于复杂环境。

Abstract: Absolute positioning accuracy is a vital specification for robots. Achieving
high position precision can be challenging due to the presence of various
sources of errors. Meanwhile, accurately depicting these errors is difficult
due to their stochastic nature. Vision-based methods are commonly integrated to
guide robotic positioning, but their performance can be highly impacted by
inevitable occlusions or adverse lighting conditions. Drawing on the
aforementioned considerations, a vision-free, model-agnostic meta-method for
compensating robotic position errors is proposed, which maximizes the
probability of accurate robotic position via interactive feedback. Meanwhile,
the proposed method endows the robot with the capability to learn and adapt to
various position errors, which is inspired by the human's instinct for grasping
under uncertainties. Furthermore, it is a self-learning and self-adaptive
method able to accelerate the robotic positioning process as more examples are
incorporated and learned. Empirical studies validate the effectiveness of the
proposed method. As of the writing of this paper, the proposed meta search
method has already been implemented in a robotic-based assembly line for
odd-form electronic components.

</details>


### [20] [A Review of Personalisation in Human-Robot Collaboration and Future Perspectives Towards Industry 5.0](https://arxiv.org/abs/2506.20447)
*James Fant-Male,Roel Pieters*

Main category: cs.RO

TL;DR: 本文综述了从工业4.0到工业5.0的转变，强调以人为中心的工作环境，并探讨了人机协作（HRC）在个性化适应方面的最新进展。


<details>
  <summary>Details</summary>
Motivation: 工业5.0（I5.0）的核心是实现以人为中心的工作场所，关注社会福祉价值。人机协作（HRC）作为I5.0的重要组成部分，需要更多个性化与适应性研究。

Method: 通过综述近期研究，分析个性化HRC的关键趋势，包括个人因素、工作单元设计、交互设计及适应性任务完成。

Result: 研究发现个性化HRC的研究趋势增长，但缺乏统一方法。同时，提出了未来发展的关键考虑，尤其是伦理和监管问题。

Conclusion: 个性化HRC是工业5.0的重要方向，未来需关注伦理与监管框架的统一发展。

Abstract: The shift in research focus from Industry 4.0 to Industry 5.0 (I5.0) promises
a human-centric workplace, with social and well-being values at the centre of
technological implementation. Human-Robot Collaboration (HRC) is a core aspect
of I5.0 development, with an increase in adaptive and personalised interactions
and behaviours. This review investigates recent advancements towards
personalised HRC, where user-centric adaption is key. There is a growing trend
for adaptable HRC research, however there lacks a consistent and unified
approach. The review highlights key research trends on which personal factors
are considered, workcell and interaction design, and adaptive task completion.
This raises various key considerations for future developments, particularly
around the ethical and regulatory development of personalised systems, which
are discussed in detail.

</details>


### [21] [EANS: Reducing Energy Consumption for UAV with an Environmental Adaptive Navigation Strategy](https://arxiv.org/abs/2506.20485)
*Tian Liu,Han Liu,Boyang Li,Long Chen,Kai Huang*

Main category: cs.RO

TL;DR: 提出了一种动态调整无人机导航策略的方法，通过分析动态特性和时间特性，显著减少能耗。


<details>
  <summary>Details</summary>
Motivation: 无人机受限于机载能源，现有静态策略在动态场景中效率低下，需解决任务管道依赖、环境-策略关联和参数选择等挑战。

Method: 分析无人机的动态特性和自主导航管道的时间特性，动态调整导航策略。

Result: 硬件在环仿真和实际实验显示，任务时间提升3.2倍和2.6倍，能耗降低2.4倍和1.6倍。

Conclusion: 动态调整导航策略能有效减少无人机能耗，适应环境变化。

Abstract: Unmanned Aerial Vehicles (UAVS) are limited by the onboard energy. Refinement
of the navigation strategy directly affects both the flight velocity and the
trajectory based on the adjustment of key parameters in the UAVS pipeline, thus
reducing energy consumption. However, existing techniques tend to adopt static
and conservative strategies in dynamic scenarios, leading to inefficient energy
reduction. Dynamically adjusting the navigation strategy requires overcoming
the challenges including the task pipeline interdependencies, the
environmental-strategy correlations, and the selecting parameters. To solve the
aforementioned problems, this paper proposes a method to dynamically adjust the
navigation strategy of the UAVS by analyzing its dynamic characteristics and
the temporal characteristics of the autonomous navigation pipeline, thereby
reducing UAVS energy consumption in response to environmental changes. We
compare our method with the baseline through hardware-in-the-loop (HIL)
simulation and real-world experiments, showing our method 3.2X and 2.6X
improvements in mission time, 2.4X and 1.6X improvements in energy,
respectively.

</details>


### [22] [Behavior Foundation Model: Towards Next-Generation Whole-Body Control System of Humanoid Robots](https://arxiv.org/abs/2506.20487)
*Mingqi Yuan,Tao Yu,Wenqi Ge,Xiuyong Yao,Dapeng Li,Huijiang Wang,Jiayu Chen,Xin Jin,Bo Li,Hua Chen,Wei Zhang,Wenjun Zeng*

Main category: cs.RO

TL;DR: 本文综述了行为基础模型（BFMs）在人形机器人全身控制（WBC）中的应用，探讨了其发展、实际应用、局限性和未来机遇。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在复杂动态、欠驱动和多样化任务需求下实现高效全身控制的挑战，避免学习型控制器因依赖重训练而受限的问题。

Method: 利用大规模预训练的行为基础模型（BFMs）学习可重用的原始技能和行为先验，支持零样本或快速适应下游任务。

Result: BFMs为可扩展和通用的人形机器人智能提供了关键方法，并提供了相关论文和项目的资源列表。

Conclusion: BFMs是推动人形机器人智能发展的有前景的范式，但仍需解决当前局限性和挑战。

Abstract: Humanoid robots are drawing significant attention as versatile platforms for
complex motor control, human-robot interaction, and general-purpose physical
intelligence. However, achieving efficient whole-body control (WBC) in
humanoids remains a fundamental challenge due to sophisticated dynamics,
underactuation, and diverse task requirements. While learning-based controllers
have shown promise for complex tasks, their reliance on labor-intensive and
costly retraining for new scenarios limits real-world applicability. To address
these limitations, behavior(al) foundation models (BFMs) have emerged as a new
paradigm that leverages large-scale pretraining to learn reusable primitive
skills and behavioral priors, enabling zero-shot or rapid adaptation to a wide
range of downstream tasks. In this paper, we present a comprehensive overview
of BFMs for humanoid WBC, tracing their development across diverse pre-training
pipelines. Furthermore, we discuss real-world applications, current
limitations, urgent challenges, and future opportunities, positioning BFMs as a
key approach toward scalable and general-purpose humanoid intelligence.
Finally, we provide a curated and long-term list of BFM papers and projects to
facilitate more subsequent research, which is available at
https://github.com/yuanmingqi/awesome-bfm-papers.

</details>


### [23] [Critical Anatomy-Preserving & Terrain-Augmenting Navigation (CAPTAiN): Application to Laminectomy Surgical Education](https://arxiv.org/abs/2506.20496)
*Jonathan Wang,Hisashi Ishida,David Usevitch,Kesavan Venkatesh,Yi Wang,Mehran Armand,Rachel Bronheim,Amit Jain,Adnan Munawar*

Main category: cs.RO

TL;DR: CAPTAiN系统通过分层彩色体素引导，显著提高了椎板切除术的完成率并降低了认知负荷，使新手表现接近高级学员。


<details>
  <summary>Details</summary>
Motivation: 椎板切除术中硬膜撕裂风险高（11.3%），且缺乏辅助工具，患者解剖结构差异增加了新手学习难度。

Method: 开发CAPTAiN导航系统，通过分层彩色体素增强解剖意识，并与标准非导航方法对比，由11名学员完成110次虚拟手术。

Result: CAPTAiN显著提高目标解剖完成率（87.99% vs. 74.42%），降低认知负荷，缩小经验差距。

Conclusion: CAPTAiN优化手术执行，支持技能发展，并有望应用于其他外科领域。

Abstract: Surgical training remains a crucial milestone in modern medicine, with
procedures such as laminectomy exemplifying the high risks involved.
Laminectomy drilling requires precise manual control to mill bony tissue while
preserving spinal segment integrity and avoiding breaches in the dura: the
protective membrane surrounding the spinal cord. Despite unintended tears
occurring in up to 11.3% of cases, no assistive tools are currently utilized to
reduce this risk. Variability in patient anatomy further complicates learning
for novice surgeons. This study introduces CAPTAiN, a critical
anatomy-preserving and terrain-augmenting navigation system that provides
layered, color-coded voxel guidance to enhance anatomical awareness during
spinal drilling. CAPTAiN was evaluated against a standard non-navigated
approach through 110 virtual laminectomies performed by 11 orthopedic residents
and medical students. CAPTAiN significantly improved surgical completion rates
of target anatomy (87.99% vs. 74.42%) and reduced cognitive load across
multiple NASA-TLX domains. It also minimized performance gaps across experience
levels, enabling novices to perform on par with advanced trainees. These
findings highlight CAPTAiN's potential to optimize surgical execution and
support skill development across experience levels. Beyond laminectomy, it
demonstrates potential for broader applications across various surgical and
drilling procedures, including those in neurosurgery, otolaryngology, and other
medical fields.

</details>


### [24] [Leveraging Correlation Across Test Platforms for Variance-Reduced Metric Estimation](https://arxiv.org/abs/2506.20553)
*Rachel Luo,Heng Yang,Michael Watson,Apoorva Sharma,Sushant Veer,Edward Schmerling,Marco Pavone*

Main category: cs.RO

TL;DR: 提出一种利用配对数据（如仿真和现实观测）的控制变量方法，减少机器人系统验证所需的现实样本数量。


<details>
  <summary>Details</summary>
Motivation: 减少基于学习的机器人系统验证的高成本和数据不足问题。

Method: 利用控制变量方法，结合廉价辅助测量（如仿真输出）优化蒙特卡罗估计。

Result: 理论分析和实验表明，方法显著提高了样本效率，降低了现实测试负担。

Conclusion: 该方法能更高效、经济地评估机器人系统性能。

Abstract: Learning-based robotic systems demand rigorous validation to assure reliable
performance, but extensive real-world testing is often prohibitively expensive,
and if conducted may still yield insufficient data for high-confidence
guarantees. In this work, we introduce a general estimation framework that
leverages paired data across test platforms, e.g., paired simulation and
real-world observations, to achieve better estimates of real-world metrics via
the method of control variates. By incorporating cheap and abundant auxiliary
measurements (for example, simulator outputs) as control variates for costly
real-world samples, our method provably reduces the variance of Monte Carlo
estimates and thus requires significantly fewer real-world samples to attain a
specified confidence bound on the mean performance. We provide theoretical
analysis characterizing the variance and sample-efficiency improvement, and
demonstrate empirically in autonomous driving and quadruped robotics settings
that our approach achieves high-probability bounds with markedly improved
sample efficiency. Our technique can lower the real-world testing burden for
validating the performance of the stack, thereby enabling more efficient and
cost-effective experimental evaluation of robotic systems.

</details>


### [25] [HRIBench: Benchmarking Vision-Language Models for Real-Time Human Perception in Human-Robot Interaction](https://arxiv.org/abs/2506.20566)
*Zhonghao Shi,Enyu Zhao,Nathaniel Dennler,Jingzhen Wang,Xinyang Xu,Kaleen Shrestha,Mengxue Fu,Daniel Seita,Maja Matarić*

Main category: cs.RO

TL;DR: HRIBench是一个用于评估视觉语言模型（VLMs）在人类感知任务中性能和延迟权衡的基准测试，覆盖五个关键领域。结果显示当前VLMs在实时部署中表现不足。


<details>
  <summary>Details</summary>
Motivation: 研究VLMs在人类-机器人交互（HRI）中的实时感知能力及其性能与延迟的权衡。

Method: 开发HRIBench基准测试，包含1000个视觉问答问题，覆盖五个HRI关键领域，并评估11种VLMs。

Result: 当前VLMs在核心感知能力上表现不足，且缺乏适合实时部署的性能-延迟权衡。

Conclusion: 需要开发更小、低延迟的VLMs以提升实时HRI感知能力。

Abstract: Real-time human perception is crucial for effective human-robot interaction
(HRI). Large vision-language models (VLMs) offer promising generalizable
perceptual capabilities but often suffer from high latency, which negatively
impacts user experience and limits VLM applicability in real-world scenarios.
To systematically study VLM capabilities in human perception for HRI and
performance-latency trade-offs, we introduce HRIBench, a visual
question-answering (VQA) benchmark designed to evaluate VLMs across a diverse
set of human perceptual tasks critical for HRI. HRIBench covers five key
domains: (1) non-verbal cue understanding, (2) verbal instruction
understanding, (3) human-robot object relationship understanding, (4) social
navigation, and (5) person identification. To construct HRIBench, we collected
data from real-world HRI environments to curate questions for non-verbal cue
understanding, and leveraged publicly available datasets for the remaining four
domains. We curated 200 VQA questions for each domain, resulting in a total of
1000 questions for HRIBench. We then conducted a comprehensive evaluation of
both state-of-the-art closed-source and open-source VLMs (N=11) on HRIBench.
Our results show that, despite their generalizability, current VLMs still
struggle with core perceptual capabilities essential for HRI. Moreover, none of
the models within our experiments demonstrated a satisfactory
performance-latency trade-off suitable for real-time deployment, underscoring
the need for future research on developing smaller, low-latency VLMs with
improved human perception capabilities. HRIBench and our results can be found
in this Github repository: https://github.com/interaction-lab/HRIBench.

</details>


### [26] [Communication-Aware Map Compression for Online Path-Planning: A Rate-Distortion Approach](https://arxiv.org/abs/2506.20579)
*Ali Reza Pedram,Evangelos Psomiadis,Dipankar Maity,Panagiotis Tsiotras*

Main category: cs.RO

TL;DR: 论文提出了一种在带宽限制下，通过压缩地图信息辅助机器人协作导航的方法，优化了通信效率和任务相关性。


<details>
  <summary>Details</summary>
Motivation: 解决未知环境中两个机器人（Seeker和Supporter）协作导航时，如何在带宽限制下高效传输地图信息以支持路径规划的问题。

Method: 引入基于二进制编码长度的比特率度量，将压缩设计问题建模为率失真优化问题，采用反向注水法求解。

Result: 仿真结果表明，该方法能在严格带宽限制下生成任务相关的地图压缩表示，有效指导Seeker的路径规划。

Conclusion: 提出的方法通过优化压缩策略，实现了高效、低计算量的实时协作导航，减少了通信开销。

Abstract: This paper addresses the problem of collaborative navigation in an unknown
environment, where two robots, referred to in the sequel as the Seeker and the
Supporter, traverse the space simultaneously. The Supporter assists the Seeker
by transmitting a compressed representation of its local map under bandwidth
constraints to support the Seeker's path-planning task. We introduce a bit-rate
metric based on the expected binary codeword length to quantify communication
cost. Using this metric, we formulate the compression design problem as a
rate-distortion optimization problem that determines when to communicate, which
regions of the map should be included in the compressed representation, and at
what resolution (i.e., quantization level) they should be encoded. Our
formulation allows different map regions to be encoded at varying quantization
levels based on their relevance to the Seeker's path-planning task. We
demonstrate that the resulting optimization problem is convex, and admits a
closed-form solution known in the information theory literature as reverse
water-filling, enabling efficient, low-computation, and real-time
implementation. Additionally, we show that the Seeker can infer the compression
decisions of the Supporter independently, requiring only the encoded map
content and not the encoding policy itself to be transmitted, thereby reducing
communication overhead. Simulation results indicate that our method effectively
constructs compressed, task-relevant map representations, both in content and
resolution, that guide the Seeker's planning decisions even under tight
bandwidth limitations.

</details>


### [27] [A Computationally Aware Multi Objective Framework for Camera LiDAR Calibration](https://arxiv.org/abs/2506.20636)
*Venkat Karramreddy,Rangarajan Ramanujam*

Main category: cs.RO

TL;DR: 提出了一种多目标优化框架，用于联合优化LiDAR与相机的外参标定中的几何对齐误差和计算成本。


<details>
  <summary>Details</summary>
Motivation: LiDAR与相机传感器的精确外参标定对自动驾驶系统的可靠感知至关重要。

Method: 使用NSGA-II进化算法，优化6自由度变换和点采样率，生成Pareto前沿，平衡标定精度与计算效率。

Result: 在KITTI数据集上验证，性能优于现有梯度法和学习方法，具有可解释性和低部署开销。

Conclusion: 该框架为资源受限条件下的标定提供了可扩展且透明的方法，适用于长期自主运行的L3+车辆。

Abstract: Accurate extrinsic calibration between LiDAR and camera sensors is important
for reliable perception in autonomous systems. In this paper, we present a
novel multi-objective optimization framework that jointly minimizes the
geometric alignment error and computational cost associated with camera-LiDAR
calibration. We optimize two objectives: (1) error between projected LiDAR
points and ground-truth image edges, and (2) a composite metric for
computational cost reflecting runtime and resource usage. Using the NSGA-II
\cite{deb2002nsga2} evolutionary algorithm, we explore the parameter space
defined by 6-DoF transformations and point sampling rates, yielding a
well-characterized Pareto frontier that exposes trade-offs between calibration
fidelity and resource efficiency. Evaluations are conducted on the KITTI
dataset using its ground-truth extrinsic parameters for validation, with
results verified through both multi-objective and constrained single-objective
baselines. Compared to existing gradient-based and learned calibration methods,
our approach demonstrates interpretable, tunable performance with lower
deployment overhead. Pareto-optimal configurations are further analyzed for
parameter sensitivity and innovation insights. A preference-based
decision-making strategy selects solutions from the Pareto knee region to suit
the constraints of the embedded system. The robustness of calibration is tested
across variable edge-intensity weighting schemes, highlighting optimal balance
points. Although real-time deployment on embedded platforms is deferred to
future work, this framework establishes a scalable and transparent method for
calibration under realistic misalignment and resource-limited conditions,
critical for long-term autonomy, particularly in SAE L3+ vehicles receiving OTA
updates.

</details>


### [28] [DemoDiffusion: One-Shot Human Imitation using pre-trained Diffusion Policy](https://arxiv.org/abs/2506.20668)
*Sungjae Park,Homanga Bharadhwaj,Shubham Tulsiani*

Main category: cs.RO

TL;DR: DemoDiffusion是一种简单且可扩展的方法，通过模仿单次人类演示使机器人能在自然环境中完成任务。结合运动重定向和扩散策略优化轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决机器人模仿人类演示时轨迹不匹配的问题，避免需要在线强化学习或配对数据。

Method: 1. 通过运动重定向将人类手部运动转换为机器人轨迹；2. 使用预训练的扩散策略优化轨迹。

Result: 在仿真和真实环境中优于基准策略和重定向轨迹，适应新任务和场景。

Conclusion: DemoDiffusion通过结合人类演示和扩散策略，实现了高效且鲁棒的机器人操作。

Abstract: We propose DemoDiffusion, a simple and scalable method for enabling robots to
perform manipulation tasks in natural environments by imitating a single human
demonstration. Our approach is based on two key insights. First, the hand
motion in a human demonstration provides a useful prior for the robot's
end-effector trajectory, which we can convert into a rough open-loop robot
motion trajectory via kinematic retargeting. Second, while this retargeted
motion captures the overall structure of the task, it may not align well with
plausible robot actions in-context. To address this, we leverage a pre-trained
generalist diffusion policy to modify the trajectory, ensuring it both follows
the human motion and remains within the distribution of plausible robot
actions. Our approach avoids the need for online reinforcement learning or
paired human-robot data, enabling robust adaptation to new tasks and scenes
with minimal manual effort. Experiments in both simulation and real-world
settings show that DemoDiffusion outperforms both the base policy and the
retargeted trajectory, enabling the robot to succeed even on tasks where the
pre-trained generalist policy fails entirely. Project page:
https://demodiffusion.github.io/

</details>
