<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 21]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Dynamic Shape Control of Soft Robots Enabled by Data-Driven Model Reduction](https://arxiv.org/abs/2511.03931)
*Iman Adibnazari,Harsh Sharma,Myungsun Park,Jacobo Cervera-Torralba,Boris Kramer,Michael T. Tolley*

Main category: cs.RO

TL;DR: 本文比较了三种数据驱动模型降阶技术（ERA、DMDc、LOpInf）在软体机器人动态形状控制中的效果，发现基于LOpInf的控制器在所有实验中都能产生最低的跟踪误差。


<details>
  <summary>Details</summary>
Motivation: 软体机器人需要能够处理高维动力学的控制器，但缺乏适用于控制的通用建模工具。

Method: 使用三种数据驱动模型降阶技术（ERA、DMDc、LOpInf）生成线性模型，并基于这些模型开发模型预测控制策略，在模拟的鳗鱼启发的软体机器人上进行动态形状控制实验。

Result: 在所有三个实验中（跟踪可行参考轨迹、生物鳗鱼运动学轨迹、物理模拟轨迹），基于LOpInf的控制策略产生的跟踪误差均低于其他模型。

Conclusion: LOpInf方法在软体机器人动态形状控制中表现最优，为软体机器人的控制提供了有效的模型降阶解决方案。

Abstract: Soft robots have shown immense promise in settings where they can leverage
dynamic control of their entire bodies. However, effective dynamic shape
control requires a controller that accounts for the robot's high-dimensional
dynamics--a challenge exacerbated by a lack of general-purpose tools for
modeling soft robots amenably for control. In this work, we conduct a
comparative study of data-driven model reduction techniques for generating
linear models amendable to dynamic shape control. We focus on three
methods--the eigensystem realization algorithm, dynamic mode decomposition with
control, and the Lagrangian operator inference (LOpInf) method. Using each
class of model, we explored their efficacy in model predictive control policies
for the dynamic shape control of a simulated eel-inspired soft robot in three
experiments: 1) tracking simulated reference trajectories guaranteed to be
feasible, 2) tracking reference trajectories generated from a biological model
of eel kinematics, and 3) tracking reference trajectories generated by a
reduced-scale physical analog. In all experiments, the LOpInf-based policies
generated lower tracking errors than policies based on other models.

</details>


### [2] [Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots](https://arxiv.org/abs/2511.03996)
*Yushi Wang,Changsheng Luo,Penghui Chen,Jianran Liu,Weijian Sun,Tong Guo,Kechang Yang,Biao Hu,Yangang Zhang,Mingguo Zhao*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的统一控制器，使仿人机器人能够通过视觉感知和运动控制的直接集成来获得反应式足球技能。


<details>
  <summary>Details</summary>
Motivation: 现有系统通常依赖解耦模块，导致动态环境中响应延迟和行为不连贯，而现实世界的感知限制进一步加剧了这些问题。

Method: 扩展了对抗运动先验到现实动态环境中的感知设置，结合编码器-解码器架构和虚拟感知系统，从有缺陷的观察中恢复特权状态，建立感知与动作的主动协调。

Result: 生成的控制器表现出强大的反应性，在各种场景中持续执行连贯且鲁棒的足球行为，包括真实的RoboCup比赛。

Conclusion: 该方法成功地将视觉感知与运动控制直接集成，实现了仿人机器人在动态足球环境中的反应式技能获取。

Abstract: Humanoid soccer poses a representative challenge for embodied intelligence,
requiring robots to operate within a tightly coupled perception-action loop.
However, existing systems typically rely on decoupled modules, resulting in
delayed responses and incoherent behaviors in dynamic environments, while
real-world perceptual limitations further exacerbate these issues. In this
work, we present a unified reinforcement learning-based controller that enables
humanoid robots to acquire reactive soccer skills through the direct
integration of visual perception and motion control. Our approach extends
Adversarial Motion Priors to perceptual settings in real-world dynamic
environments, bridging motion imitation and visually grounded dynamic control.
We introduce an encoder-decoder architecture combined with a virtual perception
system that models real-world visual characteristics, allowing the policy to
recover privileged states from imperfect observations and establish active
coordination between perception and action. The resulting controller
demonstrates strong reactivity, consistently executing coherent and robust
soccer behaviors across various scenarios, including real RoboCup matches.

</details>


### [3] [Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration](https://arxiv.org/abs/2511.04009)
*Chenzui Li,Yiming Chen,Xi Wu,Giacinto Barresi,Fei Chen*

Main category: cs.RO

TL;DR: 提出了一种用于增强双人协作搬运任务中人体工学和力操纵性的上肢姿态优化方法，通过优化简化人体骨骼模型的关节角度来平衡安全性和操作能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常只关注人类安全或操作效率，而该方法独特地将这两个方面整合起来，以在不同条件下（如不同的抓握姿势和物体形状）加强协作。

Method: 通过最小化成本函数来优化简化人体骨骼模型的关节角度，优先考虑安全性和操作能力；通过变换模块生成机器人末端执行器的参考姿态；提出双手机器人模型预测阻抗控制器（MPIC）来重新校准末端执行器姿态。

Result: 该方法在人与人协作（HHC）和人机协作（HRC）中通过不同受试者和物体进行了验证，实验结果显示通过比较优化前后目标肌肉的激活情况，肌肉状况有显著改善。

Conclusion: 所提出的方法能够有效改善双人协作搬运任务中的人体工学和力操纵性，显著提升肌肉状况，为安全高效的人机协作提供了有效解决方案。

Abstract: This paper introduces an upper limb postural optimization method for
enhancing physical ergonomics and force manipulability during bimanual
human-robot co-carrying tasks. Existing research typically emphasizes human
safety or manipulative efficiency, whereas our proposed method uniquely
integrates both aspects to strengthen collaboration across diverse conditions
(e.g., different grasping postures of humans, and different shapes of objects).
Specifically, the joint angles of a simplified human skeleton model are
optimized by minimizing the cost function to prioritize safety and manipulative
capability. To guide humans towards the optimized posture, the reference
end-effector poses of the robot are generated through a transformation module.
A bimanual model predictive impedance controller (MPIC) is proposed for our
human-like robot, CURI, to recalibrate the end effector poses through planned
trajectories. The proposed method has been validated through various subjects
and objects during human-human collaboration (HHC) and human-robot
collaboration (HRC). The experimental results demonstrate significant
improvement in muscle conditions by comparing the activation of target muscles
before and after optimization.

</details>


### [4] [An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue](https://arxiv.org/abs/2511.04042)
*Kailun Ji,Xiaoyu Hu,Xinyu Zhang,Jun Chen*

Main category: cs.RO

TL;DR: 提出基于LLM-CRF的系统，通过自然语言和多模态交互解决无人机群在灾害搜救中的意图-行动差距问题，显著提升任务效率和降低认知负担


<details>
  <summary>Details</summary>
Motivation: 解决大规模灾害搜救中无人机群协调时存在的"意图-行动差距"问题，即高层次的救援目标难以有效转化为低层次的群控指令，减轻操作员的认知负担

Method: 开发LLM-CRF系统，利用大语言模型作为认知引擎，通过语音或图形标注捕获操作员意图，进行意图理解、分层任务分解和任务规划，形成闭环框架

Result: 在模拟搜救场景中，相比传统命令接口，任务完成时间减少64.2%，任务成功率提高7%，NASA-TLX认知负荷评分下降42.9%

Conclusion: LLM能够创建更直观有效的人-群协作系统，在高风险场景中具有巨大潜力

Abstract: Large-scale disaster Search And Rescue (SAR) operations are persistently
challenged by complex terrain and disrupted communications. While Unmanned
Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area
search and supply delivery, yet their effective coordination places a
significant cognitive burden on human operators. The core human-machine
collaboration bottleneck lies in the ``intention-to-action gap'', which is an
error-prone process of translating a high-level rescue objective into a
low-level swarm command under high intensity and pressure. To bridge this gap,
this study proposes a novel LLM-CRF system that leverages Large Language Models
(LLMs) to model and augment human-swarm teaming cognition. The proposed
framework initially captures the operator's intention through natural and
multi-modal interactions with the device via voice or graphical annotations. It
then employs the LLM as a cognitive engine to perform intention comprehension,
hierarchical task decomposition, and mission planning for the UAV swarm. This
closed-loop framework enables the swarm to act as a proactive partner,
providing active feedback in real-time while reducing the need for manual
monitoring and control, which considerably advances the efficacy of the SAR
task. We evaluate the proposed framework in a simulated SAR scenario.
Experimental results demonstrate that, compared to traditional order and
command-based interfaces, the proposed LLM-driven approach reduced task
completion time by approximately $64.2\%$ and improved task success rate by
$7\%$. It also leads to a considerable reduction in subjective cognitive
workload, with NASA-TLX scores dropping by $42.9\%$. This work establishes the
potential of LLMs to create more intuitive and effective human-swarm
collaborations in high-stakes scenarios.

</details>


### [5] [Enhancing Fault-Tolerant Space Computing: Guidance Navigation and Control (GNC) and Landing Vision System (LVS) Implementations on Next-Gen Multi-Core Processors](https://arxiv.org/abs/2511.04052)
*Kyongsik Yun,David Bayard,Gerik Kubiak,Austin Owens,Andrew Johnson,Ryan Johnson,Dan Scharf,Thomas Lu*

Main category: cs.RO

TL;DR: 评估新一代多核处理器在行星探测任务中部署GNC和LVS算法的性能，并提出ARBITER多核投票机制进行实时故障检测和纠正。


<details>
  <summary>Details</summary>
Motivation: 未来行星探测任务需要高性能、容错的计算能力，以支持自主的制导导航控制和着陆视觉系统在进入、下降和着陆阶段的运行。

Method: 在HPSC、Snapdragon VOXL2和AMD Xilinx Versal等多核处理器上部署GNC和LVS算法，并开发ARBITER多核投票机制进行实时故障检测和纠正。

Result: LVS图像处理实现15倍加速，GFOLD轨迹优化实现250倍加速；ARBITER在静态优化和动态闭环控制中验证有效；故障注入研究识别GFOLD梯度计算阶段对位级错误最敏感。

Conclusion: 建立了可扩展且节能的架构，适用于需要机载自主性、低延迟和故障恢复能力的未来任务，如火星样本返回、土卫二轨道着陆器和谷神星样本返回。

Abstract: Future planetary exploration missions demand high-performance, fault-tolerant
computing to enable autonomous Guidance, Navigation, and Control (GNC) and
Lander Vision System (LVS) operations during Entry, Descent, and Landing (EDL).
This paper evaluates the deployment of GNC and LVS algorithms on
next-generation multi-core processors--HPSC, Snapdragon VOXL2, and AMD Xilinx
Versal--demonstrating up to 15x speedup for LVS image processing and over 250x
speedup for Guidance for Fuel-Optimal Large Divert (GFOLD) trajectory
optimization compared to legacy spaceflight hardware. To ensure computational
reliability, we present ARBITER (Asynchronous Redundant Behavior Inspection for
Trusted Execution and Recovery), a Multi-Core Voting (MV) mechanism that
performs real-time fault detection and correction across redundant cores.
ARBITER is validated in both static optimization tasks (GFOLD) and dynamic
closed-loop control (Attitude Control System). A fault injection study further
identifies the gradient computation stage in GFOLD as the most sensitive to
bit-level errors, motivating selective protection strategies and vector-based
output arbitration. This work establishes a scalable and energy-efficient
architecture for future missions, including Mars Sample Return, Enceladus
Orbilander, and Ceres Sample Return, where onboard autonomy, low latency, and
fault resilience are critical.

</details>


### [6] [CBMC-V3: A CNS-inspired Control Framework Towards Manipulation Agility with SNN](https://arxiv.org/abs/2511.04109)
*Yanbo Pang,Qingkai Li,Mingguo Zhao*

Main category: cs.RO

TL;DR: 提出基于脉冲神经网络的仿生控制框架，模拟人类中枢神经系统，实现机器人手臂在复杂环境中的敏捷控制。


<details>
  <summary>Details</summary>
Motivation: 随着机器人手臂应用扩展到医疗、服务和日常生活领域，现有控制算法难以在具有动态轨迹、不可预测交互和多样化物体的复杂环境中实现敏捷操作。

Method: 构建包含五个控制模块（大脑皮层、小脑、丘脑、脑干、脊髓）、三个层次控制级别和两条信息通路的仿生框架，全部使用脉冲神经网络实现，包括LIF神经元、强化学习和回归学习等技术。

Result: 在仿真和真实机器人平台上验证，该方法在多种负载和轨迹条件下优于工业级位置控制，展现出更好的操作敏捷性。

Conclusion: 基于脉冲神经网络的仿生控制框架能够有效解决复杂环境中的机器人手臂敏捷控制问题，为机器人控制提供了新的生物启发式解决方案。

Abstract: As robotic arm applications extend beyond industrial settings into
healthcare, service, and daily life, existing control algorithms struggle to
achieve the agile manipulation required for complex environments with dynamic
trajectories, unpredictable interactions, and diverse objects. This paper
presents a biomimetic control framework based on Spiking Neural Networks (SNN),
inspired by the human Central Nervous System (CNS), to achieve agile control in
such environments. The proposed framework features five control modules
(cerebral cortex, cerebellum, thalamus, brainstem, spinal cord), three
hierarchical control levels (first-order, second-order, third-order), and two
information pathways (ascending, descending). Each module is fully implemented
using SNN. The spinal cord module uses spike encoding and Leaky
Integrate-and-Fire (LIF) neurons for feedback control. The brainstem module
employs a network of LIF and non-spiking LIF neurons to dynamically adjust
spinal cord parameters via reinforcement learning. The thalamus module
similarly adjusts the cerebellum's torque outputs. The cerebellum module uses a
recurrent SNN to learn the robotic arm's dynamics through regression, providing
feedforward gravity compensation torques. The framework is validated both in
simulation and on real-world robotic arm platform under various loads and
trajectories. Results demonstrate that our method outperforms the
industrial-grade position control in manipulation agility.

</details>


### [7] [BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning](https://arxiv.org/abs/2511.04131)
*Yitang Li,Zhengyi Luo,Tonghe Zhang,Cunxi Dai,Anssi Kanervisto,Andrea Tirinzoni,Haoyang Weng,Kris Kitani,Mateusz Guzek,Ahmed Touati,Alessandro Lazaric,Matteo Pirotta,Guanya Shi*

Main category: cs.RO

TL;DR: BFM-Zero是一个用于人形机器人的行为基础模型框架，通过共享潜在表示统一多种控制任务，支持零样本运动跟踪、目标到达和奖励优化，以及少样本优化适应。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么仅部署在模拟人形角色上，要么专门用于特定任务如跟踪，缺乏能够统一多种控制任务的通用策略。

Method: 基于无监督强化学习和前向-后向模型，学习嵌入运动、目标和奖励的共享潜在表示，结合关键奖励塑造、领域随机化和历史依赖非对称学习来弥合模拟到现实的差距。

Result: 在真实世界的Unitree G1人形机器人上实现了多功能和鲁棒的全身体技能，通过多种推理方法完成下游任务而无需重新训练。

Conclusion: BFM-Zero朝着可扩展、可提示的全身体人形控制行为基础模型迈出了重要一步。

Abstract: Building Behavioral Foundation Models (BFMs) for humanoid robots has the
potential to unify diverse control tasks under a single, promptable generalist
policy. However, existing approaches are either exclusively deployed on
simulated humanoid characters, or specialized to specific tasks such as
tracking. We propose BFM-Zero, a framework that learns an effective shared
latent representation that embeds motions, goals, and rewards into a common
space, enabling a single policy to be prompted for multiple downstream tasks
without retraining. This well-structured latent space in BFM-Zero enables
versatile and robust whole-body skills on a Unitree G1 humanoid in the real
world, via diverse inference methods, including zero-shot motion tracking, goal
reaching, and reward optimization, and few-shot optimization-based adaptation.
Unlike prior on-policy reinforcement learning (RL) frameworks, BFM-Zero builds
upon recent advancements in unsupervised RL and Forward-Backward (FB) models,
which offer an objective-centric, explainable, and smooth latent representation
of whole-body motions. We further extend BFM-Zero with critical reward shaping,
domain randomization, and history-dependent asymmetric learning to bridge the
sim-to-real gap. Those key design choices are quantitatively ablated in
simulation. A first-of-its-kind model, BFM-Zero establishes a step toward
scalable, promptable behavioral foundation models for whole-body humanoid
control.

</details>


### [8] [PUL-SLAM: Path-Uncertainty Co-Optimization with Lightweight Stagnation Detection for Efficient Robotic Exploration](https://arxiv.org/abs/2511.04180)
*Yizhen Yin,Dapeng Feng,Hongbo Chen,Yuhua Qi*

Main category: cs.RO

TL;DR: 提出了一种结合路径-不确定性协同优化深度强化学习和轻量级停滞检测机制的混合框架，显著提升了主动SLAM的探索效率和路径质量。


<details>
  <summary>Details</summary>
Motivation: 现有主动SLAM方法存在探索速度慢和路径次优的问题，需要一种能够平衡探索与利用、减少冗余探索的高效解决方案。

Method: 采用路径-不确定性协同优化框架通过双目标奖励函数联合优化旅行距离和地图不确定性，结合轻量级停滞检测机制通过激光雷达静态异常检测和地图更新停滞检测来减少冗余探索。

Result: 相比前沿方法和RRT方法，该方法将探索时间缩短了65%，路径距离减少了42%，在复杂环境中显著提高了探索效率，同时保持了可靠的地图完整性。

Conclusion: 该混合框架有效解决了主动SLAM中的探索效率和路径优化问题，消融研究证实了协同机制的加速训练收敛效果，物理机器人平台验证了算法从仿真到现实环境的成功迁移性。

Abstract: Existing Active SLAM methodologies face issues such as slow exploration speed
and suboptimal paths. To address these limitations, we propose a hybrid
framework combining a Path-Uncertainty Co-Optimization Deep Reinforcement
Learning framework and a Lightweight Stagnation Detection mechanism. The
Path-Uncertainty Co-Optimization framework jointly optimizes travel distance
and map uncertainty through a dual-objective reward function, balancing
exploration and exploitation. The Lightweight Stagnation Detection reduces
redundant exploration through Lidar Static Anomaly Detection and Map Update
Stagnation Detection, terminating episodes on low expansion rates. Experimental
results show that compared with the frontier-based method and RRT method, our
approach shortens exploration time by up to 65% and reduces path distance by up
to 42%, significantly improving exploration efficiency in complex environments
while maintaining reliable map completeness. Ablation studies confirm that the
collaborative mechanism accelerates training convergence. Empirical validation
on a physical robotic platform demonstrates the algorithm's practical
applicability and its successful transferability from simulation to real-world
environments.

</details>


### [9] [GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments](https://arxiv.org/abs/2511.04199)
*Shenglin Wang,Mingtong Dai,Jingxuan Su,Lingbo Liu,Chunjie Chen,Xinyu Wu,Liang Lin*

Main category: cs.RO

TL;DR: GraspView是一个仅使用RGB相机的机器人抓取系统，在杂乱环境中无需深度传感器即可实现精确操作，特别适用于透明物体和遮挡严重的情况。


<details>
  <summary>Details</summary>
Motivation: 传统机器人抓取依赖RGB-D相机提供几何信息，但在透明或反光物体上会失效，且在近距离时性能下降。需要一种仅使用RGB相机的可靠抓取方案。

Method: 集成三个关键组件：全局感知场景重建（从单RGB视图生成局部一致的几何）、渲染评分主动感知策略（动态选择最佳视角揭示遮挡区域）、在线度量对齐模块（校准抓取预测与机器人运动学）。

Result: 实验表明GraspView在多种桌面物体上显著优于RGB-D和单视图RGB基线方法，特别是在严重遮挡、近场感知和透明物体情况下表现优异。

Conclusion: GraspView是RGB-D管道的实用替代方案，能够在非结构化真实环境中实现可靠抓取。

Abstract: Robotic grasping is a fundamental capability for autonomous manipulation, yet
remains highly challenging in cluttered environments where occlusion, poor
perception quality, and inconsistent 3D reconstructions often lead to unstable
or failed grasps. Conventional pipelines have widely relied on RGB-D cameras to
provide geometric information, which fail on transparent or glossy objects and
degrade at close range. We present GraspView, an RGB-only robotic grasping
pipeline that achieves accurate manipulation in cluttered environments without
depth sensors. Our framework integrates three key components: (i) global
perception scene reconstruction, which provides locally consistent, up-to-scale
geometry from a single RGB view and fuses multi-view projections into a
coherent global 3D scene; (ii) a render-and-score active perception strategy,
which dynamically selects next-best-views to reveal occluded regions; and (iii)
an online metric alignment module that calibrates VGGT predictions against
robot kinematics to ensure physical scale consistency. Building on these
tailor-designed modules, GraspView performs best-view global grasping, fusing
multi-view reconstructions and leveraging GraspNet for robust execution.
Experiments on diverse tabletop objects demonstrate that GraspView
significantly outperforms both RGB-D and single-view RGB baselines, especially
under heavy occlusion, near-field sensing, and with transparent objects. These
results highlight GraspView as a practical and versatile alternative to RGB-D
pipelines, enabling reliable grasping in unstructured real-world environments.

</details>


### [10] [Can Context Bridge the Reality Gap? Sim-to-Real Transfer of Context-Aware Policies](https://arxiv.org/abs/2511.04249)
*Marco Iannotta,Yuxuan Yang,Johannes A. Stork,Erik Schaffernicht,Todor Stoyanov*

Main category: cs.RO

TL;DR: 该论文提出了一种上下文感知的强化学习方法，通过将动态参数估计集成到基于域随机化的RL框架中，改善了模拟到现实的迁移性能。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在机器人领域中的模拟到现实迁移问题，传统域随机化方法虽然能提升泛化性但会降低性能，作者探索通过让策略感知动态参数变化来改进迁移效果。

Method: 在基于域随机化的强化学习框架中集成了上下文估计模块，系统比较了最先进的监督策略，让策略能够根据估计的动态参数（上下文）进行条件化。

Result: 在标准控制基准和真实世界推任务（使用Franka Emika Panda机器人）上的评估显示，上下文感知策略在所有设置中都优于上下文无关的基线方法，但最佳监督策略因任务而异。

Conclusion: 上下文感知策略能有效提升模拟到现实的迁移性能，但需要根据具体任务选择合适的监督策略。

Abstract: Sim-to-real transfer remains a major challenge in reinforcement learning (RL)
for robotics, as policies trained in simulation often fail to generalize to the
real world due to discrepancies in environment dynamics. Domain Randomization
(DR) mitigates this issue by exposing the policy to a wide range of randomized
dynamics during training, yet leading to a reduction in performance. While
standard approaches typically train policies agnostic to these variations, we
investigate whether sim-to-real transfer can be improved by conditioning the
policy on an estimate of the dynamics parameters -- referred to as context. To
this end, we integrate a context estimation module into a DR-based RL framework
and systematically compare SOTA supervision strategies. We evaluate the
resulting context-aware policies in both a canonical control benchmark and a
real-world pushing task using a Franka Emika Panda robot. Results show that
context-aware policies outperform the context-agnostic baseline across all
settings, although the best supervision strategy depends on the task.

</details>


### [11] [Design and Control of a Coaxial Dual-rotor Reconfigurable Tailsitter UAV Based on Swashplateless Mechanism](https://arxiv.org/abs/2511.04251)
*Jinfeng Liang,Haocheng Guo,Ximin Lyu*

Main category: cs.RO

TL;DR: 本文提出了一种可重构机翼的尾坐式VTOL无人机，采用同轴异构双旋翼配置和无斜盘机构，通过优化结构设计实现多旋翼模式下的抗风能力和固定翼模式下的高效飞行。


<details>
  <summary>Details</summary>
Motivation: 传统尾坐式VTOL无人机在多旋翼模式下暴露较大的机身面积，容易受到风扰影响。需要解决抗风能力和功率效率的问题。

Method: 1. 可重构机翼设计：多旋翼模式收缩机翼，固定翼模式展开机翼；2. 同轴异构双旋翼配置提高功率效率；3. 改进的无斜盘机构控制俯仰和滚转；4. 通过添加挥舞铰链优化结构减少振动。

Result: 通过全面的过渡飞行测试验证了无人机在整个飞行包线内的稳定飞行性能，显著降低了总功耗和结构振动。

Conclusion: 所提出的可重构机翼尾坐式无人机设计有效解决了风扰问题，提高了功率效率，简化了结构复杂性，实现了稳定的全包线飞行性能。

Abstract: The tailsitter vertical takeoff and landing (VTOL) UAV is widely used due to
its lower dead weight, which eliminates the actuators and mechanisms for
tilting. However, the tailsitter UAV is susceptible to wind disturbances in
multi-rotor mode, as it exposes a large frontal fuselage area. To address this
issue, our tailsitter UAV features a reconfigurable wing design, allowing wings
to retract in multi-rotor mode and extend in fixed- wing mode. Considering
power efficiency, we design a coaxial heterogeneous dual-rotor configuration,
which significantly re- duces the total power consumption. To reduce structural
weight and simplify structural complexity, we employ a swashplateless mechanism
with an improved design to control pitch and roll in multi-rotor mode. We
optimize the structure of the swashplateless mechanism by adding flapping
hinges, which reduces vibration during cyclic acceleration and deceleration.
Finally, we perform comprehensive transition flight tests to validate stable
flight performance across the entire flight envelope of the tailsitter UAV.

</details>


### [12] [MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments](https://arxiv.org/abs/2511.04320)
*Kuankuan Sima,Longbin Tang,Haozhe Ma,Lin Zhao*

Main category: cs.RO

TL;DR: MacroNav是一个基于学习的导航框架，通过轻量级上下文编码器和强化学习策略，在未知环境中实现高效自主导航，显著提升了成功率和路径效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在丰富的上下文表示和导航效率之间取得平衡，特别是在部分可观测的未知环境中需要紧凑而具有表现力的空间理解来支持高级决策。

Method: 提出两个关键组件：(1)通过多任务自监督学习训练的轻量级上下文编码器，捕捉多尺度、导航中心的空间表示；(2)强化学习策略，将这些表示与基于图的推理无缝集成以进行高效动作选择。

Result: 广泛实验证明上下文编码器具有高效和鲁棒的环境理解能力。真实世界部署进一步验证了MacroNav的有效性，在成功率和路径长度加权成功率方面相比最先进导航方法都有显著提升，同时保持低计算成本。

Conclusion: MacroNav框架在未知环境自主导航中实现了上下文表示与导航效率的良好平衡，为实际部署提供了高效可靠的解决方案。

Abstract: Autonomous navigation in unknown environments requires compact yet expressive
spatial understanding under partial observability to support high-level
decision making. Existing approaches struggle to balance rich contextual
representation with navigation efficiency. We present MacroNav, a
learning-based navigation framework featuring two key components: (1) a
lightweight context encoder trained via multi-task self-supervised learning to
capture multi-scale, navigation-centric spatial representations; and (2) a
reinforcement learning policy that seamlessly integrates these representations
with graph-based reasoning for efficient action selection. Extensive
experiments demonstrate the context encoder's efficient and robust
environmental understanding. Real-world deployments further validate MacroNav's
effectiveness, yielding significant gains over state-of-the-art navigation
methods in both Success Rate (SR) and Success weighted by Path Length (SPL),
while maintaining low computational cost. Code will be released upon
acceptance.

</details>


### [13] [GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies](https://arxiv.org/abs/2511.04357)
*Maëlic Neau,Zoe Falomir,Paulo E. Santos,Anne-Gwenn Bosser,Cédric Buche*

Main category: cs.RO

TL;DR: GraSP-VLA是一个神经符号框架，使用连续场景图表示来生成人类演示的符号表示，用于在推理时生成新的规划领域，并协调低层VLA策略以扩展连续可执行动作的数量。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案中，端到端模仿学习的VLA模型缺乏高层符号规划能力，而符号方法的AML缺乏泛化性和可扩展性。需要结合两者优势来解决长时程任务中的挑战。

Method: 使用连续场景图表示生成人类演示的符号表示，该表示用于在推理时生成新的规划领域，并作为低层VLA策略的协调器。

Result: GraSP-VLA在自动规划领域生成任务中有效建模符号表示，真实世界实验显示其连续场景图表示在长时程任务中协调低层VLA策略具有潜力。

Conclusion: GraSP-VLA通过神经符号方法结合了VLA和AML的优势，为长时程任务提供了有效的解决方案。

Abstract: Deploying autonomous robots that can learn new skills from demonstrations is
an important challenge of modern robotics. Existing solutions often apply
end-to-end imitation learning with Vision-Language Action (VLA) models or
symbolic approaches with Action Model Learning (AML). On the one hand, current
VLA models are limited by the lack of high-level symbolic planning, which
hinders their abilities in long-horizon tasks. On the other hand, symbolic
approaches in AML lack generalization and scalability perspectives. In this
paper we present a new neuro-symbolic approach, GraSP-VLA, a framework that
uses a Continuous Scene Graph representation to generate a symbolic
representation of human demonstrations. This representation is used to generate
new planning domains during inference and serves as an orchestrator for
low-level VLA policies, scaling up the number of actions that can be reproduced
in a row. Our results show that GraSP-VLA is effective for modeling symbolic
representations on the task of automatic planning domain generation from
observations. In addition, results on real-world experiments show the potential
of our Continuous Scene Graph representation to orchestrate low-level VLA
policies in long-horizon tasks.

</details>


### [14] [Studying the Effect of Explicit Interaction Representations on Learning Scene-level Distributions of Human Trajectories](https://arxiv.org/abs/2511.04375)
*Anna Mészáros,Javier Alonso-Mora,Jens Kober*

Main category: cs.RO

TL;DR: 本文研究了在自动驾驶场景中如何最佳地表示智能体之间的交互关系，发现明确定义的交互（如路口谁先通过）比让网络从数据中学习隐式交互能带来更好的性能提升。


<details>
  <summary>Details</summary>
Motivation: 有效捕捉场景中所有智能体的联合分布对于预测场景真实演变和提供更准确的自动驾驶决策信息至关重要。目前对于如何最佳表示智能体间交互尚无共识——是通过神经网络从数据中隐式学习，还是使用更贴近人类决策的时空关系进行显式建模。

Method: 在同一网络结构中研究不同交互描述方式及其对最终学习到的联合分布的影响，比较隐式学习交互与明确定义交互（如路口通行优先级）的效果。

Result: 研究发现，简单地让网络基于数据建立智能体间的交互连接通常会对性能产生负面影响。相反，具有明确定义的交互（如确定智能体对中谁先通过路口）往往能显著提升性能。

Conclusion: 明确定义的交互建模方法优于让网络隐式学习交互的方式，在自动驾驶场景的联合分布学习中，基于人类决策逻辑的显式交互定义能带来更优的性能表现。

Abstract: Effectively capturing the joint distribution of all agents in a scene is
relevant for predicting the true evolution of the scene and in turn providing
more accurate information to the decision processes of autonomous vehicles.
While new models have been developed for this purpose in recent years, it
remains unclear how to best represent the joint distributions particularly from
the perspective of the interactions between agents. Thus far there is no clear
consensus on how best to represent interactions between agents; whether they
should be learned implicitly from data by neural networks, or explicitly
modeled using the spatial and temporal relations that are more grounded in
human decision-making. This paper aims to study various means of describing
interactions within the same network structure and their effect on the final
learned joint distributions. Our findings show that more often than not, simply
allowing a network to establish interactive connections between agents based on
data has a detrimental effect on performance. Instead, having well defined
interactions (such as which agent of an agent pair passes first at an
intersection) can often bring about a clear boost in performance.

</details>


### [15] [ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation](https://arxiv.org/abs/2511.04381)
*Dexin wang,Faliang Chang,Chunsheng Liu*

Main category: cs.RO

TL;DR: ForeRobo是一个生成式机器人代理，通过生成模拟自主获取操作技能，结合生成范式与经典控制，实现零样本模拟到真实环境的迁移。


<details>
  <summary>Details</summary>
Motivation: 有效利用模拟来获取高级操作技能具有挑战性且意义重大，现有端到端策略学习方法缺乏可解释性和执行效率。

Method: 采用自引导的"提议-生成-学习-执行"循环：提议技能并构建模拟环境，配置物体生成技能一致的目标状态(ForeGen)，用虚拟无限数据训练状态生成模型(ForeFormer)，最后使用经典控制算法在真实环境中执行动作。

Result: 在多种刚体和关节物体操作任务中，ForeFormer比最先进的状态生成模型平均提升56.32%，在20多个真实机器人任务中实现零样本迁移，平均成功率达79.28%。

Conclusion: ForeRobo展示了生成模拟与经典控制结合的有效性，提供更好的可解释性和执行效率，在多种操作模式上表现出强大的泛化能力。

Abstract: Efficiently leveraging simulation to acquire advanced manipulation skills is
both challenging and highly significant. We introduce \textit{ForeRobo}, a
generative robotic agent that utilizes generative simulations to autonomously
acquire manipulation skills driven by envisioned goal states. Instead of
directly learning low-level policies, we advocate integrating generative
paradigms with classical control. Our approach equips a robotic agent with a
self-guided \textit{propose-generate-learn-actuate} cycle. The agent first
proposes the skills to be acquired and constructs the corresponding simulation
environments; it then configures objects into appropriate arrangements to
generate skill-consistent goal states (\textit{ForeGen}). Subsequently, the
virtually infinite data produced by ForeGen are used to train the proposed
state generation model (\textit{ForeFormer}), which establishes point-wise
correspondences by predicting the 3D goal position of every point in the
current state, based on the scene state and task instructions. Finally,
classical control algorithms are employed to drive the robot in real-world
environments to execute actions based on the envisioned goal states. Compared
with end-to-end policy learning methods, ForeFormer offers superior
interpretability and execution efficiency. We train and benchmark ForeFormer
across a variety of rigid-body and articulated-object manipulation tasks, and
observe an average improvement of 56.32\% over the state-of-the-art state
generation models, demonstrating strong generality across different
manipulation patterns. Moreover, in real-world evaluations involving more than
20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits
remarkable generalization capabilities, attaining an average success rate of
79.28\%.

</details>


### [16] [Temporal Action Selection for Action Chunking](https://arxiv.org/abs/2511.04421)
*Yueyang Weng,Xiaopeng Zhang,Yongjin Mu,Yingcong Zhu,Yanjie Li,Qi Liu*

Main category: cs.RO

TL;DR: 提出Temporal Action Selector (TAS)算法，通过缓存多时间步的预测动作块并使用轻量级选择器网络动态选择最优动作，解决了动作分块方法在反应性、决策一致性和运动连贯性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 动作分块方法通过建模多步动作块而非单步动作，增强了人类专家策略的建模能力，但降低了决策频率，限制了最近观测的利用，导致反应性下降，特别是在适应传感器噪声和动态环境变化方面表现不足。现有方法无法同时实现反应性和决策一致性。

Method: 提出TAS算法：缓存来自多个时间步的预测动作块，通过轻量级选择器网络动态选择最优动作。将TAS作为基础策略与残差强化学习结合，进一步提升训练效率和性能。

Result: 在多个任务和不同基础策略上的实验表明，TAS显著提高了成功率，绝对增益高达73.3%。与残差强化学习结合后，大幅提升了训练效率并提高了性能上限。仿真和物理机器人实验验证了方法的有效性。

Conclusion: TAS算法在反应性、决策一致性和运动连贯性三个关键维度上实现了平衡优化，有效解决了动作分块方法的局限性，在多种任务中表现出显著性能提升。

Abstract: Action chunking is a widely adopted approach in Learning from Demonstration
(LfD). By modeling multi-step action chunks rather than single-step actions,
action chunking significantly enhances modeling capabilities for human expert
policies. However, the reduced decision frequency restricts the utilization of
recent observations, degrading reactivity - particularly evident in the
inadequate adaptation to sensor noise and dynamic environmental changes.
Existing efforts to address this issue have primarily resorted to trading off
reactivity against decision consistency, without achieving both. To address
this limitation, we propose a novel algorithm, Temporal Action Selector (TAS),
which caches predicted action chunks from multiple timesteps and dynamically
selects the optimal action through a lightweight selector network. TAS achieves
balanced optimization across three critical dimensions: reactivity, decision
consistency, and motion coherence. Experiments across multiple tasks with
diverse base policies show that TAS significantly improves success rates -
yielding an absolute gain of up to 73.3%. Furthermore, integrating TAS as a
base policy with residual reinforcement learning (RL) substantially enhances
training efficiency and elevates the performance plateau. Experiments in both
simulation and physical robots confirm the method's efficacy.

</details>


### [17] [Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment](https://arxiv.org/abs/2511.04555)
*Tao Lin,Yilei Zhong,Yuxin Du,Jingjing Zhang,Jiting Liu,Yinxinyu Chen,Encheng Gu,Ziyan Liu,Hongyi Cai,Yanwen Zou,Lixing Zou,Zhaoye Zhou,Gen Li,Bo Zhao*

Main category: cs.RO

TL;DR: Evo-1是一个轻量级的视觉-语言-动作模型，仅需7.7亿参数，无需机器人数据预训练，在多个基准测试中达到最先进性能，并在真实世界评估中实现78%的成功率。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型参数庞大，依赖大规模机器人数据预训练，导致计算成本高、部署效率低，且容易过拟合、泛化能力差。

Method: 基于原生多模态视觉语言模型，引入交叉调制扩散变换器和优化集成模块，采用两阶段训练范式逐步对齐动作与感知。

Result: 在Meta-World和RoboTwin套件上分别超越之前最佳模型12.4%和6.9%，在LIBERO上达到94.8%，真实世界评估成功率78%。

Conclusion: Evo-1证明了轻量级VLA模型的可行性，在保持高性能的同时显著降低了计算成本和部署难度。

Abstract: Vision-Language-Action (VLA) models have emerged as a powerful framework that
unifies perception, language, and control, enabling robots to perform diverse
tasks through multimodal understanding. However, current VLA models typically
contain massive parameters and rely heavily on large-scale robot data
pretraining, leading to high computational costs during training, as well as
limited deployability for real-time inference. Moreover, most training
paradigms often degrade the perceptual representations of the vision-language
backbone, resulting in overfitting and poor generalization to downstream tasks.
In this work, we present Evo-1, a lightweight VLA model that reduces
computation and improves deployment efficiency, while maintaining strong
performance without pretraining on robot data. Evo-1 builds on a native
multimodal Vision-Language model (VLM), incorporating a novel cross-modulated
diffusion transformer along with an optimized integration module, together
forming an effective architecture. We further introduce a two-stage training
paradigm that progressively aligns action with perception, preserving the
representations of the VLM. Notably, with only 0.77 billion parameters, Evo-1
achieves state-of-the-art results on the Meta-World and RoboTwin suite,
surpassing the previous best models by 12.4% and 6.9%, respectively, and also
attains a competitive result of 94.8% on LIBERO. In real-world evaluations,
Evo-1 attains a 78% success rate with high inference frequency and low memory
overhead, outperforming all baseline methods. We release code, data, and model
weights to facilitate future research on lightweight and efficient VLA models.

</details>


### [18] [SAFe-Copilot: Unified Shared Autonomy Framework](https://arxiv.org/abs/2511.04664)
*Phat Nguyen,Erfan Aasi,Shiva Sreeram,Guy Rosman,Andrew Silva,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: 提出基于视觉语言模型的共享自动驾驶框架，在语义层面整合人类输入和自主规划，通过多模态线索推断驾驶意图，实现人机协同控制。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在罕见、模糊和分布外场景中表现脆弱，而人类驾驶员能通过上下文推理成功处理。现有方法局限于低层轨迹仲裁，无法保持驾驶意图。

Method: 利用视觉语言模型从驾驶员动作和环境上下文等多模态线索推断驾驶意图，在更高抽象层面综合协调人类和自主控制策略。

Result: 在模拟人类设置中实现完美召回率和高精度；92%参与者认同仲裁结果；在Bench2Drive基准测试中显著降低碰撞率并提升整体性能。

Conclusion: 基于语义语言表示的仲裁是共享自动驾驶的关键设计原则，使系统能够运用常识推理并保持与人类意图的连续性。

Abstract: Autonomous driving systems remain brittle in rare, ambiguous, and
out-of-distribution scenarios, where human driver succeed through contextual
reasoning. Shared autonomy has emerged as a promising approach to mitigate such
failures by incorporating human input when autonomy is uncertain. However, most
existing methods restrict arbitration to low-level trajectories, which
represent only geometric paths and therefore fail to preserve the underlying
driving intent. We propose a unified shared autonomy framework that integrates
human input and autonomous planners at a higher level of abstraction. Our
method leverages Vision Language Models (VLMs) to infer driver intent from
multi-modal cues -- such as driver actions and environmental context -- and to
synthesize coherent strategies that mediate between human and autonomous
control. We first study the framework in a mock-human setting, where it
achieves perfect recall alongside high accuracy and precision. A human-subject
survey further shows strong alignment, with participants agreeing with
arbitration outcomes in 92% of cases. Finally, evaluation on the Bench2Drive
benchmark demonstrates a substantial reduction in collision rate and
improvement in overall performance compared to pure autonomy. Arbitration at
the level of semantic, language-based representations emerges as a design
principle for shared autonomy, enabling systems to exercise common-sense
reasoning and maintain continuity with human intent.

</details>


### [19] [Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions](https://arxiv.org/abs/2511.04665)
*Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li*

Main category: cs.RO

TL;DR: 提出了一种基于真实世界视频构建软体数字孪生的真实到仿真策略评估框架，使用3D高斯泼溅技术实现逼真渲染，用于评估机器人操作策略。


<details>
  <summary>Details</summary>
Motivation: 真实世界中的机器人操作策略评估成本高、耗时长且难以复现，特别是涉及可变形物体的任务。现有仿真器难以捕捉软体交互的视觉和物理复杂性。

Method: 从真实世界视频构建软体数字孪生，使用3D高斯泼溅技术渲染机器人、物体和环境，实现照片级逼真度。

Result: 在毛绒玩具打包、绳索布线和T型块推动等代表性可变形操作任务上验证，仿真推演与现实执行性能高度相关，并能揭示学习策略的关键行为模式。

Conclusion: 结合物理信息重建与高质量渲染可实现机器人操作策略的可重复、可扩展且准确的评估。

Abstract: Robotic manipulation policies are advancing rapidly, but their direct
evaluation in the real world remains costly, time-consuming, and difficult to
reproduce, particularly for tasks involving deformable objects. Simulation
provides a scalable and systematic alternative, yet existing simulators often
fail to capture the coupled visual and physical complexity of soft-body
interactions. We present a real-to-sim policy evaluation framework that
constructs soft-body digital twins from real-world videos and renders robots,
objects, and environments with photorealistic fidelity using 3D Gaussian
Splatting. We validate our approach on representative deformable manipulation
tasks, including plush toy packing, rope routing, and T-block pushing,
demonstrating that simulated rollouts correlate strongly with real-world
execution performance and reveal key behavioral patterns of learned policies.
Our results suggest that combining physics-informed reconstruction with
high-quality rendering enables reproducible, scalable, and accurate evaluation
of robotic manipulation policies. Website: https://real2sim-eval.github.io/

</details>


### [20] [X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations](https://arxiv.org/abs/2511.04671)
*Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia*

Main category: cs.RO

TL;DR: X-Diffusion是一个利用人类视频数据训练机器人扩散策略的框架，通过噪声注入解决人类与机器人执行动作的不匹配问题，在五个操作任务中平均成功率比最佳基线提高16%。


<details>
  <summary>Details</summary>
Motivation: 人类视频数据获取快速且规模大，是机器人学习的宝贵训练数据源，但人类与机器人在具体执行动作上存在根本差异，直接使用人类动作会产生物理上不可行的机器人动作。

Method: 利用前向扩散过程：随着噪声添加到动作中，低级执行差异逐渐消失，而高级任务指导得以保留。训练分类器预测噪声动作是由人类还是机器人执行，只有当添加足够噪声使分类器无法区分时，才将人类动作纳入策略训练。

Result: 实验表明，在存在执行不匹配的情况下，简单共同训练会降低策略性能，而X-Diffusion始终能提高性能。在五个操作任务中，X-Diffusion的平均成功率比最佳基线高16%。

Conclusion: X-Diffusion提供了一个原则性框架，能够最大限度地利用人类数据而不学习动态不可行的动作，有效解决了人类与机器人动作执行不匹配的问题。

Abstract: Human videos can be recorded quickly and at scale, making them an appealing
source of training data for robot learning. However, humans and robots differ
fundamentally in embodiment, resulting in mismatched action execution. Direct
kinematic retargeting of human hand motion can therefore produce actions that
are physically infeasible for robots. Despite these low-level differences,
human demonstrations provide valuable motion cues about how to manipulate and
interact with objects. Our key idea is to exploit the forward diffusion
process: as noise is added to actions, low-level execution differences fade
while high-level task guidance is preserved. We present X-Diffusion, a
principled framework for training diffusion policies that maximally leverages
human data without learning dynamically infeasible motions. X-Diffusion first
trains a classifier to predict whether a noisy action is executed by a human or
robot. Then, a human action is incorporated into policy training only after
adding sufficient noise such that the classifier cannot discern its embodiment.
Actions consistent with robot execution supervise fine-grained denoising at low
noise levels, while mismatched human actions provide only coarse guidance at
higher noise levels. Our experiments show that naive co-training under
execution mismatches degrades policy performance, while X-Diffusion
consistently improves it. Across five manipulation tasks, X-Diffusion achieves
a 16% higher average success rate than the best baseline. The project website
is available at https://portal-cornell.github.io/X-Diffusion/.

</details>


### [21] [GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction](https://arxiv.org/abs/2511.04679)
*Qingzhou Lu,Yao Feng,Baiyu Shi,Michael Piseno,Zhenan Bao,C. Karen Liu*

Main category: cs.RO

TL;DR: GentleHumanoid是一个将阻抗控制集成到全身运动跟踪策略中的框架，旨在实现上半身的柔顺性，通过统一的弹簧模型处理抵抗性和引导性接触，在保持任务成功的同时显著降低接触力。


<details>
  <summary>Details</summary>
Motivation: 人形机器人需要在以人为中心的环境中安全自然地交互，但现有强化学习策略过于强调刚性跟踪而抑制外力，现有阻抗控制方法通常局限于基座或末端执行器控制，且主要关注抵抗极端力而非实现柔顺性。

Method: 提出GentleHumanoid框架，核心是统一的弹簧模型，同时建模抵抗性接触（按压表面时的恢复力）和引导性接触（从人类运动数据采样的推拉动作），确保肩部、肘部和腕部的运动学一致性力，并通过任务可调力阈值保证安全性。

Result: 在仿真和Unitree G1人形机器人上评估，在需要不同柔顺性水平的任务中（轻柔拥抱、坐站辅助、安全物体操作），相比基线方法，该策略在保持任务成功率的同时持续降低峰值接触力，实现更平滑自然的交互。

Conclusion: GentleHumanoid朝着能够安全有效与人类协作并在真实环境中处理物体的人形机器人迈出了重要一步，展示了在保持任务性能的同时实现柔顺交互的可行性。

Abstract: Humanoid robots are expected to operate in human-centered environments where
safe and natural physical interaction is essential. However, most recent
reinforcement learning (RL) policies emphasize rigid tracking and suppress
external forces. Existing impedance-augmented approaches are typically
restricted to base or end-effector control and focus on resisting extreme
forces rather than enabling compliance. We introduce GentleHumanoid, a
framework that integrates impedance control into a whole-body motion tracking
policy to achieve upper-body compliance. At its core is a unified spring-based
formulation that models both resistive contacts (restoring forces when pressing
against surfaces) and guiding contacts (pushes or pulls sampled from human
motion data). This formulation ensures kinematically consistent forces across
the shoulder, elbow, and wrist, while exposing the policy to diverse
interaction scenarios. Safety is further supported through task-adjustable
force thresholds. We evaluate our approach in both simulation and on the
Unitree G1 humanoid across tasks requiring different levels of compliance,
including gentle hugging, sit-to-stand assistance, and safe object
manipulation. Compared to baselines, our policy consistently reduces peak
contact forces while maintaining task success, resulting in smoother and more
natural interactions. These results highlight a step toward humanoid robots
that can safely and effectively collaborate with humans and handle objects in
real-world environments.

</details>
