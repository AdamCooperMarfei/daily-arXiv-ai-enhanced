<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 20]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ScaleADFG: Affordance-based Dexterous Functional Grasping via Scalable Dataset](https://arxiv.org/abs/2511.09602)
*Sizhe Wang,Yifan Yang,Yongkang Luo,Daheng Li,Wei Wei,Yan Zhang,Peiying Hu,Yunjin Fu,Haonan Duan,Jia Sun,Peng Wang*

Main category: cs.RO

TL;DR: 提出了ScaleADFG框架，通过自动化数据集构建和轻量级抓取生成网络，解决了机器人工具使用抓取中的尺度不匹配和泛化性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在构建大规模数据集和泛化到日常物体尺度方面面临挑战，主要由于机器人手与人类手的大小不匹配以及现实世界物体尺度的多样性。

Method: 包含全自动数据集构建流水线和轻量级抓取生成网络。数据集使用基于可供性的算法合成多样化的工具使用抓取配置，无需专家演示，支持灵活的对象-手大小比例。

Result: 构建了包含5个对象类别、每个类别超过1000个独特形状、15种尺度变体的数据集，过滤后为2个灵巧机器人手提供超过60,000个抓取。网络在模拟和真实机器人实验中表现出对变化尺度的强适应性。

Conclusion: ScaleADFG框架显著提升了功能抓取的稳定性、多样性和泛化能力，网络能够有效零样本迁移到真实世界物体。

Abstract: Dexterous functional tool-use grasping is essential for effective robotic manipulation of tools. However, existing approaches face significant challenges in efficiently constructing large-scale datasets and ensuring generalizability to everyday object scales. These issues primarily arise from size mismatches between robotic and human hands, and the diversity in real-world object scales. To address these limitations, we propose the ScaleADFG framework, which consists of a fully automated dataset construction pipeline and a lightweight grasp generation network. Our dataset introduce an affordance-based algorithm to synthesize diverse tool-use grasp configurations without expert demonstrations, allowing flexible object-hand size ratios and enabling large robotic hands (compared to human hands) to grasp everyday objects effectively. Additionally, we leverage pre-trained models to generate extensive 3D assets and facilitate efficient retrieval of object affordances. Our dataset comprising five object categories, each containing over 1,000 unique shapes with 15 scale variations. After filtering, the dataset includes over 60,000 grasps for each 2 dexterous robotic hands. On top of this dataset, we train a lightweight, single-stage grasp generation network with a notably simple loss design, eliminating the need for post-refinement. This demonstrates the critical importance of large-scale datasets and multi-scale object variant for effective training. Extensive experiments in simulation and on real robot confirm that the ScaleADFG framework exhibits strong adaptability to objects of varying scales, enhancing functional grasp stability, diversity, and generalizability. Moreover, our network exhibits effective zero-shot transfer to real-world objects. Project page is available at https://sizhe-wang.github.io/ScaleADFG_webpage

</details>


### [2] [A Shared-Autonomy Construction Robotic System for Overhead Works](https://arxiv.org/abs/2511.09695)
*David Minkwan Kim,K. M. Brian Lee,Yong Hyeok Seo,Nikola Raicevic,Runfa Blark Li,Kehan Long,Chan Seon Yoon,Dong Min Kang,Byeong Jo Lim,Young Pyoung Kim,Nikolay Atanasov,Truong Nguyen,Se Woong Jun,Young Wook Kim*

Main category: cs.RO

TL;DR: 开发用于天花板钻孔等高空作业的机器人系统，包含移动底座、双级升降平台和双臂躯干，配备定制钻孔末端执行器和RGB-D相机。使用高斯泼溅进行在线3D重建，引入运动参数建模移动物体，开发神经配置空间屏障方法实现动态环境中的安全遥操作。


<details>
  <summary>Details</summary>
Motivation: 解决高空作业（如天花板钻孔）中的安全性和效率问题，特别是在动态环境中进行遥操作时面临的有限视野和移动障碍物挑战。

Method: 硬件平台采用移动底座配合双级升降平台和双臂躯干，配备定制钻孔末端执行器；软件方面使用高斯泼溅进行在线3D重建，引入运动参数建模移动物体，开发神经配置空间屏障方法进行规划和控制。

Result: 初步可行性研究表明硬件能够完成钻孔、螺栓固定和锚固任务，软件能够在动态环境中实现安全遥操作。

Conclusion: 该系统展示了在高空作业中结合先进感知和安全控制方法的可行性，为动态环境下的机器人遥操作提供了有效解决方案。

Abstract: We present the ongoing development of a robotic system for overhead work such as ceiling drilling. The hardware platform comprises a mobile base with a two-stage lift, on which a bimanual torso is mounted with a custom-designed drilling end effector and RGB-D cameras. To support teleoperation in dynamic environments with limited visibility, we use Gaussian splatting for online 3D reconstruction and introduce motion parameters to model moving objects. For safe operation around dynamic obstacles, we developed a neural configuration-space barrier approach for planning and control. Initial feasibility studies demonstrate the capability of the hardware in drilling, bolting, and anchoring, and the software in safe teleoperation in a dynamic environment.

</details>


### [3] [Baby Sophia: A Developmental Approach to Self-Exploration through Self-Touch and Hand Regard](https://arxiv.org/abs/2511.09727)
*Stelios Zarifis,Ioannis Chalkiadakis,Artemis Chardouveli,Vasiliki Moutzouri,Aggelos Sotirchos,Katerina Papadimitriou,Panagiotis Filntisis,Niki Efthymiou,Petros Maragos,Katerina Pastra*

Main category: cs.RO

TL;DR: 提出基于婴儿发育启发的强化学习框架，让机器人Baby Sophia通过内在奖励学习自我触摸和手部注视行为，模仿婴儿好奇心驱动的身体探索过程。


<details>
  <summary>Details</summary>
Motivation: 受婴儿发育过程启发，研究如何通过纯粹的内在好奇心驱动信号（无需外部监督）来实现自主多模态学习，模仿婴儿从随机运动到有目的行为的进展。

Method: 使用BabyBench仿真环境，通过内在奖励和课程学习：1）自我触摸：将高维触觉输入转换为紧凑表示，通过内在奖励鼓励广泛身体覆盖；2）手部注视：通过运动咿呀学语学习手部视觉特征，内在奖励鼓励新颖手部动作和视线跟随，采用从单手到双手的课程学习。

Result: 结果表明，纯粹基于好奇心的信号能够驱动协调的多模态学习，成功模仿了婴儿从随机运动咿呀到有目的行为的发展过程。

Conclusion: 这项工作证明了内在好奇心驱动的方法在实现自主多模态学习方面的有效性，为开发更自然的机器人学习机制提供了新思路。

Abstract: Inspired by infant development, we propose a Reinforcement Learning (RL) framework for autonomous self-exploration in a robotic agent, Baby Sophia, using the BabyBench simulation environment. The agent learns self-touch and hand regard behaviors through intrinsic rewards that mimic an infant's curiosity-driven exploration of its own body. For self-touch, high-dimensional tactile inputs are transformed into compact, meaningful representations, enabling efficient learning. The agent then discovers new tactile contacts through intrinsic rewards and curriculum learning that encourage broad body coverage, balance, and generalization. For hand regard, visual features of the hands, such as skin-color and shape, are learned through motor babbling. Then, intrinsic rewards encourage the agent to perform novel hand motions, and follow its hands with its gaze. A curriculum learning setup from single-hand to dual-hand training allows the agent to reach complex visual-motor coordination. The results of this work demonstrate that purely curiosity-based signals, with no external supervision, can drive coordinated multimodal learning, imitating an infant's progression from random motor babbling to purposeful behaviors.

</details>


### [4] [A Robust Task-Level Control Architecture for Learned Dynamical Systems](https://arxiv.org/abs/2511.09790)
*Eshika Pathak,Ahmed Aboudonia,Sandeep Banik,Naira Hovakimyan*

Main category: cs.RO

TL;DR: 提出L1-DS框架，通过L1自适应控制器和动态时间规整目标选择器解决DS-LfD中的任务执行不匹配问题


<details>
  <summary>Details</summary>
Motivation: DS-LfD生成的运动计划在实际执行中会因未建模动态、持续干扰和系统延迟导致任务空间状态与期望轨迹偏离，存在任务执行不匹配问题

Method: 在任意DS-LfD模型基础上增加标称稳定控制器和L1自适应控制器，并引入基于窗口动态时间规整的目标选择器处理时间错位

Result: 在LASA和IROS手写数据集上验证了架构的有效性

Conclusion: L1-DS框架能有效处理任务执行不匹配问题，提高运动轨迹跟踪的鲁棒性和相位一致性

Abstract: Dynamical system (DS)-based learning from demonstration (LfD) is a powerful tool for generating motion plans in the operation (`task') space of robotic systems. However, the realization of the generated motion plans is often compromised by a ''task-execution mismatch'', where unmodeled dynamics, persistent disturbances, and system latency cause the robot's actual task-space state to diverge from the desired motion trajectory. We propose a novel task-level robust control architecture, L1-augmented Dynamical Systems (L1-DS), that explicitly handles the task-execution mismatch in tracking a nominal motion plan generated by any DS-based LfD scheme. Our framework augments any DS-based LfD model with a nominal stabilizing controller and an L1 adaptive controller. Furthermore, we introduce a windowed Dynamic Time Warping (DTW)-based target selector, which enables the nominal stabilizing controller to handle temporal misalignment for improved phase-consistent tracking. We demonstrate the efficacy of our architecture on the LASA and IROS handwriting datasets.

</details>


### [5] [Provably Safe Stein Variational Clarity-Aware Informative Planning](https://arxiv.org/abs/2511.09836)
*Kaleb Ben Naveed,Utkrisht Sahai,Anouck Girard,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出了一种结合信息感知规划和安全约束的机器人轨迹优化框架，通过Stein变分推理学习信息丰富的轨迹，同时使用门卫机制确保安全性。


<details>
  <summary>Details</summary>
Motivation: 现有规划器大多将信息建模为静态或均匀衰减，忽略了空间变化的衰减率，且往往将安全作为软约束处理，无法在信息收集任务中同时保证信息获取和安全性。

Method: 使用清晰度模型表示环境不确定性，将清晰度动态嵌入轨迹优化，通过Stein变分推理进行贝叶斯推理学习，并采用门卫框架进行安全验证。

Result: 在具有不同衰减率和障碍物的环境中进行硬件实验和仿真，展示了持续的安全性和减少的信息赤字。

Conclusion: 该框架能够在空间和时间变化的环境中有效规划信息丰富且安全的轨迹，解决了信息衰减和安全约束的关键挑战。

Abstract: Autonomous robots are increasingly deployed for information-gathering tasks in environments that vary across space and time. Planning informative and safe trajectories in such settings is challenging because information decays when regions are not revisited. Most existing planners model information as static or uniformly decaying, ignoring environments where the decay rate varies spatially; those that model non-uniform decay often overlook how it evolves along the robot's motion, and almost all treat safety as a soft penalty. In this paper, we address these challenges. We model uncertainty in the environment using clarity, a normalized representation of differential entropy from our earlier work that captures how information improves through new measurements and decays over time when regions are not revisited. Building on this, we present Stein Variational Clarity-Aware Informative Planning, a framework that embeds clarity dynamics within trajectory optimization and enforces safety through a low-level filtering mechanism based on our earlier gatekeeper framework for safety verification. The planner performs Bayesian inference-based learning via Stein variational inference, refining a distribution over informative trajectories while filtering each nominal Stein informative trajectory to ensure safety. Hardware experiments and simulations across environments with varying decay rates and obstacles demonstrate consistent safety and reduced information deficits.

</details>


### [6] [PuffyBot: An Untethered Shape Morphing Robot for Multi-environment Locomotion](https://arxiv.org/abs/2511.09885)
*Shashwat Singh,Zilin Si,Zeynep Temel*

Main category: cs.RO

TL;DR: PuffyBot是一个无缆形状变形机器人，通过剪刀式升降机构和连杆系统实现形态变化，能够在陆地和水下多种环境中移动，包括爬行和游泳模式切换。


<details>
  <summary>Details</summary>
Motivation: 受两栖动物在陆地和水环境中适应形态和运动的生物学特征启发，开发能够通过形态变化适应多种环境的机器人平台。

Method: 采用剪刀式升降机构作为主要结构实现形状变形，结合钟形曲柄连杆调节伺服驱动肢体90度旋转，使用TPU面料实现防水，配备1000mAh电池可无缆运行2小时。

Result: 机器人实现了体积从255.00 cm³到423.75 cm³的变化，可抵消3.237N的下沉力，成功展示了陆地爬行、水下爬行、水面游泳和双模式浮力调节等多种环境运动能力。

Conclusion: 形状变形技术能够创建适用于多种环境的通用且节能的机器人平台，展示了在多样化环境中应用的潜力。

Abstract: Amphibians adapt their morphologies and motions to accommodate movement in both terrestrial and aquatic environments. Inspired by these biological features, we present PuffyBot, an untethered shape morphing robot capable of changing its body morphology to navigate multiple environments. Our robot design leverages a scissor-lift mechanism driven by a linear actuator as its primary structure to achieve shape morphing. The transformation enables a volume change from 255.00 cm3 to 423.75 cm3, modulating the buoyant force to counteract a downward force of 3.237 N due to 330 g mass of the robot. A bell-crank linkage is integrated with the scissor-lift mechanism, which adjusts the servo-actuated limbs by 90 degrees, allowing a seamless transition between crawling and swimming modes. The robot is fully waterproof, using thermoplastic polyurethane (TPU) fabric to ensure functionality in aquatic environments. The robot can operate untethered for two hours with an onboard battery of 1000 mA h. Our experimental results demonstrate multi-environment locomotion, including crawling on the land, crawling on the underwater floor, swimming on the water surface, and bimodal buoyancy adjustment to submerge underwater or resurface. These findings show the potential of shape morphing to create versatile and energy efficient robotic platforms suitable for diverse environments.

</details>


### [7] [A Study on Enhancing the Generalization Ability of Visuomotor Policies via Data Augmentation](https://arxiv.org/abs/2511.09932)
*Hanwen Wang*

Main category: cs.RO

TL;DR: 本文研究了如何通过自动生成多样化数据来提升视觉运动策略的泛化能力，创建了一个包含多种机械臂和夹具的广泛随机化数据集，发现场景随机化能有效增强策略的零样本仿真到真实迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成的轨迹增强数据缺乏多样性，限制了模仿学习策略的泛化能力，特别是在处理场景中物体随机放置时表现不足。

Method: 通过自动化数据生成，创建了包含五种机械臂和两种夹具的广泛随机化数据集，涵盖了相机姿态、光照条件、桌面纹理和桌面高度等多种随机化因素。

Result: 所有随机化因素都会影响策略的泛化能力，任何形式的随机化都能增强策略泛化，其中多样化轨迹在弥合视觉差距方面特别有效。

Conclusion: 在低成本机械臂上验证了所提出的场景随机化方法能有效增强视觉运动策略的零样本仿真到真实迁移的泛化能力。

Abstract: The generalization ability of visuomotor policy is crucial, as a good policy should be deployable across diverse scenarios. Some methods can collect large amounts of trajectory augmentation data to train more generalizable imitation learning policies, aimed at handling the random placement of objects on the scene's horizontal plane. However, the data generated by these methods still lack diversity, which limits the generalization ability of the trained policy. To address this, we investigate the performance of policies trained by existing methods across different scene layout factors via automate the data generation for those factors that significantly impact generalization. We have created a more extensively randomized dataset that can be efficiently and automatically generated with only a small amount of human demonstration. The dataset covers five types of manipulators and two types of grippers, incorporating extensive randomization factors such as camera pose, lighting conditions, tabletop texture, and table height across six manipulation tasks. We found that all of these factors influence the generalization ability of the policy. Applying any form of randomization enhances policy generalization, with diverse trajectories particularly effective in bridging visual gap. Notably, we investigated on low-cost manipulator the effect of the scene randomization proposed in this work on enhancing the generalization capability of visuomotor policies for zero-shot sim-to-real transfer.

</details>


### [8] [Audio-VLA: Adding Contact Audio Perception to Vision-Language-Action Model for Robotic Manipulation](https://arxiv.org/abs/2511.09958)
*Xiangyi Wei,Haotian Zhang,Xinyi Cao,Siyu Xie,Weifeng Ge,Yang Li,Changbo Wang*

Main category: cs.RO

TL;DR: Audio-VLA是一种多模态机器人操作策略，通过接触音频感知接触事件和动态过程反馈，克服了纯视觉VLA模型的局限性，并引入任务完成率(TCR)指标来系统评估动态操作过程。


<details>
  <summary>Details</summary>
Motivation: 纯视觉VLA模型在感知交互和操作动态过程方面存在根本性限制，需要引入音频模态来增强对接触事件和动态过程的感知能力。

Method: 使用预训练的DINOv2和SigLIP作为视觉编码器，AudioCLIP作为音频编码器，Llama2作为大语言模型骨干，通过LoRA微调和多模态投影层实现跨模态理解，并在仿真环境中添加基于碰撞的音频生成。

Result: 在LIBERO、RLBench和两个真实世界任务上的广泛实验表明，Audio-VLA优于纯视觉对比方法，TCR指标有效量化了动态过程感知能力。

Conclusion: Audio-VLA通过引入音频模态显著提升了机器人操作性能，TCR指标为动态操作过程的系统评估提供了有效工具。

Abstract: The Vision-Language-Action models (VLA) have achieved significant advances in robotic manipulation recently. However, vision-only VLA models create fundamental limitations, particularly in perceiving interactive and manipulation dynamic processes. This paper proposes Audio-VLA, a multimodal manipulation policy that leverages contact audio to perceive contact events and dynamic process feedback. Audio-VLA overcomes the vision-only constraints of VLA models. Additionally, this paper introduces the Task Completion Rate (TCR) metric to systematically evaluate dynamic operational processes. Audio-VLA employs pre-trained DINOv2 and SigLIP as visual encoders, AudioCLIP as the audio encoder, and Llama2 as the large language model backbone. We apply LoRA fine-tuning to these pre-trained modules to achieve robust cross-modal understanding of both visual and acoustic inputs. A multimodal projection layer aligns features from different modalities into the same feature space. Moreover RLBench and LIBERO simulation environments are enhanced by adding collision-based audio generation to provide realistic sound feedback during object interactions. Since current robotic manipulation evaluations focus on final outcomes rather than providing systematic assessment of dynamic operational processes, the proposed TCR metric measures how well robots perceive dynamic processes during manipulation, creating a more comprehensive evaluation metric. Extensive experiments on LIBERO, RLBench, and two real-world tasks demonstrate Audio-VLA's superior performance over vision-only comparative methods, while the TCR metric effectively quantifies dynamic process perception capabilities.

</details>


### [9] [Phantom Menace: Exploring and Enhancing the Robustness of VLA Models against Physical Sensor Attacks](https://arxiv.org/abs/2511.10008)
*Xuancun Lu,Jiaxiang Chen,Shilin Xiao,Zizhi Jin,Zhangrui Chen,Hanwen Yu,Bohan Qian,Ruochen Zhou,Xiaoyu Ji,Wenyuan Xu*

Main category: cs.RO

TL;DR: 本文首次系统研究了针对视觉-语言-动作(VLA)模型的物理传感器攻击，提出了"真实-仿真-真实"框架来模拟和验证攻击，并开发了基于对抗训练的防御方法。


<details>
  <summary>Details</summary>
Motivation: VLA模型严重依赖传感器输入，但针对物理世界传感器攻击的安全性研究严重不足，需要填补这一空白。

Method: 提出"真实-仿真-真实"框架，自动模拟基于物理的传感器攻击向量（包括6种摄像头攻击和2种麦克风攻击），并在真实机器人系统上验证。

Result: 通过大规模评估发现VLA模型存在显著漏洞，易感性模式显示对任务类型和模型设计的关键依赖。

Conclusion: 研究结果揭示了在安全关键环境中部署VLA模型时，迫切需要标准化鲁棒性基准和缓解策略。

Abstract: Vision-Language-Action (VLA) models revolutionize robotic systems by enabling end-to-end perception-to-action pipelines that integrate multiple sensory modalities, such as visual signals processed by cameras and auditory signals captured by microphones. This multi-modality integration allows VLA models to interpret complex, real-world environments using diverse sensor data streams. Given the fact that VLA-based systems heavily rely on the sensory input, the security of VLA models against physical-world sensor attacks remains critically underexplored.
  To address this gap, we present the first systematic study of physical sensor attacks against VLAs, quantifying the influence of sensor attacks and investigating the defenses for VLA models. We introduce a novel ``Real-Sim-Real'' framework that automatically simulates physics-based sensor attack vectors, including six attacks targeting cameras and two targeting microphones, and validates them on real robotic systems. Through large-scale evaluations across various VLA architectures and tasks under varying attack parameters, we demonstrate significant vulnerabilities, with susceptibility patterns that reveal critical dependencies on task types and model designs. We further develop an adversarial-training-based defense that enhances VLA robustness against out-of-distribution physical perturbations caused by sensor attacks while preserving model performance. Our findings expose an urgent need for standardized robustness benchmarks and mitigation strategies to secure VLA deployments in safety-critical environments.

</details>


### [10] [DecARt Leg: Design and Evaluation of a Novel Humanoid Robot Leg with Decoupled Actuation for Agile Locomotion](https://arxiv.org/abs/2511.10021)
*Egor Davydenko,Andrei Volchenkov,Vladimir Gerasimov,Roman Gorbachev*

Main category: cs.RO

TL;DR: 提出了一种新型电动驱动机器人腿DecARt Leg，用于实现灵活动作，具有准伸缩运动学结构、近人形外观和新型多杆系统等特征，并通过FAST指标进行定量评估。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够实现灵活动作的电动驱动机器人腿，解决传统设计中存在的耦合驱动问题，并提高运动性能。

Method: 采用准伸缩运动学结构配合旋转电机实现解耦驱动，设计近人形外观和向前膝盖，开发新型多杆系统从膝盖上方电机传输踝关节扭矩。

Result: 通过FAST指标定量评估显示该设计优于其他设计，仿真和初步硬件实验验证了基于DecARt Leg的机器人性能。

Conclusion: DecARt Leg设计在灵活动作方面表现出色，为电动驱动机器人腿的设计提供了新思路，并通过实验验证了其可行性。

Abstract: In this paper, we propose a novel design of an electrically actuated robotic leg, called the DecARt (Decoupled Actuation Robot) Leg, aimed at performing agile locomotion. This design incorporates several new features, such as the use of a quasi-telescopic kinematic structure with rotational motors for decoupled actuation, a near-anthropomorphic leg appearance with a forward facing knee, and a novel multi-bar system for ankle torque transmission from motors placed above the knee. To analyze the agile locomotion capabilities of the design numerically, we propose a new descriptive metric, called the `Fastest Achievable Swing Time` (FAST), and perform a quantitative evaluation of the proposed design and compare it with other designs. Then we evaluate the performance of the DecARt Leg-based robot via extensive simulation and preliminary hardware experiments.

</details>


### [11] [Physics-informed Machine Learning for Static Friction Modeling in Robotic Manipulators Based on Kolmogorov-Arnold Networks](https://arxiv.org/abs/2511.10079)
*Yizheng Wang,Timon Rabczuk,Yinghua Liu*

Main category: cs.RO

TL;DR: 提出基于Kolmogorov Arnold Network (KAN)的物理启发机器学习方法，用于机器人关节静摩擦建模，结合样条激活函数和符号回归机制，在保持高精度和可解释性的同时实现模型简化和物理表达式提取。


<details>
  <summary>Details</summary>
Motivation: 传统静态摩擦模型需要预定义函数假设，在处理未知函数结构时面临挑战，需要开发既能保持高精度又具备可解释性的数据驱动摩擦建模方法。

Method: 基于KAN网络，集成样条激活函数和符号回归机制，通过剪枝和属性评分实现模型简化和物理表达式提取，验证方法在已知函数模型和未知函数结构条件下的性能。

Result: 在合成数据和六自由度工业机械臂真实摩擦数据上的实验表明，该方法在各种任务中决定系数大于0.95，成功提取简洁且物理意义明确的摩擦表达式。

Conclusion: 该研究为可解释和数据驱动的机器人摩擦建模提供了新视角，具有良好工程应用前景。

Abstract: Friction modeling plays a crucial role in achieving high-precision motion control in robotic operating systems. Traditional static friction models (such as the Stribeck model) are widely used due to their simple forms; however, they typically require predefined functional assumptions, which poses significant challenges when dealing with unknown functional structures. To address this issue, this paper proposes a physics-inspired machine learning approach based on the Kolmogorov Arnold Network (KAN) for static friction modeling of robotic joints. The method integrates spline activation functions with a symbolic regression mechanism, enabling model simplification and physical expression extraction through pruning and attribute scoring, while maintaining both high prediction accuracy and interpretability. We first validate the method's capability to accurately identify key parameters under known functional models, and further demonstrate its robustness and generalization ability under conditions with unknown functional structures and noisy data. Experiments conducted on both synthetic data and real friction data collected from a six-degree-of-freedom industrial manipulator show that the proposed method achieves a coefficient of determination greater than 0.95 across various tasks and successfully extracts concise and physically meaningful friction expressions. This study provides a new perspective for interpretable and data-driven robotic friction modeling with promising engineering applicability.

</details>


### [12] [Opinion: Towards Unified Expressive Policy Optimization for Robust Robot Learning](https://arxiv.org/abs/2511.10087)
*Haidong Huang,Haiyue Zhu. Jiayu Song,Xixin Zhao,Yaohua Zhou,Jiayi Zhang,Yuze Zhai,Xiaocong Li*

Main category: cs.RO

TL;DR: UEPO是一个统一的生成框架，通过多模态扩散策略、动态发散正则化和扩散数据增强，解决离线到在线强化学习中的行为覆盖不足和分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 解决离线到在线强化学习中两个基本挑战：多模态行为覆盖不足和在线适应期间的分布偏移。

Method: 提出多种子动态感知扩散策略捕获多样模态，动态发散正则化机制确保物理意义策略多样性，以及基于扩散的数据增强模块提升动态模型泛化能力。

Result: 在D4RL基准测试中，UEPO在运动任务上比Uni-O4绝对提升5.9%，在灵巧操作任务上提升12.4%，展现出强大的泛化性和可扩展性。

Conclusion: UEPO框架通过统一生成方法有效解决了O2O-RL的核心挑战，在多个任务上取得了显著性能提升。

Abstract: Offline-to-online reinforcement learning (O2O-RL) has emerged as a promising paradigm for safe and efficient robotic policy deployment but suffers from two fundamental challenges: limited coverage of multimodal behaviors and distributional shifts during online adaptation. We propose UEPO, a unified generative framework inspired by large language model pretraining and fine-tuning strategies. Our contributions are threefold: (1) a multi-seed dynamics-aware diffusion policy that efficiently captures diverse modalities without training multiple models; (2) a dynamic divergence regularization mechanism that enforces physically meaningful policy diversity; and (3) a diffusion-based data augmentation module that enhances dynamics model generalization. On the D4RL benchmark, UEPO achieves +5.9\% absolute improvement over Uni-O4 on locomotion tasks and +12.4\% on dexterous manipulation, demonstrating strong generalization and scalability.

</details>


### [13] [Learning a Thousand Tasks in a Day](https://arxiv.org/abs/2511.10110)
*Kamil Dreczkowski,Pietro Vitiello,Vitalis Vosylius,Edward Johns*

Main category: cs.RO

TL;DR: 本文提出了一种基于轨迹分解和检索的模仿学习方法MT3，通过将操作轨迹分解为对齐和交互两个阶段，在少量演示（<10个）的情况下，相比单阶段学习实现了数量级的数据效率提升，能够从单个演示学习日常操作任务。


<details>
  <summary>Details</summary>
Motivation: 当前机器人模仿学习方法通常需要数百或数千个演示才能学习一个任务，而人类能够从少量演示中高效学习。本文旨在研究如何通过轨迹分解和检索先验来提高学习效率。

Method: 将操作轨迹分解为顺序对齐和交互两个阶段，开发了基于分解和检索的多任务轨迹转移方法MT3。通过3,450次真实世界测试系统研究了这种分解方法，比较了对齐和交互阶段的不同设计选择。

Result: 在少量演示情况下，分解方法比单阶段学习的数据效率提高了一个数量级。MT3能够从单个演示学习日常操作任务，并在24小时内教会机器人1,000个不同的日常任务。通过2,200次额外测试验证了MT3在不同任务族中的能力和局限性。

Conclusion: 轨迹分解和检索是提高模仿学习效率的有效方法，MT3方法在少量演示情况下表现出色，能够实现大规模任务学习，但仍有局限性需要进一步研究。

Abstract: Humans are remarkably efficient at learning tasks from demonstrations, but today's imitation learning methods for robot manipulation often require hundreds or thousands of demonstrations per task. We investigate two fundamental priors for improving learning efficiency: decomposing manipulation trajectories into sequential alignment and interaction phases, and retrieval-based generalisation. Through 3,450 real-world rollouts, we systematically study this decomposition. We compare different design choices for the alignment and interaction phases, and examine generalisation and scaling trends relative to today's dominant paradigm of behavioural cloning with a single-phase monolithic policy. In the few-demonstrations-per-task regime (<10 demonstrations), decomposition achieves an order of magnitude improvement in data efficiency over single-phase learning, with retrieval consistently outperforming behavioural cloning for both alignment and interaction. Building on these insights, we develop Multi-Task Trajectory Transfer (MT3), an imitation learning method based on decomposition and retrieval. MT3 learns everyday manipulation tasks from as little as a single demonstration each, whilst also generalising to novel object instances. This efficiency enables us to teach a robot 1,000 distinct everyday tasks in under 24 hours of human demonstrator time. Through 2,200 additional real-world rollouts, we reveal MT3's capabilities and limitations across different task families. Videos of our experiments can be found on at https://www.robot-learning.uk/learning-1000-tasks.

</details>


### [14] [RoboBenchMart: Benchmarking Robots in Retail Environment](https://arxiv.org/abs/2511.10276)
*Konstantin Soshin,Alexander Krapukhin,Andrei Spiridonov,Denis Shepelev,Gregorii Bukhtuev,Andrey Kuznetsov,Vlad Shakhuro*

Main category: cs.RO

TL;DR: 提出了RoboBenchMart基准测试，针对黑暗商店环境中的复杂机器人操作任务，解决了现有基准测试局限于简化桌面场景的问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作基准测试主要关注简化的桌面场景，缺乏对真实零售环境中复杂操作任务的评估，而零售领域具有近期自动化的巨大潜力。

Method: 开发了RoboBenchMart套件，包括程序化商店布局生成器、轨迹生成管道、评估工具和微调基线模型。

Result: 当前最先进的通用模型在常见的零售任务上表现不佳，证明了该基准测试的挑战性。

Conclusion: RoboBenchMart为零售环境中的机器人操作研究提供了更真实、更具挑战性的评估平台，有助于推动该领域的发展。

Abstract: Most existing robotic manipulation benchmarks focus on simplified tabletop scenarios, typically involving a stationary robotic arm interacting with various objects on a flat surface. To address this limitation, we introduce RoboBenchMart, a more challenging and realistic benchmark designed for dark store environments, where robots must perform complex manipulation tasks with diverse grocery items. This setting presents significant challenges, including dense object clutter and varied spatial configurations -- with items positioned at different heights, depths, and in close proximity. By targeting the retail domain, our benchmark addresses a setting with strong potential for near-term automation impact. We demonstrate that current state-of-the-art generalist models struggle to solve even common retail tasks. To support further research, we release the RoboBenchMart suite, which includes a procedural store layout generator, a trajectory generation pipeline, evaluation tools and fine-tuned baseline models.

</details>


### [15] [nuPlan-R: A Closed-Loop Planning Benchmark for Autonomous Driving via Reactive Multi-Agent Simulation](https://arxiv.org/abs/2511.10403)
*Mingxing Peng,Ruoyu Yao,Xusen Guo,Jun Ma*

Main category: cs.RO

TL;DR: nuPlan-R是一个新的反应式闭环规划基准，用基于学习的反应式多智能体模拟取代了基于规则的IDM智能体，提供了更真实、多样和类人的交通行为评估环境。


<details>
  <summary>Details</summary>
Motivation: 现有的自动驾驶规划基准仍然依赖基于规则的反应式智能体（如IDM），这些智能体缺乏行为多样性，无法捕捉真实的人类交互，导致交通动态过于简化。

Method: 将基于学习的反应式多智能体模拟集成到nuPlan框架中，用噪声解耦的基于扩散的反应式智能体替换基于规则的IDM智能体，并引入交互感知的智能体选择机制以确保真实性和计算效率。

Result: 实验表明，反应式智能体模型产生更真实、多样和类人的交通行为，基准环境能更好地反映真实世界的交互驾驶。重新实现的规划方法在复杂交互场景中更清晰地反映了规划器性能。

Conclusion: nuPlan-R为公平、反应式和真实的闭环规划评估建立了新标准，更好地突显了基于学习的规划器在复杂动态场景中的优势。

Abstract: Recent advances in closed-loop planning benchmarks have significantly improved the evaluation of autonomous vehicles. However, existing benchmarks still rely on rule-based reactive agents such as the Intelligent Driver Model (IDM), which lack behavioral diversity and fail to capture realistic human interactions, leading to oversimplified traffic dynamics. To address these limitations, we present nuPlan-R, a new reactive closed-loop planning benchmark that integrates learning-based reactive multi-agent simulation into the nuPlan framework. Our benchmark replaces the rule-based IDM agents with noise-decoupled diffusion-based reactive agents and introduces an interaction-aware agent selection mechanism to ensure both realism and computational efficiency. Furthermore, we extend the benchmark with two additional metrics to enable a more comprehensive assessment of planning performance. Extensive experiments demonstrate that our reactive agent model produces more realistic, diverse, and human-like traffic behaviors, leading to a benchmark environment that better reflects real-world interactive driving. We further reimplement a collection of rule-based, learning-based, and hybrid planning approaches within our nuPlan-R benchmark, providing a clearer reflection of planner performance in complex interactive scenarios and better highlighting the advantages of learning-based planners in handling complex and dynamic scenarios. These results establish nuPlan-R as a new standard for fair, reactive, and realistic closed-loop planning evaluation. We will open-source the code for the new benchmark.

</details>


### [16] [LongComp: Long-Tail Compositional Zero-Shot Generalization for Robust Trajectory Prediction](https://arxiv.org/abs/2511.10411)
*Benjamin Stoler,Jonathan Francis,Jean Oh*

Main category: cs.RO

TL;DR: 提出了自动驾驶轨迹预测的长尾评估方法，通过场景分解构建OOD测试集，并开发了任务模块化门控网络和难度预测头来提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶轨迹预测需要处理罕见但安全关键的长尾场景，仅依赖真实世界数据收集不可行，需要评估模型在OOD条件下的鲁棒性。

Method: 1) 提出安全导向的场景分解框架，将场景解耦为离散的自我和社会上下文；2) 基于零样本图像标注类比，构建封闭世界和开放世界的OOD测试集；3) 扩展任务模块化门控网络，开发难度预测头来优化内部表示。

Result: 在封闭世界和开放世界设置中，OOD性能差距分别为5.0%和14.7%。提出的方法将这两个差距分别降低到2.8%和11.5%，同时仍提高了分布内性能。

Conclusion: 通过场景分解和模块化架构改进，可以有效提升轨迹预测模型在长尾OOD场景下的鲁棒性和泛化能力。

Abstract: Methods for trajectory prediction in Autonomous Driving must contend with rare, safety-critical scenarios that make reliance on real-world data collection alone infeasible. To assess robustness under such conditions, we propose new long-tail evaluation settings that repartition datasets to create challenging out-of-distribution (OOD) test sets. We first introduce a safety-informed scenario factorization framework, which disentangles scenarios into discrete ego and social contexts. Building on analogies to compositional zero-shot image-labeling in Computer Vision, we then hold out novel context combinations to construct challenging closed-world and open-world settings. This process induces OOD performance gaps in future motion prediction of 5.0% and 14.7% in closed-world and open-world settings, respectively, relative to in-distribution performance for a state-of-the-art baseline. To improve generalization, we extend task-modular gating networks to operate within trajectory prediction models, and develop an auxiliary, difficulty-prediction head to refine internal representations. Our strategies jointly reduce the OOD performance gaps to 2.8% and 11.5% in the two settings, respectively, while still improving in-distribution performance.

</details>


### [17] [Improving dependability in robotized bolting operations](https://arxiv.org/abs/2511.10448)
*Lorenzo Pagliara,Violeta Redondo,Enrico Ferrentino,Manuel Ferre,Pasquale Chiacchio*

Main category: cs.RO

TL;DR: 提出了一种用于可靠机器人螺栓连接任务的控制框架，该系统具有精确的扭矩控制、主动柔顺性和多模态人机界面，在故障条件下仍能安全运行。


<details>
  <summary>Details</summary>
Motivation: 当前机器人系统在螺栓操作中缺乏可靠的自主性和故障管理能力，需要提高操作安全性和有效性。

Method: 采用控制架构确保精确的驱动扭矩控制和主动柔顺性，设计多模态人机界面提供实时可视化，高层监督器协调执行并管理控制模式转换。

Result: 在代表性螺栓操作中验证，结果显示改进的故障检测能力、增强的操作员态势感知以及准确柔顺的螺栓操作执行。

Conclusion: 该系统提高了螺栓操作的可靠性和安全性，但依赖单一摄像头实现完全态势感知存在局限性。

Abstract: Bolting operations are critical in industrial assembly and in the maintenance of scientific facilities, requiring high precision and robustness to faults. Although robotic solutions have the potential to improve operational safety and effectiveness, current systems still lack reliable autonomy and fault management capabilities. To address this gap, we propose a control framework for dependable robotized bolting tasks and instantiate it on a specific robotic system. The system features a control architecture ensuring accurate driving torque control and active compliance throughout the entire operation, enabling safe interaction even under fault conditions. By designing a multimodal human-robot interface (HRI) providing real-time visualization of relevant system information and supporting seamless transitions between automatic and manual control, we improve operator situation awareness and fault detection capabilities. A high-level supervisor (SV) coordinates the execution and manages transitions between control modes, ensuring consistency with the supervisory control (SVC) paradigm, while preserving the human operator's authority. The system is validated in a representative bolting operation involving pipe flange joining, under several fault conditions. The results demonstrate improved fault detection capabilities, enhanced operator situational awareness, and accurate and compliant execution of the bolting operation. However, they also reveal the limitations of relying on a single camera to achieve full situational awareness.

</details>


### [18] [From Fold to Function: Dynamic Modeling and Simulation-Driven Design of Origami Mechanisms](https://arxiv.org/abs/2511.10580)
*Tianhui Han,Shashwat Singh,Sarvesh Patil,Zeynep Temel*

Main category: cs.RO

TL;DR: 提出基于MuJoCo的折纸机构仿真设计框架，通过图形界面定义折纸片的约束和驱动，实现物理一致的仿真，并通过折纸弹射器的案例验证了仿真驱动优化的有效性。


<details>
  <summary>Details</summary>
Motivation: 折纸机构具有轻量化、紧凑和复杂运动能力等优点，但在机器人系统和可展开系统中，准确模拟其折叠行为和环境交互仍具挑战性。

Method: 使用MuJoCo的可变形体功能，将折纸片表示为相互连接的可变形元素图，通过图形界面定义折痕和驱动等约束，生成物理一致的仿真。

Result: 通过折纸弹射器案例研究，使用CMA-ES算法优化设计参数，实验验证优化后的结构实现了改进的投掷性能。

Conclusion: 该系统实现了快速、仿真驱动的折纸设计、优化和分析，为折纸机构的应用提供了有效的工具。

Abstract: Origami-inspired mechanisms can transform flat sheets into functional three-dimensional dynamic structures that are lightweight, compact, and capable of complex motion. These properties make origami increasingly valuable in robotic and deployable systems. However, accurately simulating their folding behavior and interactions with the environment remains challenging. To address this, we present a design framework for origami mechanism simulation that utilizes MuJoCo's deformable-body capabilities. In our approach, origami sheets are represented as graphs of interconnected deformable elements with user-specified constraints such as creases and actuation, defined through an intuitive graphical user interface (GUI). This framework allows users to generate physically consistent simulations that capture both the geometric structure of origami mechanisms and their interactions with external objects and surfaces. We demonstrate our method's utility through a case study on an origami catapult, where design parameters are optimized in simulation using the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) and validated experimentally on physical prototypes. The optimized structure achieves improved throwing performance, illustrating how our system enables rapid, simulation-driven origami design, optimization, and analysis.

</details>


### [19] [Optimizing the flight path for a scouting Uncrewed Aerial Vehicle](https://arxiv.org/abs/2511.10598)
*Raghav Adhikari,Sachet Khatiwada,Suman Poudel*

Main category: cs.RO

TL;DR: 使用无人机在灾后环境中进行侦察，通过优化方法规划无人机在最佳高度飞行，以最大化传感器覆盖面积并最小化数据不确定性。


<details>
  <summary>Details</summary>
Motivation: 灾后环境结构混乱，难以规划救援车辆路径，需要无人机进行环境侦察。

Method: 提出基于优化的方法，规划无人机在最佳高度的飞行路径。

Result: 无人机传感器能够在最佳高度覆盖最大面积并收集不确定性最小的数据。

Conclusion: 优化方法能够有效解决灾后环境中的无人机侦察路径规划问题。

Abstract: Post-disaster situations pose unique navigation challenges. One of those challenges is the unstructured nature of the environment, which makes it hard to layout paths for rescue vehicles. We propose the use of Uncrewed Aerial Vehicle (UAV) in such scenario to perform reconnaissance across the environment. To accomplish this, we propose an optimization-based approach to plan a path for the UAV at optimal height where the sensors of the UAV can cover the most area and collect data with minimum uncertainty.

</details>


### [20] [Robot Crash Course: Learning Soft and Stylized Falling](https://arxiv.org/abs/2511.10635)
*Pascal Strauch,David Müller,Sammy Christen,Agon Serifi,Ruben Grandia,Espen Knoop,Moritz Bächer*

Main category: cs.RO

TL;DR: 提出了一种机器人无关的奖励函数，用于在强化学习中平衡实现期望的最终姿势与冲击最小化及保护关键机器人部件。通过模拟初始和最终姿势的采样策略，使策略对广泛的初始跌落条件具有鲁棒性，并能在推理时指定任意未见过的最终姿势。


<details>
  <summary>Details</summary>
Motivation: 尽管双足机器人在稳健运动方面取得了进展，但在现实世界中操作时仍有跌倒风险。大多数研究专注于防止跌倒，而本文关注跌倒现象本身，旨在减少机器人物理损伤，同时让用户能够控制机器人的最终姿势。

Method: 提出机器人无关的奖励函数，在强化学习中平衡实现期望最终姿势、最小化冲击和保护关键部件。引入基于模拟的初始和最终姿势采样策略，使策略对广泛初始跌落条件具有鲁棒性，并能在推理时指定任意未见过的最终姿势。

Result: 通过模拟和真实世界实验证明，即使是双足机器人也能执行受控的软着陆。

Conclusion: 本文展示了双足机器人能够执行受控的软着陆，通过平衡最终姿势控制和冲击最小化来减少物理损伤。

Abstract: Despite recent advances in robust locomotion, bipedal robots operating in the real world remain at risk of falling. While most research focuses on preventing such events, we instead concentrate on the phenomenon of falling itself. Specifically, we aim to reduce physical damage to the robot while providing users with control over a robot's end pose. To this end, we propose a robot agnostic reward function that balances the achievement of a desired end pose with impact minimization and the protection of critical robot parts during reinforcement learning. To make the policy robust to a broad range of initial falling conditions and to enable the specification of an arbitrary and unseen end pose at inference time, we introduce a simulation-based sampling strategy of initial and end poses. Through simulated and real-world experiments, our work demonstrates that even bipedal robots can perform controlled, soft falls.

</details>
