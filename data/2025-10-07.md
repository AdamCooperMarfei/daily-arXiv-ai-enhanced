<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 55]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Gemini Robotics 1.5: Pushing the Frontier of Generalist Robots with Advanced Embodied Reasoning, Thinking, and Motion Transfer](https://arxiv.org/abs/2510.03342)
*Abbas Abdolmaleki,Saminda Abeyruwan,Joshua Ainslie,Jean-Baptiste Alayrac,Montserrat Gonzalez Arenas,Ashwin Balakrishna,Nathan Batchelor,Alex Bewley,Jeff Bingham,Michael Bloesch,Konstantinos Bousmalis,Philemon Brakel,Anthony Brohan,Thomas Buschmann,Arunkumar Byravan,Serkan Cabi,Ken Caluwaerts,Federico Casarini,Christine Chan,Oscar Chang,London Chappellet-Volpini,Jose Enrique Chen,Xi Chen,Hao-Tien Lewis Chiang,Krzysztof Choromanski,Adrian Collister,David B. D'Ambrosio,Sudeep Dasari,Todor Davchev,Meet Kirankumar Dave,Coline Devin,Norman Di Palo,Tianli Ding,Carl Doersch,Adil Dostmohamed,Yilun Du,Debidatta Dwibedi,Sathish Thoppay Egambaram,Michael Elabd,Tom Erez,Xiaolin Fang,Claudio Fantacci,Cody Fong,Erik Frey,Chuyuan Fu,Ruiqi Gao,Marissa Giustina,Keerthana Gopalakrishnan,Laura Graesser,Oliver Groth,Agrim Gupta,Roland Hafner,Steven Hansen,Leonard Hasenclever,Sam Haves,Nicolas Heess,Brandon Hernaez,Alex Hofer,Jasmine Hsu,Lu Huang,Sandy H. Huang,Atil Iscen,Mithun George Jacob,Deepali Jain,Sally Jesmonth,Abhishek Jindal,Ryan Julian,Dmitry Kalashnikov,M. Emre Karagozler,Stefani Karp,Matija Kecman,J. Chase Kew,Donnie Kim,Frank Kim,Junkyung Kim,Thomas Kipf,Sean Kirmani,Ksenia Konyushkova,Li Yang Ku,Yuheng Kuang,Thomas Lampe,Antoine Laurens,Tuan Anh Le,Isabel Leal,Alex X. Lee,Tsang-Wei Edward Lee,Guy Lever,Jacky Liang,Li-Heng Lin,Fangchen Liu,Shangbang Long,Caden Lu,Sharath Maddineni,Anirudha Majumdar,Kevis-Kokitsi Maninis,Andrew Marmon,Sergio Martinez,Assaf Hurwitz Michaely,Niko Milonopoulos,Joss Moore,Robert Moreno,Michael Neunert,Francesco Nori,Joy Ortiz,Kenneth Oslund,Carolina Parada,Emilio Parisotto,Amaris Paryag,Acorn Pooley,Thomas Power,Alessio Quaglino,Haroon Qureshi,Rajkumar Vasudeva Raju,Helen Ran,Dushyant Rao,Kanishka Rao,Isaac Reid,David Rendleman,Krista Reymann,Miguel Rivas,Francesco Romano,Yulia Rubanova,Peter Pastor Sampedro,Pannag R Sanketi,Dhruv Shah,Mohit Sharma,Kathryn Shea,Mohit Shridhar,Charles Shu,Vikas Sindhwani,Sumeet Singh,Radu Soricut,Rachel Sterneck,Ian Storz,Razvan Surdulescu,Jie Tan,Jonathan Tompson,Saran Tunyasuvunakool,Jake Varley,Grace Vesom,Giulia Vezzani,Maria Bauza Villalonga,Oriol Vinyals,René Wagner,Ayzaan Wahid,Stefan Welker,Paul Wohlhart,Chengda Wu,Markus Wulfmeier,Fei Xia,Ted Xiao,Annie Xie,Jinyu Xie,Peng Xu,Sichun Xu,Ying Xu,Zhuo Xu,Jimmy Yan,Sherry Yang,Skye Yang,Yuxiang Yang,Hiu Hong Yu,Wenhao Yu,Wentao Yuan,Yuan Yuan,Jingwei Zhang,Tingnan Zhang,Zhiyuan Zhang,Allan Zhou,Guangyao Zhou,Yuxiang Zhou*

Main category: cs.RO

TL;DR: Gemini Robotics 1.5是一个多具身视觉-语言-动作模型，具有运动转移机制和内部推理过程，能在行动前进行思考；Gemini Robotics-ER 1.5是先进的具身推理模型，在视觉空间理解、任务规划和进度评估方面达到新水平。


<details>
  <summary>Details</summary>
Motivation: 通用机器人需要深入理解物理世界、高级推理能力和通用灵巧控制能力，因此开发新一代机器人模型家族。

Method: 采用新型架构和运动转移机制，从异构多具身机器人数据中学习；在自然语言中交织动作与多级内部推理过程；建立具身推理模型。

Result: 模型能够分解和执行复杂的多步骤任务，使机器人行为对用户更可解释，在具身推理方面达到最先进水平。

Conclusion: 这一模型家族推动了物理智能体时代的到来，使机器人能够感知、思考然后行动，解决复杂多步骤任务。

Abstract: General-purpose robots need a deep understanding of the physical world,
advanced reasoning, and general and dexterous control. This report introduces
the latest generation of the Gemini Robotics model family: Gemini Robotics 1.5,
a multi-embodiment Vision-Language-Action (VLA) model, and Gemini Robotics-ER
1.5, a state-of-the-art Embodied Reasoning (ER) model. We are bringing together
three major innovations. First, Gemini Robotics 1.5 features a novel
architecture and a Motion Transfer (MT) mechanism, which enables it to learn
from heterogeneous, multi-embodiment robot data and makes the VLA more general.
Second, Gemini Robotics 1.5 interleaves actions with a multi-level internal
reasoning process in natural language. This enables the robot to "think before
acting" and notably improves its ability to decompose and execute complex,
multi-step tasks, and also makes the robot's behavior more interpretable to the
user. Third, Gemini Robotics-ER 1.5 establishes a new state-of-the-art for
embodied reasoning, i.e., for reasoning capabilities that are critical for
robots, such as visual and spatial understanding, task planning, and progress
estimation. Together, this family of models takes us a step towards an era of
physical agents-enabling robots to perceive, think and then act so they can
solve complex multi-step tasks.

</details>


### [2] [Optimal swimming with body compliance in an overdamped medium](https://arxiv.org/abs/2510.03457)
*Jianfeng Lin,Tianyu Wang,Baxi Chong,Matthew Fernandez,Zhaochen Xu,Daniel I. Goldman*

Main category: cs.RO

TL;DR: 扩展几何力学框架以预测和控制柔性波动游泳机器人的运动性能，通过引入关节弹簧的柔性三连杆游泳器模型，在颗粒介质中验证了运动预测和优化策略。


<details>
  <summary>Details</summary>
Motivation: 现有几何力学方法假设精确执行规定的步态，但实际环境中柔性体与环境的相互作用会干扰实现轨迹，需要扩展框架来处理柔性波动游泳器的运动控制。

Method: 在Purcell三连杆游泳器基础上引入串联弹簧创建柔性模型，结合阻力理论推导体动力学，将几何力学融入运动预测和优化框架，识别实现最大位移的控制策略。

Result: 在物理电缆驱动的三连杆无肢机器人上验证了框架，在颗粒介质中准确预测和优化了不同编程状态相关柔性下的运动性能。

Conclusion: 建立了一个系统的基于物理的方法来建模和控制柔性游泳运动，强调柔性可以作为在均匀和非均匀环境中实现稳健运动的设计特征。

Abstract: Elongate animals and robots use undulatory body waves to locomote through
diverse environments. Geometric mechanics provides a framework to model and
optimize such systems in highly damped environments, connecting a prescribed
shape change pattern (gait) with locomotion displacement. However, existing
approaches assume precise execution of prescribed gaits, whereas in practice
environmental interactions with compliant bodies of animals or robots
frequently perturb the realized trajectories. In this work, we extend geometric
mechanics to predict locomotor performance and search for optimal swimming
strategy of compliant undulators. We introduce a compliant extension of
Purcell's three-link swimmer by incorporating series-connected springs at the
joints. Body dynamics are derived with resistive force theory. Geometric
mechanics is incorporated into movement prediction and into an optimization
framework that identifies strategies for controlling compliant swimmers to
achieve maximal displacement. We validate our framework on a physical
cable-driven three-link limbless robot, and demonstrate accurate prediction and
optimization of locomotor performance under varied programmed, state-dependent
compliance in a granular medium. Our results establish a systematic
physics-based approach for modeling and controlling compliant swimming
locomotion, highlighting compliance as a design feature that can be exploited
for robust movement in homogeneous and heterogeneous environments.

</details>


### [3] [Warm-Starting Optimization-Based Motion Planning for Robotic Manipulators via Point Cloud-Conditioned Flow Matching](https://arxiv.org/abs/2510.03460)
*Sibo Tian,Minghui Zheng,Xiao Liang*

Main category: cs.RO

TL;DR: 提出一种基于流匹配模型的生成式初始化方法，通过单视角点云条件生成接近最优的轨迹，用于优化运动规划的初始化，提高成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 在HRC系统中需要实时生成机器人运动，现有采样规划器在高维空间扩展性差且需要后处理，优化规划器对初始化敏感易陷入局部最优。

Method: 使用流匹配模型，以单视角点云为条件学习接近最优的优化初始化解，无需先验环境知识，直接从深度相机输入生成可行轨迹。

Result: 在UR5e机械臂杂乱工作空间的仿真中，该方法单独使用成功率高，显著提升轨迹优化成功率，减少优化迭代次数，对未见环境有强泛化能力。

Conclusion: 所提出的生成式初始化器能有效解决优化规划器的初始化问题，在复杂环境中实现高效、安全的机器人运动规划。

Abstract: Rapid robot motion generation is critical in Human-Robot Collaboration (HRC)
systems, as robots need to respond to dynamic environments in real time by
continuously observing their surroundings and replanning their motions to
ensure both safe interactions and efficient task execution. Current
sampling-based motion planners face challenges in scaling to high-dimensional
configuration spaces and often require post-processing to interpolate and
smooth the generated paths, resulting in time inefficiency in complex
environments. Optimization-based planners, on the other hand, can incorporate
multiple constraints and generate smooth trajectories directly, making them
potentially more time-efficient. However, optimization-based planners are
sensitive to initialization and may get stuck in local minima. In this work, we
present a novel learning-based method that utilizes a Flow Matching model
conditioned on a single-view point cloud to learn near-optimal solutions for
optimization initialization. Our method does not require prior knowledge of the
environment, such as obstacle locations and geometries, and can generate
feasible trajectories directly from single-view depth camera input. Simulation
studies on a UR5e robotic manipulator in cluttered workspaces demonstrate that
the proposed generative initializer achieves a high success rate on its own,
significantly improves the success rate of trajectory optimization compared
with traditional and learning-based benchmark initializers, requires fewer
optimization iterations, and exhibits strong generalization to unseen
environments.

</details>


### [4] [A Simulation Evaluation Suite for Robust Adaptive Quadcopter Control](https://arxiv.org/abs/2510.03471)
*Dingqi Zhang,Ran Tao,Sheng Cheng,Naira Hovakimyan,Mark W. Mueller*

Main category: cs.RO

TL;DR: 提出了一个基于RotorPy的模块化四旋翼控制仿真测试平台，用于在多种干扰条件下系统评估自适应控制方法。


<details>
  <summary>Details</summary>
Motivation: 现有四旋翼自适应控制方法在不同任务、仿真器和实现中的碎片化评估阻碍了系统比较，需要统一的测试环境。

Method: 开发易于部署的模块化仿真测试平台，包含代表性自适应和非自适应控制器库，提供任务相关指标评估跟踪精度和鲁棒性。

Result: 该框架支持在风扰、载荷偏移、旋翼故障和控制延迟等多种干扰场景下进行可重复评估，消除了扰动模型、轨迹生成器等组件的冗余实现。

Conclusion: 该测试平台通过多种干扰场景和轨迹类型的示例展示了其多功能性，为系统分析提供了实用工具。

Abstract: Robust adaptive control methods are essential for maintaining quadcopter
performance under external disturbances and model uncertainties. However,
fragmented evaluations across tasks, simulators, and implementations hinder
systematic comparison of these methods. This paper introduces an
easy-to-deploy, modular simulation testbed for quadcopter control, built on
RotorPy, that enables evaluation under a wide range of disturbances such as
wind, payload shifts, rotor faults, and control latency. The framework includes
a library of representative adaptive and non-adaptive controllers and provides
task-relevant metrics to assess tracking accuracy and robustness. The unified
modular environment enables reproducible evaluation across control methods and
eliminates redundant reimplementation of components such as disturbance models,
trajectory generators, and analysis tools. We illustrate the testbed's
versatility through examples spanning multiple disturbance scenarios and
trajectory types, including automated stress testing, to demonstrate its
utility for systematic analysis. Code is available at
https://github.com/Dz298/AdaptiveQuadBench.

</details>


### [5] [Destination-to-Chutes Task Mapping Optimization for Multi-Robot Coordination in Robotic Sorting Systems](https://arxiv.org/abs/2510.03472)
*Yulun Zhang,Alexandre O. G. Barbosa,Federico Pecora,Jiaoyang Li*

Main category: cs.RO

TL;DR: 本文研究了在机器人分拣系统中优化目的地到滑槽的任务映射以提高吞吐量，提出了基于进化算法和混合整数线性规划的优化方法，并展示了优化映射在各种系统设置下的优势。


<details>
  <summary>Details</summary>
Motivation: 在机器人分拣系统中，目的地到滑槽的任务映射直接影响系统吞吐量，但由于系统复杂性（包括机器人目标分配、路径规划、滑槽关闭时间等），找到高质量的任务映射具有挑战性。

Method: 首先正式定义了任务映射和任务映射优化问题，然后开发了机器人分拣系统模拟器，提出了基于进化算法和混合整数线性规划的简单优化方法。

Result: 在各种不同地图大小、滑槽数量和目的地的机器人分拣系统设置中，优化后的任务映射相比贪婪生成的映射具有明显优势。

Conclusion: 通过质量多样性算法分析多样化任务映射的吞吐量，证明了优化任务映射对提高机器人分拣系统性能的重要性。

Abstract: We study optimizing a destination-to-chutes task mapping to improve
throughput in Robotic Sorting Systems (RSS), where a team of robots sort
packages on a sortation floor by transporting them from induct workstations to
eject chutes based on their shipping destinations (e.g. Los Angeles or
Pittsburgh). The destination-to-chutes task mapping is used to determine which
chutes a robot can drop its package. Finding a high-quality task mapping is
challenging because of the complexity of a real-world RSS. First, optimizing
task mapping is interdependent with robot target assignment and path planning.
Second, chutes will be CLOSED for a period of time once they receive sufficient
packages to allow for downstream processing. Third, task mapping quality
directly impacts the downstream processing, as scattered chutes for the same
destination increase package handling time. In this paper, we first formally
define task mappings and the problem of Task Mapping Optimization (TMO). We
then present a simulator of RSS to evaluate task mappings. We then present a
simple TMO method based on the Evolutionary Algorithm and Mixed Integer Linear
Programming, demonstrating the advantage of our optimized task mappings over
the greedily generated ones in various RSS setups with different map sizes,
numbers of chutes, and destinations. Finally, we use Quality Diversity
algorithms to analyze the throughput of a diverse set of task mappings. Our
code is available online at https://github.com/lunjohnzhang/tmo_public.

</details>


### [6] [Robust Permissive Controller Synthesis for Interval MDPs](https://arxiv.org/abs/2510.03481)
*Khang Vo Huynh,David Parker,Lu Feng*

Main category: cs.RO

TL;DR: 提出了首个在区间马尔可夫决策过程(IMDPs)上的鲁棒宽松控制器合成框架，保证所有符合合成多策略的策略在所有允许转移下满足可达性或基于奖励的规范。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在不确定动态下运行的鲁棒控制器合成问题，传统控制器合成通常产生单一确定性策略，限制了适应性，而宽松控制器允许多个动作，但先前工作假设精确转移概率，这在机器人应用中不现实。

Method: 将问题表述为混合整数线性规划(MILPs)，提出了两种编码方法：基线顶点枚举方法和可扩展的对偶方法，避免显式枚举。

Result: 在四个基准域上的实验表明，两种方法都能合成鲁棒、最大宽松的控制器，并可扩展到具有数十万个状态的大型IMDPs。

Conclusion: 提出的框架是首个在IMDPs上合成鲁棒宽松控制器的方法，有效处理机器人应用中的不确定性，同时保持运行时灵活性。

Abstract: We address the problem of robust permissive controller synthesis for robots
operating under uncertain dynamics, modeled as Interval Markov Decision
Processes (IMDPs). IMDPs generalize standard MDPs by allowing transition
probabilities to vary within intervals, capturing epistemic uncertainty from
sensing noise, actuation imprecision, and coarse system abstractions-common in
robotics. Traditional controller synthesis typically yields a single
deterministic strategy, limiting adaptability. In contrast, permissive
controllers (multi-strategies) allow multiple actions per state, enabling
runtime flexibility and resilience. However, prior work on permissive
controller synthesis generally assumes exact transition probabilities, which is
unrealistic in many robotic applications. We present the first framework for
robust permissive controller synthesis on IMDPs, guaranteeing that all
strategies compliant with the synthesized multi-strategy satisfy reachability
or reward-based specifications under all admissible transitions. We formulate
the problem as mixed-integer linear programs (MILPs) and propose two encodings:
a baseline vertex-enumeration method and a scalable duality-based method that
avoids explicit enumeration. Experiments on four benchmark domains show that
both methods synthesize robust, maximally permissive controllers and scale to
large IMDPs with up to hundreds of thousands of states.

</details>


### [7] [Digital-Twin Evaluation for Proactive Human-Robot Collision Avoidance via Prediction-Guided A-RRT*](https://arxiv.org/abs/2510.03496)
*Vadivelan Murugesan,Rajasundaram Mathiazhagan,Sanjana Joshi,Aliasghar Arab*

Main category: cs.RO

TL;DR: 提出了一种基于预测的安全规划框架，通过数字孪生验证的细粒度人体运动预测，结合胶囊人工势场和自适应RRT*规划器，实现主动避障。


<details>
  <summary>Details</summary>
Motivation: 人机协作需要长期精确预测人体运动以实现主动避障，现有规划器仅依赖运动学模型存在局限性。

Method: 使用深度相机提取3D骨骼姿态，CNN-BiLSTM模型预测关节轨迹，胶囊人工势场评估碰撞风险，触发A-RRT*规划器，通过数字孪生验证轨迹。

Result: 在50次试验中实现100%主动避障，安全距离大于250毫米，重规划时间小于2秒。

Conclusion: 该方法通过预测性人体建模与数字孪生验证的结合，相比仅基于运动学的规划器具有更高的精度和可靠性。

Abstract: Human-robot collaboration requires precise prediction of human motion over
extended horizons to enable proactive collision avoidance. Unlike existing
planners that rely solely on kinodynamic models, we present a prediction-driven
safe planning framework that leverages granular, joint-by-joint human motion
forecasting validated in a physics-based digital twin. A capsule-based
artificial potential field (APF) converts these granular predictions into
collision risk metrics, triggering an Adaptive RRT* (A-RRT*) planner when
thresholds are exceeded. The depth camera is used to extract 3D skeletal poses
and a convolutional neural network-bidirectional long short-term memory
(CNN-BiLSTM) model to predict individual joint trajectories ahead of time. A
digital twin model integrates real-time human posture prediction placed in
front of a simulated robot to evaluate motions and physical contacts. The
proposed method enables validation of planned trajectories ahead of time and
bridging potential latency gaps in updating planned trajectories in real-time.
In 50 trials, our method achieved 100% proactive avoidance with > 250 mm
clearance and sub-2 s replanning, demonstrating superior precision and
reliability compared to existing kinematic-only planners through the
integration of predictive human modeling with digital twin validation.

</details>


### [8] [Distributed Connectivity Maintenance and Recovery for Quadrotor Motion Planning](https://arxiv.org/abs/2510.03504)
*Yutong Wang,Yichun Qu,Tengxiang Wang,Lishuo Pan,Nora Ayanian*

Main category: cs.RO

TL;DR: 提出了一种基于高阶控制屏障函数的实时分布式多机器人导航框架，能够在避障的同时维持机器人间的连接性，并支持从断开状态恢复连接。


<details>
  <summary>Details</summary>
Motivation: 在多机器人应用中保持连接性至关重要，但容易受到障碍物和视觉遮挡的影响。现有方法难以在复杂环境中同时保证连接维护和避障。

Method: 采用统一MPC-CLF-CBF框架，结合Bezier参数化轨迹生成平滑曲线，通过高阶控制屏障函数控制机器人间距，利用控制Lyapunov函数实现连接恢复。

Result: 通过大量仿真和4架Crazyflie纳米四旋翼的物理实验验证了该框架的有效性，能够在障碍物丰富的环境中保持稳健的连接性。

Conclusion: 该框架为多机器人系统提供了一种连续时间轨迹生成和控制方法，能够同时实现连接维护和恢复，在复杂环境中表现鲁棒。

Abstract: Maintaining connectivity is crucial in many multi-robot applications, yet
fragile to obstacles and visual occlusions. We present a real-time distributed
framework for multi-robot navigation certified by high-order control barrier
functions (HOCBFs) that controls inter-robot proximity to maintain connectivity
while avoiding collisions. We incorporate control Lyapunov functions to enable
connectivity recovery from initial disconnected configurations and temporary
losses, providing robust connectivity during navigation in obstacle-rich
environments. Our trajectory generation framework concurrently produces
planning and control through a Bezier-parameterized trajectory, which naturally
provides smooth curves with arbitrary degree of derivatives. The main
contribution is the unified MPC-CLF-CBF framework, a continuous-time trajectory
generation and control method for connectivity maintenance and recovery of
multi-robot systems. We validate the framework through extensive simulations
and a physical experiment with 4 Crazyflie nano-quadrotors.

</details>


### [9] [LapSurgie: Humanoid Robots Performing Surgery via Teleoperated Handheld Laparoscopy](https://arxiv.org/abs/2510.03529)
*Zekai Liang,Xiao Liang,Soofiyan Atar,Sreyan Das,Zoe Chiu,Peihan Zhang,Florian Richter,Shanglei Liu,Michael C. Yip*

Main category: cs.RO

TL;DR: 提出了LapSurgie，首个基于人形机器人的腹腔镜远程操作系统，旨在解决手术机器人系统在资源匮乏地区的部署难题。


<details>
  <summary>Details</summary>
Motivation: 解决手术机器人平台主要局限于高资源医疗中心的问题，缩小农村和低资源地区的医疗差距，探索人形机器人系统在无需大规模基础设施改造的手术环境中的部署潜力。

Method: 采用逆向映射策略控制手动腕式腹腔镜器械，遵守远程运动中心约束，实现精确的手到工具控制；配备立体视觉系统的控制台提供实时视觉反馈。

Result: 跨平台的综合用户研究证明了所提出框架的有效性，并为人形机器人在腹腔镜手术中部署的可行性提供了初步证据。

Conclusion: LapSurgie系统展示了人形机器人系统在腹腔镜远程手术中的潜力，为扩大手术机器人技术在资源匮乏地区的可及性提供了可行方案。

Abstract: Robotic laparoscopic surgery has gained increasing attention in recent years
for its potential to deliver more efficient and precise minimally invasive
procedures. However, adoption of surgical robotic platforms remains largely
confined to high-resource medical centers, exacerbating healthcare disparities
in rural and low-resource regions. To close this gap, a range of solutions has
been explored, from remote mentorship to fully remote telesurgery. Yet, the
practical deployment of surgical robotic systems to underserved communities
remains an unsolved challenge. Humanoid systems offer a promising path toward
deployability, as they can directly operate in environments designed for humans
without extensive infrastructure modifications -- including operating rooms. In
this work, we introduce LapSurgie, the first humanoid-robot-based laparoscopic
teleoperation framework. The system leverages an inverse-mapping strategy for
manual-wristed laparoscopic instruments that abides to remote center-of-motion
constraints, enabling precise hand-to-tool control of off-the-shelf surgical
laparoscopic tools without additional setup requirements. A control console
equipped with a stereo vision system provides real-time visual feedback.
Finally, a comprehensive user study across platforms demonstrates the
effectiveness of the proposed framework and provides initial evidence for the
feasibility of deploying humanoid robots in laparoscopic procedures.

</details>


### [10] [Efficient Surgical Robotic Instrument Pose Reconstruction in Real World Conditions Using Unified Feature Detection](https://arxiv.org/abs/2510.03532)
*Zekai Liang,Kazuya Miyata,Xiao Liang,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: 提出了一种用于微创手术机器人相机-机器人标定的新框架，通过共享编码统一检测几何基元（关键点和轴边缘），实现高效姿态估计。


<details>
  <summary>Details</summary>
Motivation: 微创手术机器人具有长运动链和部分自由度可见性的特点，传统相机-机器人标定方法假设刚性机器人和良好可见性，难以适用。现有方法在特征检测一致性或推理时间方面存在不足。

Method: 通过共享编码统一检测关键点和轴边缘，在单次推理中同时检测两者，使用大规模合成数据和投影标注进行训练，利用投影几何实现高效姿态估计。

Result: 在特征检测和姿态估计方面均表现出色，在具有挑战性的手术环境中实现了快速性能和最先进的精度。

Conclusion: 该框架在微创手术机器人相机-机器人标定中实现了高效准确的特征检测和姿态估计，适用于在线机器人控制。

Abstract: Accurate camera-to-robot calibration is essential for any vision-based
robotic control system and especially critical in minimally invasive surgical
robots, where instruments conduct precise micro-manipulations. However, MIS
robots have long kinematic chains and partial visibility of their degrees of
freedom in the camera, which introduces challenges for conventional
camera-to-robot calibration methods that assume stiff robots with good
visibility. Previous works have investigated both keypoint-based and
rendering-based approaches to address this challenge in real-world conditions;
however, they often struggle with consistent feature detection or have long
inference times, neither of which are ideal for online robot control. In this
work, we propose a novel framework that unifies the detection of geometric
primitives (keypoints and shaft edges) through a shared encoding, enabling
efficient pose estimation via projection geometry. This architecture detects
both keypoints and edges in a single inference and is trained on large-scale
synthetic data with projective labeling. This method is evaluated across both
feature detection and pose estimation, with qualitative and quantitative
results demonstrating fast performance and state-of-the-art accuracy in
challenging surgical environments.

</details>


### [11] [Shape-Space Graphs: Fast and Collision-Free Path Planning for Soft Robots](https://arxiv.org/abs/2510.03547)
*Carina Veil,Moritz Flaschel,Ellen Kuhl*

Main category: cs.RO

TL;DR: 提出了一种基于图搜索的软体机器人路径规划方法，通过预计算形状库和构建k近邻图，实现快速避障和能量高效的运动规划。


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有非凡的灵活性，但在杂乱环境中的运动规划仍然是一个挑战，因为其高度非线性和无限维的运动学特性。

Method: 使用受形态弹性和主动细丝理论启发的生物力学模型，预计算形状库并在形状空间中构建k近邻图，利用符号距离函数修剪与障碍物碰撞的节点和边，定义基于几何距离和驱动力的多目标边成本。

Result: 算法能够在毫秒级时间内从预计算图中可靠地避开障碍物并生成可行路径，包含能量成本可以显著减少驱动力，但代价是更长的末端轨迹。

Conclusion: 形状空间图搜索在软体机器人领域具有快速可靠路径规划的潜力，为手术、工业和辅助环境中的实时应用铺平了道路。

Abstract: Soft robots, inspired by elephant trunks or octopus arms, offer extraordinary
flexibility to bend, twist, and elongate in ways that rigid robots cannot.
However, their motion planning remains a challenge, especially in cluttered
environments with obstacles, due to their highly nonlinear and
infinite-dimensional kinematics. Here, we present a graph-based path planning
tool for an elephant-trunk-inspired soft robotic arm designed with three
artificial muscle fibers that allow for multimodal continuous deformation
through contraction. Using a biomechanical model inspired by morphoelasticity
and active filament theory, we precompute a shape library and construct a
$k$-nearest neighbor graph in \emph{shape space}, ensuring that each node
corresponds to a mechanically accurate and physically valid robot shape. For
the graph, we use signed distance functions to prune nodes and edges colliding
with obstacles, and define multi-objective edge costs based on geometric
distance and actuation effort, enabling energy-efficient planning with
collision avoidance. We demonstrate that our algorithm reliably avoids
obstacles and generates feasible paths within milliseconds from precomputed
graphs using Dijkstra's algorithm. We show that including energy costs can
drastically reduce the actuation effort compared to geometry-only planning, at
the expense of longer tip trajectories. Our results highlight the potential of
shape-space graph search for fast and reliable path planning in the field of
soft robotics, paving the way for real-time applications in surgical,
industrial, and assistive settings.

</details>


### [12] [Learning to Act Through Contact: A Unified View of Multi-Task Robot Learning](https://arxiv.org/abs/2510.03599)
*Shafeef Omar,Majid Khadiv*

Main category: cs.RO

TL;DR: 提出了一种基于接触显式表示的统一多任务运动与操作策略学习框架，通过接触目标序列定义任务，实现单一策略执行多种接触密集型任务。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要为不同任务设计不同策略，缺乏统一框架。本文旨在利用接触丰富的任务间的共享结构，实现单一策略的多任务执行能力。

Method: 使用接触目标序列（期望接触位置、时间和活动末端执行器）统一任务定义，训练目标条件强化学习策略来实现给定的接触计划。

Result: 在多种机器人形态和任务上验证：四足机器人多种步态、人形机器人双足和四足步态、人形机器人双手物体操作任务，均通过单一策略控制，表现出多功能和鲁棒行为。

Conclusion: 显式接触推理显著提高了对未见场景的泛化能力，接触显式策略学习为可扩展的运动操作提供了有前景的基础。

Abstract: We present a unified framework for multi-task locomotion and manipulation
policy learning grounded in a contact-explicit representation. Instead of
designing different policies for different tasks, our approach unifies the
definition of a task through a sequence of contact goals-desired contact
positions, timings, and active end-effectors. This enables leveraging the
shared structure across diverse contact-rich tasks, leading to a single policy
that can perform a wide range of tasks. In particular, we train a
goal-conditioned reinforcement learning (RL) policy to realise given contact
plans. We validate our framework on multiple robotic embodiments and tasks: a
quadruped performing multiple gaits, a humanoid performing multiple biped and
quadrupedal gaits, and a humanoid executing different bimanual object
manipulation tasks. Each of these scenarios is controlled by a single policy
trained to execute different tasks grounded in contacts, demonstrating
versatile and robust behaviours across morphologically distinct systems. Our
results show that explicit contact reasoning significantly improves
generalisation to unseen scenarios, positioning contact-explicit policy
learning as a promising foundation for scalable loco-manipulation.

</details>


### [13] [Safety-Oriented Dynamic Path Planning for Automated Vehicles](https://arxiv.org/abs/2510.03640)
*Mostafa Emam,Matthias Gerdts*

Main category: cs.RO

TL;DR: 提出了一种双层控制框架，通过结合障碍物移动的时间相关网格投影来增强道路边界，实现精确的自适应路径规划。主控制回路使用非线性模型预测控制进行实时路径优化，备用回路提供安全回退轨迹。


<details>
  <summary>Details</summary>
Motivation: 确保自动驾驶车辆在动态环境中的安全性，需要先进的路径规划和障碍物避让能力。

Method: 采用双层控制框架：主控制回路使用非线性模型预测控制(NMPC)进行实时路径优化，并采用同伦约束松弛提高最优控制问题的可解性；同时运行独立的备用回路，在主回路无法在关键时间帧内计算最优轨迹时提供安全回退轨迹。

Result: 评估显示该方法在各种驾驶场景中具有优势，突出了实时适用性和鲁棒性。

Conclusion: 该框架代表了在复杂动态环境中实现更安全可靠自动驾驶的重要进展。

Abstract: Ensuring safety in autonomous vehicles necessitates advanced path planning
and obstacle avoidance capabilities, particularly in dynamic environments. This
paper introduces a bi-level control framework that efficiently augments road
boundaries by incorporating time-dependent grid projections of obstacle
movements, thus enabling precise and adaptive path planning. The main control
loop utilizes Nonlinear Model Predictive Control (NMPC) for real-time path
optimization, wherein homotopy-based constraint relaxation is employed to
improve the solvability of the optimal control problem (OCP). Furthermore, an
independent backup loop runs concurrently to provide safe fallback trajectories
when an optimal trajectory cannot be computed by the main loop within a
critical time frame, thus enhancing safety and real-time performance. Our
evaluation showcases the benefits of the proposed methods in various driving
scenarios, highlighting the real-time applicability and robustness of our
approach. Overall, the framework represents a significant step towards safer
and more reliable autonomous driving in complex and dynamic environments.

</details>


### [14] [Geometrically Exact Hard Magneto-Elastic Cosserat Shells: Static Formulation for Shape Morphing](https://arxiv.org/abs/2510.03644)
*Mohammadjavad Javadi,Robin Chhabra*

Main category: cs.RO

TL;DR: 开发了一种基于Cosserat壳理论的硬磁壳静态模型，适用于宽长比较大的软磁机器人，采用SE(3)群上的坐标无关方法，避免了传统壳模型中的奇点和锁定问题。


<details>
  <summary>Details</summary>
Motivation: 现有的Cosserat杆理论主要适用于1D细长结构，但许多软机器人具有较大的宽长比，属于2D壳结构，需要更合适的建模方法。

Method: 基于SE(3)特殊欧几里得群上的Cosserat壳理论，将壳视为具有六个自由度的2D流形，推导了平衡方程的强形式和弱形式，并提取线性化版本用于有限元实现。

Result: 模型通过一系列测试案例进行了分析和实验验证，在壳经历严重旋转和位移时表现出优越的有效性。

Conclusion: 提出的坐标无关Cosserat壳模型为硬磁壳结构提供了一种高效的建模方法，特别适用于大变形情况，克服了传统壳模型的数值问题。

Abstract: Cosserat rod theory is the popular approach to modeling ferromagnetic soft
robots as 1-Dimensional (1D) slender structures in most applications, such as
biomedical. However, recent soft robots designed for locomotion and
manipulation often exhibit a large width-to-length ratio that categorizes them
as 2D shells. For analysis and shape-morphing control purposes, we develop an
efficient coordinate-free static model of hard-magnetic shells found in soft
magnetic grippers and walking soft robots. The approach is based on a novel
formulation of Cosserat shell theory on the Special Euclidean group
($\mathbf{SE}(3)$). The shell is assumed to be a 2D manifold of material points
with six degrees of freedom (position & rotation) suitable for capturing the
behavior of a uniformly distributed array of spheroidal hard magnetic particles
embedded in the rheological elastomer. The shell's configuration manifold is
the space of all smooth embeddings $\mathbb{R}^2\rightarrow\mathbf{SE}(3)$.
According to a novel definition of local deformation gradient based on the Lie
group structure of $\mathbf{SE}(3)$, we derive the strong and weak forms of
equilibrium equations, following the principle of virtual work. We extract the
linearized version of the weak form for numerical implementations. The
resulting finite element approach can avoid well-known challenges such as
singularity and locking phenomenon in modeling shell structures. The proposed
model is analytically and experimentally validated through a series of test
cases that demonstrate its superior efficacy, particularly when the shell
undergoes severe rotations and displacements.

</details>


### [15] [An Amphibious Untethered Inchworm Soft Robot for Fast Crawling Locomotion](https://arxiv.org/abs/2510.03660)
*Mohammadjavad Javadi,Charlie Wadds,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出了一种受尺蠖启发的完全无束缚软体机器人，采用磁性驱动，具备多模态运动能力，包括行走、转向、游泳和负载运输，无需外部基础设施支持。


<details>
  <summary>Details</summary>
Motivation: 开发无束缚软体机器人对于推进软体机器人系统在多样化、多任务环境中的实际部署至关重要，旨在摆脱对外部基础设施的依赖。

Method: 设计具有弯曲柔性结构的磁性驱动软体机器人，配备紧凑轻量化的板载控制电路实现无线指令传输，集成摄像头进行环境感知，通过结构优化和系统级集成实现多功能。

Result: 机器人总质量102.63克，最大行走速度3.74 cm/s，游泳速度0.82 cm/s，成功展示了行走、转向、游泳和负载运输等多种功能。

Conclusion: 该研究通过系统级集成和结构优化，成功开发出具备多模态运动能力的完全无束缚软体机器人，为软体机器人在实际环境中的应用提供了可行方案。

Abstract: Untethered soft robots are essential for advancing the real-world deployment
of soft robotic systems in diverse and multitasking environments. Inspired by
soft-bodied inchworm, we present a fully untethered soft robot with a curved,
flexible structure actuated by magnetic forces. The robot has a total mass of
102.63 g and demonstrates multimodal locomotion, achieving a maximum walking
speed of 3.74 cm/s and a swimming speed of 0.82 cm/s. A compact and lightweight
onboard control circuit enables wireless command transmission, while an
integrated camera provides environmental perception. Through structural
optimization and system-level integration, the robot successfully performs
walking, steering, swimming, and payload transport without reliance on external
infrastructure. The robot's dynamic performance and locomotion capabilities are
systematically validated through experimental characterization.

</details>


### [16] [Robust Visual Embodiment: How Robots Discover Their Bodies in Real Environments](https://arxiv.org/abs/2510.03677)
*Salim Rezvani,Ammar Jaleel Mahmood,Robin Chhabra*

Main category: cs.RO

TL;DR: 该论文研究了视觉退化对机器人自建模的影响，并提出了一种结合经典修复和形态保持约束的任务感知去噪框架，显著提升了自建模在噪声和杂乱背景下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自主建模管道在真实感知条件（如噪声图像和杂乱背景）下表现脆弱，限制了具有内部视觉自模型的机器人在不可预测现实环境中的适应性。

Method: 引入任务感知去噪框架，结合经典修复方法和形态保持约束，确保保留对自建模至关重要的结构线索；同时集成语义分割以从杂乱场景中鲁棒地分离机器人。

Result: 在仿真和物理实验中，该方法恢复了接近基线的性能，而现有管道性能显著下降；在形态预测、轨迹规划和损伤恢复等任务中表现出色。

Conclusion: 这些贡献推进了视觉自建模的鲁棒性，为在不可预测现实环境中部署自感知机器人建立了实用基础。

Abstract: Robots with internal visual self-models promise unprecedented adaptability,
yet existing autonomous modeling pipelines remain fragile under realistic
sensing conditions such as noisy imagery and cluttered backgrounds. This paper
presents the first systematic study quantifying how visual
degradations--including blur, salt-and-pepper noise, and Gaussian noise--affect
robotic self-modeling. Through both simulation and physical experiments, we
demonstrate their impact on morphology prediction, trajectory planning, and
damage recovery in state-of-the-art pipelines. To overcome these challenges, we
introduce a task-aware denoising framework that couples classical restoration
with morphology-preserving constraints, ensuring retention of structural cues
critical for self-modeling. In addition, we integrate semantic segmentation to
robustly isolate robots from cluttered and colorful scenes. Extensive
experiments show that our approach restores near-baseline performance across
simulated and physical platforms, while existing pipelines degrade
significantly. These contributions advance the robustness of visual
self-modeling and establish practical foundations for deploying self-aware
robots in unpredictable real-world environments.

</details>


### [17] [EmbodiSwap for Zero-Shot Robot Imitation Learning](https://arxiv.org/abs/2510.03706)
*Eadom Dessalene,Pavan Mantripragada,Michael Maynord,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: EmbodiSwap是一种在人类视频上生成逼真合成机器人覆盖的方法，用于零样本模仿学习，弥合了野外人类视频与目标机器人具身之间的差距。


<details>
  <summary>Details</summary>
Motivation: 解决在野外人类视频与目标机器人具身之间的具身差距问题，实现零样本模仿学习。

Method: 使用EmbodiSwap方法在人类视频上生成合成机器人覆盖，并采用V-JEPA作为视觉骨干网络，将其从视频理解领域重新用于合成机器人视频的模仿学习。

Result: 在真实世界测试中，零样本训练的V-JEPA模型达到82%的成功率，优于少样本训练的π₀网络以及使用EmbodiSwap数据训练的π₀网络。

Conclusion: EmbodiSwap方法结合V-JEPA视觉骨干在机器人模仿学习中表现出色，为机器人学习提供了有效的零样本解决方案。

Abstract: We introduce EmbodiSwap - a method for producing photorealistic synthetic
robot overlays over human video. We employ EmbodiSwap for zero-shot imitation
learning, bridging the embodiment gap between in-the-wild ego-centric human
video and a target robot embodiment. We train a closed-loop robot manipulation
policy over the data produced by EmbodiSwap. We make novel use of V-JEPA as a
visual backbone, repurposing V-JEPA from the domain of video understanding to
imitation learning over synthetic robot videos. Adoption of V-JEPA outperforms
alternative vision backbones more conventionally used within robotics. In
real-world tests, our zero-shot trained V-JEPA model achieves an $82\%$ success
rate, outperforming a few-shot trained $\pi_0$ network as well as $\pi_0$
trained over data produced by EmbodiSwap. We release (i) code for generating
the synthetic robot overlays which takes as input human videos and an arbitrary
robot URDF and generates a robot dataset, (ii) the robot dataset we synthesize
over EPIC-Kitchens, HOI4D and Ego4D, and (iii) model checkpoints and inference
code, to facilitate reproducible research and broader adoption.

</details>


### [18] [Model-Based Adaptive Precision Control for Tabletop Planar Pushing Under Uncertain Dynamics](https://arxiv.org/abs/2510.03768)
*Aydin Ahmadi,Baris Akgun*

Main category: cs.RO

TL;DR: 提出了一种基于模型的桌面非抓取推动框架，使用单一学习模型处理多种任务而无需重新训练，结合GRU架构和MPPI控制器实现自适应控制。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的平面推动方法能力有限，通常只针对特定任务（如侧边切换、精确定位等），限制了更广泛的应用。需要开发能够处理多种任务且无需重新训练的通用框架。

Method: 采用循环GRU架构配合非线性层捕捉物体-环境动力学，使用定制化的状态-动作表示实现泛化。将学习到的动力学模型与基于采样的MPPI控制器集成，生成自适应、面向任务的动作。

Result: 在仿真和真实世界实验中展示了高精确定位成功率、强大的轨迹跟踪和避障性能。通过改变控制器目标函数即可解决多种任务，无需重新训练模型。

Conclusion: 该框架成功实现了单一模型处理多种推动任务的能力，支持侧边切换、变长推动等复杂操作，具有良好的泛化性和实际应用价值。

Abstract: Data-driven planar pushing methods have recently gained attention as they
reduce manual engineering effort and improve generalization compared to
analytical approaches. However, most prior work targets narrow capabilities
(e.g., side switching, precision, or single-task training), limiting broader
applicability. We present a model-based framework for non-prehensile tabletop
pushing that uses a single learned model to address multiple tasks without
retraining. Our approach employs a recurrent GRU-based architecture with
additional non-linear layers to capture object-environment dynamics while
ensuring stability. A tailored state-action representation enables the model to
generalize across uncertain dynamics, variable push lengths, and diverse tasks.
For control, we integrate the learned dynamics with a sampling-based Model
Predictive Path Integral (MPPI) controller, which generates adaptive,
task-oriented actions. This framework supports side switching, variable-length
pushes, and objectives such as precise positioning, trajectory following, and
obstacle avoidance. Training is performed in simulation with domain
randomization to support sim-to-real transfer. We first evaluate the
architecture through ablation studies, showing improved prediction accuracy and
stable rollouts. We then validate the full system in simulation and real-world
experiments using a Franka Panda robot with markerless tracking. Results
demonstrate high success rates in precise positioning under strict thresholds
and strong performance in trajectory tracking and obstacle avoidance. Moreover,
multiple tasks are solved simply by changing the controller's objective
function, without retraining. While our current focus is on a single object
type, we extend the framework by training on wider push lengths and designing a
balanced controller that reduces the number of steps for longer-horizon goals.

</details>


### [19] [Trajectory prediction for heterogeneous agents: A performance analysis on small and imbalanced datasets](https://arxiv.org/abs/2510.03776)
*Tiago Rodrigues de Almeida,Yufei Zhu,Andrey Rudenko,Tomasz P. Kucner,Johannes A. Stork,Martin Magnusson,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 该论文研究了类别条件轨迹预测方法，发现在考虑类别标签时能提高预测准确性，特别是在数据不平衡或新环境数据有限的情况下，基于模式的方法可能优于深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 在复杂动态环境中，机器人需要预测周围智能体的未来动作和意图以实现高效导航和避碰。由于智能体的动态特性取决于其任务、角色或可观察标签，类别条件运动预测成为减少预测不确定性和提高异质智能体预测准确性的有吸引力的方法。

Method: 提出了基于条件模式的高效深度学习基线方法，并在机器人学和室外数据集（THÖR-MAGNI和斯坦福无人机数据集）上评估了不同类别条件轨迹预测方法的性能。

Result: 实验表明，在考虑类别标签时，所有方法在大多数设置下都能提高准确性。更重要的是，在从不平衡数据集学习或在新环境中数据不足时存在显著差异。深度学习在平衡数据集上表现更好，但在数据有限的应用中，基于模式的方法可能更优。

Conclusion: 类别条件轨迹预测能有效提高预测准确性，特别是在数据不平衡或新环境数据有限的情况下。深度学习适合平衡数据集，而基于模式的方法在数据有限场景（如机器人新环境冷启动或类别不平衡）中更具优势。

Abstract: Robots and other intelligent systems navigating in complex dynamic
environments should predict future actions and intentions of surrounding agents
to reach their goals efficiently and avoid collisions. The dynamics of those
agents strongly depends on their tasks, roles, or observable labels.
Class-conditioned motion prediction is thus an appealing way to reduce forecast
uncertainty and get more accurate predictions for heterogeneous agents.
However, this is hardly explored in the prior art, especially for mobile robots
and in limited data applications. In this paper, we analyse different
class-conditioned trajectory prediction methods on two datasets. We propose a
set of conditional pattern-based and efficient deep learning-based baselines,
and evaluate their performance on robotics and outdoors datasets (TH\"OR-MAGNI
and Stanford Drone Dataset). Our experiments show that all methods improve
accuracy in most of the settings when considering class labels. More
importantly, we observe that there are significant differences when learning
from imbalanced datasets, or in new environments where sufficient data is not
available. In particular, we find that deep learning methods perform better on
balanced datasets, but in applications with limited data, e.g., cold start of a
robot in a new environment, or imbalanced classes, pattern-based methods may be
preferable.

</details>


### [20] [COVER:COverage-VErified Roadmaps for Fixed-time Motion Planning in Continuous Semi-Static Environments](https://arxiv.org/abs/2510.03875)
*Niranjan Kumar Ilampooranan,Constantinos Chamzas*

Main category: cs.RO

TL;DR: COVER是一个用于半静态环境运动规划的框架，通过构建覆盖验证路线图来保证固定时间内的查询响应。


<details>
  <summary>Details</summary>
Motivation: 解决半静态环境中固定时间运动规划问题，现有方法缺乏形式化保证或依赖限制性离散化，限制了实际应用。

Method: 通过划分障碍物配置空间并在每个分区内求解可行路径，系统性地验证路线图在每个分区中的可行性。

Result: 在7自由度Panda机器人模拟实验中，COVER比现有方法实现了更广泛的覆盖范围和更高的查询成功率。

Conclusion: COVER框架能够为半静态环境提供更强的运动规划保证，比现有方法表现更优。

Abstract: Having the ability to answer motion-planning queries within a fixed time
budget is critical for the widespread deployment of robotic systems.
Semi-static environments, where most obstacles remain static but a limited set
can vary across queries, exhibit structured variability that can be
systematically exploited to provide stronger guarantees than in general
motion-planning problems. However, prior approaches in this setting either lack
formal guarantees or rely on restrictive discretizations of obstacle
configurations, limiting their applicability in realistic domains. This paper
introduces COVER, a novel framework that incrementally constructs a
coverage-verified roadmap in semi-static environments. By partitioning the
obstacle configuration space and solving for feasible paths within each
partition, COVER systematically verifies feasibility of the roadmap in each
partition and guarantees fixed-time motion planning queries within the verified
regions. We validate COVER with a 7-DOF simulated Panda robot performing table
and shelf tasks, demonstrating that COVER achieves broader coverage with higher
query success rates than prior works.

</details>


### [21] [Seeing the Bigger Picture: 3D Latent Mapping for Mobile Manipulation Policy Learning](https://arxiv.org/abs/2510.03885)
*Sunghwan Kim,Woojeh Chung,Zhirui Dai,Dwait Bhatt,Arth Shukla,Hao Su,Yulun Tian,Nikolay Atanasov*

Main category: cs.RO

TL;DR: SBP是一种端到端的移动操作策略学习方法，使用3D潜在地图进行空间和时间推理，相比仅依赖图像的策略表现更好。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的策略在空间和时间推理方面存在局限，需要一种能超越当前视野并聚合长期观察的方法。

Method: 通过增量融合多视角观察构建场景特定的3D潜在特征网格，使用预训练解码器重构目标嵌入，并采用3D特征聚合器获取全局上下文。

Result: SBP在场景级移动操作和顺序桌面操作任务中表现优异，相比图像策略在分布内和新场景中成功率提升25%。

Conclusion: 3D潜在地图策略能实现全局场景推理、长期记忆利用，在移动操作任务中显著优于纯图像方法。

Abstract: In this paper, we demonstrate that mobile manipulation policies utilizing a
3D latent map achieve stronger spatial and temporal reasoning than policies
relying solely on images. We introduce Seeing the Bigger Picture (SBP), an
end-to-end policy learning approach that operates directly on a 3D map of
latent features. In SBP, the map extends perception beyond the robot's current
field of view and aggregates observations over long horizons. Our mapping
approach incrementally fuses multiview observations into a grid of
scene-specific latent features. A pre-trained, scene-agnostic decoder
reconstructs target embeddings from these features and enables online
optimization of the map features during task execution. A policy, trainable
with behavior cloning or reinforcement learning, treats the latent map as a
state variable and uses global context from the map obtained via a 3D feature
aggregator. We evaluate SBP on scene-level mobile manipulation and sequential
tabletop manipulation tasks. Our experiments demonstrate that SBP (i) reasons
globally over the scene, (ii) leverages the map as long-horizon memory, and
(iii) outperforms image-based policies in both in-distribution and novel
scenes, e.g., improving the success rate by 25% for the sequential manipulation
task.

</details>


### [22] [NoTVLA: Narrowing of Dense Action Trajectories for Generalizable Robot Manipulation](https://arxiv.org/abs/2510.03895)
*Zheng Huang,Mingyu Liu,Xiaoyi Lin,Muzhi Zhu,Canyu Zhao,Zongze Du,Xiaoman Li,Yiduo Jia,Hao Zhong,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: 提出了NoTVLA框架，通过关注稀疏轨迹而非密集动作序列来解决VLA模型的灾难性遗忘问题，在计算效率和多任务泛化方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型在现实部署中面临的灾难性遗忘问题，该问题源于对连续动作序列的过度依赖导致的知识隔离。

Method: 采用轨迹规划策略，聚焦机器人末端执行器的稀疏轨迹而非目标物体轨迹，通过时间压缩和空间推理剪枝，使用稀疏轨迹进行训练。

Result: 在多任务评估中，NoTVLA相比pi0表现更优，计算资源节省超过一个数量级，无需腕部摄像头，操作精度接近单任务专家模型。

Conclusion: NoTVLA能有效避免灾难性遗忘，保持语言能力，支持跨机器人平台统一部署，并在新视角任务中展现泛化能力。

Abstract: Vision-Language-Action (VLA) models represent a pivotal advance in embodied
intelligence, yet they confront critical barriers to real-world deployment,
most notably catastrophic forgetting. This issue stems from their overreliance
on continuous action sequences or action chunks, which inadvertently create
isolated data silos that disrupt knowledge retention across tasks. To tackle
these challenges, we propose the Narrowing of Trajectory VLA (NoTVLA)
framework: a novel approach that narrows its focus to sparse trajectories,
thereby avoiding the catastrophic forgetting associated with dense trajectory
fine-tuning. A key innovation of NoTVLA lies in its trajectory planning
strategy: instead of centering on the target object's trajectory, it leverages
temporal compression and spatial reasoning pruning specifically for the robot
end effector's trajectory. Furthermore, training is conducted using these
sparse trajectories rather than dense action trajectories, an optimization that
delivers remarkable practical advantages with better performance in zero-shot.
In multi-task evaluation scenarios, NoTVLA achieves superior performance and
generalization compared to pi0 while operating under two critical constraints:
it uses over an order of magnitude less computing power than pi0 and requires
no wrist-mounted camera. This design ensures that NoTVLA's operational accuracy
closely approximates that of single-task expert models. Crucially, it also
preserves the model's inherent language capabilities, enabling zero-shot
generalization in specific scenarios, supporting unified model deployment
across multiple robot platforms, and fostering a degree of generalization even
when perceiving tasks from novel perspectives.

</details>


### [23] [WAFFLE: A Wearable Approach to Bite Timing Estimation in Robot-Assisted Feeding](https://arxiv.org/abs/2510.03910)
*Akhil Padmanabha,Jessie Yuan,Tanisha Mehta,Rajat Kumar Jenamani,Eric Hu,Victoria de León,Anthony Wertz,Janavi Gupta,Ben Dodson,Yunting Yan,Carmel Majidi,Tapomayukh Bhattacharjee,Zackory Erickson*

Main category: cs.RO

TL;DR: WAFFLE是一个基于可穿戴传感器的喂食系统，通过机器学习预测咬合时机，提高机器人喂食的自然性和反应性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人喂食系统中咬合时机估计的技术挑战，增强用户自主性和生活质量，减轻护理人员负担。

Method: 使用可穿戴传感器数据训练监督回归模型，结合用户可调节的自信度阈值来预测咬合时机。

Result: 在15名无运动障碍参与者研究中，WAFFLE在控制感、机器人理解和工作量方面表现优于基线方法，并在2名运动障碍参与者的家庭环境中验证了通用性。

Conclusion: WAFFLE能够实现自然、反应灵敏的咬合时机预测，适用于不同用户、机器人硬件、环境和用餐场景。

Abstract: Millions of people around the world need assistance with feeding. Robotic
feeding systems offer the potential to enhance autonomy and quality of life for
individuals with impairments and reduce caregiver workload. However, their
widespread adoption has been limited by technical challenges such as estimating
bite timing, the appropriate moment for the robot to transfer food to a user's
mouth. In this work, we introduce WAFFLE: Wearable Approach For Feeding with
LEarned bite timing, a system that accurately predicts bite timing by
leveraging wearable sensor data to be highly reactive to natural user cues such
as head movements, chewing, and talking. We train a supervised regression model
on bite timing data from 14 participants and incorporate a user-adjustable
assertiveness threshold to convert predictions into proceed or stop commands.
In a study with 15 participants without motor impairments with the Obi feeding
robot, WAFFLE performs statistically on par with or better than baseline
methods across measures of feeling of control, robot understanding, and
workload, and is preferred by the majority of participants for both individual
and social dining. We further demonstrate WAFFLE's generalizability in a study
with 2 participants with motor impairments in their home environments using a
Kinova 7DOF robot. Our findings support WAFFLE's effectiveness in enabling
natural, reactive bite timing that generalizes across users, robot hardware,
robot positioning, feeding trajectories, foods, and both individual and social
dining contexts.

</details>


### [24] [TCB-VIO: Tightly-Coupled Focal-Plane Binary-Enhanced Visual Inertial Odometry](https://arxiv.org/abs/2510.03919)
*Matthew Lisondra,Junseo Kim,Glenn Takashi Shimoda,Kourosh Zareinia,Sajad Saeedi*

Main category: cs.RO

TL;DR: TCB-VIO是一种在焦平面传感器处理器阵列上实现的紧密耦合6自由度视觉惯性里程计，通过多状态约束卡尔曼滤波器在250FPS高帧率下运行，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统视觉惯性里程计存在空间漂移（视觉位姿估计）和时间漂移（惯性测量）问题，FPSP通过高帧率运行来匹配惯性测量的高频输出，从而规避空间漂移。

Method: 使用多状态约束卡尔曼滤波器实现紧密耦合的6自由度视觉惯性里程计，在焦平面传感器处理器阵列上以250FPS高帧率运行，IMU测量频率为400Hz。

Result: TCB-VIO在性能上超越了当前最先进的方法：ROVIO、VINS-Mono和ORB-SLAM3。

Conclusion: 在FPSP上实现高帧率视觉惯性里程计能有效解决空间漂移问题，TCB-VIO展示了优越的性能表现。

Abstract: Vision algorithms can be executed directly on the image sensor when
implemented on the next-generation sensors known as focal-plane
sensor-processor arrays (FPSP)s, where every pixel has a processor. FPSPs
greatly improve latency, reducing the problems associated with the bottleneck
of data transfer from a vision sensor to a processor. FPSPs accelerate
vision-based algorithms such as visual-inertial odometry (VIO). However, VIO
frameworks suffer from spatial drift due to the vision-based pose estimation,
whilst temporal drift arises from the inertial measurements. FPSPs circumvent
the spatial drift by operating at a high frame rate to match the high-frequency
output of the inertial measurements. In this paper, we present TCB-VIO, a
tightly-coupled 6 degrees-of-freedom VIO by a Multi-State Constraint Kalman
Filter (MSCKF), operating at a high frame-rate of 250 FPS and from IMU
measurements obtained at 400 Hz. TCB-VIO outperforms state-of-the-art methods:
ROVIO, VINS-Mono, and ORB-SLAM3.

</details>


### [25] [A Real-Time Framework for Intermediate Map Construction and Kinematically Feasible Off-Road Planning Without OSM](https://arxiv.org/abs/2510.03948)
*Otobong Jerome,Geesara Prathap Kulathunga,Devitt Dmitry,Eugene Murawjow,Alexandr Klimchik*

Main category: cs.RO

TL;DR: 提出了一种专为越野环境设计的全局路径规划方法，通过构建包含地理特征的中间地图，将规划问题分解为图路径规划、运动学可行性检查和路径平滑三个子问题，实现了实时性能、运动学可行性和内存效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统全局路径规划方法在越野环境中表现不佳，无法处理大规模地图，且忽略了实时性能、运动学可行性和内存效率等关键因素。

Method: 在像素坐标系中构建包含越野路径、水域、限制区域和树木等地理特征的中间地图，将规划问题分解为图路径规划、运动学可行性检查和路径平滑三个子问题。

Result: 在多个越野环境和大规模地图（达数平方公里）中测试，平均1.5秒内找到可行路径，极端条件下仅使用约1.5GB内存。

Conclusion: 该框架具有通用性，适用于搜救任务、农业作业等多种越野自主导航任务。

Abstract: Off-road environments present unique challenges for autonomous navigation due
to their complex and unstructured nature. Traditional global path-planning
methods, which typically aim to minimize path length and travel time, perform
poorly on large-scale maps and fail to account for critical factors such as
real-time performance, kinematic feasibility, and memory efficiency. This paper
introduces a novel global path-planning method specifically designed for
off-road environments, addressing these essential factors. The method begins by
constructing an intermediate map within the pixel coordinate system,
incorporating geographical features like off-road trails, waterways, restricted
and passable areas, and trees. The planning problem is then divided into three
sub-problems: graph-based path planning, kinematic feasibility checking, and
path smoothing. This approach effectively meets real-time performance
requirements while ensuring kinematic feasibility and efficient memory use. The
method was tested in various off-road environments with large-scale maps up to
several square kilometers in size, successfully identifying feasible paths in
an average of 1.5 seconds and utilizing approximately 1.5GB of memory under
extreme conditions. The proposed framework is versatile and applicable to a
wide range of off-road autonomous navigation tasks, including search and rescue
missions and agricultural operations.

</details>


### [26] [SITCOM: Scaling Inference-Time COMpute for VLAs](https://arxiv.org/abs/2510.04041)
*Ayudh Saxena,Harsh Shah,Sandeep Routray,Rishi Rajesh Shah,Esha Pahwa*

Main category: cs.RO

TL;DR: SITCOM框架通过模型预测控制和奖励轨迹选择，将单步视觉语言动作模型增强为长时程规划器，显著提升任务完成率


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言动作模型缺乏前瞻机制，在动态任务中容易积累误差，难以处理长时程规划问题

Method: 使用学习到的动力学模型进行多步动作推演，基于模拟器奖励选择最佳候选计划，结合模型预测控制思想

Result: 在SIMPLER环境中，SITCOM将任务完成率从48%提升到72%

Conclusion: SITCOM框架能有效增强预训练VLA模型的规划能力，实现更鲁棒的机器人控制

Abstract: Learning robust robotic control policies remains a major challenge due to the
high cost of collecting labeled data, limited generalization to unseen
environments, and difficulties in planning over long horizons. While
Vision-Language-Action (VLA) models offer a promising solution by grounding
natural language instructions into single-step control commands, they often
lack mechanisms for lookahead and struggle with compounding errors in dynamic
tasks. In this project, we introduce Scaling Inference-Time COMpute for VLAs
(SITCOM), a framework that augments any pretrained VLA with model-based
rollouts and reward-based trajectory selection, inspired by Model Predictive
Control algorithm. SITCOM leverages a learned dynamics model to simulate
multi-step action rollouts to select the best candidate plan for real-world
execution, transforming one-shot VLAs into robust long-horizon planners. We
develop an efficient transformer-based dynamics model trained on large-scale
BridgeV2 data and fine-tuned on SIMPLER environments to bridge the Real2Sim
gap, and score candidate rollouts using rewards from simulator. Through
comprehensive evaluation across multiple tasks and settings in the SIMPLER
environment, we demonstrate that SITCOM when combined with a good reward
function can significantly improve task completion rate from 48% to 72% using
trained dynamics model.

</details>


### [27] [Feedback Matters: Augmenting Autonomous Dissection with Visual and Topological Feedback](https://arxiv.org/abs/2510.04074)
*Chung-Pang Wang,Changwei Chen,Xiao Liang,Soofiyan Atar,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 提出了一种用于自主组织解剖的反馈驱动框架，通过内窥镜图像推理拓扑变化，结合可见性度量和最优控制器设计，显著提升手术自主性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有手术机器人反馈机制在处理组织解剖的拓扑和感知挑战方面存在局限，需要能够适应动态手术环境的自适应系统。

Method: 开发了基于内窥镜图像的拓扑变化推理框架，引入组织暴露可见性度量，并设计主动操纵组织以最大化可见性的最优控制器。

Result: 实验证明该反馈机制显著增强了自主性，减少了错误，并在复杂手术场景中提高了系统的鲁棒性。

Conclusion: 反馈驱动的组织解剖框架通过在线适应和可见性优化，为自主手术系统提供了更可靠和自适应的解决方案。

Abstract: Autonomous surgical systems must adapt to highly dynamic environments where
tissue properties and visual cues evolve rapidly. Central to such adaptability
is feedback: the ability to sense, interpret, and respond to changes during
execution. While feedback mechanisms have been explored in surgical robotics,
ranging from tool and tissue tracking to error detection, existing methods
remain limited in handling the topological and perceptual challenges of tissue
dissection. In this work, we propose a feedback-enabled framework for
autonomous tissue dissection that explicitly reasons about topological changes
from endoscopic images after each dissection action. This structured feedback
guides subsequent actions, enabling the system to localize dissection progress
and adapt policies online. To improve the reliability of such feedback, we
introduce visibility metrics that quantify tissue exposure and formulate
optimal controller designs that actively manipulate tissue to maximize
visibility. Finally, we integrate these feedback mechanisms with both
planning-based and learning-based dissection methods, and demonstrate
experimentally that they significantly enhance autonomy, reduce errors, and
improve robustness in complex surgical scenarios.

</details>


### [28] [From Shadow to Light: Toward Safe and Efficient Policy Learning Across MPC, DeePC, RL, and LLM Agents](https://arxiv.org/abs/2510.04076)
*Amin Vahidi-Moghaddam,Sayed Pedram Haeri Boroujeni,Iman Jebellat,Ehsan Jebellat,Niloufar Mehrabi,Zhaojian Li*

Main category: cs.RO

TL;DR: 本文综述了现代控制应用中实现准确、快速和安全运动控制的挑战，介绍了MPC、ML-MPC、RL、DeePC和LLM代理等数据驱动方法，并提出了八种降低计算复杂度的技术。


<details>
  <summary>Details</summary>
Motivation: 解决数据驱动控制在实时系统中面临的计算复杂度高、响应慢和内存需求大的问题，使其更适用于动态快速、计算资源有限的现实系统。

Method: 提出了八种降低计算复杂度的技术，包括降阶建模、函数逼近策略学习和凸松弛等方法，并在机器人手臂、软机器人和车辆运动控制等实际应用中验证。

Result: 这些方法在真实应用中表现出有效性，能够显著降低计算负担，同时保持控制性能。

Conclusion: 通过提出的计算复杂度降低技术，数据驱动控制方法可以更好地应用于资源受限的现实系统，平衡了控制性能与计算效率的需求。

Abstract: One of the main challenges in modern control applications, particularly in
robot and vehicle motion control, is achieving accurate, fast, and safe
movement. To address this, optimal control policies have been developed to
enforce safety while ensuring high performance. Since basic first-principles
models of real systems are often available, model-based controllers are widely
used. Model predictive control (MPC) is a leading approach that optimizes
performance while explicitly handling safety constraints. However, obtaining
accurate models for complex systems is difficult, which motivates data-driven
alternatives. ML-based MPC leverages learned models to reduce reliance on
hand-crafted dynamics, while reinforcement learning (RL) can learn near-optimal
policies directly from interaction data. Data-enabled predictive control
(DeePC) goes further by bypassing modeling altogether, directly learning safe
policies from raw input-output data. Recently, large language model (LLM)
agents have also emerged, translating natural language instructions into
structured formulations of optimal control problems. Despite these advances,
data-driven policies face significant limitations. They often suffer from slow
response times, high computational demands, and large memory needs, making them
less practical for real-world systems with fast dynamics, limited onboard
computing, or strict memory constraints. To address this, various technique,
such as reduced-order modeling, function-approximated policy learning, and
convex relaxations, have been proposed to reduce computational complexity. In
this paper, we present eight such approaches and demonstrate their
effectiveness across real-world applications, including robotic arms, soft
robots, and vehicle motion control.

</details>


### [29] [HEHA: Hierarchical Planning for Heterogeneous Multi-Robot Exploration of Unknown Environments](https://arxiv.org/abs/2510.04161)
*Longrui Yang,Yiyu Wang,Jingfan Tang,Yunpeng Lv,Shizhe Zhao,Chao Cao,Zhongqiang Ren*

Main category: cs.RO

TL;DR: 提出HEHA方法解决多异构机器人自主探索未知环境的路径规划问题，通过分层规划和PEAF路由算法优化探索效率


<details>
  <summary>Details</summary>
Motivation: 解决多异构机器人（无人机、轮式、腿式机器人）在未知环境中探索时的智能分配问题，考虑不同机器人的地形通过能力约束

Method: 采用分层探索方法HEHA，包含全局规划和局部规划。全局规划使用PEAF（部分任意时间焦点搜索）路由算法快速找到有界次优解，局部规划考虑异构性避免重复探索

Result: 实验结果显示HEHA相比基线方法可减少高达30%的探索时间

Conclusion: HEHA方法能有效解决多异构机器人探索问题，通过分层规划和PEAF算法显著提升探索效率

Abstract: This paper considers the path planning problem for autonomous exploration of
an unknown environment using multiple heterogeneous robots such as drones,
wheeled, and legged robots, which have different capabilities to traverse
complex terrains. A key challenge there is to intelligently allocate the robots
to the unknown areas to be explored and determine the visiting order of those
spaces subject to traversablity constraints, which leads to a large scale
constrained optimization problem that needs to be quickly and iteratively
solved every time when new space are explored. To address the challenge, we
propose HEHA (Hierarchical Exploration with Heterogeneous Agents) by leveraging
a recent hierarchical method that decompose the exploration into global
planning and local planning. The major contribution in HEHA is its global
planning, where we propose a new routing algorithm PEAF (Partial Anytime Focal
search) that can quickly find bounded sub-optimal solutions to minimize the
maximum path length among the agents subject to traversability constraints.
Additionally, the local planner in HEHA also considers heterogeneity to avoid
repeated and duplicated exploration among the robots. The experimental results
show that, our HEHA can reduce up to 30% of the exploration time than the
baselines.

</details>


### [30] [Learning to Capture Rocks using an Excavator: A Reinforcement Learning Approach with Guiding Reward Formulation](https://arxiv.org/abs/2510.04168)
*Amirmasoud Molaei,Reza Ghabcheloo*

Main category: cs.RO

TL;DR: 本文提出了一个完全数据驱动的控制框架，用于挖掘机抓取岩石任务，使用无模型强化学习在模拟器中训练，无需显式建模岩石或土壤属性。


<details>
  <summary>Details</summary>
Motivation: 传统挖掘机抓取岩石需要熟练操作员，现有自主挖掘方法主要针对连续介质或依赖专用夹具，难以应用于真实建筑工地的非结构化环境。

Method: 使用AGX Dynamics模拟器，基于PPO算法训练强化学习智能体，通过广泛领域随机化增强鲁棒性，直接输出关节速度命令控制挖掘机。

Result: 学习到的策略在未见过的岩石和不同土壤条件下泛化良好，成功率与人类参与者相当，同时保持机器稳定性。

Conclusion: 证明了基于学习的方法可以在不需要专用硬件或详细材料模型的情况下，实现离散物体操作的可行性。

Abstract: Rock capturing with standard excavator buckets is a challenging task
typically requiring the expertise of skilled operators. Unlike soil digging, it
involves manipulating large, irregular rocks in unstructured environments where
complex contact interactions with granular material make model-based control
impractical. Existing autonomous excavation methods focus mainly on continuous
media or rely on specialized grippers, limiting their applicability to
real-world construction sites. This paper introduces a fully data-driven
control framework for rock capturing that eliminates the need for explicit
modeling of rock or soil properties. A model-free reinforcement learning agent
is trained in the AGX Dynamics simulator using the Proximal Policy Optimization
(PPO) algorithm and a guiding reward formulation. The learned policy outputs
joint velocity commands directly to the boom, arm, and bucket of a CAT365
excavator model. Robustness is enhanced through extensive domain randomization
of rock geometry, density, and mass, as well as the initial configurations of
the bucket, rock, and goal position. To the best of our knowledge, this is the
first study to develop and evaluate an RL-based controller for the rock
capturing task. Experimental results show that the policy generalizes well to
unseen rocks and varying soil conditions, achieving high success rates
comparable to those of human participants while maintaining machine stability.
These findings demonstrate the feasibility of learning-based excavation
strategies for discrete object manipulation without requiring specialized
hardware or detailed material models.

</details>


### [31] [VBM-NET: Visual Base Pose Learning for Mobile Manipulation using Equivariant TransporterNet and GNNs](https://arxiv.org/abs/2510.04171)
*Lakshadeep Naik,Adam Fischer,Daniel Duberg,Danica Kragic*

Main category: cs.RO

TL;DR: VBM-NET是一种基于学习的移动机器人基座姿态规划方法，使用俯视正交投影图像和强化学习来选择最优抓取基座姿态，在计算时间显著减少的同时达到与传统方法相当的性能。


<details>
  <summary>Details</summary>
Motivation: 移动操作中，选择最优的移动基座姿态对成功抓取物体至关重要。现有方法依赖可靠的状态信息（如精确物体位姿和环境模型），而本文研究直接从俯视正交投影图像进行基座姿态规划。

Method: 使用等变TransporterNet利用空间对称性高效学习候选基座姿态，然后使用图神经网络表示可变数量的候选姿态，通过强化学习从中选择最优基座姿态。

Result: VBM-NET在显著减少计算时间的同时，能够产生与传统方法相当的解决方案，并成功实现了从仿真到真实世界的策略迁移。

Conclusion: 该方法证明了直接从俯视正交投影图像进行基座姿态规划的有效性，为移动操作提供了高效且实用的解决方案。

Abstract: In Mobile Manipulation, selecting an optimal mobile base pose is essential
for successful object grasping. Previous works have addressed this problem
either through classical planning methods or by learning state-based policies.
They assume access to reliable state information, such as the precise object
poses and environment models. In this work, we study base pose planning
directly from top-down orthographic projections of the scene, which provide a
global overview of the scene while preserving spatial structure. We propose
VBM-NET, a learning-based method for base pose selection using such top-down
orthographic projections. We use equivariant TransporterNet to exploit spatial
symmetries and efficiently learn candidate base poses for grasping. Further, we
use graph neural networks to represent a varying number of candidate base poses
and use Reinforcement Learning to determine the optimal base pose among them.
We show that VBM-NET can produce comparable solutions to the classical methods
in significantly less computation time. Furthermore, we validate sim-to-real
transfer by successfully deploying a policy trained in simulation to real-world
mobile manipulation.

</details>


### [32] [Using Robotics to Improve Transcatheter Edge-to-Edge Repair of the Mitral Valve](https://arxiv.org/abs/2510.04178)
*Léa Pistorius,Namrata U. Nayar,Phillip Tran,Sammy Elmariah,Pierre E. Dupont*

Main category: cs.RO

TL;DR: 使用机器人系统替代传统手动导管系统进行二尖瓣边对边修复，通过游戏控制器实现直观控制，在心脏模型上验证了机器人系统能减少手术时间、运动误差并提高夹子放置精度。


<details>
  <summary>Details</summary>
Motivation: 传统经导管瓣膜修复手术存在机械限制和学习曲线陡峭的问题，需要更直观可靠的手术平台来改善手术效果。

Method: 将临床修复设备的复杂手柄控制替换为通过游戏控制器实现的机器人关节控制，在心脏和血管模型上分解设备输送任务为具体步骤，比较手动与机器人性能。

Result: 机器人系统能够减少手术时间和运动误差，同时提高夹子放置的准确性。

Conclusion: 机器人辅助能够解决手动系统的关键限制，为复杂经导管手术提供更可靠和用户友好的平台。

Abstract: Transcatheter valve repair presents significant challenges due to the
mechanical limitations and steep learning curve associated with manual catheter
systems. This paper investigates the use of robotics to facilitate
transcatheter procedures in the context of mitral valve edge-to-edge repair.
The complex handle-based control of a clinical repair device is replaced by
intuitive robotic joint-based control via a game controller. Manual versus
robotic performance is analyzed by decomposing the overall device delivery task
into motion-specific steps and comparing capabilities on a step-by-step basis
in a phantom model of the heart and vasculature. Metrics include procedure
duration and clip placement accuracy. Results demonstrate that the robotic
system can reduce procedural time and motion errors while also improving
accuracy of clip placement. These findings suggest that robotic assistance can
address key limitations of manual systems, offering a more reliable and
user-friendly platform for complex transcatheter procedures.

</details>


### [33] [Zenbo Patrol: A Social Assistive Robot Based on Multimodal Deep Learning for Real-time Illegal Parking Recognition and Notification](https://arxiv.org/abs/2510.04190)
*Jian-jie Zheng,Chih-kai Yang,Po-han Chen,Lyn Chao-ling Chen*

Main category: cs.RO

TL;DR: 该研究开发了一个使用社交机器人进行实时非法停车检测的系统，采用GPT-4o多模态模型识别车牌号码，并在检测到非法停车时通过Line消息通知系统管理员。


<details>
  <summary>Details</summary>
Motivation: 解决停车场非法停车问题，通过社交机器人提供实时监控和通知功能，提高停车管理的效率和自动化水平。

Method: 使用社交机器人作为巡逻员，在模拟停车场中导航并自动调整摄像头角度捕捉车牌图像。采用GPT-4o多模态模型直接识别车牌号码，无需预处理步骤。

Result: 开发了一个在室内停车场可应用的社交辅助机器人系统，验证了新颖的多模态深度学习方法在车牌识别方面具有高准确率。

Conclusion: 该工作成功验证了多模态深度学习方法在车牌识别中的有效性，并提供了一个可在真实场景中解决问题的社交辅助机器人系统，适用于室内停车场管理。

Abstract: In the study, the social robot act as a patrol to recognize and notify
illegal parking in real-time. Dual-model pipeline method and large multimodal
model were compared, and the GPT-4o multimodal model was adopted in license
plate recognition without preprocessing. For moving smoothly on a flat ground,
the robot navigated in a simulated parking lot in the experiments. The robot
changes angle view of the camera automatically to capture the images around
with the format of license plate number. From the captured images of the robot,
the numbers on the plate are recognized through the GPT-4o model, and
identifies legality of the numbers. When an illegal parking is detected, the
robot sends Line messages to the system manager immediately. The contribution
of the work is that a novel multimodal deep learning method has validated with
high accuracy in license plate recognition, and a social assistive robot is
also provided for solving problems in a real scenario, and can be applied in an
indoor parking lot.

</details>


### [34] [Flexible Locomotion Learning with Diffusion Model Predictive Control](https://arxiv.org/abs/2510.04234)
*Runhan Huang,Haldun Balim,Heng Yang,Yilun Du*

Main category: cs.RO

TL;DR: 提出了Diffusion-MPC方法，利用学习的生成扩散模型作为规划的动态先验，通过奖励和约束优化实现灵活测试时适应。


<details>
  <summary>Details</summary>
Motivation: 足式运动需要既鲁棒又适应的控制器，但无模型强化学习方法产生固定策略难以适应新行为，而传统MPC依赖准确动态模型在复杂环境中难以获得。

Method: 使用生成扩散模型作为近似动态先验进行规划，在反向步骤中结合奖励规划和约束投影，并通过交互式训练算法更新去噪器。

Result: 在真实世界中验证了强大的运动能力和灵活适应能力，能够适应新的奖励规范而无需重新训练。

Conclusion: Diffusion-MPC实现了强大的测试时适应性，允许规划器调整到新的奖励规范而无需重新训练。

Abstract: Legged locomotion demands controllers that are both robust and adaptable,
while remaining compatible with task and safety considerations. However,
model-free reinforcement learning (RL) methods often yield a fixed policy that
can be difficult to adapt to new behaviors at test time. In contrast, Model
Predictive Control (MPC) provides a natural approach to flexible behavior
synthesis by incorporating different objectives and constraints directly into
its optimization process. However, classical MPC relies on accurate dynamics
models, which are often difficult to obtain in complex environments and
typically require simplifying assumptions. We present Diffusion-MPC, which
leverages a learned generative diffusion model as an approximate dynamics prior
for planning, enabling flexible test-time adaptation through reward and
constraint based optimization. Diffusion-MPC jointly predicts future states and
actions; at each reverse step, we incorporate reward planning and impose
constraint projection, yielding trajectories that satisfy task objectives while
remaining within physical limits. To obtain a planning model that adapts beyond
imitation pretraining, we introduce an interactive training algorithm for
diffusion based planner: we execute our reward-and-constraint planner in
environment, then filter and reweight the collected trajectories by their
realized returns before updating the denoiser. Our design enables strong
test-time adaptability, allowing the planner to adjust to new reward
specifications without retraining. We validate Diffusion-MPC on real world,
demonstrating strong locomotion and flexible adaptation.

</details>


### [35] [ContextVLA: Vision-Language-Action Model with Amortized Multi-Frame Context](https://arxiv.org/abs/2510.04246)
*Huiwon Jang,Sihyun Yu,Heeseung Kwon,Hojin Jeon,Younggyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: ContextVLA是一个通过有效利用多帧观测来提升机器人任务性能的策略模型，通过将过去观测压缩为单个上下文token，在保持多帧训练优势的同时减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有行为克隆方法在使用多帧观测时性能提升不一致，而视觉-语言-动作模型(VLA)能更有效地利用多帧观测生成动作，但视频输入的高维度带来了显著的计算开销。

Method: 提出ContextVLA模型，将过去观测压缩为单个上下文token，使策略能够高效利用时间上下文生成动作，同时减少训练和推理时间。

Result: 实验表明ContextVLA相比单帧VLA持续改进性能，实现了完整多帧训练的优势，但训练和推理时间更短。

Conclusion: ContextVLA通过有效压缩多帧观测，在机器人任务中实现了稳健的性能提升，同时解决了VLA模型处理视频输入时的计算效率问题。

Abstract: Leveraging temporal context is crucial for success in partially observable
robotic tasks. However, prior work in behavior cloning has demonstrated
inconsistent performance gains when using multi-frame observations. In this
paper, we introduce ContextVLA, a policy model that robustly improves robotic
task performance by effectively leveraging multi-frame observations. Our
approach is motivated by the key observation that Vision-Language-Action models
(VLA), i.e., policy models built upon a Vision-Language Model (VLM), more
effectively utilize multi-frame observations for action generation. This
suggests that VLMs' inherent temporal understanding capability enables them to
extract more meaningful context from multi-frame observations. However, the
high dimensionality of video inputs introduces significant computational
overhead, making VLA training and inference inefficient. To address this,
ContextVLA compresses past observations into a single context token, allowing
the policy to efficiently leverage temporal context for action generation. Our
experiments show that ContextVLA consistently improves over single-frame VLAs
and achieves the benefits of full multi-frame training but with reduced
training and inference times.

</details>


### [36] [Integrated Planning and Control on Manifolds: Factor Graph Representation and Toolkit](https://arxiv.org/abs/2510.04278)
*Peiwen Yang,Weisong Wen,Runqiu Yang,Yuanyuan Zhang,Jiahao Hu,Yingming Chen,Naigui Xiao,Jiaqi Zhao*

Main category: cs.RO

TL;DR: FactorMPC：基于因子图的MPC工具包，在非线性流形上实现实时、安全的关键控制，支持流形值状态和高维系统。


<details>
  <summary>Details</summary>
Motivation: 传统MPC在处理非线性流形系统（如机器人姿态动力学）时面临奇异性、过参数化和收敛困难等问题，需要几何一致且高效的解决方案。

Method: 使用因子图统一系统动力学、约束和目标，支持流形值状态和切空间中的高斯不确定性建模，利用因子图的稀疏性和概率结构实现实时性能。

Result: 在四旋翼无人机上的仿真和实验表明，相比基线方法，在轨迹跟踪和避障方面表现更优。

Conclusion: FactorMPC通过连接图模型与安全关键MPC，为集成规划与控制提供了可扩展且几何一致的框架，并提供了开源实现。

Abstract: Model predictive control (MPC) faces significant limitations when applied to
systems evolving on nonlinear manifolds, such as robotic attitude dynamics and
constrained motion planning, where traditional Euclidean formulations struggle
with singularities, over-parameterization, and poor convergence. To overcome
these challenges, this paper introduces FactorMPC, a factor-graph based MPC
toolkit that unifies system dynamics, constraints, and objectives into a
modular, user-friendly, and efficient optimization structure. Our approach
natively supports manifold-valued states with Gaussian uncertainties modeled in
tangent spaces. By exploiting the sparsity and probabilistic structure of
factor graphs, the toolkit achieves real-time performance even for
high-dimensional systems with complex constraints. The velocity-extended
on-manifold control barrier function (CBF)-based obstacle avoidance factors are
designed for safety-critical applications. By bridging graphical models with
safety-critical MPC, our work offers a scalable and geometrically consistent
framework for integrated planning and control. The simulations and experimental
results on the quadrotor demonstrate superior trajectory tracking and obstacle
avoidance performance compared to baseline methods. To foster research
reproducibility, we have provided open-source implementation offering
plug-and-play factors.

</details>


### [37] [Stability-Aware Retargeting for Humanoid Multi-Contact Teleoperation](https://arxiv.org/abs/2510.04353)
*Stephen McCrory,Romeo Orsolino,Dhruv Thanki,Luigi Penco,Robert Griffin*

Main category: cs.RO

TL;DR: 提出了一种基于质心稳定性的重定向方法，在遥操作过程中动态调整接触点和姿态，以增强在复杂接触场景下的稳定性。


<details>
  <summary>Details</summary>
Motivation: 遥操作在涉及手部接触和非共面表面的复杂任务中面临挑战，容易导致电机扭矩饱和或通过滑动失去稳定性。

Method: 使用高效的解析计算稳定性裕度梯度，识别对遥操作设定点敏感的稳定性场景，并局部调整这些设定点。

Result: 在仿真和硬件实验中验证了框架，展示了增加稳定性裕度，并经验证明更高的稳定性裕度与改善的冲击恢复能力和关节扭矩裕度相关。

Conclusion: 所提出的方法有效提高了人形机器人在复杂遥操作任务中的稳定性表现。

Abstract: Teleoperation is a powerful method to generate reference motions and enable
humanoid robots to perform a broad range of tasks. However, teleoperation
becomes challenging when using hand contacts and non-coplanar surfaces, often
leading to motor torque saturation or loss of stability through slipping. We
propose a centroidal stability-based retargeting method that dynamically
adjusts contact points and posture during teleoperation to enhance stability in
these difficult scenarios. Central to our approach is an efficient analytical
calculation of the stability margin gradient. This gradient is used to identify
scenarios for which stability is highly sensitive to teleoperation setpoints
and inform the local adjustment of these setpoints. We validate the framework
in simulation and hardware by teleoperating manipulation tasks on a humanoid,
demonstrating increased stability margins. We also demonstrate empirically that
higher stability margins correlate with improved impulse resilience and joint
torque margin.

</details>


### [38] [Reliable and Scalable Robot Policy Evaluation with Imperfect Simulators](https://arxiv.org/abs/2510.04354)
*Apurva Badithela,David Snyder,Lihan Zha,Joseph Mikhail,Matthew O'Kelly,Anushri Dixit,Anirudha Majumdar*

Main category: cs.RO

TL;DR: SureSim框架通过结合大规模仿真和小规模真实世界测试，为机器人策略在真实世界中的性能提供可靠的统计推断，可节省20-25%的硬件评估成本。


<details>
  <summary>Details</summary>
Motivation: 当前机器人策略评估通常仅基于少量硬件试验，缺乏统计保证，需要更可靠的方法来评估策略在真实世界中的性能。

Method: 将真实与仿真评估结合问题形式化为预测驱动的推理问题，使用少量配对的真实和仿真评估来校正大规模仿真的偏差，并利用非渐近均值估计算法提供策略性能的置信区间。

Result: 在基于物理的仿真中评估扩散策略和多任务微调π₀策略，发现该方法可节省20-25%的硬件评估工作量，同时获得相似的性能边界。

Conclusion: SureSim框架能够有效结合仿真和真实世界测试，为机器人策略性能评估提供统计上可靠的推断，显著减少硬件测试需求。

Abstract: Rapid progress in imitation learning, foundation models, and large-scale
datasets has led to robot manipulation policies that generalize to a wide-range
of tasks and environments. However, rigorous evaluation of these policies
remains a challenge. Typically in practice, robot policies are often evaluated
on a small number of hardware trials without any statistical assurances. We
present SureSim, a framework to augment large-scale simulation with relatively
small-scale real-world testing to provide reliable inferences on the real-world
performance of a policy. Our key idea is to formalize the problem of combining
real and simulation evaluations as a prediction-powered inference problem, in
which a small number of paired real and simulation evaluations are used to
rectify bias in large-scale simulation. We then leverage non-asymptotic mean
estimation algorithms to provide confidence intervals on mean policy
performance. Using physics-based simulation, we evaluate both diffusion policy
and multi-task fine-tuned \(\pi_0\) on a joint distribution of objects and
initial conditions, and find that our approach saves over \(20-25\%\) of
hardware evaluation effort to achieve similar bounds on policy performance.

</details>


### [39] [PAD-TRO: Projection-Augmented Diffusion for Direct Trajectory Optimization](https://arxiv.org/abs/2510.04436)
*Jushan Chen,Santiago Paternain*

Main category: cs.RO

TL;DR: 提出了一种基于模型扩散的直接轨迹优化方法，通过梯度自由投影机制确保动态可行性，在四旋翼无人机导航任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的轨迹优化方法采用单次射击方式，无法显式强制执行状态约束，经常导致次优解和动态可行性问题。

Method: 提出直接轨迹优化方法，通过模型扩散直接生成状态序列，并在反向扩散过程中加入梯度自由投影机制来确保动态可行性。

Result: 在四旋翼无人机航点导航场景中，相比现有最优基线方法，实现了零动态可行性误差和约4倍的成功率提升。

Conclusion: 所提出的直接轨迹优化方法通过梯度自由投影机制有效解决了动态可行性约束问题，在复杂导航任务中表现出显著优势。

Abstract: Recently, diffusion models have gained popularity and attention in trajectory
optimization due to their capability of modeling multi-modal probability
distributions. However, addressing nonlinear equality constraints, i.e, dynamic
feasi- bility, remains a great challenge in diffusion-based trajectory
optimization. Recent diffusion-based trajectory optimization frameworks rely on
a single-shooting style approach where the denoised control sequence is applied
to forward propagate the dynamical system, which cannot explicitly enforce
constraints on the states and frequently leads to sub-optimal solutions. In
this work, we propose a novel direct trajectory optimization approach via
model-based diffusion, which directly generates a sequence of states. To ensure
dynamic feasibility, we propose a gradient-free projection mechanism that is
incorporated into the reverse diffusion process. Our results show that,
compared to a recent state-of-the-art baseline, our approach leads to zero
dynamic feasibility error and approximately 4x higher success rate in a
quadrotor waypoint navigation scenario involving dense static obstacles.

</details>


### [40] [Velocity-Form Data-Enabled Predictive Control of Soft Robots under Unknown External Payloads](https://arxiv.org/abs/2510.04509)
*Huanqing Wang,Kaixiang Zhang,Kyungjoon Lee,Yu Mei,Vaibhav Srivastava,Jun Sheng,Ziyou Song,Zhaojian Li*

Main category: cs.RO

TL;DR: 提出了一种新颖的速度形式DeePC框架，用于在未知负载下对软体机器人进行鲁棒和最优控制。


<details>
  <summary>Details</summary>
Motivation: 在物体操作任务中，未知的外部负载和干扰会显著改变系统动力学和行为，导致偏移误差和控制性能下降。

Method: 利用增量表示的输入输出数据来减轻未知负载引起的性能下降，无需加权数据集或干扰估计器。

Result: 在平面软体机器人上进行了实验验证，证明了该方法在涉及未知负载的场景中优于标准DeePC。

Conclusion: 所提出的速度形式DeePC框架能够有效处理未知负载，提高软体机器人的控制性能。

Abstract: Data-driven control methods such as data-enabled predictive control (DeePC)
have shown strong potential in efficient control of soft robots without
explicit parametric models. However, in object manipulation tasks, unknown
external payloads and disturbances can significantly alter the system dynamics
and behavior, leading to offset error and degraded control performance. In this
paper, we present a novel velocity-form DeePC framework that achieves robust
and optimal control of soft robots under unknown payloads. The proposed
framework leverages input-output data in an incremental representation to
mitigate performance degradation induced by unknown payloads, eliminating the
need for weighted datasets or disturbance estimators. We validate the method
experimentally on a planar soft robot and demonstrate its superior performance
compared to standard DeePC in scenarios involving unknown payloads.

</details>


### [41] [Everything-Grasping (EG) Gripper: A Universal Gripper with Synergistic Suction-Grasping Capabilities for Cross-Scale and Cross-State Manipulation](https://arxiv.org/abs/2510.04585)
*Jianshu Zhou,Jing Shu,Tianle Pan,Puchen Zhu,Jiajun An,Huayu Zhang,Junda Huang,Upinder Kaur,Xin Ma,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 提出了Everything-Grasping（EG）夹持器，结合分布式表面吸力和内部颗粒堵塞机制，能够跨尺度和跨状态（固体和液体）操作物体，无需气密密封。


<details>
  <summary>Details</summary>
Motivation: 在软体机器人中，使用单一夹持器抓取尺寸差异巨大且物理状态不同（包括固体和液体）的物体仍然是一个基本挑战。

Method: EG夹持器整合分布式表面吸力和内部颗粒堵塞，结合触觉感知框架（液体检测和基于压力的吸力反馈），通过TIGMS算法自主选择抓取模式。

Result: 夹持器能够处理从0.2mm²（玻璃珠）到超过62,000mm²（A4纸和编织袋）的物体，比自身接触面积小3500倍和大88倍。在水下抓取、易碎物体处理和液体捕获等任务中表现出稳健和可重复的性能。

Conclusion: 这是第一个使用统一柔性架构可靠抓取跨尺度固体和液体物体的软体夹持器。

Abstract: Grasping objects across vastly different sizes and physical states-including
both solids and liquids-with a single robotic gripper remains a fundamental
challenge in soft robotics. We present the Everything-Grasping (EG) Gripper, a
soft end-effector that synergistically integrates distributed surface suction
with internal granular jamming, enabling cross-scale and cross-state
manipulation without requiring airtight sealing at the contact interface with
target objects. The EG Gripper can handle objects with surface areas ranging
from sub-millimeter scale 0.2 mm2 (glass bead) to over 62,000 mm2 (A4 sized
paper and woven bag), enabling manipulation of objects nearly 3,500X smaller
and 88X larger than its own contact area (approximated at 707 mm2 for a 30
mm-diameter base). We further introduce a tactile sensing framework that
combines liquid detection and pressure-based suction feedback, enabling
real-time differentiation between solid and liquid targets. Guided by the
actile-Inferred Grasping Mode Selection (TIGMS) algorithm, the gripper
autonomously selects grasping modes based on distributed pressure and voltage
signals. Experiments across diverse tasks-including underwater grasping,
fragile object handling, and liquid capture-demonstrate robust and repeatable
performance. To our knowledge, this is the first soft gripper to reliably grasp
both solid and liquid objects across scales using a unified compliant
architecture.

</details>


### [42] [MobRT: A Digital Twin-Based Framework for Scalable Learning in Mobile Manipulation](https://arxiv.org/abs/2510.04592)
*Yilin Mei,Peng Qiu,Wei Zhang,WenChao Zhang,Wenjie Song*

Main category: cs.RO

TL;DR: 提出了MobRT框架，通过数字孪生技术为移动操作机器人自动生成多样化的演示数据，解决了移动操作任务中高质量演示数据收集困难的问题。


<details>
  <summary>Details</summary>
Motivation: 移动操作机器人需要在动态、部分可观测的高维环境中协调基座移动和手臂操作，但收集大规模高质量演示数据非常困难，导致现有研究多局限于简单的桌面场景。

Method: 使用数字孪生框架，结合虚拟运动学控制和全身运动规划，自主生成与铰接物体交互（如开门、开抽屉）和移动基座拾取放置任务的多样化、逼真演示。

Result: 在多个基线算法上评估生成数据质量，建立了综合基准，证明任务成功率与生成轨迹数量强相关。模拟和真实世界实验表明该方法显著提升了策略泛化能力和性能。

Conclusion: MobRT框架能够有效解决移动操作任务中演示数据稀缺的问题，在模拟和真实环境中都实现了鲁棒的性能，为移动操作研究提供了重要工具。

Abstract: Recent advances in robotics have been largely driven by imitation learning,
which depends critically on large-scale, high-quality demonstration data.
However, collecting such data remains a significant challenge-particularly for
mobile manipulators, which must coordinate base locomotion and arm manipulation
in high-dimensional, dynamic, and partially observable environments.
Consequently, most existing research remains focused on simpler tabletop
scenarios, leaving mobile manipulation relatively underexplored. To bridge this
gap, we present \textit{MobRT}, a digital twin-based framework designed to
simulate two primary categories of complex, whole-body tasks: interaction with
articulated objects (e.g., opening doors and drawers) and mobile-base
pick-and-place operations. \textit{MobRT} autonomously generates diverse and
realistic demonstrations through the integration of virtual kinematic control
and whole-body motion planning, enabling coherent and physically consistent
execution. We evaluate the quality of \textit{MobRT}-generated data across
multiple baseline algorithms, establishing a comprehensive benchmark and
demonstrating a strong correlation between task success and the number of
generated trajectories. Experiments integrating both simulated and real-world
demonstrations confirm that our approach markedly improves policy
generalization and performance, achieving robust results in both simulated and
real-world environments.

</details>


### [43] [OKVIS2-X: Open Keyframe-based Visual-Inertial SLAM Configurable with Dense Depth or LiDAR, and GNSS](https://arxiv.org/abs/2510.04612)
*Simon Boche,Jaehyung Jung,Sebastián Barbas Laina,Stefan Leutenegger*

Main category: cs.RO

TL;DR: OKVIS2-X是一个先进的多传感器SLAM系统，能够构建密集体素占据地图，在大规模环境中实时运行，并在多个基准测试中达到最先进的精度。


<details>
  <summary>Details</summary>
Motivation: 为移动机器人提供可用地图以及最高状态估计精度和鲁棒性，通过统一框架集成多种传感器模态，并提倡使用密集体素地图表示。

Method: 采用高效的子地图策略，通过地图对齐因子紧密耦合估计器和子地图，支持在线相机外参标定，集成视觉、惯性、深度、LiDAR和GNSS测量。

Result: 在EuRoC中达到最高轨迹精度，在Hilti22 VI-only基准中优于所有竞争对手，在LiDAR版本中具有竞争力，在VBR数据集的大规模序列中展示最先进精度。

Conclusion: OKVIS2-X是一个可扩展、实时运行的多传感器SLAM系统，能够生成全局一致的地图，直接用于自主导航，并在多个基准测试中表现出卓越性能。

Abstract: To empower mobile robots with usable maps as well as highest state estimation
accuracy and robustness, we present OKVIS2-X: a state-of-the-art multi-sensor
Simultaneous Localization and Mapping (SLAM) system building dense volumetric
occupancy maps, while scalable to large environments and operating in realtime.
Our unified SLAM framework seamlessly integrates different sensor modalities:
visual, inertial, measured or learned depth, LiDAR and Global Navigation
Satellite System (GNSS) measurements. Unlike most state-of-the-art SLAM
systems, we advocate using dense volumetric map representations when leveraging
depth or range-sensing capabilities. We employ an efficient submapping strategy
that allows our system to scale to large environments, showcased in sequences
of up to 9 kilometers. OKVIS2-X enhances its accuracy and robustness by
tightly-coupling the estimator and submaps through map alignment factors. Our
system provides globally consistent maps, directly usable for autonomous
navigation. To further improve the accuracy of OKVIS2-X, we also incorporate
the option of performing online calibration of camera extrinsics. Our system
achieves the highest trajectory accuracy in EuRoC against state-of-the-art
alternatives, outperforms all competitors in the Hilti22 VI-only benchmark,
while also proving competitive in the LiDAR version, and showcases state of the
art accuracy in the diverse and large-scale sequences from the VBR dataset.

</details>


### [44] [Bio-Inspired Robotic Houbara: From Development to Field Deployment for Behavioral Studies](https://arxiv.org/abs/2510.04692)
*Lyes Saad Saoud,Irfan Hussain*

Main category: cs.RO

TL;DR: 开发了一个仿生机器人平台，模拟雌性波斑鸨的形态和外观，用于野外生态研究和保护工作。该系统结合了数字制造、实时感知和自主视觉伺服控制，在沙漠环境中成功验证了与真实鸟类的自然互动。


<details>
  <summary>Details</summary>
Motivation: 研究野生鸟类行为面临挑战，需要高度逼真的形态、耐用的户外操作能力以及能够适应非受控环境的智能感知系统。

Method: 采用全数字化可复制的制造流程，包括高分辨率结构光3D扫描、参数化CAD建模、关节式3D打印和逼真UV纹理乙烯基饰面。使用六轮摇杆转向架底盘确保沙地和崎岖地形的稳定移动，嵌入NVIDIA Jetson模块实现实时RGB和热感知、基于YOLO的检测以及自主视觉伺服控制。

Result: 沙漠鸟舍的现场试验显示，系统能够以15-22 FPS的帧率可靠运行，延迟低于100毫秒，平台在恶劣户外条件下能够引发活波斑鸨的自然识别和互动反应。

Conclusion: 该集成框架通过结合可复制的数字制造、具身视觉智能和生态验证，推进了仿生野外机器人技术，为动物-机器人交互研究、保护机器人和公众参与提供了可转移的蓝图。

Abstract: Biomimetic intelligence and robotics are transforming field ecology by
enabling lifelike robotic surrogates that interact naturally with animals under
real world conditions. Studying avian behavior in the wild remains challenging
due to the need for highly realistic morphology, durable outdoor operation, and
intelligent perception that can adapt to uncontrolled environments. We present
a next generation bio inspired robotic platform that replicates the morphology
and visual appearance of the female Houbara bustard to support controlled
ethological studies and conservation oriented field research. The system
introduces a fully digitally replicable fabrication workflow that combines high
resolution structured light 3D scanning, parametric CAD modelling, articulated
3D printing, and photorealistic UV textured vinyl finishing to achieve
anatomically accurate and durable robotic surrogates. A six wheeled rocker
bogie chassis ensures stable mobility on sand and irregular terrain, while an
embedded NVIDIA Jetson module enables real time RGB and thermal perception,
lightweight YOLO based detection, and an autonomous visual servoing loop that
aligns the robot's head toward detected targets without human intervention. A
lightweight thermal visible fusion module enhances perception in low light
conditions. Field trials in desert aviaries demonstrated reliable real time
operation at 15 to 22 FPS with latency under 100 ms and confirmed that the
platform elicits natural recognition and interactive responses from live
Houbara bustards under harsh outdoor conditions. This integrated framework
advances biomimetic field robotics by uniting reproducible digital fabrication,
embodied visual intelligence, and ecological validation, providing a
transferable blueprint for animal robot interaction research, conservation
robotics, and public engagement.

</details>


### [45] [Building Gradient by Gradient: Decentralised Energy Functions for Bimanual Robot Assembly](https://arxiv.org/abs/2510.04696)
*Alexander L. Mitchell,Joe Watson,Ingmar Posner*

Main category: cs.RO

TL;DR: 提出了一种基于梯度的分散式框架，使用自适应势函数的自动组合来生成分段连续能量函数，用于解决双臂装配任务中的快速重规划问题。


<details>
  <summary>Details</summary>
Motivation: 双臂装配面临高层序列规划、多机器人协调和接触丰富的操作等挑战。传统任务和运动规划方法在需要新任务序列时收敛缓慢，特别是在公差严格的装配中，摩擦或变形等难以建模的动态特性需要快速重规划和重试。

Method: 采用分散式梯度优化框架，通过自适应势函数的自动组合构建分段连续能量函数。该方法仅使用近视优化生成子目标，而非长时域规划。

Result: 该方法能够扩展到物理双臂装配任务，构建公差严格的装配体。梯度快速重规划框架能够以涌现方式生成自动重试、协调运动和自主交接。

Conclusion: 所提出的基于梯度的方法通过能量函数的结构和自适应性，能够有效解决长时域任务，为双臂装配提供了灵活高效的规划解决方案。

Abstract: There are many challenges in bimanual assembly, including high-level
sequencing, multi-robot coordination, and low-level, contact-rich operations
such as component mating. Task and motion planning (TAMP) methods, while
effective in this domain, may be prohibitively slow to converge when adapting
to disturbances that require new task sequencing and optimisation. These events
are common during tight-tolerance assembly, where difficult-to-model dynamics
such as friction or deformation require rapid replanning and reattempts.
Moreover, defining explicit task sequences for assembly can be cumbersome,
limiting flexibility when task replanning is required. To simplify this
planning, we introduce a decentralised gradient-based framework that uses a
piecewise continuous energy function through the automatic composition of
adaptive potential functions. This approach generates sub-goals using only
myopic optimisation, rather than long-horizon planning. It demonstrates
effectiveness at solving long-horizon tasks due to the structure and adaptivity
of the energy function. We show that our approach scales to physical bimanual
assembly tasks for constructing tight-tolerance assemblies. In these
experiments, we discover that our gradient-based rapid replanning framework
generates automatic retries, coordinated motions and autonomous handovers in an
emergent fashion.

</details>


### [46] [Performance-guided Task-specific Optimization for Multirotor Design](https://arxiv.org/abs/2510.04724)
*Etor Arza,Welf Rehberg,Philipp Weiss,Mihir Kulkarni,Kostas Alexis*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习、贝叶斯优化和协方差矩阵自适应进化策略的多旋翼微型飞行器任务特定设计优化方法，通过闭环性能优化电机姿态配置，在敏捷航点导航任务中优于传统多旋翼设计。


<details>
  <summary>Details</summary>
Motivation: 传统多旋翼飞行器设计通常基于经验或理论分析，缺乏针对特定任务的系统性优化方法。本文旨在开发一种数据驱动的设计优化框架，直接根据闭环任务性能来优化飞行器设计。

Method: 结合强化学习、贝叶斯优化和协方差矩阵自适应进化策略，在考虑可制造性约束和最小气动干扰的前提下，系统探索电机姿态配置的设计空间。

Result: 优化设计在敏捷航点导航任务中表现出优于传统多旋翼配置的性能，甚至超越了文献中的全驱动设计。通过实际制造和测试验证了模拟到现实的迁移能力。

Conclusion: 该方法能够有效优化多旋翼飞行器的任务特定设计，通过数据驱动的方式获得性能更优的配置，且具有良好的实际应用价值。

Abstract: This paper introduces a methodology for task-specific design optimization of
multirotor Micro Aerial Vehicles. By leveraging reinforcement learning,
Bayesian optimization, and covariance matrix adaptation evolution strategy, we
optimize aerial robot designs guided exclusively by their closed-loop
performance in a considered task. Our approach systematically explores the
design space of motor pose configurations while ensuring manufacturability
constraints and minimal aerodynamic interference. Results demonstrate that
optimized designs achieve superior performance compared to conventional
multirotor configurations in agile waypoint navigation tasks, including against
fully actuated designs from the literature. We build and test one of the
optimized designs in the real world to validate the sim2real transferability of
our approach.

</details>


### [47] [Online automatic code generation for robot swarms: LLMs and self-organizing hierarchy](https://arxiv.org/abs/2510.04774)
*Weixu Zhu,Marco Dorigo,Mary Katherine Heinrich*

Main category: cs.RO

TL;DR: 论文介绍了自组织神经系统(SoNS)，使机器人群体能够自动请求外部LLM生成代码来解决任务中的卡顿问题，在6个真实机器人和30+模拟机器人的测试中达到85%的任务成功率。


<details>
  <summary>Details</summary>
Motivation: 为机器人群体提供行为设计的便利性和全局配置估计能力，实现在线自动代码生成，解决群体机器人任务执行中的卡顿问题。

Method: 使用自组织神经系统(SoNS)增强机器人群体，当群体卡住时自动向外部LLM请求代码生成并实时执行。

Result: 在6个真实机器人和30多个模拟机器人的测试中，系统能够成功完成任务的比率为85%。

Conclusion: SoNS系统能够有效解决机器人群体任务执行中的卡顿问题，通过自动代码生成显著提高任务成功率。

Abstract: Our recently introduced self-organizing nervous system (SoNS) provides robot
swarms with 1) ease of behavior design and 2) global estimation of the swarm
configuration and its collective environment, facilitating the implementation
of online automatic code generation for robot swarms. In a demonstration with 6
real robots and simulation trials with >30 robots, we show that when a
SoNS-enhanced robot swarm gets stuck, it can automatically solicit and run code
generated by an external LLM on the fly, completing its mission with an 85%
success rate.

</details>


### [48] [TAG-K: Tail-Averaged Greedy Kaczmarz for Computationally Efficient and Performant Online Inertial Parameter Estimation](https://arxiv.org/abs/2510.04839)
*Shuo Sha,Anupam Bhakta,Zhenyuan Jiang,Kevin Qiu,Ishaan Mahajan,Gabriel Bravo,Brian Plancher*

Main category: cs.RO

TL;DR: TAG-K是一种轻量级在线惯性参数估计算法，结合贪婪随机行选择和尾部平均，在动态环境中实现快速稳定的参数自适应，相比传统方法显著提升计算速度和估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统在线惯性参数估计方法如RLS和KF在跟踪突变参数时表现不佳或计算成本高，限制了在动态环境和计算受限机器人系统中的有效性。

Method: 提出TAG-K算法，作为Kaczmarz方法的轻量级扩展，结合贪婪随机行选择实现快速收敛，使用尾部平均增强噪声和不一致性下的鲁棒性，保持Kaczmarz框架的低每迭代复杂度。

Result: 在合成基准测试和四旋翼跟踪任务中，TAG-K在笔记本电脑CPU上实现1.5x-1.9x更快的求解时间，在嵌入式微控制器上实现4.8x-20.7x更快的求解时间，同时提高对测量噪声的鲁棒性，估计误差减少25%，端到端跟踪性能提升近2倍。

Conclusion: TAG-K在保持计算效率的同时，显著提升了在线惯性参数估计的速度和精度，特别适合动态环境和计算受限的机器人系统。

Abstract: Accurate online inertial parameter estimation is essential for adaptive
robotic control, enabling real-time adjustment to payload changes,
environmental interactions, and system wear. Traditional methods such as
Recursive Least Squares (RLS) and the Kalman Filter (KF) often struggle to
track abrupt parameter shifts or incur high computational costs, limiting their
effectiveness in dynamic environments and for computationally constrained
robotic systems. As such, we introduce TAG-K, a lightweight extension of the
Kaczmarz method that combines greedy randomized row selection for rapid
convergence with tail averaging for robustness under noise and inconsistency.
This design enables fast, stable parameter adaptation while retaining the low
per-iteration complexity inherent to the Kaczmarz framework. We evaluate TAG-K
in synthetic benchmarks and quadrotor tracking tasks against RLS, KF, and other
Kaczmarz variants. TAG-K achieves 1.5x-1.9x faster solve times on laptop-class
CPUs and 4.8x-20.7x faster solve times on embedded microcontrollers. More
importantly, these speedups are paired with improved resilience to measurement
noise and a 25% reduction in estimation error, leading to nearly 2x better
end-to-end tracking performance.

</details>


### [49] [CLEAR-IR: Clarity-Enhanced Active Reconstruction of Infrared Imagery](https://arxiv.org/abs/2510.04883)
*Nathan Shankar,Pawel Ladosz,Hujun Yin*

Main category: cs.RO

TL;DR: 提出基于U-Net的架构，从含发射器图案的红外图像中重建干净图像，提升暗光环境下机器人感知性能


<details>
  <summary>Details</summary>
Motivation: 红外流在低光条件下比RGB更抗噪，但被主动发射器图案主导，阻碍了物体检测、跟踪和定位等高级任务

Method: 使用U-Net架构重建干净的红外图像，去除发射器图案干扰

Result: 该方法优于现有增强技术，能在从良好光照到极端低光场景下实现可靠的视觉驱动机器人系统操作

Conclusion: 提出的方法有效解决了红外图像中发射器图案干扰问题，显著提升了暗光环境下机器人感知的鲁棒性

Abstract: This paper presents a novel approach for enabling robust robotic perception
in dark environments using infrared (IR) stream. IR stream is less susceptible
to noise than RGB in low-light conditions. However, it is dominated by active
emitter patterns that hinder high-level tasks such as object detection,
tracking and localisation. To address this, a U-Net-based architecture is
proposed that reconstructs clean IR images from emitter-populated input,
improving both image quality and downstream robotic performance. This approach
outperforms existing enhancement techniques and enables reliable operation of
vision-driven robotic systems across illumination conditions from well-lit to
extreme low-light scenes.

</details>


### [50] [HyperVLA: Efficient Inference in Vision-Language-Action Models via Hypernetworks](https://arxiv.org/abs/2510.04898)
*Zheng Xiong,Kang Li,Zilin Wang,Matthew Jackson,Jakob Foerster,Shimon Whiteson*

Main category: cs.RO

TL;DR: HyperVLA提出了一种基于超网络的视觉语言动作模型架构，通过仅激活小型任务特定策略来大幅降低推理成本，同时保持多任务训练能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型的主要缺点是推理成本极高，限制了实际应用。需要一种既能保持高性能又能显著降低推理开销的解决方案。

Method: 采用超网络架构，训练时保留完整模型容量，推理时仅激活小型任务特定策略；结合现有视觉基础模型先验知识、超网络归一化和动作生成策略等关键技术。

Result: 相比OpenVLA，激活参数减少90倍，推理速度提升120倍，在零样本泛化和少样本适应任务上达到相似或更高的成功率。

Conclusion: HyperVLA在保持VLA模型高性能的同时，通过创新的超网络架构显著降低了推理成本，为通用机器人策略的实际部署提供了可行方案。

Abstract: Built upon language and vision foundation models with strong generalization
ability and trained on large-scale robotic data, Vision-Language-Action (VLA)
models have recently emerged as a promising approach to learning generalist
robotic policies. However, a key drawback of existing VLAs is their extremely
high inference costs. In this paper, we propose HyperVLA to address this
problem. Unlike existing monolithic VLAs that activate the whole model during
both training and inference, HyperVLA uses a novel hypernetwork (HN)-based
architecture that activates only a small task-specific policy during inference,
while still retaining the high model capacity needed to accommodate diverse
multi-task behaviors during training. Successfully training an HN-based VLA is
nontrivial so HyperVLA contains several key algorithm design features that
improve its performance, including properly utilizing the prior knowledge from
existing vision foundation models, HN normalization, and an action generation
strategy. Compared to monolithic VLAs, HyperVLA achieves a similar or even
higher success rate for both zero-shot generalization and few-shot adaptation,
while significantly reducing inference costs. Compared to OpenVLA, a
state-of-the-art VLA model, HyperVLA reduces the number of activated parameters
at test time by $90\times$, and accelerates inference speed by $120\times$.
Code is publicly available at https://github.com/MasterXiong/HyperVLA

</details>


### [51] [Efficient Navigation in Unknown Indoor Environments with Vision-Language Models](https://arxiv.org/abs/2510.04991)
*D. Schwartz,K. Kondo,J. P. How*

Main category: cs.RO

TL;DR: 提出一种利用视觉语言模型进行高层规划的新框架，通过零样本推理选择更有效的子目标，提升未知室内环境中的自主导航效率。


<details>
  <summary>Details</summary>
Motivation: 传统探索方法因全局推理能力有限和依赖局部启发式，在存在许多死路的未知室内环境中常采取低效路径。

Method: 将3D占据网格转换为部分2D地图，生成候选子目标，由VLM模型进行零样本评估和排序，并集成到DYNUS轨迹规划器中。

Result: 在仿真中展示了导航效率的提升，VLM能从非完整地图推断结构模式，平衡目标进展与未知空间风险，减少贪婪失败。

Conclusion: 该方法平均缩短约10%的路径长度，有效改善了未知室内环境中的自主导航性能。

Abstract: We present a novel high-level planning framework that leverages
vision-language models (VLMs) to improve autonomous navigation in unknown
indoor environments with many dead ends. Traditional exploration methods often
take inefficient routes due to limited global reasoning and reliance on local
heuristics. In contrast, our approach enables a VLM to reason directly about an
occupancy map in a zero-shot manner, selecting subgoals that are likely to lead
to more efficient paths. At each planning step, we convert a 3D occupancy grid
into a partial 2D map of the environment, and generate candidate subgoals. Each
subgoal is then evaluated and ranked against other candidates by the model. We
integrate this planning scheme into DYNUS \cite{kondo2025dynus}, a
state-of-the-art trajectory planner, and demonstrate improved navigation
efficiency in simulation. The VLM infers structural patterns (e.g., rooms,
corridors) from incomplete maps and balances the need to make progress toward a
goal against the risk of entering unknown space. This reduces common greedy
failures (e.g., detouring into small rooms) and achieves about 10\% shorter
paths on average.

</details>


### [52] [Walking, Rolling, and Beyond: First-Principles and RL Locomotion on a TARS-Inspired Robot](https://arxiv.org/abs/2510.05001)
*Aditya Sripada,Abhishek Warrier*

Main category: cs.RO

TL;DR: TARS3D是一个受《星际穿越》电影启发的非仿生机器人，具有7个自由度，实现了行走和滚动两种步态，并通过分析建模和深度强化学习探索了更多运动模式。


<details>
  <summary>Details</summary>
Motivation: 传统机器人运动研究通常借鉴生物腿设计，但许多工程场景需要非人形形态。该研究探索电影中TARS机器人的块状设计在实际机器人平台上的可行性。

Method: 构建了TARS3D机器人平台，为行走和滚动步态建立降阶模型并推导闭式极限环条件，同时使用深度强化学习在仿真中探索未开发的运动空间。

Result: 实验验证机器人遵守关节限制，实现左右交替接触，在滚动模式下保持八步混合极限环。学习策略能够复现分析步态并发现新行为。

Conclusion: TARS3D的虚构启发生物超越形态能够实现多种先前未探索的运动模式，分析合成与强化学习的结合为多模态机器人开辟了有前景的途径。

Abstract: Robotic locomotion research typically draws from biologically inspired leg
designs, yet many human-engineered settings can benefit from
non-anthropomorphic forms. TARS3D translates the block-shaped 'TARS' robot from
Interstellar into a 0.25 m, 0.99 kg research platform with seven actuated
degrees of freedom. The film shows two primary gaits: a bipedal-like walk and a
high-speed rolling mode. For TARS3D, we build reduced-order models for each,
derive closed-form limit-cycle conditions, and validate the predictions on
hardware. Experiments confirm that the robot respects its +/-150 degree hip
limits, alternates left-right contacts without interference, and maintains an
eight-step hybrid limit cycle in rolling mode. Because each telescopic leg
provides four contact corners, the rolling gait is modeled as an eight-spoke
double rimless wheel. The robot's telescopic leg redundancy implies a far
richer gait repertoire than the two limit cycles treated analytically. So, we
used deep reinforcement learning (DRL) in simulation to search the unexplored
space. We observed that the learned policy can recover the analytic gaits under
the right priors and discover novel behaviors as well. Our findings show that
TARS3D's fiction-inspired bio-transcending morphology can realize multiple
previously unexplored locomotion modes and that further learning-driven search
is likely to reveal more. This combination of analytic synthesis and
reinforcement learning opens a promising pathway for multimodal robotics.

</details>


### [53] [StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation](https://arxiv.org/abs/2510.05057)
*Mingyu Liu,Jiuhe Shu,Hui Chen,Zeju Li,Canyu Zhao,Jiange Yang,Shenyuan Gao,Hao Chen,Chunhua Shen*

Main category: cs.RO

TL;DR: 提出了一种无监督方法StaMo，学习高度压缩的双令牌状态表示，利用轻量编码器和预训练扩散变换器解码器，能够从静态图像中学习可泛化的机器人运动。


<details>
  <summary>Details</summary>
Motivation: 解决具身智能中开发表达性强且紧凑的状态表示这一基本挑战，现有方法往往无法平衡表达性和紧凑性，导致表示要么过于冗余，要么缺乏任务关键信息。

Method: 使用轻量编码器和预训练扩散变换器解码器学习压缩的双令牌状态表示，通过潜在插值获得令牌间的差异作为潜在动作，可解码为可执行的机器人动作。

Result: 在LIBERO上性能提升14.3%，真实世界任务成功率提高30%，推理开销最小；潜在动作增强策略协同训练，比先前方法提升10.4%，并在各种数据源上有效扩展。

Conclusion: StaMo方法能够从静态图像中学习紧凑的状态表示和可泛化的运动，挑战了依赖复杂架构和视频数据学习潜在动作的普遍做法，具有高效、可解释和可扩展的特点。

Abstract: A fundamental challenge in embodied intelligence is developing expressive and
compact state representations for efficient world modeling and decision making.
However, existing methods often fail to achieve this balance, yielding
representations that are either overly redundant or lacking in task-critical
information. We propose an unsupervised approach that learns a highly
compressed two-token state representation using a lightweight encoder and a
pre-trained Diffusion Transformer (DiT) decoder, capitalizing on its strong
generative prior. Our representation is efficient, interpretable, and
integrates seamlessly into existing VLA-based models, improving performance by
14.3% on LIBERO and 30% in real-world task success with minimal inference
overhead. More importantly, we find that the difference between these tokens,
obtained via latent interpolation, naturally serves as a highly effective
latent action, which can be further decoded into executable robot actions. This
emergent capability reveals that our representation captures structured
dynamics without explicit supervision. We name our method StaMo for its ability
to learn generalizable robotic Motion from compact State representation, which
is encoded from static images, challenging the prevalent dependence to learning
latent action on complex architectures and video data. The resulting latent
actions also enhance policy co-training, outperforming prior methods by 10.4%
with improved interpretability. Moreover, our approach scales effectively
across diverse data sources, including real-world robot data, simulation, and
human egocentric video.

</details>


### [54] [Automaton Constrained Q-Learning](https://arxiv.org/abs/2510.05061)
*Anastasios Manganaris,Vittorio Giammarino,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出了ACQL算法，将目标条件值学习与自动机引导强化学习相结合，解决机器人任务中需要满足时序目标和时间变化安全约束的问题。


<details>
  <summary>Details</summary>
Motivation: 现实机器人任务需要实现时序目标序列并遵守时间变化的安全约束，但标准强化学习范式在这些设置中存在根本限制。现有方法无法同时支持时序排序目标和安全性，不适合实际机器人场景。

Method: ACQL算法结合目标条件值学习和自动机引导强化学习，利用LTL任务规范的自动机表示来显式编码阶段化目标进展以及静态和非静态安全约束。

Result: ACQL在连续控制任务中优于现有方法，包括在先前方法无法满足目标达成或安全约束的情况下。在6-DOF机械臂上的真实世界部署验证了其适用性。

Conclusion: ACQL是根据丰富时序规范学习机器人行为的鲁棒且可扩展的解决方案。

Abstract: Real-world robotic tasks often require agents to achieve sequences of goals
while respecting time-varying safety constraints. However, standard
Reinforcement Learning (RL) paradigms are fundamentally limited in these
settings. A natural approach to these problems is to combine RL with
Linear-time Temporal Logic (LTL), a formal language for specifying complex,
temporally extended tasks and safety constraints. Yet, existing RL methods for
LTL objectives exhibit poor empirical performance in complex and continuous
environments. As a result, no scalable methods support both temporally ordered
goals and safety simultaneously, making them ill-suited for realistic robotics
scenarios. We propose Automaton Constrained Q-Learning (ACQL), an algorithm
that addresses this gap by combining goal-conditioned value learning with
automaton-guided reinforcement. ACQL supports most LTL task specifications and
leverages their automaton representation to explicitly encode stage-wise goal
progression and both stationary and non-stationary safety constraints. We show
that ACQL outperforms existing methods across a range of continuous control
tasks, including cases where prior methods fail to satisfy either goal-reaching
or safety constraints. We further validate its real-world applicability by
deploying ACQL on a 6-DOF robotic arm performing a goal-reaching task in a
cluttered, cabinet-like space with safety constraints. Our results demonstrate
that ACQL is a robust and scalable solution for learning robotic behaviors
according to rich temporal specifications.

</details>


### [55] [ResMimic: From General Motion Tracking to Humanoid Whole-body Loco-Manipulation via Residual Learning](https://arxiv.org/abs/2510.05070)
*Siheng Zhao,Yanjie Ze,Yue Wang,C. Karen Liu,Pieter Abbeel,Guanya Shi,Rocky Duan*

Main category: cs.RO

TL;DR: ResMimic是一个两阶段残差学习框架，通过结合通用运动跟踪策略和精确的残差策略，实现了人形机器人精确的全身运动控制和物体交互。


<details>
  <summary>Details</summary>
Motivation: 现有通用运动跟踪策略虽然能复现多样化人类运动，但缺乏精确性和物体感知能力，无法满足人形机器人全身移动操作的需求。

Method: 采用两阶段残差学习：首先训练通用运动跟踪策略作为基础，然后学习高效的残差策略来精炼输出，改进运动并整合物体交互。设计了点云物体跟踪奖励、接触奖励和课程式虚拟物体控制器来优化训练。

Result: 在仿真和真实Unitree G1人形机器人上的实验显示，相比基线方法在任务成功率、训练效率和鲁棒性方面都有显著提升。

Conclusion: ResMimic框架成功解决了人形机器人精确全身移动操作的问题，通过残差学习实现了人类运动数据的精确控制和物体交互能力。

Abstract: Humanoid whole-body loco-manipulation promises transformative capabilities
for daily service and warehouse tasks. While recent advances in general motion
tracking (GMT) have enabled humanoids to reproduce diverse human motions, these
policies lack the precision and object awareness required for
loco-manipulation. To this end, we introduce ResMimic, a two-stage residual
learning framework for precise and expressive humanoid control from human
motion data. First, a GMT policy, trained on large-scale human-only motion,
serves as a task-agnostic base for generating human-like whole-body movements.
An efficient but precise residual policy is then learned to refine the GMT
outputs to improve locomotion and incorporate object interaction. To further
facilitate efficient training, we design (i) a point-cloud-based object
tracking reward for smoother optimization, (ii) a contact reward that
encourages accurate humanoid body-object interactions, and (iii) a
curriculum-based virtual object controller to stabilize early training. We
evaluate ResMimic in both simulation and on a real Unitree G1 humanoid. Results
show substantial gains in task success, training efficiency, and robustness
over strong baselines. Videos are available at https://resmimic.github.io/ .

</details>
