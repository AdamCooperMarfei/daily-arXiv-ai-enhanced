<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 42]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Conversations with Andrea: Visitors' Opinions on Android Robots in a Museum](https://arxiv.org/abs/2506.22466)
*Marcel Heisler,Christian Becker-Asano*

Main category: cs.RO

TL;DR: Andrea机器人博物馆实验总结


<details>
  <summary>Details</summary>
Motivation: 研究公众对自主对话机器人的接受度及潜在应用场景。

Method: 在博物馆部署Andrea机器人六天，收集44名访客的结构化访谈数据，并分析4436条系统日志。

Result: 机器人总体评价积极，性别线索无显著影响；访客希望其提供展品信息，但对其他角色意见不一；改进需求包括多语言支持和更快响应。

Conclusion: 实验为改进机器人系统提供了实用建议，推动其成为实际应用。

Abstract: The android robot Andrea was set up at a public museum in Germany for six
consecutive days to have conversations with visitors, fully autonomously. No
specific context was given, so visitors could state their opinions regarding
possible use-cases in structured interviews, without any bias. Additionally the
44 interviewees were asked for their general opinions of the robot, their
reasons (not) to interact with it and necessary improvements for future use.
The android's voice and wig were changed between different days of operation to
give varying cues regarding its gender. This did not have a significant impact
on the positive overall perception of the robot. Most visitors want the robot
to provide information about exhibits in the future, while opinions on other
roles, like a receptionist, were both wanted and explicitly not wanted by
different visitors. Speaking more languages (than only English) and faster
response times were the improvements most desired. These findings from the
interviews are in line with an analysis of the system logs, which revealed,
that after chitchat and personal questions, most of the 4436 collected requests
asked for information related to the museum and to converse in a different
language. The valuable insights gained from these real-world interactions are
now used to improve the system to become a useful real-world application.

</details>


### [2] [Unsupervised Discovery of Behavioral Primitives from Sensorimotor Dynamic Functional Connectivity](https://arxiv.org/abs/2506.22473)
*Fernando Diaz Ledezma,Valentin Marcel,Matej Hoffmann*

Main category: cs.RO

TL;DR: 该论文提出了一种分析机器人多模态感官信号动态功能连接的方法，揭示其底层结构，并应用于行为选择。


<details>
  <summary>Details</summary>
Motivation: 研究高维感官运动信息的动态功能连接，帮助机器人或新生儿理解未处理的感官运动时间序列。

Method: 使用瞬时互信息捕捉动态功能连接，结合无限关系模型和非负矩阵分解识别传感器运动模块及其演化。

Result: 揭示了传感器运动关系，分解出运动基元或协同作用，可用于行为选择。

Conclusion: 该方法未来可应用于机器人学习和人类运动或脑信号分析。

Abstract: The movements of both animals and robots give rise to streams of
high-dimensional motor and sensory information. Imagine the brain of a newborn
or the controller of a baby humanoid robot trying to make sense of unprocessed
sensorimotor time series. Here, we present a framework for studying the dynamic
functional connectivity between the multimodal sensory signals of a robotic
agent to uncover an underlying structure. Using instantaneous mutual
information, we capture the time-varying functional connectivity (FC) between
proprioceptive, tactile, and visual signals, revealing the sensorimotor
relationships. Using an infinite relational model, we identified sensorimotor
modules and their evolving connectivity. To further interpret these dynamic
interactions, we employed non-negative matrix factorization, which decomposed
the connectivity patterns into additive factors and their corresponding
temporal coefficients. These factors can be considered the agent's motion
primitives or movement synergies that the agent can use to make sense of its
sensorimotor space and later for behavior selection. In the future, the method
can be deployed in robot learning as well as in the analysis of human movement
trajectories or brain signals.

</details>


### [3] [DriveBLIP2: Attention-Guided Explanation Generation for Complex Driving Scenarios](https://arxiv.org/abs/2506.22494)
*Shihong Ling,Yue Wan,Xiaowei Jia,Na Du*

Main category: cs.RO

TL;DR: DriveBLIP2框架基于BLIP2-OPT架构，通过注意力图生成器提升自动驾驶场景中的解释质量。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在复杂多目标环境中表现不佳，尤其在实时自动驾驶中难以快速识别关键对象。

Method: 提出注意力图生成器，突出关键视频帧中对驾驶决策重要的对象。

Result: 在DRAMA数据集上，DriveBLIP2在BLEU、ROUGE、CIDEr和SPICE分数上显著优于基线模型。

Conclusion: 定向注意力机制可提升视觉语言模型在实时自动驾驶中的解释能力。

Abstract: This paper introduces a new framework, DriveBLIP2, built upon the BLIP2-OPT
architecture, to generate accurate and contextually relevant explanations for
emerging driving scenarios. While existing vision-language models perform well
in general tasks, they encounter difficulties in understanding complex,
multi-object environments, particularly in real-time applications such as
autonomous driving, where the rapid identification of key objects is crucial.
To address this limitation, an Attention Map Generator is proposed to highlight
significant objects relevant to driving decisions within critical video frames.
By directing the model's focus to these key regions, the generated attention
map helps produce clear and relevant explanations, enabling drivers to better
understand the vehicle's decision-making process in critical situations.
Evaluations on the DRAMA dataset reveal significant improvements in explanation
quality, as indicated by higher BLEU, ROUGE, CIDEr, and SPICE scores compared
to baseline models. These findings underscore the potential of targeted
attention mechanisms in vision-language models for enhancing explainability in
real-time autonomous driving.

</details>


### [4] [Directed Shape Morphing using Kirigami-enhanced Thermoplastics](https://arxiv.org/abs/2506.22572)
*Mrunmayi Mungekar,Sanjith Menon,M. Ravi Shankar,M. Khalid Jawed*

Main category: cs.RO

TL;DR: 提出一种简单方法，利用均匀加热和常见工具（如家用烤箱和剪刀）将平面塑料片自主转化为复杂三维结构。


<details>
  <summary>Details</summary>
Motivation: 探索一种无需复杂控制即可实现复杂形状自变形的通用制造方法。

Method: 结合热收缩热塑性塑料与定制Kirigami图案，形成双层复合材料，通过均匀加热驱动变形。

Result: 成功制造出多种复杂结构（如碗、金字塔、鼠标盖），并通过有限元模拟验证变形机制。

Conclusion: 该方法通过几何设计实现低信息刺激下的高复杂度变形，为自适应设计和规模化制造提供了通用平台。

Abstract: We present a simple, accessible method for autonomously transforming flat
plastic sheets into intricate three-dimensional structures using only uniform
heating and common tools such as household ovens and scissors. Our approach
combines heat-shrinkable thermoplastics with Kirigami patterns tailored to the
target 3D shape, creating bilayer composites that morph into a wide range of
complex structures, e.g., bowls, pyramids, and even custom ergonomic surfaces
like mouse covers. Critically, the transformation is driven by a
low-information stimulus (uniform heat) yet produces highly intricate shapes
through programmed geometric design. The morphing behavior, confirmed by finite
element simulations, arises from strain mismatch between the contracting
thermoplastic layer and the constraining Kirigami layer. By decoupling material
composition from mechanical response, this method avoids detailed process
control and enables a broad class of self-morphing structures, offering a
versatile platform for adaptive design and scalable manufacturing.

</details>


### [5] [Pixels-to-Graph: Real-time Integration of Building Information Models and Scene Graphs for Semantic-Geometric Human-Robot Understanding](https://arxiv.org/abs/2506.22593)
*Antonello Longo,Chanyoung Chung,Matteo Palieri,Sung-Kyun Kim,Ali Agha,Cataldo Guaragnella,Shehryar Khattak*

Main category: cs.RO

TL;DR: Pix2G方法通过实时生成场景图，连接2D BIM与3D地图，支持资源受限机器人在未知环境中的自主探索。


<details>
  <summary>Details</summary>
Motivation: 解决人类操作员与机器人之间因环境表示差异（2D BIM与3D地图）导致的协作效率问题。

Method: 提出Pix2G方法，利用图像像素和LiDAR地图实时生成结构化场景图，仅使用CPU满足资源限制。

Result: 生成去噪2D地图和结构分割3D点云，通过多层图连接，实验验证了在真实环境中的实时性能。

Conclusion: Pix2G为资源受限平台提供了一种轻量级解决方案，有效支持自主探索任务。

Abstract: Autonomous robots are increasingly playing key roles as support platforms for
human operators in high-risk, dangerous applications. To accomplish challenging
tasks, an efficient human-robot cooperation and understanding is required.
While typically robotic planning leverages 3D geometric information, human
operators are accustomed to a high-level compact representation of the
environment, like top-down 2D maps representing the Building Information Model
(BIM). 3D scene graphs have emerged as a powerful tool to bridge the gap
between human readable 2D BIM and the robot 3D maps. In this work, we introduce
Pixels-to-Graph (Pix2G), a novel lightweight method to generate structured
scene graphs from image pixels and LiDAR maps in real-time for the autonomous
exploration of unknown environments on resource-constrained robot platforms. To
satisfy onboard compute constraints, the framework is designed to perform all
operation on CPU only. The method output are a de-noised 2D top-down
environment map and a structure-segmented 3D pointcloud which are seamlessly
connected using a multi-layer graph abstracting information from object-level
up to the building-level. The proposed method is quantitatively and
qualitatively evaluated during real-world experiments performed using the NASA
JPL NeBula-Spot legged robot to autonomously explore and map cluttered garage
and urban office like environments in real-time.

</details>


### [6] [Robust Peg-in-Hole Assembly under Uncertainties via Compliant and Interactive Contact-Rich Manipulation](https://arxiv.org/abs/2506.22766)
*Yiting Chen,Kenneth Kimble,Howard H. Qian,Podshara Chanrungmaneekul,Robert Seney,Kaiyu Hang*

Main category: cs.RO

TL;DR: 提出了一种基于接触约束的鲁棒自适应机器人插孔装配方法，通过碰撞包容性交互和操纵漏斗概念，解决了紧密公差下的不确定性挑战。


<details>
  <summary>Details</summary>
Motivation: 工业应用中紧密公差下的插孔装配存在感知和物理不确定性，传统方法难以应对。

Method: 利用接触约束消除不确定性，通过碰撞包容性交互和操纵漏斗概念实现装配。

Result: 系统在多种插孔场景中表现出鲁棒性，无需依赖精确感知或学习。

Conclusion: 该方法为紧密公差下的插孔装配提供了一种通用且鲁棒的解决方案。

Abstract: Robust and adaptive robotic peg-in-hole assembly under tight tolerances is
critical to various industrial applications. However, it remains an open
challenge due to perceptual and physical uncertainties from contact-rich
interactions that easily exceed the allowed clearance. In this paper, we study
how to leverage contact between the peg and its matching hole to eliminate
uncertainties in the assembly process under unstructured settings. By examining
the role of compliance under contact constraints, we present a manipulation
system that plans collision-inclusive interactions for the peg to 1)
iteratively identify its task environment to localize the target hole and 2)
exploit environmental contact constraints to refine insertion motions into the
target hole without relying on precise perception, enabling a robust solution
to peg-in-hole assembly. By conceptualizing the above process as the
composition of funneling in different state spaces, we present a formal
approach to constructing manipulation funnels as an uncertainty-absorbing
paradigm for peg-in-hole assembly. The proposed system effectively generalizes
across diverse peg-in-hole scenarios across varying scales, shapes, and
materials in a learning-free manner. Extensive experiments on a NIST Assembly
Task Board (ATB) and additional challenging scenarios validate its robustness
in real-world applications.

</details>


### [7] [Learning Efficient Robotic Garment Manipulation with Standardization](https://arxiv.org/abs/2506.22769)
*Changshi Zhou,Feng Luan,Jiarui Hu,Shaoqiang Meng,Zhipeng Wang,Yanchao Dong,Yanmin Zhou,Bin He*

Main category: cs.RO

TL;DR: APS-Net提出了一种结合展开和标准化的统一框架，用于机器人服装操作，通过动态投掷和精确对齐实现高效展开和标准化。


<details>
  <summary>Details</summary>
Motivation: 现有服装展开方法忽视了标准化的重要性，而标准化能显著简化后续任务（如折叠、熨烫和包装）。

Method: 采用双臂多基元策略，结合动态投掷和精确对齐，并引入因子化奖励函数（覆盖率、关键点距离和IoU）指导学习。

Result: 在仿真中，APS-Net在长袖服装上表现优于现有方法，覆盖率提高3.9%，IoU提高5.2%，关键点距离减少0.14。

Conclusion: 标准化简化了折叠任务，APS-Net在服装操作中表现出高效性和实用性。

Abstract: Garment manipulation is a significant challenge for robots due to the complex
dynamics and potential self-occlusion of garments. Most existing methods of
efficient garment unfolding overlook the crucial role of standardization of
flattened garments, which could significantly simplify downstream tasks like
folding, ironing, and packing. This paper presents APS-Net, a novel approach to
garment manipulation that combines unfolding and standardization in a unified
framework. APS-Net employs a dual-arm, multi-primitive policy with dynamic
fling to quickly unfold crumpled garments and pick-and-place (p and p) for
precise alignment. The purpose of garment standardization during unfolding
involves not only maximizing surface coverage but also aligning the garment's
shape and orientation to predefined requirements. To guide effective robot
learning, we introduce a novel factorized reward function for standardization,
which incorporates garment coverage (Cov), keypoint distance (KD), and
intersection-over-union (IoU) metrics. Additionally, we introduce a spatial
action mask and an Action Optimized Module to improve unfolding efficiency by
selecting actions and operation points effectively. In simulation, APS-Net
outperforms state-of-the-art methods for long sleeves, achieving 3.9 percent
better coverage, 5.2 percent higher IoU, and a 0.14 decrease in KD (7.09
percent relative reduction). Real-world folding tasks further demonstrate that
standardization simplifies the folding process. Project page: see
https://hellohaia.github.io/APS/

</details>


### [8] [SPI-BoTER: Error Compensation for Industrial Robots via Sparse Attention Masking and Hybrid Loss with Spatial-Physical Information](https://arxiv.org/abs/2506.22788)
*Xuao Hou,Yongquan Jia,Shijin Zhang,Yuqiang Wu*

Main category: cs.RO

TL;DR: 本文提出了一种结合物理模型与Transformer架构的方法（SPI-BoTER），用于工业机器人末端执行器的高精度误差补偿，在小样本条件下显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 工业机器人轨迹精度要求日益严格，但现有误差补偿方法存在建模简化、数据驱动缺乏物理一致性及数据需求大等问题，难以同时实现高精度与强泛化能力。

Method: 提出SPI-BoTER方法，融合机器人运动学方程与稀疏自注意力Transformer架构，采用参数自适应混合损失函数迭代优化网络，并结合梯度下降进行逆关节角补偿。

Result: 在UR5机械臂小样本数据集上，3D绝对定位误差为0.2515 mm（标准差0.15 mm），较传统DNN方法误差降低35.16%；逆角度补偿算法平均147次迭代收敛至0.01 mm精度。

Conclusion: SPI-BoTER结合物理可解释性与数据适应性，为工业机器人高精度控制提供了有效解决方案，有望推动智能制造中精密任务的可靠执行。

Abstract: The widespread application of industrial robots in fields such as cutting and
welding has imposed increasingly stringent requirements on the trajectory
accuracy of end-effectors. However, current error compensation methods face
several critical challenges, including overly simplified mechanism modeling, a
lack of physical consistency in data-driven approaches, and substantial data
requirements. These issues make it difficult to achieve both high accuracy and
strong generalization simultaneously. To address these challenges, this paper
proposes a Spatial-Physical Informed Attention Residual Network (SPI-BoTER).
This method integrates the kinematic equations of the robotic manipulator with
a Transformer architecture enhanced by sparse self-attention masks. A
parameter-adaptive hybrid loss function incorporating spatial and physical
information is employed to iteratively optimize the network during training,
enabling high-precision error compensation under small-sample conditions.
Additionally, inverse joint angle compensation is performed using a gradient
descent-based optimization method. Experimental results on a small-sample
dataset from a UR5 robotic arm (724 samples, with a train:test:validation split
of 8:1:1) demonstrate the superior performance of the proposed method. It
achieves a 3D absolute positioning error of 0.2515 mm with a standard deviation
of 0.15 mm, representing a 35.16\% reduction in error compared to conventional
deep neural network (DNN) methods. Furthermore, the inverse angle compensation
algorithm converges to an accuracy of 0.01 mm within an average of 147
iterations. This study presents a solution that combines physical
interpretability with data adaptability for high-precision control of
industrial robots, offering promising potential for the reliable execution of
precision tasks in intelligent manufacturing.

</details>


### [9] [Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation](https://arxiv.org/abs/2506.22827)
*André Schakkal,Ben Zandonati,Zhutian Yang,Navid Azizan*

Main category: cs.RO

TL;DR: 提出了一种分层规划与控制框架，用于实现可靠的多步骤人形机器人操作，结合强化学习、模仿学习和视觉语言模型，实验验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 为了在工业和家庭环境中有效部署人形机器人，需要解决其执行复杂多步骤操作任务的可靠性问题。

Method: 系统分为三层：低层RL控制器跟踪全身运动目标；中层模仿学习技能策略生成任务步骤的运动目标；高层视觉语言规划模块决定技能执行并实时监控。

Result: 在Unitree G1机器人上进行的实验中，系统在多步骤操作任务中实现了72.5%的成功率。

Conclusion: 分层系统结合视觉语言模型的技能规划和监控在多步骤操作场景中具有可行性。

Abstract: Enabling humanoid robots to reliably execute complex multi-step manipulation
tasks is crucial for their effective deployment in industrial and household
environments. This paper presents a hierarchical planning and control framework
designed to achieve reliable multi-step humanoid manipulation. The proposed
system comprises three layers: (1) a low-level RL-based controller responsible
for tracking whole-body motion targets; (2) a mid-level set of skill policies
trained via imitation learning that produce motion targets for different steps
of a task; and (3) a high-level vision-language planning module that determines
which skills should be executed and also monitors their completion in real-time
using pretrained vision-language models (VLMs). Experimental validation is
performed on a Unitree G1 humanoid robot executing a non-prehensile
pick-and-place task. Over 40 real-world trials, the hierarchical system
achieved a 72.5% success rate in completing the full manipulation sequence.
These experiments confirm the feasibility of the proposed hierarchical system,
highlighting the benefits of VLM-based skill planning and monitoring for
multi-step manipulation scenarios. See https://vlp-humanoid.github.io/ for
video demonstrations of the policy rollout.

</details>


### [10] [Safe Reinforcement Learning with a Predictive Safety Filter for Motion Planning and Control: A Drifting Vehicle Example](https://arxiv.org/abs/2506.22894)
*Bei Zhou,Baha Zarrouki,Mattia Piccinini,Cheng Hu,Lei Xie,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了一种基于安全强化学习（RL）的运动规划器，用于自动驾驶漂移，结合模型漂移动力学和预测安全过滤器（PSF），确保安全高效的学习和稳定漂移操作。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法在高速漂移时难以应对不稳定性和不可预测性，现有学习方法的探索能力有限且安全性不足。

Method: 集成RL代理与模型漂移动力学，通过PSF在线调整动作以防止不安全状态。

Result: 在Matlab-Carsim平台上验证，显著提升漂移性能、减少跟踪误差并提高计算效率。

Conclusion: 该方法有望扩展自动驾驶车辆在安全关键场景中的能力。

Abstract: Autonomous drifting is a complex and crucial maneuver for safety-critical
scenarios like slippery roads and emergency collision avoidance, requiring
precise motion planning and control. Traditional motion planning methods often
struggle with the high instability and unpredictability of drifting,
particularly when operating at high speeds. Recent learning-based approaches
have attempted to tackle this issue but often rely on expert knowledge or have
limited exploration capabilities. Additionally, they do not effectively address
safety concerns during learning and deployment. To overcome these limitations,
we propose a novel Safe Reinforcement Learning (RL)-based motion planner for
autonomous drifting. Our approach integrates an RL agent with model-based drift
dynamics to determine desired drift motion states, while incorporating a
Predictive Safety Filter (PSF) that adjusts the agent's actions online to
prevent unsafe states. This ensures safe and efficient learning, and stable
drift operation. We validate the effectiveness of our method through
simulations on a Matlab-Carsim platform, demonstrating significant improvements
in drift performance, reduced tracking errors, and computational efficiency
compared to traditional methods. This strategy promises to extend the
capabilities of autonomous vehicles in safety-critical maneuvers.

</details>


### [11] [Energy-Constrained Resilient Multi-Robot Coverage Control](https://arxiv.org/abs/2506.22942)
*Kartik A. Pant,Jaehyeok Kim,James M. Goppert,Inseok Hwang*

Main category: cs.RO

TL;DR: 提出了一种多机器人覆盖控制的弹性网络设计与控制方法，解决机器人同时离开任务空间充电时网络拓扑中断的问题。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统在覆盖控制中，机器人同时离开充电会破坏通信和感知的网络拓扑，影响任务性能。

Method: 将机器人运动、能量和网络动态建模为混合系统，设计模式转换条件和能量感知的轴承刚性网络拓扑。

Result: 通过数值模拟验证了方法的有效性，确保覆盖性能、能量约束和网络连通性。

Conclusion: 提出的方法能有效增强多机器人系统的结构弹性，支持机器人充电时的任务连续性。

Abstract: The problem of multi-robot coverage control becomes significantly challenging
when multiple robots leave the mission space simultaneously to charge their
batteries, disrupting the underlying network topology for communication and
sensing. To address this, we propose a resilient network design and control
approach that allows robots to achieve the desired coverage performance while
satisfying energy constraints and maintaining network connectivity throughout
the mission. We model the combined motion, energy, and network dynamics of the
multirobot systems (MRS) as a hybrid system with three modes, i.e., coverage,
return-to-base, and recharge, respectively. We show that ensuring the energy
constraints can be transformed into designing appropriate guard conditions for
mode transition between each of the three modes. Additionally, we present a
systematic procedure to design, maintain, and reconfigure the underlying
network topology using an energy-aware bearing rigid network design, enhancing
the structural resilience of the MRS even when a subset of robots departs to
charge their batteries. Finally, we validate our proposed method using
numerical simulations.

</details>


### [12] [SPICE-HL3: Single-Photon, Inertial, and Stereo Camera dataset for Exploration of High-Latitude Lunar Landscapes](https://arxiv.org/abs/2506.22956)
*David Rodríguez-Martínez,Dave van der Meer,Junlin Song,Abishek Bera,C. J. Pérez-del-Pulgar,Miguel Angel Olivares-Mendez*

Main category: cs.RO

TL;DR: 论文介绍了一个在LunaLab设施中记录的高纬度月球环境模拟数据集，包含图像、惯性测量和轮式里程数据，用于验证感知任务。


<details>
  <summary>Details</summary>
Motivation: 高纬度月球区域的视觉环境对机器人极具挑战性，需要模拟低太阳高度角和动态阴影的条件。

Method: 使用立体RGB-惯性传感器、单色相机和新型SPAD相机，在多种光照条件下记录机器人导航数据。

Result: 生成了88个序列共130万张图像的数据集，涵盖静态和动态场景，适用于感知任务验证。

Conclusion: 该数据集为未来月球任务中的自主导航和科学成像提供了宝贵资源。

Abstract: Exploring high-latitude lunar regions presents an extremely challenging
visual environment for robots. The low sunlight elevation angle and minimal
light scattering result in a visual field dominated by a high dynamic range
featuring long, dynamic shadows. Reproducing these conditions on Earth requires
sophisticated simulators and specialized facilities. We introduce a unique
dataset recorded at the LunaLab from the SnT - University of Luxembourg, an
indoor test facility designed to replicate the optical characteristics of
multiple lunar latitudes. Our dataset includes images, inertial measurements,
and wheel odometry data from robots navigating seven distinct trajectories
under multiple illumination scenarios, simulating high-latitude lunar
conditions from dawn to night time with and without the aid of headlights,
resulting in 88 distinct sequences containing a total of 1.3M images. Data was
captured using a stereo RGB-inertial sensor, a monocular monochrome camera, and
for the first time, a novel single-photon avalanche diode (SPAD) camera. We
recorded both static and dynamic image sequences, with robots navigating at
slow (5 cm/s) and fast (50 cm/s) speeds. All data is calibrated, synchronized,
and timestamped, providing a valuable resource for validating perception tasks
from vision-based autonomous navigation to scientific imaging for future lunar
missions targeting high-latitude regions or those intended for robots operating
across perceptually degraded environments. The dataset can be downloaded from
https://zenodo.org/records/13970078?preview=1, and a visual overview is
available at https://youtu.be/d7sPeO50_2I. All supplementary material can be
found at https://github.com/spaceuma/spice-hl3.

</details>


### [13] [Scenario-Based Hierarchical Reinforcement Learning for Automated Driving Decision Making](https://arxiv.org/abs/2506.23023)
*M. Youssef Abdelhamid,Lennart Vater,Zlatan Ajanovic*

Main category: cs.RO

TL;DR: 提出SAD-RL框架，结合分层强化学习和场景化环境，提升自动驾驶决策算法的通用性和学习效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统需在复杂开放环境中安全运行，现有强化学习方法在复杂任务中通用性和效率不足。

Method: SAD-RL框架结合分层策略（高层选择模板，低层执行）和场景化环境，控制训练体验并引入挑战性场景。

Result: 实验表明，SAD-RL训练的代理能在简单和复杂场景中高效实现安全行为，分层学习和场景多样性是关键。

Conclusion: SAD-RL框架通过分层策略和场景化训练，显著提升了自动驾驶决策算法的性能。

Abstract: Developing decision-making algorithms for highly automated driving systems
remains challenging, since these systems have to operate safely in an open and
complex environments. Reinforcement Learning (RL) approaches can learn
comprehensive decision policies directly from experience and already show
promising results in simple driving tasks. However, current approaches fail to
achieve generalizability for more complex driving tasks and lack learning
efficiency. Therefore, we present Scenario-based Automated Driving
Reinforcement Learning (SAD-RL), the first framework that integrates
Reinforcement Learning (RL) of hierarchical policy in a scenario-based
environment. A high-level policy selects maneuver templates that are evaluated
and executed by a low-level control logic. The scenario-based environment
allows to control the training experience for the agent and to explicitly
introduce challenging, but rate situations into the training process. Our
experiments show that an agent trained using the SAD-RL framework can achieve
safe behaviour in easy as well as challenging situations efficiently. Our
ablation studies confirmed that both HRL and scenario diversity are essential
for achieving these results.

</details>


### [14] [Event-based Stereo Visual-Inertial Odometry with Voxel Map](https://arxiv.org/abs/2506.23078)
*Zhaoxing Zhang,Xiaoxiang Wang,Chengliang Zhang,Yangyang Guo,Zikang Yuan,Xin Yang*

Main category: cs.RO

TL;DR: Voxel-ESVIO是一种基于事件相机的立体视觉惯性里程计系统，通过体素地图管理高效筛选高质量3D点，提升状态估计精度。


<details>
  <summary>Details</summary>
Motivation: 事件相机的高动态范围和卓越时间分辨率使其成为视觉里程计的重要传感器，但事件流中的固有噪声影响了高质量地图点的选择，进而影响状态估计精度。

Method: 提出Voxel-ESVIO系统，采用体素地图管理，通过体素点选择和体素感知点管理优化地图点的选择和更新。

Result: 在三个公开基准测试中，Voxel-ESVIO在精度和计算效率上均优于现有方法。

Conclusion: Voxel-ESVIO通过体素管理策略有效筛选噪声鲁棒的地图点，显著提升了状态估计的准确性。

Abstract: The event camera, renowned for its high dynamic range and exceptional
temporal resolution, is recognized as an important sensor for visual odometry.
However, the inherent noise in event streams complicates the selection of
high-quality map points, which critically determine the precision of state
estimation. To address this challenge, we propose Voxel-ESVIO, an event-based
stereo visual-inertial odometry system that utilizes voxel map management,
which efficiently filter out high-quality 3D points. Specifically, our
methodology utilizes voxel-based point selection and voxel-aware point
management to collectively optimize the selection and updating of map points on
a per-voxel basis. These synergistic strategies enable the efficient retrieval
of noise-resilient map points with the highest observation likelihood in
current frames, thereby ensureing the state estimation accuracy. Extensive
evaluations on three public benchmarks demonstrate that our Voxel-ESVIO
outperforms state-of-the-art methods in both accuracy and computational
efficiency.

</details>


### [15] [Minimizing Acoustic Noise: Enhancing Quiet Locomotion for Quadruped Robots in Indoor Applications](https://arxiv.org/abs/2506.23114)
*Zhanxiang Cao,Buqing Nie,Yang Zhang,Yue Gao*

Main category: cs.RO

TL;DR: 该研究通过优化步态设计和控制策略，降低了四足机器人在运动时的噪音，平均减少约8 dBA，使其更适合噪音敏感的室内环境。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在复杂户外环境中的移动能力已显著提升，但其运动时产生的噪音问题在噪音敏感的室内环境（如服务和医疗场所）中被忽视。

Method: 提出了一种新颖的方法，通过优化步态设计和定制控制策略来最小化噪音排放。

Result: 实验结果显示，该方法在多种室内环境中有效，平均噪音降低了约8 dBA。

Conclusion: 该研究展示了四足机器人在噪音敏感环境中实现安静操作的潜力。

Abstract: Recent advancements in quadruped robot research have significantly improved
their ability to traverse complex and unstructured outdoor environments.
However, the issue of noise generated during locomotion is generally
overlooked, which is critically important in noise-sensitive indoor
environments, such as service and healthcare settings, where maintaining low
noise levels is essential. This study aims to optimize the acoustic noise
generated by quadruped robots during locomotion through the development of
advanced motion control algorithms. To achieve this, we propose a novel
approach that minimizes noise emissions by integrating optimized gait design
with tailored control strategies. This method achieves an average noise
reduction of approximately 8 dBA during movement, thereby enhancing the
suitability of quadruped robots for deployment in noise-sensitive indoor
environments. Experimental results demonstrate the effectiveness of this
approach across various indoor settings, highlighting the potential of
quadruped robots for quiet operation in noise-sensitive environments.

</details>


### [16] [Learning Motion Skills with Adaptive Assistive Curriculum Force in Humanoid Robots](https://arxiv.org/abs/2506.23125)
*Zhanxiang Cao,Yang Zhang,Buqing Nie,Huangxuan Lin,Haoyang Li,Yue Gao*

Main category: cs.RO

TL;DR: A2CF方法通过自适应辅助力加速人形机器人学习复杂动作，比基线方法快30%，失败率降低40%。


<details>
  <summary>Details</summary>
Motivation: 受婴儿和运动员依赖外部支持学习技能的启发，提出A2CF方法以解决人形机器人复杂任务学习难题。

Method: 训练双代理系统，辅助力代理根据状态施加力并逐步减少辅助，以提升机器人熟练度。

Result: 在行走、舞蹈和后空翻任务中，A2CF比基线方法收敛快30%，失败率降低40%。

Conclusion: 自适应辅助力显著加速高维机器人控制中复杂技能的获取。

Abstract: Learning policies for complex humanoid tasks remains both challenging and
compelling. Inspired by how infants and athletes rely on external support--such
as parental walkers or coach-applied guidance--to acquire skills like walking,
dancing, and performing acrobatic flips, we propose A2CF: Adaptive Assistive
Curriculum Force for humanoid motion learning. A2CF trains a dual-agent system,
in which a dedicated assistive force agent applies state-dependent forces to
guide the robot through difficult initial motions and gradually reduces
assistance as the robot's proficiency improves. Across three
benchmarks--bipedal walking, choreographed dancing, and backflip--A2CF achieves
convergence 30% faster than baseline methods, lowers failure rates by over 40%,
and ultimately produces robust, support-free policies. Real-world experiments
further demonstrate that adaptively applied assistive forces significantly
accelerate the acquisition of complex skills in high-dimensional robotic
control.

</details>


### [17] [ParticleFormer: A 3D Point Cloud World Model for Multi-Object, Multi-Material Robotic Manipulation](https://arxiv.org/abs/2506.23126)
*Suning Huang,Qianzhong Chen,Xiaohan Zhang,Jiankai Sun,Mac Schwager*

Main category: cs.RO

TL;DR: ParticleFormer是一种基于Transformer的点云世界模型，通过混合点云重建损失训练，能够捕捉多材料、多物体交互的精细动态特征，无需复杂场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有3D世界模型主要局限于单材料动态，且需要耗时的3D场景重建。ParticleFormer旨在解决这些问题，直接利用真实机器人感知数据训练。

Method: 采用Transformer架构和混合点云重建损失，监督全局和局部动态特征，适用于多材料、多物体交互。

Result: 在3D场景预测和下游操控任务中表现优异，仿真和真实实验中均超越基线方法。

Conclusion: ParticleFormer在多材料、多物体交互的动态预测和机器人操控任务中具有显著优势。

Abstract: 3D world models (i.e., learning-based 3D dynamics models) offer a promising
approach to generalizable robotic manipulation by capturing the underlying
physics of environment evolution conditioned on robot actions. However,
existing 3D world models are primarily limited to single-material dynamics
using a particle-based Graph Neural Network model, and often require
time-consuming 3D scene reconstruction to obtain 3D particle tracks for
training. In this work, we present ParticleFormer, a Transformer-based point
cloud world model trained with a hybrid point cloud reconstruction loss,
supervising both global and local dynamics features in multi-material,
multi-object robot interactions. ParticleFormer captures fine-grained
multi-object interactions between rigid, deformable, and flexible materials,
trained directly from real-world robot perception data without an elaborate
scene reconstruction. We demonstrate the model's effectiveness both in 3D scene
forecasting tasks, and in downstream manipulation tasks using a Model
Predictive Control (MPC) policy. In addition, we extend existing dynamics
learning benchmarks to include diverse multi-material, multi-object interaction
scenarios. We validate our method on six simulation and three real-world
experiments, where it consistently outperforms leading baselines by achieving
superior dynamics prediction accuracy and less rollout error in downstream
visuomotor tasks. Experimental videos are available at
https://particleformer.github.io/.

</details>


### [18] [Flatness-based Finite-Horizon Multi-UAV Formation Trajectory Planning and Directionally Aware Collision Avoidance Tracking](https://arxiv.org/abs/2506.23129)
*Hossein B. Jond,Logan Beaver,Martin Jiroušek,Naiemeh Ahmadlou,Veli Bakırcıoğlu,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种基于微分平坦度的无人机编队控制方案，避免了数值方法依赖，通过有限时间最优控制和碰撞约束调节实现无碰撞编队。


<details>
  <summary>Details</summary>
Motivation: 解决无人机编队控制中初始猜测敏感和碰撞避免的挑战。

Method: 利用微分平坦性设计有限时间最优控制问题，结合碰撞约束调节和方向感知避障策略。

Result: 仿真验证了四无人机编队问题的有效性。

Conclusion: 该方法无需数值方法，能有效实现无碰撞编队控制。

Abstract: Collision-free optimal formation control of unmanned aerial vehicle (UAV)
teams is challenging. The state-of-the-art optimal control approaches often
rely on numerical methods sensitive to initial guesses. This paper presents an
innovative collision-free finite-time formation control scheme for multiple
UAVs leveraging the differential flatness of the UAV dynamics, eliminating the
need for numerical methods. We formulate a finite-time optimal control problem
to plan a formation trajectory for feasible initial states. This formation
trajectory planning optimal control problem involves a collective performance
index to meet the formation requirements of achieving relative positions and
velocity consensus. It is solved by applying Pontryagin's principle.
Subsequently, a collision-constrained regulating problem is addressed to ensure
collision-free tracking of the planned formation trajectory. The tracking
problem incorporates a directionally aware collision avoidance strategy that
prioritizes avoiding UAVs in the forward path and relative approach. It assigns
lower priority to those on the sides with an oblique relative approach and
disregards UAVs behind and not in the relative approach. The simulation results
for a four-UAV team (re)formation problem confirm the efficacy of the proposed
control scheme.

</details>


### [19] [DexH2R: A Benchmark for Dynamic Dexterous Grasping in Human-to-Robot Handover](https://arxiv.org/abs/2506.23152)
*Youzhuo Wang,Jiayi Ye,Chuyang Xiao,Yiming Zhong,Heng Tao,Hang Yu,Yumeng Liu,Jingyi Yu,Yuexin Ma*

Main category: cs.RO

TL;DR: 论文介绍了DexH2R数据集，用于解决人机交接任务中高质量真实数据缺乏的问题，并提出DynamicGrasp解决方案。


<details>
  <summary>Details</summary>
Motivation: 人机交接任务因缺乏真实数据集而受限，现有数据多为静态或合成，与实际机器人运动模式差异大。

Method: 通过遥操作收集数据，构建DexH2R数据集，并提出DynamicGrasp解决方案。

Result: 数据集包含多样交互对象、动态运动模式和丰富视觉数据，DynamicGrasp在交接任务中表现优异。

Conclusion: DexH2R数据集和DynamicGrasp方案将推动人机交接研究的发展。

Abstract: Handover between a human and a dexterous robotic hand is a fundamental yet
challenging task in human-robot collaboration. It requires handling dynamic
environments and a wide variety of objects and demands robust and adaptive
grasping strategies. However, progress in developing effective dynamic
dexterous grasping methods is limited by the absence of high-quality,
real-world human-to-robot handover datasets. Existing datasets primarily focus
on grasping static objects or rely on synthesized handover motions, which
differ significantly from real-world robot motion patterns, creating a
substantial gap in applicability. In this paper, we introduce DexH2R, a
comprehensive real-world dataset for human-to-robot handovers, built on a
dexterous robotic hand. Our dataset captures a diverse range of interactive
objects, dynamic motion patterns, rich visual sensor data, and detailed
annotations. Additionally, to ensure natural and human-like dexterous motions,
we utilize teleoperation for data collection, enabling the robot's movements to
align with human behaviors and habits, which is a crucial characteristic for
intelligent humanoid robots. Furthermore, we propose an effective solution,
DynamicGrasp, for human-to-robot handover and evaluate various state-of-the-art
approaches, including auto-regressive models and diffusion policy methods,
providing a thorough comparison and analysis. We believe our benchmark will
drive advancements in human-to-robot handover research by offering a
high-quality dataset, effective solutions, and comprehensive evaluation
metrics.

</details>


### [20] [Mode Collapse Happens: Evaluating Critical Interactions in Joint Trajectory Prediction Models](https://arxiv.org/abs/2506.23164)
*Maarten Hugenholtz,Anna Meszaros,Jens Kober,Zlatan Ajanovic*

Main category: cs.RO

TL;DR: 本文提出了一种新的评估框架，用于检测多模态轨迹预测中的模式崩溃问题，并引入了相关指标，以提高自动驾驶系统的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有模型在预测人类行为时可能因模式崩溃而仅预测最可能模式，忽视交互多样性，且传统评估指标未定量评估交互模式或模式崩溃。

Method: 提出了一种评估框架，包括模式崩溃、模式正确性和覆盖率的指标，特别关注预测的时序维度。

Result: 测试了四种多智能体轨迹预测模型，发现模式崩溃确实存在，且即使接近交互事件时预测准确性提高，仍无法预测正确的交互模式。

Conclusion: 该框架有助于研究者深入理解模式崩溃问题，推动开发更一致和准确的预测模型，提升自动驾驶安全性。

Abstract: Autonomous Vehicle decisions rely on multimodal prediction models that
account for multiple route options and the inherent uncertainty in human
behavior. However, models can suffer from mode collapse, where only the most
likely mode is predicted, posing significant safety risks. While existing
methods employ various strategies to generate diverse predictions, they often
overlook the diversity in interaction modes among agents. Additionally,
traditional metrics for evaluating prediction models are dataset-dependent and
do not evaluate inter-agent interactions quantitatively. To our knowledge, none
of the existing metrics explicitly evaluates mode collapse. In this paper, we
propose a novel evaluation framework that assesses mode collapse in joint
trajectory predictions, focusing on safety-critical interactions. We introduce
metrics for mode collapse, mode correctness, and coverage, emphasizing the
sequential dimension of predictions. By testing four multi-agent trajectory
prediction models, we demonstrate that mode collapse indeed happens. When
looking at the sequential dimension, although prediction accuracy improves
closer to interaction events, there are still cases where the models are unable
to predict the correct interaction mode, even just before the interaction mode
becomes inevitable. We hope that our framework can help researchers gain new
insights and advance the development of more consistent and accurate prediction
models, thus enhancing the safety of autonomous driving systems.

</details>


### [21] [InfGen: Scenario Generation as Next Token Group Prediction](https://arxiv.org/abs/2506.23316)
*Zhenghao Peng,Yuxin Liu,Bolei Zhou*

Main category: cs.RO

TL;DR: InfGen是一个基于Transformer的交通场景生成框架，支持动态、长时程的交通模拟，并能持续插入新车辆。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动的交通模拟方法依赖静态初始化或日志回放数据，难以模拟动态、长时程的交通场景。

Method: InfGen将整个场景表示为包含交通信号、车辆状态和运动向量的令牌序列，通过Transformer模型进行自回归模拟。

Result: 实验表明，InfGen能生成真实、多样且自适应的交通行为，且在其生成的场景中训练的强化学习策略具有更好的鲁棒性和泛化能力。

Conclusion: InfGen是一个高保真度的自动驾驶模拟环境，支持无限场景生成。

Abstract: Realistic and interactive traffic simulation is essential for training and
evaluating autonomous driving systems. However, most existing data-driven
simulation methods rely on static initialization or log-replay data, limiting
their ability to model dynamic, long-horizon scenarios with evolving agent
populations. We propose InfGen, a scenario generation framework that outputs
agent states and trajectories in an autoregressive manner. InfGen represents
the entire scene as a sequence of tokens, including traffic light signals,
agent states, and motion vectors, and uses a transformer model to simulate
traffic over time. This design enables InfGen to continuously insert new agents
into traffic, supporting infinite scene generation. Experiments demonstrate
that InfGen produces realistic, diverse, and adaptive traffic behaviors.
Furthermore, reinforcement learning policies trained in InfGen-generated
scenarios achieve superior robustness and generalization, validating its
utility as a high-fidelity simulation environment for autonomous driving. More
information is available at https://metadriverse.github.io/infgen/.

</details>


### [22] [Simplifying Data-Driven Modeling of the Volume-Flow-Pressure Relationship in Hydraulic Soft Robotic Actuators](https://arxiv.org/abs/2506.23326)
*Sang-Yoep Lee,Leonardo Zamora Yanez,Jacob Rogatinsky,Vi T. Vo,Tanvi Shingade,Tommaso Ranzani*

Main category: cs.RO

TL;DR: 研究提出了一种数据驱动的方法，用于建模液压软执行器的体积-流量-压力关系，重点在于低复杂度高精度模型。


<details>
  <summary>Details</summary>
Motivation: 传统物理模型难以捕捉软机器人系统的复杂非线性行为，因此需要更有效的建模方法。

Method: 采用回归分析，比较了指数、多项式和神经网络模型（含或不含自回归输入）在堆叠气球执行器系统上的表现。

Result: 结果表明，较简单的模型（尤其是多元多项式）能以较少参数有效预测压力动态。

Conclusion: 该研究为实时软机器人应用提供了实用解决方案，平衡了模型复杂性和计算效率，并可能适用于其他需要显式解析模型的技术。

Abstract: Soft robotic systems are known for their flexibility and adaptability, but
traditional physics-based models struggle to capture their complex, nonlinear
behaviors. This study explores a data-driven approach to modeling the
volume-flow-pressure relationship in hydraulic soft actuators, focusing on
low-complexity models with high accuracy. We perform regression analysis on a
stacked balloon actuator system using exponential, polynomial, and neural
network models with or without autoregressive inputs. The results demonstrate
that simpler models, particularly multivariate polynomials, effectively predict
pressure dynamics with fewer parameters. This research offers a practical
solution for real-time soft robotics applications, balancing model complexity
and computational efficiency. Moreover, the approach may benefit various
techniques that require explicit analytical models.

</details>


### [23] [Moving Matter: Using a Single, Simple Robot to Reconfigure a Connected Set of Building Blocks](https://arxiv.org/abs/2506.23333)
*Javier Garcia,Jonas Friemel,Ramin Kosfeld,Michael Yannuzzi,Peter Kramer,Christian Rieck,Christian Scheffer,Arne Schmidt,Harm Kube,Dan Biediger,Sándor P. Fekete,Aaron T. Becker*

Main category: cs.RO

TL;DR: 论文研究了使用单个机器人重新配置连接瓷砖结构的方法，评估了基于直方图的算法，并与现有启发式算法进行了比较。


<details>
  <summary>Details</summary>
Motivation: 探索如何高效地将连接的瓷砖结构重新配置为目标形状，同时保持结构的连通性。

Method: 实现并评估了Becker等人提出的基于直方图的算法，使用模拟和实际环境中的机器人进行实验。

Result: 在模拟和实际环境中验证了该算法的性能，并与两种启发式算法进行了比较。

Conclusion: 基于直方图的算法在特定条件下（起始和目标配置分离良好）能保证接近最优解的性能。

Abstract: We implement and evaluate different methods for the reconfiguration of a
connected arrangement of tiles into a desired target shape, using a single
active robot that can move along the tile structure. This robot can pick up,
carry, or drop off one tile at a time, but it must maintain a single connected
configuration at all times.
  Becker et al. (CCCG 2025) recently proposed an algorithm that uses histograms
as canonical intermediate configurations, guaranteeing performance within a
constant factor of the optimal solution if the start and target configuration
are well-separated. We implement and evaluate this algorithm, both in a
simulated and practical setting, using an inchworm type robot to compare it
with two existing heuristic algorithms.

</details>


### [24] [Safe and Performant Deployment of Autonomous Systems via Model Predictive Control and Hamilton-Jacobi Reachability Analysis](https://arxiv.org/abs/2506.23346)
*Hao Wang,Armand Jordana,Ludovic Righetti,Somil Bansal*

Main category: cs.RO

TL;DR: 提出了一种基于MPC和HJ可达性的框架，优化自主系统的任务性能并确保安全性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在保证安全性的同时高效完成任务，需要一种兼顾性能与安全的解决方案。

Method: 结合模型预测控制（MPC）和Hamilton-Jacobi（HJ）可达性理论，确保递归可行性并适用于高维系统。

Result: 在4D Dubins Car和6 Dof Kuka iiwa机械臂的仿真实验中，框架显著提高了系统的安全性。

Conclusion: 该框架在保证任务性能的同时，有效提升了自主系统的安全性，适用于复杂高维系统。

Abstract: While we have made significant algorithmic developments to enable autonomous
systems to perform sophisticated tasks, it remains difficult for them to
perform tasks effective and safely. Most existing approaches either fail to
provide any safety assurances or substantially compromise task performance for
safety. In this work, we develop a framework, based on model predictive control
(MPC) and Hamilton-Jacobi (HJ) reachability, to optimize task performance for
autonomous systems while respecting the safety constraints. Our framework
guarantees recursive feasibility for the MPC controller, and it is scalable to
high-dimensional systems. We demonstrate the effectiveness of our framework
with two simulation studies using a 4D Dubins Car and a 6 Dof Kuka iiwa
manipulator, and the experiments show that our framework significantly improves
the safety constraints satisfaction of the systems over the baselines.

</details>


### [25] [Benchmarking Generalizable Bimanual Manipulation: RoboTwin Dual-Arm Collaboration Challenge at CVPR 2025 MEIS Workshop](https://arxiv.org/abs/2506.23351)
*Tianxing Chen,Kaixuan Wang,Zhaohui Yang,Yuhao Zhang,Zanxin Chen,Baijun Chen,Wanxi Dong,Ziyuan Liu,Dong Chen,Tianshuo Yang,Haibao Yu,Xiaokang Yang,Yusen Qin,Zhiqiang Xie,Yao Mu,Ping Luo,Tian Nian,Weiliang Deng,Yiheng Ge,Yibin Liu,Zixuan Li,Dehui Wang,Zhixuan Liang,Haohui Xie,Rijie Zeng,Yunfei Ge,Peiqing Cong,Guannan He,Zhaoming Han,Ruocheng Yin,Jingxiang Guo,Lunkai Lin,Tianling Xu,Hongzhe Bi,Xuewu Lin,Tianwei Lin,Shujie Luo,Keyu Li,Ziyan Zhao,Ke Fan,Heyang Xu,Bo Peng,Wenlong Gao,Dongjiang Li,Feng Jin,Hui Shen,Jinming Li,Chaowei Cui,Yuchen,Yaxin Peng,Lingdong Zeng,Wenlong Dong,Tengfei Li,Weijie Ke,Jun Chen,Erdemt Bao,Tian Lan,Tenglong Liu,Jin Yang,Huiping Zhuang,Baozhi Jia,Shuai Zhang,Zhengfeng Zou,Fangheng Guan,Tianyi Jia,Ke Zhou,Hongjiu Zhang,Yating Han,Cheng Fang,Yixian Zou,Chongyang Xu,Qinglun Zhang,Shen Cheng,Xiaohe Wang,Ping Tan,Haoqiang Fan,Shuaicheng Liu,Jiaheng Chen,Chuxuan Huang,Chengliang Lin,Kaijun Luo,Boyu Yue,Yi Liu,Jinyu Chen,Zichang Tan,Liming Deng,Shuo Xu,Zijian Cai,Shilong Yin,Hao Wang,Hongshan Liu,Tianyang Li,Long Shi,Ran Xu,Huilin Xu,Zhengquan Zhang,Congsheng Xu,Jinchang Yang,Feng Xu*

Main category: cs.RO

TL;DR: 论文介绍了RoboTwin双臂协作挑战赛，旨在推动双臂机器人在复杂任务中的研究，吸引了全球64支团队参与，并提出了通用双臂策略学习的新见解。


<details>
  <summary>Details</summary>
Motivation: 推动自主系统在复杂物理环境中的感知、推理和行动能力，特别是双臂协作系统在刚性、可变形和触觉敏感物体任务中的应用。

Method: 基于RoboTwin仿真平台和AgileX COBOT-Magic机器人平台，设计了三个阶段的比赛，包括仿真和现实世界任务。

Result: 吸引了64支全球团队，产生了如SEM和AnchorDP3等优秀解决方案，为通用双臂策略学习提供了宝贵见解。

Conclusion: 挑战赛为未来研究提供了框架和方向，支持开发鲁棒且通用的双臂操作策略。

Abstract: Embodied Artificial Intelligence (Embodied AI) is an emerging frontier in
robotics, driven by the need for autonomous systems that can perceive, reason,
and act in complex physical environments. While single-arm systems have shown
strong task performance, collaborative dual-arm systems are essential for
handling more intricate tasks involving rigid, deformable, and
tactile-sensitive objects. To advance this goal, we launched the RoboTwin
Dual-Arm Collaboration Challenge at the 2nd MEIS Workshop, CVPR 2025. Built on
the RoboTwin Simulation platform (1.0 and 2.0) and the AgileX COBOT-Magic Robot
platform, the competition consisted of three stages: Simulation Round 1,
Simulation Round 2, and a final Real-World Round. Participants totally tackled
17 dual-arm manipulation tasks, covering rigid, deformable, and tactile-based
scenarios. The challenge attracted 64 global teams and over 400 participants,
producing top-performing solutions like SEM and AnchorDP3 and generating
valuable insights into generalizable bimanual policy learning. This report
outlines the competition setup, task design, evaluation methodology, key
findings and future direction, aiming to support future research on robust and
generalizable bimanual manipulation policies. The Challenge Webpage is
available at https://robotwin-benchmark.github.io/cvpr-2025-challenge/.

</details>


### [26] [GS-NBV: a Geometry-based, Semantics-aware Viewpoint Planning Algorithm for Avocado Harvesting under Occlusions](https://arxiv.org/abs/2506.23369)
*Xiao'ao Song,Konstantinos Karydis*

Main category: cs.RO

TL;DR: 提出一种基于几何和语义的视点规划算法，用于自动化采摘不规则形状的牛油果，通过采样、评估和执行三步实现高效采摘。


<details>
  <summary>Details</summary>
Motivation: 牛油果的不规则形状和生长环境增加了自动化采摘的难度，需要特定视点才能成功采摘。

Method: 算法包括视点采样、评估和执行三步，利用几何信息约束搜索空间，并引入新的采摘评分指标。

Result: 在模拟实验中，算法在遮挡严重的情况下实现了100%的成功率。

Conclusion: 该方法高效且鲁棒，适用于自动化牛油果采摘。

Abstract: Efficient identification of picking points is critical for automated fruit
harvesting. Avocados present unique challenges owing to their irregular shape,
weight, and less-structured growing environments, which require specific
viewpoints for successful harvesting. We propose a geometry-based,
semantics-aware viewpoint-planning algorithm to address these challenges. The
planning process involves three key steps: viewpoint sampling, evaluation, and
execution. Starting from a partially occluded view, the system first detects
the fruit, then leverages geometric information to constrain the viewpoint
search space to a 1D circle, and uniformly samples four points to balance the
efficiency and exploration. A new picking score metric is introduced to
evaluate the viewpoint suitability and guide the camera to the next-best view.
We validate our method through simulation against two state-of-the-art
algorithms. Results show a 100% success rate in two case studies with
significant occlusions, demonstrating the efficiency and robustness of our
approach. Our code is available at https://github.com/lineojcd/GSNBV

</details>


### [27] [A Model Predictive Control Framework to Enhance Safety and Quality in Mobile Additive Manufacturing Systems](https://arxiv.org/abs/2506.23400)
*Yifei Li,Joshua A. Robbins,Guha Manogharan,Herschel C. Pangborn,Ilya Kovalenko*

Main category: cs.RO

TL;DR: 论文提出了一种基于模型预测控制的移动增材制造平台，旨在解决传统增材制造系统的静态设置和人工依赖问题，同时确保高打印质量。


<details>
  <summary>Details</summary>
Motivation: 近年来，制造业对定制化、按需生产的需求增加，但传统增材制造系统受限于静态设置和人工依赖，导致生产周期长且扩展性有限。移动机器人可以提升生产系统的灵活性。

Method: 通过将增材制造系统与移动机器人集成，提出了一种模型预测控制框架，确保在动态环境中安全导航并维持高打印质量。

Result: 通过三个案例研究验证了所提系统的可行性和可靠性。

Conclusion: 该框架为移动增材制造平台提供了一种有效的解决方案，能够同时优化生产灵活性和打印质量。

Abstract: In recent years, the demand for customized, on-demand production has grown in
the manufacturing sector. Additive Manufacturing (AM) has emerged as a
promising technology to enhance customization capabilities, enabling greater
flexibility, reduced lead times, and more efficient material usage. However,
traditional AM systems remain constrained by static setups and human worker
dependencies, resulting in long lead times and limited scalability. Mobile
robots can improve the flexibility of production systems by transporting
products to designated locations in a dynamic environment. By integrating AM
systems with mobile robots, manufacturers can optimize travel time for
preparatory tasks and distributed printing operations. Mobile AM robots have
been deployed for on-site production of large-scale structures, but often
neglect critical print quality metrics like surface roughness. Additionally,
these systems do not have the precision necessary for producing small,
intricate components. We propose a model predictive control framework for a
mobile AM platform that ensures safe navigation on the plant floor while
maintaining high print quality in a dynamic environment. Three case studies are
used to test the feasibility and reliability of the proposed systems.

</details>


### [28] [Risk-Based Filtering of Valuable Driving Situations in the Waymo Open Motion Dataset](https://arxiv.org/abs/2506.23433)
*Tim Puphal,Vipul Ramtekkar,Kenji Nishimiya*

Main category: cs.RO

TL;DR: 提出了一种基于风险的过滤方法，用于从大型数据集中识别有价值的驾驶场景，重点关注高风险的一阶和二阶交互。


<details>
  <summary>Details</summary>
Motivation: 提高自动驾驶软件需要包含丰富道路用户交互的驾驶数据，但现有方法难以有效筛选出这些有价值的情境。

Method: 使用概率风险模型检测高风险驾驶情境，特别关注一阶和二阶交互。

Result: 在Waymo Open Motion Dataset中验证了方法的有效性，相比基线指标（Kalman难度和TTP），能识别更复杂和互补的情境。

Conclusion: 该方法提升了自动驾驶测试数据的质量，相关风险数据已开源。

Abstract: Improving automated vehicle software requires driving data rich in valuable
road user interactions. In this paper, we propose a risk-based filtering
approach that helps identify such valuable driving situations from large
datasets. Specifically, we use a probabilistic risk model to detect high-risk
situations. Our method stands out by considering a) first-order situations
(where one vehicle directly influences another and induces risk) and b)
second-order situations (where influence propagates through an intermediary
vehicle). In experiments, we show that our approach effectively selects
valuable driving situations in the Waymo Open Motion Dataset. Compared to the
two baseline interaction metrics of Kalman difficulty and Tracks-To-Predict
(TTP), our filtering approach identifies complex and complementary situations,
enriching the quality in automated vehicle testing. The risk data is made
open-source: https://github.com/HRI-EU/RiskBasedFiltering.

</details>


### [29] [MGPRL: Distributed Multi-Gaussian Processes for Wi-Fi-based Multi-Robot Relative Localization in Large Indoor Environments](https://arxiv.org/abs/2506.23514)
*Sai Krishna Ghanta,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: 论文提出了一种基于Wi-Fi信号的多机器人相对定位框架MGPRL，利用高斯过程和凸包对齐实现高效定位。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖昂贵或短程传感器（如摄像头和LiDAR）以及高计算开销的问题。

Method: 使用多输出高斯过程预测Wi-Fi信号强度，结合凸包对齐进行相对位姿估计。

Result: MGPRL在定位精度和计算效率上优于现有方法。

Conclusion: MGPRL是一种适用于资源受限设备的分布式定位方案，无需预校准或离线指纹。

Abstract: Relative localization is a crucial capability for multi-robot systems
operating in GPS-denied environments. Existing approaches for multi-robot
relative localization often depend on costly or short-range sensors like
cameras and LiDARs. Consequently, these approaches face challenges such as high
computational overhead (e.g., map merging) and difficulties in disjoint
environments. To address this limitation, this paper introduces MGPRL, a novel
distributed framework for multi-robot relative localization using convex-hull
of multiple Wi-Fi access points (AP). To accomplish this, we employ
co-regionalized multi-output Gaussian Processes for efficient Radio Signal
Strength Indicator (RSSI) field prediction and perform uncertainty-aware
multi-AP localization, which is further coupled with weighted convex hull-based
alignment for robust relative pose estimation. Each robot predicts the RSSI
field of the environment by an online scan of APs in its environment, which are
utilized for position estimation of multiple APs. To perform relative
localization, each robot aligns the convex hull of its predicted AP locations
with that of the neighbor robots. This approach is well-suited for devices with
limited computational resources and operates solely on widely available Wi-Fi
RSSI measurements without necessitating any dedicated pre-calibration or
offline fingerprinting. We rigorously evaluate the performance of the proposed
MGPRL in ROS simulations and demonstrate it with real-world experiments,
comparing it against multiple state-of-the-art approaches. The results showcase
that MGPRL outperforms existing methods in terms of localization accuracy and
computational efficiency. Finally, we open source MGPRL as a ROS package
https://github.com/herolab-uga/MGPRL.

</details>


### [30] [Online Human Action Detection during Escorting](https://arxiv.org/abs/2506.23573)
*Siddhartha Mondal,Avik Mitra,Chayan Sarkar*

Main category: cs.RO

TL;DR: 论文提出了一种新型神经网络架构，用于实时行人重识别和动作预测，以提升机器人在拥挤环境中的护送效果。


<details>
  <summary>Details</summary>
Motivation: 当前护送机器人主要依赖导航策略，假设被护送者会顺利跟随，但在拥挤环境中这一假设常不成立，导致服务效果不佳。

Method: 提出了一种能同时完成行人重识别和动作预测的神经网络架构，使机器人能动态调整速度并应对中断。

Result: 在对比评估中，该系统表现出更高的效率和有效性。

Conclusion: 该系统有望显著提升机器人在复杂现实场景中的护送服务能力。

Abstract: The deployment of robot assistants in large indoor spaces has seen
significant growth, with escorting tasks becoming a key application. However,
most current escorting robots primarily rely on navigation-focused strategies,
assuming that the person being escorted will follow without issue. In crowded
environments, this assumption often falls short, as individuals may struggle to
keep pace, become obstructed, get distracted, or need to stop unexpectedly. As
a result, conventional robotic systems are often unable to provide effective
escorting services due to their limited understanding of human movement
dynamics. To address these challenges, an effective escorting robot must
continuously detect and interpret human actions during the escorting process
and adjust its movement accordingly. However, there is currently no existing
dataset designed specifically for human action detection in the context of
escorting. Given that escorting often occurs in crowded environments, where
other individuals may enter the robot's camera view, the robot also needs to
identify the specific human it is escorting (the subject) before predicting
their actions. Since no existing model performs both person re-identification
and action prediction in real-time, we propose a novel neural network
architecture that can accomplish both tasks. This enables the robot to adjust
its speed dynamically based on the escortee's movements and seamlessly resume
escorting after any disruption. In comparative evaluations against strong
baselines, our system demonstrates superior efficiency and effectiveness,
showcasing its potential to significantly improve robotic escorting services in
complex, real-world scenarios.

</details>


### [31] [Passage-traversing optimal path planning with sampling-based algorithms](https://arxiv.org/abs/2506.23614)
*Jing Huang,Hao Su,Kwok Wai Samuel Au*

Main category: cs.RO

TL;DR: 本文提出了一种新的最优路径规划范式PTOPP，通过优化路径穿越的通道来实现特定目标，特别适用于机器人路径规划中自由空间优化的需求。


<details>
  <summary>Details</summary>
Motivation: 机器人路径规划中，自由空间的优化是一个基本需求，而传统方法在通道（自由空间收缩处）的处理上存在局限性。

Method: 提出基于邻近图的通道检测和自由空间分解方法，并开发采样算法解决PTOPP问题。

Result: PTOPP在可配置性、解的最优性和效率上显著优于现有方法（如基于间隙的方法）。

Conclusion: PTOPP为自由空间优化提供了一种高效且通用的解决方案，适用于广泛的路径规划问题。

Abstract: This paper introduces a new paradigm of optimal path planning, i.e.,
passage-traversing optimal path planning (PTOPP), that optimizes paths'
traversed passages for specified optimization objectives. In particular, PTOPP
is utilized to find the path with optimal accessible free space along its
entire length, which represents a basic requirement for paths in robotics. As
passages are places where free space shrinks and becomes constrained, the core
idea is to leverage the path's passage traversal status to characterize its
accessible free space comprehensively. To this end, a novel passage detection
and free space decomposition method using proximity graphs is proposed,
enabling fast detection of sparse but informative passages and environment
decompositions. Based on this preprocessing, optimal path planning with
accessible free space objectives or constraints is formulated as PTOPP problems
compatible with sampling-based optimal planners. Then, sampling-based
algorithms for PTOPP, including their dependent primitive procedures, are
developed leveraging partitioned environments for fast passage traversal check.
All these methods are implemented and thoroughly tested for effectiveness and
efficiency validation. Compared to existing approaches, such as clearance-based
methods, PTOPP demonstrates significant advantages in configurability, solution
optimality, and efficiency, addressing prior limitations and incapabilities. It
is believed to provide an efficient and versatile solution to accessible free
space optimization over conventional avenues and more generally, to a broad
class of path planning problems that can be formulated as PTOPP.

</details>


### [32] [Towards Universal Shared Control in Teleoperation Without Haptic Feedback](https://arxiv.org/abs/2506.23624)
*Max Grobbel,Tristan Schneider,Sören Hohmann*

Main category: cs.RO

TL;DR: 论文提出了一种通过多目标优化将用户输入转换为无碰撞UR5e关节轨迹的方法，同时抑制玻璃中液体晃动，实现了13毫秒的平均规划延迟。


<details>
  <summary>Details</summary>
Motivation: 非触觉VR控制器剥夺了操作员的运动反馈，需要一种方法来提供实时反馈并抑制液体晃动。

Method: 嵌入多目标优化问题，将用户输入转换为无碰撞UR5e关节轨迹，并主动抑制液体晃动。

Result: 控制器实现了13毫秒的平均规划延迟，验证了实时性能。

Conclusion: 该方法可用于进一步扩展其他目标的远程操作。

Abstract: Teleoperation with non-haptic VR controllers deprives human operators of
critical motion feedback. We address this by embedding a multi-objective
optimization problem that converts user input into collision-free UR5e joint
trajectories while actively suppressing liquid slosh in a glass. The controller
maintains 13 ms average planning latency, confirming real-time performance and
motivating the augmentation of this teleoperation approach to further
objectives.

</details>


### [33] [A comprehensive control architecture for semi-autonomous dual-arm robots in agriculture settings](https://arxiv.org/abs/2506.23723)
*Jozsef Palmieri,Paolo Di Lillo,Stefano Chiaverini,Alessandro Marino*

Main category: cs.RO

TL;DR: 本文提出了一种用于复杂农业环境（如葡萄园）的移动机器人控制架构，采用分层二次规划（HQP）方法，同时支持自主和半自主操作。


<details>
  <summary>Details</summary>
Motivation: 在复杂农业环境中，移动机器人需要灵活且高效地整合感知与控制，以完成多项任务（如葡萄采摘），同时处理环境不确定性和人机交互。

Method: 使用16自由度双臂移动机器人，通过HQP方法处理优先级不同的等式和不等式约束，并结合感知系统选择葡萄串。

Result: 在实验室和真实葡萄园中验证了系统的功能，包括自主和半自主采摘，成功处理了感知不确定性和环境交互。

Conclusion: 提出的HQP控制架构在复杂农业环境中表现优异，支持灵活的任务执行和人机协作。

Abstract: The adoption of mobile robotic platforms in complex environments, such as
agricultural settings, requires these systems to exhibit a flexible yet
effective architecture that integrates perception and control. In such
scenarios, several tasks need to be accomplished simultaneously, ranging from
managing robot limits to performing operational tasks and handling human
inputs. The purpose of this paper is to present a comprehensive control
architecture for achieving complex tasks such as robotized harvesting in
vineyards within the framework of the European project CANOPIES. In detail, a
16-DOF dual-arm mobile robot is employed, controlled via a Hierarchical
Quadratic Programming (HQP) approach capable of handling both equality and
inequality constraints at various priorities to harvest grape bunches selected
by the perception system developed within the project. Furthermore, given the
complexity of the scenario and the uncertainty in the perception system, which
could potentially lead to collisions with the environment, the handling of
interaction forces is necessary. Remarkably, this was achieved using the same
HQP framework. This feature is further leveraged to enable semi-autonomous
operations, allowing a human operator to assist the robotic counterpart in
completing harvesting tasks. Finally, the obtained results are validated
through extensive testing conducted first in a laboratory environment to prove
individual functionalities, then in a real vineyard, encompassing both
autonomous and semi-autonomous grape harvesting operations.

</details>


### [34] [PAC Bench: Do Foundation Models Understand Prerequisites for Executing Manipulation Policies?](https://arxiv.org/abs/2506.23725)
*Atharva Gundawar,Som Sagar,Ransalu Senanayake*

Main category: cs.RO

TL;DR: PAC Bench是一个评估视觉语言模型（VLMs）在物理属性、功能性和约束（PAC）理解上的基准测试，揭示了当前模型在物理基础理解上的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管VLMs在机器人操作任务中广泛应用，但其对低层次物理前提（如物体属性、功能性和约束）的理解尚未验证，可能影响任务可靠性。

Method: 提出PAC Bench基准测试，包含多样化数据集（30,000+标注、673张真实图像、100个人类视角场景和120个模拟约束场景），系统评估VLMs的PAC理解能力。

Result: 评估显示当前VLMs在基础物理概念理解上存在显著差距，不适合可靠的机器人操作。

Conclusion: PAC Bench为评估VLMs的物理推理能力提供了标准化基准，并指导开发更稳健的物理基础模型。

Abstract: Vision-Language Models (VLMs) are increasingly pivotal for generalist robot
manipulation, enabling tasks such as physical reasoning, policy generation, and
failure detection. However, their proficiency in these high-level applications
often assumes a deep understanding of low-level physical prerequisites, a
capability that remains largely unverified. For robots to perform actions
reliably, they must comprehend intrinsic object properties (e.g., material,
weight), action affordances (e.g., graspable, stackable), and physical
constraints (e.g., stability, reachability, or an object's state, such as being
closed). Despite the widespread use of VLMs in manipulation tasks, we argue
that off-the-shelf models may lack this granular, physically grounded
understanding, as such prerequisites are often overlooked during training.
  To address this critical gap, we introduce PAC Bench, a comprehensive
benchmark designed to systematically evaluate VLMs on their understanding of
core Properties, Affordances, and Constraints (PAC) from a task executability
perspective. PAC Bench features a diverse dataset with over 30,000 annotations,
comprising 673 real-world images (115 object classes, 15 property types, and 1
to 3 affordances defined per class), 100 real-world humanoid-view scenarios,
and 120 unique simulated constraint scenarios across four tasks.
  Our evaluations reveal significant gaps in the ability of current VLMs to
grasp fundamental physical concepts, highlighting limitations in their
suitability for reliable robot manipulation and pointing to key areas for
targeted research. PAC Bench also serves as a standardized benchmark for
rigorously evaluating physical reasoning in VLMs and guiding the development of
more robust, physically grounded models for robotic applications.
  Project Page: https://pacbench.github.io/

</details>


### [35] [Validation of AI-Based 3D Human Pose Estimation in a Cyber-Physical Environment](https://arxiv.org/abs/2506.23739)
*Lisa Marie Otto,Michael Kaiser,Daniel Seebacher,Steffen Müller*

Main category: cs.RO

TL;DR: 论文提出了一种结合车辆在环测试台和运动实验室的测试环境，用于验证车辆与行人/骑行者交互的可行性，并通过比较真实世界与虚拟场景中的人体姿态估计（HPE）来评估感知准确性。


<details>
  <summary>Details</summary>
Motivation: 为确保自动驾驶系统与城市环境中的弱势道路使用者（VRUs）的安全和真实交互，需要先进的测试方法。

Method: 结合车辆在环测试台和运动实验室，利用Unreal Engine 5生成虚拟场景，实时投影VRUs动画以刺激摄像头，并通过商业单目摄像头AI进行3D骨骼检测。

Result: 结果显示，在稳定运动模式下，HPE在真实世界与虚拟场景中表现一致，但在动态运动和遮挡情况下（尤其是复杂骑行者姿势）存在显著误差。

Conclusion: 研究为改进下一代基于AI的车辆感知测试方法提供了参考，并优化了自动驾驶车辆与VRUs在虚拟环境中的交互模型。

Abstract: Ensuring safe and realistic interactions between automated driving systems
and vulnerable road users (VRUs) in urban environments requires advanced
testing methodologies. This paper presents a test environment that combines a
Vehiclein-the-Loop (ViL) test bench with a motion laboratory, demonstrating the
feasibility of cyber-physical (CP) testing of vehicle-pedestrian and
vehicle-cyclist interactions. Building upon previous work focused on pedestrian
localization, we further validate a human pose estimation (HPE) approach
through a comparative analysis of real-world (RW) and virtual representations
of VRUs. The study examines the perception of full-body motion using a
commercial monocular camera-based 3Dskeletal detection AI. The virtual scene is
generated in Unreal Engine 5, where VRUs are animated in real time and
projected onto a screen to stimulate the camera. The proposed stimulation
technique ensures the correct perspective, enabling realistic vehicle
perception. To assess the accuracy and consistency of HPE across RW and CP
domains, we analyze the reliability of detections as well as variations in
movement trajectories and joint estimation stability. The validation includes
dynamic test scenarios where human avatars, both walking and cycling, are
monitored under controlled conditions. Our results show a strong alignment in
HPE between RW and CP test conditions for stable motion patterns, while notable
inaccuracies persist under dynamic movements and occlusions, particularly for
complex cyclist postures. These findings contribute to refining CP testing
approaches for evaluating next-generation AI-based vehicle perception and to
enhancing interaction models of automated vehicles and VRUs in CP environments.

</details>


### [36] [Motion Tracking with Muscles: Predictive Control of a Parametric Musculoskeletal Canine Model](https://arxiv.org/abs/2506.23768)
*Vittorio La Barbera,Steven Bohez,Leonard Hasenclever,Yuval Tassa,John R. Hutchinson*

Main category: cs.RO

TL;DR: 提出了一种基于3D肌肉网格的狗骨骼肌肉模型，并开发了运动捕捉任务和改进的肌肉动力学模型，验证了模拟肌肉激活模式与实验EMG数据的一致性。


<details>
  <summary>Details</summary>
Motivation: 填补生物力学、机器人和计算神经科学之间的空白，为研究肌肉驱动和神经肌肉控制提供平台。

Method: 使用3D肌肉网格生成骨骼肌肉模型，结合运动捕捉任务和改进的肌肉动力学模型。

Result: 模拟肌肉激活模式与实验EMG数据一致，验证了模型的有效性。

Conclusion: 该模型为相关研究提供了可靠工具，未来将公开模型和运动捕捉数据以促进研究。

Abstract: We introduce a novel musculoskeletal model of a dog, procedurally generated
from accurate 3D muscle meshes. Accompanying this model is a motion
capture-based locomotion task compatible with a variety of control algorithms,
as well as an improved muscle dynamics model designed to enhance convergence in
differentiable control frameworks. We validate our approach by comparing
simulated muscle activation patterns with experimentally obtained
electromyography (EMG) data from previous canine locomotion studies. This work
aims to bridge gaps between biomechanics, robotics, and computational
neuroscience, offering a robust platform for researchers investigating muscle
actuation and neuromuscular control.We plan to release the full model along
with the retargeted motion capture clips to facilitate further research and
development.

</details>


### [37] [Multi-Timescale Hierarchical Reinforcement Learning for Unified Behavior and Control of Autonomous Driving](https://arxiv.org/abs/2506.23771)
*Guizhe Jin,Zhuoren Li,Bo Leng,Ran Yu,Lu Xiong*

Main category: cs.RO

TL;DR: 提出了一种多时间尺度分层强化学习方法，用于自动驾驶，结合长时运动指导和短时控制命令，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在自动驾驶中忽略了策略结构设计，导致行为波动或无法统一优化。

Method: 采用分层策略结构，高低层策略统一训练，分别生成长时运动指导和短时控制命令，并设计分层安全机制。

Result: 在模拟器和HighD数据集的高速公路多车道场景中，显著提高了驾驶效率、行为一致性和安全性。

Conclusion: 多时间尺度分层强化学习方法有效解决了自动驾驶中的行为波动和统一优化问题。

Abstract: Reinforcement Learning (RL) is increasingly used in autonomous driving (AD)
and shows clear advantages. However, most RL-based AD methods overlook policy
structure design. An RL policy that only outputs short-timescale vehicle
control commands results in fluctuating driving behavior due to fluctuations in
network outputs, while one that only outputs long-timescale driving goals
cannot achieve unified optimality of driving behavior and control. Therefore,
we propose a multi-timescale hierarchical reinforcement learning approach. Our
approach adopts a hierarchical policy structure, where high- and low-level RL
policies are unified-trained to produce long-timescale motion guidance and
short-timescale control commands, respectively. Therein, motion guidance is
explicitly represented by hybrid actions to capture multimodal driving
behaviors on structured road and support incremental low-level extend-state
updates. Additionally, a hierarchical safety mechanism is designed to ensure
multi-timescale safety. Evaluation in simulator-based and HighD dataset-based
highway multi-lane scenarios demonstrates that our approach significantly
improves AD performance, effectively increasing driving efficiency, action
consistency and safety.

</details>


### [38] [Data-Driven Predictive Planning and Control for Aerial 3D Inspection with Back-face Elimination](https://arxiv.org/abs/2506.23781)
*Savvas Papaioannou,Panayiotis Kolios,Christos G. Panayiotou,Marios M. Polycarpou*

Main category: cs.RO

TL;DR: 提出了一种基于数据驱动预测控制的3D检测方法，统一感知、规划与控制，适用于现成无人机系统。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将感知、规划和控分离，且缺乏长时程规划能力，难以满足无人机自动检测的需求。

Method: 采用数据驱动预测控制框架，结合3D计算机图形学中的背面消除技术，实现在线生成长时程3D检测轨迹。

Result: 该方法无需已知无人机动态模型，仅需输入输出数据，适用于现成黑盒无人机系统。

Conclusion: 提出的方法解决了现有技术的局限性，为无人机自动检测提供了更高效、灵活的解决方案。

Abstract: Automated inspection with Unmanned Aerial Systems (UASs) is a transformative
capability set to revolutionize various application domains. However, this task
is inherently complex, as it demands the seamless integration of perception,
planning, and control which existing approaches often treat separately.
Moreover, it requires accurate long-horizon planning to predict action
sequences, in contrast to many current techniques, which tend to be myopic. To
overcome these limitations, we propose a 3D inspection approach that unifies
perception, planning, and control within a single data-driven predictive
control framework. Unlike traditional methods that rely on known UAS dynamic
models, our approach requires only input-output data, making it easily
applicable to off-the-shelf black-box UASs. Our method incorporates back-face
elimination, a visibility determination technique from 3D computer graphics,
directly into the control loop, thereby enabling the online generation of
accurate, long-horizon 3D inspection trajectories.

</details>


### [39] [World4Omni: A Zero-Shot Framework from Image Generation World Model to Robotic Manipulation](https://arxiv.org/abs/2506.23919)
*Haonan Chen,Bangjun Wang,Jingxiang Guo,Tianrui Zhang,Yiwen Hou,Xuchuan Huang,Chenrui Tie,Lin Shao*

Main category: cs.RO

TL;DR: 提出一种利用预训练多模态图像生成模型作为世界模型指导策略学习的新框架，实现无需任务特定训练的高效通用机器人操作。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中数据效率和泛化能力的核心挑战。

Method: 利用预训练多模态图像生成模型生成未来状态预测，结合零样本低级控制模块。

Result: 在仿真和真实环境中验证了方法在多种操作任务中的高效性能，无需额外数据收集或微调。

Conclusion: 该方法为通用机器人操作提供了一种高效且泛化能力强的解决方案。

Abstract: Improving data efficiency and generalization in robotic manipulation remains
a core challenge. We propose a novel framework that leverages a pre-trained
multimodal image-generation model as a world model to guide policy learning. By
exploiting its rich visual-semantic representations and strong generalization
across diverse scenes, the model generates open-ended future state predictions
that inform downstream manipulation. Coupled with zero-shot low-level control
modules, our approach enables general-purpose robotic manipulation without
task-specific training. Experiments in both simulation and real-world
environments demonstrate that our method achieves effective performance across
a wide range of manipulation tasks with no additional data collection or
fine-tuning. Supplementary materials are available on our website:
https://world4omni.github.io/.

</details>


### [40] [Adapt Your Body: Mitigating Proprioception Shifts in Imitation Learning](https://arxiv.org/abs/2506.23944)
*Fuhang Kuang,Jiacheng You,Yingdong Hu,Tong Zhang,Chuan Wen,Yang Gao*

Main category: cs.RO

TL;DR: 论文提出了一种解决模仿学习中本体感受偏移问题的方法，通过域适应框架和Wasserstein距离对齐训练与部署分布。


<details>
  <summary>Details</summary>
Motivation: 模仿学习模型通常依赖多模态输入，但直接引入所有本体感受状态会导致性能下降。研究发现这是由于训练和部署时本体感受状态的分布差异（本体感受偏移问题）。

Method: 提出了一种域适应框架，利用部署期间收集的数据，通过Wasserstein距离量化专家与部署本体感受状态的差异，并通过添加噪声最小化这种差异。

Result: 实验表明，该方法在机器人操作任务中有效，优于直接丢弃本体感受状态或其他处理分布偏移的基线方法。

Conclusion: 该方法成功解决了本体感受偏移问题，使模仿策略能够利用本体感受信息并减少其负面影响。

Abstract: Imitation learning models for robotic tasks typically rely on multi-modal
inputs, such as RGB images, language, and proprioceptive states. While
proprioception is intuitively important for decision-making and obstacle
avoidance, simply incorporating all proprioceptive states leads to a surprising
degradation in imitation learning performance. In this work, we identify the
underlying issue as the proprioception shift problem, where the distributions
of proprioceptive states diverge significantly between training and deployment.
To address this challenge, we propose a domain adaptation framework that
bridges the gap by utilizing rollout data collected during deployment. Using
Wasserstein distance, we quantify the discrepancy between expert and rollout
proprioceptive states and minimize this gap by adding noise to both sets of
states, proportional to the Wasserstein distance. This strategy enhances
robustness against proprioception shifts by aligning the training and
deployment distributions. Experiments on robotic manipulation tasks demonstrate
the efficacy of our method, enabling the imitation policy to leverage
proprioception while mitigating its adverse effects. Our approach outperforms
the naive solution which discards proprioception, and other baselines designed
to address distributional shifts.

</details>


### [41] [Predictive Risk Analysis and Safe Trajectory Planning for Intelligent and Connected Vehicles](https://arxiv.org/abs/2506.23999)
*Zeyu Han,Mengchi Cai,Chaoyi Chen,Qingwen Meng,Guangwei Wang,Ying Liu,Qing Xu,Jianqiang Wang,Keqiang Li*

Main category: cs.RO

TL;DR: 提出了一种智能网联车辆的预测风险分析与安全轨迹规划框架，结合未来预测优化轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 现有风险评估理论仅基于当前信息，忽略未来预测，无法满足智能网联车辆的安全需求。

Method: 通过局部风险感知算法预测物体未来轨迹，利用预测结果进行时空离散化的预测风险分析，并生成安全轨迹。

Result: 仿真和车辆实验验证了方法的有效性和实时实用性。

Conclusion: 该框架为智能网联车辆提供了更安全的轨迹规划方案。

Abstract: The safe trajectory planning of intelligent and connected vehicles is a key
component in autonomous driving technology. Modeling the environment risk
information by field is a promising and effective approach for safe trajectory
planning. However, existing risk assessment theories only analyze the risk by
current information, ignoring future prediction. This paper proposes a
predictive risk analysis and safe trajectory planning framework for intelligent
and connected vehicles. This framework first predicts future trajectories of
objects by a local risk-aware algorithm, following with a
spatiotemporal-discretised predictive risk analysis using the prediction
results. Then the safe trajectory is generated based on the predictive risk
analysis. Finally, simulation and vehicle experiments confirm the efficacy and
real-time practicability of our approach.

</details>


### [42] [Exploring Accelerated Skill Acquisition via Tandem Training for Colonoscopy](https://arxiv.org/abs/2506.24046)
*Olivia Richards,Keith L. Obstein,Nabil Simaan*

Main category: cs.RO

TL;DR: 提出了一种新型结肠镜训练系统，通过远程操控的导师结肠镜实时指导新手操作，加速技能学习。


<details>
  <summary>Details</summary>
Motivation: 当前结肠镜培训方法依赖工具交接，限制了新手对设备的熟练度发展，亟需实时指导工具。

Method: 设计了一种双控系统，可自动切换专家和新手对结肠镜角度控制轮的操作。

Result: 初步用户研究表明，该系统能有效提升新手技能学习效果。

Conclusion: 该系统有望加速结肠镜技能学习，未来可实现个性化指导和双向操作教学。

Abstract: New endoscopists require a large volume of expert-proctored colonoscopies to
attain minimal competency. Developing multi-fingered, synchronized control of a
colonoscope requires significant time and exposure to the device. Current
training methods inhibit this development by relying on tool hand-off for
expert demonstrations. There is a need for colonoscopy training tools that
enable in-hand expert guidance in real-time. We present a new concept of a
tandem training system that uses a telemanipulated preceptor colonoscope to
guide novice users as they perform a colonoscopy. This system is capable of
dual-control and can automatically toggle between expert and novice control of
a standard colonoscope's angulation control wheels. Preliminary results from a
user study with novice and expert users show the effectiveness of this device
as a skill acquisition tool. We believe that this device has the potential to
accelerate skill acquisition for colonoscopy and, in the future, enable
individualized instruction and responsive teaching through bidirectional
actuation.

</details>
