<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Studying the Effects of Robot Intervention on School Shooters in Virtual Reality](https://arxiv.org/abs/2510.17948)
*Christopher A McClurg,Alan R Wagner*

Main category: cs.RO

TL;DR: 虚拟现实研究表明，自主机器人通过预测校园枪手行动并进行战略干扰，能有效减少受害者数量46.6%，但引发伦理问题


<details>
  <summary>Details</summary>
Motivation: 探讨机器人在高风险场景中干预校园枪击事件的潜力，特别是通过分散枪手注意力来减少伤亡

Method: 使用虚拟现实模拟，150名大学生扮演校园枪手角色，测试不同机器人策略（激进vs被动）和干扰方法（低中高三个级别）的效果

Result: 激进且高干扰的机器人策略能显著减少46.6%的受害者数量，证明机器人干预的有效性

Conclusion: 机器人干预具有增强校园安全的潜力，但其在校园环境中的使用引发了紧迫的伦理问题

Abstract: We advance the understanding of robotic intervention in high-risk scenarios
by examining their potential to distract and impede a school shooter. To
evaluate this concept, we conducted a virtual reality study with 150 university
participants role-playing as a school shooter. Within the simulation, an
autonomous robot predicted the shooter's movements and positioned itself
strategically to interfere and distract. The strategy the robot used to
approach the shooter was manipulated -- either moving directly in front of the
shooter (aggressive) or maintaining distance (passive) -- and the distraction
method, ranging from no additional cues (low), to siren and lights (medium), to
siren, lights, and smoke to impair visibility (high). An aggressive,
high-distraction robot reduced the number of victims by 46.6% relative to a
no-robot control. This outcome underscores both the potential of robotic
intervention to enhance safety and the pressing ethical questions surrounding
their use in school environments.

</details>


### [2] [RoboChallenge: Large-scale Real-robot Evaluation of Embodied Policies](https://arxiv.org/abs/2510.17950)
*Adina Yakefu,Bin Xie,Chongyang Xu,Enwen Zhang,Erjin Zhou,Fan Jia,Haitao Yang,Haoqiang Fan,Haowei Zhang,Hongyang Peng,Jing Tan,Junwen Huang,Kai Liu,Kaixin Liu,Kefan Gu,Qinglun Zhang,Ruitao Zhang,Saike Huang,Shen Cheng,Shuaicheng Liu,Tiancai Wang,Tiezhen Wang,Wei Sun,Wenbin Tang,Yajun Wei,Yang Chen,Youqiang Gui,Yucheng Zhao,Yunchao Ma,Yunfei Wei,Yunhuan Yang,Yutong Guo,Ze Chen,Zhengyuan Du,Ziheng Zhang,Ziming Liu,Ziwei Yan*

Main category: cs.RO

TL;DR: 提出了RoboChallenge在线评估系统，用于大规模测试机器人控制算法，特别是VLA模型，并利用Table30基准对最新VLA模型进行了调查。


<details>
  <summary>Details</summary>
Motivation: 学习型算法（尤其是VLA模型）需要大规模评估，即在大量任务上测试大量模型，但实现可扩展性和可重复性具有挑战性。

Method: 构建RoboChallenge在线评估系统，采用Table30作为初始基准，对最先进的VLA模型进行系统评估。

Result: 开发了一个可扩展且可重复的在线评估系统，能够支持大规模机器人控制算法的测试需求。

Conclusion: RoboChallenge系统为VLA模型的大规模评估提供了有效解决方案，解决了可扩展性和可重复性问题。

Abstract: Testing on real machines is indispensable for robotic control algorithms. In
the context of learning-based algorithms, especially VLA models, demand for
large-scale evaluation, i.e. testing a large number of models on a large number
of tasks, is becoming increasingly urgent. However, doing this right is highly
non-trivial, especially when scalability and reproducibility is taken into
account. In this report, we describe our methodology for constructing
RoboChallenge, an online evaluation system to test robotic control algorithms,
and our survey of recent state-of-the-art VLA models using our initial
benchmark Table30.

</details>


### [3] [Humanoid Goalkeeper: Learning from Position Conditioned Task-Motion Constraints](https://arxiv.org/abs/2510.18002)
*Junli Ren,Junfeng Long,Tao Huang,Huayi Wang,Zirui Wang,Feiyu Jia,Wentao Zhang,Jingbo Wang,Ping Luo,Jiangmiao Pang*

Main category: cs.RO

TL;DR: 提出一个用于人形机器人自主守门的强化学习框架，通过集成人类运动先验和对抗训练，实现自然、动态的全身运动控制。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人守门的两大挑战：生成自然的类人全身运动，以及在相同响应时间内覆盖更广的守护范围。

Method: 使用端到端强化学习策略，通过对抗训练方案将基于感知输入的多个人类运动先验集成到RL训练中。

Result: 在真实世界实验中，人形机器人成功执行了敏捷、自主且自然的快速移动球拦截，并展示了在球逃脱和抓取等任务上的泛化能力。

Conclusion: 为机器人与移动物体之间的高度动态交互提供了一个实用且可扩展的解决方案，推动了更具适应性和逼真度的机器人行为发展。

Abstract: We present a reinforcement learning framework for autonomous goalkeeping with
humanoid robots in real-world scenarios. While prior work has demonstrated
similar capabilities on quadrupedal platforms, humanoid goalkeeping introduces
two critical challenges: (1) generating natural, human-like whole-body motions,
and (2) covering a wider guarding range with an equivalent response time.
Unlike existing approaches that rely on separate teleoperation or fixed motion
tracking for whole-body control, our method learns a single end-to-end RL
policy, enabling fully autonomous, highly dynamic, and human-like robot-object
interactions. To achieve this, we integrate multiple human motion priors
conditioned on perceptual inputs into the RL training via an adversarial
scheme. We demonstrate the effectiveness of our method through real-world
experiments, where the humanoid robot successfully performs agile, autonomous,
and naturalistic interceptions of fast-moving balls. In addition to
goalkeeping, we demonstrate the generalization of our approach through tasks
such as ball escaping and grabbing. Our work presents a practical and scalable
solution for enabling highly dynamic interactions between robots and moving
objects, advancing the field toward more adaptive and lifelike robotic
behaviors.

</details>


### [4] [MOFM-Nav: On-Manifold Ordering-Flexible Multi-Robot Navigation](https://arxiv.org/abs/2510.18063)
*Bin-Bin Hu,Weijia Yao,Ming Cao*

Main category: cs.RO

TL;DR: 本文提出了一种改进的协调梯度向量场算法，用于解决多机器人在n维欧几里得空间中m维流形上的导航问题，同时保持灵活的空间排序。通过选择合适的辅助向量和引入虚拟坐标，解决了流形参数间的强耦合问题，实现了非欧几里得度量下的协调控制。


<details>
  <summary>Details</summary>
Motivation: 在多机器人导航中，当机器人在n维空间的m维流形上运动时，流形参数间的强耦合会影响机器人的流形上机动，并对基于非欧几里得度量的灵活排序协调设计带来挑战。

Method: 首先识别可行的辅助向量解以解耦传播项的最后m个条目；然后重新设计协调梯度向量场算法，将m个流形参数视为额外的虚拟坐标；最后通过共享虚拟坐标实现流形上的灵活排序协调。

Result: 通过大量仿真验证了算法在不同初始位置、高维流形和机器人故障情况下的灵活性、适应性和鲁棒性。

Conclusion: 所提出的算法有效解决了流形参数耦合问题，实现了多机器人在复杂流形上的灵活协调导航，避免了使用欧几里得度量可能带来的复杂计算。

Abstract: This paper addresses the problem of multi-robot navigation where robots
maneuver on a desired \(m\)-dimensional (i.e., \(m\)-D) manifold in the
$n$-dimensional Euclidean space, and maintain a {\it flexible spatial
ordering}. We consider $ m\geq 2$, and the multi-robot coordination is achieved
via non-Euclidean metrics. However, since the $m$-D manifold can be
characterized by the zero-level sets of $n$ implicit functions, the last $m$
entries of the GVF propagation term become {\it strongly coupled} with the
partial derivatives of these functions if the auxiliary vectors are not
appropriately chosen. These couplings not only influence the on-manifold
maneuvering of robots, but also pose significant challenges to the further
design of the ordering-flexible coordination via non-Euclidean metrics.
  To tackle this issue, we first identify a feasible solution of auxiliary
vectors such that the last $m$ entries of the propagation term are effectively
decoupled to be the same constant. Then, we redesign the coordinated GVF (CGVF)
algorithm to {\it boost} the advantages of singularities elimination and global
convergence by treating $m$ manifold parameters as additional $m$ virtual
coordinates. Furthermore, we enable the on-manifold ordering-flexible motion
coordination by allowing each robot to share $m$ virtual coordinates with its
time-varying neighbors and a virtual target robot, which {\it circumvents} the
possible complex calculation if Euclidean metrics were used instead. Finally,
we showcase the proposed algorithm's flexibility, adaptability, and robustness
through extensive simulations with different initial positions,
higher-dimensional manifolds, and robot breakdown, respectively.

</details>


### [5] [R2BC: Multi-Agent Imitation Learning from Single-Agent Demonstrations](https://arxiv.org/abs/2510.18085)
*Connor Mattson,Varun Raveendra,Ellen Novoseller,Nicholas Waytowich,Vernon J. Lawhern,Daniel S. Brown*

Main category: cs.RO

TL;DR: 提出了R2BC方法，让单个操作员通过轮流遥控单个机器人的方式训练多机器人系统，无需在联合动作空间中进行演示。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在多机器人系统中应用较少，特别是当单个人类需要为协作机器人团队提供演示时。现有方法通常需要复杂的联合动作空间演示。

Method: R2BC方法采用轮询行为克隆，操作员一次只遥控一个机器人，通过顺序的单智能体演示逐步教授多智能体行为。

Result: 在四个多智能体模拟任务中，R2BC方法匹配甚至超越了基于特权同步演示的oracle行为克隆方法的性能。在两个物理机器人任务中成功部署。

Conclusion: R2BC为单个操作员训练多机器人系统提供了一种有效方法，无需复杂的联合动作空间演示，在实际应用中具有可行性。

Abstract: Imitation Learning (IL) is a natural way for humans to teach robots,
particularly when high-quality demonstrations are easy to obtain. While IL has
been widely applied to single-robot settings, relatively few studies have
addressed the extension of these methods to multi-agent systems, especially in
settings where a single human must provide demonstrations to a team of
collaborating robots. In this paper, we introduce and study Round-Robin
Behavior Cloning (R2BC), a method that enables a single human operator to
effectively train multi-robot systems through sequential, single-agent
demonstrations. Our approach allows the human to teleoperate one agent at a
time and incrementally teach multi-agent behavior to the entire system, without
requiring demonstrations in the joint multi-agent action space. We show that
R2BC methods match, and in some cases surpass, the performance of an oracle
behavior cloning approach trained on privileged synchronized demonstrations
across four multi-agent simulated tasks. Finally, we deploy R2BC on two
physical robot tasks trained using real human demonstrations.

</details>


### [6] [ANGEL: A Novel Gripper for Versatile and Light-touch Fruit Harvesting](https://arxiv.org/abs/2510.18127)
*Dharmik Patel,Antonio Rafael Vazquez Pantoja,Jiuzhou Lei,Kiju Lee,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 提出了一种受拉绳启发的线驱动软夹具，用于水果采摘，通过3D打印TPU口袋和集成钢丝实现均匀压力分布，减少水果损伤。


<details>
  <summary>Details</summary>
Motivation: 水果采摘主要依赖人工劳动，现有刚性或真空夹具需要复杂机械设计或高能耗，而包裹式夹具缺乏对不同尺寸水果的适应性。

Method: 使用3D打印TPU材料制作口袋，集成钢丝，通过伺服驱动线缆控制实现夹持，电机反馈提供自主夹持力调节。

Result: 在有效尺寸范围内的番茄采摘中，实现0%即时损伤率和5天后小于9%的瘀伤率。

Conclusion: 该软夹具设计简单、成本低，适合水果采摘应用，能有效减少水果损伤。

Abstract: Fruit harvesting remains predominantly a labor-intensive process, motivating
the development of research for robotic grippers. Conventional rigid or
vacuum-driven grippers require complex mechanical design or high energy
consumption. Current enveloping-based fruit harvesting grippers lack
adaptability to fruits of different sizes. This paper introduces a
drawstring-inspired, cable-driven soft gripper for versatile and gentle fruit
harvesting. The design employs 3D-printed Thermoplastic Polyurethane (TPU)
pockets with integrated steel wires that constrict around the fruit when
actuated, distributing pressure uniformly to minimize bruising and allow
versatility to fruits of varying sizes. The lightweight structure, which
requires few components, reduces mechanical complexity and cost compared to
other grippers. Actuation is achieved through servo-driven cable control, while
motor feedback provides autonomous grip adjustment with tunable grip strength.
Experimental validation shows that, for tomatoes within the gripper's effective
size range, harvesting was achieved with a 0% immediate damage rate and a
bruising rate of less than 9% after five days, reinforcing the gripper's
suitability for fruit harvesting.

</details>


### [7] [Quality Over Quantity: Curating Contact-Based Robot Datasets Improves Learning](https://arxiv.org/abs/2510.18137)
*Hrishikesh Sathyanarayan,Victor Vantilborgh,Ian Abraham*

Main category: cs.RO

TL;DR: 研究数据集在机器人学习中的效用，发现接触数据比更多数据更重要，提出基于Fisher信息度量的数据筛选方法，证明较少但信息丰富的数据能加速学习。


<details>
  <summary>Details</summary>
Motivation: 探究机器人学习中数据集的效用，特别关注接触数据的价值，因为接触包含重要的学习信息，想量化接触数据的效用。

Method: 提出接触感知的目标函数，用于从位姿和接触数据中学习物体动力学和形状，使用接触感知的Fisher信息度量来评估和筛选数据。

Result: 基于信息度量的数据筛选能改进学习任务并使学习过程确定性化，较少但信息丰富的数据比更多数据更有效，能加速学习。

Conclusion: 接触感知的Fisher信息度量可为基于接触的机器人学习提供数据筛选指导，强调数据质量而非数量对学习的重要性。

Abstract: In this paper, we investigate the utility of datasets and whether more data
or the 'right' data is advantageous for robot learning. In particular, we are
interested on quantifying the utility of contact-based data as contact holds
significant information for robot learning. Our approach derives a
contact-aware objective function for learning object dynamics and shape from
pose and contact data. We show that the contact-aware Fisher-information metric
can be used to rank and curate contact-data based on how informative data is
for learning. In addition, we find that selecting a reduced dataset based on
this ranking improves the learning task while also making learning a
deterministic process. Interestingly, our results show that more data is not
necessarily advantageous, and rather, less but informative data can accelerate
learning, especially depending on the contact interactions. Last, we show how
our metric can be used to provide initial guidance on data curation for
contact-based robot learning.

</details>


### [8] [MoMaGen: Generating Demonstrations under Soft and Hard Constraints for Multi-Step Bimanual Mobile Manipulation](https://arxiv.org/abs/2510.18316)
*Chengshu Li,Mengdi Xu,Arpit Bahety,Hang Yin,Yunfan Jiang,Huang Huang,Josiah Wong,Sujay Garlanka,Cem Gokmen,Ruohan Zhang,Weiyu Liu,Jiajun Wu,Roberto Martín-Martín,Li Fei-Fei*

Main category: cs.RO

TL;DR: MoMaGen是一个用于多步骤双手移动操作的数据生成框架，通过约束优化解决基座放置和相机定位问题，显著提高数据多样性，仅需单次演示和少量真实世界演示即可训练成功的模仿学习策略。


<details>
  <summary>Details</summary>
Motivation: 大规模人类演示数据收集成本高且耗时，特别是在多步骤双手移动操作场景中。现有自动化数据生成方法在移动设置中存在基座放置和相机定位两个关键挑战。

Method: 将数据生成建模为约束优化问题，强制执行硬约束（如可达性）并平衡软约束（如导航期间的可见性），为未来方法提供理论基础。

Result: 在四个多步骤双手移动操作任务上评估，MoMaGen生成的数据集比现有方法多样性显著提高，仅需单次源演示即可训练成功策略，并通过40次真实世界演示微调即可在物理机器人上部署。

Conclusion: MoMaGen为多步骤双手移动操作提供了一种高效的数据生成方法，解决了基座放置和相机定位的关键挑战，显著减少了数据收集需求。

Abstract: Imitation learning from large-scale, diverse human demonstrations has proven
effective for training robots, but collecting such data is costly and
time-consuming. This challenge is amplified for multi-step bimanual mobile
manipulation, where humans must teleoperate both a mobile base and two
high-degree-of-freedom arms. Prior automated data generation frameworks have
addressed static bimanual manipulation by augmenting a few human demonstrations
in simulation, but they fall short for mobile settings due to two key
challenges: (1) determining base placement to ensure reachability, and (2)
positioning the camera to provide sufficient visibility for visuomotor
policies. To address these issues, we introduce MoMaGen, which formulates data
generation as a constrained optimization problem that enforces hard constraints
(e.g., reachability) while balancing soft constraints (e.g., visibility during
navigation). This formulation generalizes prior approaches and provides a
principled foundation for future methods. We evaluate MoMaGen on four
multi-step bimanual mobile manipulation tasks and show that it generates
significantly more diverse datasets than existing methods. Leveraging this
diversity, MoMaGen can train successful imitation learning policies from a
single source demonstration, and these policies can be fine-tuned with as few
as 40 real-world demonstrations to achieve deployment on physical robotic
hardware. More details are available at our project page: momagen.github.io.

</details>


### [9] [MoTVLA: A Vision-Language-Action Model with Unified Fast-Slow Reasoning](https://arxiv.org/abs/2510.18337)
*Wenhui Huang,Changhe Chen,Han Qi,Chen Lv,Yilun Du,Heng Yang*

Main category: cs.RO

TL;DR: MoTVLA是一个基于混合Transformer的视觉-语言-动作模型，通过集成快慢统一推理与行为策略学习，解决了现有方法在语言可控性和推理延迟方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临两个挑战：当不使用生成推理作为条件时语言可控性有限，或者当加入推理时推理延迟显著。需要一种既能保持预训练VLM通用智能又能提高策略执行效率的方法。

Method: MoTVLA采用混合Transformer架构，包含预训练VLM作为通用专家和领域专家Transformer。领域专家生成领域特定的快速推理（如机器人运动分解），动作专家基于分解的运动指令学习多样化行为。

Result: 在自然语言处理基准、机器人仿真环境和真实世界实验中的广泛评估证实了MoTVLA在快慢推理和操作任务性能方面的优越性。

Conclusion: MoTVLA通过集成快慢统一推理与行为策略学习，显著提高了语言可控性和策略执行效率，在多种评估场景中表现出色。

Abstract: Integrating visual-language instructions into visuomotor policies is gaining
momentum in robot learning for enhancing open-world generalization. Despite
promising advances, existing approaches face two challenges: limited language
steerability when no generated reasoning is used as a condition, or significant
inference latency when reasoning is incorporated.In this work, we introduce
MoTVLA, a mixture-of-transformers (MoT)-based vision-language-action (VLA)
model that integrates fast-slow unified reasoning with behavior policy
learning. MoTVLA preserves the general intelligence of pre-trained VLMs
(serving as the generalist) for tasks such as perception, scene understanding,
and semantic planning, while incorporating a domain expert, a second
transformer that shares knowledge with the pretrained VLM, to generate
domain-specific fast reasoning (e.g., robot motion decomposition), thereby
improving policy execution efficiency. By conditioning the action expert on
decomposed motion instructions, MoTVLA can learn diverse behaviors and
substantially improve language steerability. Extensive evaluations across
natural language processing benchmarks, robotic simulation environments, and
real-world experiments confirm the superiority of MoTVLA in both fast-slow
reasoning and manipulation task performance.

</details>


### [10] [Coverage-Recon: Coordinated Multi-Drone Image Sampling with Online Map Feedback](https://arxiv.org/abs/2510.18347)
*Muhammad Hanif,Reiji Terunuma,Takumi Sumino,Kelvin Cheng,Takeshi Hatanaka*

Main category: cs.RO

TL;DR: Coverage-Recon是一种多无人机协同3D地图重建算法，通过集成在线地图反馈来实时提高重建质量，使用QP角度感知覆盖控制器确保多视角图像采集，并通过NeuralRecon算法实时生成3D网格。


<details>
  <summary>Details</summary>
Motivation: 实现高质量3D重建需要从不同视角捕获关键点图像，而覆盖控制是满足这一需求的有效框架。实时3D重建算法的进步使得能够在飞行期间渲染演化地图，为无人机运动提供即时反馈。

Method: 提出Coverage-Recon协调图像采样算法，使用QP角度感知覆盖控制器协调无人机运动，确保多视角图像采集并强制执行安全约束。捕获的图像通过NeuralRecon算法实时处理生成3D网格，网格变化作为重建不确定性指标反馈给覆盖控制。

Result: 通过仿真和实验验证了Coverage-Recon的有效性，定性和定量结果表明，与传统方法相比，集成在线地图反馈能够产生更完整和准确的3D重建。

Conclusion: Coverage-Recon通过集成在线地图反馈成功提高了多无人机协同3D重建的质量，证明了实时反馈机制在覆盖控制中的重要性。

Abstract: This article addresses collaborative 3D map reconstruction using multiple
drones. Achieving high-quality reconstruction requires capturing images of
keypoints within the target scene from diverse viewing angles, and coverage
control offers an effective framework to meet this requirement. Meanwhile,
recent advances in real-time 3D reconstruction algorithms make it possible to
render an evolving map during flight, enabling immediate feedback to guide
drone motion. Building on this, we present Coverage-Recon, a novel coordinated
image sampling algorithm that integrates online map feedback to improve
reconstruction quality on-the-fly. In Coverage-Recon, the coordinated motion of
drones is governed by a Quadratic Programming (QP)-based angle-aware coverage
controller, which ensures multi-viewpoint image capture while enforcing safety
constraints. The captured images are processed in real time by the NeuralRecon
algorithm to generate an evolving 3D mesh. Mesh changes across the scene are
interpreted as indicators of reconstruction uncertainty and serve as feedback
to update the importance index of the coverage control as the map evolves. The
effectiveness of Coverage-Recon is validated through simulation and
experiments, demonstrating both qualitatively and quantitatively that
incorporating online map feedback yields more complete and accurate 3D
reconstructions than conventional methods. Project page:
https://htnk-lab.github.io/coverage-recon/

</details>


### [11] [PGTT: Phase-Guided Terrain Traversal for Perceptive Legged Locomotion](https://arxiv.org/abs/2510.18348)
*Alexandros Ntagkas,Chairi Kiourt,Konstantinos Chatzilygeroudis*

Main category: cs.RO

TL;DR: PGTT是一种感知感知的深度强化学习方法，通过奖励塑造而非动作先验来实施步态结构，在复杂地形上实现更鲁棒的四足机器人运动控制。


<details>
  <summary>Details</summary>
Motivation: 现有的感知强化学习控制器要么施加步态先验限制动作空间并降低跨形态适应性，要么"盲操作"难以预测后腿地形且对噪声脆弱。

Method: 使用三次Hermite样条编码每腿相位，根据局部高度图统计调整摆动高度，添加摆动相位接触惩罚，策略直接在关节空间操作支持形态无关部署。

Result: 在程序生成的楼梯状地形上训练，PGTT在推力扰动下成功率中位数提高7.5%，在离散障碍物上提高9%，收敛速度比端到端基线快约2倍。

Conclusion: 地形自适应、相位引导的奖励塑造是实现跨平台鲁棒感知运动的简单通用机制。

Abstract: State-of-the-art perceptive Reinforcement Learning controllers for legged
robots either (i) impose oscillator or IK-based gait priors that constrain the
action space, add bias to the policy optimization and reduce adaptability
across robot morphologies, or (ii) operate "blind", which struggle to
anticipate hind-leg terrain, and are brittle to noise. In this paper, we
propose Phase-Guided Terrain Traversal (PGTT), a perception-aware deep-RL
approach that overcomes these limitations by enforcing gait structure purely
through reward shaping, thereby reducing inductive bias in policy learning
compared to oscillator/IK-conditioned action priors. PGTT encodes per-leg phase
as a cubic Hermite spline that adapts swing height to local heightmap
statistics and adds a swing-phase contact penalty, while the policy acts
directly in joint space supporting morphology-agnostic deployment. Trained in
MuJoCo (MJX) on procedurally generated stair-like terrains with curriculum and
domain randomization, PGTT achieves the highest success under push disturbances
(median +7.5% vs. the next best method) and on discrete obstacles (+9%), with
comparable velocity tracking, and converging to an effective policy roughly 2x
faster than strong end-to-end baselines. We validate PGTT on a Unitree Go2
using a real-time LiDAR elevation-to-heightmap pipeline, and we report
preliminary results on ANYmal-C obtained with the same hyperparameters. These
findings indicate that terrain-adaptive, phase-guided reward shaping is a
simple and general mechanism for robust perceptive locomotion across platforms.

</details>


### [12] [MMRHP: A Miniature Mixed-Reality HIL Platform for Auditable Closed-Loop Evaluation](https://arxiv.org/abs/2510.18371)
*Mingxin Li,Haibo Hu,Jinghuai Deng,Yuchen Xi,Xinhong Chen,Jianping Wang*

Main category: cs.RO

TL;DR: 提出了MMRHP微型混合现实硬件在环平台，将自动驾驶系统测试从功能演示提升到严格、可重复的定量分析，支持SOTIF标准导向的系统性测试流程。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统验证需要在测试保真度、成本和可扩展性之间权衡。现有的微型HIL平台缺乏系统性框架支持严格定量分析，限制了其作为科学评估工具的价值。

Method: 提出三阶段测试流程面向SOTIF标准，设计实现以统一时空测量核心为中心的HIL平台，确保物理运动和系统时序的一致可追溯量化。

Result: 平台验证达到10.27毫米RMSE空间精度和约45毫秒稳定闭环延迟基线。Autoware案例研究发现40毫秒注入延迟时的关键性能悬崖。

Conclusion: 结构化流程与提供统一时空基准的平台相结合，能够实现自动驾驶系统可重复、可解释和定量的闭环评估。

Abstract: Validation of autonomous driving systems requires a trade-off between test
fidelity, cost, and scalability. While miniaturized hardware-in-the-loop (HIL)
platforms have emerged as a promising solution, a systematic framework
supporting rigorous quantitative analysis is generally lacking, limiting their
value as scientific evaluation tools. To address this challenge, we propose
MMRHP, a miniature mixed-reality HIL platform that elevates miniaturized
testing from functional demonstration to rigorous, reproducible quantitative
analysis. The core contributions are threefold. First, we propose a systematic
three-phase testing process oriented toward the Safety of the Intended
Functionality(SOTIF)standard, providing actionable guidance for identifying the
performance limits and triggering conditions of otherwise correctly functioning
systems. Second, we design and implement a HIL platform centered around a
unified spatiotemporal measurement core to support this process, ensuring
consistent and traceable quantification of physical motion and system timing.
Finally, we demonstrate the effectiveness of this solution through
comprehensive experiments. The platform itself was first validated, achieving a
spatial accuracy of 10.27 mm RMSE and a stable closed-loop latency baseline of
approximately 45 ms. Subsequently, an in-depth Autoware case study leveraged
this validated platform to quantify its performance baseline and identify a
critical performance cliff at an injected latency of 40 ms. This work shows
that a structured process, combined with a platform offering a unified
spatio-temporal benchmark, enables reproducible, interpretable, and
quantitative closed-loop evaluation of autonomous driving systems.

</details>


### [13] [Biomechanically consistent real-time action recognition for human-robot interaction](https://arxiv.org/abs/2510.18373)
*Wanchen Li,Kahina Chalabi,Sabbah Maxime,Thomas Bousquet,Robin Passama,Sofiane Ramdani,Andrea Cherubini,Vincent Bonnet*

Main category: cs.RO

TL;DR: 提出了一种基于标准2D摄像头的实时工业动作识别框架，使用生物力学先验（关节角度）而非传统关节中心位置，结合时间平滑的Transformer网络，在实时性能下达到88%准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多依赖关节中心位置且为离线处理，缺乏对传感器姿态、人体姿态和个体差异的鲁棒性，无法满足工业环境中的实时识别需求。

Method: 构建完整流水线：从2D摄像头估计人体关节运动学，输入到时间平滑的Transformer网络进行动作识别，使用生物力学先验（关节角度）替代传统关节中心位置。

Result: 在包含11名受试者的新数据集上评估，达到88%准确率，优于最佳基线模型，且对非面向摄像头的受试者具有良好的泛化能力。通过在线交互实验验证了技术的实用性。

Conclusion: 基于关节角度的方法具有传感器和姿态无关性、个体差异鲁棒性，在实时工业动作识别中表现出色，并通过机器人控制实验证明了实际应用价值。

Abstract: This paper presents a novel framework for real-time human action recognition
in industrial contexts, using standard 2D cameras. We introduce a complete
pipeline for robust and real-time estimation of human joint kinematics, input
to a temporally smoothed Transformer-based network, for action recognition. We
rely on a new dataset including 11 subjects performing various actions, to
evaluate our approach. Unlike most of the literature that relies on joint
center positions (JCP) and is offline, ours uses biomechanical prior, eg. joint
angles, for fast and robust real-time recognition. Besides, joint angles make
the proposed method agnostic to sensor and subject poses as well as to
anthropometric differences, and ensure robustness across environments and
subjects. Our proposed learning model outperforms the best baseline model,
running also in real-time, along various metrics. It achieves 88% accuracy and
shows great generalization ability, for subjects not facing the cameras.
Finally, we demonstrate the robustness and usefulness of our technique, through
an online interaction experiment, with a simulated robot controlled in
real-time via the recognized actions.

</details>


### [14] [MPC-based motion planning for non-holonomic systems in non-convex domains](https://arxiv.org/abs/2510.18402)
*Matthias Lorenzen,Teodoro Alamo,Martina Mammarella,Fabrizio Dabbene*

Main category: cs.RO

TL;DR: 提出了一种用于非完整系统和非凸约束的输出跟踪模型预测控制(MPC)方法，保证在现实假设下收敛到目标位置


<details>
  <summary>Details</summary>
Motivation: 现有MPC方法大多假设系统为完整系统且约束为凸的，而在自主移动机器人运动规划应用中，系统通常是非完整的且约束是非凸的，缺乏理论保证

Method: 设计了一种新颖的MPC公式，能够处理非完整系统和非凸约束，并保证收敛性

Result: 提出的MPC方法能够在相关现实场景中验证的假设下，保证收敛到期望目标

Conclusion: 该方法填补了非完整系统和非凸约束下输出跟踪MPC的理论空白，为自主移动机器人运动规划提供了理论保证

Abstract: Motivated by the application of using model predictive control (MPC) for
motion planning of autonomous mobile robots, a form of output tracking MPC for
non-holonomic systems and with non-convex constraints is studied. Although the
advantages of using MPC for motion planning have been demonstrated in several
papers, in most of the available fundamental literature on output tracking MPC
it is assumed, often implicitly, that the model is holonomic and generally the
state or output constraints must be convex. Thus, in application-oriented
publications, empirical results dominate and the topic of proving completeness,
in particular under which assumptions the target is always reached, has
received comparatively little attention. To address this gap, we present a
novel MPC formulation that guarantees convergence to the desired target under
realistic assumptions, which can be verified in relevant real-world scenarios.

</details>


### [15] [Efficient Model-Based Reinforcement Learning for Robot Control via Online Learning](https://arxiv.org/abs/2510.18518)
*Fang Nan,Hao Ma,Qinghua Guan,Josie Hughes,Michael Muehlebach,Marco Hutter*

Main category: cs.RO

TL;DR: 提出了一种基于模型的在线强化学习算法，可直接在真实世界中训练复杂机器人系统，相比模型无关方法显著提高了样本效率。


<details>
  <summary>Details</summary>
Motivation: 现有sim-to-real方法依赖大量离线仿真和模型无关策略优化，存在模拟数据偏差问题，难以直接在真实世界中高效学习。

Method: 从实时交互数据构建动力学模型，基于学习到的模型指导策略更新，采用在线学习分析推导次线性遗憾界。

Result: 在液压挖掘机臂和软体机器人臂上的实验表明，相比模型无关方法具有更强的样本效率，数小时内达到相当性能，并能适应动态变化。

Conclusion: 该方法为挑战性控制任务提供了高效可靠的机器人上学习途径。

Abstract: We present an online model-based reinforcement learning algorithm suitable
for controlling complex robotic systems directly in the real world. Unlike
prevailing sim-to-real pipelines that rely on extensive offline simulation and
model-free policy optimization, our method builds a dynamics model from
real-time interaction data and performs policy updates guided by the learned
dynamics model. This efficient model-based reinforcement learning scheme
significantly reduces the number of samples to train control policies, enabling
direct training on real-world rollout data. This significantly reduces the
influence of bias in the simulated data, and facilitates the search for
high-performance control policies. We adopt online learning analysis to derive
sublinear regret bounds under standard stochastic online optimization
assumptions, providing formal guarantees on performance improvement as more
interaction data are collected. Experimental evaluations were performed on a
hydraulic excavator arm and a soft robot arm, where the algorithm demonstrates
strong sample efficiency compared to model-free reinforcement learning methods,
reaching comparable performance within hours. Robust adaptation to shifting
dynamics was also observed when the payload condition was randomized. Our
approach paves the way toward efficient and reliable on-robot learning for a
broad class of challenging control tasks.

</details>


### [16] [EfficientNav: Towards On-Device Object-Goal Navigation with Navigation Map Caching and Retrieval](https://arxiv.org/abs/2510.18546)
*Zebin Yang,Sunjian Zheng,Tong Xie,Tianshi Xu,Bo Yu,Fan Wang,Jie Tang,Shaoshan Liu,Meng Li*

Main category: cs.RO

TL;DR: EfficientNav 是一种基于小型LLM的零样本物体导航方法，通过语义感知内存检索和离散内存缓存技术，在本地设备上实现高效导航，性能超越GPT-4基线。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的物体导航方法严重依赖云端大型模型如GPT-4，而直接切换到小型LLM会导致性能显著下降且延迟高，阻碍在本地设备上的部署。

Method: 提出语义感知内存检索来修剪导航图中的冗余信息，帮助小型LLM更好理解环境；使用离散内存缓存和基于注意力的内存聚类来高效保存和重用KV缓存以减少延迟。

Result: 在HM3D基准测试中，EfficientNav相比GPT-4基线实现了11.1%的成功率提升，实时延迟减少6.7倍，端到端延迟减少4.7倍。

Conclusion: EfficientNav成功实现了在本地设备上基于小型LLM的高效零样本物体导航，性能优于大型云端模型。

Abstract: Object-goal navigation (ObjNav) tasks an agent with navigating to the
location of a specific object in an unseen environment. Embodied agents
equipped with large language models (LLMs) and online constructed navigation
maps can perform ObjNav in a zero-shot manner. However, existing agents heavily
rely on giant LLMs on the cloud, e.g., GPT-4, while directly switching to small
LLMs, e.g., LLaMA3.2-11b, suffer from significant success rate drops due to
limited model capacity for understanding complex navigation maps, which
prevents deploying ObjNav on local devices. At the same time, the long prompt
introduced by the navigation map description will cause high planning latency
on local devices. In this paper, we propose EfficientNav to enable on-device
efficient LLM-based zero-shot ObjNav. To help the smaller LLMs better
understand the environment, we propose semantics-aware memory retrieval to
prune redundant information in navigation maps. To reduce planning latency, we
propose discrete memory caching and attention-based memory clustering to
efficiently save and re-use the KV cache. Extensive experimental results
demonstrate that EfficientNav achieves 11.1% improvement in success rate on
HM3D benchmark over GPT-4-based baselines, and demonstrates 6.7x real-time
latency reduction and 4.7x end-to-end latency reduction over GPT-4 planner. Our
code will be released soon.

</details>


### [17] [Flexbee: A Grasping and Perching UAV Based on Soft Vector-Propulsion Nozzle](https://arxiv.org/abs/2510.18558)
*Yue Wang,Lixian Zhang,Yimin Zhu,Yangguang Liu,Xuwei Yang*

Main category: cs.RO

TL;DR: Flexbee是一种新型的抓取和栖息无人机，采用软体矢量推进喷嘴集成飞行、抓取和栖息功能，具有解耦控制、高结构重用和强适应性等优势。


<details>
  <summary>Details</summary>
Motivation: 设计一种集飞行、抓取和栖息功能于一体的无人机，解决传统无人机在这些功能上的分离问题，提高结构效率和适应性。

Method: 开发了Flexbee的动力学模型，通过等效力矩模型的线性化解决非线性耦合问题，采用分层控制策略设计两种操作模式的控制器。

Result: 通过飞行、抓取和栖息实验验证了Flexbee的运动学能力和控制策略的有效性。

Conclusion: Flexbee成功实现了集成的飞行、抓取和栖息功能，证明了软体矢量推进喷嘴设计的可行性和控制策略的有效性。

Abstract: The aim of this paper is to design a new type of grasping and perching
unmanned aerial vehicle (UAV), called Flexbee, which features a soft
vector-propulsion nozzle (SVPN). Compared to previous UAVs, Flexbee integrates
flight, grasping, and perching functionalities into the four SVPNs. This
integration offers advantages including decoupled position and attitude
control, high structural reuse, and strong adaptability strong adaptability for
grasping and perching. A dynamics model of Flexbee has been developed, and the
nonlinear coupling issue of the moment has been resolved through linearization
of the equivalent moment model. A hierarchical control strategy was used to
design controllers for the two operational modes of Flexbee. Finally, flight,
grasping, and perching experiments were conducted to validate Flexbee's
kinematic capabilities and the effectiveness of the control strategy.

</details>


### [18] [Quadrupeds for Planetary Exploration: Field Testing Control Algorithms on an Active Volcano](https://arxiv.org/abs/2510.18600)
*Shubham Vyas,Franek Stark,Rohit Kumar,Hannah Isermann,Jonas Haack,Mihaela Popescu,Jakob Middelberg,Dennis Mronga,Frank Kirchner*

Main category: cs.RO

TL;DR: 在意大利武尔卡诺火山进行的四足机器人实地测试，验证了用于月球和火星表面模拟环境的新型自适应最优控制算法。


<details>
  <summary>Details</summary>
Motivation: 扩展行星探索任务的能力，通过腿式机器人穿越比轮式漫游车更困难的地形，如跳跃地面裂缝或在崎岖地形中行进。

Method: 在武尔卡诺火山进行实地实验，使用四足机器人测试新开发的自适应最优控制算法，包括技术方法、测试计划、软件架构和部署策略。

Result: 成功在月球和火星表面高保真模拟环境中验证了四足运动的自适应最优控制算法。

Conclusion: 腿式机器人能够显著提升未来行星探索任务的覆盖范围和能力，特别是在困难地形中的移动性能。

Abstract: Missions such as the Ingenuity helicopter have shown the advantages of using
novel locomotion modes to increase the scientific return of planetary
exploration missions. Legged robots can further expand the reach and capability
of future planetary missions by traversing more difficult terrain than wheeled
rovers, such as jumping over cracks on the ground or traversing rugged terrain
with boulders. To develop and test algorithms for using quadruped robots, the
AAPLE project was carried out at DFKI. As part of the project, we conducted a
series of field experiments on the Volcano on the Aeolian island of Vulcano, an
active stratovolcano near Sicily, Italy. The experiments focused on validating
newly developed state-of-the-art adaptive optimal control algorithms for
quadrupedal locomotion in a high-fidelity analog environment for Lunar and
Martian surfaces. This paper presents the technical approach, test plan,
software architecture, field deployment strategy, and evaluation results from
the Vulcano campaign.

</details>


### [19] [A Compositional Paradigm for Foundation Models: Towards Smarter Robotic Agents](https://arxiv.org/abs/2510.18608)
*Luigi Quarantiello,Elia Piccoli,Jack Bell,Malio Li,Giacomo Carfì,Eric Nuertey Coleman,Gerlando Gramaglia,Lanpei Li,Mauro Madeddu,Irene Testa,Vincenzo Lomonaco*

Main category: cs.RO

TL;DR: 应用持续学习和组合性原则来增强基础模型的适应性和灵活性


<details>
  <summary>Details</summary>
Motivation: 基础模型在处理动态现实场景时存在适应性问题，需要重新训练整个模型

Method: 提出将持续学习和组合性原则应用于基础模型开发

Result: 未在摘要中明确说明具体结果

Conclusion: 持续学习和组合性原则有助于开发更灵活、高效和智能的AI解决方案

Abstract: The birth of Foundation Models brought unprecedented results in a wide range
of tasks, from language to vision, to robotic control. These models are able to
process huge quantities of data, and can extract and develop rich
representations, which can be employed across different domains and modalities.
However, they still have issues in adapting to dynamic, real-world scenarios
without retraining the entire model from scratch. In this work, we propose the
application of Continual Learning and Compositionality principles to foster the
development of more flexible, efficient and smart AI solutions.

</details>


### [20] [Least Restrictive Hyperplane Control Barrier Functions](https://arxiv.org/abs/2510.18643)
*Mattias Trende,Petter Ögren*

Main category: cs.RO

TL;DR: 提出了一种优化控制屏障函数(CBF)和控制动作的方法，通过同时优化CBF和安全控制来最小化对期望控制的限制，同时保持安全保证。


<details>
  <summary>Details</summary>
Motivation: 传统CBF方法在处理复杂形状不安全区域时往往需要保守近似，这会过度限制控制动作。本文旨在减少这种保守性，让系统在保证安全的同时尽可能接近期望控制。

Method: 提出最小限制超平面CBF方法，通过优化CBF和控制动作的组合，使系统控制尽可能接近期望控制。提供了CBF族的光滑参数化方法，并在带加速度约束的双积分器系统上验证。

Result: 该方法能够在保证安全的同时，显著减少对控制动作的限制，使系统能够更接近期望的行为轨迹。

Conclusion: 通过同时优化CBF和控制动作，可以设计出既保证安全又最小化限制的控制策略，特别适用于处理复杂形状障碍物的情况。

Abstract: Control Barrier Functions (CBFs) can provide provable safety guarantees for
dynamic systems. However, finding a valid CBF for a system of interest is often
non-trivial, especially if the shape of the unsafe region is complex and the
CBFs are of higher order. A common solution to this problem is to make a
conservative approximation of the unsafe region in the form of a
line/hyperplane, and use the corresponding conservative Hyperplane-CBF when
deciding on safe control actions. In this letter, we note that conservative
constraints are only a problem if they prevent us from doing what we want.
Thus, instead of first choosing a CBF and then choosing a safe control with
respect to the CBF, we optimize over a combination of CBFs and safe controls to
get as close as possible to our desired control, while still having the safety
guarantee provided by the CBF. We call the corresponding CBF the least
restrictive Hyperplane-CBF. Finally, we also provide a way of creating a smooth
parameterization of the CBF-family for the optimization, and illustrate the
approach on a double integrator dynamical system with acceleration constraints,
moving through a group of arbitrarily shaped static and moving obstacles.

</details>


### [21] [Towards An Adaptive Locomotion Strategy For Quadruped Rovers: Quantifying When To Slide Or Walk On Planetary Slopes](https://arxiv.org/abs/2510.18678)
*Alberto Sanchez-Delgado,João Carlos Virgolino Soares,David Omar Al Tawil,Alessia Li Noce,Matteo Villa,Victor Barasuol,Paolo Arena,Claudio Semini*

Main category: cs.RO

TL;DR: 比较四足机器人在不同坡度、摩擦条件和速度下的行走与躯干滑动运动的运输成本，旨在确定两种策略之间的转换阈值条件。


<details>
  <summary>Details</summary>
Motivation: 传统腿式运动在松散和倾斜的星球表面（如陨石坑壁和洞穴斜坡）可能能量效率低下且对漫游车危险，需要更高效的自适应运动策略。

Method: 结合Isaac Sim中的物理模拟和ANSYS-Rocky中的粒子交互验证，分析行走与滑动运动的运输成本曲线。

Result: 通过识别行走和滑动运输成本曲线的交点，定义了触发两种策略转换的阈值条件。

Conclusion: 这项研究代表了向行星腿式漫游车自适应运动策略发展的初步步骤。

Abstract: Legged rovers provide enhanced mobility compared to wheeled platforms,
enabling navigation on steep and irregular planetary terrains. However,
traditional legged locomotion might be energetically inefficient and
potentially dangerous to the rover on loose and inclined surfaces, such as
crater walls and cave slopes. This paper introduces a preliminary study that
compares the Cost of Transport (CoT) of walking and torso-based sliding
locomotion for quadruped robots across different slopes, friction conditions
and speed levels. By identifying intersections between walking and sliding CoT
curves, we aim to define threshold conditions that may trigger transitions
between the two strategies. The methodology combines physics-based simulations
in Isaac Sim with particle interaction validation in ANSYS-Rocky. Our results
represent an initial step towards adaptive locomotion strategies for planetary
legged rovers.

</details>


### [22] [Event-Grounding Graph: Unified Spatio-Temporal Scene Graph from Robotic Observations](https://arxiv.org/abs/2510.18697)
*Phuoc Nguyen,Francesco Verdoja,Ville Kyrki*

Main category: cs.RO

TL;DR: 提出了事件接地图（EGG）框架，将事件交互与场景空间特征连接起来，使机器人能够感知、推理和响应复杂的时空查询。


<details>
  <summary>Details</summary>
Motivation: 当前语义场景表示方法缺乏空间特征与动态事件之间的连接，限制了机器人对环境理解的完整性。

Method: 开发事件接地图框架，将事件交互接地到场景的空间特征上，支持复杂的时空查询处理。

Result: 在真实机器人数据上的实验表明，EGG能够检索相关信息并准确响应有关环境和事件的人类查询。

Conclusion: EGG框架成功连接了空间特征和动态事件，提升了机器人的环境理解和交互能力，代码和数据集已开源。

Abstract: A fundamental aspect for building intelligent autonomous robots that can
assist humans in their daily lives is the construction of rich environmental
representations. While advances in semantic scene representations have enriched
robotic scene understanding, current approaches lack a connection between
spatial features and dynamic events; e.g., connecting the blue mug to the event
washing a mug. In this work, we introduce the event-grounding graph (EGG), a
framework grounding event interactions to spatial features of a scene. This
representation allows robots to perceive, reason, and respond to complex
spatio-temporal queries. Experiments using real robotic data demonstrate EGG's
capability to retrieve relevant information and respond accurately to human
inquiries concerning the environment and events within. Furthermore, the EGG
framework's source code and evaluation dataset are released as open-source at:
https://github.com/aalto-intelligent-robotics/EGG.

</details>


### [23] [Sharing the Load: Distributed Model-Predictive Control for Precise Multi-Rover Cargo Transport](https://arxiv.org/abs/2510.18766)
*Alexander Krawciw,Sven Lilge,Luka Antonyshyn,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 开发了用于多车辆货物运输的分布式模型预测控制器，通过共享地图实现车辆间精确定位，无需GPS或直接观测，在10公里测试中保持20厘米内的间距精度。


<details>
  <summary>Details</summary>
Motivation: 自主货物运输中，多机器人车队比单个大型机器人更具操作灵活性，需要精确的车辆间距和路径跟踪能力。

Method: 基于激光雷达教学重复的精确路径跟踪，开发分布式MPC控制器，使用共享地图进行车辆间相对定位。

Result: 分布式MPC与集中式MPC性能相当，在2-3辆车的车队测试中，能在各种条件下实时保持20厘米内的目标间距。

Conclusion: 分布式计算方法提供了操作灵活性，适合实际部署，能有效支持多车辆货物运输任务。

Abstract: For autonomous cargo transportation, teams of mobile robots can provide more
operational flexibility than a single large robot. In these scenarios,
precision in both inter-vehicle distance and path tracking is key. With this
motivation, we develop a distributed model-predictive controller (MPC) for
multi-vehicle cargo operations that builds on the precise path-tracking of
lidar teach and repeat. To carry cargo, a following vehicle must maintain a
Euclidean distance offset from a lead vehicle regardless of the path curvature.
Our approach uses a shared map to localize the robots relative to each other
without GNSS or direct observations. We compare our approach to a centralized
MPC and a baseline approach that directly measures the inter-vehicle distance.
The distributed MPC shows equivalent nominal performance to the more complex
centralized MPC. Using a direct measurement of the relative distance between
the leader and follower shows improved tracking performance in close-range
scenarios but struggles with long-range offsets. The operational flexibility
provided by distributing the computation makes it well suited for real
deployments. We evaluate four types of convoyed path trackers with over 10 km
of driving in a coupled convoy. With convoys of two and three rovers, the
proposed distributed MPC method works in real-time to allow map-based convoying
to maintain maximum spacing within 20 cm of the target in various conditions.

</details>


### [24] [Online Object-Level Semantic Mapping for Quadrupeds in Real-World Environments](https://arxiv.org/abs/2510.18776)
*Emad Razavi,Angelo Bratta,João Carlos Virgolino Soares,Carmine Recchiuto,Claudio Semini*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人的在线语义对象映射系统，能够在真实室内环境中将传感器检测转换为全局地图中的命名对象。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在机器人运行过程中实时构建语义对象地图的系统，使机器人能够持续跟踪和管理环境中的对象实例。

Method: 集成距离几何与相机检测，在帧内合并共位检测，并在帧间将重复检测关联到持久对象实例。对象在视野外时仍保留在地图中，重复观测更新同一实例而非创建重复项。

Result: 系统输出一个紧凑的对象层，可查询类别、姿态和置信度，与占据地图集成且可供规划器读取。在机器人测试中，该层在不同视角变化下保持稳定。

Conclusion: 该系统成功实现了在真实室内环境中为四足机器人构建稳定、持久的语义对象地图，支持机器人的长期环境感知和规划任务。

Abstract: We present an online semantic object mapping system for a quadruped robot
operating in real indoor environments, turning sensor detections into named
objects in a global map. During a run, the mapper integrates range geometry
with camera detections, merges co-located detections within a frame, and
associates repeated detections into persistent object instances across frames.
Objects remain in the map when they are out of view, and repeated sightings
update the same instance rather than creating duplicates. The output is a
compact object layer that can be queried (class, pose, and confidence), is
integrated with the occupancy map and readable by a planner. In on-robot tests,
the layer remained stable across viewpoint changes.

</details>


### [25] [MADR: MPC-guided Adversarial DeepReach](https://arxiv.org/abs/2510.18845)
*Ryan Teoh,Sander Tonkens,William Sharpless,Aijia Yang,Zeyuan Feng,Somil Bansal,Sylvia Herbert*

Main category: cs.RO

TL;DR: 提出了MADR框架，通过结合MPC指导来近似双人零和微分博弈的值函数，解决了传统HJ可达性方法的维度灾难问题，在多种高维机器人系统中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统HJ可达性方法面临维度灾难，而物理信息深度学习虽然能克服这一问题，但存在收敛慢、精度低的问题。现有方法仅限于单玩家问题和简单博弈，需要扩展至更复杂的双人零和博弈场景。

Method: MADR框架结合MPC指导与对抗性深度学习方法，通过丰富自监督过程的正则监督来加速收敛，能够鲁棒地近似双人零和微分博弈的值函数。

Result: 在多种高维模拟和真实机器人系统上测试，MADR显著优于现有最优基线方法，在仿真和硬件实验中均取得优异结果。

Conclusion: MADR为双人零和微分博弈提供了一种有效的值函数近似框架，能够生成最优策略和最坏情况下的鲁棒安全策略，在高维机器人系统中具有实际应用价值。

Abstract: Hamilton-Jacobi (HJ) Reachability offers a framework for generating safe
value functions and policies in the face of adversarial disturbance, but is
limited by the curse of dimensionality. Physics-informed deep learning is able
to overcome this infeasibility, but itself suffers from slow and inaccurate
convergence, primarily due to weak PDE gradients and the complexity of
self-supervised learning. A few works, recently, have demonstrated that
enriching the self-supervision process with regular supervision (based on the
nature of the optimal control problem), greatly accelerates convergence and
solution quality, however, these have been limited to single player problems
and simple games. In this work, we introduce MADR: MPC-guided Adversarial
DeepReach, a general framework to robustly approximate the two-player, zero-sum
differential game value function. In doing so, MADR yields the corresponding
optimal strategies for both players in zero-sum games as well as safe policies
for worst-case robustness. We test MADR on a multitude of high-dimensional
simulated and real robotic agents with varying dynamics and games, finding that
our approach significantly out-performs state-of-the-art baselines in
simulation and produces impressive results in hardware.

</details>
