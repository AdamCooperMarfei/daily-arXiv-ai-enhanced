<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 20]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Self-Organizing Aerial Swarm Robotics for Resilient Load Transportation : A Table-Mechanics-Inspired Approach](https://arxiv.org/abs/2509.03563)
*Quan Quan,Jiwen Xu,Runxiao Liu,Yi Ding,Jiaxing Che,Kai-Yuan Cai*

Main category: cs.RO

TL;DR: 基于物理温度的分布式力模型，通过模仿桌腿负荷分配机制，实现了无需显式通信的自主形成稳定和适应性负荷分配


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在可扩展性、通信依赖性和动态故障耐受性方面的挑战，为物流和灾难响应领域提供变革性解决方案

Method: 发展分布式耗散力模型，模仿桌腿负荷分配机制，每个机器人根据邻居机器人和悬挂负荷动态调整位置

Result: 模拟显示跟踪错误仅为现有方法的20%-68%，实验中6台飞行机器人实现94%成功率，在单机故障、连接中断、25%负荷变化和40%绳长不确定性下保持强壁性

Conclusion: 该物理受启发方法垩接了群智能与机械稳定性原理，为异构空中系统提供了可扩展框架，能在通信受限环境中集体处理复杂运输任务

Abstract: In comparison with existing approaches, which struggle with scalability,
communication dependency, and robustness against dynamic failures, cooperative
aerial transportation via robot swarms holds transformative potential for
logistics and disaster response. Here, we present a physics-inspired
cooperative transportation approach for flying robot swarms that imitates the
dissipative mechanics of table-leg load distribution. By developing a
decentralized dissipative force model, our approach enables autonomous
formation stabilization and adaptive load allocation without the requirement of
explicit communication. Based on local neighbor robots and the suspended
payload, each robot dynamically adjusts its position. This is similar to
energy-dissipating table leg reactions. The stability of the resultant control
system is rigorously proved. Simulations demonstrate that the tracking errors
of the proposed approach are 20%, 68%, 55.5%, and 21.9% of existing approaches
under the cases of capability variation, cable uncertainty, limited vision, and
payload variation, respectively. In real-world experiments with six flying
robots, the cooperative aerial transportation system achieved a 94% success
rate under single-robot failure, disconnection events, 25% payload variation,
and 40% cable length uncertainty, demonstrating strong robustness under outdoor
winds up to Beaufort scale 4. Overall, this physics-inspired approach bridges
swarm intelligence and mechanical stability principles, offering a scalable
framework for heterogeneous aerial systems to collectively handle complex
transportation tasks in communication-constrained environments.

</details>


### [2] [Cooperative Grasping for Collective Object Transport in Constrained Environments](https://arxiv.org/abs/2509.03638)
*David Alvear,George Turkiyyah,Shinkyu Park*

Main category: cs.RO

TL;DR: 一种基于条件嵌入模型的新颖框架，用于两台机器人在约束环境中协作抓取物体运输的决策制定


<details>
  <summary>Details</summary>
Motivation: 解决两台机器人在空间约束环境中协同抓取和运输物体时的可行性判断问题，提高协作抓取的可靠性和适用性

Method: 使用两个神经网络构成的条件嵌入(CE)模型，将抓取配置信息映射到嵌入空间，通过负样本监督学习训练区分可行和不可行抓取配置

Result: 模型在幻算中在广泛环境和物体上能够可靠识别可行抓取配置，并通过物理机器人平台实验验证了其实际应用性

Conclusion: 该框架能够有效地解决协作抓取运输的决策问题，具有良好的通用性和实际应用价值

Abstract: We propose a novel framework for decision-making in cooperative grasping for
two-robot object transport in constrained environments. The core of the
framework is a Conditional Embedding (CE) model consisting of two neural
networks that map grasp configuration information into an embedding space. The
resulting embedding vectors are then used to identify feasible grasp
configurations that allow two robots to collaboratively transport an object. To
ensure generalizability across diverse environments and object geometries, the
neural networks are trained on a dataset comprising a range of environment maps
and object shapes. We employ a supervised learning approach with negative
sampling to ensure that the learned embeddings effectively distinguish between
feasible and infeasible grasp configurations. Evaluation results across a wide
range of environments and objects in simulations demonstrate the model's
ability to reliably identify feasible grasp configurations. We further validate
the framework through experiments on a physical robotic platform, confirming
its practical applicability.

</details>


### [3] [Efficient Virtuoso: A Latent Diffusion Transformer Model for Goal-Conditioned Trajectory Planning](https://arxiv.org/abs/2509.03658)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: Efficient Virtuoso是一个基于条件潜在扩散模型的轨迹规划方法，通过两阶段归一化管道和低维潜在空间去噪，在Waymo数据集上达到0.25 minADE的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶规划系统中生成多样化、合理未来轨迹的挑战，需要同时实现高保真度、计算效率和精确控制。

Method: 提出条件潜在扩散模型，采用两阶段归一化管道：先缩放轨迹保持几何纵横比，再对PCA潜在空间归一化；使用MLP去噪器和基于Transformer的状态编码器融合场景上下文。

Result: 在Waymo Open Motion Dataset上达到state-of-the-art性能，minADE为0.25；通过消融研究发现多步稀疏路径比单端点目标能实现更精确的战术执行。

Conclusion: 多步稀疏路径表示对于实现精确、高保真度的战术执行至关重要，能够更好地模拟人类驾驶的细微行为。

Abstract: The ability to generate a diverse and plausible distribution of future
trajectories is a critical capability for autonomous vehicle planning systems.
While recent generative models have shown promise, achieving high fidelity,
computational efficiency, and precise control remains a significant challenge.
In this paper, we present the \textbf{Efficient Virtuoso}, a conditional latent
diffusion model for goal-conditioned trajectory planning. Our approach
introduces a novel two-stage normalization pipeline that first scales
trajectories to preserve their geometric aspect ratio and then normalizes the
resulting PCA latent space to ensure a stable training target. The denoising
process is performed efficiently in this low-dimensional latent space by a
simple MLP denoiser, which is conditioned on a rich scene context fused by a
powerful Transformer-based StateEncoder. We demonstrate that our method
achieves state-of-the-art performance on the Waymo Open Motion Dataset,
reaching a \textbf{minADE of 0.25}. Furthermore, through a rigorous ablation
study on goal representation, we provide a key insight: while a single endpoint
goal can resolve strategic ambiguity, a richer, multi-step sparse route is
essential for enabling the precise, high-fidelity tactical execution that
mirrors nuanced human driving behavior.

</details>


### [4] [Low-Cost Open-Source Ambidextrous Robotic Hand with 23 Direct-Drive servos for American Sign Language Alphabet](https://arxiv.org/abs/2509.03690)
*Kelvin Daniel Gonzalez Amador*

Main category: cs.RO

TL;DR: VulcanV3是一个低成本、开源、3D打印的双手机器人手，能够完整重现美国手语字母表（52个手势），具有96.97%的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 为聋人社区提供可访问的手语交流解决方案，现有机器人方案成本高且功能有限。

Method: 使用23个直接驱动伺服执行器实现精确的手指和手腕运动，由Arduino Mega和双PCA9685模块控制，采用可逆设计。

Result: 经验测试确认了所有52个ASL手形的准确重现，参与者研究（n=33）达到96.97%的识别准确率，视频演示后提升至98.78%。

Conclusion: VulcanV3通过结合经济性、完整的ASL覆盖和双手灵巧性，在开放共享平台上推进了辅助机器人技术，为无障碍通信技术和包容性创新做出贡献。

Abstract: Accessible communication through sign language is vital for deaf communities,
1 yet robotic solutions are often costly and limited. This study presents
VulcanV3, a low- 2 cost, open-source, 3D-printed ambidextrous robotic hand
capable of reproducing the full 3 American Sign Language (ASL) alphabet (52
signs for right- and left-hand configurations). 4 The system employs 23
direct-drive servo actuators for precise finger and wrist movements, 5
controlled by an Arduino Mega with dual PCA9685 modules. Unlike most humanoid
upper- 6 limb systems, which rarely employ direct-drive actuation, VulcanV3
achieves complete ASL 7 coverage with a reversible design. All CAD files and
code are released under permissive 8 open-source licenses to enable
replication. Empirical tests confirmed accurate reproduction 9 of all 52 ASL
handshapes, while a participant study (n = 33) achieved 96.97% recognition 10
accuracy, improving to 98.78% after video demonstration. VulcanV3 advances
assistive 11 robotics by combining affordability, full ASL coverage, and
ambidexterity in an openly 12 shared platform, contributing to accessible
communication technologies and inclusive 13 innovation.

</details>


### [5] [Real-Time Buoyancy Estimation for AUV Simulations Using Convex Hull-Based Submerged Volume Calculation](https://arxiv.org/abs/2509.03804)
*Ad-Deen Mahbub,Md Ragib Shaharear*

Main category: cs.RO

TL;DR: 基于凸包算法的实时浮力模型，为NVIDIA Isaac Sim水下模拟提供精确的浮力计算


<details>
  <summary>Details</summary>
Motivation: NVIDIA Isaac Sim缺乏原生浮力系统，需要外部解决方案来实现精确的水下物理模拟

Method: 通过提取模拟环境中的网格几何，使用凸包算法动态计算AUV的沉水体积，采用截面积扩展降低计算开销

Result: 方法能够在实时性能下适应位置、深度和正弦波动(±0.3m)，提高了SAUVC 2025客制AUV设计的模拟保真度

Conclusion: 该方法为水下机器人研究提供了不依赖预计算水动力学模型的高保真度模拟方案，具有实时性能和可扩展性

Abstract: Accurate real-time buoyancy modeling is essential for high-fidelity
Autonomous Underwater Vehicle (AUV) simulations, yet NVIDIA Isaac Sim lacks a
native buoyancy system, requiring external solutions for precise underwater
physics. This paper presents a novel convex hull-based approach to dynamically
compute the submerged volume of an AUV in real time. By extracting mesh
geometry from the simulation environment and calculating the hull portion
intersecting the water level along the z-axis, our method enhances accuracy
over traditional geometric approximations. A cross-sectional area extension
reduces computational overhead, enabling efficient buoyant force updates that
adapt to orientation, depth, and sinusoidal wave fluctuations (+-0.3 m). Tested
on a custom AUV design for SAUVC 2025, this approach delivers real-time
performance and scalability, improving simulation fidelity for underwater
robotics research without precomputed hydrodynamic models.

</details>


### [6] [INGRID: Intelligent Generative Robotic Design Using Large Language Models](https://arxiv.org/abs/2509.03842)
*Guanglu Jia,Ceng Zhang,Gregory S. Chirikjian*

Main category: cs.RO

TL;DR: INGRID是一个通过深度集成互易螺旋理论和运动学综合方法来自动设计并联机器人机构的框架，能够生成具有固定和可变自由度的新型并联机构，突破了现有串行机构的硬件限制。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的机器人系统仍受限于现有的串行机器人架构，这种硬件依赖性从根本上限制了机器人智能的发展范围。

Method: 将设计挑战分解为四个渐进任务：约束分析、运动关节生成、链构建和完整机构设计，结合互易螺旋理论和运动学综合方法。

Result: INGRID能够生成文献中未记载的新型并联机构，通过三个案例研究验证了其基于所需自由度要求帮助用户设计任务特定并联机器人的能力。

Conclusion: 该工作建立了机构智能的基础，使AI系统能够主动设计机器人硬件，有望改变具身AI系统的开发方式，将机器人智能进步与硬件约束解耦。

Abstract: The integration of large language models (LLMs) into robotic systems has
accelerated progress in embodied artificial intelligence, yet current
approaches remain constrained by existing robotic architectures, particularly
serial mechanisms. This hardware dependency fundamentally limits the scope of
robotic intelligence. Here, we present INGRID (Intelligent Generative Robotic
Design), a framework that enables the automated design of parallel robotic
mechanisms through deep integration with reciprocal screw theory and kinematic
synthesis methods. We decompose the design challenge into four progressive
tasks: constraint analysis, kinematic joint generation, chain construction, and
complete mechanism design. INGRID demonstrates the ability to generate novel
parallel mechanisms with both fixed and variable mobility, discovering
kinematic configurations not previously documented in the literature. We
validate our approach through three case studies demonstrating how INGRID
assists users in designing task-specific parallel robots based on desired
mobility requirements. By bridging the gap between mechanism theory and machine
learning, INGRID enables researchers without specialized robotics training to
create custom parallel mechanisms, thereby decoupling advances in robotic
intelligence from hardware constraints. This work establishes a foundation for
mechanism intelligence, where AI systems actively design robotic hardware,
potentially transforming the development of embodied AI systems.

</details>


### [7] [Learning Multi-Stage Pick-and-Place with a Legged Mobile Manipulator](https://arxiv.org/abs/2509.03859)
*Haichao Zhang,Haonan Yu,Le Zhao,Andrew Choi,Qinxun Bai,Yiqing Yang,Wei Xu*

Main category: cs.RO

TL;DR: 提出了一种在仿真中训练视觉运动策略的方法，用于四足机器人移动抓取任务，在真实世界中达到近80%的成功率，能够执行搜索、接近、抓取、运输和放置等完整操作链。


<details>
  <summary>Details</summary>
Motivation: 四足机器人移动操作面临技能多样性、长任务周期和部分可观测性等挑战，需要开发能够在仿真中训练并有效迁移到真实世界的策略。

Method: 使用多阶段拾取放置任务作为测试平台，在仿真中训练端到端的视觉运动策略，通过关键技术实现高效的仿真到真实迁移。

Result: 在真实世界中达到近80%的成功率，策略能够表现出重新抓取和任务链等涌现行为，并在各种室内外环境中成功部署。

Conclusion: 该方法证明了在仿真中训练复杂移动操作策略的可行性，并通过有效的sim-to-real技术实现了高性能的真实世界部署。

Abstract: Quadruped-based mobile manipulation presents significant challenges in
robotics due to the diversity of required skills, the extended task horizon,
and partial observability. After presenting a multi-stage pick-and-place task
as a succinct yet sufficiently rich setup that captures key desiderata for
quadruped-based mobile manipulation, we propose an approach that can train a
visuo-motor policy entirely in simulation, and achieve nearly 80\% success in
the real world. The policy efficiently performs search, approach, grasp,
transport, and drop into actions, with emerged behaviors such as re-grasping
and task chaining. We conduct an extensive set of real-world experiments with
ablation studies highlighting key techniques for efficient training and
effective sim-to-real transfer. Additional experiments demonstrate deployment
across a variety of indoor and outdoor environments. Demo videos and additional
resources are available on the project page:
https://horizonrobotics.github.io/gail/SLIM.

</details>


### [8] [Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance](https://arxiv.org/abs/2509.03889)
*Neha Sunil,Megha Tippur,Arnau Saumell,Edward Adelson,Alberto Rodriguez*

Main category: cs.RO

TL;DR: 一种结合视觉和触觉的双臂框架，通过信心度感知和触觉监督的抓取支撑来操作混乱和悬挂的服装


<details>
  <summary>Details</summary>
Motivation: 服装操作面临复杂配置、变化材料动态和频繁自聊的挑战，之前系统多假设服装平坠或关键特征可见

Method: 使用分布损失在高保真模拟数据集训练符合衣物对称性的密集对应模型，结合触觉监督的抓取支撑网络和反应式状态机

Result: 系统能够处理高度遮挡的桌面和空中配置，在折叠和悬挂任务中展示任务无关的抓取选择能力

Conclusion: 密集描述符为其他规划模态提供了可重用的中间表示，为更具普遍性和可扩展的服装操作排除了道路

Abstract: Manipulating clothing is challenging due to complex configurations, variable
material dynamics, and frequent self-occlusion. Prior systems often flatten
garments or assume visibility of key features. We present a dual-arm
visuotactile framework that combines confidence-aware dense visual
correspondence and tactile-supervised grasp affordance to operate directly on
crumpled and suspended garments. The correspondence model is trained on a
custom, high-fidelity simulated dataset using a distributional loss that
captures cloth symmetries and generates correspondence confidence estimates.
These estimates guide a reactive state machine that adapts folding strategies
based on perceptual uncertainty. In parallel, a visuotactile grasp affordance
network, self-supervised using high-resolution tactile feedback, determines
which regions are physically graspable. The same tactile classifier is used
during execution for real-time grasp validation. By deferring action in
low-confidence states, the system handles highly occluded table-top and in-air
configurations. We demonstrate our task-agnostic grasp selection module in
folding and hanging tasks. Moreover, our dense descriptors provide a reusable
intermediate representation for other planning modalities, such as extracting
grasp targets from human video demonstrations, paving the way for more
generalizable and scalable garment manipulation.

</details>


### [9] [Odometry Calibration and Pose Estimation of a 4WIS4WID Mobile Wall Climbing Robot](https://arxiv.org/abs/2509.04016)
*Branimir Ćaran,Vladimir Milić,Marko Švaco,Bojan Jerbić*

Main category: cs.RO

TL;DR: 提出基于EKF和UKF的多模态测量融合姿态估计器，用于4WIS4WID爬墙机器人，解决建筑环境中传统定位传感器不可用的问题


<details>
  <summary>Details</summary>
Motivation: 爬墙机器人在建筑环境中需要精确定位来携带测量设备和维护工具，但由于建筑立面的复杂几何和材料特性，传统定位传感器（激光、超声波、雷达）不可行，GPS也因信号衰减不可靠，机器人里程计成为主要位置信息来源但存在漂移问题

Method: 使用扩展卡尔曼滤波(EKF)和无迹卡尔曼滤波(UKF)融合车轮里程计、视觉里程计和IMU数据；采用非线性优化和Levenberg-Marquardt方法进行系统参数校准，使用遗传算法和粒子群算法进行运动学参数校准

Result: 在实验性爬墙移动机器人上详细验证了校准方法和姿态估计器的性能和结果

Conclusion: 提出的多模态测量融合方法为爬墙机器人提供了可靠的姿态估计解决方案，解决了建筑环境中传统定位技术受限的问题

Abstract: This paper presents the design of a pose estimator for a four wheel
independent steer four wheel independent drive (4WIS4WID) wall climbing mobile
robot, based on the fusion of multimodal measurements, including wheel
odometry, visual odometry, and an inertial measurement unit (IMU) data using
Extended Kalman Filter (EKF) and Unscented Kalman Filter (UKF). The pose
estimator is a critical component of wall climbing mobile robots, as their
operational environment involves carrying precise measurement equipment and
maintenance tools in construction, requiring information about pose on the
building at the time of measurement. Due to the complex geometry and material
properties of building facades, the use of traditional localization sensors
such as laser, ultrasonic, or radar is often infeasible for wall-climbing
robots. Moreover, GPS-based localization is generally unreliable in these
environments because of signal degradation caused by reinforced concrete and
electromagnetic interference. Consequently, robot odometry remains the primary
source of velocity and position information, despite being susceptible to drift
caused by both systematic and non-systematic errors. The calibrations of the
robot's systematic parameters were conducted using nonlinear optimization and
Levenberg-Marquardt methods as Newton-Gauss and gradient-based model fitting
methods, while Genetic algorithm and Particle swarm were used as
stochastic-based methods for kinematic parameter calibration. Performance and
results of the calibration methods and pose estimators were validated in detail
with experiments on the experimental mobile wall climbing robot.

</details>


### [10] [FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction](https://arxiv.org/abs/2509.04018)
*Yifan Yang,Zhixiang Duan,Tianshi Xie,Fuyu Cao,Pinxi Shen,Peili Song,Piaopiao Jin,Guokang Sun,Shaoqing Xu,Yangwei You,Jingtai Liu*

Main category: cs.RO

TL;DR: FPC-VLA是一个双模型框架，将视觉-语言-动作模型与故障预测和纠正监督器集成，通过视觉语言查询评估动作可行性并生成纠正策略，显著提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统感知-规划流水线在开放任务中灵活性不足，而单端到端VLA模型缺乏故障预测和恢复机制，需要更可靠的自主系统架构。

Method: 提出双模型框架：VLA模型负责主要动作执行，监督器通过视觉语言查询评估动作可行性并生成纠正策略，采用相似性引导融合模块优化动作，关键帧激活监督器以减少时间开销。

Result: 在多个仿真平台和机器人实体上评估显示，FPC-VLA在零样本和微调设置下均优于最先进模型，任务成功率显著提升且执行时间影响最小，实际部署验证了其泛化能力和实用性。

Conclusion: FPC-VLA通过集成故障预测和纠正机制，为构建更可靠的自主系统提供了有效的解决方案，具有强大的泛化能力和实际应用价值。

Abstract: Robotic manipulation is a fundamental component of automation. However,
traditional perception-planning pipelines often fall short in open-ended tasks
due to limited flexibility, while the architecture of a single end-to-end
Vision-Language-Action (VLA) offers promising capabilities but lacks crucial
mechanisms for anticipating and recovering from failure. To address these
challenges, we propose FPC-VLA, a dual-model framework that integrates VLA with
a supervisor for failure prediction and correction. The supervisor evaluates
action viability through vision-language queries and generates corrective
strategies when risks arise, trained efficiently without manual labeling. A
similarity-guided fusion module further refines actions by leveraging past
predictions. Evaluation results on multiple simulation platforms (SIMPLER and
LIBERO) and robot embodiments (WidowX, Google Robot, Franka) show that FPC-VLA
outperforms state-of-the-art models in both zero-shot and fine-tuned settings.
By activating the supervisor only at keyframes, our approach significantly
increases task success rates with minimal impact on execution time. Successful
real-world deployments on diverse, long-horizon tasks confirm FPC-VLA's strong
generalization and practical utility for building more reliable autonomous
systems.

</details>


### [11] [Integrated Wheel Sensor Communication using ESP32 -- A Contribution towards a Digital Twin of the Road System](https://arxiv.org/abs/2509.04061)
*Ventseslav Yordanov,Simon Schäfer,Alexander Mann,Stefan Kowalewski,Bassam Alrifaee,Lutz Eckstein*

Main category: cs.RO

TL;DR: 这篇论文提出了一种基于ESP32微控制器的新题订阅通信方案，用于高效传输集成轮滴传感器数据，在数据传输量方面超越了现有方案。


<details>
  <summary>Details</summary>
Motivation: 当前车载状态估计方法无法揭示轮胎与路面之间的交互信息，需要一种高效的通信方案来传输集成轮滴传感器数据。

Method: 采用发布-订阅系统架构，使用ESP32微控制器实现数据传输，在漫漫轮测试台上进行测试，测试频率范围1 Hz到32000 Hz。

Result: 原型传感器系统显示了最小的数据损失，约为采样数据的0.1%，验证了通信系统的可靠性。

Conclusion: 这项工作推进了实时数据获取技术，为优化集成轮滴传感器通信提供了重要见解。

Abstract: While current onboard state estimation methods are adequate for most driving
and safety-related applications, they do not provide insights into the
interaction between tires and road surfaces. This paper explores a novel
communication concept for efficiently transmitting integrated wheel sensor data
from an ESP32 microcontroller. Our proposed approach utilizes a
publish-subscribe system, surpassing comparable solutions in the literature
regarding data transmission volume. We tested this approach on a drum tire test
rig with our prototype sensors system utilizing a diverse selection of sample
frequencies between 1 Hz and 32 000 Hz to demonstrate the efficacy of our
communication concept. The implemented prototype sensor showcases minimal data
loss, approximately 0.1 % of the sampled data, validating the reliability of
our developed communication system. This work contributes to advancing
real-time data acquisition, providing insights into optimizing integrated wheel
sensor communication.

</details>


### [12] [Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models](https://arxiv.org/abs/2509.04063)
*Hongyin Zhang,Shiyuan Zhang,Junxi Jin,Qixin Zeng,Yifan Qiao,Hongchao Lu,Donglin Wang*

Main category: cs.RO

TL;DR: 提出ARFM算法，通过自适应调整缩放因子在VLA流匹配模型中构建偏差-方差权衡目标函数，实现离线强化学习微调，提升动作精度和稳定性


<details>
  <summary>Details</summary>
Motivation: 现有基于流匹配的VLA模型在复杂下游任务中动作精度不足，仅依赖模仿学习的后训练范式难以深入理解数据质量分布特性，而强化学习在这方面具有优势

Method: 理论提出VLA流模型的离线RL后训练目标，推导出自适应强化流匹配(ARFM)算法。通过在VLA流模型损失中引入自适应调整的缩放因子，构建有原则的偏差-方差权衡目标函数

Result: 大量仿真和真实世界实验结果表明，ARFM展现出优异的泛化性、鲁棒性、少样本学习和持续学习性能

Conclusion: ARFM算法通过自适应平衡RL优势保持和流损失梯度方差控制，实现了更稳定高效的微调过程，显著提升了VLA模型在复杂任务中的表现

Abstract: Vision-Language-Action (VLA) models based on flow matching have shown
excellent performance in general-purpose robotic manipulation tasks. However,
the action accuracy of these models on complex downstream tasks is
unsatisfactory. One important reason is that these models rely solely on the
post-training paradigm of imitation learning, which makes it difficult to have
a deeper understanding of the distribution properties of data quality, which is
exactly what Reinforcement Learning (RL) excels at. In this paper, we
theoretically propose an offline RL post-training objective for VLA flow models
and induce an efficient and feasible offline RL fine-tuning algorithm --
Adaptive Reinforced Flow Matching (ARFM). By introducing an adaptively adjusted
scaling factor in the VLA flow model loss, we construct a principled
bias-variance trade-off objective function to optimally control the impact of
RL signal on flow loss. ARFM adaptively balances RL advantage preservation and
flow loss gradient variance control, resulting in a more stable and efficient
fine-tuning process. Extensive simulation and real-world experimental results
show that ARFM exhibits excellent generalization, robustness, few-shot
learning, and continuous learning performance.

</details>


### [13] [Solving Robotics Tasks with Prior Demonstration via Exploration-Efficient Deep Reinforcement Learning](https://arxiv.org/abs/2509.04069)
*Chengyandan Shen,Christoffer Sloth*

Main category: cs.RO

TL;DR: 提出了DRLR框架，通过改进动作选择模块来减少bootstrapping误差，使用SAC替代TD3防止策略收敛到次优解，在机器人任务中验证了有效性并实现了sim2real部署


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习在机器人任务中的探索效率问题，特别是bootstrapping误差导致的低效探索和策略收敛到次优解的问题

Method: 基于IBRL算法开发DRLR框架，改进动作选择模块提供校准的Q值，使用SAC作为RL策略，在桶装和开抽屉两个机器人任务上进行验证

Result: 实证验证了方法在减少bootstrapping误差和防止过拟合方面的有效性，展示了框架在不同状态-动作维度和演示质量任务中的鲁棒性，成功实现了真实轮式装载机上的sim2real部署

Conclusion: DRLR框架能够有效提高探索效率，减少bootstrapping误差，防止策略次优收敛，并在真实工业机器人任务中成功应用

Abstract: This paper proposes an exploration-efficient Deep Reinforcement Learning with
Reference policy (DRLR) framework for learning robotics tasks that incorporates
demonstrations. The DRLR framework is developed based on an algorithm called
Imitation Bootstrapped Reinforcement Learning (IBRL). We propose to improve
IBRL by modifying the action selection module. The proposed action selection
module provides a calibrated Q-value, which mitigates the bootstrapping error
that otherwise leads to inefficient exploration. Furthermore, to prevent the RL
policy from converging to a sub-optimal policy, SAC is used as the RL policy
instead of TD3. The effectiveness of our method in mitigating bootstrapping
error and preventing overfitting is empirically validated by learning two
robotics tasks: bucket loading and open drawer, which require extensive
interactions with the environment. Simulation results also demonstrate the
robustness of the DRLR framework across tasks with both low and high
state-action dimensions, and varying demonstration qualities. To evaluate the
developed framework on a real-world industrial robotics task, the bucket
loading task is deployed on a real wheel loader. The sim2real results validate
the successful deployment of the DRLR framework.

</details>


### [14] [Keypoint-based Diffusion for Robotic Motion Planning on the NICOL Robot](https://arxiv.org/abs/2509.04076)
*Lennart Clasmeier,Jan-Gerrit Habekost,Connor Gäde,Philipp Allgeuer,Stefan Wermter*

Main category: cs.RO

TL;DR: 通过深度学习建立了一种基于扩散模型的机器人运动规划方法，在保持高成功率的同时大大缩短了运行时间


<details>
  <summary>Details</summary>
Motivation: 传统数值规划方法虽然能解决普通运动规划问题，但需要消耗大量运行时间，需要快速的替代方案

Method: 使用深度学习把数值规划器生成的数据集进行训练，初始模型使用点云嵌入作为输入来预测关键点基于的关节序列，后来发现条件化面临挑战后精经了数据集

Result: 即使不使用点云编码，模型也能在运行时间上超过数值模型一个数量级，在测试集上达到有达90%的无碰撞解决方案成功率

Conclusion: 深度学习基于扩散模型的方法可以在机器人运动规划中实现高效的性能，在保持高成功率的同时显著减少运行时间

Abstract: We propose a novel diffusion-based action model for robotic motion planning.
Commonly, established numerical planning approaches are used to solve general
motion planning problems, but have significant runtime requirements. By
leveraging the power of deep learning, we are able to achieve good results in a
much smaller runtime by learning from a dataset generated by these planners.
While our initial model uses point cloud embeddings in the input to predict
keypoint-based joint sequences in its output, we observed in our ablation study
that it remained challenging to condition the network on the point cloud
embeddings. We identified some biases in our dataset and refined it, which
improved the model's performance. Our model, even without the use of the point
cloud encodings, outperforms numerical models by an order of magnitude
regarding the runtime, while reaching a success rate of up to 90% of collision
free solutions on the test set.

</details>


### [15] [Object-Reconstruction-Aware Whole-body Control of Mobile Manipulators](https://arxiv.org/abs/2509.04094)
*Fatih Dursun,Bruno Vilhena Adorno,Simon Watson,Wei Pan*

Main category: cs.RO

TL;DR: 这篇论文提出了一种高效的视觉路径规划方法，通过计算信息最丰富区域的焦点并使机器人沿路径保持该点在视野内，实现了与采样基准方法相似的物体覆盖率和信息量，但计算效率提高了8倍。


<details>
  <summary>Details</summary>
Motivation: 解决现有采样基础路径规划技术在物体重建和检测任务中计算成本过高的问题，需要评估多个候选视角，影响了效率。

Method: 提出一种计算效率高的方法：计算最信息丰富区域的焦点，让机器人在移动过程中保持该点在摄像头视野内，通过可视性约束集成到全身控制中，无需额外路径规划器。

Result: 在114个多样化物体的模拟测试中，新方法在物体覆盖率和信息量上与采样基准方法没有显著差异，但平均视角切换时间约简化了8倍。实际机器人实验也验证了方法的实际性能。

Conclusion: 该方法通过焦点维护策略有效解决了视觉路径规划的计算效率问题，在保持与采样方法相符的重建性能同时，大幅提高了视角切换速度，为机器人物体检测和重建任务提供了更高效的解决方案。

Abstract: Object reconstruction and inspection tasks play a crucial role in various
robotics applications. Identifying paths that reveal the most unknown areas of
the object becomes paramount in this context, as it directly affects
efficiency, and this problem is known as the view path planning problem.
Current methods often use sampling-based path planning techniques, evaluating
potential views along the path to enhance reconstruction performance. However,
these methods are computationally expensive as they require evaluating several
candidate views on the path. To this end, we propose a computationally
efficient solution that relies on calculating a focus point in the most
informative (unknown) region and having the robot maintain this point in the
camera field of view along the path. We incorporated this strategy into the
whole-body control of a mobile manipulator employing a visibility constraint
without the need for an additional path planner. We conducted comprehensive and
realistic simulations using a large dataset of 114 diverse objects of varying
sizes from 57 categories to compare our method with a sampling-based planning
strategy using Bayesian data analysis. Furthermore, we performed real-world
experiments with an 8-DoF mobile manipulator to demonstrate the proposed
method's performance in practice. Our results suggest that there is no
significant difference in object coverage and entropy. In contrast, our method
is approximately nine times faster than the baseline sampling-based method in
terms of the average time the robot spends between views.

</details>


### [16] [Cloud-Assisted Remote Control for Aerial Robots: From Theory to Proof-of-Concept Implementation](https://arxiv.org/abs/2509.04095)
*Achilleas Santi Seisa,Viswa Narayanan Sankaranarayanan,Gerasimos Damigos,Sumeet Gajanan Satpute,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 一种基于容器化技术的可扩展测试框架，用于模拟云端和边缘机器人系统的实际网络条件


<details>
  <summary>Details</summary>
Motivation: 云机器人技术虽有优势，但网络延迟、安全问题和资源管理等挑战使得整合变得复杂，需要有效的测试框架

Method: 使用容器化技术构建云集群和机器人模拟环境，通过UDP隧道实现双向通信，利用Linux流量控制模拟延迟和振动

Result: 框架能够模拟实际云机器人部署中遇到的变化网络条件，以云端远程控制航空机器人为例

Conclusion: 该框架提供了一种直观且可扩展的方法，有助于解决云机器人系统集成中的网络挑战

Abstract: Cloud robotics has emerged as a promising technology for robotics
applications due to its advantages of offloading computationally intensive
tasks, facilitating data sharing, and enhancing robot coordination. However,
integrating cloud computing with robotics remains a complex challenge due to
network latency, security concerns, and the need for efficient resource
management. In this work, we present a scalable and intuitive framework for
testing cloud and edge robotic systems. The framework consists of two main
components enabled by containerized technology: (a) a containerized cloud
cluster and (b) the containerized robot simulation environment. The system
incorporates two endpoints of a User Datagram Protocol (UDP) tunnel, enabling
bidirectional communication between the cloud cluster container and the robot
simulation environment, while simulating realistic network conditions. To
achieve this, we consider the use case of cloud-assisted remote control for
aerial robots, while utilizing Linux-based traffic control to introduce
artificial delay and jitter, replicating variable network conditions
encountered in practical cloud-robot deployments.

</details>


### [17] [Lightweight Kinematic and Static Modeling of Cable-Driven Continuum Robots via Actuation-Space Energy Formulation](https://arxiv.org/abs/2509.04119)
*Ke Wu,Yuhao Wang,Kevin Henry,Cesare Stefanini,Gang Zheng*

Main category: cs.RO

TL;DR: 提出了LASEM框架，用于缆线驱动连续体机器人的轻量化建模，直接在驱动空间建立势能模型，避免显式缆线-骨架接触建模，支持实时计算和逆运动学求解。


<details>
  <summary>Details</summary>
Motivation: 连续体机器人具有柔顺性和灵活性，但其连续变形形态给运动规划和控制带来挑战，需要准确但轻量化的模型。

Method: 基于几何非线性梁杆理论和哈密顿原理，在驱动空间直接建立势能模型，统一处理力和位移输入，支持非均匀几何、任意缆线布线、分布载荷和轴向可扩展性。

Result: 数值仿真验证了模型的准确性，开发了半解析迭代方案用于逆运动学，并通过数值优化处理实际机器人的离散化问题。

Conclusion: LASEM框架为缆线驱动连续体机器人提供了准确、轻量化的建模方法，避免了复杂的接触建模，具有实时计算能力，适用于各种复杂工况。

Abstract: Continuum robots, inspired by octopus arms and elephant trunks, combine
dexterity with intrinsic compliance, making them well suited for unstructured
and confined environments. Yet their continuously deformable morphology poses
challenges for motion planning and control, calling for accurate but
lightweight models. We propose the Lightweight Actuation Space Energy Modeling
(LASEM) framework for cable driven continuum robots, which formulates actuation
potential energy directly in actuation space. LASEM yields an analytical
forward model derived from geometrically nonlinear beam and rod theories via
Hamilton's principle, while avoiding explicit modeling of cable backbone
contact. It accepts both force and displacement inputs, thereby unifying
kinematic and static formulations. Assuming the friction is neglected, the
framework generalizes to nonuniform geometries, arbitrary cable routings,
distributed loading and axial extensibility, while remaining computationally
efficient for real-time use. Numerical simulations validate its accuracy, and a
semi-analytical iterative scheme is developed for inverse kinematics. To
address discretization in practical robots, LASEM further reformulates the
functional minimization as a numerical optimization, which also naturally
incorporates cable potential energy without explicit contact modeling.

</details>


### [18] [OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent Detection](https://arxiv.org/abs/2509.04324)
*Chen Hu,Shan Luo,Letizia Gionfrida*

Main category: cs.RO

TL;DR: OVGrasp是一个基于软体外骨骼的抓取辅助分层控制框架，整合RGB-D视觉、开放词汇提示和语音命令，实现多模态交互，在开放环境中具有零样本检测能力。


<details>
  <summary>Details</summary>
Motivation: 为运动障碍患者在非结构化环境中提供抓取辅助，这些环境中物体类别和用户意图多样且不可预测，需要增强泛化能力。

Method: 采用分层控制框架，整合视觉语言基础模型和开放词汇机制，多模态决策器融合空间和语言线索推断用户意图，部署在自定义的自我中心视角可穿戴外骨骼上。

Result: 在15个物体和3种抓取类型上系统评估，10名参与者测试显示抓取能力得分达87.00%，优于最先进基线，运动学对齐自然手部运动更佳。

Conclusion: OVGrasp框架通过多模态交互和开放词汇机制，有效提升了在非结构化环境中的抓取辅助性能，为运动障碍患者提供了实用的辅助解决方案。

Abstract: Grasping assistance is essential for restoring autonomy in individuals with
motor impairments, particularly in unstructured environments where object
categories and user intentions are diverse and unpredictable. We present
OVGrasp, a hierarchical control framework for soft exoskeleton-based grasp
assistance that integrates RGB-D vision, open-vocabulary prompts, and voice
commands to enable robust multimodal interaction. To enhance generalization in
open environments, OVGrasp incorporates a vision-language foundation model with
an open-vocabulary mechanism, allowing zero-shot detection of previously unseen
objects without retraining. A multimodal decision-maker further fuses spatial
and linguistic cues to infer user intent, such as grasp or release, in
multi-object scenarios. We deploy the complete framework on a custom
egocentric-view wearable exoskeleton and conduct systematic evaluations on 15
objects across three grasp types. Experimental results with ten participants
demonstrate that OVGrasp achieves a grasping ability score (GAS) of 87.00%,
outperforming state-of-the-art baselines and achieving improved kinematic
alignment with natural hand motion.

</details>


### [19] [DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation](https://arxiv.org/abs/2509.04441)
*Hao-Shu Fang,Branden Romero,Yichen Xie,Arthur Hu,Bo-Ruei Huang,Juan Alvarez,Matthew Kim,Gabriel Margolis,Kavya Anbarasu,Masayoshi Tomizuka,Edward Adelson,Pulkit Agrawal*

Main category: cs.RO

TL;DR: DEXOP是一个被动手部外骨骼系统，通过perioperation范式收集人类操作数据，提供直接接触反馈和姿态镜像，相比遥操作能更高效地收集高质量演示数据用于机器人技能学习。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人灵巧操作数据收集的挑战，传统遥操作方式存在效率低、不自然的问题，需要一种能够最大化数据可迁移性并提高收集效率的方法。

Method: 开发DEXOP被动手部外骨骼，机械连接人类手指和机器人手指，提供直接接触反馈和姿态镜像功能，在自然环境中收集丰富的视觉+触觉传感数据。

Result: DEXOP在多种灵巧接触密集型任务中表现出色，相比遥操作显著提高了单位时间数据收集的任务性能，能够大规模收集高质量演示数据。

Conclusion: DEXOP通过perioperation范式为机器人灵巧性发展提供了强大工具，其数据收集效率和质量优于传统遥操作方法。

Abstract: We introduce perioperation, a paradigm for robotic data collection that
sensorizes and records human manipulation while maximizing the transferability
of the data to real robots. We implement this paradigm in DEXOP, a passive hand
exoskeleton designed to maximize human ability to collect rich sensory (vision
+ tactile) data for diverse dexterous manipulation tasks in natural
environments. DEXOP mechanically connects human fingers to robot fingers,
providing users with direct contact feedback (via proprioception) and mirrors
the human hand pose to the passive robot hand to maximize the transfer of
demonstrated skills to the robot. The force feedback and pose mirroring make
task demonstrations more natural for humans compared to teleoperation,
increasing both speed and accuracy. We evaluate DEXOP across a range of
dexterous, contact-rich tasks, demonstrating its ability to collect
high-quality demonstration data at scale. Policies learned with DEXOP data
significantly improve task performance per unit time of data collection
compared to teleoperation, making DEXOP a powerful tool for advancing robot
dexterity. Our project page is at https://dex-op.github.io.

</details>


### [20] [EMMA: Scaling Mobile Manipulation via Egocentric Human Data](https://arxiv.org/abs/2509.04443)
*Lawrence Y. Zhu,Pranav Kuppili,Ryan Punamiya,Patcharapong Aphiwetsa,Dhruv Patel,Simar Kareer,Sehoon Ha,Danfei Xu*

Main category: cs.RO

TL;DR: EMMA框架通过结合人类全身运动数据和静态机器人数据来训练移动操作策略，避免了昂贵的移动机器人遥操作，在三个真实世界任务中表现出与基于遥操作数据训练的基线相当的性能。


<details>
  <summary>Details</summary>
Motivation: 移动操作模仿学习的规模化受限于昂贵的移动机器人遥操作成本，需要找到替代方法来降低数据收集成本。

Method: 提出EMMA端到端框架，通过共同训练人类全身运动数据和静态机器人数据来学习移动操作策略，无需移动遥操作数据。

Result: 在三个真实世界任务中，EMMA表现出与基于遥操作数据训练的Mobile ALOHA基线相当或更好的任务成功率，能够泛化到新的空间配置和场景，且性能随人类数据量增加而提升。

Conclusion: EMMA为真实世界环境中的可扩展机器人学习开辟了新途径，通过利用人类数据替代昂贵的机器人遥操作数据来实现高效的移动操作策略学习。

Abstract: Scaling mobile manipulation imitation learning is bottlenecked by expensive
mobile robot teleoperation. We present Egocentric Mobile MAnipulation (EMMA),
an end-to-end framework training mobile manipulation policies from human mobile
manipulation data with static robot data, sidestepping mobile teleoperation. To
accomplish this, we co-train human full-body motion data with static robot
data. In our experiments across three real-world tasks, EMMA demonstrates
comparable performance to baselines trained on teleoperated mobile robot data
(Mobile ALOHA), achieving higher or equivalent task performance in full task
success. We find that EMMA is able to generalize to new spatial configurations
and scenes, and we observe positive performance scaling as we increase the
hours of human data, opening new avenues for scalable robotic learning in
real-world environments. Details of this project can be found at
https://ego-moma.github.io/.

</details>
