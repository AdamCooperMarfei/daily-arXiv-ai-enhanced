<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Autonomous Reactive Masonry Construction using Collaborative Heterogeneous Aerial Robots with Experimental Demonstration](https://arxiv.org/abs/2510.15114)
*Marios-Nektarios Stamatopoulos,Elias Small,Shridhar Velhal,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出了一种使用异构无人机进行全自主空中砌体建造的框架，包含砖块搬运无人机和粘合剂涂布无人机，通过反应式任务规划和动态任务分配实现协同建造。


<details>
  <summary>Details</summary>
Motivation: 开发全自主的空中机器人建造系统，解决传统建造方法在危险环境或复杂地形中的局限性，通过异构无人机协同工作提高建造效率和精度。

Method: 使用两种专用无人机：带球关节驱动机构的砖块搬运无人机和带伺服控制阀的粘合剂涂布无人机；采用反应式任务规划、分层状态机、动态任务分配和最小抖动轨迹生成；砖块搬运无人机使用基于ArUco标记的实时位姿估计系统。

Result: 实验验证了框架的有效性，成功实现了全自主的空中砌体建造，其中一架无人机精确放置砖块，另一架自动在砖块间涂布粘合剂材料。

Conclusion: 这是首个使用异构无人机进行全自主空中砌体建造的实验演示，为未来自主空中机器人建造系统的发展奠定了基础。

Abstract: This article presents a fully autonomous aerial masonry construction
framework using heterogeneous unmanned aerial vehicles (UAVs), supported by
experimental validation. Two specialized UAVs were developed for the task: (i)
a brick-carrier UAV equipped with a ball-joint actuation mechanism for precise
brick manipulation, and (ii) an adhesion UAV integrating a servo-controlled
valve and extruder nozzle for accurate adhesion application. The proposed
framework employs a reactive mission planning unit that combines a dependency
graph of the construction layout with a conflict graph to manage simultaneous
task execution, while hierarchical state machines ensure robust operation and
safe transitions during task execution. Dynamic task allocation allows
real-time adaptation to environmental feedback, while minimum-jerk trajectory
generation ensures smooth and precise UAV motion during brick pickup and
placement. Additionally, the brick-carrier UAV employs an onboard vision system
that estimates brick poses in real time using ArUco markers and a least-squares
optimization filter, enabling accurate alignment during construction. To the
best of the authors' knowledge, this work represents the first experimental
demonstration of fully autonomous aerial masonry construction using
heterogeneous UAVs, where one UAV precisely places the bricks while another
autonomously applies adhesion material between them. The experimental results
supported by the video showcase the effectiveness of the proposed framework and
demonstrate its potential to serve as a foundation for future developments in
autonomous aerial robotic construction.

</details>


### [2] [RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation](https://arxiv.org/abs/2510.15189)
*Xiangyu Chen,Chuhao Zhou,Yuxi Liu,Jianfei Yang*

Main category: cs.RO

TL;DR: 提出了角色模型强化学习（RM-RL）框架，通过自动生成近似最优动作标签来替代人工演示，统一在线和离线训练，在真实环境中实现精确机器人操作。


<details>
  <summary>Details</summary>
Motivation: 精确机器人操作在化学和生物实验等应用中至关重要，但现有方法依赖高质量人工演示，获取困难且耗时，离线强化学习存在分布偏移和数据效率低的问题。

Method: 采用角色模型策略自动为在线训练数据生成标签，将策略学习重新表述为监督训练，减少分布不匹配的不稳定性，并通过混合训练方案重复利用在线数据提高数据效率。

Result: 实验显示RM-RL比现有RL方法收敛更快更稳定，在真实操作中实现53%的平移精度提升和20%的旋转精度提升，成功完成细胞板精确放置等挑战性任务。

Conclusion: RM-RL框架有效解决了精确操作任务中人工演示依赖和数据效率问题，在真实环境中表现出优越性能，为精细操作应用提供了可行解决方案。

Abstract: Precise robot manipulation is critical for fine-grained applications such as
chemical and biological experiments, where even small errors (e.g., reagent
spillage) can invalidate an entire task. Existing approaches often rely on
pre-collected expert demonstrations and train policies via imitation learning
(IL) or offline reinforcement learning (RL). However, obtaining high-quality
demonstrations for precision tasks is difficult and time-consuming, while
offline RL commonly suffers from distribution shifts and low data efficiency.
We introduce a Role-Model Reinforcement Learning (RM-RL) framework that unifies
online and offline training in real-world environments. The key idea is a
role-model strategy that automatically generates labels for online training
data using approximately optimal actions, eliminating the need for human
demonstrations. RM-RL reformulates policy learning as supervised training,
reducing instability from distribution mismatch and improving efficiency. A
hybrid training scheme further leverages online role-model data for offline
reuse, enhancing data efficiency through repeated sampling. Extensive
experiments show that RM-RL converges faster and more stably than existing RL
methods, yielding significant gains in real-world manipulation: 53% improvement
in translation accuracy and 20% in rotation accuracy. Finally, we demonstrate
the successful execution of a challenging task, precisely placing a cell plate
onto a shelf, highlighting the framework's effectiveness where prior methods
fail.

</details>


### [3] [Lagrange-Poincaré-Kepler Equations of Disturbed Space-Manipulator Systems in Orbit](https://arxiv.org/abs/2510.15199)
*Borna Monazzah Moghaddam,Robin Chhabra*

Main category: cs.RO

TL;DR: 提出Lagrange-Poincare-Kepler方程(LPKE)，将Lagrange-Poincare方程扩展到非惯性轨道参考系中的航天器-机械臂系统动力学建模


<details>
  <summary>Details</summary>
Motivation: 现有Lagrange-Poincare方程主要针对车辆-机械臂系统，需要扩展到航天器在轨道环境中的动力学建模，考虑轨道运动与机械臂的耦合效应

Method: 结合Euler-Poincare方程(航天器姿态)、开普勒轨道动力学(参考系)和简化Euler-Lagrange方程(机械臂形状空间)，使用指数关节参数化，基于主丛上的Lagrange-d'Alembert原理推导

Result: 推导出新的封闭形式结构矩阵，明确捕捉轨道扰动效应及其与机械臂系统的动态耦合，系统性地包含外部施加的对称破缺力/力矩

Conclusion: LPKE框架为轨道环境中的自主机器人操作提供了可直接集成到硬件在环仿真和基于模型控制架构的有效模型，数值模拟验证了模型的有效性和数值优越性

Abstract: This article presents an extension of the Lagrange-Poincare Equations (LPE)
to model the dynamics of spacecraft-manipulator systems operating within a
non-inertial orbital reference frame. Building upon prior formulations of LPE
for vehicle-manipulator systems, the proposed framework, termed the
Lagrange-Poincare-Kepler Equations (LPKE), incorporates the coupling between
spacecraft attitude dynamics, orbital motion, and manipulator kinematics. The
formalism combines the Euler-Poincare equations for the base spacecraft,
Keplerian orbital dynamics for the reference frame, and reduced Euler-Lagrange
equations for the manipulator's shape space, using an exponential joint
parametrization. Leveraging the Lagrange-d'Alembert principle on principal
bundles, we derive novel closed-form structural matrices that explicitly
capture the effects of orbital disturbances and their dynamic coupling with the
manipulator system. The LPKE framework also systematically includes externally
applied, symmetry-breaking wrenches, allowing for immediate integration into
hardware-in-the-loop simulations and model-based control architectures for
autonomous robotic operations in the orbital environment. To illustrate the
effectiveness of the proposed model and its numerical superiority, we present a
simulation study analyzing orbital effects on a 7-degree-of-freedom manipulator
mounted on a spacecraft.

</details>


### [4] [LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization](https://arxiv.org/abs/2510.15220)
*Kevin Christiansen Marsim,Minho Oh,Byeongho Yu,Seungjae Lee,I Made Aswin Nahrendra,Hyungtae Lim,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种鲁棒的LiDAR-视觉-惯性-运动学里程计系统，通过多传感器融合在复杂动态环境中实现稳定的自主导航。


<details>
  <summary>Details</summary>
Motivation: 解决传统传感器融合SLAM方法在挑战性环境中由于不合适的融合策略导致的估计漂移问题。

Method: 采用融合位姿估计方法，结合优化型视觉-惯性-运动学里程计(VIKO)和滤波型LiDAR-惯性-运动学里程计(LIKO)，基于测量可用性运行。VIKO使用足部预积分和基于超像素聚类的鲁棒LiDAR-视觉深度一致性滑动窗口优化，LIKO结合足部运动学并在误差状态迭代卡尔曼滤波中使用点对面残差。

Result: 与现有传感器融合SLAM算法相比，在公开和长期数据集上表现出鲁棒性能。

Conclusion: 该系统通过有效的多传感器融合策略，在复杂动态环境中实现了稳定的定位和建图性能。

Abstract: Autonomous navigation for legged robots in complex and dynamic environments
relies on robust simultaneous localization and mapping (SLAM) systems to
accurately map surroundings and localize the robot, ensuring safe and efficient
operation. While prior sensor fusion-based SLAM approaches have integrated
various sensor modalities to improve their robustness, these algorithms are
still susceptible to estimation drift in challenging environments due to their
reliance on unsuitable fusion strategies. Therefore, we propose a robust
LiDAR-visual-inertial-kinematic odometry system that integrates information
from multiple sensors, such as a camera, LiDAR, inertial measurement unit
(IMU), and joint encoders, for visual and LiDAR-based odometry estimation. Our
system employs a fusion-based pose estimation approach that runs
optimization-based visual-inertial-kinematic odometry (VIKO) and filter-based
LiDAR-inertial-kinematic odometry (LIKO) based on measurement availability. In
VIKO, we utilize the footpreintegration technique and robust LiDAR-visual depth
consistency using superpixel clusters in a sliding window optimization. In
LIKO, we incorporate foot kinematics and employ a point-toplane residual in an
error-state iterative Kalman filter (ESIKF). Compared with other sensor
fusion-based SLAM algorithms, our approach shows robust performance across
public and longterm datasets.

</details>


### [5] [PolyFly: Polytopic Optimal Planning for Collision-Free Cable-Suspended Aerial Payload Transportation](https://arxiv.org/abs/2510.15226)
*Mrunal Sarvaiya,Guanrui Li,Giuseppe Loianno*

Main category: cs.RO

TL;DR: PolyFly是一种用于空中运输机器人的最优全局规划器，通过将机器人组件（四旋翼、缆绳和负载）和环境建模为独立多面体，消除了现有方法的保守性限制，实现了更快的轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 现有方法对飞行器和障碍物进行几何过度近似，导致保守的机动和增加的飞行时间。需要一种能够考虑非保守表示的规划方法，使机器人能够在紧密约束环境中进行激进飞行。

Method: 提出PolyFly方法，将环境中的每个物理组件和机器人组件建模为独立多面体，并通过构建方向感知多面体来提高模型精度。利用对偶理论将多面体约束转换为平滑可微约束，从而高效解决最优控制问题。

Result: 在八个迷宫式环境中与现有最先进方法进行比较，PolyFly在每个场景中都产生了更快的轨迹。在真实四旋翼悬挂负载平台上进行了实验验证，证明了方法的实用可靠性和准确性。

Conclusion: PolyFly通过非保守的多面体建模和方向感知约束，显著提高了空中运输机器人在紧密约束环境中的轨迹规划性能，实现了更快的飞行轨迹和更高的实用性。

Abstract: Aerial transportation robots using suspended cables have emerged as versatile
platforms for disaster response and rescue operations. To maximize the
capabilities of these systems, robots need to aggressively fly through tightly
constrained environments, such as dense forests and structurally unsafe
buildings, while minimizing flight time and avoiding obstacles. Existing
methods geometrically over-approximate the vehicle and obstacles, leading to
conservative maneuvers and increased flight times. We eliminate these
restrictions by proposing PolyFly, an optimal global planner which considers a
non-conservative representation for aerial transportation by modeling each
physical component of the environment, and the robot (quadrotor, cable and
payload), as independent polytopes. We further increase the model accuracy by
incorporating the attitude of the physical components by constructing
orientation-aware polytopes. The resulting optimal control problem is
efficiently solved by converting the polytope constraints into smooth
differentiable constraints via duality theory. We compare our method against
the existing state-of-the-art approach in eight maze-like environments and show
that PolyFly produces faster trajectories in each scenario. We also
experimentally validate our proposed approach on a real quadrotor with a
suspended payload, demonstrating the practical reliability and accuracy of our
method.

</details>


### [6] [A Generalized Sylvester-Fermat-Torricelli problem with application in disaster relief operations by UAVs](https://arxiv.org/abs/2510.15229)
*Sina Kazemdehbashi,Yanchao Liu,Boris S. Mordukhovich*

Main category: cs.RO

TL;DR: 提出了一种考虑风力和无人机异质性的新型数学框架，用于优化移动无人机基站位置，可将操作时间浪费减少84%。


<details>
  <summary>Details</summary>
Motivation: 自然灾害中通信基础设施常被破坏，无人机能帮助收集数据和建立临时通信网络，但风力等恶劣天气条件对无人机部署构成重大挑战。

Method: 将Sylvester问题推广为Sylvester-Fermat-Torricelli问题，建立统一框架来考虑风力影响、无人机异质性和往返运动等复杂因素。

Result: 实验结果表明，该框架能减少高达84%的操作时间浪费，显著提高灾后任务的效率和效果。

Conclusion: 所提出的数学框架通过考虑现实世界因素如风力和无人机异质性，增强了基于无人机的灾害响应规划的实用性。

Abstract: Natural and human-made disasters can cause severe devastation and claim
thousands of lives worldwide. Therefore, developing efficient methods for
disaster response and management is a critical task for relief teams. One of
the most essential components of effective response is the rapid collection of
information about affected areas, damages, and victims. More data translates
into better coordination, faster rescue operations, and ultimately, more lives
saved. However, in some disasters, such as earthquakes, the communication
infrastructure is often partially or completely destroyed, making it extremely
difficult for victims to send distress signals and for rescue teams to locate
and assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as
valuable tools in such scenarios. In particular, a fleet of UAVs can be
dispatched from a mobile station to the affected area to facilitate data
collection and establish temporary communication networks. Nevertheless,
real-world deployment of UAVs faces several challenges, with adverse weather
conditions--especially wind--being among the most significant. To address this,
we develop a novel mathematical framework to determine the optimal location of
a mobile UAV station while explicitly accounting for the heterogeneity of the
UAVs and the effect of wind. In particular, we generalize the Sylvester problem
to introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures
complex factors such as wind influence, UAV heterogeneity, and back-and-forth
motion within a unified framework. The proposed framework enhances the
practicality of UAV-based disaster response planning by accounting for
real-world factors such as wind and UAV heterogeneity. Experimental results
demonstrate that it can reduce wasted operational time by up to 84%, making
post-disaster missions significantly more efficient and effective.

</details>


### [7] [Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping](https://arxiv.org/abs/2510.15319)
*Jeewon Kim,Minho Oh,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种可穿越性感知的房间分割方法，通过考虑机器人与环境的交互来改进场景图的分层结构，提高姿态图优化的语义一致性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在分割空间特征时，由于视角变化和传感器视野限制，难以一致识别房间。实时方法常将大房间过度分割成无用的小空间，而体素方法在复杂情况下又分割不足，导致姿态图优化中出现错误约束。

Method: 提出可穿越性感知的房间分割方法，考虑机器人与周围环境的交互，确保可穿越性信息的一致性可行性。

Result: 通过在重复遍历相同路径的数据集上展示相同房间的重新检测频率提高，以及优化时间消耗的减少，证明了性能改进。

Conclusion: 该方法增强了姿态图优化的语义一致性和计算效率，解决了现有方法在房间分割中的过分割和欠分割问题。

Abstract: Scene graphs enhance 3D mapping capabilities in robotics by understanding the
relationships between different spatial elements, such as rooms and objects.
Recent research extends scene graphs to hierarchical layers, adding and
leveraging constraints across these levels. This approach is tightly integrated
with pose-graph optimization, improving both localization and mapping accuracy
simultaneously. However, when segmenting spatial characteristics, consistently
recognizing rooms becomes challenging due to variations in viewpoints and
limited field of view (FOV) of sensors. For example, existing real-time
approaches often over-segment large rooms into smaller, non-functional spaces
that are not useful for localization and mapping due to the time-dependent
method. Conversely, their voxel-based room segmentation method often
under-segment in complex cases like not fully enclosed 3D space that are
non-traversable for ground robots or humans, leading to false constraints in
pose-graph optimization. We propose a traversability-aware room segmentation
method that considers the interaction between robots and surroundings, with
consistent feasibility of traversability information. This enhances both the
semantic coherence and computational efficiency of pose-graph optimization.
Improved performance is demonstrated through the re-detection frequency of the
same rooms in a dataset involving repeated traversals of the same space along
the same path, as well as the optimization time consumption.

</details>


### [8] [ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning](https://arxiv.org/abs/2510.15331)
*Gahee Kim,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 提出了主动仿真推理（ASBI）框架，通过机器人主动收集真实世界数据来准确调整黑盒仿真器参数，解决了传统方法中观测信息不足的问题。


<details>
  <summary>Details</summary>
Motivation: 黑盒仿真器在机器人领域广泛应用，但由于无法访问似然函数，参数优化具有挑战性。传统仿真推理方法在离线设置下难以准备包含足够参数估计信息的观测数据。

Method: 使用主动数据收集策略，通过最大化信息增益来优化机器人动作。利用神经后验估计（NPE）学习后验估计器，克服黑盒仿真器中无法计算似然函数的问题。

Result: 三个仿真实验定量验证了方法的准确性，后验分布紧密集中在真实参数周围。真实机器人实验成功估计了立方体颗粒的仿真参数。

Conclusion: ASBI框架能够有效解决黑盒仿真器参数估计问题，通过主动数据收集实现了准确的参数校准。

Abstract: Black-box simulators are widely used in robotics, but optimizing their
parameters remains challenging due to inaccessible likelihoods.
Simulation-Based Inference (SBI) tackles this issue using simulation-driven
approaches, estimating the posterior from offline real observations and forward
simulations. However, in black-box scenarios, preparing observations that
contain sufficient information for parameter estimation is difficult due to the
unknown relationship between parameters and observations. In this work, we
present Active Simulation-Based Inference (ASBI), a parameter estimation
framework that uses robots to actively collect real-world online data to
achieve accurate black-box simulator tuning. Our framework optimizes robot
actions to collect informative observations by maximizing information gain,
which is defined as the expected reduction in Shannon entropy between the
posterior and the prior. While calculating information gain requires the
likelihood, which is inaccessible in black-box simulators, our method solves
this problem by leveraging Neural Posterior Estimation (NPE), which leverages a
neural network to learn the posterior estimator. Three simulation experiments
quantitatively verify that our method achieves accurate parameter estimation,
with posteriors sharply concentrated around the true parameters. Moreover, we
show a practical application using a real robot to estimate the simulation
parameters of cubic particles corresponding to two real objects, beads and
gravel, with a bucket pouring action.

</details>


### [9] [Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles](https://arxiv.org/abs/2510.15336)
*Liviu-Mihai Stan,Ranulfo Bezerra,Shotaro Kojima,Tsige Tadesse Alemayoh,Satoshi Tadokoro,Masashi Konyo,Kazunori Ohno*

Main category: cs.RO

TL;DR: 提出了一种用于灾难响应和室内非结构化环境的自适应路径规划框架，能够识别并处理可移动障碍物，集成在ROS2 Nav2堆栈中。


<details>
  <summary>Details</summary>
Motivation: 在灾难响应和非结构化室内环境中，机器人不仅需要避开障碍物，还需要识别哪些障碍物可以被推开，以提高导航成功率。

Method: 使用LiDAR和里程计，通过可移动障碍物层标记静态地图中不存在的激光返回点，并分配较低的穿越成本。配合慢速姿态进度检查器监控速度比，在减速时提高局部成本，促使全局规划器重新规划路径。

Result: 在Gazebo模拟环境中测试显示，相比无层基线方法，该方法具有更高的目标到达率和更少的死锁情况，穿越时间大致相当。

Conclusion: 该方法仅依赖平面扫描和CPU级计算，适合资源受限的搜救机器人，表明交互感知成本地图是轻量级的ROS2原生扩展，可用于非结构化环境中的可移动障碍物导航。

Abstract: Reliable navigation in disaster-response and other unstructured indoor
settings requires robots not only to avoid obstacles but also to recognise when
those obstacles can be pushed aside. We present an adaptive, LiDAR and
odometry-based path-planning framework that embeds this capability into the
ROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing
from a prior static map as tentatively movable and assigns a reduced traversal
cost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to
actual velocity; when the robot slows appreciably, the local cost is raised
from light to heavy, and on a stall to lethal, prompting the global planner to
back out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated
objects and cluttered corridors, show higher goal-reach rates and fewer
deadlocks than a no-layer baseline, with traversal times broadly comparable.
Because the method relies only on planar scans and CPU-level computation, it
suits resource-constrained search and rescue robots and integrates into
heterogeneous platforms with minimal engineering. Overall, the results indicate
that interaction-aware cost maps are a lightweight, ROS2-native extension for
navigating among potentially movable obstacles in unstructured settings. The
full implementation will be released as open source
athttps://costmap-namo.github.io.

</details>


### [10] [Nauplius Optimisation for Autonomous Hydrodynamics](https://arxiv.org/abs/2510.15350)
*Shyalan Ramesh,Scott Mann,Alex Stumpf*

Main category: cs.RO

TL;DR: NOAH是一种受藤壶幼体启发的自主水下车辆群优化算法，结合了水流感知漂移、持久感知节点的不可逆沉降和群体通信，解决了现有群算法在水下环境中的关键限制。


<details>
  <summary>Details</summary>
Motivation: 自主水下车辆在强水流、有限声学带宽和持久感知需求的环境中运行，传统群优化方法不可靠，需要开发专门的水下群优化算法。

Method: NOAH算法结合了水流感知漂移、不可逆沉降机制和群体通信，借鉴藤壶幼体的行为模式，为水下探索任务提供水动力感知能力。

Result: 验证研究显示在永久锚定场景中达到86%的成功率，提供了水动力约束和不可逆沉降行为的统一公式，并在水流条件下进行了实证研究。

Conclusion: NOAH算法为可扩展和节能的水下群机器人建立了全面基础，具有经过验证的性能分析。

Abstract: Autonomous Underwater vehicles must operate in strong currents, limited
acoustic bandwidth, and persistent sensing requirements where conventional
swarm optimisation methods are unreliable. This paper presents NOAH, a novel
nature-inspired swarm optimisation algorithm that combines current-aware drift,
irreversible settlement in persistent sensing nodes, and colony-based
communication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH
addresses the critical limitations of existing swarm algorithms by providing
hydrodynamic awareness, irreversible anchoring mechanisms, and colony-based
communication capabilities essential for underwater exploration missions. The
algorithm establishes a comprehensive foundation for scalable and
energy-efficient underwater swarm robotics with validated performance analysis.
Validation studies demonstrate an 86% success rate for permanent anchoring
scenarios, providing a unified formulation for hydrodynamic constraints and
irreversible settlement behaviours with an empirical study under flow.

</details>


### [11] [GaussGym: An open-source real-to-sim framework for learning locomotion from pixels](https://arxiv.org/abs/2510.15352)
*Alejandro Escontrela,Justin Kerr,Arthur Allshire,Jonas Frey,Rocky Duan,Carmelo Sferrazza,Pieter Abbeel*

Main category: cs.RO

TL;DR: 提出了一种将3D高斯泼溅作为渲染器集成到向量化物理模拟器中的新方法，实现了超过10万步/秒的高速模拟，同时保持高视觉保真度，并展示了在sim-to-real机器人应用中的适用性。


<details>
  <summary>Details</summary>
Motivation: 为了桥接高吞吐量模拟和高保真感知，推进可扩展和通用化的机器人学习，需要一种既能快速运行又能保持视觉真实感的模拟方法。

Method: 将3D高斯泼溅作为渲染器集成到向量化物理模拟器（如IsaacGym）中，可以轻松整合来自iPhone扫描、大规模场景数据集和生成视频模型的环境数据。

Result: 在消费级GPU上实现了超过10万步/秒的模拟速度，同时保持了高视觉保真度，展示了在sim-to-real机器人设置中的适用性，以及丰富的视觉语义如何改善导航和决策。

Conclusion: 这项工作桥接了高吞吐量模拟和高保真感知，推进了可扩展和通用化的机器人学习，所有代码和数据将开源供社区使用。

Abstract: We present a novel approach for photorealistic robot simulation that
integrates 3D Gaussian Splatting as a drop-in renderer within vectorized
physics simulators such as IsaacGym. This enables unprecedented speed --
exceeding 100,000 steps per second on consumer GPUs -- while maintaining high
visual fidelity, which we showcase across diverse tasks. We additionally
demonstrate its applicability in a sim-to-real robotics setting. Beyond
depth-based sensing, our results highlight how rich visual semantics improve
navigation and decision-making, such as avoiding undesirable regions. We
further showcase the ease of incorporating thousands of environments from
iPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs
from generative video models like Veo, enabling rapid creation of realistic
training worlds. This work bridges high-throughput simulation and high-fidelity
perception, advancing scalable and generalizable robot learning. All code and
data will be open-sourced for the community to build upon. Videos, code, and
data available at https://escontrela.me/gauss_gym/.

</details>


### [12] [Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting](https://arxiv.org/abs/2510.15376)
*Zhaodong Yang,Ai-Ping Hu,Harish Ravichandar*

Main category: cs.RO

TL;DR: 该论文开发了一个自动化鸡肩去骨系统，通过强化学习训练具有力反馈的切割策略，能够在部分遮挡、可变形、多材料的关节中精确切割，避免接触骨骼。


<details>
  <summary>Details</summary>
Motivation: 自动化鸡肩去骨需要精确的6自由度切割，但由于关节部分遮挡、可变形且包含多种材料，接触骨骼会带来严重的健康和安全风险。

Method: 1. 开发开源多材料切割模拟器；2. 设计可重复使用的物理测试平台；3. 训练残差强化学习策略，使用离散化力观测和领域随机化，实现零样本模拟到真实环境的迁移。

Result: 学习到的策略可靠地导航关节间隙，减少不必要的骨骼/软骨接触，在成功率和骨骼避免方面比现有开环切割基准提高了4倍。

Conclusion: 力反馈对于安全有效的多材料切割是必要的，该研究首次展示了学习策略在真实鸡肩上去骨的应用。

Abstract: Automating chicken shoulder deboning requires precise 6-DoF cutting through a
partially occluded, deformable, multi-material joint, since contact with the
bones presents serious health and safety risks. Our work makes both
systems-level and algorithmic contributions to train and deploy a reactive
force-feedback cutting policy that dynamically adapts a nominal trajectory and
enables full 6-DoF knife control to traverse the narrow joint gap while
avoiding contact with the bones. First, we introduce an open-source
custom-built simulator for multi-material cutting that models coupling,
fracture, and cutting forces, and supports reinforcement learning, enabling
efficient training and rapid prototyping. Second, we design a reusable physical
testbed to emulate the chicken shoulder: two rigid "bone" spheres with
controllable pose embedded in a softer block, enabling rigorous and repeatable
evaluation while preserving essential multi-material characteristics of the
target problem. Third, we train and deploy a residual RL policy, with
discretized force observations and domain randomization, enabling robust
zero-shot sim-to-real transfer and the first demonstration of a learned policy
that debones a real chicken shoulder. Our experiments in our simulator, on our
physical testbed, and on real chicken shoulders show that our learned policy
reliably navigates the joint gap and reduces undesired bone/cartilage contact,
resulting in up to a 4x improvement over existing open-loop cutting baselines
in terms of success rate and bone avoidance. Our results also illustrate the
necessity of force feedback for safe and effective multi-material cutting. The
project website is at https://sites.google.com/view/chickendeboning-2026.

</details>


### [13] [VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving](https://arxiv.org/abs/2510.15446)
*Ziang Guo,Zufeng Zhang*

Main category: cs.RO

TL;DR: VDRive是一个用于端到端自动驾驶的新型框架，通过显式建模状态-动作映射来解决动态环境和极端场景的挑战，实现可解释和鲁棒的决策。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中的动态环境和极端场景对车辆状态理解和决策的鲁棒性构成重大挑战，需要开发能够处理这些复杂情况的系统。

Method: 结合视觉语言动作模型的状态理解能力和基于扩散策略的动作头，通过上下文预测未来观测和几何强化学习微调来预测轨迹和动作，采用演员-评论家框架进行策略学习。

Result: 在Bench2Drive闭环基准测试和nuScenes开环规划中达到了最先进的性能。

Conclusion: VDRive通过显式建模状态-动作映射，实现了可解释且鲁棒的自动驾驶决策，在多个基准测试中表现出色。

Abstract: In autonomous driving, dynamic environment and corner cases pose significant
challenges to the robustness of ego vehicle's state understanding and decision
making. We introduce VDRive, a novel pipeline for end-to-end autonomous driving
that explicitly models state-action mapping to address these challenges,
enabling interpretable and robust decision making. By leveraging the
advancement of the state understanding of the Vision Language Action Model
(VLA) with generative diffusion policy-based action head, our VDRive guides the
driving contextually and geometrically. Contextually, VLA predicts future
observations through token generation pre-training, where the observations are
represented as discrete codes by a Conditional Vector Quantized Variational
Autoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning
fine-tuning of the VLA to predict future trajectories and actions based on
current driving conditions. VLA supplies the current state tokens and predicted
state tokens for the action policy head to generate hierarchical actions and
trajectories. During policy training, a learned critic evaluates the actions
generated by the policy and provides gradient-based feedback, forming an
actor-critic framework that enables a reinforcement-based policy learning
pipeline. Experiments show that our VDRive achieves state-of-the-art
performance in the Bench2Drive closed-loop benchmark and nuScenes open-loop
planning.

</details>


### [14] [Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving](https://arxiv.org/abs/2510.15505)
*Aron Distelzweig,Faris Janjoš,Oliver Scheel,Sirish Reddy Varra,Raghu Rajan,Joschka Boedecker*

Main category: cs.RO

TL;DR: 研究发现当前集成预测与规划方法未能充分利用预测信息，提出以高质量提案生成为核心的方法，在交互复杂场景中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 探讨集成预测与规划方法中预测的实际作用，验证其是否真正提升规划性能，特别是在交互复杂场景中。

Method: 基于PDM（简单车道跟随方法）增强提案生成，强调生成多样但现实的高质量提案，主要使用预测进行碰撞检查。

Result: 提案中心方法在分布外和高度交互场景中表现优异，创造了新的最先进结果，而完美预测并未带来更好的规划结果。

Conclusion: 当前IPP方法未能充分利用预测信息，提案质量比预测准确性更重要，提案中心方法在复杂场景中具有显著优势。

Abstract: Traditionally, prediction and planning in autonomous driving (AD) have been
treated as separate, sequential modules. Recently, there has been a growing
shift towards tighter integration of these components, known as Integrated
Prediction and Planning (IPP), with the aim of enabling more informed and
adaptive decision-making. However, it remains unclear to what extent this
integration actually improves planning performance. In this work, we
investigate the role of prediction in IPP approaches, drawing on the widely
adopted Val14 benchmark, which encompasses more common driving scenarios with
relatively low interaction complexity, and the interPlan benchmark, which
includes highly interactive and out-of-distribution driving situations. Our
analysis reveals that even access to perfect future predictions does not lead
to better planning outcomes, indicating that current IPP methods often fail to
fully exploit future behavior information. Instead, we focus on high-quality
proposal generation, while using predictions primarily for collision checks. We
find that many imitation learning-based planners struggle to generate realistic
and plausible proposals, performing worse than PDM - a simple lane-following
approach. Motivated by this observation, we build on PDM with an enhanced
proposal generation method, shifting the emphasis towards producing diverse but
realistic and high-quality proposals. This proposal-centric approach
significantly outperforms existing methods, especially in out-of-distribution
and highly interactive settings, where it sets new state-of-the-art results.

</details>


### [15] [VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation](https://arxiv.org/abs/2510.15530)
*Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He*

Main category: cs.RO

TL;DR: 提出了一种仅使用视觉输入的单视图扩散策略学习方法VO-DP，利用预训练视觉基础模型融合语义和几何特征，在仿真和真实世界任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法主要依赖点云作为观测输入，缺乏对仅使用视觉输入的解决方案的深入探索，而这类方法具有显著潜力。

Method: 利用VGGT的中间特征，结合DINOv2的语义特征和交替注意力块的几何特征，通过交叉注意力融合特征，并使用CNN进行空间压缩后输入策略头。

Result: 在仿真任务中平均成功率64.6%（与DP3的64.0%相当，远高于DP的34.8%），在真实世界任务中达到87.9%（优于DP3的67.5%和DP的11.2%），且在颜色、大小、背景和光照变化下保持高度稳定。

Conclusion: VO-DP证明了仅使用视觉输入的扩散策略学习方法的有效性，并开源了支持多机多GPU并行训练和混合精度训练的机器人操作训练库。

Abstract: In the context of imitation learning, visuomotor-based diffusion policy
learning is one of the main directions in robotic manipulation. Most of these
approaches rely on point clouds as observation inputs and construct scene
representations through point clouds feature learning, which enables them to
achieve remarkable accuracy. However, the existing literature lacks an in-depth
exploration of vision-only solutions that have significant potential. In this
paper, we propose a Vision-Only and single-view Diffusion Policy learning
method (VO-DP) that leverages pretrained visual foundation models to achieve
effective fusion of semantic and geometric features. We utilize intermediate
features from VGGT incorporating semantic features from DINOv2 and geometric
features from Alternating Attention blocks. Features are fused via
cross-attention and spatially compressed with a CNN to form the input to the
policy head. Extensive experiments demonstrate that VO-DP not only outperforms
the vision-only baseline DP significantly but also exhibits distinct
performance trends against the point cloud-based method DP3: in simulation
tasks, VO-DP achieves an average success rate of 64.6% on par with DP3 64.0%
and far higher than DP 34.8%, while in real-world tasks, it reaches 87.9%,
outperforming both DP3 67.5% and DP 11.2% by a notable margin. Further
robustness evaluations confirm that VO-DP remains highly stable under varying
conditions including color, size, background, and lighting. Lastly, we
open-source a training library for robotic manipulation. Built on Accelerate,
this library supports multi-machine and multi-GPU parallel training, as well as
mixed precision training. It is compatible with visuomotor policies such as DP,
DP3 and VO-DP, and also supports the RoboTwin simulator.

</details>


### [16] [Improved Extended Kalman Filter-Based Disturbance Observers for Exoskeletons](https://arxiv.org/abs/2510.15533)
*Shilei Li,Dawei Shi,Makoto Iwasaki,Yan Ning,Hongpeng Zhou,Ling Shi*

Main category: cs.RO

TL;DR: 本文提出两种新型干扰观测器方法，在二自由度控制结构中解决未知干扰导致的性能下降问题，在外骨骼实验中显著提高了关节跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 机械系统的名义性能常因未知干扰而下降，二自由度控制结构虽能解耦名义性能与干扰抑制，但当干扰动态未知时无法实现完美干扰抑制，需要改进干扰估计方法。

Method: 提出了两种新型干扰观测器：基于交互多模型扩展卡尔曼滤波的干扰观测器和基于多核相关熵扩展卡尔曼滤波的干扰观测器。

Result: 实验表明，在时变交互力场景下，与基于扩展卡尔曼滤波的干扰观测器相比，所提两种方法分别将髋关节跟踪误差降低了36.3%和16.2%，膝关节跟踪误差降低了46.3%和24.4%。

Conclusion: 所提出的两种干扰观测器方法在干扰估计方面表现优越，显著提高了外骨骼系统的跟踪精度。

Abstract: The nominal performance of mechanical systems is often degraded by unknown
disturbances. A two-degree-of-freedom control structure can decouple nominal
performance from disturbance rejection. However, perfect disturbance rejection
is unattainable when the disturbance dynamic is unknown. In this work, we
reveal an inherent trade-off in disturbance estimation subject to tracking
speed and tracking uncertainty. Then, we propose two novel methods to enhance
disturbance estimation: an interacting multiple model extended Kalman
filter-based disturbance observer and a multi-kernel correntropy extended
Kalman filter-based disturbance observer. Experiments on an exoskeleton verify
that the proposed two methods improve the tracking accuracy $36.3\%$ and
$16.2\%$ in hip joint error, and $46.3\%$ and $24.4\%$ in knee joint error,
respectively, compared to the extended Kalman filter-based disturbance
observer, in a time-varying interaction force scenario, demonstrating the
superiority of the proposed method.

</details>


### [17] [Adaptive Legged Locomotion via Online Learning for Model Predictive Control](https://arxiv.org/abs/2510.15626)
*Hongyu Zhou,Xiaoyu Zhang,Vasileios Tzoumas*

Main category: cs.RO

TL;DR: 提出了一种通过在线学习和模型预测控制实现自适应腿式运动的算法，该算法结合模型预测控制和残差动力学的在线学习，能够在未知负载和不平地形等不确定条件下实现鲁棒控制。


<details>
  <summary>Details</summary>
Motivation: 面向未来自主四足机器人能够在存在未知不确定性的真实环境中执行复杂任务，如未知负载和不平地形等挑战。

Method: 使用随机傅里叶特征在再生核希尔伯特空间中近似残差动力学，并基于当前学习的残差动力学模型进行模型预测控制，通过最小二乘法在线自监督更新模型。

Result: 算法具有次线性动态遗憾性能，在Gazebo和MuJoCo仿真中验证了有效性，能够处理高达12倍重力的未知外力、20度斜坡、0.25米高度变化的粗糙地形，以及8kg负载和时变地面摩擦系数。

Conclusion: 该算法通过在线学习和模型预测控制的结合，为腿式机器人在未知不确定环境中的自适应运动控制提供了有效解决方案。

Abstract: We provide an algorithm for adaptive legged locomotion via online learning
and model predictive control. The algorithm is composed of two interacting
modules: model predictive control (MPC) and online learning of residual
dynamics. The residual dynamics can represent modeling errors and external
disturbances. We are motivated by the future of autonomy where quadrupeds will
autonomously perform complex tasks despite real-world unknown uncertainty, such
as unknown payload and uneven terrains. The algorithm uses random Fourier
features to approximate the residual dynamics in reproducing kernel Hilbert
spaces. Then, it employs MPC based on the current learned model of the residual
dynamics. The model is updated online in a self-supervised manner using least
squares based on the data collected while controlling the quadruped. The
algorithm enjoys sublinear \textit{dynamic regret}, defined as the
suboptimality against an optimal clairvoyant controller that knows how the
residual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations,
where the quadruped aims to track reference trajectories. The Gazebo
simulations include constant unknown external forces up to $12\boldsymbol{g}$,
where $\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain
with $20\degree$ inclination, and rough terrain with $0.25m$ height variation.
The MuJoCo simulations include time-varying unknown disturbances with payload
up to $8~kg$ and time-varying ground friction coefficients in flat terrain.

</details>


### [18] [Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO MINDSTORMS](https://arxiv.org/abs/2510.15638)
*Jared K. Lepora,Haoran Li,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: 使用乐高MINDSTORMS构建的教育型仿人机器人手，采用肌腱驱动和欠驱动设计，通过双电机驱动肌腱对实现精细控制，使用差速机构和离合器齿轮实现软协同运动。


<details>
  <summary>Details</summary>
Motivation: 为教育环境设计一个仅使用标准乐高零件和常见家用设备的机器人手，让学生能够接触现代机器人技术的前沿概念。

Method: 基于Pisa/IIT SoftHand设计，采用肌腱驱动、高度欠驱动结构，每个手指使用双电机驱动肌腱对，通过差速机构和离合器齿轮实现软协同运动。

Result: 设计出能够自适应抓取各种物体的仿人机器人手，使用简单的驱动和控制机制，仅使用乐高零件即可构建。

Conclusion: 该乐高机器人手设计成功地将先进的机器人手概念引入教育领域，具有教育和启发儿童学习现代机器人技术的潜力。

Abstract: This paper introduces an anthropomorphic robot hand built entirely using LEGO
MINDSTORMS: the Educational SoftHand-A, a tendon-driven, highly-underactuated
robot hand based on the Pisa/IIT SoftHand and related hands. To be suitable for
an educational context, the design is constrained to use only standard LEGO
pieces with tests using common equipment available at home. The hand features
dual motors driving an agonist/antagonist opposing pair of tendons on each
finger, which are shown to result in reactive fine control. The finger motions
are synchonized through soft synergies, implemented with a differential
mechanism using clutch gears. Altogether, this design results in an
anthropomorphic hand that can adaptively grasp a broad range of objects using a
simple actuation and control mechanism. Since the hand can be constructed from
LEGO pieces and uses state-of-the-art design concepts for robotic hands, it has
the potential to educate and inspire children to learn about the frontiers of
modern robotics.

</details>


### [19] [Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation](https://arxiv.org/abs/2510.15639)
*Manuel J. Fernandez,Alejandro Suarez,Anibal Ollero,Matteo Fumagalli*

Main category: cs.RO

TL;DR: 本文提出了一种用于长距离空中操纵的可变刚度连杆(VSL)，能够在多旋翼平台和双臂机械手之间实现可调节的机械耦合，在柔性和刚性模式间切换以适应不同任务需求。


<details>
  <summary>Details</summary>
Motivation: 传统长距离操纵系统使用刚性或缆绳连接，限制了精度或将干扰传递给飞行器，需要一种能够根据任务需求调整刚度的连接机制。

Method: 在配备LiCAS双臂机械手的四旋翼无人机上集成可变刚度连杆，通过实验评估其在外部干扰和包裹运输任务中的性能。

Result: 可变刚度显著改变了无人机与负载之间的动态交互：柔性配置可衰减外部冲击和空气动力扰动，刚性配置则提高了操纵阶段的定位精度。

Conclusion: VSL增强了系统的多功能性和安全性，提供了可控的柔顺性与精度权衡，未来将研究自主刚度调节、多绳配置和协作空中操纵。

Abstract: This paper presents the integration of a Variable Stiffness Link (VSL) for
long-reach aerial manipulation, enabling adaptable mechanical coupling between
an aerial multirotor platform and a dual-arm manipulator. Conventional
long-reach manipulation systems rely on rigid or cable connections, which limit
precision or transmit disturbances to the aerial vehicle. The proposed VSL
introduces an adjustable stiffness mechanism that allows the link to behave
either as a flexible rope or as a rigid rod, depending on task requirements.
  The system is mounted on a quadrotor equipped with the LiCAS dual-arm
manipulator and evaluated through teleoperated experiments, involving external
disturbances and parcel transportation tasks. Results demonstrate that varying
the link stiffness significantly modifies the dynamic interaction between the
UAV and the payload. The flexible configuration attenuates external impacts and
aerodynamic perturbations, while the rigid configuration improves positional
accuracy during manipulation phases.
  These results confirm that VSL enhances versatility and safety, providing a
controllable trade-off between compliance and precision. Future work will focus
on autonomous stiffness regulation, multi-rope configurations, cooperative
aerial manipulation and user studies to further assess its impact on
teleoperated and semi-autonomous aerial tasks.

</details>


### [20] [Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing](https://arxiv.org/abs/2510.15668)
*Yameng Zhang,Dianye Huang,Max Q. -H. Meng,Nassir Navab,Zhongliang Jiang*

Main category: cs.RO

TL;DR: 提出了一种基于轻量级摄像头和视觉伺服的低成本3D超声成像解决方案，通过图像修复和仿真循环方法解决遮挡和姿态估计问题，在多个模型上验证了其鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统自由手3D超声成像依赖昂贵的跟踪系统，而基于神经网络的方法受图像噪声和误差累积影响，重建精度受限。需要一种成本效益高且准确的方法。

Method: 使用轻量级摄像头捕捉纹理平面工作区的视觉反馈；引入图像修复方法重建遮挡区域；开发仿真循环姿态估计方法，在仿真中复制系统设置并最小化姿态误差；使用视觉伺服控制器优化相机视图对齐。

Result: 在软血管模型、3D打印圆锥模型和人体手臂上的验证显示，与参考重建的Hausdorff距离分别为0.359mm、1.171mm和0.858mm。

Conclusion: 该方法在自由手3D超声重建中表现出鲁棒性和准确性，具有临床应用潜力。

Abstract: Freehand 3D ultrasound (US) imaging using conventional 2D probes offers
flexibility and accessibility for diverse clinical applications but faces
challenges in accurate probe pose estimation. Traditional methods depend on
costly tracking systems, while neural network-based methods struggle with image
noise and error accumulation, compromising reconstruction precision. We propose
a cost-effective and versatile solution that leverages lightweight cameras and
visual servoing in simulated environments for precise 3D US imaging. These
cameras capture visual feedback from a textured planar workspace. To counter
occlusions and lighting issues, we introduce an image restoration method that
reconstructs occluded regions by matching surrounding texture patterns. For
pose estimation, we develop a simulation-in-the-loop approach, which replicates
the system setup in simulation and iteratively minimizes pose errors between
simulated and real-world observations. A visual servoing controller refines the
alignment of camera views, improving translational estimation by optimizing
image alignment. Validations on a soft vascular phantom, a 3D-printed conical
model, and a human arm demonstrate the robustness and accuracy of our approach,
with Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171
mm, and 0.858 mm, respectively. These results confirm the method's potential
for reliable freehand 3D US reconstruction.

</details>


### [21] [HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward](https://arxiv.org/abs/2510.15679)
*Yuhong Cao,Yizhuo Wang,Jingsong Liang,Shuhao Liao,Yifeng Zhang,Peizhuo Li,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: HEADER是一种基于注意力的强化学习方法，使用分层图进行大规模环境中的高效自主探索，在模拟和真实场景中都表现出优越的探索效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 推动基于学习的方法在自主机器人探索中的边界，特别是在环境规模和探索效率方面，解决现有方法在大规模环境中的局限性。

Method: 采用基于注意力的强化学习，构建分层图表示，设计新颖的基于社区的算法来构建和更新全局图，同时引入无参数的优先奖励机制。

Result: 在模拟的大规模探索场景中，HEADER比大多数现有学习方法表现出更好的可扩展性，探索效率比最先进基线提高了20%。在真实硬件部署中，成功验证了在300m*230m校园环境中的有效性。

Conclusion: HEADER通过分层图表示、注意力机制和无参数奖励设计，实现了在大规模环境中高效、可扩展的自主探索，为机器人探索任务提供了有效的解决方案。

Abstract: This work pushes the boundaries of learning-based methods in autonomous robot
exploration in terms of environmental scale and exploration efficiency. We
present HEADER, an attention-based reinforcement learning approach with
hierarchical graphs for efficient exploration in large-scale environments.
HEADER follows existing conventional methods to construct hierarchical
representations for the robot belief/map, but further designs a novel
community-based algorithm to construct and update a global graph, which remains
fully incremental, shape-adaptive, and operates with linear complexity.
Building upon attention-based networks, our planner finely reasons about the
nearby belief within the local range while coarsely leveraging distant
information at the global scale, enabling next-best-viewpoint decisions that
consider multi-scale spatial dependencies. Beyond novel map representation, we
introduce a parameter-free privileged reward that significantly improves model
performance and produces near-optimal exploration behaviors, by avoiding
training objective bias caused by handcrafted reward shaping. In simulated
challenging, large-scale exploration scenarios, HEADER demonstrates better
scalability than most existing learning and non-learning methods, while
achieving a significant improvement in exploration efficiency (up to 20%) over
state-of-the-art baselines. We also deploy HEADER on hardware and validate it
in complex, large-scale real-life scenarios, including a 300m*230m campus
environment.

</details>


### [22] [Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution for Multi-Robot Systems](https://arxiv.org/abs/2510.15686)
*Taehyeon Kim,Vishnunandan L. N. Venkatesh,Byung-Cheol Min*

Main category: cs.RO

TL;DR: 提出DDACE框架，通过解耦时空要素实现多机器人系统的少样本学习，显著降低数据需求


<details>
  <summary>Details</summary>
Motivation: 传统从演示中学习方法需要大量数据，难以适应多机器人系统的实际应用需求

Method: 使用时序图网络学习任务无关的时间序列，高斯过程建模空间轨迹，实现模块化设计

Result: 实验证明在少样本条件下成功执行任务，并在动态多样化环境中有效泛化

Conclusion: 模块化架构能提升多机器人系统在实际应用中的实用性和可扩展性

Abstract: In this paper, we propose a novel few-shot learning framework for multi-robot
systems that integrate both spatial and temporal elements: Few-Shot
Demonstration-Driven Task Coordination and Trajectory Execution (DDACE). Our
approach leverages temporal graph networks for learning task-agnostic temporal
sequencing and Gaussian Processes for spatial trajectory modeling, ensuring
modularity and generalization across various tasks. By decoupling temporal and
spatial aspects, DDACE requires only a small number of demonstrations,
significantly reducing data requirements compared to traditional learning from
demonstration approaches. To validate our proposed framework, we conducted
extensive experiments in task environments designed to assess various aspects
of multi-robot coordination-such as multi-sequence execution, multi-action
dynamics, complex trajectory generation, and heterogeneous configurations. The
experimental results demonstrate that our approach successfully achieves task
execution under few-shot learning conditions and generalizes effectively across
dynamic and diverse settings. This work underscores the potential of modular
architectures in enhancing the practicality and scalability of multi-robot
systems in real-world applications. Additional materials are available at
https://sites.google.com/view/ddace.

</details>


### [23] [DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation](https://arxiv.org/abs/2510.15786)
*Xinyue Xu,Jieqiang Sun,Jing,Dai,Siyuan Chen,Lanjie Ma,Ke Sun,Bin Zhao,Jianbo Yuan,Yiwen Lu*

Main category: cs.RO

TL;DR: DexCanvas是一个大规模混合现实-合成的人类操作数据集，包含7000小时灵巧手-物体交互数据，基于70小时真实人类演示构建，涵盖21种基本操作类型。


<details>
  <summary>Details</summary>
Motivation: 现有的操作数据集缺乏大规模真实演示、系统性技能覆盖和物理验证的接触标注，限制了机器人操作学习、接触丰富控制和技能迁移的研究。

Method: 采用真实到仿真的流程，使用强化学习训练策略来控制物理仿真中的驱动MANO手，重现人类演示并发现产生观察物体运动的底层接触力。

Result: 创建了首个结合大规模真实演示、基于既定分类的系统技能覆盖和物理验证接触标注的操作数据集，包含同步多视角RGB-D、高精度动作捕捉和每帧接触点。

Conclusion: DexCanvas数据集能够促进机器人操作学习、接触丰富控制和不同手形态间的技能迁移研究。

Abstract: We present DexCanvas, a large-scale hybrid real-synthetic human manipulation
dataset containing 7,000 hours of dexterous hand-object interactions seeded
from 70 hours of real human demonstrations, organized across 21 fundamental
manipulation types based on the Cutkosky taxonomy. Each entry combines
synchronized multi-view RGB-D, high-precision mocap with MANO hand parameters,
and per-frame contact points with physically consistent force profiles. Our
real-to-sim pipeline uses reinforcement learning to train policies that control
an actuated MANO hand in physics simulation, reproducing human demonstrations
while discovering the underlying contact forces that generate the observed
object motion. DexCanvas is the first manipulation dataset to combine
large-scale real demonstrations, systematic skill coverage based on established
taxonomies, and physics-validated contact annotations. The dataset can
facilitate research in robotic manipulation learning, contact-rich control, and
skill transfer across different hand morphologies.

</details>


### [24] [Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric Methods with Real-Time Feedback Using INAF Fusion](https://arxiv.org/abs/2510.15803)
*Zahra Arjmandi,Gunho Sohn*

Main category: cs.RO

TL;DR: 提出了一种基于推断注意力融合(INAF)模块的新型LiDAR SLAM融合技术，通过AI与几何里程计的结合提升定位和3D建图精度。


<details>
  <summary>Details</summary>
Motivation: 旨在改进LiDAR传感器的定位和3D建图能力，通过融合AI技术增强系统在复杂环境中的适应性和测量精度。

Method: 采用推断注意力融合(INAF)模块，基于KITTI数据集的LiDAR数据，根据环境反馈动态调整注意力权重。

Result: 该方法显著提升了定位和3D建图的精度，增强了系统在复杂场景中的适应性。

Conclusion: 该融合技术展示了提升自主导航系统在复杂场景中性能的潜力，证明了AI与几何方法结合的有效性。

Abstract: This paper presents a novel fusion technique for LiDAR Simultaneous
Localization and Mapping (SLAM), aimed at improving localization and 3D mapping
using LiDAR sensor. Our approach centers on the Inferred Attention Fusion
(INAF) module, which integrates AI with geometric odometry. Utilizing the KITTI
dataset's LiDAR data, INAF dynamically adjusts attention weights based on
environmental feedback, enhancing the system's adaptability and measurement
accuracy. This method advances the precision of both localization and 3D
mapping, demonstrating the potential of our fusion technique to enhance
autonomous navigation systems in complex scenarios.

</details>
