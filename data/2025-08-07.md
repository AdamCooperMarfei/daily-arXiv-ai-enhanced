<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 16]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Uncertainty-aware Accurate Elevation Modeling for Off-road Navigation via Neural Processes](https://arxiv.org/abs/2508.03890)
*Sanghun Jung,Daehoon Gwak,Byron Boots,James Hays*

Main category: cs.RO

TL;DR: 提出了一种基于神经过程（NPs）的地形高程建模方法，结合贝叶斯不确定性估计和神经网络的高效性，显著提升了实时性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如高斯过程和神经网络）无法同时满足实时性、准确性和不确定性量化的需求，限制了越野导航的可靠性和安全性。

Method: 利用LiDAR和相机传感器的语义特征，结合局部球查询注意力机制，降低计算复杂度并提升插值和外推精度。

Result: 在包含复杂几何特征的越野数据集上表现优于基线方法，计算复杂度降低了17%。

Conclusion: 神经过程为复杂越野环境中的地形建模提供了一种高效且表达能力强的解决方案。

Abstract: Terrain elevation modeling for off-road navigation aims to accurately
estimate changes in terrain geometry in real-time and quantify the
corresponding uncertainties. Having precise estimations and uncertainties plays
a crucial role in planning and control algorithms to explore safe and reliable
maneuver strategies. However, existing approaches, such as Gaussian Processes
(GPs) and neural network-based methods, often fail to meet these needs. They
are either unable to perform in real-time due to high computational demands,
underestimating sharp geometry changes, or harming elevation accuracy when
learned with uncertainties. Recently, Neural Processes (NPs) have emerged as a
promising approach that integrates the Bayesian uncertainty estimation of GPs
with the efficiency and flexibility of neural networks. Inspired by NPs, we
propose an effective NP-based method that precisely estimates sharp elevation
changes and quantifies the corresponding predictive uncertainty without losing
elevation accuracy. Our method leverages semantic features from LiDAR and
camera sensors to improve interpolation and extrapolation accuracy in
unobserved regions. Also, we introduce a local ball-query attention mechanism
to effectively reduce the computational complexity of global attention by 17\%
while preserving crucial local and spatial information. We evaluate our method
on off-road datasets having interesting geometric features, collected from
trails, deserts, and hills. Our results demonstrate superior performance over
baselines and showcase the potential of neural processes for effective and
expressive terrain modeling in complex off-road environments.

</details>


### [2] [Constraint-Preserving Data Generation for Visuomotor Policy Learning](https://arxiv.org/abs/2508.03944)
*Kevin Lin,Varun Ragunath,Andrew McAlinden,Aaditya Prasad,Jimmy Wu,Yuke Zhu,Jeannette Bohg*

Main category: cs.RO

TL;DR: CP-Gen利用单条专家轨迹生成包含新物体几何和姿态的机器人演示数据，训练出的策略在真实世界中零样本迁移且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 大规模演示数据成本高且耗时，CP-Gen旨在通过少量数据生成多样化演示，提升机器人操作的泛化能力。

Method: 将专家轨迹分解为自由空间运动和机器人技能，通过关键点轨迹约束实现几何感知的数据生成，采样变换后优化机器人关节配置。

Result: 在16个仿真任务和4个真实任务中，CP-Gen训练的策略平均成功率达77%，优于基线方法的50%。

Conclusion: CP-Gen通过几何感知的数据生成方法，显著提升了机器人策略的泛化能力和真实世界适应性。

Abstract: Large-scale demonstration data has powered key breakthroughs in robot
manipulation, but collecting that data remains costly and time-consuming. We
present Constraint-Preserving Data Generation (CP-Gen), a method that uses a
single expert trajectory to generate robot demonstrations containing novel
object geometries and poses. These generated demonstrations are used to train
closed-loop visuomotor policies that transfer zero-shot to the real world and
generalize across variations in object geometries and poses. Similar to prior
work using pose variations for data generation, CP-Gen first decomposes expert
demonstrations into free-space motions and robot skills. But unlike those
works, we achieve geometry-aware data generation by formulating robot skills as
keypoint-trajectory constraints: keypoints on the robot or grasped object must
track a reference trajectory defined relative to a task-relevant object. To
generate a new demonstration, CP-Gen samples pose and geometry transforms for
each task-relevant object, then applies these transforms to the object and its
associated keypoints or keypoint trajectories. We optimize robot joint
configurations so that the keypoints on the robot or grasped object track the
transformed keypoint trajectory, and then motion plan a collision-free path to
the first optimized joint configuration. Experiments on 16 simulation tasks and
four real-world tasks, featuring multi-stage, non-prehensile and
tight-tolerance manipulation, show that policies trained using CP-Gen achieve
an average success rate of 77%, outperforming the best baseline that achieves
an average of 50%.

</details>


### [3] [Optimization of sliding control parameters for a 3-dof robot arm using genetic algorithm (GA)](https://arxiv.org/abs/2508.04009)
*Vu Ngoc Son,Pham Van Cuong,Dao Thi My Linh,Le Tieu Nien*

Main category: cs.RO

TL;DR: 使用遗传算法优化机器人滑模控制参数，提高轨迹跟踪精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在不确定和干扰条件下，滑模控制（SMC）参数的选取对系统性能和鲁棒性至关重要，但难以确定。

Method: 采用遗传算法（GA）寻找最优SMC参数，满足性能需求。

Result: 仿真结果表明，GA-SMC方法比传统SMC和模糊SMC具有更好的跟踪能力和更小的抖动效应。

Conclusion: 遗传算法优化SMC参数是一种高效方法，适用于机器人轨迹跟踪控制。

Abstract: This paper presents a method for optimizing the sliding mode control (SMC)
parameter for a robot manipulator applying a genetic algorithm (GA). The
objective of the SMC is to achieve precise and consistent tracking of the
trajectory of the robot manipulator under uncertain and disturbed conditions.
However, the system effectiveness and robustness depend on the choice of the
SMC parameters, which is a difficult and crucial task. To solve this problem, a
genetic algorithm is used to locate the optimal values of these parameters that
gratify the capability criteria. The proposed method is efficient compared with
the conventional SMC and Fuzzy-SMC. The simulation results show that the
genetic algorithm with SMC can achieve better tracking capability and reduce
the chattering effect.

</details>


### [4] [SCOUT: An in-vivo Methane Sensing System for Real-time Monitoring of Enteric Emissions in Cattle with ex-vivo Validation](https://arxiv.org/abs/2508.04056)
*Yuelin Deng,Hinayah Rojas de Oliveira,Richard M. Voyles,Upinder Kaur*

Main category: cs.RO

TL;DR: SCOUT系统是一种新型的体内甲烷监测技术，通过闭环气体循环设计实现高分辨率连续监测，显著优于传统环境采样方法。


<details>
  <summary>Details</summary>
Motivation: 当前肠道甲烷排放测量方法存在数据保留率低、环境干扰大和时间分辨率不足的问题，限制了畜牧业的可持续发展。

Method: 开发了SCOUT系统，采用闭环气体循环设计，通过高分辨率连续监测瘤胃甲烷浓度，并与传统环境采样系统进行交叉验证。

Result: SCOUT数据保留率达82%，甲烷浓度测量范围比传统方法高100-1000倍，揭示了行为与排放的新关联。

Conclusion: SCOUT系统为基因组选择和精准畜牧管理提供了可靠工具，推动了可持续畜牧业的发展。

Abstract: Accurate measurement of enteric methane emissions remains a critical
bottleneck for advancing livestock sustainability through genetic selection and
precision management. Existing ambient sampling approaches suffer from low data
retention rates, environmental interference, and limited temporal resolution.
We developed SCOUT (Smart Cannula-mounted Optical Unit for Trace-methane), the
first robust in-vivo sensing system enabling continuous, high-resolution
monitoring of ruminal methane concentrations through an innovative closed-loop
gas recirculation design. We conducted comprehensive validation with two
cannulated Simmental heifers under contrasting dietary treatments, with
cross-platform comparison against established ambient sniffer systems. SCOUT
achieved exceptional performance with 82% data retention compared to 17% for
conventional sniffer systems, while capturing methane concentrations 100-1000x
higher than ambient approaches. Cross-platform validation demonstrated strong
scale-dependent correlations, with optimal correlation strength (r = -0.564
$\pm$ 0.007) at biologically relevant 40-minute windows and 100% statistical
significance. High-frequency monitoring revealed novel behavior-emission
coupling, including rapid concentration changes (14.5 $\pm$ 11.3k ppm)
triggered by postural transitions within 15 minutes, insights previously
inaccessible through existing technologies. The SCOUT system represents a
transformative advancement, enabling accurate, continuous emission phenotyping
essential for genomic selection programs and sustainable precision livestock
management. This validation framework establishes new benchmarks for
agricultural sensor performance while generating unprecedented biological
insights into ruminal methane dynamics, contributing essential tools for
sustainable livestock production in climate-conscious agricultural systems.

</details>


### [5] [DRIVE: Dynamic Rule Inference and Verified Evaluation for Constraint-Aware Autonomous Driving](https://arxiv.org/abs/2508.04066)
*Longling Geng,Huangxing Li,Viktor Lado Naess,Mert Pilanci*

Main category: cs.RO

TL;DR: DRIVE框架通过动态规则推断和验证评估，从专家演示中建模人类驾驶约束，结合概率表示和凸优化规划，实现安全且符合人类偏好的自动驾驶轨迹生成。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需遵守隐含且上下文相关的软约束，但现有方法难以明确表达这些约束。

Method: DRIVE利用指数族似然建模估计状态转移可行性，构建概率化行为规则，并通过凸优化规划生成轨迹。

Result: 实验表明DRIVE在多种驾驶场景中实现0.0%软约束违反率，轨迹更平滑且泛化能力更强。

Conclusion: DRIVE为自动驾驶提供了一种高效、可解释且鲁棒的框架，适用于实际部署。

Abstract: Understanding and adhering to soft constraints is essential for safe and
socially compliant autonomous driving. However, such constraints are often
implicit, context-dependent, and difficult to specify explicitly. In this work,
we present DRIVE, a novel framework for Dynamic Rule Inference and Verified
Evaluation that models and evaluates human-like driving constraints from expert
demonstrations. DRIVE leverages exponential-family likelihood modeling to
estimate the feasibility of state transitions, constructing a probabilistic
representation of soft behavioral rules that vary across driving contexts.
These learned rule distributions are then embedded into a convex
optimization-based planning module, enabling the generation of trajectories
that are not only dynamically feasible but also compliant with inferred human
preferences. Unlike prior approaches that rely on fixed constraint forms or
purely reward-based modeling, DRIVE offers a unified framework that tightly
couples rule inference with trajectory-level decision-making. It supports both
data-driven constraint generalization and principled feasibility verification.
We validate DRIVE on large-scale naturalistic driving datasets, including inD,
highD, and RoundD, and benchmark it against representative inverse constraint
learning and planning baselines. Experimental results show that DRIVE achieves
0.0% soft constraint violation rates, smoother trajectories, and stronger
generalization across diverse driving scenarios. Verified evaluations further
demonstrate the efficiency, explanability, and robustness of the framework for
real-world deployment.

</details>


### [6] [Industrial Robot Motion Planning with GPUs: Integration of cuRobo for Extended DOF Systems](https://arxiv.org/abs/2508.04146)
*Luai Abuelsamen,Harsh Rana,Ho-Wei Lu,Wenhan Tang,Swati Priyadarshini,Gabriel Gomes*

Main category: cs.RO

TL;DR: 论文提出了一种基于GPU加速的运动规划方法，通过集成NVIDIA的cuRobo库，显著提升了工业机器人在复杂环境中的运动规划效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 工业机器人（尤其是多轴系统）在复杂环境中的高效运动规划是一个关键挑战。

Method: 利用NVIDIA的cuRobo库，结合CAD数字孪生和实时并行优化，实现快速轨迹生成和动态避障。

Result: 在配备额外自由度（如第7轴龙门架）的机器人上测试，结果显示规划速度和鲁棒性显著提升。

Conclusion: GPU加速的运动规划管道在现代工业工作流程中具有可扩展和适应性部署的潜力。

Abstract: Efficient motion planning remains a key challenge in industrial robotics,
especially for multi-axis systems operating in complex environments. This paper
addresses that challenge by integrating GPU-accelerated motion planning through
NVIDIA's cuRobo library into Vention's modular automation platform. By
leveraging accurate CAD-based digital twins and real-time parallel
optimization, our system enables rapid trajectory generation and dynamic
collision avoidance for pick-and-place tasks. We demonstrate this capability on
robots equipped with additional degrees of freedom, including a 7th-axis
gantry, and benchmark performance across various scenarios. The results show
significant improvements in planning speed and robustness, highlighting the
potential of GPU-based planning pipelines for scalable, adaptable deployment in
modern industrial workflows.

</details>


### [7] [Improving Tactile Gesture Recognition with Optical Flow](https://arxiv.org/abs/2508.04338)
*Shaohong Zhong,Alessandro Albini,Giammarco Caroleo,Giorgio Cannata,Perla Maiolino*

Main category: cs.RO

TL;DR: 提出了一种通过计算密集光流来增强触觉图像动态信息的方法，显著提升了触觉手势识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有触觉手势识别系统仅依赖触觉图像的压力分布信息，难以区分动态相似但静态图像相似的手势。

Method: 在触觉图像中计算密集光流，以突出接触动态信息，作为分类器的额外输入。

Result: 实验表明，使用光流增强触觉图像的分类器在手势识别任务中准确率提升了9%。

Conclusion: 通过引入动态信息，触觉手势识别的准确性得到显著提升，为HRI提供了更可靠的交互方式。

Abstract: Tactile gesture recognition systems play a crucial role in Human-Robot
Interaction (HRI) by enabling intuitive communication between humans and
robots. The literature mainly addresses this problem by applying machine
learning techniques to classify sequences of tactile images encoding the
pressure distribution generated when executing the gestures. However, some
gestures can be hard to differentiate based on the information provided by
tactile images alone. In this paper, we present a simple yet effective way to
improve the accuracy of a gesture recognition classifier. Our approach focuses
solely on processing the tactile images used as input by the classifier. In
particular, we propose to explicitly highlight the dynamics of the contact in
the tactile image by computing the dense optical flow. This additional
information makes it easier to distinguish between gestures that produce
similar tactile images but exhibit different contact dynamics. We validate the
proposed approach in a tactile gesture recognition task, showing that a
classifier trained on tactile images augmented with optical flow information
achieved a 9% improvement in gesture classification accuracy compared to one
trained on standard tactile images.

</details>


### [8] [Tactile Comfort: Lowering Heart Rate Through Interactions](https://arxiv.org/abs/2508.04372)
*Morten Roed Frederiksen,Kasper Støy,Maja Matarić*

Main category: cs.RO

TL;DR: 研究探讨了一种无需预先训练的口袋伴侣机器人，通过触觉游戏分散注意力，显著降低儿童心率。


<details>
  <summary>Details</summary>
Motivation: 现有焦虑管理策略需预先训练，而机器人可提供即时放松效果。

Method: 通过两项研究（14天试点和主研究），测量儿童使用机器人前后的心率变化。

Result: 机器人显著降低心率（p<0.01），显示一致放松效果。

Conclusion: 触觉伴侣机器人有望提升放松技术的治疗效果。

Abstract: Children diagnosed with anxiety disorders are taught a range of strategies to
navigate situations of heightened anxiety. Techniques such as deep breathing
and repetition of mantras are commonly employed, as they are known to be
calming and reduce elevated heart rates. Although these strategies are often
effective, their successful application relies on prior training of the
children for successful use when faced with challenging situations. This paper
investigates a pocket-sized companion robot designed to offer a relaxation
technique requiring no prior training, with a focus on immediate impact on the
user's heart rate. The robot utilizes a tactile game to divert the user's
attention, thereby promoting relaxation. We conducted two studies with children
who were not diagnosed with anxiety: a 14-day pilot study with two children
(age 8) and a main study with 18 children (ages 7-8). Both studies employed a
within-subjects design and focused on measuring heart rate during tactile
interaction with the robot and during non-use. Interacting with the robot was
found to significantly lower the study participants' heart rate (p$<$0.01)
compared to the non-use condition, indicating a consistent calming effect
across all participants. These results suggest that tactile companion robots
have the potential to enhance the therapeutic value of relaxation techniques.

</details>


### [9] [Incorporating Stochastic Models of Controller Behavior into Kinodynamic Efficiently Adaptive State Lattices for Mobile Robot Motion Planning in Off-Road Environments](https://arxiv.org/abs/2508.04384)
*Eric R. Damm,Eli S. Lancaster,Felix A. Sanchez,Kiana Bronder,Jason M. Gregory,Thomas M. Howard*

Main category: cs.RO

TL;DR: 论文提出三种方法，将随机控制器行为整合到KEASL规划器的重组搜索空间中，以减少物理机器人运动中的误差和不确定性。实验表明，该方法能生成更保守的轨迹，降低碰撞概率。


<details>
  <summary>Details</summary>
Motivation: 解决物理机器人运动中因实际物理和控制器不确定性导致的模型误差问题。

Method: 提出三种方法，将随机控制器行为整合到KEASL规划器的重组搜索空间中。

Result: 实验表明，该方法生成的轨迹更保守，碰撞概率降低，但与基线规划相比，规划成功率有所下降。

Conclusion: 整合随机控制器行为能有效减少碰撞概率，但需权衡规划成功率。

Abstract: Mobile robot motion planners rely on theoretical models to predict how the
robot will move through the world. However, when deployed on a physical robot,
these models are subject to errors due to real-world physics and uncertainty in
how the lower-level controller follows the planned trajectory. In this work, we
address this problem by presenting three methods of incorporating stochastic
controller behavior into the recombinant search space of the Kinodynamic
Efficiently Adaptive State Lattice (KEASL) planner. To demonstrate this work,
we analyze the results of experiments performed on a Clearpath Robotics Warthog
Unmanned Ground Vehicle (UGV) in an off-road, unstructured environment using
two different perception algorithms, and performed an ablation study using a
full spectrum of simulated environment map complexities. Analysis of the data
found that incorporating stochastic controller sampling into KEASL leads to
more conservative trajectories that decrease predicted collision likelihood
when compared to KEASL without sampling. When compared to baseline planning
with expanded obstacle footprints, the predicted likelihood of collisions
becomes more comparable, but reduces the planning success rate for baseline
search.

</details>


### [10] [Reliable and Real-Time Highway Trajectory Planning via Hybrid Learning-Optimization Frameworks](https://arxiv.org/abs/2508.04436)
*Yujia Lu,Chong Wei,Lu Ma*

Main category: cs.RO

TL;DR: 提出了一种混合轨迹规划框架，结合学习方法的适应性和优化方法的安全性，用于高速公路自动驾驶，实现高效、安全的轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 高速公路驾驶环境变化快、反应时间有限，碰撞风险高，需要可靠且高效的轨迹规划方法。

Method: 采用双层架构：上层使用图神经网络（GNN）预测人类驾驶行为，下层通过混合整数二次规划（MIQP）进行路径优化，引入线性近似降低计算复杂度。

Result: 在复杂紧急场景中生成平滑、无碰撞轨迹，成功率超过97%，平均规划时间54毫秒，具备实时性。

Conclusion: 该框架有效结合学习与优化方法，显著提升轨迹规划的安全性和效率，适用于实时自动驾驶。

Abstract: Autonomous highway driving presents a high collision risk due to
fast-changing environments and limited reaction time, necessitating reliable
and efficient trajectory planning. This paper proposes a hybrid trajectory
planning framework that integrates the adaptability of learning-based methods
with the formal safety guarantees of optimization-based approaches. The
framework features a two-layer architecture: an upper layer employing a graph
neural network (GNN) trained on real-world highway data to predict human-like
longitudinal velocity profiles, and a lower layer utilizing path optimization
formulated as a mixed-integer quadratic programming (MIQP) problem. The primary
contribution is the lower-layer path optimization model, which introduces a
linear approximation of discretized vehicle geometry to substantially reduce
computational complexity, while enforcing strict spatiotemporal non-overlapping
constraints to formally guarantee collision avoidance throughout the planning
horizon. Experimental results demonstrate that the planner generates highly
smooth, collision-free trajectories in complex real-world emergency scenarios,
achieving success rates exceeding 97% with average planning times of 54 ms,
thereby confirming real-time capability.

</details>


### [11] [Behaviorally Adaptive Multi-Robot Hazard Localization in Failure-Prone, Communication-Denied Environments](https://arxiv.org/abs/2508.04537)
*Alkesh K. Srivastava,Aamodh Suresh,Carlos Nieto-Granda*

Main category: cs.RO

TL;DR: 论文提出了一种基于行为熵的多机器人自适应路径规划框架（BAPP），用于高风险环境中的自主危险地图绘制，并通过算法BAPP-TID和BAPP-SIG优化信息收集和机器人存活率。


<details>
  <summary>Details</summary>
Motivation: 解决高风险、易故障、通信受限环境中多机器人自主探索和地图绘制的挑战，如灾后区域或行星表面。

Method: 提出了基于行为熵（BE）的自适应路径规划框架（BAPP），包含BAPP-TID（智能触发高保真机器人）和BAPP-SIG（高风险下安全部署）两种算法。

Result: BAPP框架在单机器人和多机器人模拟中优于基于香农熵和随机策略的方法，BAPP-TID加速熵减，BAPP-SIG提高存活率且信息损失最小。

Conclusion: 行为自适应规划在复杂高风险环境中具有显著优势，通过空间分区和角色异构实现多机器人高效扩展。

Abstract: We address the challenge of multi-robot autonomous hazard mapping in
high-risk, failure-prone, communication-denied environments such as
post-disaster zones, underground mines, caves, and planetary surfaces. In these
missions, robots must explore and map hazards while minimizing the risk of
failure due to environmental threats or hardware limitations. We introduce a
behavior-adaptive, information-theoretic planning framework for multi-robot
teams grounded in the concept of Behavioral Entropy (BE), that generalizes
Shannon entropy (SE) to capture diverse human-like uncertainty evaluations.
Building on this formulation, we propose the Behavior-Adaptive Path Planning
(BAPP) framework, which modulates information gathering strategies via a
tunable risk-sensitivity parameter, and present two planning algorithms:
BAPP-TID for intelligent triggering of high-fidelity robots, and BAPP-SIG for
safe deployment under high risk. We provide theoretical insights on the
informativeness of the proposed BAPP framework and validate its effectiveness
through both single-robot and multi-robot simulations. Our results show that
the BAPP stack consistently outperforms Shannon-based and random strategies:
BAPP-TID accelerates entropy reduction, while BAPP-SIG improves robot
survivability with minimal loss in information gain. In multi-agent
deployments, BAPP scales effectively through spatial partitioning, mobile base
relocation, and role-aware heterogeneity. These findings underscore the value
of behavior-adaptive planning for robust, risk-sensitive exploration in
complex, failure-prone environments.

</details>


### [12] [$NavA^3$: Understanding Any Instruction, Navigating Anywhere, Finding Anything](https://arxiv.org/abs/2508.04598)
*Lingfeng Zhang,Xiaoshuai Hao,Yingbo Tang,Haoxiang Fu,Xinyu Zheng,Pengwei Wang,Zhongyuan Wang,Wenbo Ding,Shanghang Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种名为$NavA^3$的分层框架，用于解决开放场景下的长时程导航任务，结合全局和局部策略，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有导航任务局限于预定义对象或指令跟随，无法满足真实场景中复杂开放需求，因此需要一种能理解高级指令并具备开放词汇定位能力的方法。

Method: 采用分层框架，全局策略利用Reasoning-VLM解析指令并结合3D场景视图，局部策略通过NaviAfford模型（PointingVLM）实现开放词汇定位和空间感知。

Result: 实验表明$NavA^3$在导航性能上达到SOTA，并能成功完成不同机器人平台的长时程导航任务。

Conclusion: $NavA^3$为通用导航提供了新方向，数据集和代码将公开。

Abstract: Embodied navigation is a fundamental capability of embodied intelligence,
enabling robots to move and interact within physical environments. However,
existing navigation tasks primarily focus on predefined object navigation or
instruction following, which significantly differs from human needs in
real-world scenarios involving complex, open-ended scenes. To bridge this gap,
we introduce a challenging long-horizon navigation task that requires
understanding high-level human instructions and performing spatial-aware object
navigation in real-world environments. Existing embodied navigation methods
struggle with such tasks due to their limitations in comprehending high-level
human instructions and localizing objects with an open vocabulary. In this
paper, we propose $NavA^3$, a hierarchical framework divided into two stages:
global and local policies. In the global policy, we leverage the reasoning
capabilities of Reasoning-VLM to parse high-level human instructions and
integrate them with global 3D scene views. This allows us to reason and
navigate to regions most likely to contain the goal object. In the local
policy, we have collected a dataset of 1.0 million samples of spatial-aware
object affordances to train the NaviAfford model (PointingVLM), which provides
robust open-vocabulary object localization and spatial awareness for precise
goal identification and navigation in complex environments. Extensive
experiments demonstrate that $NavA^3$ achieves SOTA results in navigation
performance and can successfully complete longhorizon navigation tasks across
different robot embodiments in real-world settings, paving the way for
universal embodied navigation. The dataset and code will be made available.
Project website: https://NavigationA3.github.io/.

</details>


### [13] [RoboTron-Sim: Improving Real-World Driving via Simulated Hard-Case](https://arxiv.org/abs/2508.04642)
*Baihui Xiao,Chengjian Feng,Zhijian Huang,Feng yan,Yujie Zhong,Lin Ma*

Main category: cs.RO

TL;DR: RoboTron-Sim利用模拟数据提升自动驾驶系统在关键场景中的性能，通过HASS数据集和SPE、I2E Encoder方法，性能提升约50%。


<details>
  <summary>Details</summary>
Motivation: 解决现实中罕见高风险场景数据不足的问题，提升自动驾驶系统在关键情况下的表现。

Method: 开发HASS模拟数据集，引入SPE和I2E Encoder方法，利用多模态大语言模型学习驾驶技能。

Result: 在nuScenes上实验显示性能提升约50%，达到实时开环规划的最优结果。

Conclusion: RoboTron-Sim能有效管理罕见高风险驾驶场景，提升自动驾驶系统的鲁棒性。

Abstract: Collecting real-world data for rare high-risk scenarios, long-tailed driving
events, and complex interactions remains challenging, leading to poor
performance of existing autonomous driving systems in these critical
situations. In this paper, we propose RoboTron-Sim that improves real-world
driving in critical situations by utilizing simulated hard cases. First, we
develop a simulated dataset called Hard-case Augmented Synthetic Scenarios
(HASS), which covers 13 high-risk edge-case categories, as well as balanced
environmental conditions such as day/night and sunny/rainy. Second, we
introduce Scenario-aware Prompt Engineering (SPE) and an Image-to-Ego Encoder
(I2E Encoder) to enable multimodal large language models to effectively learn
real-world challenging driving skills from HASS, via adapting to environmental
deviations and hardware differences between real-world and simulated scenarios.
Extensive experiments on nuScenes show that RoboTron-Sim improves driving
performance in challenging scenarios by around 50%, achieving state-of-the-art
results in real-world open-loop planning. Qualitative results further
demonstrate the effectiveness of RoboTron-Sim in better managing rare high-risk
driving scenarios. Project page: https://stars79689.github.io/RoboTron-Sim/

</details>


### [14] [Open Scene Graphs for Open-World Object-Goal Navigation](https://arxiv.org/abs/2508.04678)
*Joel Loo,Zhanxin Wu,David Hsu*

Main category: cs.RO

TL;DR: OSG Navigator是一个基于基础模型的模块化系统，用于开放世界的语义导航，通过Open Scene Graph表示空间信息，实现零样本适应新环境。


<details>
  <summary>Details</summary>
Motivation: 解决开放世界语义导航的挑战，如在新环境中根据自然语言搜索目标物体。

Method: 使用Open Scene Graph作为空间记忆，通过OSG模式层次化组织空间信息，自动生成环境模板。

Result: 在仿真和真实世界实验中，OSG Navigator在ObjectNav基准测试中表现优异，并能零样本适应多样化目标、环境和机器人。

Conclusion: OSG Navigator通过基础模型和Open Scene Graph实现了高效的开放世界语义导航，具有广泛适用性。

Abstract: How can we build general-purpose robot systems for open-world semantic
navigation, e.g., searching a novel environment for a target object specified
in natural language? To tackle this challenge, we introduce OSG Navigator, a
modular system composed of foundation models, for open-world Object-Goal
Navigation (ObjectNav). Foundation models provide enormous semantic knowledge
about the world, but struggle to organise and maintain spatial information
effectively at scale. Key to OSG Navigator is the Open Scene Graph
representation, which acts as spatial memory for OSG Navigator. It organises
spatial information hierarchically using OSG schemas, which are templates, each
describing the common structure of a class of environments. OSG schemas can be
automatically generated from simple semantic labels of a given environment,
e.g., "home" or "supermarket". They enable OSG Navigator to adapt zero-shot to
new environment types. We conducted experiments using both Fetch and Spot
robots in simulation and in the real world, showing that OSG Navigator achieves
state-of-the-art performance on ObjectNav benchmarks and generalises zero-shot
over diverse goals, environments, and robot embodiments.

</details>


### [15] [From MAS to MARS: Coordination Failures and Reasoning Trade-offs in Hierarchical Multi-Agent Robotic Systems within a Healthcare Scenario](https://arxiv.org/abs/2508.04691)
*Yuanchen Bai,Zijian Ding,Shaoyue Wen,Xiang Chang,Angelique Taylor*

Main category: cs.RO

TL;DR: 论文研究了多智能体机器人系统（MARS）在实际部署中的性能权衡，通过两个实验分析了协调失败和通信结构的改进。


<details>
  <summary>Details</summary>
Motivation: 尽管存在先进的多智能体框架，但其在机器人上的实际应用有限，阻碍了MARS研究的进展。

Method: 通过两个实验（使用CrewAI和AutoGen）在模拟医疗场景中分析协调失败和改进通信结构。

Result: 研究发现协调失败（如工具访问违规）无法仅通过上下文知识解决，并强调了自主性与稳定性之间的权衡。

Conclusion: 强调了边缘案例测试的重要性，以提高未来实际部署中的系统可靠性和安全性。

Abstract: Multi-agent robotic systems (MARS) build upon multi-agent systems by
integrating physical and task-related constraints, increasing the complexity of
action execution and agent coordination. However, despite the availability of
advanced multi-agent frameworks, their real-world deployment on robots remains
limited, hindering the advancement of MARS research in practice. To bridge this
gap, we conducted two studies to investigate performance trade-offs of
hierarchical multi-agent frameworks in a simulated real-world multi-robot
healthcare scenario. In Study 1, using CrewAI, we iteratively refine the
system's knowledge base, to systematically identify and categorize coordination
failures (e.g., tool access violations, lack of timely handling of failure
reports) not resolvable by providing contextual knowledge alone. In Study 2,
using AutoGen, we evaluate a redesigned bidirectional communication structure
and further measure the trade-offs between reasoning and non-reasoning models
operating within the same robotic team setting. Drawing from our empirical
findings, we emphasize the tension between autonomy and stability and the
importance of edge-case testing to improve system reliability and safety for
future real-world deployment. Supplementary materials, including codes, task
agent setup, trace outputs, and annotated examples of coordination failures and
reasoning behaviors, are available at:
https://byc-sophie.github.io/mas-to-mars/.

</details>


### [16] [Achieving Precise and Reliable Locomotion with Differentiable Simulation-Based System Identification](https://arxiv.org/abs/2508.04696)
*Vyacheslav Kovalev,Ekaterina Chaikovskaia,Egor Davydenko,Roman Gorbachev*

Main category: cs.RO

TL;DR: 提出了一种结合系统辨识和强化学习的控制框架，利用可微分仿真优化系统参数，仅需轨迹数据和输入控制即可估计参数，显著提升轨迹跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 双足行走中轨迹漂移问题严重，传统方法依赖扭矩测量，限制了灵活性和扩展性。

Method: 使用可微分仿真器MuJoCo-XLA，仅需轨迹数据和控制输入优化系统参数，支持质量和惯性等物理特性，并通过神经网络处理复杂非线性行为。

Result: 实验表明，该框架显著改善了轨迹跟踪性能。

Conclusion: 该框架为双足行走提供了灵活且可扩展的系统辨识方法，适用于强化学习和模型控制。

Abstract: Accurate system identification is crucial for reducing trajectory drift in
bipedal locomotion, particularly in reinforcement learning and model-based
control. In this paper, we present a novel control framework that integrates
system identification into the reinforcement learning training loop using
differentiable simulation. Unlike traditional approaches that rely on direct
torque measurements, our method estimates system parameters using only
trajectory data (positions, velocities) and control inputs. We leverage the
differentiable simulator MuJoCo-XLA to optimize system parameters, ensuring
that simulated robot behavior closely aligns with real-world motion. This
framework enables scalable and flexible parameter optimization. Accurate system
identification is crucial for reducing trajectory drift in bipedal locomotion,
particularly in reinforcement learning and model-based control. In this paper,
we present a novel control framework that integrates system identification into
the reinforcement learning training loop using differentiable simulation.
Unlike traditional approaches that rely on direct torque measurements, our
method estimates system parameters using only trajectory data (positions,
velocities) and control inputs. We leverage the differentiable simulator
MuJoCo-XLA to optimize system parameters, ensuring that simulated robot
behavior closely aligns with real-world motion. This framework enables scalable
and flexible parameter optimization. It supports fundamental physical
properties such as mass and inertia. Additionally, it handles complex system
nonlinear behaviors, including advanced friction models, through neural network
approximations. Experimental results show that our framework significantly
improves trajectory following.

</details>
