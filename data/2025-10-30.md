<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 30]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [SCOUT: A Lightweight Framework for Scenario Coverage Assessment in Autonomous Driving](https://arxiv.org/abs/2510.24949)
*Anil Yildiz,Sarah M. Thornton,Carl Hildebrandt,Sreeja Roy-Singh,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 提出SCOUT轻量级替代模型，直接从智能体潜在传感器表示预测场景覆盖标签，避免昂贵的人工标注或大型视觉语言模型推理，实现高效可扩展的场景覆盖评估。


<details>
  <summary>Details</summary>
Motivation: 现有场景覆盖评估方法依赖昂贵的人工标注或计算密集型大型视觉语言模型，在大规模部署中成本高且效率低，需要更实用的解决方案。

Method: 通过蒸馏过程训练SCOUT模型，学习近似LVLM生成的覆盖标签，利用预计算感知特征，避免冗余计算，直接从智能体潜在传感器表示预测场景覆盖。

Result: 在真实自动驾驶导航场景数据集上评估，SCOUT在保持高精度的同时显著降低计算成本，为大规模覆盖分析提供有效实用的替代方案。

Conclusion: SCOUT代表了自主系统中高效场景覆盖监督的重要进展，虽然性能依赖于LVLM生成训练标签的质量，但为大规模部署提供了可行的解决方案。

Abstract: Assessing scenario coverage is crucial for evaluating the robustness of
autonomous agents, yet existing methods rely on expensive human annotations or
computationally intensive Large Vision-Language Models (LVLMs). These
approaches are impractical for large-scale deployment due to cost and
efficiency constraints. To address these shortcomings, we propose SCOUT
(Scenario Coverage Oversight and Understanding Tool), a lightweight surrogate
model designed to predict scenario coverage labels directly from an agent's
latent sensor representations. SCOUT is trained through a distillation process,
learning to approximate LVLM-generated coverage labels while eliminating the
need for continuous LVLM inference or human annotation. By leveraging
precomputed perception features, SCOUT avoids redundant computations and
enables fast, scalable scenario coverage estimation. We evaluate our method
across a large dataset of real-life autonomous navigation scenarios,
demonstrating that it maintains high accuracy while significantly reducing
computational cost. Our results show that SCOUT provides an effective and
practical alternative for large-scale coverage analysis. While its performance
depends on the quality of LVLM-generated training labels, SCOUT represents a
major step toward efficient scenario coverage oversight in autonomous systems.

</details>


### [2] [Smooth path planning with safety margins using Piece-Wise Bezier curves](https://arxiv.org/abs/2510.24972)
*Iancu Andrei,Marius Kloetzer,Cristian Mahulea,Catalin Dosoftei*

Main category: cs.RO

TL;DR: 提出了一种基于二次规划的高效路径规划方法，使用分段二次贝塞尔曲线为移动机器人生成平滑的C1连续路径，在保证安全裕度的同时实现实时计算。


<details>
  <summary>Details</summary>
Motivation: 传统分段线性路径规划方法在平滑性和鲁棒性方面存在不足，需要一种既能保证路径质量又能满足实时计算需求的新方法。

Method: 采用分段二次贝塞尔曲线，在结构化优化框架中显式地整合安全裕度，平衡轨迹平滑度、鲁棒性和计算复杂度。

Result: 相比传统分段线性方法，新方法显著减少了轨迹偏差，增强了鲁棒性，提高了整体路径质量，并通过Pure-Pursuit控制器验证了有效性。

Conclusion: 该方法为移动机器人安全导航提供了一种实用且可扩展的解决方案，特别适合实时和嵌入式应用场景。

Abstract: In this paper, we propose a computationally efficient quadratic programming
(QP) approach for generating smooth, $C^1$ continuous paths for mobile robots
using piece-wise quadratic Bezier (PWB) curves. Our method explicitly
incorporates safety margins within a structured optimization framework,
balancing trajectory smoothness and robustness with manageable numerical
complexity suitable for real-time and embedded applications. Comparative
simulations demonstrate clear advantages over traditional piece-wise linear
(PWL) path planning methods, showing reduced trajectory deviations, enhanced
robustness, and improved overall path quality. These benefits are validated
through simulations using a Pure-Pursuit controller in representative
scenarios, highlighting the practical effectiveness and scalability of our
approach for safe navigation.

</details>


### [3] [Defect Mitigation for Robot Arm-based Additive Manufacturing Utilizing Intelligent Control and IOT](https://arxiv.org/abs/2510.24994)
*Matsive Ali,Blake Gassen,Sen Liu*

Main category: cs.RO

TL;DR: 开发了一个集成机器人熔融沉积建模系统，具有闭环热控制、智能原位缺陷校正功能，使用6自由度机械臂和Oak-D相机实现实时质量保证。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D打印中缺乏实时质量控制和缺陷自动校正的问题，为航空航天、生物医学和工业应用提供可扩展的自适应制造框架。

Method: 使用6自由度机械臂配合E3D热端，通过IoT微控制器实现闭环热控制；ROS2协调机器人运动与挤出同步；OpenCV视觉系统检测层间缺陷并自动重新挤出；采用逆运动学进行运动规划，单应性变换校正相机视角。

Result: 实验验证显示系统成功缓解了打印操作中的缺陷，在不中断打印过程的情况下有效减轻表面异常。

Conclusion: 通过结合实时热调节、运动控制和智能缺陷检测与校正，该架构建立了一个可扩展的自适应机器人增材制造框架，适用于多种工业应用。

Abstract: This paper presents an integrated robotic fused deposition modeling additive
manufacturing system featuring closed-loop thermal control and intelligent
in-situ defect correction using a 6-degree of freedom robotic arm and an Oak-D
camera. The robot arm end effector was modified to mount an E3D hotend
thermally regulated by an IoT microcontroller, enabling precise temperature
control through real-time feedback. Filament extrusion system was synchronized
with robotic motion, coordinated via ROS2, ensuring consistent deposition along
complex trajectories. A vision system based on OpenCV detects layer-wise
defects position, commanding autonomous re-extrusion at identified sites.
Experimental validation demonstrated successful defect mitigation in printing
operations. The integrated system effectively addresses challenges real-time
quality assurance. Inverse kinematics were used for motion planning, while
homography transformations corrected camera perspectives for accurate defect
localization. The intelligent system successfully mitigated surface anomalies
without interrupting the print process. By combining real-time thermal
regulation, motion control, and intelligent defect detection & correction, this
architecture establishes a scalable and adaptive robotic additive manufacturing
framework suitable for aerospace, biomedical, and industrial applications.

</details>


### [4] [Scalable predictive processing framework for multitask caregiving robots](https://arxiv.org/abs/2510.25053)
*Hayato Idei,Tamon Miyake,Tetsuya Ogata,Yuichi Yamashita*

Main category: cs.RO

TL;DR: 提出基于预测处理的分层多模态循环神经网络，能够直接处理高维视觉-本体感觉输入，在护理任务中展现出自组织、鲁棒性和多任务学习能力。


<details>
  <summary>Details</summary>
Motivation: 现有护理机器人系统多为任务特定且依赖手工预处理，缺乏泛化能力。受人类大脑分层预测处理机制的启发，旨在开发能够灵活适应多样化场景的自主护理机器人。

Method: 基于自由能原理的预测处理框架，构建分层多模态循环神经网络，直接整合超过30,000维的视觉-本体感觉输入，无需降维或任务特定特征工程。

Result: 模型成功学习了刚体重新定位和柔性毛巾擦拭两个代表性护理任务，展现出分层潜在动态自组织、视觉退化下的鲁棒性，以及多任务学习中的不对称干扰特性。

Conclusion: 预测处理可作为通用且可扩展的计算原理，为实现鲁棒、灵活和自主的护理机器人提供理论基础，同时为理解人类大脑在不确定环境中的灵活适应能力提供理论洞见。

Abstract: The rapid aging of societies is intensifying demand for autonomous care
robots; however, most existing systems are task-specific and rely on
handcrafted preprocessing, limiting their ability to generalize across diverse
scenarios. A prevailing theory in cognitive neuroscience proposes that the
human brain operates through hierarchical predictive processing, which
underlies flexible cognition and behavior by integrating multimodal sensory
signals. Inspired by this principle, we introduce a hierarchical multimodal
recurrent neural network grounded in predictive processing under the
free-energy principle, capable of directly integrating over 30,000-dimensional
visuo-proprioceptive inputs without dimensionality reduction. The model was
able to learn two representative caregiving tasks, rigid-body repositioning and
flexible-towel wiping, without task-specific feature engineering. We
demonstrate three key properties: (i) self-organization of hierarchical latent
dynamics that regulate task transitions, capture variability in uncertainty,
and infer occluded states; (ii) robustness to degraded vision through
visuo-proprioceptive integration; and (iii) asymmetric interference in
multitask learning, where the more variable wiping task had little influence on
repositioning, whereas learning the repositioning task led to a modest
reduction in wiping performance, while the model maintained overall robustness.
Although the evaluation was limited to simulation, these results establish
predictive processing as a universal and scalable computational principle,
pointing toward robust, flexible, and autonomous caregiving robots while
offering theoretical insight into the human brain's ability to achieve flexible
adaptation in uncertain real-world environments.

</details>


### [5] [Non-Invasive Calibration Of A Stewart Platform By Photogrammetry](https://arxiv.org/abs/2510.25072)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 提出了一种基于Denavit-Hartenberg约定的正向运动学校准方法，使用摄影测量技术对Stewart平台进行非侵入式校准，通过最小二乘法估计误差补偿策略，显著提高了平台姿态精度。


<details>
  <summary>Details</summary>
Motivation: Stewart平台的正向运动学校准具有挑战性，因为正向运动学通常会产生多个可行和不可行的解，且六个执行器路径之间的复杂运动学关系使得难以建立直接高效的校准方法。

Method: 使用Denavit-Hartenberg约定开发正向运动学校准方法，采用摄影测量技术（高分辨率数码相机和现成软件）捕捉移动平台中心的姿态，通过最小二乘法估计误差补偿策略。

Result: 三种补偿方法均显示出平台姿态精度的显著提升，表明还有进一步改进的空间。

Conclusion: 提出的基于摄影测量的非侵入式校准方法有效提高了Stewart平台的精度，且不需要对六足机器人硬件进行任何改动或附加设备。

Abstract: Accurate calibration of a Stewart platform is important for their precise and
efficient operation. However, the calibration of these platforms using forward
kinematics is a challenge for researchers because forward kinematics normally
generates multiple feasible and unfeasible solutions for any pose of the moving
platform. The complex kinematic relations among the six actuator paths
connecting the fixed base to the moving platform further compound the
difficulty in establishing a straightforward and efficient calibration method.
The authors developed a new forward kinematics-based calibration method using
Denavit-Hartenberg convention and used the Stewart platform Tiger 66.1
developed in their lab for experimenting with the photogrammetry-based
calibration strategies described in this paper. This system became operational
upon completion of construction, marking its inaugural use. The authors used
their calibration model for estimating the errors in the system and adopted
three compensation options or strategies as per Least Square method to improve
the accuracy of the system. These strategies leveraged a high-resolution
digital camera and off-the-shelf software to capture the poses of the moving
platform's center. This process is non-invasive and does not need any
additional equipment to be attached to the hexapod or any alteration of the
hexapod hardware. This photogrammetry-based calibration process involves
multiple high-resolution images from different angles to measure the position
and orientation of the platform center in the three-dimensional space. The
Target poses and Actual poses are then compared, and the error compensations
are estimated using the Least-Squared methods to calculate the Predicted poses.
Results from each of the three compensation approaches demonstrated noticeable
enhancements in platform pose accuracies, suggesting room for further
improvements.

</details>


### [6] [Mean-Shift Theory and Its Applications in Swarm Robotics: A New Way to Enhance the Efficiency of Multi-Robot Collaboration](https://arxiv.org/abs/2510.25086)
*Guibin Sun,Jinhu Lü,Kexin Liu,Zhenqian Wang,Guanrong Chen*

Main category: cs.RO

TL;DR: 本文综述了机器人群体无分配协作的最新进展，特别关注形状形成问题，介绍了均值漂移探索策略及其在智能仓储、区域探索和货物运输等工业场景中的应用。


<details>
  <summary>Details</summary>
Motivation: 自然界中群体行为展现出的高效协作启发了机器人群体智能的研究。传统的基于分配的方法在效率和鲁棒性方面存在根本性限制，无法适应群体规模的变化。

Method: 采用均值漂移探索策略作为核心理论组件，该方法通过无分配协作方式解决机器人群体形状形成问题。

Result: 均值漂移探索策略将大规模群体协作效率提高了数十倍，且随着群体规模增加，效率提升更加显著。

Conclusion: 无分配协作方法为机器人群体协作提供了更高效和鲁棒的新途径，均值漂移探索策略在多个工业应用场景中展现出良好前景。

Abstract: Swarms evolving from collective behaviors among multiple individuals are
commonly seen in nature, which enables biological systems to exhibit more
efficient and robust collaboration. Creating similar swarm intelligence in
engineered robots poses challenges to the design of collaborative algorithms
that can be programmed at large scales. The assignment-based method has played
an eminent role for a very long time in solving collaboration problems of robot
swarms. However, it faces fundamental limitations in terms of efficiency and
robustness due to its unscalability to swarm variants. This article presents a
tutorial review on recent advances in assignment-free collaboration of robot
swarms, focusing on the problem of shape formation. A key theoretical component
is the recently developed \emph{mean-shift exploration} strategy, which
improves the collaboration efficiency of large-scale swarms by dozens of times.
Further, the efficiency improvement is more significant as the swarm scale
increases. Finally, this article discusses three important applications of the
mean-shift exploration strategy, including precise shape formation, area
coverage formation, and maneuvering formation, as well as their corresponding
industrial scenarios in smart warehousing, area exploration, and cargo
transportation.

</details>


### [7] [NanoVLA: Routing Decoupled Vision-Language Understanding for Nano-sized Generalist Robotic Policies](https://arxiv.org/abs/2510.25122)
*Jiahong Chen,Jing Wang,Long Chen,Chuwei Cai,Jinghui Lu*

Main category: cs.RO

TL;DR: NanoVLA是一个轻量级视觉-语言-动作模型，专为资源受限的边缘设备设计，通过视觉-语言解耦、长短动作分块和动态路由等创新，在保持高性能的同时大幅降低计算需求和延迟。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在资源受限的边缘设备（如移动机器人、嵌入式系统）上部署困难，因为计算需求高、功耗大、延迟严重，限制了在实际场景中的应用。

Method: 采用视觉-语言解耦策略将早期融合改为后期融合，支持缓存降低推理开销；使用长短动作分块确保多步规划的连贯性；通过动态路由根据任务复杂度自适应选择轻量或重量主干网络。

Result: 在边缘设备上实现高达52倍的推理加速，参数减少98%，同时保持或超越了现有VLA模型的任务准确性和泛化能力。

Conclusion: NanoVLA通过创新的架构设计，成功解决了VLA模型在资源受限设备上的部署难题，实现了高效、精确的机器人操作，具有重要的实际应用价值。

Abstract: Vision-language-action (VLA) models have significantly advanced robotic
manipulation by integrating vision-language models (VLMs), and action decoders
into a unified architecture. However, their deployment on resource-constrained
edge devices, such as mobile robots or embedded systems (e.g., Jetson Orin
Nano), remains challenging due to high computational demands, especially in
real-world scenarios where power, latency, and computational resources are
critical. To close this gap, we introduce Nano-scale Vision-Language Action
(NanoVLA), a family of lightweight VLA architectures that achieve high
performance with minimal resources. Our core innovations include: (1)
vision-language decoupling that moves conventional early vision and language
inputs fusion in VLM to late stage, achieving better performance while enabling
caching and reduce inference overhead and latency; (2) long-short action
chunking to ensure smooth, coherent multi-step planning without sacrificing
real-time responsiveness; (3) dynamic routing that adaptively assigns
lightweight or heavy backbones based on task complexity, further optimizing
inference efficiency. Experimental results on several benchmarks, as well as
real-world deployments, demonstrate that NanoVLA achieves up to 52x faster
inference on edge devices compared to previous state-of-the-art VLA models,
with 98% less parameters while maintaining or surpassing their task accuracy
and generalization. Ablation studies confirm that our decoupling strategy
preserves cross-task transferability, and the routing module enhances
cost-performance trade-offs, enabling practical, high-precision robotic
manipulation on resource-constrained hardware.

</details>


### [8] [Learning Spatial-Aware Manipulation Ordering](https://arxiv.org/abs/2510.25138)
*Yuxiang Yan,Zhiyuan Zhou,Xin Gao,Guanghao Li,Shenglin Li,Jiaqi Chen,Qunyan Pu,Jian Pu*

Main category: cs.RO

TL;DR: OrderMind是一个空间感知的物体操作排序框架，通过空间图神经网络学习物体操作优先级，解决杂乱环境中物体操作顺序问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法往往忽视物体间的空间关系，导致操作顺序不当引发碰撞或访问阻塞，限制了灵活性和可扩展性。

Method: 集成空间上下文编码器和时间优先级结构化模块，使用k近邻构建空间图聚合几何信息，编码物体-物体和物体-操作器交互，并通过空间先验标签方法生成监督信号。

Result: 在包含163,222个样本的操作排序基准测试中，OrderMind在仿真和真实环境中均显著优于现有方法，实现了高效鲁棒的杂乱场景操作。

Conclusion: OrderMind通过空间感知的优先级学习，有效解决了杂乱环境中的物体操作排序问题，提升了操作效率和鲁棒性。

Abstract: Manipulation in cluttered environments is challenging due to spatial
dependencies among objects, where an improper manipulation order can cause
collisions or blocked access. Existing approaches often overlook these spatial
relationships, limiting their flexibility and scalability. To address these
limitations, we propose OrderMind, a unified spatial-aware manipulation
ordering framework that directly learns object manipulation priorities based on
spatial context. Our architecture integrates a spatial context encoder with a
temporal priority structuring module. We construct a spatial graph using
k-Nearest Neighbors to aggregate geometric information from the local layout
and encode both object-object and object-manipulator interactions to support
accurate manipulation ordering in real-time. To generate physically and
semantically plausible supervision signals, we introduce a spatial prior
labeling method that guides a vision-language model to produce reasonable
manipulation orders for distillation. We evaluate OrderMind on our Manipulation
Ordering Benchmark, comprising 163,222 samples of varying difficulty. Extensive
experiments in both simulation and real-world environments demonstrate that our
method significantly outperforms prior approaches in effectiveness and
efficiency, enabling robust manipulation in cluttered scenes.

</details>


### [9] [SoraNav: Adaptive UAV Task-Centric Navigation via Zeroshot VLM Reasoning](https://arxiv.org/abs/2510.25191)
*Hongyu Song,Rishabh Dev Yadav,Cheng Guo,Wei Pan*

Main category: cs.RO

TL;DR: SoraNav是一个自适应无人机导航框架，结合零样本视觉语言模型推理与几何感知决策，在2.5D和3D场景中显著提升了导航成功率（SR）和路径效率（SPL）。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言导航方法主要针对地面机器人，难以推广到需要完整3D空间推理的空中任务。大型视觉语言模型虽然具备零样本语义推理能力，但缺乏空间基础，无法直接用于导航。

Method: 提出SoraNav框架，将几何先验融入图像标注以约束VLM动作空间，采用混合切换策略结合VLM推理和基于几何的探索，并构建了包含数字孪生和物理微无人机的PX4平台进行可重复评估。

Result: 在2.5D场景中，成功率提升25.7%，路径效率提升17%；在3D场景中，成功率提升29.5%，路径效率提升18.5%。

Conclusion: SoraNav通过整合零样本VLM推理与几何感知决策，有效解决了无人机在复杂3D环境中的语言驱动导航问题，显著提升了导航性能。

Abstract: Interpreting visual observations and natural language instructions for
complex task execution remains a key challenge in robotics and AI. Despite
recent advances, language-driven navigation is still difficult, particularly
for UAVs in small-scale 3D environments. Existing Vision-Language Navigation
(VLN) approaches are mostly designed for ground robots and struggle to
generalize to aerial tasks that require full 3D spatial reasoning. The
emergence of large Vision-Language Models (VLMs), such as GPT and Claude,
enables zero-shot semantic reasoning from visual and textual inputs. However,
these models lack spatial grounding and are not directly applicable to
navigation. To address these limitations, SoraNav is introduced, an adaptive
UAV navigation framework that integrates zero-shot VLM reasoning with
geometry-aware decision-making. Geometric priors are incorporated into image
annotations to constrain the VLM action space and improve decision quality. A
hybrid switching strategy leverages navigation history to alternate between VLM
reasoning and geometry-based exploration, mitigating dead-ends and redundant
revisits. A PX4-based hardware-software platform, comprising both a digital
twin and a physical micro-UAV, enables reproducible evaluation. Experimental
results show that in 2.5D scenarios, our method improves Success Rate (SR) by
25.7% and Success weighted by Path Length (SPL) by 17%. In 3D scenarios, it
improves SR by 29.5% and SPL by 18.5% relative to the baseline.

</details>


### [10] [RoadSens-4M: A Multimodal Smartphone & Camera Dataset for Holistic Road-way Analysis](https://arxiv.org/abs/2510.25211)
*Amith Khandakar,David Michelson,Shaikh Golam Rabbani,Fariya Bintay Shafi,Md. Faysal Ahamed,Khondokar Radwanur Rahman,Md Abidur Rahman,Md. Fahmidun Nabi,Mohamed Arselene Ayari,Khaled Khan,Ponnuthurai Nagaratnam Suganthan*

Main category: cs.RO

TL;DR: 提出了一个结合GIS、天气信息和视频数据的道路质量监测数据集，旨在促进智能交通系统的研究


<details>
  <summary>Details</summary>
Motivation: 缺乏高质量、标准化的道路监测数据集阻碍了基于智能手机传感器的道路质量评估研究进展

Method: 开发移动应用收集GPS、加速度计、陀螺仪、磁力计、重力传感器和方向传感器数据，并整合GIS数据、天气信息和道路视频

Result: 创建了一个包含车辆速度、加速度、旋转速率、磁场强度等传感器数据，以及地理空间、天气和视觉上下文信息的综合数据集

Conclusion: 该数据集将公开可用，为交通管理、基础设施发展、道路安全和城市规划提供数据支持，促进智能交通系统创新

Abstract: It's important to monitor road issues such as bumps and potholes to enhance
safety and improve road conditions. Smartphones are equipped with various
built-in sensors that offer a cost-effective and straightforward way to assess
road quality. However, progress in this area has been slow due to the lack of
high-quality, standardized datasets. This paper discusses a new dataset created
by a mobile app that collects sensor data from devices like GPS,
accelerometers, gyroscopes, magnetometers, gravity sensors, and orientation
sensors. This dataset is one of the few that integrates Geographic Information
System (GIS) data with weather information and video footage of road
conditions, providing a comprehensive understanding of road issues with
geographic context. The dataset allows for a clearer analysis of road
conditions by compiling essential data, including vehicle speed, acceleration,
rotation rates, and magnetic field intensity, along with the visual and spatial
context provided by GIS, weather, and video data. Its goal is to provide
funding for initiatives that enhance traffic management, infrastructure
development, road safety, and urban planning. Additionally, the dataset will be
publicly accessible to promote further research and innovation in smart
transportation systems.

</details>


### [11] [Hybrid Vision Servoing with Depp Alignment and GRU-Based Occlusion Recovery](https://arxiv.org/abs/2510.25233)
*Jee Won Lee,Hansol Lim,Sooyeun Yang,Jongseong Brad Choi*

Main category: cs.RO

TL;DR: 提出了一种混合视觉跟踪框架，结合全局模板匹配、深度特征Lucas-Kanade和残差回归器，在严重遮挡下仍能保持亚像素精度跟踪，为机器人视觉伺服控制提供直接控制信号。


<details>
  <summary>Details</summary>
Motivation: 解决视觉伺服控制中在部分或完全遮挡情况下保持鲁棒目标跟踪的挑战，传统方法对遮挡和漂移敏感，而深度学习方法需要持续可见性和大量计算。

Method: 1. 快速全局模板匹配器约束位姿搜索区域；2. 在VGG早期层上运行的深度特征Lucas-Kanade模块进行亚像素精度对齐；3. 轻量级残差回归器校正局部错位；4. 当视觉置信度低时，GRU预测器从运动历史中推断位姿更新。

Result: 在手持视频序列上评估，即使面对90%遮挡，系统仍能维持低于2像素的跟踪误差，为30Hz图像伺服循环提供直接控制信号。

Conclusion: 该混合框架展示了在真实世界机器人视觉应用中实现鲁棒性和低延迟精度所需的关键特性，能够可靠处理严重遮挡情况。

Abstract: Vision-based control systems, such as image-based visual servoing (IBVS),
have been extensively explored for precise robot manipulation. A persistent
challenge, however, is maintaining robust target tracking under partial or full
occlusions. Classical methods like Lucas-Kanade (LK) offer lightweight tracking
but are fragile to occlusion and drift, while deep learning-based approaches
often require continuous visibility and intensive computation. To address these
gaps, we propose a hybrid visual tracking framework that bridges advanced
perception with real-time servo control. First, a fast global template matcher
constrains the pose search region; next, a deep-feature Lucas-Kanade module
operating on early VGG layers refines alignment to sub-pixel accuracy (<2px);
then, a lightweight residual regressor corrects local misalignments caused by
texture degradation or partial occlusion. When visual confidence falls below a
threshold, a GRU-based predictor seamlessly extrapolates pose updates from
recent motion history. Crucially, the pipeline's final outputs-translation,
rotation, and scale deltas-are packaged as direct control signals for 30Hz
image-based servo loops. Evaluated on handheld video sequences with up to 90%
occlusion, our system sustains under 2px tracking error, demonstrating the
robustness and low-latency precision essential for reliable real-world robot
vision applications.

</details>


### [12] [One-shot Humanoid Whole-body Motion Learning](https://arxiv.org/abs/2510.25241)
*Hao Huang,Geeta Chandra Raju Bethala,Shuaihang Yuan,Congcong Wen,Anthony Tzes,Yi Fang*

Main category: cs.RO

TL;DR: 提出了一种仅需单个非行走运动样本和现成行走运动就能训练人形机器人运动策略的新方法，通过最优传输和插值生成中间姿态，在CMU MoCap数据集上表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法需要每个运动类别多个训练样本的问题，降低高质量人体运动数据集的收集成本和工作量。

Method: 利用保序最优传输计算行走和非行走序列间的距离，沿测地线插值生成新的中间姿态骨架，优化碰撞自由配置并重定向到人形机器人，在模拟环境中通过强化学习训练策略。

Result: 在CMU MoCap数据集上的实验评估表明，该方法始终优于基线方法，在各项指标上均取得优越性能。

Conclusion: 该方法能够有效利用少量样本训练人形机器人运动策略，为降低运动数据集收集成本提供了可行方案。

Abstract: Whole-body humanoid motion represents a cornerstone challenge in robotics,
integrating balance, coordination, and adaptability to enable human-like
behaviors. However, existing methods typically require multiple training
samples per motion category, rendering the collection of high-quality human
motion datasets both labor-intensive and costly. To address this, we propose a
novel approach that trains effective humanoid motion policies using only a
single non-walking target motion sample alongside readily available walking
motions. The core idea lies in leveraging order-preserving optimal transport to
compute distances between walking and non-walking sequences, followed by
interpolation along geodesics to generate new intermediate pose skeletons,
which are then optimized for collision-free configurations and retargeted to
the humanoid before integration into a simulated environment for policy
training via reinforcement learning. Experimental evaluations on the CMU MoCap
dataset demonstrate that our method consistently outperforms baselines,
achieving superior performance across metrics. Code will be released upon
acceptance.

</details>


### [13] [Time-Optimal Transport of Loosely Placed Liquid Filled Cups along Prescribed Paths](https://arxiv.org/abs/2510.25255)
*Klaus Zauner,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出一种优化控制方法，用于在最短时间内沿规定路径运输液体填充的杯子，同时最小化液体晃动以避免溢出。


<details>
  <summary>Details</summary>
Motivation: 处理松散放置的物体对机器人操作来说很困难，特别是当物体是装有液体的容器时，液体晃动会导致溢出问题，需要专门的控制策略。

Method: 将液体晃动动力学纳入动态模型，采用直接多重打靶法求解最优控制问题。

Result: 开发了一个能够考虑液体晃动动态的优化控制框架，用于规划机器人操纵器的轨迹。

Conclusion: 通过将液体晃动动力学整合到最优控制问题中，可以有效减少液体溢出，实现安全高效的液体容器运输。

Abstract: Handling loosely placed objects with robotic manipulators is a difficult task
from the point of view of trajectory planning and control. This becomes even
more challenging when the object to be handled is a container filled with
liquid. This paper addresses the task of transporting a liquid-filled cup
placed on a tray along a prescribed path in shortest time. The objective is to
minimize swapping, thus avoiding spillage of the fluid. To this end, the
sloshing dynamics is incorporated into the dynamic model used within the
optimal control problem formulation. The optimization problem is solved using a
direct multiple shooting approach.

</details>


### [14] [SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object with Discrete Human Object Interaction Representation](https://arxiv.org/abs/2510.25268)
*Wang zhi,Yuyan Liu,Liu Liu,Li Zhang,Ruixuan Lu,Dan Guo*

Main category: cs.RO

TL;DR: SynHLMA框架通过语言指令生成手部与铰接物体的交互序列，使用离散HAOI表示和语言嵌入在共享空间中训练，实现HAOI生成、预测和插值任务。


<details>
  <summary>Details</summary>
Motivation: 在铰接物体交互中，手部抓取不仅需要对象功能性，还需要考虑物体变形时的长期操作序列，现有方法难以处理这种复杂交互。

Method: 利用铰接物体的完整点云，采用离散HAOI表示建模每个交互帧，结合语言嵌入通过HAOI操作语言模型训练，使用关节感知损失确保抓取跟随铰接关节的动态变化。

Result: 在HAOI-lang数据集上评估显示优于现有方法，能够实现三种典型的手部操作任务，并在机器人抓取应用中通过模仿学习实现灵巧抓取执行。

Conclusion: SynHLMA框架成功解决了铰接物体手部语言操作序列生成问题，为具身AI和VR/AR应用提供了有效解决方案。

Abstract: Generating hand grasps with language instructions is a widely studied topic
that benefits from embodied AI and VR/AR applications. While transferring into
hand articulatied object interaction (HAOI), the hand grasps synthesis requires
not only object functionality but also long-term manipulation sequence along
the object deformation. This paper proposes a novel HAOI sequence generation
framework SynHLMA, to synthesize hand language manipulation for articulated
objects. Given a complete point cloud of an articulated object, we utilize a
discrete HAOI representation to model each hand object interaction frame. Along
with the natural language embeddings, the representations are trained by an
HAOI manipulation language model to align the grasping process with its
language description in a shared representation space. A joint-aware loss is
employed to ensure hand grasps follow the dynamic variations of articulated
object joints. In this way, our SynHLMA achieves three typical hand
manipulation tasks for articulated objects of HAOI generation, HAOI prediction
and HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and
experimental results demonstrate the superior hand grasp sequence generation
performance comparing with state-of-the-art. We also show a robotics grasp
application that enables dexterous grasps execution from imitation learning
using the manipulation sequence provided by our SynHLMA. Our codes and datasets
will be made publicly available.

</details>


### [15] [Development of Implicit-Explicit Control Based Amphibious Centipede-Type Robot and Evaluation of its Mobile Performance](https://arxiv.org/abs/2510.25280)
*Yusuke Tsunoda,Seiya Yamamoto,Kazuki Ito,Runze Xiao,Keisuke Naniwa,Koichi Osuka*

Main category: cs.RO

TL;DR: 开发了一种能够在陆地和水域环境中使用统一控制方案导航的蜈蚣型移动机器人，通过巧妙设计腿部结构实现两栖运动。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要为不同环境设计不同的步态控制器，但为复杂多样的环境设计合适步态并准确确定控制器切换具有挑战性。

Method: 基于隐式-显式控制理念，设计具有柔性关节和左右腿的蜈蚣型机器人，重点开发了三种与环境广泛接触的腿部结构。

Result: 实验评估了三种腿部结构在陆地和水中的运动性能，使用腿部滑移率和执行器能耗作为评价指标。

Conclusion: 确认存在能够在相同控制下导航水陆两种环境的合适腿部结构。

Abstract: Multi-legged mobile robots possess high mobility performance in rough terrain
environments, stemming from their high postural stability, joint flexibility,
and the redundancy provided by multiple legs. In prior research on navigating
between different environments such as land and water, the primary strategy
employed involves switching to a controller that generates an appropriate gait
for the new environment upon entering it. However, designing appropriate gaits
for each complex and diverse environment and accurately determining controller
switching for each environment is challenging. Therefore, this research
develops a centipede-type mobile robot that navigates both aquatic and
terrestrial environments with a simple, unified control scheme, based on the
implicit-explicit control philosophy and by ingeniously designing the robot's
body structure. In this research, we developed the robot featuring flexible
joints and left and right legs on each body segment and focused on the leg
structure which has extensive contact with the environment. This paper
evaluates the locomotion performance on land and water using the three
developed leg structures, using the robot's leg slip rate and actuator energy
consumption as evaluation metrics. The experimental results confirmed the
existence of an appropriate leg structure capable of navigating both aquatic
and terrestrial environments under identical control.

</details>


### [16] [An approach for combining transparency and motion assistance of a lower body exoskeleton](https://arxiv.org/abs/2510.25335)
*Jakob Ziegler,Bernhard Rameder,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种结合透明模式和运动辅助模式的下半身外骨骼步态辅助方法，利用齿轮间隙实现透明模式，通过自适应振荡器学习步态周期性信号进行运动辅助


<details>
  <summary>Details</summary>
Motivation: 开发一种能够同时实现透明模式和运动辅助模式的下半身外骨骼系统，在用户自由运动时提供最小交互力感知，在行走时提供引导性辅助

Method: 利用驱动单元的齿轮间隙实现透明模式，使用自适应振荡器学习步态的准周期性信号，在行走时叠加辅助模式施加额外扭矩引导腿部运动

Result: 初步实验显示出有希望的结果

Conclusion: 该方法成功结合了透明模式和运动辅助模式，为下半身外骨骼步态辅助提供了一种有效解决方案

Abstract: In this paper, an approach for gait assistance with a lower body exoskeleton
is described. Two concepts, transparency and motion assistance, are combined.
The transparent mode, where the system is following the user's free motion with
a minimum of perceived interaction forces, is realized by exploiting the gear
backlash of the actuation units. During walking a superimposed assistance mode
applies an additional torque guiding the legs to their estimated future
position. The concept of adaptive oscillators is utilized to learn the
quasi-periodic signals typical for locomotion. First experiments showed
promising results.

</details>


### [17] [Geometric Robot Calibration Using a Calibration Plate](https://arxiv.org/abs/2510.25338)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种使用校准板进行几何机器人校准的新方法，通过测量板上已知距离的点来确定系统误差参数，相比传统方法更经济、便携且机械稳健。


<details>
  <summary>Details</summary>
Motivation: 传统机器人校准方法如激光跟踪仪或运动捕捉系统成本高、设备笨重，需要开发更经济、便携且机械稳健的校准方案。

Method: 使用具有精确已知点距的校准板，通过测量板上点间相对位置来确定系统误差参数，采用最小二乘法和约束优化进行参数识别。

Result: 实验验证了该方法的有效性，结果与激光跟踪仪校准结果具有良好相关性，显示出有前景的校准精度。

Conclusion: 该方法为机器人校准提供了一种经济、便携且稳健的替代方案，虽然以龙门机器人为例开发，但适用于其他类型机器人。

Abstract: In this paper a new method for geometric robot calibration is introduced,
which uses a calibration plate with precisely known distances between its
measuring points. The relative measurement between two points on the
calibration plate is used to determine predefined error parameters of the
system. In comparison to conventional measurement methods, like laser tracker
or motion capture systems, the calibration plate provides a more mechanically
robust and cheaper alternative, which is furthermore easier to transport due to
its small size. The calibration method, the plate design, the mathematical
description of the error system as well as the identification of the parameters
are described in detail. For identifying the error parameters, the least
squares method and a constrained optimization problem are used. The
functionality of this method was demonstrated in experiments that led to
promising results, correlated with one of a laser tracker calibration. The
modeling and identification of the error parameters is done for a gantry
machine, but is not restricted to that type of robot.

</details>


### [18] [Integrating Legal and Logical Specifications in Perception, Prediction, and Planning for Automated Driving: A Survey of Methods](https://arxiv.org/abs/2510.25386)
*Kumar Manas,Mert Keser,Alois Knoll*

Main category: cs.RO

TL;DR: 本文综述了将法律和逻辑规范整合到自动驾驶系统感知、预测和规划模块中的方法，分析了现有技术在确保法规合规性和可解释性方面的能力，并提出了分类法来系统化分析相关挑战。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在动态和不确定的驾驶环境中面临感知可靠性、法律合规性和决策可辩护性之间的交叉挑战，需要确保技术稳健且法律上可辩护的决策。

Method: 引入分类法按理论基础、架构实现和验证策略对现有方法进行分类，重点关注处理感知不确定性和整合明确法律规范的方法，涵盖神经符号集成、逻辑驱动规则表示和规范感知预测策略。

Result: 系统分析了当前方法在确保法规合规和可解释性方面的能力，识别了感知可靠性、法律合规和决策可辩护性之间的关键挑战。

Conclusion: 强调了需要解决的关键开放问题和实际权衡，提供了来自工程、逻辑和法律的多学科见解，以指导未来法律合规自动驾驶系统的发展。

Abstract: This survey provides an analysis of current methodologies integrating legal
and logical specifications into the perception, prediction, and planning
modules of automated driving systems. We systematically explore techniques
ranging from logic-based frameworks to computational legal reasoning
approaches, emphasizing their capability to ensure regulatory compliance and
interpretability in dynamic and uncertain driving environments. A central
finding is that significant challenges arise at the intersection of perceptual
reliability, legal compliance, and decision-making justifiability. To
systematically analyze these challenges, we introduce a taxonomy categorizing
existing approaches by their theoretical foundations, architectural
implementations, and validation strategies. We particularly focus on methods
that address perceptual uncertainty and incorporate explicit legal norms,
facilitating decisions that are both technically robust and legally defensible.
The review covers neural-symbolic integration methods for perception,
logic-driven rule representation, and norm-aware prediction strategies, all
contributing toward transparent and accountable autonomous vehicle operation.
We highlight critical open questions and practical trade-offs that must be
addressed, offering multidisciplinary insights from engineering, logic, and law
to guide future developments in legally compliant autonomous driving systems.

</details>


### [19] [Sim-to-Real Gentle Manipulation of Deformable and Fragile Objects with Stress-Guided Reinforcement Learning](https://arxiv.org/abs/2510.25405)
*Kei Ikemura,Yifei Dong,David Blanco-Mulero,Alberta Longhini,Li Chen,Florian T. Pokorny*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的强化学习方法，通过应力惩罚奖励和课程学习策略，实现对易碎物体的轻柔操作，在模拟和真实环境中均能有效减少36.5%的应力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作易碎和可变形物体的方法依赖精确物体模型或专用传感器，复杂度高且泛化能力差，需要一种更通用的轻柔操作解决方案。

Method: 使用视觉强化学习框架，引入应力惩罚奖励机制，结合离线演示和从刚性代理到可变形物体的课程学习策略。

Result: 在模拟和真实环境中验证，学习到的策略能够以零样本方式迁移到现实世界，成功完成如拿起和推动豆腐等任务，相比普通RL策略减少36.5%的应力。

Conclusion: 该方法能够学习到损伤感知的轻柔操作行为，在完成任务目标的同时显著降低对易碎物体的应力，具有良好的实际应用价值。

Abstract: Robotic manipulation of deformable and fragile objects presents significant
challenges, as excessive stress can lead to irreversible damage to the object.
While existing solutions rely on accurate object models or specialized sensors
and grippers, this adds complexity and often lacks generalization. To address
this problem, we present a vision-based reinforcement learning approach that
incorporates a stress-penalized reward to discourage damage to the object
explicitly. In addition, to bootstrap learning, we incorporate offline
demonstrations as well as a designed curriculum progressing from rigid proxies
to deformables. We evaluate the proposed method in both simulated and
real-world scenarios, showing that the policy learned in simulation can be
transferred to the real world in a zero-shot manner, performing tasks such as
picking up and pushing tofu. Our results show that the learned policies exhibit
a damage-aware, gentle manipulation behavior, demonstrating their effectiveness
by decreasing the stress applied to fragile objects by 36.5% while achieving
the task goals, compared to vanilla RL policies.

</details>


### [20] [Solving the Right Problem with Multi-Robot Formations](https://arxiv.org/abs/2510.25422)
*Chaz Cornwall,Jeremy P. Bos*

Main category: cs.RO

TL;DR: 提出一种编队规划器，通过两步骤优化问题来减少编队形状与原始成本函数之间的不匹配，使用加权代理成本函数来近似非线性不可微成本，并通过非合作编队控制器实现期望的相对位置。


<details>
  <summary>Details</summary>
Motivation: 传统的编队控制将复杂成本函数简化为固定形状，但当环境信息变化时，静态形状无法最小化原始保护成本，导致编队形状与成本函数之间存在不匹配。

Method: 两步骤优化：首先用加权代理成本函数估计非线性不可微成本，然后最小化加权代理成本函数得到期望相对位置，最后使用基于Lyapunov直接法的非合作编队控制器实现这些位置。

Result: 仿真显示编队规划器可将单一成本降低75%以上，在同时最小化多个成本函数时，使用自适应权重的编队规划器可将成本降低20-40%。

Conclusion: 编队规划通过最小化近似原始成本函数的代理成本函数，而不是依赖形状抽象，提供了更好的性能。

Abstract: Formation control simplifies minimizing multi-robot cost functions by
encoding a cost function as a shape the robots maintain. However, by reducing
complex cost functions to formations, discrepancies arise between maintaining
the shape and minimizing the original cost function. For example, a Diamond or
Box formation shape is often used for protecting all members of the formation.
When more information about the surrounding environment becomes available, a
static shape often no longer minimizes the original protection cost. We propose
a formation planner to reduce mismatch between a formation and the cost
function while still leveraging efficient formation controllers. Our formation
planner is a two-step optimization problem that identifies desired relative
robot positions. We first solve a constrained problem to estimate non-linear
and non-differentiable costs with a weighted sum of surrogate cost functions.
We theoretically analyze this problem and identify situations where weights do
not need to be updated. The weighted, surrogate cost function is then minimized
using relative positions between robots. The desired relative positions are
realized using a non-cooperative formation controller derived from Lyapunov's
direct approach. We then demonstrate the efficacy of this approach for
military-like costs such as protection and obstacle avoidance. In simulations,
we show a formation planner can reduce a single cost by over 75%. When
minimizing a variety of cost functions simultaneously, using a formation
planner with adaptive weights can reduce the cost by 20-40%. Formation planning
provides better performance by minimizing a surrogate cost function that
closely approximates the original cost function instead of relying on a shape
abstraction.

</details>


### [21] [Combining Moving Mass Actuators and Manoeuvring Models for Underwater Vehicles: A Lagrangian Approach](https://arxiv.org/abs/2510.25479)
*Alexander B. Rambech,Ivar B. Saksvik,Vahid Hassani*

Main category: cs.RO

TL;DR: 本文提出了水下航行器内部移动质量作动器的牛顿-欧拉动力学方程，将移动质量影响纳入Fossen机动模型扩展中，并通过仿真验证了与哈密顿方法的等效性。


<details>
  <summary>Details</summary>
Motivation: 为水下航行器内部移动质量作动器建立更直观的牛顿-欧拉动力学模型，替代传统的哈密顿方法，便于工程应用。

Method: 基于牛顿-欧拉公式推导运动方程，将移动质量动力学表达为Fossen机动模型的扩展，在体坐标系中描述移动质量影响，并纳入运动学和刚体动力学方程。

Result: 成功建立了包含移动质量作动器的水下航行器牛顿-欧拉模型，通过仿真验证了与传统哈密顿方法的一致性。

Conclusion: 提出的牛顿-欧拉模型为水下航行器移动质量作动器提供了有效的动力学建模方法，比哈密顿方法更直观且易于工程实现。

Abstract: In this paper, we present a Newton-Euler formulation of the equations of
motion for underwater vehicles with an interntal moving mass actuator.
Furthermore, the moving mass dynamics are expressed as an extension to the
manoeuvring model for underwater vehicles, originally introduced by Fossen
(1991). The influence of the moving mass is described in body-frame and
included as states in both an additional kinematic equation and as part of the
coupled rigid-body kinetics of the underwater vehicle. The Coriolis-centripetal
effects are derived from Kirchhoff's equations and the hydrostatics are derived
using first principals. The proposed Newton-Euler model is validated through
simulation and compared with the traditional Hamiltonian internal moving mass
actuator formulation.

</details>


### [22] [Octopus-like Reaching Motion: A Perspective Inspired by Whipping](https://arxiv.org/abs/2510.25520)
*Shengyao Zhang,Yiyuan Zhang,Chenrui Zhang,Yiming Li,Wenci Xin,Yuliang Liufu,Hong Wei Ng,Cecilia Laschi*

Main category: cs.RO

TL;DR: 该研究通过在水中进行鞭打实验，发现Ecoflex Gel 2手臂在150rpm驱动下能重现章鱼触手弯曲传播特征，但弯曲点速度呈单调递减而非生物钟形曲线，证实章鱼触手运动不是单纯的被动鞭打行为。


<details>
  <summary>Details</summary>
Motivation: 研究章鱼触手伸展运动的鞭状动力学机制，探索其与鞭子动力学原理的相似性，以及周围介质对运动形成的关键作用。

Method: 在水和空气中进行平台鞭打测试，系统改变材料刚度和驱动速度，通过图像量化分析弯曲传播特征。

Result: Ecoflex Gel 2手臂在150rpm驱动下重现了章鱼触手的弯曲传播，但弯曲点速度呈单调递减而非生物钟形曲线；空气中无传播现象表明周围介质对运动形成至关重要。

Conclusion: 章鱼触手伸展运动不是单纯的被动鞭打行为，周围介质在形成章鱼样伸展运动中起关键作用，为理解生物伸展运动提供了新视角和潜在的水动力学研究平台。

Abstract: The stereotypical reaching motion of the octopus arm has drawn growing
attention for its efficient control of a highly deformable body. Previous
studies suggest that its characteristic bend propagation may share underlying
principles with the dynamics of a whip. This work investigates whether
whip-like passive dynamics in water can reproduce the kinematic features
observed in biological reaching and their similarities and differences.
Platform-based whipping tests were performed in water and air while
systematically varying material stiffness and driving speed. Image-based
quantification revealed that the Ecoflex Gel 2 arm driven at 150 rpm (motor
speed) reproduced curvature propagation similar to that observed in octopus
reaching. However, its bend-point velocity decreased monotonically rather than
exhibiting the biological bell-shaped profile, confirming that the octopus
reaching movement is not merely a passive whipping behavior. The absence of
propagation in air further highlights the critical role of the surrounding
medium in forming octopus-like reaching motion. This study provides a new
perspective for understand biological reaching movement, and offers a potential
platform for future hydrodynamic research.

</details>


### [23] [Using VLM Reasoning to Constrain Task and Motion Planning](https://arxiv.org/abs/2510.25548)
*Muyang Yan,Miras Mengdibayev,Ardon Floros,Weihang Guo,Lydia E. Kavraki,Zachary Kingston*

Main category: cs.RO

TL;DR: VIZ-COAST利用预训练视觉语言模型的常识空间推理能力，在任务规划阶段提前识别向下细化问题，避免在规划过程中修复这些失败，从而显著减少规划时间。


<details>
  <summary>Details</summary>
Motivation: 在任务和运动规划中，高层任务规划基于世界抽象进行，但当领域的向下细化能力较差时，看似有效的任务级计划可能在运动规划阶段失败，需要重新规划，导致整体性能下降。现有方法只在细化失败时添加约束，浪费大量搜索精力在不可行分支上。

Method: 提出VIZ-COAST方法，利用大型预训练视觉语言模型的常识空间推理能力，在任务规划阶段提前识别向下细化问题，避免在规划过程中修复这些失败。

Result: 在两个具有挑战性的TAMP领域上的实验表明，该方法能够从图像和领域描述中提取合理的约束，大幅减少规划时间，在某些情况下完全消除向下细化失败，并能泛化到更广泛领域的不同实例。

Conclusion: VIZ-COAST通过利用视觉语言模型的常识推理能力，在任务规划阶段提前识别和避免向下细化问题，显著提高了任务和运动规划的效率和可靠性。

Abstract: In task and motion planning, high-level task planning is done over an
abstraction of the world to enable efficient search in long-horizon robotics
problems. However, the feasibility of these task-level plans relies on the
downward refinability of the abstraction into continuous motion. When a
domain's refinability is poor, task-level plans that appear valid may
ultimately fail during motion planning, requiring replanning and resulting in
slower overall performance. Prior works mitigate this by encoding refinement
issues as constraints to prune infeasible task plans. However, these approaches
only add constraints upon refinement failure, expending significant search
effort on infeasible branches. We propose VIZ-COAST, a method of leveraging the
common-sense spatial reasoning of large pretrained Vision-Language Models to
identify issues with downward refinement a priori, bypassing the need to fix
these failures during planning. Experiments on two challenging TAMP domains
show that our approach is able to extract plausible constraints from images and
domain descriptions, drastically reducing planning times and, in some cases,
eliminating downward refinement failures altogether, generalizing to a diverse
range of instances from the broader domain.

</details>


### [24] [Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot Skills](https://arxiv.org/abs/2510.25634)
*Weikang Wan,Fabio Ramos,Xuning Yang,Caelan Garrett*

Main category: cs.RO

TL;DR: 提出了一种用于长时程接触丰富的双手操作的分层框架，将挑战构建为技能规划与调度问题，支持并行技能执行。


<details>
  <summary>Details</summary>
Motivation: 长时程接触丰富的双手操作需要复杂的协调，涉及并行执行和顺序协作的混合，传统方法难以处理。

Method: 基于单臂和双手原始技能库，使用强化学习在GPU加速仿真中训练，然后训练基于Transformer的规划器作为高级调度器，同时预测技能离散调度和连续参数。

Result: 该方法在复杂接触丰富任务上比端到端强化学习方法获得更高成功率，比传统顺序规划器产生更高效、协调的行为。

Conclusion: 分层技能规划与调度框架有效解决了长时程双手操作的协调挑战，优于现有方法。

Abstract: Long-horizon contact-rich bimanual manipulation presents a significant
challenge, requiring complex coordination involving a mixture of parallel
execution and sequential collaboration between arms. In this paper, we
introduce a hierarchical framework that frames this challenge as an integrated
skill planning & scheduling problem, going beyond purely sequential
decision-making to support simultaneous skill invocation. Our approach is built
upon a library of single-arm and bimanual primitive skills, each trained using
Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a
Transformer-based planner on a dataset of skill compositions to act as a
high-level scheduler, simultaneously predicting the discrete schedule of skills
as well as their continuous parameters. We demonstrate that our method achieves
higher success rates on complex, contact-rich tasks than end-to-end RL
approaches and produces more efficient, coordinated behaviors than traditional
sequential-only planners.

</details>


### [25] [Collision avoidance and path finding in a robotic mobile fulfillment system using multi-objective meta-heuristics](https://arxiv.org/abs/2510.25650)
*Ahmad Kokhahi,Mary Kurz*

Main category: cs.RO

TL;DR: 该论文提出了一种考虑能耗的AGV多智能体路径规划方法，包含新的碰撞避免策略和两种多目标任务分配算法。


<details>
  <summary>Details</summary>
Motivation: 现有MAPF研究主要关注最小化碰撞和行驶时间，但忽略了能耗问题。本文旨在解决AGV路径规划中的碰撞避免和任务分配问题，同时考虑能耗优化。

Method: 提出了考虑能耗和行驶时间的碰撞避免策略，以及两种多目标算法：非支配排序遗传算法(NSGA)和自适应大邻域搜索(ALNS)用于任务分配。

Result: 比较评估表明，所提出的方法在碰撞避免和任务分配方面均优于现有方法。

Conclusion: 综合考虑能耗的AGV路径规划方法能够有效提升系统性能，在碰撞避免和任务分配方面表现出色。

Abstract: Multi-Agent Path Finding (MAPF) has gained significant attention, with most
research focusing on minimizing collisions and travel time. This paper also
considers energy consumption in the path planning of automated guided vehicles
(AGVs). It addresses two main challenges: i) resolving collisions between AGVs
and ii) assigning tasks to AGVs. We propose a new collision avoidance strategy
that takes both energy use and travel time into account. For task assignment,
we present two multi-objective algorithms: Non-Dominated Sorting Genetic
Algorithm (NSGA) and Adaptive Large Neighborhood Search (ALNS). Comparative
evaluations show that these proposed methods perform better than existing
approaches in both collision avoidance and task assignment.

</details>


### [26] [Robotic Assistant: Completing Collaborative Tasks with Dexterous Vision-Language-Action Models](https://arxiv.org/abs/2510.25713)
*Boshi An,Chenyu Yang,Robert Katzschmann*

Main category: cs.RO

TL;DR: 提出了一个改进的视觉-语言-动作模型用于灵巧的人机协作，通过FiLM条件化、辅助意图预测和动作空间后处理来减少语言提示需求，在实时系统中实现了长时程行为组合。


<details>
  <summary>Details</summary>
Motivation: 为了在灵巧的人机协作中减少语言提示的需求，使机器人能够更自然地与人类协作。

Method: 在预训练的VLA模型基础上添加：(1) FiLM条件化视觉主干实现任务感知；(2) 辅助意图头预测协作者的手部姿态和目标线索；(3) 动作空间后处理预测紧凑的增量动作和PCA降维的手指关节。

Result: 增量动作表现良好，4个主成分解释了约96%的手部关节方差；动作后处理是主要性能驱动因素；实时系统延迟约0.3秒，能够组合"拾取"和"传递"行为。

Conclusion: 该方法有效减少了语言提示需求，但面临"训练者过拟合"到特定演示者的关键限制。

Abstract: We adapt a pre-trained Vision-Language-Action (VLA) model (Open-VLA) for
dexterous human-robot collaboration with minimal language prompting. Our
approach adds (i) FiLM conditioning to visual backbones for task-aware
perception, (ii) an auxiliary intent head that predicts collaborator hand pose
and target cues, and (iii) action-space post-processing that predicts compact
deltas (position/rotation) and PCA-reduced finger joints before mapping to full
commands. Using a multi-view, teleoperated Franka and Mimic-hand dataset
augmented with MediaPipe hand poses, we demonstrate that delta actions are
well-behaved and that four principal components explain ~96% of hand-joint
variance. Ablations identify action post-processing as the primary performance
driver; auxiliary intent helps, FiLM is mixed, and a directional motion loss is
detrimental. A real-time stack (~0.3 s latency on one RTX 4090) composes
"pick-up" and "pass" into a long-horizon behavior. We surface "trainer
overfitting" to specific demonstrators as the key limitation.

</details>


### [27] [A Humanoid Visual-Tactile-Action Dataset for Contact-Rich Manipulation](https://arxiv.org/abs/2510.25725)
*Eunju Kwon,Seungwon Oh,In-Chang Baek,Yucheon Park,Gyungbo Kim,JaeYoung Moon,Yunho Choi,Kyung-Joong Kim*

Main category: cs.RO

TL;DR: 提出了一个用于操作可变形软物体的人形视觉-触觉-动作数据集，填补了机器人学习数据集中对压力条件多样性表征不足的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人学习数据集主要关注刚性物体，未能充分体现真实世界操作中压力条件的多样性，特别是在接触丰富的操作任务中。

Method: 通过远程操作配备灵巧手的人形机器人收集数据，捕捉不同压力条件下的多模态交互信息。

Result: 成功构建了一个包含视觉、触觉和动作信息的人形机器人数据集，专门针对可变形软物体的操作任务。

Conclusion: 该数据集为未来研究提供了基础，激励开发能够有效利用触觉信号复杂性和多样性的优化策略模型。

Abstract: Contact-rich manipulation has become increasingly important in robot
learning. However, previous studies on robot learning datasets have focused on
rigid objects and underrepresented the diversity of pressure conditions for
real-world manipulation. To address this gap, we present a humanoid
visual-tactile-action dataset designed for manipulating deformable soft
objects. The dataset was collected via teleoperation using a humanoid robot
equipped with dexterous hands, capturing multi-modal interactions under varying
pressure conditions. This work also motivates future research on models with
advanced optimization strategies capable of effectively leveraging the
complexity and diversity of tactile signals.

</details>


### [28] [Modeling Collapse of Steered Vine Robots Under Their Own Weight](https://arxiv.org/abs/2510.25727)
*Ciera McFarland,Margaret McGuinness*

Main category: cs.RO

TL;DR: 提出了一个全面的坍塌模型，能够预测软体生长机器人在任何形状下的坍塌长度，使用真实形状信息和尾部张力。


<details>
  <summary>Details</summary>
Motivation: 软体生长机器人在受限环境中具有高机动性，但在面对环境间隙时可能因自身重量而坍塌，需要预测和防止坍塌。

Method: 开发了一个坍塌预测模型，使用真实形状信息和尾部张力来预测机器人的坍塌行为，并在无转向和单执行器转向的机器人上进行了验证。

Result: 模型准确预测了无转向机器人的坍塌趋势，并能准确预测单执行器转向机器人的坍塌情况。在间隙跨越任务中，模型支持机器人需要充气执行器才能成功跨越间隙而不坍塌。

Conclusion: 该模型能够在任何开放环境中模拟机器人的坍塌行为，并理解其在3D导航任务中成功所需的参数，可应用于其他机器人变体。

Abstract: Soft, vine-inspired growing robots that move by eversion are highly mobile in
confined environments, but, when faced with gaps in the environment, they may
collapse under their own weight while navigating a desired path. In this work,
we present a comprehensive collapse model that can predict the collapse length
of steered robots in any shape using true shape information and tail tension.
We validate this model by collapsing several unsteered robots without true
shape information. The model accurately predicts the trends of those
experiments. We then attempt to collapse a robot steered with a single actuator
at different orientations. Our models accurately predict collapse when it
occurs. Finally, we demonstrate how this could be used in the field by having a
robot attempt a gap-crossing task with and without inflating its actuators. The
robot needs its actuators inflated to cross the gap without collapsing, which
our model supports. Our model has been specifically tested on straight and
series pouch motor-actuated robots made of non-stretchable material, but it
could be applied to other robot variations. This work enables us to model the
robot's collapse behavior in any open environment and understand the parameters
it needs to succeed in 3D navigation tasks.

</details>


### [29] [GET-USE: Learning Generalized Tool Usage for Bimanual Mobile Manipulation via Simulated Embodiment Extensions](https://arxiv.org/abs/2510.25754)
*Bohan Wu,Paul de La Sayette,Li Fei-Fei,Roberto Martín-Martín*

Main category: cs.RO

TL;DR: GeT-USE是一个两阶段方法，通过在模拟中学习机器人本体扩展，然后将学到的几何知识迁移到真实机器人视觉运动策略中，实现通用工具使用。


<details>
  <summary>Details</summary>
Motivation: 当前机器人工具使用方法假设只有一个可用对象，且该对象能完成任务，无法从多个对象中选择最佳工具，特别是当最优工具缺失时。

Method: 首先在模拟中学习机器人本体扩展（构建新末端执行器），识别对任务最有利的通用工具几何形状，然后将学到的几何知识蒸馏到真实机器人策略中。

Result: 在具有22个自由度的真实机器人上，GeT-USE在三个基于视觉的双手机器人移动操作工具使用任务中，比最先进方法的成功率高出30-60%。

Conclusion: 通过模拟中学习本体扩展来获取通用几何知识，可以有效实现真实机器人的通用工具使用，显著提升机器人选择和使用最佳可用工具的能力。

Abstract: The ability to use random objects as tools in a generalizable manner is a
missing piece in robots' intelligence today to boost their versatility and
problem-solving capabilities. State-of-the-art robotic tool usage methods
focused on procedurally generating or crowd-sourcing datasets of tools for a
task to learn how to grasp and manipulate them for that task. However, these
methods assume that only one object is provided and that it is possible, with
the correct grasp, to perform the task; they are not capable of identifying,
grasping, and using the best object for a task when many are available,
especially when the optimal tool is absent. In this work, we propose GeT-USE, a
two-step procedure that learns to perform real-robot generalized tool usage by
learning first to extend the robot's embodiment in simulation and then
transferring the learned strategies to real-robot visuomotor policies. Our key
insight is that by exploring a robot's embodiment extensions (i.e., building
new end-effectors) in simulation, the robot can identify the general tool
geometries most beneficial for a task. This learned geometric knowledge can
then be distilled to perform generalized tool usage tasks by selecting and
using the best available real-world object as tool. On a real robot with 22
degrees of freedom (DOFs), GeT-USE outperforms state-of-the-art methods by
30-60% success rates across three vision-based bimanual mobile manipulation
tool-usage tasks.

</details>


### [30] [STITCH 2.0: Extending Augmented Suturing with EKF Needle Estimation and Thread Management](https://arxiv.org/abs/2510.25768)
*Kush Hari,Ziyang Chen,Hansoul Kim,Ken Goldberg*

Main category: cs.RO

TL;DR: STITCH 2.0是一个改进的机器人缝合系统，通过七项技术改进实现了74.4%的平均伤口闭合率，比基线方法多66%的缝合针数且节省38%时间。


<details>
  <summary>Details</summary>
Motivation: 外科缝合技能在医生间差异很大，需要机器人辅助。现有机器人缝合系统如STITCH 1.0由于针位跟踪不准和线管理不佳，难以完全闭合伤口。

Method: STITCH 2.0包含七项改进：改进的EKF针位估计、新的解线方法、自动3D缝合对齐算法等。

Result: 15次试验中，STITCH 2.0平均实现74.4%伤口闭合，每次试验4.87针，比基线多66%针数且节省38%时间。允许两次人工干预时，平均6针实现100%伤口闭合。

Conclusion: STITCH 2.0显著提升了机器人缝合性能，展示了在手术机器人辅助缝合方面的潜力。

Abstract: Surgical suturing is a high-precision task that impacts patient healing and
scarring. Suturing skill varies widely between surgeons, highlighting the need
for robot assistance. Previous robot suturing works, such as STITCH 1.0 [1],
struggle to fully close wounds due to inaccurate needle tracking and poor
thread management. To address these challenges, we present STITCH 2.0, an
elevated augmented dexterity pipeline with seven improvements including:
improved EKF needle pose estimation, new thread untangling methods, and an
automated 3D suture alignment algorithm. Experimental results over 15 trials
find that STITCH 2.0 on average achieves 74.4% wound closure with 4.87 sutures
per trial, representing 66% more sutures in 38% less time compared to the
previous baseline. When two human interventions are allowed, STITCH 2.0
averages six sutures with 100% wound closure rate. Project website:
https://stitch-2.github.io/

</details>
