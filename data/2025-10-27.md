<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 18]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ROPES: Robotic Pose Estimation via Score-Based Causal Representation Learning](https://arxiv.org/abs/2510.20884)
*Pranamya Kulkarni,Puranjay Datta,Burak Varıcı,Emre Acartürk,Karthikeyan Shanmugam,Ali Tajer*

Main category: cs.RO

TL;DR: ROPES是一个基于分数因果表示学习的无监督机器人姿态估计框架，通过利用机器人自然干预（关节控制）来解耦可控潜在变量，无需标注数据即可高保真地恢复机器人姿态。


<details>
  <summary>Details</summary>
Motivation: 弥合因果表示学习理论与实际应用之间的差距，将CRL应用于机器人领域，解决机器人姿态估计这一明确问题。机器人领域为CRL提供了自然的干预环境。

Method: 提出ROPES框架，利用机器人执行器命令作为自然干预，通过分数因果表示学习识别和解耦可控潜在变量（如关节角度），仅使用分布变化无需标注数据。

Result: 在半合成机械臂实验中，ROPES成功以高保真度解耦潜在生成因子，与真实值高度一致，且优于最近提出的半监督基线方法。

Conclusion: 机器人姿态估计可作为因果表示学习的近实用测试平台，ROPES展示了无监督CRL在机器人领域的实际应用潜力。

Abstract: Causal representation learning (CRL) has emerged as a powerful unsupervised
framework that (i) disentangles the latent generative factors underlying
high-dimensional data, and (ii) learns the cause-and-effect interactions among
the disentangled variables. Despite extensive recent advances in
identifiability and some practical progress, a substantial gap remains between
theory and real-world practice. This paper takes a step toward closing that gap
by bringing CRL to robotics, a domain that has motivated CRL. Specifically,
this paper addresses the well-defined robot pose estimation -- the recovery of
position and orientation from raw images -- by introducing Robotic Pose
Estimation via Score-Based CRL (ROPES). Being an unsupervised framework, ROPES
embodies the essence of interventional CRL by identifying those generative
factors that are actuated: images are generated by intrinsic and extrinsic
latent factors (e.g., joint angles, arm/limb geometry, lighting, background,
and camera configuration) and the objective is to disentangle and recover the
controllable latent variables, i.e., those that can be directly manipulated
(intervened upon) through actuation. Interventional CRL theory shows that
variables that undergo variations via interventions can be identified. In
robotics, such interventions arise naturally by commanding actuators of various
joints and recording images under varied controls. Empirical evaluations in
semi-synthetic manipulator experiments demonstrate that ROPES successfully
disentangles latent generative factors with high fidelity with respect to the
ground truth. Crucially, this is achieved by leveraging only distributional
changes, without using any labeled data. The paper also includes a comparison
with a baseline based on a recently proposed semi-supervised framework. This
paper concludes by positioning robot pose estimation as a near-practical
testbed for CRL.

</details>


### [2] [Aircraft Collision Avoidance Systems: Technological Challenges and Solutions on the Path to Regulatory Acceptance](https://arxiv.org/abs/2510.20916)
*Sydney M. Katz,Robert J. Moss,Dylan M. Asmar,Wesley A. Olson,James K. Kuchar,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 本文综述了飞机防撞系统的技术挑战、解决方案和验证过程，强调经过严格验证并被监管机构接受的系统，可作为其他安全关键系统的案例研究。


<details>
  <summary>Details</summary>
Motivation: 飞机防撞系统对现代航空至关重要，需要解决监视、决策和验证等技术挑战，这些挑战在其他领域也普遍存在。

Method: 通过综述过去几十年的研究和开发成果，重点分析经过严格验证过程和监管机构接受的解决方案。

Result: 识别了飞机防撞系统的关键技术和验证方法，这些系统可作为其他安全关键系统的宝贵参考案例。

Conclusion: 飞机防撞系统的开发经验为广泛的安全关键系统提供了有价值的见解，特别是在技术挑战解决和验证流程方面。

Abstract: Aircraft collision avoidance systems is critical to modern aviation. These
systems are designed to predict potential collisions between aircraft and
recommend appropriate avoidance actions. Creating effective collision avoidance
systems requires solutions to a variety of technical challenges related to
surveillance, decision making, and validation. These challenges have sparked
significant research and development efforts over the past several decades that
have resulted in a variety of proposed solutions. This article provides an
overview of these challenges and solutions with an emphasis on those that have
been put through a rigorous validation process and accepted by regulatory
bodies. The challenges posed by the collision avoidance problem are often
present in other domains, and aircraft collision avoidance systems can serve as
case studies that provide valuable insights for a wide range of safety-critical
systems.

</details>


### [3] [SutureBot: A Precision Framework & Benchmark For Autonomous End-to-End Suturing](https://arxiv.org/abs/2510.20965)
*Jesse Haworth,Juo-Tung Chen,Nigel Nelson,Ji Woong Kim,Masoud Moghani,Chelsea Finn,Axel Krieger*

Main category: cs.RO

TL;DR: SutureBot是一个在da Vinci手术机器人上的自主缝合基准测试系统，涵盖针拾取、组织插入和打结等完整缝合流程，并发布了包含1890次演示的高质量数据集。


<details>
  <summary>Details</summary>
Motivation: 缝合是典型的长时程灵巧操作任务，需要协调的针抓取、精确的组织穿透和安全打结。尽管已有端到端自主化的努力，但完全自主的缝合系统尚未在物理硬件上实现。

Method: 提出了一个目标条件框架，明确优化插入点精度，并评估了包括π₀、GR00T N1、OpenVLA-OFT和多任务ACT在内的最先进视觉-语言-动作模型，每个模型都配备了高级任务预测策略。

Result: 与仅任务基线相比，目标条件框架将目标精度提高了59%-74%，为灵巧模仿学习建立了基准。

Conclusion: 自主缝合是实现手术机器人自主化的关键里程碑，这些贡献支持可重复评估和开发端到端缝合所需的精确聚焦、长时程灵巧操作策略。

Abstract: Robotic suturing is a prototypical long-horizon dexterous manipulation task,
requiring coordinated needle grasping, precise tissue penetration, and secure
knot tying. Despite numerous efforts toward end-to-end autonomy, a fully
autonomous suturing pipeline has yet to be demonstrated on physical hardware.
We introduce SutureBot: an autonomous suturing benchmark on the da Vinci
Research Kit (dVRK), spanning needle pickup, tissue insertion, and knot tying.
To ensure repeatability, we release a high-fidelity dataset comprising 1,890
suturing demonstrations. Furthermore, we propose a goal-conditioned framework
that explicitly optimizes insertion-point precision, improving targeting
accuracy by 59\%-74\% over a task-only baseline. To establish this task as a
benchmark for dexterous imitation learning, we evaluate state-of-the-art
vision-language-action (VLA) models, including $\pi_0$, GR00T N1, OpenVLA-OFT,
and multitask ACT, each augmented with a high-level task-prediction policy.
Autonomous suturing is a key milestone toward achieving robotic autonomy in
surgery. These contributions support reproducible evaluation and development of
precision-focused, long-horizon dexterous manipulation policies necessary for
end-to-end suturing. Dataset is available at:
https://huggingface.co/datasets/jchen396/suturebot

</details>


### [4] [Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization](https://arxiv.org/abs/2510.20974)
*Michael Bezick,Vittorio Giammarino,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出了PPC框架，通过将任意刚体变换下的点云映射到唯一规范姿态，显著提升点云强化学习对相机姿态变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决点云强化学习对相机姿态失配的敏感性，提高在真实环境中的可靠性。

Method: PPC框架将点云映射到规范姿态，使观测对齐到一致坐标系。

Result: 实验显示PPC在挑战性机器人任务中显著提升对未见相机姿态的鲁棒性。

Conclusion: PPC为领域随机化提供了原则性替代方案，有效缓解视角引起的不一致性。

Abstract: Reinforcement Learning (RL) from raw visual input has achieved impressive
successes in recent years, yet it remains fragile to out-of-distribution
variations such as changes in lighting, color, and viewpoint. Point Cloud
Reinforcement Learning (PC-RL) offers a promising alternative by mitigating
appearance-based brittleness, but its sensitivity to camera pose mismatches
continues to undermine reliability in realistic settings. To address this
challenge, we propose PCA Point Cloud (PPC), a canonicalization framework
specifically tailored for downstream robotic control. PPC maps point clouds
under arbitrary rigid-body transformations to a unique canonical pose, aligning
observations to a consistent frame, thereby substantially decreasing
viewpoint-induced inconsistencies. In our experiments, we show that PPC
improves robustness to unseen camera poses across challenging robotic tasks,
providing a principled alternative to domain randomization.

</details>


### [5] [HRT1: One-Shot Human-to-Robot Trajectory Transfer for Mobile Manipulation](https://arxiv.org/abs/2510.21026)
*Sai Haneesh Allu,Jishnu Jaykumar P,Ninad Khargonkar,Tyler Summers,Jian Yao,Yu Xiang*

Main category: cs.RO

TL;DR: 提出基于人类演示视频的机器人轨迹迁移系统，通过AR头显收集演示数据，提取3D手部轨迹并转换为机器人末端轨迹，实现一次演示后在不同环境中执行移动操作任务


<details>
  <summary>Details</summary>
Motivation: 让机器人通过观看人类演示视频学习操作技能，实现跨环境的任务执行能力，解决传统方法需要多次演示或环境特定训练的问题

Method: 四模块系统：AR头显数据收集、视频理解检测物体和3D手部轨迹、人类手部轨迹到机器人末端轨迹转换、轨迹优化算法求解机器人配置空间轨迹

Result: 在移动机械臂上验证了不同操作任务的有效性，系统能够观看一次演示后在不同环境中重复相同的移动操作任务

Conclusion: 该系统成功实现了从人类演示到机器人操作的轨迹迁移，具备跨环境泛化能力，为机器人学习人类技能提供了有效解决方案

Abstract: We introduce a novel system for human-to-robot trajectory transfer that
enables robots to manipulate objects by learning from human demonstration
videos. The system consists of four modules. The first module is a data
collection module that is designed to collect human demonstration videos from
the point of view of a robot using an AR headset. The second module is a video
understanding module that detects objects and extracts 3D human-hand
trajectories from demonstration videos. The third module transfers a human-hand
trajectory into a reference trajectory of a robot end-effector in 3D space. The
last module utilizes a trajectory optimization algorithm to solve a trajectory
in the robot configuration space that can follow the end-effector trajectory
transferred from the human demonstration. Consequently, these modules enable a
robot to watch a human demonstration video once and then repeat the same mobile
manipulation task in different environments, even when objects are placed
differently from the demonstrations. Experiments of different manipulation
tasks are conducted on a mobile manipulator to verify the effectiveness of our
system

</details>


### [6] [Sequentially Teaching Sequential Tasks $(ST)^2$: Teaching Robots Long-horizon Manipulation Skills](https://arxiv.org/abs/2510.21046)
*Zlatan Ajanović,Ravi Prakash,Leandro de Souza Rosa,Jens Kober*

Main category: cs.RO

TL;DR: 比较两种机器人示教框架：传统整体方法和顺序分段方法。研究表明两种方法在轨迹质量和成功率上相似，但用户偏好不同。


<details>
  <summary>Details</summary>
Motivation: 解决长时程任务示教中偏差累积、分布偏移和教师疲劳的问题，探索更有效的示教框架。

Method: 提出$(ST)^2$顺序学习方法，允许用户定义关键点进行增量结构化示教，并与传统整体方法进行用户研究对比。

Result: 两种方法在轨迹质量和成功率上表现相似，用户偏好分化：顺序方法提供迭代控制，整体方法更简单。

Conclusion: 两种示教框架各有优势，选择应基于具体应用场景和用户偏好。

Abstract: Learning from demonstration is effective for teaching robots complex skills
with high sample efficiency. However, teaching long-horizon tasks with multiple
skills is difficult, as deviations accumulate, distributional shift increases,
and human teachers become fatigued, raising the chance of failure. In this
work, we study user responses to two teaching frameworks: (i) a traditional
monolithic approach, where users demonstrate the entire trajectory of a
long-horizon task; and (ii) a sequential approach, where the task is segmented
by the user and demonstrations are provided step by step. To support this
study, we introduce $(ST)^2$, a sequential method for learning long-horizon
manipulation tasks that allows users to control the teaching flow by defining
key points, enabling incremental and structured demonstrations. We conducted a
user study on a restocking task with 16 participants in a realistic retail
environment to evaluate both user preference and method effectiveness. Our
objective and subjective results show that both methods achieve similar
trajectory quality and success rates. Some participants preferred the
sequential approach for its iterative control, while others favored the
monolithic approach for its simplicity.

</details>


### [7] [Revisiting Replanning from Scratch: Real-Time Incremental Planning with Fast Almost-Surely Asymptotically Optimal Planners](https://arxiv.org/abs/2510.21074)
*Mitchell E. C. Sabbadini,Andrew H. Liu,Joseph Ruan,Tyler S. Wilson,Zachary Kingston,Jonathan D. Gammell*

Main category: cs.RO

TL;DR: 本文挑战了反应式重规划必须更新现有计划的传统假设，提出使用快速几乎必然渐近最优（ASAO）规划算法将增量规划问题转化为一系列独立问题求解，从而在动态环境中实现高效规划。


<details>
  <summary>Details</summary>
Motivation: 传统反应式规划方法需要重用信息并更新密集规划图，这在信息变化时计算成本高昂，且在某些应用中检测变化本身就需要大量工作。本文旨在探索更高效的替代方案。

Method: 使用快速几乎必然渐近最优（ASAO）规划算法，如Effort Informed Trees (EIT*)和Asymptotically Optimal RRT-Connect (AORRTC)，这些算法能快速找到初始解并收敛到最优解，无需显式重用现有计划。

Result: 模拟实验显示EIT*找到的中位解路径比测试的反应式规划算法更短，并在机器人臂的真实规划问题中通过AORRTC得到进一步验证。

Conclusion: ASAO算法能够在变化障碍物环境中找到一致的全局规划，而无需显式计划重用，为反应式重规划提供了更高效的替代方案。

Abstract: Robots operating in changing environments either predict obstacle changes
and/or plan quickly enough to react to them. Predictive approaches require a
strong prior about the position and motion of obstacles. Reactive approaches
require no assumptions about their environment but must replan quickly and find
high-quality paths to navigate effectively.
  Reactive approaches often reuse information between queries to reduce
planning cost. These techniques are conceptually sound but updating dense
planning graphs when information changes can be computationally prohibitive. It
can also require significant effort to detect the changes in some applications.
  This paper revisits the long-held assumption that reactive replanning
requires updating existing plans. It shows that the incremental planning
problem can alternatively be solved more efficiently as a series of independent
problems using fast almost-surely asymptotically optimal (ASAO) planning
algorithms. These ASAO algorithms quickly find an initial solution and converge
towards an optimal solution which allows them to find consistent global plans
in the presence of changing obstacles without requiring explicit plan reuse.
This is demonstrated with simulated experiments where Effort Informed Trees
(EIT*) finds shorter median solution paths than the tested reactive planning
algorithms and is further validated using Asymptotically Optimal RRT-Connect
(AORRTC) on a real-world planning problem on a robot arm.

</details>


### [8] [Generalizable Hierarchical Skill Learning via Object-Centric Representation](https://arxiv.org/abs/2510.21121)
*Haibo Zhao,Yu Qi,Boce Hu,Yizhe Zhu,Ziyan Chen,Heng Tian,Xupeng Zhu,Owen Howell,Haojie Huang,Robin Walters,Dian Wang,Robert Platt*

Main category: cs.RO

TL;DR: GSL框架通过对象中心技能作为高层视觉语言模型与低层视觉运动策略的接口，显著提升机器人操作中的策略泛化能力和样本效率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中策略泛化能力不足和样本效率低下的问题，特别是在面对未见过的空间排列、物体外观和任务组合时。

Method: 使用基础模型将演示分解为可迁移的对象规范化技能基元，在测试时将高层代理预测的技能-对象对映射回世界坐标系执行。

Result: 在仿真中，仅用每个任务3个演示训练的GSL比使用30倍数据训练的基线在未见任务上表现提升15.5%；在真实世界实验中，也优于使用10倍数据训练的基线。

Conclusion: GSL的结构化但灵活设计显著提高了样本效率和泛化能力，为机器人操作提供了一种有效的分层策略学习方法。

Abstract: We present Generalizable Hierarchical Skill Learning (GSL), a novel framework
for hierarchical policy learning that significantly improves policy
generalization and sample efficiency in robot manipulation. One core idea of
GSL is to use object-centric skills as an interface that bridges the high-level
vision-language model and the low-level visual-motor policy. Specifically, GSL
decomposes demonstrations into transferable and object-canonicalized skill
primitives using foundation models, ensuring efficient low-level skill learning
in the object frame. At test time, the skill-object pairs predicted by the
high-level agent are fed to the low-level module, where the inferred canonical
actions are mapped back to the world frame for execution. This structured yet
flexible design leads to substantial improvements in sample efficiency and
generalization of our method across unseen spatial arrangements, object
appearances, and task compositions. In simulation, GSL trained with only 3
demonstrations per task outperforms baselines trained with 30 times more data
by 15.5 percent on unseen tasks. In real-world experiments, GSL also surpasses
the baseline trained with 10 times more data.

</details>


### [9] [An Agnostic End-Effector Alignment Controller for Robust Assembly of Modular Space Robots](https://arxiv.org/abs/2510.21164)
*Shamistan Karimov,Elian Neppel,Shreya Santra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 开发了一种用于模块化机器人的自适应速度边界控制器，通过动态超球面钳位确保在月球任务中的平稳稳定运动，在JAXA月球环境模拟器中测试验证了其鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 模块化机器人在月球任务中需要可重构性和容错性，但需要能够安全适应现实世界干扰的控制器。

Method: 在Motion Stack基础上开发了新的控制器，通过动态超球面钳位强制执行自适应速度边界，仅使用实时末端执行器和目标姿态测量来调整平移和旋转速度限制。实现了离散步进版本和连续速度版本两种变体。

Result: 现场测试表明，步进变体产生高度可预测、低摆动的运动，连续变体收敛更快并保持毫米级位置精度，两者都对具有不同机械缺陷和传感噪声的肢体保持鲁棒性。

Conclusion: 结果突显了我们的机器人无关框架在恶劣条件下自主自组装和重构的灵活性和鲁棒性。

Abstract: Modular robots offer reconfigurability and fault tolerance essential for
lunar missions, but require controllers that adapt safely to real-world
disturbances. We build on our previous hardware-agnostic actuator
synchronization in Motion Stack to develop a new controller enforcing adaptive
velocity bounds via a dynamic hypersphere clamp. Using only real-time
end-effector and target pose measurements, the controller adjusts its
translational and rotational speed limits to ensure smooth, stable alignment
without abrupt motions. We implemented two variants, a discrete, step-based
version and a continuous, velocity-based version, and tested them on two
MoonBot limbs in JAXA's lunar environment simulator. Field trials demonstrate
that the step-based variant produces highly predictable, low-wobble motions,
while the continuous variant converges more quickly and maintains
millimeter-level positional accuracy, and both remain robust across limbs with
differing mechanical imperfections and sensing noise (e.g., backlash and flex).
These results highlight the flexibility and robustness of our robot-agnostic
framework for autonomous self-assembly and reconfiguration under harsh
conditions.

</details>


### [10] [Underwater Visual-Inertial-Acoustic-Depth SLAM with DVL Preintegration for Degraded Environments](https://arxiv.org/abs/2510.21215)
*Shuoshuo Ding,Tiedong Zhang,Dapeng Jiang,Ming Lei*

Main category: cs.RO

TL;DR: 提出了一种基于图优化的视觉-惯性-声学-深度SLAM系统，通过集成立体相机、IMU、多普勒测速仪和压力传感器，在水下视觉退化环境中实现稳定定位与建图。


<details>
  <summary>Details</summary>
Motivation: 水下环境存在能见度有限、光照不足和特征稀缺等视觉退化问题，给视觉惯性SLAM系统带来重大挑战。

Method: 采用四传感器紧密融合策略，提出基于速度偏差的DVL预积分方法，在前端使用混合跟踪策略和声学-惯性-深度联合优化，并在图优化框架中融入多源混合残差。

Result: 在模拟和真实水下场景中的定量和定性分析表明，该系统在稳定性和定位精度方面优于当前最先进的立体视觉惯性SLAM系统。

Conclusion: 该方法在视觉挑战性环境中表现出卓越的鲁棒性，有效解决了水下SLAM系统的视觉退化问题。

Abstract: Visual degradation caused by limited visibility, insufficient lighting, and
feature scarcity in underwater environments presents significant challenges to
visual-inertial simultaneous localization and mapping (SLAM) systems. To
address these challenges, this paper proposes a graph-based
visual-inertial-acoustic-depth SLAM system that integrates a stereo camera, an
inertial measurement unit (IMU), the Doppler velocity log (DVL), and a pressure
sensor. The key innovation lies in the tight integration of four distinct
sensor modalities to ensure reliable operation, even under degraded visual
conditions. To mitigate DVL drift and improve measurement efficiency, we
propose a novel velocity-bias-based DVL preintegration strategy. At the
frontend, hybrid tracking strategies and acoustic-inertial-depth joint
optimization enhance system stability. Additionally, multi-source hybrid
residuals are incorporated into a graph optimization framework. Extensive
quantitative and qualitative analyses of the proposed system are conducted in
both simulated and real-world underwater scenarios. The results demonstrate
that our approach outperforms current state-of-the-art stereo visual-inertial
SLAM systems in both stability and localization accuracy, exhibiting
exceptional robustness, particularly in visually challenging environments.

</details>


### [11] [Remote Autonomy for Multiple Small Lowcost UAVs in GNSS-denied Search and Rescue Operations](https://arxiv.org/abs/2510.21357)
*Daniel Schleich,Jan Quenzel,Sven Behnke*

Main category: cs.RO

TL;DR: 开发了一个使用消费级DJI无人机进行自主飞行的系统，通过Android应用在无人机遥控器上实现状态估计和避障，支持单操作员同时管理多架异构无人机。


<details>
  <summary>Details</summary>
Motivation: 消费级无人机在应急响应中广泛应用，但通常需要手动操作，特别是在未知GNSS受限环境和结构附近需要训练有素的飞行员。自主飞行可以简化操作并减轻操作员负担，但现有自主系统通常需要特殊编程接口、定制传感器和强大机载计算机，限制了广泛部署。

Method: 使用轻量级消费级DJI无人机，通过Android应用在无人机遥控器上直接运行状态估计和避障算法。地面控制站允许单操作员配置和监督多架异构无人机，并将所有无人机的观测数据整合到联合3D环境模型中。

Result: 实现了基于消费级硬件的自主飞行系统，无需特殊编程接口或定制传感器，降低了部署门槛。单操作员能够同时管理多架无人机，并通过联合3D环境模型提高了态势感知能力。

Conclusion: 该系统展示了在消费级无人机上实现自主飞行的可行性，通过利用现有硬件和软件平台，降低了自主无人机系统的部署复杂性，为应急响应等应用场景提供了实用的解决方案。

Abstract: In recent years, consumer-grade UAVs have been widely adopted by first
responders. In general, they are operated manually, which requires trained
pilots, especially in unknown GNSS-denied environments and in the vicinity of
structures. Autonomous flight can facilitate the application of UAVs and reduce
operator strain. However, autonomous systems usually require special
programming interfaces, custom sensor setups, and strong onboard computers,
which limits a broader deployment.
  We present a system for autonomous flight using lightweight consumer-grade
DJI drones. They are controlled by an Android app for state estimation and
obstacle avoidance directly running on the UAV's remote control. Our ground
control station enables a single operator to configure and supervise multiple
heterogeneous UAVs at once. Furthermore, it combines the observations of all
UAVs into a joint 3D environment model for improved situational awareness.

</details>


### [12] [Load-bearing Assessment for Safe Locomotion of Quadruped Robots on Collapsing Terrain](https://arxiv.org/abs/2510.21369)
*Vivian S. Medeiros,Giovanni B. Dessy,Thiago Boaventura,Marcelo Becker,Claudio Semini,Victor Barasuol*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人在不稳定地形上安全导航的鲁棒运动框架，通过整合地形探测、承重分析、运动规划和控制策略，使机器人能够检测可坍塌区域并动态调整落脚点。


<details>
  <summary>Details</summary>
Motivation: 坍塌地形在搜救任务和行星探索中常见，对四足机器人构成重大挑战，传统方法依赖专用传感器或外部地形测绘，存在局限性。

Method: 利用关节测量评估地形稳定性而无需硬件修改，通过模型预测控制(MPC)系统优化机器人运动，平衡稳定性和探测约束，状态机协调地形探测动作。

Result: 在定制坍塌平台和岩石地形上的实验结果表明，该框架能够在穿越坍塌地形时保持稳定性并优先考虑安全性。

Conclusion: 该框架为四足机器人在不稳定地形上的安全导航提供了有效解决方案，通过集成多种策略实现了鲁棒的运动控制。

Abstract: Collapsing terrains, often present in search and rescue missions or planetary
exploration, pose significant challenges for quadruped robots. This paper
introduces a robust locomotion framework for safe navigation over unstable
surfaces by integrating terrain probing, load-bearing analysis, motion
planning, and control strategies. Unlike traditional methods that rely on
specialized sensors or external terrain mapping alone, our approach leverages
joint measurements to assess terrain stability without hardware modifications.
A Model Predictive Control (MPC) system optimizes robot motion, balancing
stability and probing constraints, while a state machine coordinates terrain
probing actions, enabling the robot to detect collapsible regions and
dynamically adjust its footholds. Experimental results on custom-made
collapsing platforms and rocky terrains demonstrate the framework's ability to
traverse collapsing terrain while maintaining stability and prioritizing
safety.

</details>


### [13] [PREVENT: Proactive Risk Evaluation and Vigilant Execution of Tasks for Mobile Robotic Chemists using Multi-Modal Behavior Trees](https://arxiv.org/abs/2510.21438)
*Satheeshkumar Veeramani,Zhengxue Zhou,Francisco Munguia-Galeano,Hatem Fakhruldeen,Thomas Roddelkopf,Mohammed Faeik Ruzaij Al-Okby,Kerstin Thurow,Andrew Ian Cooper*

Main category: cs.RO

TL;DR: 提出PREVENT系统，通过多模态行为树方法解决移动化学机器人缺乏工作流意识的问题，避免误报和漏报


<details>
  <summary>Details</summary>
Motivation: 当前移动化学机器人缺乏工作流意识，小异常如样品瓶盖未盖好可能中断整个工作流程，浪费时间和资源，并可能使研究人员暴露于有毒物质

Method: 采用基于多模态行为树的方法，包含分层感知机制，利用AI技术和通过灵巧视觉、导航视觉摄像头及物联网气体传感器的感官反馈进行执行相关决策

Result: 实验评估显示该方法相对高效，在模拟风险场景中完全避免了误报和漏报，多模态感知技能在导航和操作方面的部署准确率均高于相应单模态技能的平均水平

Conclusion: PREVENT系统能够有效集成到现有软件架构中，提高移动化学机器人的工作流意识和安全性

Abstract: Mobile robotic chemists are a fast growing trend in the field of chemistry
and materials research. However, so far these mobile robots lack workflow
awareness skills. This poses the risk that even a small anomaly, such as an
improperly capped sample vial could disrupt the entire workflow. This wastes
time, and resources, and could pose risks to human researchers, such as
exposure to toxic materials. Existing perception mechanisms can be used to
predict anomalies but they often generate excessive false positives. This may
halt workflow execution unnecessarily, requiring researchers to intervene and
to resume the workflow when no problem actually exists, negating the benefits
of autonomous operation. To address this problem, we propose PREVENT a system
comprising navigation and manipulation skills based on a multimodal Behavior
Tree (BT) approach that can be integrated into existing software architectures
with minimal modifications. Our approach involves a hierarchical perception
mechanism that exploits AI techniques and sensory feedback through Dexterous
Vision and Navigational Vision cameras and an IoT gas sensor module for
execution-related decision-making. Experimental evaluations show that the
proposed approach is comparatively efficient and completely avoids both false
negatives and false positives when tested in simulated risk scenarios within
our robotic chemistry workflow. The results also show that the proposed
multi-modal perception skills achieved deployment accuracies that were higher
than the average of the corresponding uni-modal skills, both for navigation and
for manipulation.

</details>


### [14] [Enhancing Social Robots through Resilient AI](https://arxiv.org/abs/2510.21469)
*Domenico Palmisano,Giuseppe Palestra,Berardina Nadja De Carolis*

Main category: cs.RO

TL;DR: 本文探讨了韧性作为社交机器人的基本特性，特别是在医疗保健等敏感领域与老年人互动时，韧性对于建立信任至关重要。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能在医疗、教育等敏感领域的深入应用，需要确保系统具有韧性和鲁棒性，特别是在与信任度较低的老年人互动时。

Method: 将韧性定义为在不利或压力条件下，即使性能下降或减弱，仍能保持基本操作能力的能力。

Result: 研究表明韧性是社交机器人的基本特性，通过韧性可以确保对机器人本身的信任。

Conclusion: 韧性对于社交机器人在敏感环境中，特别是与老年人互动时建立和维持信任至关重要。

Abstract: As artificial intelligence continues to advance and becomes more integrated
into sensitive areas like healthcare, education, and everyday life, it's
crucial for these systems to be both resilient and robust. This paper shows how
resilience is a fundamental characteristic of social robots, which, through it,
ensure trust in the robot itself-an essential element especially when operating
in contexts with elderly people, who often have low trust in these systems.
Resilience is therefore the ability to operate under adverse or stressful
conditions, even when degraded or weakened, while maintaining essential
operational capabilities.

</details>


### [15] [AURASeg: Attention Guided Upsampling with Residual Boundary-Assistive Refinement for Drivable-Area Segmentation](https://arxiv.org/abs/2510.21536)
*Narendhiran Vijayakumar,Sridevi. M*

Main category: cs.RO

TL;DR: 提出AURASeg地面分割模型，通过注意力引导上采样和边界细化模块，在保持高精度的同时提升边界分割质量。


<details>
  <summary>Details</summary>
Motivation: 现有分割模型在室内和结构化环境中难以处理细粒度特征，存在多尺度处理不足、边界细化不佳和特征表示有限等问题。

Method: 使用CSP-Darknet骨干网络，添加残差边界细化模块(RBRM)进行精确边缘描绘，注意力渐进上采样解码器(APUD)进行特征整合，以及轻量级空洞空间金字塔池化(ASPP-Lite)模块提取多尺度上下文。

Result: 在GMRP数据集和自定义Gazebo室内数据集上，相比最先进模型，mIoU提升+1.26%，分割精度提升+1.65%。

Conclusion: 该方法在室内外环境中都能实现精确的边界细化，且对推理速度影响最小，适用于自主感知任务。

Abstract: Free space ground segmentation is essential to navigate robots and autonomous
vehicles, recognize drivable zones, and traverse efficiently. Fine-grained
features remain challenging for existing segmentation models, particularly for
robots in indoor and structured environments. These difficulties arise from
ineffective multi-scale processing, suboptimal boundary refinement, and limited
feature representation. In order to overcome these limitations, we propose
Attention-Guided Upsampling with Residual Boundary-Assistive Refinement
(AURASeg), a ground-plane semantic segmentation model that maintains high
segmentation accuracy while improving border precision. Our method uses
CSP-Darknet backbone by adding a Residual Border Refinement Module (RBRM) for
accurate edge delineation and an Attention Progressive Upsampling Decoder
(APUD) for strong feature integration. We also incorporate a lightweight Atrous
Spatial Pyramid Pooling (ASPP-Lite) module to ensure multi-scale context
extraction without compromising real-time performance. The proposed model beats
benchmark segmentation architectures in mIoU and F1 metrics when tested on the
Ground Mobile Robot Perception (GMRP) Dataset and a custom Gazebo indoor
dataset. Our approach achieves an improvement in mean Intersection-over-Union
(mIoU) of +1.26% and segmentation precision of +1.65% compared to
state-of-the-art models. These results show that our technique is feasible for
autonomous perception in both indoor and outdoor environments, enabling precise
border refinement with minimal effect on inference speed.

</details>


### [16] [Scalable Vision-Language-Action Model Pretraining for Robotic Manipulation with Real-Life Human Activity Videos](https://arxiv.org/abs/2510.21571)
*Qixiu Li,Yu Deng,Yaobo Liang,Lin Luo,Lei Zhou,Chengtang Yao,Lingqi Zeng,Zhiyuan Feng,Huizhi Liang,Sicheng Xu,Yizhong Zhang,Xi Chen,Hao Chen,Lily Sun,Dong Chen,Jiaolong Yang,Baining Guo*

Main category: cs.RO

TL;DR: 提出了一种利用未标注的真实人类手部活动视频预训练机器人视觉-语言-动作模型的新方法，通过自动化分析将人类手部视频转化为机器人训练数据，构建了包含100万片段、2600万帧的大规模数据集，并展示了强大的零样本能力和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人训练数据稀缺、覆盖范围有限的问题，利用大量未标注的人类手部活动视频作为机器人预训练数据源，扩展机器人对真实世界物体、任务和环境变化的覆盖范围。

Method: 开发全自动的人类活动分析方法，将任意人类手部视频转化为与机器人VLA训练数据格式对齐的片段，包括原子级手部活动分割、语言描述、3D手部运动和相机运动；构建大规模手部VLA数据集，设计灵巧手VLA模型架构并进行预训练。

Result: 构建了包含100万片段、2600万帧的大规模数据集，覆盖广泛的物体、概念和灵巧操作任务；模型在未见过的真实世界观察中表现出强大的零样本能力；在少量真实机器人动作数据上微调后，任务成功率和泛化能力显著提升；模型性能随预训练数据规模呈现良好的扩展性。

Conclusion: 这项工作为可扩展的VLA预训练奠定了坚实基础，推动机器人朝着真正可泛化的具身智能发展，证明了利用人类视频数据预训练机器人模型的可行性和有效性。

Abstract: This paper presents a novel approach for pretraining robotic manipulation
Vision-Language-Action (VLA) models using a large corpus of unscripted
real-life video recordings of human hand activities. Treating human hand as
dexterous robot end-effector, we show that "in-the-wild" egocentric human
videos without any annotations can be transformed into data formats fully
aligned with existing robotic V-L-A training data in terms of task granularity
and labels. This is achieved by the development of a fully-automated holistic
human activity analysis approach for arbitrary human hand videos. This approach
can generate atomic-level hand activity segments and their language
descriptions, each accompanied with framewise 3D hand motion and camera motion.
We process a large volume of egocentric videos and create a hand-VLA training
dataset containing 1M episodes and 26M frames. This training data covers a wide
range of objects and concepts, dexterous manipulation tasks, and environment
variations in real life, vastly exceeding the coverage of existing robot data.
We design a dexterous hand VLA model architecture and pretrain the model on
this dataset. The model exhibits strong zero-shot capabilities on completely
unseen real-world observations. Additionally, fine-tuning it on a small amount
of real robot action data significantly improves task success rates and
generalization to novel objects in real robotic experiments. We also
demonstrate the appealing scaling behavior of the model's task performance with
respect to pretraining data scale. We believe this work lays a solid foundation
for scalable VLA pretraining, advancing robots toward truly generalizable
embodied intelligence.

</details>


### [17] [Enhancing Tactile-based Reinforcement Learning for Robotic Control](https://arxiv.org/abs/2510.21609)
*Elle Miller,Trevor McInroe,David Abel,Oisin Mac Aodha,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 该论文开发了自监督学习方法，有效利用稀疏二进制触觉信号提升机器人操作的灵巧性，在复杂接触任务中实现超人类表现，并发布了RoTO基准测试。


<details>
  <summary>Details</summary>
Motivation: 实现安全可靠的现实世界机器人操作需要超越视觉感知，整合触觉传感来克服感官缺陷和对理想状态信息的依赖。尽管触觉传感具有潜力，但在强化学习中的效果仍不一致。

Method: 开发自监督学习(SSL)方法，有效利用触觉观测，重点关注本体感觉和稀疏二进制接触的可扩展设置。研究发现将SSL记忆与在线策略记忆解耦可以改善性能。

Result: 稀疏二进制触觉信号对于灵巧性至关重要，特别是在本体感觉控制误差无法检测的机器人-物体解耦运动中。智能体在复杂接触任务（球弹跳和保定球旋转）中实现了超人类灵巧性。

Conclusion: 触觉传感对于机器人灵巧操作至关重要，自监督学习方法能有效利用触觉信号。发布了Robot Tactile Olympiad (RoTO)基准测试来标准化和促进触觉操作研究。

Abstract: Achieving safe, reliable real-world robotic manipulation requires agents to
evolve beyond vision and incorporate tactile sensing to overcome sensory
deficits and reliance on idealised state information. Despite its potential,
the efficacy of tactile sensing in reinforcement learning (RL) remains
inconsistent. We address this by developing self-supervised learning (SSL)
methodologies to more effectively harness tactile observations, focusing on a
scalable setup of proprioception and sparse binary contacts. We empirically
demonstrate that sparse binary tactile signals are critical for dexterity,
particularly for interactions that proprioceptive control errors do not
register, such as decoupled robot-object motions. Our agents achieve superhuman
dexterity in complex contact tasks (ball bouncing and Baoding ball rotation).
Furthermore, we find that decoupling the SSL memory from the on-policy memory
can improve performance. We release the Robot Tactile Olympiad (RoTO) benchmark
to standardise and promote future research in tactile-based manipulation.
Project page: https://elle-miller.github.io/tactile_rl

</details>


### [18] [Design and Structural Validation of a Micro-UAV with On-Board Dynamic Route Planning](https://arxiv.org/abs/2510.21648)
*Inbazhagan Ravikumar,Ram Sundhar,Narendhiran Vijayakumar*

Main category: cs.RO

TL;DR: 本文介绍了一种用于搜救任务的低成本、模块化定制无人机，解决了轻型无人机在复杂地形中的结构耐久性和动态路径重规划问题。


<details>
  <summary>Details</summary>
Motivation: 解决低成本轻型无人机在搜救任务中面临的结构脆弱性和无法动态重规划路径的关键限制，特别是在复杂地形和发现新受害者或障碍物时。

Method: 使用常见材料和组件从头构建定制无人机，强调模块化、低成本和易组装性。结构框架采用轻量耐用材料加固，机载控制系统完全基于免费开源软件。

Result: 该系统在不依赖昂贵硬件加速器的情况下，展示了实时感知和自适应导航能力，为实际搜救任务提供了经济实用的解决方案。

Conclusion: 提出的定制无人机系统成功解决了搜救无人机在结构耐久性和动态路径规划方面的关键问题，证明了低成本开源方案在复杂搜救环境中的可行性。

Abstract: Micro aerial vehicles are becoming increasingly important in search and
rescue operations due to their agility, speed, and ability to access confined
spaces or hazardous areas. However, designing lightweight aerial systems
presents significant structural, aerodynamic, and computational challenges.
This work addresses two key limitations in many low-cost aerial systems under
two kilograms: their lack of structural durability during flight through rough
terrains and inability to replan paths dynamically when new victims or
obstacles are detected. We present a fully customised drone built from scratch
using only commonly available components and materials, emphasising modularity,
low cost, and ease of assembly. The structural frame is reinforced with
lightweight yet durable materials to withstand impact, while the onboard
control system is powered entirely by free, open-source software solutions. The
proposed system demonstrates real-time perception and adaptive navigation
capabilities without relying on expensive hardware accelerators, offering an
affordable and practical solution for real-world search and rescue missions.

</details>
