<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [First Plan Then Evaluate: Use a Vectorized Motion Planner for Grasping](https://arxiv.org/abs/2509.07162)
*Martin Matak,Mohanraj Devendran Ashanti,Karl Van Wyk,Tucker Hermans*

Main category: cs.RO

TL;DR: 提出并行轨迹规划框架，通过向量化运动规划器同时为多个抓取目标规划轨迹，选择成功率最高的轨迹执行，解决了传统生成器-评估器-规划器框架中时间消耗与准确性的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法对初始化敏感且耗时，生成器-评估器-规划器框架存在要么花费更多时间寻找成功轨迹、要么降低抓取成功概率估计准确性的两难问题。

Method: 提出并行轨迹规划框架：同时为多个抓取目标规划轨迹，使用向量化运动规划器高效规划，评估器估计各轨迹的抓取成功概率，选择最可能成功的轨迹执行。

Result: 实验表明该方法在不同物体、生成器和运动规划器上均优于传统框架，并能成功推广到真实世界的新环境中，包括不同货架和桌子高度。

Conclusion: 并行轨迹规划框架有效解决了传统方法的时间-准确性权衡问题，提高了抓取效率和成功率，具有良好的泛化能力。

Abstract: Autonomous multi-finger grasping is a fundamental capability in robotic
manipulation. Optimization-based approaches show strong performance, but tend
to be sensitive to initialization and are potentially time-consuming. As an
alternative, the generator-evaluator-planner framework has been proposed. A
generator generates grasp candidates, an evaluator ranks the proposed grasps,
and a motion planner plans a trajectory to the highest-ranked grasp. If the
planner doesn't find a trajectory, a new trajectory optimization is started
with the next-best grasp as the target and so on. However, executing
lower-ranked grasps means a lower chance of grasp success, and multiple
trajectory optimizations are time-consuming. Alternatively, relaxing the
threshold for motion planning accuracy allows for easier computation of a
successful trajectory but implies lower accuracy in estimating grasp success
likelihood. It's a lose-lose proposition: either spend more time finding a
successful trajectory or have a worse estimate of grasp success. We propose a
framework that plans trajectories to a set of generated grasp targets in
parallel, the evaluator estimates the grasp success likelihood of the resulting
trajectories, and the robot executes the trajectory most likely to succeed. To
plan trajectories to different targets efficiently, we propose the use of a
vectorized motion planner. Our experiments show our approach improves over the
traditional generator-evaluator-planner framework across different objects,
generators, and motion planners, and successfully generalizes to novel
environments in the real world, including different shelves and table heights.
Project website https://sites.google.com/view/fpte

</details>


### [2] [Quantum Machine Learning and Grover's Algorithm for Quantum Optimization of Robotic Manipulators](https://arxiv.org/abs/2509.07216)
*Hassen Nigatu,Shi Gaokun,Li Jituo,Wang Jin,Lu Guodong,Howard Li*

Main category: cs.RO

TL;DR: 量子机器学习与Grover算法结合的量子原生框架，用于高效解决机器人运动学优化问题，在复杂高维空间中实现二次搜索复杂度降低，相比经典方法最高达到93倍加速


<details>
  <summary>Details</summary>
Motivation: 优化高自由度机械臂需要在复杂高维配置空间中搜索，这对经典计算方法具有计算挑战性，需要更高效的优化方法

Method: 使用参数化量子电路训练前向运动学模型，构建oracle识别最优配置，利用Grover算法实现搜索复杂度的二次降低

Result: 在1-DoF、2-DoF和双臂机械臂任务上验证，随着问题维度增加，相比Nelder Mead等经典优化器实现最高93倍的加速

Conclusion: 建立了一个基础的量子原生框架，有效连接量子计算和机器人学问题，为机器人运动学优化提供了新的解决方案

Abstract: Optimizing high-degree of freedom robotic manipulators requires searching
complex, high-dimensional configuration spaces, a task that is computationally
challenging for classical methods. This paper introduces a quantum native
framework that integrates quantum machine learning with Grover's algorithm to
solve kinematic optimization problems efficiently. A parameterized quantum
circuit is trained to approximate the forward kinematics model, which then
constructs an oracle to identify optimal configurations. Grover's algorithm
leverages this oracle to provide a quadratic reduction in search complexity.
Demonstrated on 1-DoF, 2-DoF, and dual-arm manipulator tasks, the method
achieves significant speedups-up to 93x over classical optimizers like Nelder
Mead as problem dimensionality increases. This work establishes a foundational,
quantum-native framework for robot kinematic optimization, effectively bridging
quantum computing and robotics problems.

</details>


### [3] [Safe Gap-based Planning in Dynamic Settings](https://arxiv.org/abs/2509.07239)
*Max Asselmeier,Abdel Zaro,Dhruv Ahuja,Ye Zhao,Patricio A. Vela*

Main category: cs.RO

TL;DR: 本文提出了一种用于动态环境的感知信息间隙局部规划器dynamic gap，通过间隙跟踪、动态估计、间隙传播和追踪制导理论，在动态环境中实现可证明的碰撞避免


<details>
  <summary>Details</summary>
Motivation: 现有动态环境中的感知信息局部规划器通常依赖经验性鲁棒性而非对动态障碍物的形式化分析，需要更可靠的动态障碍物处理方法

Method: 1) 跟踪极坐标自由空间间隙并估计其动态；2) 通过新颖的间隙传播算法预测未来可行区域；3) 利用追踪制导理论生成理想条件下可证明无碰撞的局部轨迹；4) 在无间隙情况下执行障碍物中心化处理

Result: 在动态环境中，dynamic gap在所有基准测试中均优于传统和学习型运动规划器，并在TurtleBot2平台上通过真实世界实验验证了碰撞避免行为

Conclusion: dynamic gap通过形式化分析动态障碍物和间隙传播算法，为动态环境中的局部规划提供了可靠且性能优越的解决方案

Abstract: This chapter extends the family of perception-informed gap-based local
planners to dynamic environments. Existing perception-informed local planners
that operate in dynamic environments often rely on emergent or empirical
robustness for collision avoidance as opposed to performing formal analysis of
dynamic obstacles. This proposed planner, dynamic gap, explicitly addresses
dynamic obstacles through several steps in the planning pipeline. First, polar
regions of free space known as gaps are tracked and their dynamics are
estimated in order to understand how the local environment evolves over time.
Then, at planning time, gaps are propagated into the future through novel gap
propagation algorithms to understand what regions are feasible for passage.
Lastly, pursuit guidance theory is leveraged to generate local trajectories
that are provably collision-free under ideal conditions. Additionally,
obstacle-centric ungap processing is performed in situations where no gaps
exist to robustify the overall planning framework. A set of gap-based planners
are benchmarked against a series of classical and learned motion planners in
dynamic environments, and dynamic gap is shown to outperform all other
baselines in all environments. Furthermore, dynamic gap is deployed on a
TurtleBot2 platform in several real-world experiments to validate collision
avoidance behaviors.

</details>


### [4] [Performance Characterization of a Point-Cloud-Based Path Planner in Off-Road Terrain](https://arxiv.org/abs/2509.07321)
*Casey D. Majhor,Jeremy P. Bos*

Main category: cs.RO

TL;DR: MUONS点云导航系统在越野自主导航中表现优异，仿真测试成功率98%，实地测试零失败，通过统计分析发现Bi-RRT扩展半径是最关键参数


<details>
  <summary>Details</summary>
Motivation: 评估点云导航系统在复杂越野环境中的性能，为自主地面车辆(AGV)提供可靠的导航解决方案

Method: 采用30,000次仿真试验和实地测试，分析三种复杂地形图和七个路径规划参数的20种组合，进行统计和相关性分析

Result: 仿真成功率98%，实地测试零失败，Bi-RRT扩展半径与规划时间和路径长度相关性最强，参数调整与实地性能高度相关

Conclusion: 蒙特卡洛仿真可以有效地用于性能评估和参数调优，为越野自主导航系统开发提供了可靠的方法论

Abstract: We present a comprehensive evaluation of a point-cloud-based navigation
stack, MUONS, for autonomous off-road navigation. Performance is characterized
by analyzing the results of 30,000 planning and navigation trials in simulation
and validated through field testing. Our simulation campaign considers three
kinematically challenging terrain maps and twenty combinations of seven
path-planning parameters. In simulation, our MUONS-equipped AGV achieved a 0.98
success rate and experienced no failures in the field. By statistical and
correlation analysis we determined that the Bi-RRT expansion radius used in the
initial planning stages is most correlated with performance in terms of
planning time and traversed path length. Finally, we observed that the
proportional variation due to changes in the tuning parameters is remarkably
well correlated to performance in field testing. This finding supports the use
of Monte-Carlo simulation campaigns for performance assessment and parameter
tuning.

</details>


### [5] [Aerial-ground Cross-modal Localization: Dataset, Ground-truth, and Benchmark](https://arxiv.org/abs/2509.07362)
*Yandi Yang,Jianping Li,Youqi Liao,Yuhao Li,Yizhe Zhang,Zhen Dong,Bisheng Yang,Naser El-Sheimy*

Main category: cs.RO

TL;DR: 基于机载光轩扫描(ALS)点云的空中-地面跨平台视觉定位新数据集


<details>
  <summary>Details</summary>
Motivation: 解决密集城市环境中图像定位的挑战，如缺少纹理表面、严重视点变化和长期偏移，利用公开的ALS数据作为先验地图

Method: 构建大规模数据集，整合来自移动绘图系统的地面级图像与武汉、香港和旧金山的ALS点云数据

Result: 提供了一个新的大规模跨平台数据集，支持空中-地面跨平台视觉定位算法的验证

Conclusion: 该数据集为解决密集城市视觉定位的三大关键问题提供了基础，有助于推进ALS基于定位方法的研究和应用

Abstract: Accurate visual localization in dense urban environments poses a fundamental
task in photogrammetry, geospatial information science, and robotics. While
imagery is a low-cost and widely accessible sensing modality, its effectiveness
on visual odometry is often limited by textureless surfaces, severe viewpoint
changes, and long-term drift. The growing public availability of airborne laser
scanning (ALS) data opens new avenues for scalable and precise visual
localization by leveraging ALS as a prior map. However, the potential of
ALS-based localization remains underexplored due to three key limitations: (1)
the lack of platform-diverse datasets, (2) the absence of reliable ground-truth
generation methods applicable to large-scale urban environments, and (3)
limited validation of existing Image-to-Point Cloud (I2P) algorithms under
aerial-ground cross-platform settings. To overcome these challenges, we
introduce a new large-scale dataset that integrates ground-level imagery from
mobile mapping systems with ALS point clouds collected in Wuhan, Hong Kong, and
San Francisco.

</details>


### [6] [TransMPC: Transformer-based Explicit MPC with Variable Prediction Horizon](https://arxiv.org/abs/2509.07381)
*Sichao Wu,Jiang Wu,Xingyu Cao,Fawang Zhang,Guangyuan Yu,Junjie Zhao,Yue Qu,Fei Ma,Jingliang Duan*

Main category: cs.RO

TL;DR: TransMPC是一种基于Transformer的显式MPC算法，通过双向自注意力机制实时生成高精度控制序列，解决了传统MPC计算复杂和现有显式MPC精度不足的问题。


<details>
  <summary>Details</summary>
Motivation: 传统在线MPC方法计算复杂度过高，而现有显式MPC方法依赖简化的系统动力学和成本函数，限制了在复杂系统中的精度。需要一种既能降低在线计算负担又能保持高精度的解决方案。

Method: 使用编码器-only Transformer架构，利用双向自注意力机制，在单次前向传播中同时推断整个控制序列。采用直接策略优化框架，通过自动微分直接优化真实有限时域成本，结合随机时域采样和回放缓冲区确保训练样本的独立同分布。

Result: 大量仿真和真实车辆控制实验验证了TransMPC在解决方案精度、时域适应性和计算效率方面的有效性。

Conclusion: TransMPC成功地将Transformer架构应用于显式MPC，实现了对复杂动态系统的高精度实时控制，同时保持了低推理延迟和良好的泛化能力。

Abstract: Traditional online Model Predictive Control (MPC) methods often suffer from
excessive computational complexity, limiting their practical deployment.
Explicit MPC mitigates online computational load by pre-computing control
policies offline; however, existing explicit MPC methods typically rely on
simplified system dynamics and cost functions, restricting their accuracy for
complex systems. This paper proposes TransMPC, a novel Transformer-based
explicit MPC algorithm capable of generating highly accurate control sequences
in real-time for complex dynamic systems. Specifically, we formulate the MPC
policy as an encoder-only Transformer leveraging bidirectional self-attention,
enabling simultaneous inference of entire control sequences in a single forward
pass. This design inherently accommodates variable prediction horizons while
ensuring low inference latency. Furthermore, we introduce a direct policy
optimization framework that alternates between sampling and learning phases.
Unlike imitation-based approaches dependent on precomputed optimal
trajectories, TransMPC directly optimizes the true finite-horizon cost via
automatic differentiation. Random horizon sampling combined with a replay
buffer provides independent and identically distributed (i.i.d.) training
samples, ensuring robust generalization across varying states and horizon
lengths. Extensive simulations and real-world vehicle control experiments
validate the effectiveness of TransMPC in terms of solution accuracy,
adaptability to varying horizons, and computational efficiency.

</details>


### [7] [Attention and Risk-Aware Decision Framework for Safe Autonomous Driving](https://arxiv.org/abs/2509.07412)
*Zhen Tian,Fujiang Yuan,Yangfan He,Qinghao Li,Changlin Chen,Huilin Chen,Tianxiang Xu,Jianyu Duan,Yanhong Peng,Zhihao Lin*

Main category: cs.RO

TL;DR: 本文提出了一种改进的PPO算法，通过引入风险感知机制、风险注意力决策网络、平衡奖励函数和安全辅助机制，解决了自动驾驶中PPO算法训练效果差、效率低的问题。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中基于模型的方法难以应对意外事件，而现有的PPO算法在长序列训练中存在训练效果差、效率低的问题，训练效果差等同于驾驶任务中的碰撞风险。

Method: 开发改进的PPO算法，包含四个核心组件：风险感知机制（突出潜在碰撞区域）、风险注意力决策网络（对高风险区域进行通道和空间注意力处理）、平衡奖励函数（根据周围车辆数量调整奖励）、安全辅助机制（在车道保持和变道时监督和防止有碰撞风险的动作）。

Result: 在物理引擎上的仿真结果表明，该算法在碰撞避免方面优于基准算法，获得了更高的峰值奖励、更少的训练时间，以及在多种测试交通流场景下在风险区域停留时间更短。

Conclusion: 所提出的改进PPO算法有效提升了自动驾驶的安全性和训练效率，为解决PPO在自动驾驶应用中的挑战提供了有效的解决方案。

Abstract: Autonomous driving has attracted great interest due to its potential
capability in full-unsupervised driving. Model-based and learning-based methods
are widely used in autonomous driving. Model-based methods rely on pre-defined
models of the environment and may struggle with unforeseen events. Proximal
policy optimization (PPO), an advanced learning-based method, can adapt to the
above limits by learning from interactions with the environment. However,
existing PPO faces challenges with poor training results, and low training
efficiency in long sequences. Moreover, the poor training results are
equivalent to collisions in driving tasks. To solve these issues, this paper
develops an improved PPO by introducing the risk-aware mechanism, a
risk-attention decision network, a balanced reward function, and a
safety-assisted mechanism. The risk-aware mechanism focuses on highlighting
areas with potential collisions, facilitating safe-driving learning of the PPO.
The balanced reward function adjusts rewards based on the number of surrounding
vehicles, promoting efficient exploration of the control strategy during
training. Additionally, the risk-attention network enhances the PPO to hold
channel and spatial attention for the high-risk areas of input images.
Moreover, the safety-assisted mechanism supervises and prevents the actions
with risks of collisions during the lane keeping and lane changing. Simulation
results on a physical engine demonstrate that the proposed algorithm
outperforms benchmark algorithms in collision avoidance, achieving higher peak
reward with less training time, and shorter driving time remaining on the risky
areas among multiple testing traffic flow scenarios.

</details>


### [8] [Robust Docking Maneuvers for Autonomous Trolley Collection: An Optimization-Based Visual Servoing Scheme](https://arxiv.org/abs/2509.07413)
*Yuhan Pang,Bingyi Xia,Zhe Zhang,Zhirui Sun,Peijia Xie,Bike Zhu,Wenjun Xu,Jiankun Wang*

Main category: cs.RO

TL;DR: 基于视觉服务的优化方案，通过主动红外标记和干扰观测器实现高精度无人控小车对接


<details>
  <summary>Details</summary>
Motivation: 解决服务机器人在公共空间自主收集和重新分配手提小车时的对接挑战，包括高精度要求、环境干扰和机器人本身约束

Method: 采用优化基争视觉服务方案，结合主动红外标记进行突出特征提取，在混合视觉服务问题中显式建模非完整动力学和可见性约束，加入干扰观测器提高稳定性

Result: 在多样化环境中验证了系统的稳健性，定量评估确认了高对接精度

Conclusion: 该方案能够有效解决服务机器人对接手提小车的技术挑战，实现了高精度和稳定的自主对接功能

Abstract: Service robots have demonstrated significant potential for autonomous trolley
collection and redistribution in public spaces like airports or warehouses to
improve efficiency and reduce cost. Usually, a fully autonomous system for the
collection and transportation of multiple trolleys is based on a
Leader-Follower formation of mobile manipulators, where reliable docking
maneuvers of the mobile base are essential to align trolleys into organized
queues. However, developing a vision-based robotic docking system faces
significant challenges: high precision requirements, environmental
disturbances, and inherent robot constraints. To address these challenges, we
propose an optimization-based Visual Servoing scheme that incorporates active
infrared markers for robust feature extraction across diverse lighting
conditions. This framework explicitly models nonholonomic kinematics and
visibility constraints within the Hybrid Visual Servoing problem, augmented
with an observer for disturbance rejection to ensure precise and stable
docking. Experimental results across diverse environments demonstrate the
robustness of this system, with quantitative evaluations confirming high
docking accuracy.

</details>


### [9] [Timing the Message: Language-Based Notifications for Time-Critical Assistive Settings](https://arxiv.org/abs/2509.07438)
*Ya-Chuan Hsu,Jonathan DeCastro,Andrew Silva,Guy Rosman*

Main category: cs.RO

TL;DR: 这篇论文研究时间故感设备中语言指令的及时性与信息量的批扣，通过强化学习框架提高40%成功率


<details>
  <summary>Details</summary>
Motivation: 现有语言辅助系统过于关注内容生成而忽视了临界时间因素，如语言传达时长、人类理解延迟等，这在时间故感场景中导致延迟或意义模糊

Method: 使用增强状态马尔可夫决策过程建模，结合强化学习和生成的离线分类数据集，设计可扩展的分类数据生成流程

Result: 通过综合人类模拟评估，框架比忽视时间延迟的方法提高了超10%的成功率，同时有效平衡了及时性和信息量

Conclusion: 该研究曝露了语言辅助中及时性与信息量的重要批扣关系，为优化时间故感场景中的人工智能沟通开启了新方向

Abstract: In time-critical settings such as assistive driving, assistants often rely on
alerts or haptic signals to prompt rapid human attention, but these cues
usually leave humans to interpret situations and decide responses
independently, introducing potential delays or ambiguity in meaning.
Language-based assistive systems can instead provide instructions backed by
context, offering more informative guidance. However, current approaches (e.g.,
social assistive robots) largely prioritize content generation while
overlooking critical timing factors such as verbal conveyance duration, human
comprehension delays, and subsequent follow-through duration. These timing
considerations are crucial in time-critical settings, where even minor delays
can substantially affect outcomes. We aim to study this inherent trade-off
between timeliness and informativeness by framing the challenge as a sequential
decision-making problem using an augmented-state Markov Decision Process. We
design a framework combining reinforcement learning and a generated offline
taxonomy dataset, where we balance the trade-off while enabling a scalable
taxonomy dataset generation pipeline. Empirical evaluation with synthetic
humans shows our framework improves success rates by over 40% compared to
methods that ignore time delays, while effectively balancing timeliness and
informativeness. It also exposes an often-overlooked trade-off between these
two factors, opening new directions for optimizing communication in
time-critical human-AI assistance.

</details>


### [10] [Text2Touch: Tactile In-Hand Manipulation with LLM-Designed Reward Functions](https://arxiv.org/abs/2509.07445)
*Harrison Field,Max Yang,Yijiong Lin,Efi Psomopoulou,David Barton,Nathan F. Lepora*

Main category: cs.RO

TL;DR: Text2Touch利用大语言模型自动设计奖励函数，在具有触觉传感的多轴手内物体旋转任务中显著优于人工设计的基准，实现了更快的旋转速度和更好的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型奖励设计工作未考虑触觉传感，而触觉对于类人灵巧操作至关重要。

Method: 采用提示工程策略处理70多个环境变量，通过模拟到现实的蒸馏将策略迁移到具有触觉传感的四指灵巧机械手。

Result: Text2Touch显著优于人工设计的基准，旋转速度更快、稳定性更好，且奖励函数更简洁（短一个数量级）。

Conclusion: LLM设计的奖励函数可以显著缩短从概念到可部署灵巧触觉技能的时间，支持更快速和可扩展的多模态机器人学习。

Abstract: Large language models (LLMs) are beginning to automate reward design for
dexterous manipulation. However, no prior work has considered tactile sensing,
which is known to be critical for human-like dexterity. We present Text2Touch,
bringing LLM-crafted rewards to the challenging task of multi-axis in-hand
object rotation with real-world vision based tactile sensing in palm-up and
palm-down configurations. Our prompt engineering strategy scales to over 70
environment variables, and sim-to-real distillation enables successful policy
transfer to a tactile-enabled fully actuated four-fingered dexterous robot
hand. Text2Touch significantly outperforms a carefully tuned human-engineered
baseline, demonstrating superior rotation speed and stability while relying on
reward functions that are an order of magnitude shorter and simpler. These
results illustrate how LLM-designed rewards can significantly reduce the time
from concept to deployable dexterous tactile skills, supporting more rapid and
scalable multimodal robot learning. Project website:
https://hpfield.github.io/text2touch-website

</details>


### [11] [DepthVision: Robust Vision-Language Understanding through GAN-Based LiDAR-to-RGB Synthesis](https://arxiv.org/abs/2509.07463)
*Sven Kirchner,Nils Purschke,Ross Greer,Alois C. Knoll*

Main category: cs.RO

TL;DR: DepthVision是一个多模态场景理解框架，通过生成对抗网络从稀疏LiDAR点云合成RGB图像，并结合真实RGB数据，在光线不足条件下提升机器人视觉性能。


<details>
  <summary>Details</summary>
Motivation: 解决机器人视觉输入退化或不足时的可靠操作问题，特别是在低光照等恶劣条件下确保安全关键任务的性能。

Method: 使用条件生成对抗网络(cGAN)从LiDAR点云合成RGB图像，通过Luminance-Aware Modality Adaptation(LAMA)动态融合合成图像和真实RGB数据，无需微调下游视觉语言模型。

Result: 在真实和模拟数据集上的评估显示，DepthVision在低光照条件下显著优于仅使用RGB的基线方法，同时保持与冻结VLMs的兼容性。

Conclusion: LiDAR引导的RGB合成方法为实现现实环境中鲁棒的机器人操作提供了有前景的解决方案。

Abstract: Ensuring reliable robot operation when visual input is degraded or
insufficient remains a central challenge in robotics. This letter introduces
DepthVision, a framework for multimodal scene understanding designed to address
this problem. Unlike existing Vision-Language Models (VLMs), which use only
camera-based visual input alongside language, DepthVision synthesizes RGB
images from sparse LiDAR point clouds using a conditional generative
adversarial network (GAN) with an integrated refiner network. These synthetic
views are then combined with real RGB data using a Luminance-Aware Modality
Adaptation (LAMA), which blends the two types of data dynamically based on
ambient lighting conditions. This approach compensates for sensor degradation,
such as darkness or motion blur, without requiring any fine-tuning of
downstream vision-language models. We evaluate DepthVision on real and
simulated datasets across various models and tasks, with particular attention
to safety-critical tasks. The results demonstrate that our approach improves
performance in low-light conditions, achieving substantial gains over RGB-only
baselines while preserving compatibility with frozen VLMs. This work highlights
the potential of LiDAR-guided RGB synthesis for achieving robust robot
operation in real-world environments.

</details>


### [12] [Safe and Non-Conservative Contingency Planning for Autonomous Vehicles via Online Learning-Based Reachable Set Barriers](https://arxiv.org/abs/2509.07464)
*Rui Yang,Lei Zheng,Shuzhi Sam Ge,Jun Ma*

Main category: cs.RO

TL;DR: 提出实时应急轨迹优化框架，通过在线学习人类驾驶车辆控制意图集来量化不确定性，使用基于前向可达集的屏障约束确保安全，在保持安全的同时提高驾驶效率和舒适度。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆需要在动态不确定环境中平衡安全性和驾驶效率，但人类驾驶车辆的不可预测性和感知不准确性给规划带来挑战。过于保守的规划器会降低效率，而确定性方法在面对突发情况时可能失败。

Method: 采用事件触发的在线学习机制动态量化人类驾驶车辆的多模态不确定性，使用基于前向可达集的屏障约束确保安全不变性，通过共识ADMM算法高效求解应急轨迹优化问题。

Result: 在高速公路和城市场景的高保真仿真以及真实世界实验中，该方法在保持安全性的同时显著提高了驾驶效率和乘客舒适度。

Conclusion: 该框架能够持续适应人类驾驶车辆行为的不确定性，在不依赖过度保守策略的情况下保持可行性和安全性，为自动驾驶在不确定环境中的安全导航提供了有效解决方案。

Abstract: Autonomous vehicles must navigate dynamically uncertain environments while
balancing the safety and driving efficiency. This challenge is exacerbated by
the unpredictable nature of surrounding human-driven vehicles (HVs) and
perception inaccuracies, which require planners to adapt to evolving
uncertainties while maintaining safe trajectories. Overly conservative planners
degrade driving efficiency, while deterministic approaches may encounter
serious issues and risks of failure when faced with sudden and unexpected
maneuvers. To address these issues, we propose a real-time contingency
trajectory optimization framework in this paper. By employing event-triggered
online learning of HV control-intent sets, our method dynamically quantifies
multi-modal HV uncertainties and refines the forward reachable set (FRS)
incrementally. Crucially, we enforce invariant safety through FRS-based barrier
constraints that ensure safety without reliance on accurate trajectory
prediction of HVs. These constraints are embedded in contingency trajectory
optimization and solved efficiently through consensus alternative direction
method of multipliers (ADMM). The system continuously adapts to the
uncertainties in HV behaviors, preserving feasibility and safety without
resorting to excessive conservatism. High-fidelity simulations on highway and
urban scenarios, as well as a series of real-world experiments demonstrate
significant improvements in driving efficiency and passenger comfort while
maintaining safety under uncertainty. The project page is available at
https://pathetiue.github.io/frscp.github.io/.

</details>


### [13] [Flexible Morphing Aerial Robot with Inflatable Structure for Perching-based Human-Robot Interaction](https://arxiv.org/abs/2509.07496)
*Ayano Miyamichi,Moju Zhao,Kazuki Sugihara,Junichiro Sugihara,Masanori Konishi,Kunio Kojima,Kei Okada,Masayuki Inaba*

Main category: cs.RO

TL;DR: 这篇论文提出了一种可以在人体上栖息的变形航空机器人，通过混合变形结构和气动控制系统实现了飞行稳定性和栖息效果的平衡。


<details>
  <summary>Details</summary>
Motivation: 作者想解决可变形航空机器人在飞行稳定性和人机交互安全性方面的挑战，特别是实现在人体上安全栖息的能力。

Method: 采用混合变形结构，结合单侧灵活臂和气动能扩张器，在飞行时保持精确控制而在栖息时变得柔柔。同时开发了气动控制系统来优化压力调节、吸震和抓取力控制。

Result: 原型机成功展示了在人体上进行柔性栖息的可行性，甚至在飞行中受到推力减少导致臂部变形后仍能稳定恢复。

Conclusion: 这是首个能够在人体上栖息以支持人机交互的航空机器人，为可变形航空机器人的安全人机交互开启了新可能性。

Abstract: Birds in nature perform perching not only for rest but also for interaction
with human such as the relationship with falconers. Recently, researchers
achieve perching-capable aerial robots as a way to save energy, and deformable
structure demonstrate significant advantages in efficiency of perching and
compactness of configuration. However, ensuring flight stability remains
challenging for deformable aerial robots due to the difficulty of controlling
flexible arms. Furthermore, perching for human interaction requires high
compliance along with safety. Thus, this study aims to develop a deformable
aerial robot capable of perching on humans with high flexibility and grasping
ability. To overcome the challenges of stability of both flight and perching,
we propose a hybrid morphing structure that combines a unilateral flexible arm
and a pneumatic inflatable actuators. This design allows the robot's arms to
remain rigid during flight and soft while perching for more effective grasping.
We also develop a pneumatic control system that optimizes pressure regulation
while integrating shock absorption and adjustable grasping forces, enhancing
interaction capabilities and energy efficiency. Besides, we focus on the
structural characteristics of the unilateral flexible arm and identify
sufficient conditions under which standard quadrotor modeling and control
remain effective in terms of flight stability. Finally, the developed prototype
demonstrates the feasibility of compliant perching maneuvers on humans, as well
as the robust recovery even after arm deformation caused by thrust reductions
during flight. To the best of our knowledge, this work is the first to achieve
an aerial robot capable of perching on humans for interaction.

</details>


### [14] [OmniMap: A General Mapping Framework Integrating Optics, Geometry, and Semantics](https://arxiv.org/abs/2509.07500)
*Yinan Deng,Yufeng Yue,Jianyu Dou,Jingyu Zhao,Jiahui Wang,Yujie Tang,Yi Yang,Mengyin Fu*

Main category: cs.RO

TL;DR: OmniMap是首个能够同时捕获光学、几何和语义场景属性，并保持实时性能和模型紧凑性的在线建图框架。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只能部分满足机器人系统对环境感知的需求，存在光学模糊、几何不规则和语义模糊等问题。

Method: 采用紧密耦合的3DGS-Voxel混合表示，结合自适应相机建模、混合增量表示和概率融合等创新技术。

Result: 在渲染保真度、几何精度和零样本语义分割方面表现出色，优于现有最先进方法。

Conclusion: OmniMap框架具有多功能性，可应用于多领域场景问答、交互式编辑、感知引导操作和地图辅助导航等下游应用。

Abstract: Robotic systems demand accurate and comprehensive 3D environment perception,
requiring simultaneous capture of photo-realistic appearance (optical), precise
layout shape (geometric), and open-vocabulary scene understanding (semantic).
Existing methods typically achieve only partial fulfillment of these
requirements while exhibiting optical blurring, geometric irregularities, and
semantic ambiguities. To address these challenges, we propose OmniMap. Overall,
OmniMap represents the first online mapping framework that simultaneously
captures optical, geometric, and semantic scene attributes while maintaining
real-time performance and model compactness. At the architectural level,
OmniMap employs a tightly coupled 3DGS-Voxel hybrid representation that
combines fine-grained modeling with structural stability. At the implementation
level, OmniMap identifies key challenges across different modalities and
introduces several innovations: adaptive camera modeling for motion blur and
exposure compensation, hybrid incremental representation with normal
constraints, and probabilistic fusion for robust instance-level understanding.
Extensive experiments show OmniMap's superior performance in rendering
fidelity, geometric accuracy, and zero-shot semantic segmentation compared to
state-of-the-art methods across diverse scenes. The framework's versatility is
further evidenced through a variety of downstream applications, including
multi-domain scene Q&A, interactive editing, perception-guided manipulation,
and map-assisted navigation.

</details>


### [15] [Improving Machine Learning-Based Robot Self-Collision Checking with Input Positional Encoding](https://arxiv.org/abs/2509.07542)
*Bartlomiej Kulecki,Dominik Belter*

Main category: cs.RO

TL;DR: 将位置编码技术集成到自碰撞检测的二元分类模型中，提高了分类准确性，使模型能更好地捕捉高频变化，为复杂碰撞模式提供更精确的表示


<details>
  <summary>Details</summary>
Motivation: 探索位置编码技术在自碰撞检测中的应用，寻求比传统几何方法更快速的碰撞检测解决方案

Method: 使用轻量级多层感知器(MLP)在低维特征空间中操作，将位置编码技术集成到二元分类模型的输入向量中

Result: 集成位置编码显著提高了分类准确性，模型能够更好地捕捉高频变化，提供更详细和精确的复杂碰撞模式表示

Conclusion: 基于机器学习的轻量级MLP方法在自碰撞检测中比传统的几何方法（如三角形相交测试和BVH）更快速有效

Abstract: This manuscript investigates the integration of positional encoding -- a
technique widely used in computer graphics -- into the input vector of a binary
classification model for self-collision detection. The results demonstrate the
benefits of incorporating positional encoding, which enhances classification
accuracy by enabling the model to better capture high-frequency variations,
leading to a more detailed and precise representation of complex collision
patterns. The manuscript shows that machine learning-based techniques, such as
lightweight multilayer perceptrons (MLPs) operating in a low-dimensional
feature space, offer a faster alternative for collision checking than
traditional methods that rely on geometric approaches, such as
triangle-to-triangle intersection tests and Bounding Volume Hierarchies (BVH)
for mesh-based models.

</details>


### [16] [Can SSD-Mamba2 Unlock Reinforcement Learning for End-to-End Motion Control?](https://arxiv.org/abs/2509.07593)
*Gavin Tao,Yinuo Wang,Jinzhao Zhou*

Main category: cs.RO

TL;DR: 提出了基于SSD-Mamba2的视觉驱动跨模态强化学习框架，用于端到端运动控制，在计算效率和性能方面超越现有方法


<details>
  <summary>Details</summary>
Motivation: 现有端到端运动控制方法存在计算内存权衡不佳、长时程信用分配困难、Transformer二次计算成本高等问题，需要更高效的融合架构

Method: 使用SSD-Mamba2选择性状态空间骨干网络，支持循环和卷积扫描，将本体感知和外部感知编码为紧凑token进行融合，采用课程学习和状态中心奖励函数

Result: 在多样化运动控制场景中，在回报率、安全性、样本效率方面超越强基线方法，收敛更快且计算成本相同

Conclusion: SSD-Mamba2为可扩展、有前瞻性且高效的端到端运动控制提供了实用的融合骨干网络

Abstract: End-to-end reinforcement learning for motion control promises unified
perception-action policies that scale across embodiments and tasks, yet most
deployed controllers are either blind (proprioception-only) or rely on fusion
backbones with unfavorable compute-memory trade-offs. Recurrent controllers
struggle with long-horizon credit assignment, and Transformer-based fusion
incurs quadratic cost in token length, limiting temporal and spatial context.
We present a vision-driven cross-modal RL framework built on SSD-Mamba2, a
selective state-space backbone that applies state-space duality (SSD) to enable
both recurrent and convolutional scanning with hardware-aware streaming and
near-linear scaling. Proprioceptive states and exteroceptive observations
(e.g., depth tokens) are encoded into compact tokens and fused by stacked
SSD-Mamba2 layers. The selective state-space updates retain long-range
dependencies with markedly lower latency and memory use than quadratic
self-attention, enabling longer look-ahead, higher token resolution, and stable
training under limited compute. Policies are trained end-to-end under curricula
that randomize terrain and appearance and progressively increase scene
complexity. A compact, state-centric reward balances task progress, energy
efficiency, and safety. Across diverse motion-control scenarios, our approach
consistently surpasses strong state-of-the-art baselines in return, safety
(collisions and falls), and sample efficiency, while converging faster at the
same compute budget. These results suggest that SSD-Mamba2 provides a practical
fusion backbone for scalable, foresightful, and efficient end-to-end motion
control.

</details>


### [17] [Decoding RobKiNet: Insights into Efficient Training of Robotic Kinematics Informed Neural Network](https://arxiv.org/abs/2509.07646)
*Yanlong Peng,Zhigang Wang,Ziwen He,Pengxu Chang,Chuangchuang Zhou,Yu Yan,Ming Chen*

Main category: cs.RO

TL;DR: RobKiNet是一种基于运动学知识的神经网络方法，用于机器人在多约束配置空间中进行高效采样，相比传统方法和深度强化学习，训练速度提升74.29倍，采样精度达99.25%，任务完成率97.33%。


<details>
  <summary>Details</summary>
Motivation: 传统机器人任务与运动规划(TAMP)中，在多级约束下进行关节配置空间采样效率低下，需要一种更高效的方法来满足任务级全局约束并提升后续运动规划效率。

Method: 提出RobKiNet运动学信息神经网络，采用端到端方式在连续可行集(CFS)中进行多约束配置空间采样，建立优化期望模型，通过运动学知识注入确保稳定准确的梯度优化。

Result: 在2-DOF空间中验证理论效率，在9-DOF自主移动机械臂上展示优越的全身和解耦控制能力，电池拆卸任务中训练速度比深度强化学习快74.29倍，采样精度99.25%，实际场景任务完成率97.33%。

Conclusion: RobKiNet通过运动学知识注入显著提升了训练效率和采样精度，在多约束配置空间采样方面表现出色，为机器人任务与运动规划提供了高效的解决方案。

Abstract: In robots task and motion planning (TAMP), it is crucial to sample within the
robot's configuration space to meet task-level global constraints and enhance
the efficiency of subsequent motion planning. Due to the complexity of joint
configuration sampling under multi-level constraints, traditional methods often
lack efficiency. This paper introduces the principle of RobKiNet, a
kinematics-informed neural network, for end-to-end sampling within the
Continuous Feasible Set (CFS) under multiple constraints in configuration
space, establishing its Optimization Expectation Model. Comparisons with
traditional sampling and learning-based approaches reveal that RobKiNet's
kinematic knowledge infusion enhances training efficiency by ensuring stable
and accurate gradient optimization.Visualizations and quantitative analyses in
a 2-DOF space validate its theoretical efficiency, while its application on a
9-DOF autonomous mobile manipulator robot(AMMR) demonstrates superior
whole-body and decoupled control, excelling in battery disassembly tasks.
RobKiNet outperforms deep reinforcement learning with a training speed 74.29
times faster and a sampling accuracy of up to 99.25%, achieving a 97.33% task
completion rate in real-world scenarios.

</details>


### [18] [Collaborative Exploration with a Marsupial Ground-Aerial Robot Team through Task-Driven Map Compression](https://arxiv.org/abs/2509.07655)
*Angelos Zacharia,Mihir Dharmadhikari,Kostas Alexis*

Main category: cs.RO

TL;DR: 提出了一种地面-空中机器人协作探索框架，利用图基路径规划和带宽高效的地图压缩策略，在有限通信条件下实现高效环境探索。


<details>
  <summary>Details</summary>
Motivation: 解决自主机器人在有限通信的密闭大规模环境中高效探索的挑战，利用地面和空中平台的互补能力。

Method: 采用图基路径规划算法指导探索，在预期收益显著高于地面机器人的区域部署空中机器人；引入带宽高效的任务驱动地图压缩策略，选择性压缩和共享关键数据。

Result: 仿真和真实实验验证了该方法的有效性，在显著减少数据传输的同时提高了探索效率。

Conclusion: 所提出的协作探索框架能够有效利用异构机器人团队的互补能力，在有限通信条件下实现高效的环境探索。

Abstract: Efficient exploration of unknown environments is crucial for autonomous
robots, especially in confined and large-scale scenarios with limited
communication. To address this challenge, we propose a collaborative
exploration framework for a marsupial ground-aerial robot team that leverages
the complementary capabilities of both platforms. The framework employs a
graph-based path planning algorithm to guide exploration and deploy the aerial
robot in areas where its expected gain significantly exceeds that of the ground
robot, such as large open spaces or regions inaccessible to the ground
platform, thereby maximizing coverage and efficiency. To facilitate large-scale
spatial information sharing, we introduce a bandwidth-efficient, task-driven
map compression strategy. This method enables each robot to reconstruct
resolution-specific volumetric maps while preserving exploration-critical
details, even at high compression rates. By selectively compressing and sharing
key data, communication overhead is minimized, ensuring effective map
integration for collaborative path planning. Simulation and real-world
experiments validate the proposed approach, demonstrating its effectiveness in
improving exploration efficiency while significantly reducing data
transmission.

</details>


### [19] [Temporal Counterfactual Explanations of Behaviour Tree Decisions](https://arxiv.org/abs/2509.07674)
*Tamlin Love,Antonio Andriella,Guillem Alenyà*

Main category: cs.RO

TL;DR: 本文提出了一种自动生成行为树驱动系统的反事实解释方法，用于回答对汽人决策行为的"为什么"问题


<details>
  <summary>Details</summary>
Motivation: 行为树是汽人决策控制的流行框架，但现有方法无法生成因果性的反事实解释，影响系统的透明性和可信赖性

Method: 自动从行为树结构和域知识构建因果模型，然后查询和搜索该模型以找到多样化的反事实解释

Result: 方法能够正确解释广泛行为树结构和状态的行为，能够回答多种因果查询

Conclusion: 该方法向更透明、可理解和可信赖的汽人系统进行了重要一步

Abstract: Explainability is a critical tool in helping stakeholders understand robots.
In particular, the ability for robots to explain why they have made a
particular decision or behaved in a certain way is useful in this regard.
Behaviour trees are a popular framework for controlling the decision-making of
robots and other software systems, and thus a natural question to ask is
whether or not a system driven by a behaviour tree is capable of answering
"why" questions. While explainability for behaviour trees has seen some prior
attention, no existing methods are capable of generating causal, counterfactual
explanations which detail the reasons for robot decisions and behaviour.
Therefore, in this work, we introduce a novel approach which automatically
generates counterfactual explanations in response to contrastive "why"
questions. Our method achieves this by first automatically building a causal
model from the structure of the behaviour tree as well as domain knowledge
about the state and individual behaviour tree nodes. The resultant causal model
is then queried and searched to find a set of diverse counterfactual
explanations. We demonstrate that our approach is able to correctly explain the
behaviour of a wide range of behaviour tree structures and states. By being
able to answer a wide range of causal queries, our approach represents a step
towards more transparent, understandable and ultimately trustworthy robotic
systems.

</details>


### [20] [Robust Radar SLAM for Vehicle Parking Applications](https://arxiv.org/abs/2509.07683)
*Luis Diener,Jens Kalkkuhl,Markus Enzweiler*

Main category: cs.RO

TL;DR: 隨軌雷達SLAM方案，通過多普勒速度增强和多雷達融合，实现自動停車场景下的公分级高精度定位


<details>
  <summary>Details</summary>
Motivation: 解决自動停車场景下对公分级高精度定位的需求，免去传统IMU和轮子编码器方案的检定成本

Method: 提出以雷達为核心的隨軌定位与地图构建(SLAM)方法，融合特征点位置和多普勒速度，支持多雷達融合和基于信息的特征剪枝策略

Result: 实验结果显示该方法能够实现高精度定位，在急剧变化和恶劣天气条件下供更好的稳健性，超越现有最优方法

Conclusion: 雷達基SLAM方案能够满足自動停車对公分级高精度定位的要求，具有良好的应用前景

Abstract: We address ego-motion estimation for automated parking, where
centimeter-level accuracy is crucial due to tight spaces and nearby obstacles.
Traditional methods using inertial-measurement units and wheel encoders require
calibration, making them costly and time-consuming. To overcome this, we
propose a radar-based simultaneous localization and mapping (SLAM) approach
that leverages the robustness of radar to adverse weather and support for
online calibration. Our robocentric formulation fuses feature positions and
Doppler velocities for robust data association and filter convergence. Key
contributions include a Doppler-augmented radar SLAM method, multi-radar
support and an information-based feature-pruning strategy. Experiments
demonstrate high-accuracy localization and improved robustness over
state-of-the-art methods, meeting the demands of automated parking.

</details>


### [21] [Fault Tolerant Control of a Quadcopter using Reinforcement Learning](https://arxiv.org/abs/2509.07707)
*Muzaffar Habib,Adnan Maqsood,Adnan Fayyaz ud Din*

Main category: cs.RO

TL;DR: 提出了基于强化学习的四旋翼控制框架，专注于单螺旋桨故障时的安全性和鲁棒性，比较了动态规划和DDPG两种方法。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼在飞行中发生螺旋桨故障时需要鲁棒控制策略来维持期望高度，保护硬件和有效载荷的关键需求。

Method: 研究两种强化学习方法：动态规划（DP，基于模型）和深度确定性策略梯度（DDPG，无模型），并对算法进行修改以适应大维度连续状态和动作域。

Result: 通过MATLAB环境下的广泛仿真验证了控制框架的鲁棒性，在不同初始条件下都能在螺旋桨故障后达到期望状态。

Conclusion: 该控制框架在任务关键型四旋翼应用中具有可行性，两种RL算法在故障航空系统中都有应用潜力。

Abstract: This study presents a novel reinforcement learning (RL)-based control
framework aimed at enhancing the safety and robustness of the quadcopter, with
a specific focus on resilience to in-flight one propeller failure. Addressing
the critical need of a robust control strategy for maintaining a desired
altitude for the quadcopter to safe the hardware and the payload in physical
applications. The proposed framework investigates two RL methodologies Dynamic
Programming (DP) and Deep Deterministic Policy Gradient (DDPG), to overcome the
challenges posed by the rotor failure mechanism of the quadcopter. DP, a
model-based approach, is leveraged for its convergence guarantees, despite high
computational demands, whereas DDPG, a model-free technique, facilitates rapid
computation but with constraints on solution duration. The research challenge
arises from training RL algorithms on large dimensions and action domains. With
modifications to the existing DP and DDPG algorithms, the controllers were
trained not only to cater for large continuous state and action domain and also
achieve a desired state after an inflight propeller failure. To verify the
robustness of the proposed control framework, extensive simulations were
conducted in a MATLAB environment across various initial conditions and
underscoring its viability for mission-critical quadcopter applications. A
comparative analysis was performed between both RL algorithms and their
potential for applications in faulty aerial systems.

</details>


### [22] [Unlocking Stopped-Rotor Flight: Development and Validation of SPERO, a Novel UAV Platform](https://arxiv.org/abs/2509.07812)
*Kristan Hilby,Ian Hunter*

Main category: cs.RO

TL;DR: SPERO是一种创新的停止旋翼无人机，通过翻转锁定机翼、压力中心调节机制、推力矢量平衡等创新设计，首次实现了垂直起降和向前飞行的稳定双向转换


<details>
  <summary>Details</summary>
Motivation: 停止旋翼飞机长期以来被认为是垂直起降和向前飞行时间相当的理想飞行器，但由于气动和稳定性冲突，实际应用一直不可行

Method: 采用翻转锁定机翼、主动压力中心机制、推力矢量平衡、五旋翼架构和十一状态机飞行控制器，协调几何和控制重构

Result: 克服了停止旋翼飞行的长期挑战，实现了首个稳定的VTOL和向前飞行的双向转换

Conclusion: SPERO为停止旋翼无人机建立了可推广的设计和控制框架，解决了该领域的关键技术难题

Abstract: Stop-rotor aircraft have long been proposed as the ideal vertical takeoff and
landing (VTOL) aircraft for missions with equal time spent in both flight
regimes, such as agricultural monitoring, search and rescue, and last-mile
delivery. Featuring a central lifting surface that rotates in VTOL to generate
vertical thrust and locks in forward flight to generate passive lift, the
stop-rotor offers the potential for high efficiency across both modes. However,
practical implementation has remained infeasible due to aerodynamic and
stability conflicts between flight modes. In this work, we present SPERO
(Stopped-Penta Rotor), a stop-rotor uncrewed aerial vehicle (UAV) featuring a
flipping and latching wing, an active center of pressure mechanism, thrust
vectored counterbalances, a five-rotor architecture, and an eleven-state
machine flight controller coordinating geometric and controller
reconfiguration. Furthermore, SPERO establishes a generalizable design and
control framework for stopped-rotor UAVs. Together, these innovations overcome
longstanding challenges in stop-rotor flight and enable the first stable,
bidirectional transition between VTOL and forward flight.

</details>


### [23] [Programmable Locking Cells (PLC) for Modular Robots with High Stiffness Tunability and Morphological Adaptability](https://arxiv.org/abs/2509.07916)
*Jianshu Zhou,Wei Chen,Junda Huang,Boyuan Liang,Yunhui Liu,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 程序化锁定单元(PLC)是一种模块化的腹纳驱动机制，通过机械互锁关节实现离散精度调节，在不需持续输入力的情况下实现从柔性到硬性的状态转换，并展现出高达950%的刚度变化。


<details>
  <summary>Details</summary>
Motivation: 现有的变刚度解决方案存在依赖复杂驱动方案、持续输入力或单体设计等问题，限制了模块化和可扩展性。需要一种能够在非结构化环境中在柔性和硬性状态之间切换的机器人系统。

Method: 设计了程序化锁定单元(PLC)，通过腹纳驱动和机械互锁关节实现离散刚度调节。每个单元通过结构响应在柔性和硬性状态之间转换，多个PLC单元可组装成可重配置的机器人结构。

Result: 验证了两个功能原型：(1)变刚度抓手，能够适应性抓取、硬性持有和手内操作；(2)管道遍历机器人，在封闭环境中实现形状适应性和刚度控制。每个单元展现高达950%的刚度变化，且在高负荷硬性状态下不易受损坏。

Conclusion: PLC作为一种可扩展的、以结构为中心的机制，为程序化刚度和运动提供了解决方案，使得机器人系统能够实现可重配置形态和任务适应性交互。

Abstract: Robotic systems operating in unstructured environments require the ability to
switch between compliant and rigid states to perform diverse tasks such as
adaptive grasping, high-force manipulation, shape holding, and navigation in
constrained spaces, among others. However, many existing variable stiffness
solutions rely on complex actuation schemes, continuous input power, or
monolithic designs, limiting their modularity and scalability. This paper
presents the Programmable Locking Cell (PLC)-a modular, tendon-driven unit that
achieves discrete stiffness modulation through mechanically interlocked joints
actuated by cable tension. Each unit transitions between compliant and firm
states via structural engagement, and the assembled system exhibits high
stiffness variation-up to 950% per unit-without susceptibility to damage under
high payload in the firm state. Multiple PLC units can be assembled into
reconfigurable robotic structures with spatially programmable stiffness. We
validate the design through two functional prototypes: (1) a variable-stiffness
gripper capable of adaptive grasping, firm holding, and in-hand manipulation;
and (2) a pipe-traversing robot composed of serial PLC units that achieves
shape adaptability and stiffness control in confined environments. These
results demonstrate the PLC as a scalable, structure-centric mechanism for
programmable stiffness and motion, enabling robotic systems with reconfigurable
morphology and task-adaptive interaction.

</details>


### [24] [RaC: Robot Learning for Long-Horizon Tasks by Scaling Recovery and Correction](https://arxiv.org/abs/2509.07953)
*Zheyuan Hu,Robyn Wu,Naveen Enock,Jasmine Li,Riya Kadakia,Zackory Erickson,Aviral Kumar*

Main category: cs.RO

TL;DR: RaC是一种在模仿学习预训练后增加人类干预回放训练阶段的新方法，通过人类纠正行为来提升机器人策略的恢复和适应能力，显著减少数据收集需求并提高长时程任务的性能


<details>
  <summary>Details</summary>
Motivation: 现有基于人类遥操作的专家数据收集方法效率低下，导致接触丰富、可变形物体和长时程任务的性能远低于完美执行水平，即使使用数千条专家演示

Method: 在模仿学习预训练后，引入人类干预回放训练阶段。人类操作员在策略执行即将失败时进行干预，首先将机器人回退到熟悉的分布内状态，然后提供完成当前子任务的纠正片段

Result: 在三个真实世界双手机器人控制任务（衬衫悬挂、密封容器盖、外卖盒打包）和一个模拟装配任务中，RaC使用10倍少的数据收集时间和样本就超越了先前最先进方法

Conclusion: RaC通过训练恢复和纠正行为扩展了机器人技能库，显著提升了长时程任务的效率和鲁棒性，且训练后的RaC策略性能随恢复操作次数线性扩展

Abstract: Modern paradigms for robot imitation train expressive policy architectures on
large amounts of human demonstration data. Yet performance on contact-rich,
deformable-object, and long-horizon tasks plateau far below perfect execution,
even with thousands of expert demonstrations. This is due to the inefficiency
of existing ``expert'' data collection procedures based on human teleoperation.
To address this issue, we introduce RaC, a new phase of training on
human-in-the-loop rollouts after imitation learning pre-training. In RaC, we
fine-tune a robotic policy on human intervention trajectories that illustrate
recovery and correction behaviors. Specifically, during a policy rollout, human
operators intervene when failure appears imminent, first rewinding the robot
back to a familiar, in-distribution state and then providing a corrective
segment that completes the current sub-task. Training on this data composition
expands the robotic skill repertoire to include retry and adaptation behaviors,
which we show are crucial for boosting both efficiency and robustness on
long-horizon tasks. Across three real-world bimanual control tasks: shirt
hanging, airtight container lid sealing, takeout box packing, and a simulated
assembly task, RaC outperforms the prior state-of-the-art using 10$\times$ less
data collection time and samples. We also show that RaC enables test-time
scaling: the performance of the trained RaC policy scales linearly in the
number of recovery maneuvers it exhibits. Videos of the learned policy are
available at https://rac-scaling-robot.github.io/.

</details>


### [25] [Graph-Fused Vision-Language-Action for Policy Reasoning in Multi-Arm Robotic Manipulation](https://arxiv.org/abs/2509.07957)
*Shunlei Li,Longsen Gao,Jiuwen Cao,Yingbai Hu*

Main category: cs.RO

TL;DR: GF-VLA是一个从人类视频演示中学习双手机器人技能的框架，通过信息论方法提取任务相关线索，构建时序场景图，结合语言条件变换器生成行为树和运动基元，在双手机器人装配任务中取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于轨迹复制的方法在泛化到不同物体、空间布局和机械臂配置时存在局限，需要能够进行任务级推理和执行的新方法。

Method: 采用信息论方法提取关键的手-物体和物体-物体交互线索，构建时序场景图，结合语言条件变换器生成层次行为树和可解释的笛卡尔运动基元，并提出跨臂分配策略。

Result: 在四个双手机器人积木装配基准测试中，图准确率超过95%，子任务分割准确率93%，抓取可靠性94%，放置精度89%，整体任务成功率90%。

Conclusion: GF-VLA框架能够从RGB-D人类演示中实现任务级推理和执行，表现出强大的泛化能力和鲁棒性，适用于多样化的空间和语义变化场景。

Abstract: Acquiring dexterous robotic skills from human video demonstrations remains a
significant challenge, largely due to conventional reliance on low-level
trajectory replication, which often fails to generalize across varying objects,
spatial layouts, and manipulator configurations. To address this limitation, we
introduce Graph-Fused Vision-Language-Action (GF-VLA), a unified framework that
enables dual-arm robotic systems to perform task-level reasoning and execution
directly from RGB-D human demonstrations. GF-VLA employs an
information-theoretic approach to extract task-relevant cues, selectively
highlighting critical hand-object and object-object interactions. These cues
are structured into temporally ordered scene graphs, which are subsequently
integrated with a language-conditioned transformer to produce hierarchical
behavior trees and interpretable Cartesian motion primitives. To enhance
efficiency in bimanual execution, we propose a cross-arm allocation strategy
that autonomously determines gripper assignment without requiring explicit
geometric modeling. We validate GF-VLA on four dual-arm block assembly
benchmarks involving symbolic structure construction and spatial
generalization. Empirical results demonstrate that the proposed representation
achieves over 95% graph accuracy and 93% subtask segmentation, enabling the
language-action planner to generate robust, interpretable task policies. When
deployed on a dual-arm robot, these policies attain 94% grasp reliability, 89%
placement accuracy, and 90% overall task success across stacking,
letter-formation, and geometric reconfiguration tasks, evidencing strong
generalization and robustness under diverse spatial and semantic variations.

</details>


### [26] [TA-VLA: Elucidating the Design Space of Torque-aware Vision-Language-Action Models](https://arxiv.org/abs/2509.07962)
*Zongzheng Zhang,Haobo Xu,Zhuo Yang,Chenghao Yue,Zehao Lin,Huan-ang Gao,Ziwei Wang,Hao Zhao*

Main category: cs.RO

TL;DR: 该论文提出了扭矩感知的视觉-语言-动作模型，通过系统研究扭矩信号集成策略，发现解码器引入扭矩适配器优于编码器，并提出预测扭矩作为辅助输出以提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型缺乏整合力反馈信号的能力，而许多机器人操作任务需要感知和响应扭矩等力信号来评估任务完成情况和实现闭环控制。

Method: 系统研究扭矩信号集成到现有VLA架构的设计空间，评估多种策略，包括在编码器和解码器中引入扭矩适配器，并提出预测扭矩作为辅助输出的方法。

Result: 实验表明在解码器引入扭矩适配器性能更优；预测扭矩作为辅助输出能进一步提升性能，帮助模型建立物理交互动态的内部表征。

Conclusion: 通过定量和定性实验验证了所提方法的有效性，为扭矩感知VLA模型的发展提供了重要见解。

Abstract: Many robotic manipulation tasks require sensing and responding to force
signals such as torque to assess whether the task has been successfully
completed and to enable closed-loop control. However, current
Vision-Language-Action (VLA) models lack the ability to integrate such subtle
physical feedback. In this work, we explore Torque-aware VLA models, aiming to
bridge this gap by systematically studying the design space for incorporating
torque signals into existing VLA architectures. We identify and evaluate
several strategies, leading to three key findings. First, introducing torque
adapters into the decoder consistently outperforms inserting them into the
encoder.Third, inspired by joint prediction and planning paradigms in
autonomous driving, we propose predicting torque as an auxiliary output, which
further improves performance. This strategy encourages the model to build a
physically grounded internal representation of interaction dynamics. Extensive
quantitative and qualitative experiments across contact-rich manipulation
benchmarks validate our findings.

</details>
