<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 50]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [An integrated process for design and control of lunar robotics using AI and simulation](https://arxiv.org/abs/2509.12367)
*Daniel Lindmark,Jonas Andersson,Kenneth Bodin,Tora Bodin,Hugo Börjesson,Fredrik Nordfeldth,Martin Servin*

Main category: cs.RO

TL;DR: 开发了一个集成技术框架OpenPLX，用于并行设计月球建造设备的物理结构和控制系统，通过高保真实时3D模拟来连接CAD模型和自主系统


<details>
  <summary>Details</summary>
Motivation: 需要开发一个集成流程，使月球建造设备的物理设计和控制能够并行探索，提高开发效率

Method: 基于OpenPLX声明式语言，连接CAD模型和自主系统到高保真实时3D模拟，包括多体动力学、机器-月壤相互作用力和非理想传感器

Result: 通过两个案例研究展示了框架能力，包括结合视觉语言模型导航和强化学习控制策略的自主月球车

Conclusion: 该技术框架支持月球建造设备的集成开发过程，实现了物理设计和控制的并行探索

Abstract: We envision an integrated process for developing lunar construction
equipment, where physical design and control are explored in parallel. In this
paper, we describe a technical framework that supports this process. It relies
on OpenPLX, a readable/writable declarative language that links CAD-models and
autonomous systems to high-fidelity, real-time 3D simulations of contacting
multibody dynamics, machine regolith interaction forces, and non-ideal sensors.
To demonstrate its capabilities, we present two case studies, including an
autonomous lunar rover that combines a vision-language model for navigation
with a reinforcement learning-based control policy for locomotion.

</details>


### [2] [Geometric Red-Teaming for Robotic Manipulation](https://arxiv.org/abs/2509.12379)
*Divyam Goel,Yufei Wang,Tiancheng Wu,Guixiu Qiao,Pavel Piliptchak,David Held,Zackory Erickson*

Main category: cs.RO

TL;DR: 提出了几何红队测试(GRT)框架，通过对象中心几何扰动自动生成导致预训练操作策略灾难性失败的CrashShapes，并展示了蓝队微调可显著恢复性能


<details>
  <summary>Details</summary>
Motivation: 标准机器人操作评估协议仅评估在分布内测试集上的性能，无法揭示系统在合理变化下的失败模式，需要更全面的鲁棒性评估方法

Method: 结合基于雅可比场的变形模型和无梯度、模拟器在环的优化策略，自动生成结构有效的网格变形，通过任务级策略展开和约束感知形状探索进行鲁棒性评估

Result: 在插入、关节操作和抓取任务中，GRT始终发现导致策略性能崩溃的变形，揭示了静态基准测试遗漏的脆弱失败模式。蓝队微调可将任务成功率提高多达60个百分点

Conclusion: GRT提供了一个通用的对象中心鲁棒性评估框架，红队测试发现的几何形状可用于针对性策略优化，实验验证了模拟结果与真实机器人结果的高度一致性

Abstract: Standard evaluation protocols in robotic manipulation typically assess policy
performance over curated, in-distribution test sets, offering limited insight
into how systems fail under plausible variation. We introduce Geometric
Red-Teaming (GRT), a red-teaming framework that probes robustness through
object-centric geometric perturbations, automatically generating CrashShapes --
structurally valid, user-constrained mesh deformations that trigger
catastrophic failures in pre-trained manipulation policies. The method
integrates a Jacobian field-based deformation model with a gradient-free,
simulator-in-the-loop optimization strategy. Across insertion, articulation,
and grasping tasks, GRT consistently discovers deformations that collapse
policy performance, revealing brittle failure modes missed by static
benchmarks. By combining task-level policy rollouts with constraint-aware shape
exploration, we aim to build a general purpose framework for structured,
object-centric robustness evaluation in robotic manipulation. We additionally
show that fine-tuning on individual CrashShapes, a process we refer to as
blue-teaming, improves task success by up to 60 percentage points on those
shapes, while preserving performance on the original object, demonstrating the
utility of red-teamed geometries for targeted policy refinement. Finally, we
validate both red-teaming and blue-teaming results with a real robotic arm,
observing that simulated CrashShapes reduce task success from 90% to as low as
22.5%, and that blue-teaming recovers performance to up to 90% on the
corresponding real-world geometry -- closely matching simulation outcomes.
Videos and code can be found on our project website:
https://georedteam.github.io/ .

</details>


### [3] [Distributed Event-Triggered Distance-Based Formation Control for Multi-Agent Systems](https://arxiv.org/abs/2509.12390)
*Evangelos Psomiadis,Panagiotis Tsiotras*

Main category: cs.RO

TL;DR: 提出分布式事件触发编队控制器，通过距离测量仅在误差超阈值时更新控制，显著减少控制开销同时保持编队性能


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统在有限资源下的协同编队控制问题，减少不必要的控制更新以节省资源

Method: 基于智能体间距离测量的分布式事件触发控制器，控制更新仅在测量误差超过预定阈值时触发

Result: 通过大量仿真和真实实验验证，事件触发方法显著减少控制工作量，同时保持编队性能

Conclusion: 事件触发策略相比周期性触发策略能有效降低控制开销，是资源受限多智能体系统的有效解决方案

Abstract: This paper addresses the problem of collaborative formation control for
multi-agent systems with limited resources. We consider a team of robots tasked
with achieving a desired formation from arbitrary initial configurations. To
reduce unnecessary control updates and conserve resources, we propose a
distributed event-triggered formation controller that relies on inter-agent
distance measurements. Control updates are triggered only when the measurement
error exceeds a predefined threshold, ensuring system stability. The proposed
controller is validated through extensive simulations and real-world
experiments involving different formations, communication topologies,
scalability tests, and variations in design parameters, while also being
compared against periodic triggering strategies. Results demonstrate that the
event-triggered approach significantly reduces control efforts while preserving
formation performance.

</details>


### [4] [MinJointTracker: Real-time inertial kinematic chain tracking with joint position estimation and minimal state size](https://arxiv.org/abs/2509.12398)
*Michael Lorenz,Bertram Taetz,Gabriele Bleser-Taetz,Didier Stricker*

Main category: cs.RO

TL;DR: 无需检定的惯性动作截获算法，能够在不需外部检定的情况下实时估计关节位置和角向动力学。


<details>
  <summary>Details</summary>
Motivation: 解决传统惯性动作截获方法需要外部检定的麻烦过程，如段长度、IMU到分段坐标系对齐等。

Method: 提出了一种实时能力的无检定惯性轨迹跟踪算法，通过递归贝叶斯估计全局IMU角向动力学和IMU帧中的关节位置。

Result: 在三链条机械手和人体下半身步行数据上的实验结果显示，该算法能够提供无偏移的相对和绝对方向估计，以及稳健快速收敛的关节位置估计。

Conclusion: 该无检定轻量级算法为惯性动作截获提供了一种便捷的解决方案，在各种运动场景下都表现出良好的性能。

Abstract: Inertial motion capture is a promising approach for capturing motion outside
the laboratory. However, as one major drawback, most of the current methods
require different quantities to be calibrated or computed offline as part of
the setup process, such as segment lengths, relative orientations between
inertial measurement units (IMUs) and segment coordinate frames (IMU-to-segment
calibrations) or the joint positions in the IMU frames. This renders the setup
process inconvenient. This work contributes to real-time capable
calibration-free inertial tracking of a kinematic chain, i.e. simultaneous
recursive Bayesian estimation of global IMU angular kinematics and joint
positions in the IMU frames, with a minimal state size. Experimental results on
simulated IMU data from a three-link kinematic chain (manipulator study) as
well as re-simulated IMU data from healthy humans walking (lower body study)
show that the calibration-free and lightweight algorithm provides not only
drift-free relative but also drift-free absolute orientation estimates with a
global heading reference for only one IMU as well as robust and fast
convergence of joint position estimates in the different movement scenarios.

</details>


### [5] [Computing forward statics from tendon-length in flexible-joint hyper-redundant manipulators](https://arxiv.org/abs/2509.12444)
*Weiting Feng,Kyle L. Walker,Yunjie Yang,Francesco Giorgio-Serchi*

Main category: cs.RO

TL;DR: 这篇论文提出了一种新的线综驱动超冗余操纵器前向静力学解决方法，能够同时利用线综张力和长度作为输入，实现仅使用动力学输入的开环控制。


<details>
  <summary>Details</summary>
Motivation: 传统的线综驱动操纵器控制方法需要准确的张力测量或状态估计，而这在大规格受重力影响的系统中很难实现。需要一种能够避免这些实际问题的控制方法。

Method: 开发了基于螺旋理论的形式化方法，针对弹性关节的多节超冗余线综驱动操纵器，提出了一种前向静力学迭代解决方法，能够等效地使用线综长度或张力作为输入。

Result: 通过实验验证，首先使用传统的张力输入方法，然后证明了仅使用线综长度作为输入的方法的有效性。

Conclusion: 这种方法确认了仅使用动力学输入在静态条件下实现开环控制的可能性，可以避免线综张力测量和状态估计的实际问题，为超冗余系统提供了更简单可靠的控制方案。

Abstract: Hyper-redundant tendon-driven manipulators offer greater flexibility and
compliance over traditional manipulators. A common way of controlling such
manipulators relies on adjusting tendon lengths, which is an accessible control
parameter. This approach works well when the kinematic configuration is
representative of the real operational conditions. However, when dealing with
manipulators of larger size subject to gravity, it becomes necessary to solve a
static force problem, using tendon force as the input and employing a mapping
from the configuration space to retrieve tendon length. Alternatively,
measurements of the manipulator posture can be used to iteratively adjust
tendon lengths to achieve a desired posture. Hence, either tension measurement
or state estimation of the manipulator are required, both of which are not
always accurately available. Here, we propose a solution by reconciling cables
tension and length as the input for the solution of the system forward statics.
We develop a screw-based formulation for a tendon-driven, multi-segment,
hyper-redundant manipulator with elastic joints and introduce a forward statics
iterative solution method that equivalently makes use of either tendon length
or tension as the input. This strategy is experimentally validated using a
traditional tension input first, subsequently showing the efficacy of the
method when exclusively tendon lengths are used. The results confirm the
possibility to perform open-loop control in static conditions using a kinematic
input only, thus bypassing some of the practical problems with tension
measurement and state estimation of hyper-redundant systems.

</details>


### [6] [Neural 3D Object Reconstruction with Small-Scale Unmanned Aerial Vehicles](https://arxiv.org/abs/2509.12458)
*Àlmos Veres-Vitàlyos,Genis Castillo Gomez-Raya,Filip Lemic,Daniel Johannes Bugelnig,Bernhard Rinner,Sergi Abadal,Xavier Costa-Pérez*

Main category: cs.RO

TL;DR: 这篇论文提出了一种用于超小型无人机的自主高精度3D重建系统，通过双重建流水线和动态轨迹调整来提升扭描质量。


<details>
  <summary>Details</summary>
Motivation: 解决超小型无人机在负载和自主性方面的限制，以支持在室内和难以达到区域进行高质量3D重建的复杂任务。

Method: 采用双重建流水线：近实时流使用SfM生成立即点云模型，动态调整飞行轨迹补充拍照空白区域；非实时流结合N3DR和UWB数据进行高精度最终重建。

Result: 在Crazyflie 2.1无人机上验证，单机和多机配置下都证明动态轨迹调整能持续提升重建质量，超越传统静态飞行路径。

Conclusion: 该系统为超小型无人机提供了可扩展的自主解决方案，开启了在受限环境中进行细粒度3D重建的新能力。

Abstract: Small Unmanned Aerial Vehicles (UAVs) exhibit immense potential for
navigating indoor and hard-to-reach areas, yet their significant constraints in
payload and autonomy have largely prevented their use for complex tasks like
high-quality 3-Dimensional (3D) reconstruction. To overcome this challenge, we
introduce a novel system architecture that enables fully autonomous,
high-fidelity 3D scanning of static objects using UAVs weighing under 100
grams. Our core innovation lies in a dual-reconstruction pipeline that creates
a real-time feedback loop between data capture and flight control. A
near-real-time (near-RT) process uses Structure from Motion (SfM) to generate
an instantaneous pointcloud of the object. The system analyzes the model
quality on the fly and dynamically adapts the UAV's trajectory to intelligently
capture new images of poorly covered areas. This ensures comprehensive data
acquisition. For the final, detailed output, a non-real-time (non-RT) pipeline
employs a Neural Radiance Fields (NeRF)-based Neural 3D Reconstruction (N3DR)
approach, fusing SfM-derived camera poses with precise Ultra Wide-Band (UWB)
location data to achieve superior accuracy. We implemented and validated this
architecture using Crazyflie 2.1 UAVs. Our experiments, conducted in both
single- and multi-UAV configurations, conclusively show that dynamic trajectory
adaptation consistently improves reconstruction quality over static flight
paths. This work demonstrates a scalable and autonomous solution that unlocks
the potential of miniaturized UAVs for fine-grained 3D reconstruction in
constrained environments, a capability previously limited to much larger
platforms.

</details>


### [7] [Bio-inspired tail oscillation enables robot fast crawling on deformable granular terrains](https://arxiv.org/abs/2509.12468)
*Shipeng Liu,Meghana Sagare,Shubham Patil,Feifei Qian*

Main category: cs.RO

TL;DR: 通过模仿弹涂鱼的尾部形态和运动控制，研究发现主动振荡尾部可使机器人在颗粒介质上的速度提高67%，阻力降低46%，为软基机器人设计提供了新思路


<details>
  <summary>Details</summary>
Motivation: 解决机器人在沙土等可变形基底上的移动难题，受弹涂鱼自然适应能力的启发，研究尾部设计与控制如何协同提升机器人在颗粒介质上的运动性能

Method: 使用仿弹涂鱼的生物启发机器人，实验比较空闲尾部和主动振荡尾部配置的运动性能，并进行剪切力测量分析基底流化效应

Result: 尾部振荡使机器人速度提高67%，身体阻力降低46%；尾部形态影响振荡策略，较大水平表面积的设计能更有效利用振荡减阻效果

Conclusion: 提出了基于基底强度和尾部形态的尾部动作选择设计原则，为改进机器人在可变形基底上的运动性能提供了新的尾部设计和控制见解

Abstract: Deformable substrates such as sand and mud present significant challenges for
terrestrial robots due to complex robot-terrain interactions. Inspired by
mudskippers, amphibious animals that naturally adjust their tail morphology and
movement jointly to navigate such environments, we investigate how tail design
and control can jointly enhance flipper-driven locomotion on granular media.
Using a bio-inspired robot modeled after the mudskipper, we experimentally
compared locomotion performance between idle and actively oscillating tail
configurations. Tail oscillation increased robot speed by 67% and reduced body
drag by 46%. Shear force measurements revealed that this improvement was
enabled by tail oscillation fluidizing the substrate, thereby reducing
resistance. Additionally, tail morphology strongly influenced the oscillation
strategy: designs with larger horizontal surface areas leveraged the
oscillation-reduced shear resistance more effectively by limiting insertion
depth. Based on these findings, we present a design principle to inform tail
action selection based on substrate strength and tail morphology. Our results
offer new insights into tail design and control for improving robot locomotion
on deformable substrates, with implications for agricultural robotics, search
and rescue, and environmental exploration.

</details>


### [8] [Learning to Generate Pointing Gestures in Situated Embodied Conversational Agents](https://arxiv.org/abs/2509.12507)
*Anna Deichler,Siyang Wang,Simon Alexanderson,Jonas Beskow*

Main category: cs.RO

TL;DR: 通过模仿学习与强化学习结合的框架，生成具有高参考准确性和自然性的指向手势，在虚拟现实参考游戏中超越了监督学习基线模型。


<details>
  <summary>Details</summary>
Motivation: 实现人机自然交互需要非语言通信能力，指向手势作为重要的非语言沟通方式需要更自然和准确的生成方法。

Method: 结合模仿学习和强化学习，使用小规模运动捐捕数据集学习机器人控制策略，生成物理可行、自然的手势。

Result: 在客观指标和虚拟现实参考游戏中，系统在自然性和准确性方面都超过了监督学习和检索基线模型。

Conclusion: 模仿强化学习在沟通手势生成方面展示了强大潜力，为机器人应用提供了有前景的方法。

Abstract: One of the main goals of robotics and intelligent agent research is to enable
natural communication with humans in physically situated settings. While recent
work has focused on verbal modes such as language and speech, non-verbal
communication is crucial for flexible interaction. We present a framework for
generating pointing gestures in embodied agents by combining imitation and
reinforcement learning. Using a small motion capture dataset, our method learns
a motor control policy that produces physically valid, naturalistic gestures
with high referential accuracy. We evaluate the approach against supervised
learning and retrieval baselines in both objective metrics and a virtual
reality referential game with human users. Results show that our system
achieves higher naturalness and accuracy than state-of-the-art supervised
models, highlighting the promise of imitation-RL for communicative gesture
generation and its potential application to robots.

</details>


### [9] [Zero to Autonomy in Real-Time: Online Adaptation of Dynamics in Unstructured Environments](https://arxiv.org/abs/2509.12516)
*William Ward,Sarah Etter,Jesse Quattrociocchi,Christian Ellis,Adam J. Thorpe,Ufuk Topcu*

Main category: cs.RO

TL;DR: 基于函数编码器与递归最小二乘的在线适应方法，能够在秒级时间内从零先验知识进行安全控制，适应场景动态变化。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在非结构化环境中需要快速适应突变的地形变化（如冰面过渡），以避免控制器失稳。传统静态模型和元学习方法无法满足实时适应需求。

Method: 结合函数编码器与递归最小二乘算法，将函数编码器系数作为隐变状态从流式径程计数据中更新。该方法无需梯度基于的内循环更新，实现常数时间的系数估计。

Result: 在Van der Pol系统、Unity模拟器和Clearpath Jackal机器人上评估，包括冰面挑战场景。方法提高了模型准确性和下游规划性能，与静态模型和元学习基线相比减少了碰撞。

Conclusion: 该在线适应方法能够从几秒钟的数据中快速学习和适应，有效提升自主机器人在非结构化环境中的安全性和稳定性。

Abstract: Autonomous robots must go from zero prior knowledge to safe control within
seconds to operate in unstructured environments. Abrupt terrain changes, such
as a sudden transition to ice, create dynamics shifts that can destabilize
planners unless the model adapts in real-time. We present a method for online
adaptation that combines function encoders with recursive least squares,
treating the function encoder coefficients as latent states updated from
streaming odometry. This yields constant-time coefficient estimation without
gradient-based inner-loop updates, enabling adaptation from only a few seconds
of data. We evaluate our approach on a Van der Pol system to highlight
algorithmic behavior, in a Unity simulator for high-fidelity off-road
navigation, and on a Clearpath Jackal robot, including on a challenging terrain
at a local ice rink. Across these settings, our method improves model accuracy
and downstream planning, reducing collisions compared to static and
meta-learning baselines.

</details>


### [10] [Pre-trained Visual Representations Generalize Where it Matters in Model-Based Reinforcement Learning](https://arxiv.org/abs/2509.12531)
*Scott Jones,Liyou Zhou,Sebastian W. Pattinson*

Main category: cs.RO

TL;DR: 研究表明预训练视觉模型在基于模型的强化学习中能显著提升视觉策略学习在域偏移下的鲁棒性，部分微调在极端分布偏移下表现最佳


<details>
  <summary>Details</summary>
Motivation: 现有的基于模型的强化学习方法在视觉域偏移下泛化能力差，预训练视觉模型在无模型强化学习中有效但在基于模型方法中效果不佳，需要深入研究其在MBRL中的有效性

Method: 研究预训练视觉模型在基于模型强化学习中的应用，特别关注视觉域偏移下的泛化能力，测试不同程度的模型微调效果

Result: 在严重域偏移场景下，预训练视觉模型表现显著优于从头训练的基线模型，部分微调在极端分布偏移下保持最高平均任务性能

Conclusion: 预训练视觉模型能有效提升视觉策略学习的鲁棒性，应在基于模型的机器人学习应用中广泛采用

Abstract: In visuomotor policy learning, the control policy for the robotic agent is
derived directly from visual inputs. The typical approach, where a policy and
vision encoder are trained jointly from scratch, generalizes poorly to novel
visual scene changes. Using pre-trained vision models (PVMs) to inform a policy
network improves robustness in model-free reinforcement learning (MFRL). Recent
developments in Model-based reinforcement learning (MBRL) suggest that MBRL is
more sample-efficient than MFRL. However, counterintuitively, existing work has
found PVMs to be ineffective in MBRL. Here, we investigate PVM's effectiveness
in MBRL, specifically on generalization under visual domain shifts. We show
that, in scenarios with severe shifts, PVMs perform much better than a baseline
model trained from scratch. We further investigate the effects of varying
levels of fine-tuning of PVMs. Our results show that partial fine-tuning can
maintain the highest average task performance under the most extreme
distribution shifts. Our results demonstrate that PVMs are highly successful in
promoting robustness in visual policy learning, providing compelling evidence
for their wider adoption in model-based robotic learning applications.

</details>


### [11] [Robust Online Residual Refinement via Koopman-Guided Dynamics Modeling](https://arxiv.org/abs/2509.12562)
*Zhefei Gong,Shangke Lyu,Pengxiang Ding,Wei Xiao,Donglin Wang*

Main category: cs.RO

TL;DR: 提出了KORR框架，通过Koopman算子理论在潜在空间中建立线性时不变结构，为残差策略学习提供全局动力学建模指导，显著提升了长时程精细机器人装配任务的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的模仿学习在长时程任务和高精度控制中存在误差累积问题，现有残差策略学习方法主要关注局部修正，缺乏对状态演化的全局理解，限制了在未见场景中的鲁棒性和泛化能力。

Method: 提出KORR框架，利用Koopman算子理论在学习的潜在空间中施加线性时不变结构，使残差修正基于Koopman预测的潜在状态，实现全局信息指导的稳定动作精炼。

Result: 在长时程精细机器人家具装配任务的各种扰动下进行评估，结果显示相比强基线方法在性能、鲁棒性和泛化能力方面均取得一致提升。

Conclusion: 研究结果突显了基于Koopman的建模在连接现代学习方法与经典控制理论方面的潜力，为残差策略学习提供了有效的全局指导机制。

Abstract: Imitation learning (IL) enables efficient skill acquisition from
demonstrations but often struggles with long-horizon tasks and high-precision
control due to compounding errors. Residual policy learning offers a promising,
model-agnostic solution by refining a base policy through closed-loop
corrections. However, existing approaches primarily focus on local corrections
to the base policy, lacking a global understanding of state evolution, which
limits robustness and generalization to unseen scenarios. To address this, we
propose incorporating global dynamics modeling to guide residual policy
updates. Specifically, we leverage Koopman operator theory to impose linear
time-invariant structure in a learned latent space, enabling reliable state
transitions and improved extrapolation for long-horizon prediction and unseen
environments. We introduce KORR (Koopman-guided Online Residual Refinement), a
simple yet effective framework that conditions residual corrections on
Koopman-predicted latent states, enabling globally informed and stable action
refinement. We evaluate KORR on long-horizon, fine-grained robotic furniture
assembly tasks under various perturbations. Results demonstrate consistent
gains in performance, robustness, and generalization over strong baselines. Our
findings further highlight the potential of Koopman-based modeling to bridge
modern learning methods with classical control theory.

</details>


### [12] [The Better You Learn, The Smarter You Prune: Towards Efficient Vision-language-action Models via Differentiable Token Pruning](https://arxiv.org/abs/2509.12594)
*Titong Jiang,Xuefeng Jiang,Yuan Ma,Xin Wen,Bailin Li,Kun Zhan,Peng Jia,Yahui Liu,Sheng Sun,Xianpeng Lang*

Main category: cs.RO

TL;DR: LightVLA是一个简单有效的可微分token剪枝框架，用于视觉-语言-动作模型，通过自适应剪枝视觉token来减少计算开销，同时提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: VLA模型在资源受限平台上部署时，由于大量视觉token的注意力计算导致计算瓶颈，需要一种高效的token剪枝方法来平衡性能和效率。

Method: 使用动态查询评估视觉token重要性，采用Gumbel softmax实现可微分token选择，通过微调学习保留信息丰富的token，剪枝对任务执行无贡献的token。

Result: 在LIBERO基准测试中，LightVLA相比现有方法减少了59.1%的FLOPs和38.2%的延迟，同时任务成功率提高了2.9%。

Conclusion: LightVLA是首个将自适应视觉token剪枝应用于VLA任务的工作，实现了效率和性能的双重提升，为实时机器人系统提供了更实用的解决方案。

Abstract: We present LightVLA, a simple yet effective differentiable token pruning
framework for vision-language-action (VLA) models. While VLA models have shown
impressive capability in executing real-world robotic tasks, their deployment
on resource-constrained platforms is often bottlenecked by the heavy
attention-based computation over large sets of visual tokens. LightVLA
addresses this challenge through adaptive, performance-driven pruning of visual
tokens: It generates dynamic queries to evaluate visual token importance, and
adopts Gumbel softmax to enable differentiable token selection. Through
fine-tuning, LightVLA learns to preserve the most informative visual tokens
while pruning tokens which do not contribute to task execution, thereby
improving efficiency and performance simultaneously. Notably, LightVLA requires
no heuristic magic numbers and introduces no additional trainable parameters,
making it compatible with modern inference frameworks. Experimental results
demonstrate that LightVLA outperforms different VLA models and existing token
pruning methods across diverse tasks on the LIBERO benchmark, achieving higher
success rates with substantially reduced computational overhead. Specifically,
LightVLA reduces FLOPs and latency by 59.1% and 38.2% respectively, with a 2.9%
improvement in task success rate. Meanwhile, we also investigate the learnable
query-based token pruning method LightVLA* with additional trainable
parameters, which also achieves satisfactory performance. Our work reveals that
as VLA pursues optimal performance, LightVLA spontaneously learns to prune
tokens from a performance-driven perspective. To the best of our knowledge,
LightVLA is the first work to apply adaptive visual token pruning to VLA tasks
with the collateral goals of efficiency and performance, marking a significant
step toward more efficient, powerful and practical real-time robotic systems.

</details>


### [13] [ActiveVLN: Towards Active Exploration via Multi-Turn RL in Vision-and-Language Navigation](https://arxiv.org/abs/2509.12618)
*Zekai Zhang,Weiye Zhu,Hewei Pan,Xiangchen Wang,Rongtao Xu,Xing Sun,Feng Zheng*

Main category: cs.RO

TL;DR: ActiveVLN是一个基于多轮强化学习的视觉语言导航框架，通过主动探索减少对专家轨迹的依赖，在保持性能的同时显著降低数据收集和训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有VLN方法主要依赖模仿学习和DAgger后训练，数据收集和训练成本高；而之前的RL方法缺乏环境动态交互，依赖专家轨迹进行奖励塑造，限制了智能体发现多样化导航路径的能力。

Method: 两阶段框架：第一阶段使用少量专家轨迹进行模仿学习初始化；第二阶段通过多轮RL进行主动探索，智能体迭代预测执行动作、自动收集多样化轨迹，使用GRPO目标优化多个rollout，并引入动态早停策略剪枝失败轨迹。

Result: ActiveVLN相比IL基线实现了最大的性能提升，在使用较小模型的情况下达到了与最先进方法竞争的性能。

Conclusion: ActiveVLN通过主动探索和多轮RL有效解决了VLN任务中的数据依赖和探索限制问题，为视觉语言导航提供了更高效和多样化的解决方案。

Abstract: The Vision-and-Language Navigation (VLN) task requires an agent to follow
natural language instructions and navigate through complex environments.
Existing MLLM-based VLN methods primarily rely on imitation learning (IL) and
often use DAgger for post-training to mitigate covariate shift. While
effective, these approaches incur substantial data collection and training
costs. Reinforcement learning (RL) offers a promising alternative. However,
prior VLN RL methods lack dynamic interaction with the environment and depend
on expert trajectories for reward shaping, rather than engaging in open-ended
active exploration. This restricts the agent's ability to discover diverse and
plausible navigation routes. To address these limitations, we propose
ActiveVLN, a VLN framework that explicitly enables active exploration through
multi-turn RL. In the first stage, a small fraction of expert trajectories is
used for IL to bootstrap the agent. In the second stage, the agent iteratively
predicts and executes actions, automatically collects diverse trajectories, and
optimizes multiple rollouts via the GRPO objective. To further improve RL
efficiency, we introduce a dynamic early-stopping strategy to prune long-tail
or likely failed trajectories, along with additional engineering optimizations.
Experiments show that ActiveVLN achieves the largest performance gains over IL
baselines compared to both DAgger-based and prior RL-based post-training
methods, while reaching competitive performance with state-of-the-art
approaches despite using a smaller model. Code and data will be released soon.

</details>


### [14] [PerchMobi^3: A Multi-Modal Robot with Power-Reuse Quad-Fan Mechanism for Air-Ground-Wall Locomotion](https://arxiv.org/abs/2509.12620)
*Yikai Chen,Zhi Zheng,Jin Wang,Bingye He,Xiangyu Xu,Jialu Zhang,Huan Yu,Guodong Lu*

Main category: cs.RO

TL;DR: PerchMobi^3是一个四风扇负压空地墙三栖机器人，通过推进-吸附功率复用机制，使用四个涵道风扇同时提供空中推力和负压吸附，无需专用泵，实现了轻量化紧凑设计。


<details>
  <summary>Details</summary>
Motivation: 现有设计通常依赖额外的粘附执行器，增加了复杂性、降低了效率并损害了可靠性。为了解决这些限制，需要开发一种能够无缝集成空中飞行、地面行驶和墙面爬行的单一机器人平台。

Method: 采用四涵道风扇同时提供空中推力和负压吸附，结合四个主动驱动轮，实现推进-吸附功率复用机制。建立了建模和控制框架，实现地面、墙面和空中领域的协调操作。

Result: 通过全面的实验验证了设计的可行性，包括地面驾驶、有效载荷辅助墙面爬行、空中飞行和跨模式转换，展示了在各种运动场景中的强大适应性。

Conclusion: PerchMobi^3为多模态机器人移动性提供了一种新颖的设计范式，为未来自主和应用导向的部署铺平了道路。

Abstract: Achieving seamless integration of aerial flight, ground driving, and wall
climbing within a single robotic platform remains a major challenge, as
existing designs often rely on additional adhesion actuators that increase
complexity, reduce efficiency, and compromise reliability. To address these
limitations, we present PerchMobi^3, a quad-fan, negative-pressure,
air-ground-wall robot that implements a propulsion-adhesion power-reuse
mechanism. By repurposing four ducted fans to simultaneously provide aerial
thrust and negative-pressure adhesion, and integrating them with four actively
driven wheels, PerchMobi^3 eliminates dedicated pumps while maintaining a
lightweight and compact design. To the best of our knowledge, this is the first
quad-fan prototype to demonstrate functional power reuse for multi-modal
locomotion. A modeling and control framework enables coordinated operation
across ground, wall, and aerial domains with fan-assisted transitions. The
feasibility of the design is validated through a comprehensive set of
experiments covering ground driving, payload-assisted wall climbing, aerial
flight, and cross-mode transitions, demonstrating robust adaptability across
locomotion scenarios. These results highlight the potential of PerchMobi^3 as a
novel design paradigm for multi-modal robotic mobility, paving the way for
future extensions toward autonomous and application-oriented deployment.

</details>


### [15] [Safety filtering of robotic manipulation under environment uncertainty: a computational approach](https://arxiv.org/abs/2509.12674)
*Anna Johansson,Daniel Lindmark,Viktor Wiberg,Martin Servin*

Main category: cs.RO

TL;DR: 提出基于物理仿真的安全过滤方法，通过密集采样和稀疏重评估来处理机器人操作中的不确定性，确保在质量、摩擦等参数不确定情况下的安全操作


<details>
  <summary>Details</summary>
Motivation: 现有安全过滤器通常假设完全可观测性，限制了在真实世界任务中的适用性。需要在动态和非结构化环境中利用已知和不确定信息来确保机器人操作安全

Method: 结合密集参数采样和并行稀疏重评估，使用广义安全因子评估稳定抓取和执行器限制，通过探测动作减少不确定性

Result: 在模拟双手机器人操作任务中验证，能够有效识别和过滤不安全轨迹，展示了在质量和摩擦不确定情况下的高效安全评估

Conclusion: 基于物理的稀疏安全评估是处理不确定性下安全机器人操作的可扩展策略

Abstract: Robotic manipulation in dynamic and unstructured environments requires safety
mechanisms that exploit what is known and what is uncertain about the world.
Existing safety filters often assume full observability, limiting their
applicability in real-world tasks. We propose a physics-based safety filtering
scheme that leverages high-fidelity simulation to assess control policies under
uncertainty in world parameters. The method combines dense rollout with nominal
parameters and parallelizable sparse re-evaluation at critical
state-transitions, quantified through generalized factors of safety for stable
grasping and actuator limits, and targeted uncertainty reduction through
probing actions. We demonstrate the approach in a simulated bimanual
manipulation task with uncertain object mass and friction, showing that unsafe
trajectories can be identified and filtered efficiently. Our results highlight
physics-based sparse safety evaluation as a scalable strategy for safe robotic
manipulation under uncertainty.

</details>


### [16] [UDON: Uncertainty-weighted Distributed Optimization for Multi-Robot Neural Implicit Mapping under Extreme Communication Constraints](https://arxiv.org/abs/2509.12702)
*Hongrui Zhao,Xunlan Zhou,Boris Ivanovic,Negar Mehr*

Main category: cs.RO

TL;DR: UDON是一个实时多智能体神经隐式建图框架，通过不确定性加权分布式优化，在极低通信成功率(低至1%)下仍能保持高质量地图重建


<details>
  <summary>Details</summary>
Motivation: 多机器人神经隐式建图需要应对通信挑战(如丢包和带宽限制)，现有方法在极低通信成功率下性能仍会下降

Method: 提出不确定性加权分布式优化：不确定性加权优先处理地图中更可靠的部分，分布式优化隔离并惩罚通信智能体之间的建图不一致性

Result: 在标准基准数据集和真实机器人硬件上的实验表明，UDON显著优于现有基线方法，即使在极端通信退化情况下也能保持高保真重建和一致的场景表示

Conclusion: UDON框架通过创新的不确定性加权分布式优化方法，成功解决了多智能体神经隐式建图在严重通信退化条件下的性能问题

Abstract: Multi-robot mapping with neural implicit representations enables the compact
reconstruction of complex environments. However, it demands robustness against
communication challenges like packet loss and limited bandwidth. While prior
works have introduced various mechanisms to mitigate communication disruptions,
performance degradation still occurs under extremely low communication success
rates. This paper presents UDON, a real-time multi-agent neural implicit
mapping framework that introduces a novel uncertainty-weighted distributed
optimization to achieve high-quality mapping under severe communication
deterioration. The uncertainty weighting prioritizes more reliable portions of
the map, while the distributed optimization isolates and penalizes mapping
disagreement between individual pairs of communicating agents. We conduct
extensive experiments on standard benchmark datasets and real-world robot
hardware. We demonstrate that UDON significantly outperforms existing
baselines, maintaining high-fidelity reconstructions and consistent scene
representations even under extreme communication degradation (as low as 1%
success rate).

</details>


### [17] [MoiréTac: A Dual-Mode Visuotactile Sensor for Multidimensional Perception Using Moiré Pattern Amplification](https://arxiv.org/abs/2509.12714)
*Kit-Wa Sou,Junhao Gong,Shoujie Li,Chuqiao Lyu,Ziwu Song,Shilong Mu,Wenbo Ding*

Main category: cs.RO

TL;DR: MoiréTac是一种新型视觉触觉传感器，通过微光栅重叠产生密集的莫尔条纹，实现高分辨率触觉感知和视觉功能的结合


<details>
  <summary>Details</summary>
Motivation: 解决传统视觉触觉传感器空间分辨率低、缺乏清晰力-图像分析关系的问题

Method: 采用透明架构中的重叠微光栅产生莫尔条纹，结合物理特征和深度学习进行6轴力/力矩测量

Result: 力/力矩测量R²>0.98，灵敏度可通过几何参数调节（三倍增益调整），保持视觉功能实现物体分类

Conclusion: 传感器在灵巧操作中具有潜力，成功集成到机械臂完成瓶盖移除任务，验证了协调力扭矩控制的能力

Abstract: Visuotactile sensors typically employ sparse marker arrays that limit spatial
resolution and lack clear analytical force-to-image relationships. To solve
this problem, we present \textbf{Moir\'eTac}, a dual-mode sensor that generates
dense interference patterns via overlapping micro-gratings within a transparent
architecture. When two gratings overlap with misalignment, they create moir\'e
patterns that amplify microscopic deformations. The design preserves optical
clarity for vision tasks while producing continuous moir\'e fields for tactile
sensing, enabling simultaneous 6-axis force/torque measurement, contact
localization, and visual perception. We combine physics-based features
(brightness, phase gradient, orientation, and period) from moir\'e patterns
with deep spatial features. These are mapped to 6-axis force/torque
measurements, enabling interpretable regression through end-to-end learning.
Experimental results demonstrate three capabilities: force/torque measurement
with R^2 > 0.98 across tested axes; sensitivity tuning through geometric
parameters (threefold gain adjustment); and vision functionality for object
classification despite moir\'e overlay. Finally, we integrate the sensor into a
robotic arm for cap removal with coordinated force and torque control,
validating its potential for dexterous manipulation.

</details>


### [18] [NAMOUnc: Navigation Among Movable Obstacles with Decision Making on Uncertainty Interval](https://arxiv.org/abs/2509.12723)
*Kai Zhang,Eric Lucet,Julien Alexandre Dit Sandretto,Shoubin Chen,David Filait*

Main category: cs.RO

TL;DR: NAMOUnc框架通过将不确定性整合到决策过程中，解决了可移动障碍物导航中的观测噪声、模型近似、动作失败和部分可观测性等现实不确定性挑战


<details>
  <summary>Details</summary>
Motivation: 现有NAMO解决方案通常假设理想条件，导致次优或风险决策，无法有效处理现实世界中的各种不确定性

Method: 首先估计不确定性，然后比较移除和绕过障碍物的时间成本区间，优化成功率和时间效率

Result: 通过大量仿真和真实实验验证，相比现有NAMO框架有显著改进

Conclusion: NAMOUnc框架能够确保更安全、更高效的导航，有效处理现实世界中的不确定性

Abstract: Navigation among movable obstacles (NAMO) is a critical task in robotics,
often challenged by real-world uncertainties such as observation noise, model
approximations, action failures, and partial observability. Existing solutions
frequently assume ideal conditions, leading to suboptimal or risky decisions.
This paper introduces NAMOUnc, a novel framework designed to address these
uncertainties by integrating them into the decision-making process. We first
estimate them and compare the corresponding time cost intervals for removing
and bypassing obstacles, optimizing both the success rate and time efficiency,
ensuring safer and more efficient navigation. We validate our method through
extensive simulations and real-world experiments, demonstrating significant
improvements over existing NAMO frameworks. More details can be found in our
website: https://kai-zhang-er.github.io/namo-uncertainty/

</details>


### [19] [Deep Learning for Model-Free Prediction of Thermal States of Robot Joint Motors](https://arxiv.org/abs/2509.12739)
*Trung Kien La,Eric Guiffo Kaigom*

Main category: cs.RO

TL;DR: 使用多层LSTM和全连接网络的深度神经网络来预测机器人关节电机的热行为，采用无模型、可扩展的方法处理复杂性和不确定性挑战。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要推导、识别和验证大量难以获得的近似模型参数，面临复杂性和不确定性挑战，因此需要一种无模型的方法来预测关节电机的热行为。

Method: 采用由多个隐藏LSTM层和前馈层组成的深度神经网络，通过采集和处理传感的关节扭矩数据来预测关节电机的温度动态。

Result: 在七关节冗余机器人上获得了有前景的预测结果，成功捕捉了关节电机的温度动态。

Conclusion: 基于机器学习的方法能够有效预测机器人关节电机的热行为，为处理复杂系统的热管理问题提供了可行的解决方案。

Abstract: In this work, deep neural networks made up of multiple hidden Long Short-Term
Memory (LSTM) and Feedforward layers are trained to predict the thermal
behavior of the joint motors of robot manipulators. A model-free and scalable
approach is adopted. It accommodates complexity and uncertainty challenges
stemming from the derivation, identification, and validation of a large number
of parameters of an approximation model that is hardly available. To this end,
sensed joint torques are collected and processed to foresee the thermal
behavior of joint motors. Promising prediction results of the machine learning
based capture of the temperature dynamics of joint motors of a redundant robot
with seven joints are presented.

</details>


### [20] [Deep Generative and Discriminative Digital Twin endowed with Variational Autoencoder for Unsupervised Predictive Thermal Condition Monitoring of Physical Robots in Industry 6.0 and Society 6.0](https://arxiv.org/abs/2509.12740)
*Eric Guiffo Kaigom*

Main category: cs.RO

TL;DR: 利用变分自动编码器的智能数字双生体来预测和管理机器人温度异常，通过重构错误定义热难度指数，使机器人能够自主预测和分享运动任务的热可行性，避免过热关机并延长使用寿命。


<details>
  <summary>Details</summary>
Motivation: 使机器人在工业4.0和5.0环境中能够自主预测和适应温度满和燃伤风险，确保人员安全和机器人可用性，避免传统关机方式对生产效率的影响。

Method: 采用变分自动编码器(VAE)构建智能数字双生体，通过重构错误计算热难度指数，用于预测机器人状态的热可行性。

Result: 机器人能够预测和分享运动任务的热可行性，生成无风险的状态，避免过热关机，提高生产效率和使用寿命。

Conclusion: 该方法为工业6.0和社会6.0应用提供了一种自主热管理方案，通过智能数字双生体实现机器人的自我维持和预测能力，确保人机协作的安全性和效率。

Abstract: Robots are unrelentingly used to achieve operational efficiency in Industry
4.0 along with symbiotic and sustainable assistance for the work-force in
Industry 5.0. As resilience, robustness, and well-being are required in
anti-fragile manufacturing and human-centric societal tasks, an autonomous
anticipation and adaption to thermal saturation and burns due to motors
overheating become instrumental for human safety and robot availability. Robots
are thereby expected to self-sustain their performance and deliver user
experience, in addition to communicating their capability to other agents in
advance to ensure fully automated thermally feasible tasks, and prolong their
lifetime without human intervention. However, the traditional robot shutdown,
when facing an imminent thermal saturation, inhibits productivity in factories
and comfort in the society, while cooling strategies are hard to implement
after the robot acquisition. In this work, smart digital twins endowed with
generative AI, i.e., variational autoencoders, are leveraged to manage
thermally anomalous and generate uncritical robot states. The notion of thermal
difficulty is derived from the reconstruction error of variational
autoencoders. A robot can use this score to predict, anticipate, and share the
thermal feasibility of desired motion profiles to meet requirements from
emerging applications in Industry 6.0 and Society 6.0.

</details>


### [21] [Force-Modulated Visual Policy for Robot-Assisted Dressing with Arm Motions](https://arxiv.org/abs/2509.12741)
*Alexis Yihong Hao,Yufei Wang,Navin Sriram Ravie,Bharath Hegde,David Held,Zackory Erickson*

Main category: cs.RO

TL;DR: 开发了一个机器人辅助穿衣系统，能够处理视觉遮挡的部分观察，并在穿衣过程中适应手臂运动。通过模拟训练和少量真实数据微调，结合视觉和力觉反馈，提高了对动态手臂运动的适应性和安全性。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助穿衣可以显著改善行动不便人士的生活质量，但现有方法通常假设人体肢体静止，限制了实际应用。需要处理变形衣物、施加适当力量并适应肢体运动的系统。

Method: 在模拟环境中训练具有部分观察能力的策略，然后在现实世界中使用少量数据和多模态反馈（视觉和力觉）进行微调，以提高对手臂运动的适应性和安全性。

Result: 在模拟和真实世界研究中（12名参与者，264次试验），该系统成功为参与者穿上两种长袖日常衣物，能够适应各种手臂运动，在任务完成度和用户反馈方面显著优于现有基线方法。

Conclusion: 提出的方法能够有效处理机器人辅助穿衣中的动态肢体运动挑战，通过模拟到现实的迁移学习和多模态反馈，实现了对真实世界复杂场景的鲁棒适应，为实际应用提供了可行解决方案。

Abstract: Robot-assisted dressing has the potential to significantly improve the lives
of individuals with mobility impairments. To ensure an effective and
comfortable dressing experience, the robot must be able to handle challenging
deformable garments, apply appropriate forces, and adapt to limb movements
throughout the dressing process. Prior work often makes simplifying assumptions
-- such as static human limbs during dressing -- which limits real-world
applicability. In this work, we develop a robot-assisted dressing system
capable of handling partial observations with visual occlusions, as well as
robustly adapting to arm motions during the dressing process. Given a policy
trained in simulation with partial observations, we propose a method to
fine-tune it in the real world using a small amount of data and multi-modal
feedback from vision and force sensing, to further improve the policy's
adaptability to arm motions and enhance safety. We evaluate our method in
simulation with simplified articulated human meshes and in a real world human
study with 12 participants across 264 dressing trials. Our policy successfully
dresses two long-sleeve everyday garments onto the participants while being
adaptive to various kinds of arm motions, and greatly outperforms prior
baselines in terms of task completion and user feedback. Video are available at
https://dressing-motion.github.io/.

</details>


### [22] [NavMoE: Hybrid Model- and Learning-based Traversability Estimation for Local Navigation via Mixture of Experts](https://arxiv.org/abs/2509.12747)
*Botao He,Amir Hossein Shahidzadeh,Yu Chen,Jiayi Wu,Tianrui Guan,Guofei Chen,Howie Choset,Dinesh Manocha,Glen Chou,Cornelia Fermuller,Yiannis Aloimonos*

Main category: cs.RO

TL;DR: NAVMOE提出了一种基于专家混合的分层模块化方法，通过动态组合专门化模型来处理不同地形类型的可通行性估计，在保持路径质量的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 机器人导航中的可通行性估计需要在多样化环境中高效实现可靠预测，同时准确编码几何和语义信息，当前方法存在效率和泛化能力的瓶颈。

Method: 采用专家混合架构，结合多个专门化模型处理特定地形类型，通过门控网络动态加权不同模型的贡献，引入训练延迟门控机制减少推理时的激活专家数量。

Result: 实验表明NAVMOE在效率和性能平衡方面优于单个专家或完整集成方法，跨域泛化能力提升，计算成本降低81.2%，路径质量损失小于2%。

Conclusion: NAVMOE通过模块化设计和动态专家选择机制，有效解决了可通行性估计中的效率与泛化问题，为机器人导航提供了实用的解决方案。

Abstract: This paper explores traversability estimation for robot navigation. A key
bottleneck in traversability estimation lies in efficiently achieving reliable
and robust predictions while accurately encoding both geometric and semantic
information across diverse environments. We introduce Navigation via Mixture of
Experts (NAVMOE), a hierarchical and modular approach for traversability
estimation and local navigation. NAVMOE combines multiple specialized models
for specific terrain types, each of which can be either a classical model-based
or a learning-based approach that predicts traversability for specific terrain
types. NAVMOE dynamically weights the contributions of different models based
on the input environment through a gating network. Overall, our approach offers
three advantages: First, NAVMOE enables traversability estimation to adaptively
leverage specialized approaches for different terrains, which enhances
generalization across diverse and unseen environments. Second, our approach
significantly improves efficiency with negligible cost of solution quality by
introducing a training-free lazy gating mechanism, which is designed to
minimize the number of activated experts during inference. Third, our approach
uses a two-stage training strategy that enables the training for the gating
networks within the hybrid MoE method that contains nondifferentiable modules.
Extensive experiments show that NAVMOE delivers a better efficiency and
performance balance than any individual expert or full ensemble across
different domains, improving cross- domain generalization and reducing average
computational cost by 81.2% via lazy gating, with less than a 2% loss in path
quality.

</details>


### [23] [Toward Ownership Understanding of Objects: Active Question Generation with Large Language Model and Probabilistic Generative Model](https://arxiv.org/abs/2509.12754)
*Saki Hashimoto,Shoichi Hasegawa,Tomochika Ishikawa,Akira Taniguchi,Yoshinobu Hagiwara,Lotfi El Hafi,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: 提出了ActOwL框架，让机器人通过主动提问来学习物品所有权，结合概率生成模型和LLM常识推理，显著提高了所有权识别准确率


<details>
  <summary>Details</summary>
Motivation: 机器人在家庭和办公环境中需要理解物品所有权来正确执行指令，但仅凭视觉特征无法可靠推断所有权

Method: 使用概率生成模型选择信息增益最大的问题，利用LLM将物品预分类为共享或私有，只对私有物品进行提问

Result: 在模拟家庭环境和真实实验室环境中，比基线方法用更少的问题获得了显著更高的所有权聚类准确率

Conclusion: 结合主动推理和LLM引导的常识推理有效提升了机器人获取所有权知识的能力，使其能够更实用和符合社会规范地执行任务

Abstract: Robots operating in domestic and office environments must understand object
ownership to correctly execute instructions such as ``Bring me my cup.''
However, ownership cannot be reliably inferred from visual features alone. To
address this gap, we propose Active Ownership Learning (ActOwL), a framework
that enables robots to actively generate and ask ownership-related questions to
users. ActOwL employs a probabilistic generative model to select questions that
maximize information gain, thereby acquiring ownership knowledge efficiently to
improve learning efficiency. Additionally, by leveraging commonsense knowledge
from Large Language Models (LLM), objects are pre-classified as either shared
or owned, and only owned objects are targeted for questioning. Through
experiments in a simulated home environment and a real-world laboratory
setting, ActOwL achieved significantly higher ownership clustering accuracy
with fewer questions than baseline methods. These findings demonstrate the
effectiveness of combining active inference with LLM-guided commonsense
reasoning, advancing the capability of robots to acquire ownership knowledge
for practical and socially appropriate task execution.

</details>


### [24] [Integrating Trajectory Optimization and Reinforcement Learning for Quadrupedal Jumping with Terrain-Adaptive Landing](https://arxiv.org/abs/2509.12776)
*Renjie Wang,Shangke Lyu,Xin Lang,Wei Xiao,Donglin Wang*

Main category: cs.RO

TL;DR: 提出了一种结合轨迹优化和强化学习的四足机器人安全着陆框架，能够在粗糙地形上实现自适应着陆


<details>
  <summary>Details</summary>
Motivation: 现有四足机器人跳跃研究主要关注站立和飞行阶段，并假设平坦着陆地面，这在现实世界中不实用

Method: 结合轨迹优化(TO)和强化学习(RL)，RL智能体学习在粗糙地形环境中跟踪TO生成的参考运动，采用奖励松弛策略鼓励着陆恢复期的探索

Result: 大量实验验证了该方法在各种场景下的准确跟踪和安全着陆能力

Conclusion: 该方法能够有效实现四足机器人在复杂地形上的安全自适应着陆

Abstract: Jumping constitutes an essential component of quadruped robots' locomotion
capabilities, which includes dynamic take-off and adaptive landing. Existing
quadrupedal jumping studies mainly focused on the stance and flight phase by
assuming a flat landing ground, which is impractical in many real world cases.
This work proposes a safe landing framework that achieves adaptive landing on
rough terrains by combining Trajectory Optimization (TO) and Reinforcement
Learning (RL) together. The RL agent learns to track the reference motion
generated by TO in the environments with rough terrains. To enable the learning
of compliant landing skills on challenging terrains, a reward relaxation
strategy is synthesized to encourage exploration during landing recovery
period. Extensive experiments validate the accurate tracking and safe landing
skills benefiting from our proposed method in various scenarios.

</details>


### [25] [Bridging Perception and Planning: Towards End-to-End Planning for Signal Temporal Logic Tasks](https://arxiv.org/abs/2509.12813)
*Bowen Ye,Junyue Huang,Yang Liu,Xiaozhen Qiao,Xiang Yin*

Main category: cs.RO

TL;DR: 提出了S-MSP框架，将多视角相机观测和STL规范直接映射为可行轨迹，通过结构化混合专家模型和复合损失函数解决机器人时空逻辑规划问题


<details>
  <summary>Details</summary>
Motivation: 现有STL方法依赖预定义地图或移动性表示，在非结构化真实环境中效果不佳，需要直接从视觉观测生成满足时空逻辑规范的轨迹

Method: 使用结构化混合专家(MoE)模型，将子任务投影到时间锚定嵌入中，采用复合损失函数结合轨迹重建和STL鲁棒性，推理时加入基于规则的安全过滤器

Result: 在工厂物流场景的高保真仿真中，S-MSP在STL满足率和轨迹可行性方面优于单专家基线，安全过滤器提高了物理可执行性

Conclusion: S-MSP展示了直接从视觉输入处理复杂时空逻辑规范的实用性，为真实环境中的机器人任务和运动规划提供了有效解决方案

Abstract: We investigate the task and motion planning problem for Signal Temporal Logic
(STL) specifications in robotics. Existing STL methods rely on pre-defined maps
or mobility representations, which are ineffective in unstructured real-world
environments. We propose the \emph{Structured-MoE STL Planner}
(\textbf{S-MSP}), a differentiable framework that maps synchronized multi-view
camera observations and an STL specification directly to a feasible trajectory.
S-MSP integrates STL constraints within a unified pipeline, trained with a
composite loss that combines trajectory reconstruction and STL robustness. A
\emph{structure-aware} Mixture-of-Experts (MoE) model enables horizon-aware
specialization by projecting sub-tasks into temporally anchored embeddings. We
evaluate S-MSP using a high-fidelity simulation of factory-logistics scenarios
with temporally constrained tasks. Experiments show that S-MSP outperforms
single-expert baselines in STL satisfaction and trajectory feasibility. A
rule-based \emph{safety filter} at inference improves physical executability
without compromising logical correctness, showcasing the practicality of the
approach.

</details>


### [26] [Multi-Robot Task Planning for Multi-Object Retrieval Tasks with Distributed On-Site Knowledge via Large Language Models](https://arxiv.org/abs/2509.12838)
*Kento Murata,Shoichi Hasegawa,Tomochika Ishikawa,Yoshinobu Hagiwara,Akira Taniguchi,Lotfi El Hafi,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: 提出基于大语言模型和空间概念的多机器人任务规划框架，能够有效分解自然语言指令并分配给具有不同现场知识的机器人


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统中如何根据各机器人的现场空间知识来分配复杂自然语言指令的问题，特别是处理模糊指令和上下文相关命令

Method: 设计新颖的少样本提示策略，利用LLMs从模糊指令推断所需对象并分解为适当子任务，结合空间概念进行任务分配

Result: 在实验中实现了47/50的成功分配率，显著优于随机分配(28/50)和常识分配(26/50)，实际移动机械臂验证了框架的有效性

Conclusion: 该框架能够成功处理包含临时类别指令的任务分解、分配、顺序规划和执行，为多机器人系统提供了有效的自然语言任务规划解决方案

Abstract: It is crucial to efficiently execute instructions such as "Find an apple and
a banana" or "Get ready for a field trip," which require searching for multiple
objects or understanding context-dependent commands. This study addresses the
challenging problem of determining which robot should be assigned to which part
of a task when each robot possesses different situational on-site
knowledge-specifically, spatial concepts learned from the area designated to it
by the user. We propose a task planning framework that leverages large language
models (LLMs) and spatial concepts to decompose natural language instructions
into subtasks and allocate them to multiple robots. We designed a novel
few-shot prompting strategy that enables LLMs to infer required objects from
ambiguous commands and decompose them into appropriate subtasks. In our
experiments, the proposed method achieved 47/50 successful assignments,
outperforming random (28/50) and commonsense-based assignment (26/50).
Furthermore, we conducted qualitative evaluations using two actual mobile
manipulators. The results demonstrated that our framework could handle
instructions, including those involving ad hoc categories such as "Get ready
for a field trip," by successfully performing task decomposition, assignment,
sequential planning, and execution.

</details>


### [27] [Unleashing the Power of Discrete-Time State Representation: Ultrafast Target-based IMU-Camera Spatial-Temporal Calibration](https://arxiv.org/abs/2509.12846)
*Junlin Song,Antoine Richard,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 提出了一种基于离散时间状态表示的视觉-惯性标定新方法，相比连续时间方法显著降低了计算成本，同时解决了离散时间方法在时间标定方面的弱点


<details>
  <summary>Details</summary>
Motivation: 视觉-惯性融合在机器人导航和增强现实等应用中至关重要，但现有连续时间标定方法计算成本高，需要更高效的解决方案

Method: 采用离散时间状态表示方法，解决了离散时间在时间标定方面的技术难点

Result: 实现了极其高效的标定性能，相比传统方法大幅节省计算时间

Conclusion: 该方法对大规模设备标定具有重要意义，将为研究和工业界带来显著效益，代码将开源

Abstract: Visual-inertial fusion is crucial for a large amount of intelligent and
autonomous applications, such as robot navigation and augmented reality. To
bootstrap and achieve optimal state estimation, the spatial-temporal
displacements between IMU and cameras must be calibrated in advance. Most
existing calibration methods adopt continuous-time state representation, more
specifically the B-spline. Despite these methods achieve precise
spatial-temporal calibration, they suffer from high computational cost caused
by continuous-time state representation. To this end, we propose a novel and
extremely efficient calibration method that unleashes the power of
discrete-time state representation. Moreover, the weakness of discrete-time
state representation in temporal calibration is tackled in this paper. With the
increasing production of drones, cellphones and other visual-inertial
platforms, if one million devices need calibration around the world, saving one
minute for the calibration of each device means saving 2083 work days in total.
To benefit both the research and industry communities, our code will be
open-source.

</details>


### [28] [A Novel Skill Modeling Approach: Integrating Vergnaud's Scheme with Cognitive Architectures](https://arxiv.org/abs/2509.12851)
*Antoine Lénat,Olivier Cheminat,Damien Chablat,Camilo Charron*

Main category: cs.RO

TL;DR: 重点分析人机交互中操作员技能的形式化描述方法，通过结合命题逻辑咈谜理论与认知架构模型，以焊接为案例研究操作员技能适应机制


<details>
  <summary>Details</summary>
Motivation: 工业5.0时代人机交互日益重要，需要理论框架来形式化描述操作员技能，以支持人机协同作业和技能传输

Method: 结合Vergnaud在皮亚杰格格式概念中使用的命题逻辑方法，并集成认知架构模型来考虑认知系统约束，以焊接作业为具体案例进行研究

Result: 提出了一种能够考虑动作时机、认知资源限制、任务并行化和自动化手势等约束的操作员技能形式化表征方法

Conclusion: 通过命题逻辑与认知架构的结合，能够更完整地描述操作员技能，为人机技能传输和协同优化提供理论基础

Abstract: Human-machine interaction is increasingly important in industry, and this
trend will only intensify with the rise of Industry 5.0. Human operators have
skills that need to be adapted when using machines to achieve the best results.
It is crucial to highlight the operator's skills and understand how they use
and adapt them [18]. A rigorous description of these skills is necessary to
compare performance with and without robot assistance. Predicate logic, used by
Vergnaud within Piaget's scheme concept, offers a promising approach. However,
this theory doesn't account for cognitive system constraints, such as the
timing of actions, the limitation of cognitive resources, the parallelization
of tasks, or the activation of automatic gestures contrary to optimal
knowledge. Integrating these constraints is essential for representing agent
skills understanding skill transfer between biological and mechanical
structures. Cognitive architectures models [2] address these needs by
describing cognitive structure and can be combined with the scheme for mutual
benefit. Welding provides a relevant case study, as it highlights the
challenges faced by operators, even highly skilled ones. Welding's complexity
stems from the need for constant skill adaptation to variable parameters like
part position and process. This adaptation is crucial, as weld quality, a key
factor, is only assessed afterward via destructive testing. Thus, the welder is
confronted with a complex perception-decision-action cycle, where the
evaluation of the impact of his actions is delayed and where errors are
definitive. This dynamic underscores the importance of understanding and
modeling the skills of operators.

</details>


### [29] [Contrastive Representation Learning for Robust Sim-to-Real Transfer of Adaptive Humanoid Locomotion](https://arxiv.org/abs/2509.12858)
*Yidan Lu,Rurui Yang,Qiran Kou,Mengting Chen,Tao Fan,Peter Cui,Yinzhao Dong,Peng Lu*

Main category: cs.RO

TL;DR: 提出了一种通过对比学习框架将环境信息蒸馏到纯本体感知策略中的方法，使机器人能够主动调整步态节奏，在保持鲁棒性的同时获得前瞻能力


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中人形机器人运动控制的根本困境：需要在反应式本体感知控制的鲁棒性和复杂脆弱的感知驱动系统的主动性之间做出选择

Method: 使用对比学习框架，迫使执行器的潜在状态编码来自仿真的特权环境信息，通过"蒸馏感知"赋能自适应步态时钟，使策略能够基于地形推断主动调整节奏

Result: 通过零样本仿真到真实世界迁移，在完整尺寸人形机器人上验证了方法有效性，能够稳健地在具有挑战性的地形上运动，包括30厘米高台阶和26.5度斜坡

Conclusion: 该方法成功解决了刚性时钟步态和不稳定无时钟策略之间的经典权衡，实现了既有感知前瞻能力又无需部署时成本的纯本体感知策略

Abstract: Reinforcement learning has produced remarkable advances in humanoid
locomotion, yet a fundamental dilemma persists for real-world deployment:
policies must choose between the robustness of reactive proprioceptive control
or the proactivity of complex, fragile perception-driven systems. This paper
resolves this dilemma by introducing a paradigm that imbues a purely
proprioceptive policy with proactive capabilities, achieving the foresight of
perception without its deployment-time costs. Our core contribution is a
contrastive learning framework that compels the actor's latent state to encode
privileged environmental information from simulation. Crucially, this
``distilled awareness" empowers an adaptive gait clock, allowing the policy to
proactively adjust its rhythm based on an inferred understanding of the
terrain. This synergy resolves the classic trade-off between rigid, clocked
gaits and unstable clock-free policies. We validate our approach with zero-shot
sim-to-real transfer to a full-sized humanoid, demonstrating highly robust
locomotion over challenging terrains, including 30 cm high steps and 26.5{\deg}
slopes, proving the effectiveness of our method. Website:
https://lu-yidan.github.io/cra-loco.

</details>


### [30] [GRATE: a Graph transformer-based deep Reinforcement learning Approach for Time-efficient autonomous robot Exploration](https://arxiv.org/abs/2509.12863)
*Haozhan Ni,Jingsong Liang,Chenyu He,Yuhong Cao,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: GRATE是一个基于深度强化学习的自主机器人探索方法，使用图Transformer增强环境推理能力，结合卡尔曼滤波确保路径可行性，在距离和时间效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的自主探索方法在图结构数据处理能力有限，且忽视机器人运动特性，导致策略主要优化距离而忽略时间效率。

Method: 提出GRATE方法：1）使用图Transformer捕捉信息图的局部结构模式和全局上下文依赖；2）部署卡尔曼滤波器平滑路径点输出，确保运动学可行性。

Result: 实验显示方法在模拟基准测试中比现有传统和学习基线方法在探索效率上提升21.5%（距离）和21.3%（时间），并在真实场景中验证。

Conclusion: GRATE通过结合图Transformer和运动学约束处理，显著提升了自主机器人探索的效率和实用性。

Abstract: Autonomous robot exploration (ARE) is the process of a robot autonomously
navigating and mapping an unknown environment. Recent Reinforcement Learning
(RL)-based approaches typically formulate ARE as a sequential decision-making
problem defined on a collision-free informative graph. However, these methods
often demonstrate limited reasoning ability over graph-structured data.
Moreover, due to the insufficient consideration of robot motion, the resulting
RL policies are generally optimized to minimize travel distance, while
neglecting time efficiency. To overcome these limitations, we propose GRATE, a
Deep Reinforcement Learning (DRL)-based approach that leverages a Graph
Transformer to effectively capture both local structure patterns and global
contextual dependencies of the informative graph, thereby enhancing the model's
reasoning capability across the entire environment. In addition, we deploy a
Kalman filter to smooth the waypoint outputs, ensuring that the resulting path
is kinodynamically feasible for the robot to follow. Experimental results
demonstrate that our method exhibits better exploration efficiency (up to 21.5%
in distance and 21.3% in time to complete exploration) than state-of-the-art
conventional and learning-based baselines in various simulation benchmarks. We
also validate our planner in real-world scenarios.

</details>


### [31] [Towards Context-Aware Human-like Pointing Gestures with RL Motion Imitation](https://arxiv.org/abs/2509.12880)
*Anna Deichler,Siyang Wang,Simon Alexanderson,Jonas Beskow*

Main category: cs.RO

TL;DR: 提出了一个包含多种风格、手性和空间目标的人体指向手势运动捕捉数据集，使用强化学习和运动模仿训练能够生成人类化精确指向的策略


<details>
  <summary>Details</summary>
Motivation: 指向是与机器人交互的关键模式，但以往研究主要关注识别而非生成，需要开发能够产生自然精确指向动作的方法

Method: 收集多样化人体指向手势运动捕捉数据，采用强化学习结合运动模仿的方法训练策略，在保持动作自然性的同时最大化指向精度

Result: 训练的策略能够在仿真环境中实现上下文感知的指向行为，在任务性能和自然动态之间取得良好平衡

Conclusion: 该方法成功实现了人类化指向动作的生成，为机器人自然交互提供了有效解决方案

Abstract: Pointing is a key mode of interaction with robots, yet most prior work has
focused on recognition rather than generation. We present a motion capture
dataset of human pointing gestures covering diverse styles, handedness, and
spatial targets. Using reinforcement learning with motion imitation, we train
policies that reproduce human-like pointing while maximizing precision. Results
show our approach enables context-aware pointing behaviors in simulation,
balancing task performance with natural dynamics.

</details>


### [32] [Responsibility and Engagement -- Evaluating Interactions in Social Robot Navigation](https://arxiv.org/abs/2509.12890)
*Malte Probst,Raphael Wenzel,Monica Dasi*

Main category: cs.RO

TL;DR: 本文扩展了社交机器人导航中的责任度量框架，提出了时间归一化建模冲突积累阶段，并引入了参与度度量来捕捉冲突强度变化。通过模拟实验验证了这些度量在评估冲突解决合作性和行为质量方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 在社交机器人导航中，需要有效的度量标准来评估人机交互轨迹，特别是解决多智能体冲突时的责任分配和冲突强度变化。

Method: 扩展现有责任度量框架：1）引入时间归一化建模冲突积累阶段；2）提出参与度度量捕捉冲突强度变化；在模拟场景（二元、群体和人群交互）中进行全面测试。

Result: 实验表明所提出的度量能够有效反映交互中冲突解决的合作性信息，可用于评估行为质量和前瞻性。

Conclusion: 提出的责任和参与度度量为社交机器人导航提供了有意义的评估工具，但需要进一步讨论其适用性、设计选择和局限性。

Abstract: In Social Robot Navigation (SRN), the availability of meaningful metrics is
crucial for evaluating trajectories from human-robot interactions. In the SRN
context, such interactions often relate to resolving conflicts between two or
more agents. Correspondingly, the shares to which agents contribute to the
resolution of such conflicts are important. This paper builds on recent work,
which proposed a Responsibility metric capturing such shares. We extend this
framework in two directions: First, we model the conflict buildup phase by
introducing a time normalization. Second, we propose the related Engagement
metric, which captures how the agents' actions intensify a conflict. In a
comprehensive series of simulated scenarios with dyadic, group and crowd
interactions, we show that the metrics carry meaningful information about the
cooperative resolution of conflicts in interactions. They can be used to assess
behavior quality and foresightedness. We extensively discuss applicability,
design choices and limitations of the proposed metrics.

</details>


### [33] [Spotting the Unfriendly Robot -- Towards better Metrics for Interactions](https://arxiv.org/abs/2509.12912)
*Raphael Wenzel,Malte Probst*

Main category: cs.RO

TL;DR: 提出了两个新的社交机器人导航评估指标：冲突强度指标和责任指标，用于量化机器人在与人类交互中的合作行为，解决现有指标无法评估合作程度的问题。


<details>
  <summary>Details</summary>
Motivation: 当前社交机器人导航评估指标缺乏量化机器人合作行为的能力，无法判断在交互中是双方合作还是一方被迫避让，需要新的指标来全面评估人机交互质量。

Method: 提出冲突强度指标来评估冲突减少的程度，以及责任指标来确定哪个主体承担了解决冲突的责任，这两个指标共同评估人机交互质量。

Result: 开发了能够评估算法在减少冲突中的贡献程度以及确定责任主体的新指标，为社交机器人导航提供了更全面的评估方法。

Conclusion: 这些新指标有助于建立标准化、全面的社交机器人导航评估方法，最终提升机器人在人本环境中的安全性、效率和社交接受度。

Abstract: Establishing standardized metrics for Social Robot Navigation (SRN)
algorithms for assessing the quality and social compliance of robot behavior
around humans is essential for SRN research. Currently, commonly used
evaluation metrics lack the ability to quantify how cooperative an agent
behaves in interaction with humans. Concretely, in a simple frontal approach
scenario, no metric specifically captures if both agents cooperate or if one
agent stays on collision course and the other agent is forced to evade. To
address this limitation, we propose two new metrics, a conflict intensity
metric and the responsibility metric. Together, these metrics are capable of
evaluating the quality of human-robot interactions by showing how much a given
algorithm has contributed to reducing a conflict and which agent actually took
responsibility of the resolution. This work aims to contribute to the
development of a comprehensive and standardized evaluation methodology for SRN,
ultimately enhancing the safety, efficiency, and social acceptance of robots in
human-centric environments.

</details>


### [34] [Spatiotemporal Calibration for Laser Vision Sensor in Hand-eye System Based on Straight-line Constraint](https://arxiv.org/abs/2509.12928)
*Peiwen Yang,Mingquan Jiang,Xinyue Shen,Heping Zhang*

Main category: cs.RO

TL;DR: 本文提出一种无需教学的时空标定方法，通过线性约束和非线性优化解决激光视觉传感器的时间偏移和手眼外参变化问题。


<details>
  <summary>Details</summary>
Motivation: 激光视觉传感器在熠接应用中存在相机通信延迟导致的时间同步问题，以及长期测量中手眼外参变化的挑战。

Method: 利用S形轨迹扫描直线角熠缘，通过Plucker坐标表示直线约束，并建立非线性优化模型，使用LMA算法优化时间偏移、手眼外参和直线参数。

Result: 通过曲线熠缘扫描实验，定量验证了方法的可行性和精度。

Conclusion: 该方法能够有效解决LVS测量中的时空同步问题，并已开源相关代码和数据集。

Abstract: Laser vision sensors (LVS) are critical perception modules for industrial
robots, facilitating real-time acquisition of workpiece geometric data in
welding applications. However, the camera communication delay will lead to a
temporal desynchronization between captured images and the robot motions.
Additionally, hand-eye extrinsic parameters may vary during prolonged
measurement. To address these issues, we introduce a measurement model of LVS
considering the effect of the camera's time-offset and propose a teaching-free
spatiotemporal calibration method utilizing line constraints. This method
involves a robot equipped with an LVS repeatedly scanning straight-line fillet
welds using S-shaped trajectories. Regardless of the robot's orientation
changes, all measured welding positions are constrained to a straight-line,
represented by Plucker coordinates. Moreover, a nonlinear optimization model
based on straight-line constraints is established. Subsequently, the
Levenberg-Marquardt algorithm (LMA) is employed to optimize parameters,
including time-offset, hand-eye extrinsic parameters, and straight-line
parameters. The feasibility and accuracy of the proposed approach are
quantitatively validated through experiments on curved weld scanning. We
open-sourced the code, dataset, and simulation report at
https://anonymous.4open.science/r/LVS_ST_CALIB-015F/README.md.

</details>


### [35] [Tendon-Based Proprioception in an Anthropomorphic Underactuated Robotic Hand with Series Elastic Actuators](https://arxiv.org/abs/2509.12969)
*Jae-Hyun Lee,Jonghoo Park,Kyu-Jin Cho*

Main category: cs.RO

TL;DR: 提出了一种基于肌腱本体感知的拟人欠驱动手，通过串联弹性执行器实现全面的手-物体交互状态感知，无需视觉或触觉反馈即可完成抓取重建、柔性物体处理和盲抓等功能。


<details>
  <summary>Details</summary>
Motivation: 拟人欠驱动手因其多功能性和结构简单性被广泛应用，但紧凑的传感集成和与欠驱动机制匹配的感知解释对于实现实用抓取功能至关重要。

Method: 开发了高精度可靠的紧凑型串联弹性执行器(SEA)，将其集成到无传感器手指中。通过肌腱本体感知与基于势能的建模相结合，估计接触时机、关节角度、物体相对刚度和指示外部干扰的手指构型变化等关键抓取变量。

Result: 手指级实验和手级演示验证了该方法的有效性，证明肌腱本体感知可作为紧凑且鲁棒的传感方式，在不依赖视觉或触觉反馈的情况下实现实用操作。

Conclusion: 肌腱本体感知为欠驱动手提供了一种紧凑可靠的传感解决方案，能够实现全面的抓取状态感知和多种实用操作功能。

Abstract: Anthropomorphic underactuated hands are widely employed for their versatility
and structural simplicity. In such systems, compact sensing integration and
proper interpretation aligned with underactuation are crucial for realizing
practical grasp functionalities. This study proposes an anthropomorphic
underactuated hand that achieves comprehensive situational awareness of
hand-object interaction, utilizing tendon-based proprioception provided by
series elastic actuators (SEAs). We developed a compact SEA with high accuracy
and reliability that can be seamlessly integrated into sensorless fingers. By
coupling proprioceptive sensing with potential energy-based modeling, the
system estimates key grasp-related variables, including contact timing, joint
angles, relative object stiffness, and finger configuration changes indicating
external disturbances. These estimated variables enable grasp posture
reconstruction, safe handling of deformable objects, and blind grasping with
proprioceptive-only recognition of objects with varying geometry and stiffness.
Finger-level experiments and hand-level demonstrations confirmed the
effectiveness of the proposed approach. The results demonstrate that
tendon-based proprioception serves as a compact and robust sensing modality for
practical manipulation without reliance on vision or tactile feedback.

</details>


### [36] [Out of Distribution Detection in Self-adaptive Robots with AI-powered Digital Twins](https://arxiv.org/abs/2509.12982)
*Erblin Isaku,Hassan Sartaj,Shaukat Ali,Beatriz Sanguino,Tongtong Wang,Guoyuan Li,Houxiang Zhang,Thomas Peyrucain*

Main category: cs.RO

TL;DR: 提出了基于数字孪生的ODiSAR方法，使用Transformer模型预测机器人状态，结合重构误差和蒙特卡洛dropout进行不确定性量化，有效检测未知异常行为


<details>
  <summary>Details</summary>
Motivation: 复杂不确定环境中的自适应机器人需要主动检测和处理异常行为，包括分布外(OOD)情况，数字孪生为此提供了有价值的解决方案

Method: 使用基于Transformer的数字孪生预测机器人状态，采用重构误差和蒙特卡洛dropout进行不确定性量化，结合重构误差和预测方差来检测OOD行为，并包含可解释性层

Result: 在两个工业机器人案例中（办公室导航和船舶导航），ODiSAR实现了高达98% AUROC、96% TNR@TPR95和95% F1-score的高检测性能

Conclusion: ODiSAR方法能够有效检测未知条件下的异常行为，并提供可解释的见解来支持自适应决策，在机器人异常检测方面表现出色

Abstract: Self-adaptive robots (SARs) in complex, uncertain environments must
proactively detect and address abnormal behaviors, including
out-of-distribution (OOD) cases. To this end, digital twins offer a valuable
solution for OOD detection. Thus, we present a digital twin-based approach for
OOD detection (ODiSAR) in SARs. ODiSAR uses a Transformer-based digital twin to
forecast SAR states and employs reconstruction error and Monte Carlo dropout
for uncertainty quantification. By combining reconstruction error with
predictive variance, the digital twin effectively detects OOD behaviors, even
in previously unseen conditions. The digital twin also includes an
explainability layer that links potential OOD to specific SAR states, offering
insights for self-adaptation. We evaluated ODiSAR by creating digital twins of
two industrial robots: one navigating an office environment, and another
performing maritime ship navigation. In both cases, ODiSAR forecasts SAR
behaviors (i.e., robot trajectories and vessel motion) and proactively detects
OOD events. Our results showed that ODiSAR achieved high detection performance
-- up to 98\% AUROC, 96\% TNR@TPR95, and 95\% F1-score -- while providing
interpretable insights to support self-adaptation.

</details>


### [37] [DVDP: An End-to-End Policy for Mobile Robot Visual Docking with RGB-D Perception](https://arxiv.org/abs/2509.13024)
*Haohan Min,Zhoujian Li,Yu Yang,Jinyu Chen,Shenghai Yuan*

Main category: cs.RO

TL;DR: 一种名为DVDP的突破性端到端视觉坠落方法，仅需双目RGB-D摄像头即可直接输出机器人坠落路径，充分结合虚拟与实际环境数据集，在实际部署中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统视觉坠落方法对机器人初始位置要求过于严格的限制，提高自动坠落的灵活性和可靠性。

Method: 提出DVDP端到端视觉坠落策略，使用双目RGB-D摄像头直接生成坠落路径，通过Unity 3D平台和实际机器人系统收集大规模虚实结合数据集，并开发了专门评价指标。

Result: 实验结果显示该方法在性能上超过了领先的感知核心等方法，实际部署在SCOUT Mini机器人上生成了平滑、可行的坠落轨迹，满足物理约束并准确到达目标位姿。

Conclusion: DVDP方法为移动机器人自动坠落提供了一种精度高、成本低、部署简单的有效解决方案，具有强大的应用潜力。

Abstract: Automatic docking has long been a significant challenge in the field of
mobile robotics. Compared to other automatic docking methods, visual docking
methods offer higher precision and lower deployment costs, making them an
efficient and promising choice for this task. However, visual docking methods
impose strict requirements on the robot's initial position at the start of the
docking process. To overcome the limitations of current vision-based methods,
we propose an innovative end-to-end visual docking method named DVDP(direct
visual docking policy). This approach requires only a binocular RGB-D camera
installed on the mobile robot to directly output the robot's docking path,
achieving end-to-end automatic docking. Furthermore, we have collected a
large-scale dataset of mobile robot visual automatic docking dataset through a
combination of virtual and real environments using the Unity 3D platform and
actual mobile robot setups. We developed a series of evaluation metrics to
quantify the performance of the end-to-end visual docking method. Extensive
experiments, including benchmarks against leading perception backbones adapted
into our framework, demonstrate that our method achieves superior performance.
Finally, real-world deployment on the SCOUT Mini confirmed DVDP's efficacy,
with our model generating smooth, feasible docking trajectories that meet
physical constraints and reach the target pose.

</details>


### [38] [Practical Handling of Dynamic Environments in Decentralised Multi-Robot Patrol](https://arxiv.org/abs/2509.13069)
*James C. Ward,Arthur Richards,Edmund R. Hunt*

Main category: cs.RO

TL;DR: 多机器人巡進团队在高度动态环境中进行持续监控的分布式在线方法，能够直接观测并适应路径可通行性变化


<details>
  <summary>Details</summary>
Motivation: 实现坚固、适应性和可扩展性的分布式在线监控方案，应对高度动态环境中路径可通行性的实时变化

Method: 提出了一种新的监控和调整环境动态的分布式方法，允许巡進机器人在分布式在线方式下观测并适应路径可通行性变化

Result: 在高度动态场景中显著超过了实际基准方法，同时研究了某些动态场景下明确考虑环境动态可能不必要或不实用的情况

Conclusion: 该分布式方法在动态环境中实现了高效的持续监控，为多机器人巡進系统提供了坚固的在线适应能力

Abstract: Persistent monitoring using robot teams is of interest in fields such as
security, environmental monitoring, and disaster recovery. Performing such
monitoring in a fully on-line decentralised fashion has significant potential
advantages for robustness, adaptability, and scalability of monitoring
solutions, including, in principle, the capacity to effectively adapt in
real-time to a changing environment. We examine this through the lens of
multi-robot patrol, in which teams of patrol robots must persistently minimise
time between visits to points of interest, within environments where
traversability of routes is highly dynamic. These dynamics must be observed by
patrol agents and accounted for in a fully decentralised on-line manner. In
this work, we present a new method of monitoring and adjusting for environment
dynamics in a decentralised multi-robot patrol team. We demonstrate that our
method significantly outperforms realistic baselines in highly dynamic
scenarios, and also investigate dynamic scenarios in which explicitly
accounting for environment dynamics may be unnecessary or impractical.

</details>


### [39] [Beyond Anthropomorphism: Enhancing Grasping and Eliminating a Degree of Freedom by Fusing the Abduction of Digits Four and Five](https://arxiv.org/abs/2509.13074)
*Simon Fritsch,Liam Achenbach,Riccardo Bianco,Nicola Irmiger,Gawain Marti,Samuel Visca,Chenyu Yang,Davide Liconti,Barnabas Gavin Cangan,Robert Jomar Malate,Ronan J. Hinchet,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: SABD机械手通过将第四和第五手指的内收/外展关节合并为单个大范围运动关节，实现了400%工作空间扩展和自由度减少，同时保持灵巧性，能够抓取200mm宽物体并提高抓取稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统仿人机械手设计限制了抓取范围和操作能力，需要开发非纯仿人设计来扩展抓取包络、实现超人类操作姿势并减少执行器数量。

Method: 将第四和第五手指的内收/外展关节合并为单个具有大范围运动的关节，结合强化学习进行抓取策略研究，并通过遥操作实验验证性能。

Result: 合并关节使手指工作空间扩大400%，可抓取侧向距离达200mm的物体，在YCB物体上实现86%的成功抓取率，包括非仿人配置的挑战性抓取。

Conclusion: 该设计在不增加复杂性的情况下增强了抓取稳定性、灵活性和灵巧操作能力，适用于广泛的应用场景。

Abstract: This paper presents the SABD hand, a 16-degree-of-freedom (DoF) robotic hand
that departs from purely anthropomorphic designs to achieve an expanded grasp
envelope, enable manipulation poses beyond human capability, and reduce the
required number of actuators. This is achieved by combining the
adduction/abduction (Add/Abd) joint of digits four and five into a single joint
with a large range of motion. The combined joint increases the workspace of the
digits by 400\% and reduces the required DoFs while retaining dexterity.
Experimental results demonstrate that the combined Add/Abd joint enables the
hand to grasp objects with a side distance of up to 200 mm. Reinforcement
learning-based investigations show that the design enables grasping policies
that are effective not only for handling larger objects but also for achieving
enhanced grasp stability. In teleoperated trials, the hand successfully
performed 86\% of attempted grasps on suitable YCB objects, including
challenging non-anthropomorphic configurations. These findings validate the
design's ability to enhance grasp stability, flexibility, and dexterous
manipulation without added complexity, making it well-suited for a wide range
of applications.

</details>


### [40] [A Design Co-Pilot for Task-Tailored Manipulators](https://arxiv.org/abs/2509.13077)
*Jonathan Külz,Sehoon Ha,Matthias Althoff*

Main category: cs.RO

TL;DR: 提出了一种自动设计和优化机器人形态的完全可微分框架，能够快速生成针对特定环境的定制化机器人设计，将设计时间从小时级缩短到秒级。


<details>
  <summary>Details</summary>
Motivation: 传统机器人制造商采用"一刀切"策略，通用设计无法充分利用任务特性导致性能次优。定制化机器人开发周期长、成本高，需要克服人工工程瓶颈。

Method: 学习多种机械臂的逆运动学，建立完全可微分框架实现梯度基础的机器人形态微调和逆运动学解决方案优化。采用生成式方法加速专用设计生成。

Result: 方法能够找到可在杂乱环境中导航的机器人、在指定工作空间表现良好的机械臂，并能适应不同的硬件约束。通过模块化机器人实物验证了仿真设计的实际应用效果。

Conclusion: 该方法作为设计协同助手，实现了即时适应和有效的人机协作，显著加速了任务定制化机器人的设计过程，具有实际应用价值。

Abstract: Although robotic manipulators are used in an ever-growing range of
applications, robot manufacturers typically follow a ``one-fits-all''
philosophy, employing identical manipulators in various settings. This often
leads to suboptimal performance, as general-purpose designs fail to exploit
particularities of tasks. The development of custom, task-tailored robots is
hindered by long, cost-intensive development cycles and the high cost of
customized hardware. Recently, various computational design methods have been
devised to overcome the bottleneck of human engineering. In addition, a surge
of modular robots allows quick and economical adaptation to changing industrial
settings. This work proposes an approach to automatically designing and
optimizing robot morphologies tailored to a specific environment. To this end,
we learn the inverse kinematics for a wide range of different manipulators. A
fully differentiable framework realizes gradient-based fine-tuning of designed
robots and inverse kinematics solutions. Our generative approach accelerates
the generation of specialized designs from hours with optimization-based
methods to seconds, serving as a design co-pilot that enables instant
adaptation and effective human-AI collaboration. Numerical experiments show
that our approach finds robots that can navigate cluttered environments,
manipulators that perform well across a specified workspace, and can be adapted
to different hardware constraints. Finally, we demonstrate the real-world
applicability of our method by setting up a modular robot designed in
simulation that successfully moves through an obstacle course.

</details>


### [41] [Empowering Multi-Robot Cooperation via Sequential World Models](https://arxiv.org/abs/2509.13095)
*Zijie Zhao,Honglei Guo,Shengqian Chen,Kaixuan Xu,Bo Jiang,Yuanheng Zhu,Dongbin Zhao*

Main category: cs.RO

TL;DR: SeqWM是一个基于序列化世界模型的强化学习框架，通过独立agent-wise模型分解复杂联合动力学，实现多机器人协作中的高效意图共享和线性通信复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人协作中联合动力学复杂性的挑战，提高模型基强化学习在多智能体环境中的适用性和效率。

Method: 采用序列化结构，每个agent建立独立的世界模型，通过顺序通信进行潜在状态推演和决策，前序agent预测轨迹供后续agent规划行动。

Result: 在Bi-DexHands和Multi-Quad仿真环境中超越现有模型基和无模型方法，表现出预测适应和角色分工等高级协作行为，并在真实四足机器人上成功部署。

Conclusion: SeqWM框架有效解决了多机器人协作的复杂性，实现了高效的样本利用和通信效率，为现实世界多机器人系统提供了可行的解决方案。

Abstract: Model-based reinforcement learning (MBRL) has shown significant potential in
robotics due to its high sample efficiency and planning capability. However,
extending MBRL to multi-robot cooperation remains challenging due to the
complexity of joint dynamics. To address this, we propose the Sequential World
Model (SeqWM), a novel framework that integrates the sequential paradigm into
model-based multi-agent reinforcement learning. SeqWM employs independent,
sequentially structured agent-wise world models to decompose complex joint
dynamics. Latent rollouts and decision-making are performed through sequential
communication, where each agent generates its future trajectory and plans its
actions based on the predictions of its predecessors. This design enables
explicit intention sharing, enhancing cooperative performance, and reduces
communication overhead to linear complexity. Results in challenging simulated
environments (Bi-DexHands and Multi-Quad) show that SeqWM outperforms existing
state-of-the-art model-free and model-based baselines in both overall
performance and sample efficiency, while exhibiting advanced cooperative
behaviors such as predictive adaptation and role division. Furthermore, SeqWM
has been success fully deployed on physical quadruped robots, demonstrating its
effectiveness in real-world multi-robot systems. Demos and code are available
at: https://github.com/zhaozijie2022/seqwm-marl

</details>


### [42] [Model Predictive Control with Reference Learning for Soft Robotic Intracranial Pressure Waveform Modulation](https://arxiv.org/abs/2509.13109)
*Fabian Flürenbrock,Yanick Büchel,Johannes Köhler,Marianne Schmid Daners,Melanie N. Zeilinger*

Main category: cs.RO

TL;DR: 基于学习的软体机器人控制框架，用于调节颅内压波形，结合模型预测控制和贝叶斯优化算法，在脑模型实验中实现了精确的电机位置跟踪和期望的ICP波形调制


<details>
  <summary>Details</summary>
Motivation: 研究脑脊液动力学和神经系统疾病病理过程需要对颅内压(ICP)波形进行精确调制，但ICP与电机位置之间存在未知的非线性依赖关系，需要开发安全有效的控制框架

Method: 提出两层控制框架：第一层使用带扰动观测器的模型预测控制器(MPC)在安全约束下实现电机位置参考轨迹的无偏跟踪；第二层使用贝叶斯优化(BO)算法在线学习能够产生期望ICP调制的电机位置参考轨迹

Result: 实验验证显示，MPC相比PID控制器将平均和最大电机位置跟踪误差分别降低了83%和73%；BO算法在不到20次迭代内就能学习到产生期望平均值和幅度的ICP波形的电机位置参考轨迹

Conclusion: 该学习型控制框架能够安全有效地实现期望的ICP波形调制，为研究脑脊液动力学和神经系统疾病提供了有力的实验工具

Abstract: This paper introduces a learning-based control framework for a soft robotic
actuator system designed to modulate intracranial pressure (ICP) waveforms,
which is essential for studying cerebrospinal fluid dynamics and pathological
processes underlying neurological disorders. A two-layer framework is proposed
to safely achieve a desired ICP waveform modulation. First, a model predictive
controller (MPC) with a disturbance observer is used for offset-free tracking
of the system's motor position reference trajectory under safety constraints.
Second, to address the unknown nonlinear dependence of ICP on the motor
position, we employ a Bayesian optimization (BO) algorithm used for online
learning of a motor position reference trajectory that yields the desired ICP
modulation. The framework is experimentally validated using a test bench with a
brain phantom that replicates realistic ICP dynamics in vitro. Compared to a
previously employed proportional-integral-derivative controller, the MPC
reduces mean and maximum motor position reference tracking errors by 83 % and
73 %, respectively. In less than 20 iterations, the BO algorithm learns a motor
position reference trajectory that yields an ICP waveform with the desired mean
and amplitude.

</details>


### [43] [Hydrosoft: Non-Holonomic Hydroelastic Models for Compliant Tactile Manipulation](https://arxiv.org/abs/2509.13126)
*Miquel Oller,An Dang,Nima Fazeli*

Main category: cs.RO

TL;DR: 提出了一种计算高效的非完整水弹性模型，用于准确建模触觉传感器的路径依赖接触力分布和动态表面积变化，解决了柔性传感器复杂非线性动力学的建模挑战。


<details>
  <summary>Details</summary>
Motivation: 触觉传感器虽然具有出色的感知能力，但其固有的柔顺性带来的复杂非线性动力学特性尚未得到充分探索，需要解决被动柔顺元件引入的路径依赖行为建模问题。

Method: 扩展物体的状态空间，显式包含柔性传感器产生的分布式力，采用可微分的水弹性模型公式，支持基于梯度的轨迹优化，并与高分辨率触觉反馈无缝集成。

Result: 在模拟和真实世界实验中证明了方法的有效性，成功建模了传感器动力学的路径依赖性，实现了准确的接触力分布和动态表面积变化预测。

Conclusion: 建模传感器动力学的路径依赖性至关重要，提出的非完整水弹性模型为柔性触觉传感器的精确建模提供了有效的解决方案，支持梯度优化和实时触觉反馈集成。

Abstract: Tactile sensors have long been valued for their perceptual capabilities,
offering rich insights into the otherwise hidden interface between the robot
and grasped objects. Yet their inherent compliance -- a key driver of
force-rich interactions -- remains underexplored. The central challenge is to
capture the complex, nonlinear dynamics introduced by these passive-compliant
elements. Here, we present a computationally efficient non-holonomic
hydroelastic model that accurately models path-dependent contact force
distributions and dynamic surface area variations. Our insight is to extend the
object's state space, explicitly incorporating the distributed forces generated
by the compliant sensor. Our differentiable formulation not only accounts for
path-dependent behavior but also enables gradient-based trajectory
optimization, seamlessly integrating with high-resolution tactile feedback. We
demonstrate the effectiveness of our approach across a range of simulated and
real-world experiments and highlight the importance of modeling the path
dependence of sensor dynamics.

</details>


### [44] [An Uncertainty-Weighted Decision Transformer for Navigation in Dense, Complex Driving Scenarios](https://arxiv.org/abs/2509.13132)
*Zhihao Zhang,Chengyang Peng,Minghao Zhu,Ekim Yurtsever,Keith A. Redmill*

Main category: cs.RO

TL;DR: 提出不确定性加权决策变换器(UWDT)，通过多通道鸟瞰图占用网格和变换器序列建模，在复杂环岛场景中实现更安全高效的自动驾驶决策


<details>
  <summary>Details</summary>
Motivation: 密集动态环境中的自动驾驶需要能够利用空间结构和长时域时间依赖性的决策系统，同时保持对不确定性的鲁棒性，特别是要解决频繁低风险状态和罕见安全关键决策之间的不平衡问题

Method: UWDT框架集成多通道鸟瞰图占用网格与基于变换器的序列建模，使用冻结教师变换器估计每令牌预测熵，作为学生模型损失函数的权重，增强对不确定高影响状态的学习

Result: 在环岛模拟器中，UWDT在不同交通密度下始终优于其他基线方法，在奖励、碰撞率和行为稳定性方面表现更好

Conclusion: 不确定性感知的时空变换器能够在复杂交通环境中为自动驾驶提供更安全高效的决策

Abstract: Autonomous driving in dense, dynamic environments requires decision-making
systems that can exploit both spatial structure and long-horizon temporal
dependencies while remaining robust to uncertainty. This work presents a novel
framework that integrates multi-channel bird's-eye-view occupancy grids with
transformer-based sequence modeling for tactical driving in complex roundabout
scenarios. To address the imbalance between frequent low-risk states and rare
safety-critical decisions, we propose the Uncertainty-Weighted Decision
Transformer (UWDT). UWDT employs a frozen teacher transformer to estimate
per-token predictive entropy, which is then used as a weight in the student
model's loss function. This mechanism amplifies learning from uncertain,
high-impact states while maintaining stability across common low-risk
transitions. Experiments in a roundabout simulator, across varying traffic
densities, show that UWDT consistently outperforms other baselines in terms of
reward, collision rate, and behavioral stability. The results demonstrate that
uncertainty-aware, spatial-temporal transformers can deliver safer and more
efficient decision-making for autonomous driving in complex traffic
environments.

</details>


### [45] [TeraSim-World: Worldwide Safety-Critical Data Synthesis for End-to-End Autonomous Driving](https://arxiv.org/abs/2509.13164)
*Jiawei Wang,Haowei Sun,Xintao Yan,Shuo Feng,Jun Gao,Henry X. Liu*

Main category: cs.RO

TL;DR: TeraSim-World是一个自动化管道，用于在全球任何地方合成逼真且地理多样化的安全关键数据，用于端到端自动驾驶的训练和评估。


<details>
  <summary>Details</summary>
Motivation: 端到端自动驾驶的安全和可扩展部署需要大量多样化数据，特别是安全关键事件。现有数据主要来自模拟器（存在显著的模拟到真实差距）或道路测试（成本高且不安全）。

Method: 从任意位置开始，TeraSim-World从地理空间数据源检索真实世界地图和交通需求，从自然驾驶数据集中模拟智能体行为，编排多样化逆境创建极端情况，并通过视频生成模型Cosmos-Drive实现逼真的地理接地传感器渲染。

Result: 通过桥接智能体和传感器模拟，TeraSim-World为端到端自动驾驶系统提供了一个可扩展的关键数据合成框架。

Conclusion: TeraSim-World解决了自动驾驶数据获取的挑战，提供了一个能够合成全球范围内逼真安全关键数据的自动化解决方案。

Abstract: Safe and scalable deployment of end-to-end (E2E) autonomous driving requires
extensive and diverse data, particularly safety-critical events. Existing data
are mostly generated from simulators with a significant sim-to-real gap or
collected from on-road testing that is costly and unsafe. This paper presents
TeraSim-World, an automated pipeline that synthesizes realistic and
geographically diverse safety-critical data for E2E autonomous driving at
anywhere in the world. Starting from an arbitrary location, TeraSim-World
retrieves real-world maps and traffic demand from geospatial data sources.
Then, it simulates agent behaviors from naturalistic driving datasets, and
orchestrates diverse adversities to create corner cases. Informed by street
views of the same location, it achieves photorealistic, geographically grounded
sensor rendering via the frontier video generation model Cosmos-Drive. By
bridging agent and sensor simulations, TeraSim-World provides a scalable and
critical~data synthesis framework for training and evaluation of E2E autonomous
driving systems.

</details>


### [46] [ROOM: A Physics-Based Continuum Robot Simulator for Photorealistic Medical Datasets Generation](https://arxiv.org/abs/2509.13177)
*Salvatore Esposito,Matías Mattamala,Daniel Rebain,Francis Xiatian Zhang,Kevin Dhaliwal,Mohsen Khadem,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: ROOM是一个用于生成逼真支气管镜训练数据的综合仿真框架，通过患者CT扫描渲染多模态传感器数据，解决了医学机器人开发中真实数据收集困难的问题。


<details>
  <summary>Details</summary>
Motivation: 连续体机器人在支气管镜检查中具有重要应用价值，但其发展受到缺乏真实训练和测试环境的限制，真实数据收集存在伦理约束和患者安全顾虑。

Method: 利用患者CT扫描，构建仿真管道渲染多模态传感器数据，包括RGB图像、深度图、表面法线、光流和点云等，并在医学相关尺度上保持真实性。

Result: 验证了ROOM生成的数据在多视角姿态估计和单目深度估计等医学机器人核心任务中的有效性，能够用于微调现有深度估计模型并支持导航等下游应用。

Conclusion: ROOM框架能够在大规模患者解剖结构和程序场景中生成多样化数据，解决了临床环境中难以捕获的数据需求问题，有望推动医学机器人技术的发展。

Abstract: Continuum robots are advancing bronchoscopy procedures by accessing complex
lung airways and enabling targeted interventions. However, their development is
limited by the lack of realistic training and test environments: Real data is
difficult to collect due to ethical constraints and patient safety concerns,
and developing autonomy algorithms requires realistic imaging and physical
feedback. We present ROOM (Realistic Optical Observation in Medicine), a
comprehensive simulation framework designed for generating photorealistic
bronchoscopy training data. By leveraging patient CT scans, our pipeline
renders multi-modal sensor data including RGB images with realistic noise and
light specularities, metric depth maps, surface normals, optical flow and point
clouds at medically relevant scales. We validate the data generated by ROOM in
two canonical tasks for medical robotics -- multi-view pose estimation and
monocular depth estimation, demonstrating diverse challenges that
state-of-the-art methods must overcome to transfer to these medical settings.
Furthermore, we show that the data produced by ROOM can be used to fine-tune
existing depth estimation models to overcome these challenges, also enabling
other downstream applications such as navigation. We expect that ROOM will
enable large-scale data generation across diverse patient anatomies and
procedural scenarios that are challenging to capture in clinical settings. Code
and data: https://github.com/iamsalvatore/room.

</details>


### [47] [StageACT: Stage-Conditioned Imitation for Robust Humanoid Door Opening](https://arxiv.org/abs/2509.13200)
*Moonyoung Lee,Dong Ki Kim,Jai Krishna Bandi,Max Smith,Aileen Liao,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: StageACT是一个阶段条件模仿学习框架，通过为低级策略添加任务阶段输入来解决人形机器人开门任务中的部分可观测性问题，在真实办公室环境中对未见过的门实现了55%的成功率，比最佳基线提高了一倍多。


<details>
  <summary>Details</summary>
Motivation: 人形机器人需要在人类环境中操作，开门是基本但具有挑战性的技能。开门任务具有长时程和部分可观测性的特点，特别是门闩状态不可观测，导致标准行为克隆容易出现模式崩溃问题。

Method: 提出了StageACT框架，通过为低级策略增加任务阶段输入来增强对部分可观测性的鲁棒性。该方法支持通过阶段提示进行有意行为引导，实现恢复行为。

Result: 在真实办公室环境中，StageACT对未见过的门实现了55%的成功率，比最佳基线提高了一倍多，同时缩短了完成时间。

Conclusion: 阶段条件化是一种轻量级但强大的机制，适用于长时程人形机器人定位操作任务。

Abstract: Humanoid robots promise to operate in everyday human environments without
requiring modifications to the surroundings. Among the many skills needed,
opening doors is essential, as doors are the most common gateways in built
spaces and often limit where a robot can go. Door opening, however, poses
unique challenges as it is a long-horizon task under partial observability,
such as reasoning about the door's unobservable latch state that dictates
whether the robot should rotate the handle or push the door. This ambiguity
makes standard behavior cloning prone to mode collapse, yielding blended or
out-of-sequence actions. We introduce StageACT, a stage-conditioned imitation
learning framework that augments low-level policies with task-stage inputs.
This effective addition increases robustness to partial observability, leading
to higher success rates and shorter completion times. On a humanoid operating
in a real-world office environment, StageACT achieves a 55% success rate on
previously unseen doors, more than doubling the best baseline. Moreover, our
method supports intentional behavior guidance through stage prompting, enabling
recovery behaviors. These results highlight stage conditioning as a lightweight
yet powerful mechanism for long-horizon humanoid loco-manipulation.

</details>


### [48] [Collaborative Loco-Manipulation for Pick-and-Place Tasks with Dynamic Reward Curriculum](https://arxiv.org/abs/2509.13239)
*Tianxu An,Flavio De Vincenti,Yuntao Ma,Marco Hutter,Stelian Coros*

Main category: cs.RO

TL;DR: 提出了一种分层强化学习框架，用于训练单臂腿式机器人执行端到端的拾取放置任务，在单机器人和双机器人协作场景中均有效，通过动态奖励课程提高了55%的训练效率和18.6%的执行效率。


<details>
  <summary>Details</summary>
Motivation: 解决腿式机器人在长时程拾取放置任务中的训练效率问题，特别是在协作场景中需要协调多个机器人的挑战。

Method: 采用分层强化学习框架，引入新颖的动态奖励课程机制，通过逐步引导智能体完成以载荷为中心的子目标来学习长时程操作。

Result: 在仿真实验中相比最先进方法提升55%训练效率和18.6%执行效率；在双机器人场景中实现了自主注意力转移的有效协调；在ANYmal D平台上进行了真实世界验证。

Conclusion: 这是首个能够处理两个腿式机械臂完整协作拾取放置任务的强化学习框架，在单机和多机场景中都表现出色。

Abstract: We present a hierarchical RL pipeline for training one-armed legged robots to
perform pick-and-place (P&P) tasks end-to-end -- from approaching the payload
to releasing it at a target area -- in both single-robot and cooperative
dual-robot settings. We introduce a novel dynamic reward curriculum that
enables a single policy to efficiently learn long-horizon P&P operations by
progressively guiding the agents through payload-centered sub-objectives.
Compared to state-of-the-art approaches for long-horizon RL tasks, our method
improves training efficiency by 55% and reduces execution time by 18.6% in
simulation experiments. In the dual-robot case, we show that our policy enables
each robot to attend to different components of its observation space at
distinct task stages, promoting effective coordination via autonomous attention
shifts. We validate our method through real-world experiments using ANYmal D
platforms in both single- and dual-robot scenarios. To our knowledge, this is
the first RL pipeline that tackles the full scope of collaborative P&P with two
legged manipulators.

</details>


### [49] [Design and Control of a Perching Drone Inspired by the Prey-Capturing Mechanism of Venus Flytrap](https://arxiv.org/abs/2509.13249)
*Ye Li,Daming Liu,Yanhe Zhu,Junming Zhang,Yongsheng Luo,Ziqi Wang,Chenyu Liu,Jie Zhao*

Main category: cs.RO

TL;DR: 提出了一种受捕蝇草启发的主动柔性栖息无人机，可在100毫秒内完成栖息，采用级联高增益观测器控制方法实时补偿外部扰动，实验验证了系统的高速适应性和抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 无人机续航和能效是关键挑战，通过栖息机制可以节省能量。现有研究探索了各种栖息方式，但需要更快速、适应性更强的栖息解决方案。

Method: 设计仿生栖息结构，受捕蝇草快速捕食机制启发；开发级联扩展高增益观测器（EHGO）控制方法，实时估计和补偿外部扰动；进行系统整体设计和验证。

Result: 栖息时间小于100毫秒；栖息结构具有良好的适应性；级联EHGO控制方法能有效抵抗风和栖息扰动；实验证明了系统的优越性能。

Conclusion: 该仿生栖息无人机系统实现了快速、稳定的栖息能力，级联EHGO控制方法显著提升了系统抗干扰性能，为延长无人机任务时间提供了有效解决方案。

Abstract: The endurance and energy efficiency of drones remain critical challenges in
their design and operation. To extend mission duration, numerous studies
explored perching mechanisms that enable drones to conserve energy by
temporarily suspending flight. This paper presents a new perching drone that
utilizes an active flexible perching mechanism inspired by the rapid predation
mechanism of the Venus flytrap, achieving perching in less than 100 ms. The
proposed system is designed for high-speed adaptability to the perching
targets. The overall drone design is outlined, followed by the development and
validation of the biomimetic perching structure. To enhance the system
stability, a cascade extended high-gain observer (EHGO) based control method is
developed, which can estimate and compensate for the external disturbance in
real time. The experimental results demonstrate the adaptability of the
perching structure and the superiority of the cascaded EHGO in resisting wind
and perching disturbances.

</details>


### [50] [HARMONIC: A Content-Centric Cognitive Robotic Architecture](https://arxiv.org/abs/2509.13279)
*Sanjay Oruganti,Sergei Nirenburg,Marjorie McShane,Jesse English,Michael K. Roberts,Christian Arndt,Carlos Gonzalez,Mingyo Seo,Luis Sentis*

Main category: cs.RO

TL;DR: HARMONIC是一个认知机器人架构，用于人机协作团队中的机器人，支持语义感知、类人决策和意向性语言通信，旨在解决数据稀缺、可解释性和安全问题。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作团队中机器人的安全性、结果质量问题，以及数据稀缺、可解释性和安全性等挑战，促进透明度和信任。

Method: 开发HARMONIC认知机器人架构，支持语义感知解释、类人决策和意向性语言通信，并在高保真仿真环境和物理机器人平台上实现两个概念验证系统。

Result: 成功开发并演示了两个基于HARMONIC的机器人系统，分别在仿真环境和物理平台上实现。

Conclusion: HARMONIC架构为人机协作机器人提供了有效的解决方案，能够提升安全性、可解释性和信任度，具有实际应用价值。

Abstract: This paper introduces HARMONIC, a cognitive-robotic architecture designed for
robots in human-robotic teams. HARMONIC supports semantic perception
interpretation, human-like decision-making, and intentional language
communication. It addresses the issues of safety and quality of results; aims
to solve problems of data scarcity, explainability, and safety; and promotes
transparency and trust. Two proof-of-concept HARMONIC-based robotic systems are
demonstrated, each implemented in both a high-fidelity simulation environment
and on physical robotic platforms.

</details>
