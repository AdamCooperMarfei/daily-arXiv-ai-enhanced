<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Attentive Feature Aggregation or: How Policies Learn to Stop Worrying about Robustness and Attend to Task-Relevant Visual Cues](https://arxiv.org/abs/2511.10762)
*Nikolaos Tsagkas,Andreas Sochopoulos,Duolikun Danier,Sethu Vijayakumar,Alexandros Kouris,Oisin Mac Aodha,Chris Xiaoxuan Lu*

Main category: cs.RO

TL;DR: 提出了Attentive Feature Aggregation (AFA)，一种轻量级的可训练特征池化机制，用于提高预训练视觉表示在视觉扰动场景下的鲁棒性，无需昂贵的数据增强或PVR微调。


<details>
  <summary>Details</summary>
Motivation: 预训练视觉表示(PVRs)虽然强大，但可能编码大量任务无关的场景信息，导致训练的视觉运动策略在面对域外视觉变化和干扰物时缺乏鲁棒性。

Method: 通过注意力特征聚合(AFA)机制，学习自然地关注任务相关的视觉线索，忽略语义丰富的场景干扰物，作为视觉运动策略的特征池化解决方案。

Result: 在仿真和真实世界的广泛实验中，使用AFA训练的策略在存在视觉扰动的情况下显著优于标准池化方法。

Conclusion: 忽略无关视觉信息是部署鲁棒且可泛化的视觉运动策略的关键步骤，AFA提供了一种有效的解决方案。

Abstract: The adoption of pre-trained visual representations (PVRs), leveraging features from large-scale vision models, has become a popular paradigm for training visuomotor policies. However, these powerful representations can encode a broad range of task-irrelevant scene information, making the resulting trained policies vulnerable to out-of-domain visual changes and distractors. In this work we address visuomotor policy feature pooling as a solution to the observed lack of robustness in perturbed scenes. We achieve this via Attentive Feature Aggregation (AFA), a lightweight, trainable pooling mechanism that learns to naturally attend to task-relevant visual cues, ignoring even semantically rich scene distractors. Through extensive experiments in both simulation and the real world, we demonstrate that policies trained with AFA significantly outperform standard pooling approaches in the presence of visual perturbations, without requiring expensive dataset augmentation or fine-tuning of the PVR. Our findings show that ignoring extraneous visual information is a crucial step towards deploying robust and generalisable visuomotor policies. Project Page: tsagkas.github.io/afa

</details>


### [2] [From Framework to Reliable Practice: End-User Perspectives on Social Robots in Public Spaces](https://arxiv.org/abs/2511.10770)
*Samson Oruma,Ricardo Colomo-Palacios,Vasileios Gkioulos*

Main category: cs.RO

TL;DR: 本研究通过部署ARI社交机器人作为大学接待员，评估了基于SecuRoPS框架的伦理安全设计在实际应用中的效果，结果显示用户对安全性、隐私保护持积极态度，但在可访问性和包容性方面存在挑战。


<details>
  <summary>Details</summary>
Motivation: 随着社交机器人进入公共环境，其接受度不仅取决于技术可靠性，还涉及伦理完整性、可访问性和用户信任。研究旨在验证伦理安全框架在实际部署中的可行性。

Method: 部署ARI社交机器人作为大学接待员，让35名学生和员工与其互动，并收集关于安全性、隐私、可用性、可访问性和透明度的结构化反馈。

Result: 用户对物理安全、数据保护和伦理行为普遍持积极态度，但在可访问性、包容性和动态交互方面面临挑战。研究还提供了可复用的GitHub模板资源。

Conclusion: 研究展示了伦理安全设计框架在现实环境中的可实施性，为开发可信赖、包容和负责任的公共空间社交机器人提供了实证支持和实用资源。

Abstract: As social robots increasingly enter public environments, their acceptance depends not only on technical reliability but also on ethical integrity, accessibility, and user trust. This paper reports on a pilot deployment of an ARI social robot functioning as a university receptionist, designed in alignment with the SecuRoPS framework for secure and ethical social robot deployment. Thirty-five students and staff interacted with the robot and provided structured feedback on safety, privacy, usability, accessibility, and transparency. The results show generally positive perceptions of physical safety, data protection, and ethical behavior, while also highlighting challenges related to accessibility, inclusiveness, and dynamic interaction. Beyond the empirical findings, the study demonstrates how theoretical frameworks for ethical and secure design can be implemented in real-world contexts through end-user evaluation. It also provides a public GitHub repository containing reusable templates for ARI robot applications to support reproducibility and lower the entry barrier for new researchers. By combining user perspectives with practical technical resources, this work contributes to ongoing discussions in AI and society and supports the development of trustworthy, inclusive, and ethically responsible social robots for public spaces.

</details>


### [3] [$\rm{A}^{\rm{SAR}}$: $\varepsilon$-Optimal Graph Search for Minimum Expected-Detection-Time Paths with Path Budget Constraints for Search and Rescue](https://arxiv.org/abs/2511.10792)
*Eric Mugford,Jonathan D. Gammell*

Main category: cs.RO

TL;DR: 提出了一种名为A^SAR的ε最优搜索算法，用于搜救规划，能够找到在用户指定因子ε内的最优解，并在操作模拟和真实湖上试验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 搜救任务中，由于信息不确定、观察者不完美和搜索区域大，优化搜索能提高成功率。现有随机优化方法缺乏对有限时间内解质量的正式保证。

Method: A^SAR算法通过计算启发式来限制搜索空间，并使用图搜索方法找到保证在最优解ε范围内的解。

Result: 在操作模拟中比现有优化方法更快找到更好解，在安大略湖实地试验中仅用150秒定位了漂流人体模型。

Conclusion: A^SAR算法为搜救规划提供了具有正式质量保证的ε最优解，在实际应用中表现出色。

Abstract: Searches are conducted to find missing persons and/or objects given uncertain information, imperfect observers and large search areas in Search and Rescue (SAR). In many scenarios, such as Maritime SAR, expected survival times are short and optimal search could increase the likelihood of success. This optimization problem is complex for nontrivial problems given its probabilistic nature.
  Stochastic optimization methods search large problems by nondeterministically sampling the space to reduce the effective size of the problem. This has been used in SAR planning to search otherwise intractably large problems but the stochastic nature provides no formal guarantees on the quality of solutions found in finite time.
  This paper instead presents $\rm{A}^{\rm{SAR}}$, an $\varepsilon$-optimal search algorithm for SAR planning. It calculates a heuristic to bound the search space and uses graph-search methods to find solutions that are formally guaranteed to be within a user-specified factor, $\varepsilon$, of the optimal solution. It finds better solutions faster than existing optimization approaches in operational simulations. It is also demonstrated with a real-world field trial on Lake Ontario, Canada, where it was used to locate a drifting manikin in only 150s.

</details>


### [4] [An Investigation into Dynamically Extensible and Retractable Robotic Leg Linkages for Multi-task Execution in Search and Rescue Scenarios](https://arxiv.org/abs/2511.10816)
*William Harris,Lucas Yager,Syler Sylvester,Elizabeth Peiros,Micheal C. Yip*

Main category: cs.RO

TL;DR: 提出了一种新型动态可伸缩机器人腿，通过五连杆机构设计实现高度优势和力优势配置之间的机械切换，为搜救机器人同时提供地形适应性和高力输出能力。


<details>
  <summary>Details</summary>
Motivation: 当前搜救机器人缺乏既能快速穿越复杂地形又能执行高力救援任务的平台，传统腿式机器人难以兼顾地形适应性和高力输出。

Method: 采用动态可伸缩五连杆机构设计，通过几何变换在高度优势和力优势配置之间切换，搭建测试平台评估不同连杆几何形状和操作模式下的性能。

Result: 测试结果表明，变形腿在步长、力输出和稳定性方面表现良好，为搜救机器人提供了有前景的技术路径。

Conclusion: 这种变形腿设计为搜救机器人同时实现快速地形导航和有效救援任务提供了可行的解决方案。

Abstract: Search and rescue (SAR) robots are required to quickly traverse terrain and perform high-force rescue tasks, necessitating both terrain adaptability and controlled high-force output. Few platforms exist today for SAR, and fewer still have the ability to cover both tasks of terrain adaptability and high-force output when performing extraction. While legged robots offer significant ability to traverse uneven terrain, they typically are unable to incorporate mechanisms that provide variable high-force outputs, unlike traditional wheel-based drive trains. This work introduces a novel concept for a dynamically extensible and retractable robot leg. Leveraging a dynamically extensible and retractable five-bar linkage design, it allows for mechanically switching between height-advantaged and force-advantaged configurations via a geometric transformation. A testbed evaluated leg performance across linkage geometries and operating modes, with empirical and analytical analyses conducted on stride length, force output, and stability. The results demonstrate that the morphing leg offers a promising path toward SAR robots that can both navigate terrain quickly and perform rescue tasks effectively.

</details>


### [5] [MIGHTY: Hermite Spline-based Efficient Trajectory Planning](https://arxiv.org/abs/2511.10822)
*Kota Kondo,Yuwei Wu,Vijay Kumar,Jonathan P. How*

Main category: cs.RO

TL;DR: MIGHTY是一种基于Hermite样条的轨迹规划器，通过时空优化在连续搜索空间中实现快速计算，相比现有方法减少9.3%计算时间和13.1%行程时间。


<details>
  <summary>Details</summary>
Motivation: 硬约束轨迹规划器依赖商业求解器且计算资源需求大，现有软约束方法要么解耦时空优化，要么限制搜索空间，存在局限性。

Method: 使用Hermite样条进行时空优化，充分利用样条的连续搜索空间。

Result: 仿真中计算时间减少9.3%，行程时间减少13.1%，成功率100%；硬件实验中实现6.7m/s高速飞行和动态障碍物环境下的长时间飞行。

Conclusion: MIGHTY在保持高成功率的同时显著提升了计算效率和轨迹质量，适用于静态和动态障碍物环境。

Abstract: Hard-constraint trajectory planners often rely on commercial solvers and demand substantial computational resources. Existing soft-constraint methods achieve faster computation, but either (1) decouple spatial and temporal optimization or (2) restrict the search space. To overcome these limitations, we introduce MIGHTY, a Hermite spline-based planner that performs spatiotemporal optimization while fully leveraging the continuous search space of a spline. In simulation, MIGHTY achieves a 9.3% reduction in computation time and a 13.1% reduction in travel time over state-of-the-art baselines, with a 100% success rate. In hardware, MIGHTY completes multiple high-speed flights up to 6.7 m/s in a cluttered static environment and long-duration flights with dynamically added obstacles.

</details>


### [6] [Decentralized Swarm Control via SO(3) Embeddings for 3D Trajectories](https://arxiv.org/abs/2511.10858)
*Dimitria Silveria,Kleber Cabral,Peter Jardine,Sidney Givigi*

Main category: cs.RO

TL;DR: 提出了一种基于SO(3)李群的新型去中心化多智能体系统方法，仅需位置输入即可产生稳定周期性轨迹，无需速度信息，并包含相位控制器确保智能体均匀分布。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成周期性轨迹方面受限，且通常需要速度输入。本文旨在开发一种更通用、信息共享更少的去中心化方法，能够产生更广泛的稳定周期性行为。

Method: 利用SO(3)李群的几何嵌入来稳定系统，生成周期性轨迹；设计了无需速度输入的控制器；提出了确保智能体均匀分布的相位控制器；提供了形式化稳定性证明。

Result: 该方法能够产生比现有基于四元数方法更广泛的周期性曲线，在仿真和实验中验证了对复杂底层动力学和干扰的适应性。

Conclusion: 基于SO(3)李群的方法为多智能体系统提供了一种信息需求少、适应性强的周期性行为生成框架，扩展了去中心化控制的适用范围。

Abstract: This paper presents a novel decentralized approach for achieving emergent behavior in multi-agent systems with minimal information sharing. Based on prior work in simple orbits, our method produces a broad class of stable, periodic trajectories by stabilizing the system around a Lie group-based geometric embedding. Employing the Lie group SO(3), we generate a wider range of periodic curves than existing quaternion-based methods. Furthermore, we exploit SO(3) properties to eliminate the need for velocity inputs, allowing agents to receive only position inputs. We also propose a novel phase controller that ensures uniform agent separation, along with a formal stability proof. Validation through simulations and experiments showcases the method's adaptability to complex low-level dynamics and disturbances.

</details>


### [7] [WetExplorer: Automating Wetland Greenhouse-Gas Surveys with an Autonomous Mobile Robot](https://arxiv.org/abs/2511.10864)
*Jose Vasquez,Xuping Zhang*

Main category: cs.RO

TL;DR: WetExplorer是一个自主履带式机器人，用于自动化湿地温室气体采样工作流程，解决了手动采样劳动密集和时间消耗的问题。


<details>
  <summary>Details</summary>
Motivation: 湿地温室气体量化对气候建模和恢复评估至关重要，但手动采样劳动密集且耗时，需要自动化解决方案来提高测量频率和效率。

Method: 集成低接地压力移动、厘米级精确升降放置、双RTK传感器融合、避障规划和深度学习感知，采用容器化ROS2架构。

Result: 室外试验显示传感器融合定位误差平均1.71厘米，视觉模块物体姿态估计精度7毫米平移和3度旋转；室内试验验证运动规划管道可将采样室定位在70毫米全局容差内并避开障碍物。

Conclusion: WetExplorer通过消除人工瓶颈，实现了高频、多站点温室气体测量，为饱和湿地地形中的密集、长期数据集采集开辟了新途径。

Abstract: Quantifying greenhouse-gases (GHG) in wetlands is critical for climate modeling and restoration assessment, yet manual sampling is labor-intensive, and time demanding. We present WetExplorer, an autonomous tracked robot that automates the full GHG-sampling workflow. The robot system integrates low-ground-pressure locomotion, centimeter-accurate lift placement, dual-RTK sensor fusion, obstacle avoidance planning, and deep-learning perception in a containerized ROS2 stack. Outdoor trials verified that the sensor-fusion stack maintains a mean localization error of 1.71 cm, the vision module estimates object pose with 7 mm translational and 3° rotational accuracy, while indoor trials demonstrated that the full motion-planning pipeline positions the sampling chamber within a global tolerance of 70 mm while avoiding obstacles, all without human intervention. By eliminating the manual bottleneck, WetExplorer enables high-frequency, multi-site GHG measurements and opens the door for dense, long-duration datasets in saturated wetland terrain.

</details>


### [8] [Collaborative Multi-Robot Non-Prehensile Manipulation via Flow-Matching Co-Generation](https://arxiv.org/abs/2511.10874)
*Yorai Shaoul,Zhe Chen,Mohamed Naveed Gul Mohamed,Federico Pecora,Maxim Likhachev,Jiaoyang Li*

Main category: cs.RO

TL;DR: 提出统一框架用于协作多机器人、多物体非抓取操作，结合流匹配协同生成和匿名多机器人运动规划，在复杂环境中优于基线方法


<details>
  <summary>Details</summary>
Motivation: 现有方法要么学习整个任务，要么依赖特权信息和手动设计规划器，难以处理多样化物体和长时程任务

Method: 集成流匹配协同生成与匿名多机器人运动规划，生成模型从视觉观察协同生成接触构型和操作轨迹，新颖运动规划器协调机器人规模

Result: 在挑战性模拟环境中实验表明，该方法在运动规划和操作任务上均优于基线

Conclusion: 生成协同设计和集成规划有利于将协作操作扩展到复杂多智能体、多物体场景

Abstract: Coordinating a team of robots to reposition multiple objects in cluttered environments requires reasoning jointly about where robots should establish contact, how to manipulate objects once contact is made, and how to navigate safely and efficiently at scale. Prior approaches typically fall into two extremes -- either learning the entire task or relying on privileged information and hand-designed planners -- both of which struggle to handle diverse objects in long-horizon tasks. To address these challenges, we present a unified framework for collaborative multi-robot, multi-object non-prehensile manipulation that integrates flow-matching co-generation with anonymous multi-robot motion planning. Within this framework, a generative model co-generates contact formations and manipulation trajectories from visual observations, while a novel motion planner conveys robots at scale. Crucially, the same planner also supports coordination at the object level, assigning manipulated objects to larger target structures and thereby unifying robot- and object-level reasoning within a single algorithmic framework. Experiments in challenging simulated environments demonstrate that our approach outperforms baselines in both motion planning and manipulation tasks, highlighting the benefits of generative co-design and integrated planning for scaling collaborative manipulation to complex multi-agent, multi-object settings. Visit gco-paper.github.io for code and demonstrations.

</details>


### [9] [Terradynamics and design of tip-extending robotic anchors](https://arxiv.org/abs/2511.10901)
*Deniz Kerimoglu,Nicholas D. Naclerio,Sean Chu,Andrew Krohn,Vineet Kupunaram,Alexander Schepelmann,Daniel I. Goldman,Elliot W. Hawkes*

Main category: cs.RO

TL;DR: 本文研究了一种受树根启发的尖端延伸锚固机制，开发出轻量级软体机器人锚固装置，在火星土壤模拟物中实现40:1的锚固重量比。


<details>
  <summary>Details</summary>
Motivation: 传统桩基需要比拔出阻力更大的驱动力插入地面，这在难以到达的地点（包括外星环境）存在问题。而树根通过尖端延伸机制，仅需种子重量即可插入，但拔出阻力远大于插入力。

Method: 研究尖端延伸锚与传统桩基侵入器的地形动力学，识别关键设计原则，并开发可部署的机器人锚固装置。

Result: 开发出300克轻量级软体机器人锚固装置，能在松散火星土壤模拟物中插入45厘米深，平均锚固力120N，锚固重量比达40:1。

Conclusion: 通过尖端延伸机制和四项设计原则（临界深度、毛发状突起、近垂直延伸、多小锚组合），可实现高效锚固系统，插入力小于装置自身重量。

Abstract: Most engineered pilings require substantially more force to be driven into the ground than they can resist during extraction. This requires relatively heavy equipment for insertion, which is problematic for anchoring in hard-to-access sites, including in extraterrestrial locations. In contrast, for tree roots, the external reaction force required to extract is much greater than required to insert--little more than the weight of the seed initiates insertion. This is partly due to the mechanism by which roots insert into the ground: tip extension. Proof-of-concept robotic prototypes have shown the benefits of using this mechanism, but a rigorous understanding of the underlying granular mechanics and how they inform the design of a robotic anchor is lacking. Here, we study the terradynamics of tip-extending anchors compared to traditional piling-like intruders, develop a set of design insights, and apply these to create a deployable robotic anchor. Specifically, we identify that to increase an anchor's ratio of extraction force to insertion force, it should: (i) extend beyond a critical depth; (ii) include hair-like protrusions; (iii) extend near-vertically, and (iv) incorporate multiple smaller anchors rather than a single large anchor. Synthesizing these insights, we developed a lightweight, soft robotic, root-inspired anchoring device that inserts into the ground with a reaction force less than its weight. We demonstrate that the 300 g device can deploy a series of temperature sensors 45 cm deep into loose Martian regolith simulant while anchoring with an average of 120 N, resulting in an anchoring-to-weight ratio of 40:1.

</details>


### [10] [Dexterous Manipulation Transfer via Progressive Kinematic-Dynamic Alignment](https://arxiv.org/abs/2511.10987)
*Wenbin Bai,Qiyu Chen,Xiangbo Lin,Jianwen Li,Quancheng Li,Hejiang Pan,Yi Sun*

Main category: cs.RO

TL;DR: 提出了一种手部无关的操纵转移系统，能够将人类手部操纵视频转换为高质量的多指机器人手操纵轨迹，无需大量训练数据，解决了多指机器人手数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 多指机器人手硬件平台收集操纵数据的固有难度和有限可扩展性导致了严重的数据稀缺，阻碍了基于数据的灵巧操纵策略学习研究。

Method: 设计了渐进式转移框架：首先基于运动学匹配建立灵巧手的主要控制信号；然后训练带有动作空间重缩放和拇指引导初始化的残差策略来动态优化接触交互；最后计算手腕控制轨迹以保持操作语义。

Result: 系统能够自动为不同任务配置参数，在灵巧手、物体类别和任务之间平衡运动学匹配和动态优化，平均转移成功率达到73%。

Conclusion: 该框架能够自动生成平滑且语义正确的灵巧手操纵，忠实地再现人类意图，为收集机器人灵巧操纵数据提供了一种易于实施和可扩展的方法。

Abstract: The inherent difficulty and limited scalability of collecting manipulation data using multi-fingered robot hand hardware platforms have resulted in severe data scarcity, impeding research on data-driven dexterous manipulation policy learning. To address this challenge, we present a hand-agnostic manipulation transfer system. It efficiently converts human hand manipulation sequences from demonstration videos into high-quality dexterous manipulation trajectories without requirements of massive training data. To tackle the multi-dimensional disparities between human hands and dexterous hands, as well as the challenges posed by high-degree-of-freedom coordinated control of dexterous hands, we design a progressive transfer framework: first, we establish primary control signals for dexterous hands based on kinematic matching; subsequently, we train residual policies with action space rescaling and thumb-guided initialization to dynamically optimize contact interactions under unified rewards; finally, we compute wrist control trajectories with the objective of preserving operational semantics. Using only human hand manipulation videos, our system automatically configures system parameters for different tasks, balancing kinematic matching and dynamic optimization across dexterous hands, object categories, and tasks. Extensive experimental results demonstrate that our framework can automatically generate smooth and semantically correct dexterous hand manipulation that faithfully reproduces human intentions, achieving high efficiency and strong generalizability with an average transfer success rate of 73%, providing an easily implementable and scalable method for collecting robot dexterous manipulation data.

</details>


### [11] [Dynamic Reconfiguration of Robotic Swarms: Coordination and Control for Precise Shape Formation](https://arxiv.org/abs/2511.10989)
*Prab Prasertying,Paulo Garcia,Warisa Sritriratanarak*

Main category: cs.RO

TL;DR: 提出了一种机器人群体协调算法，实现从一种配置到另一种配置的无缝转换，利用几何公式通过控制、定位和映射技术映射到物理领域。


<details>
  <summary>Details</summary>
Motivation: 机器人群体运动与配置协调是一个计算复杂的问题，物理系统的测量误差和控制动态进一步加剧了挑战，确定每个机器人的最优路径以及如何执行这种确定和相应运动仍然是一个开放性问题。

Method: 利用几何公式，通过适当的控制、定位和映射技术将其映射到物理领域，实现机器人群体配置的无缝转换。

Result: 开发出能够实现机器人群体配置无缝转换的协调算法。

Conclusion: 该算法为机器人群体更复杂的分布式行为铺平了道路，推动了机器人群体新颖应用的发展。

Abstract: Coordination of movement and configuration in robotic swarms is a challenging endeavor. Deciding when and where each individual robot must move is a computationally complex problem. The challenge is further exacerbated by difficulties inherent to physical systems, such as measurement error and control dynamics. Thus, how to best determine the optimal path for each robot, when moving from one configuration to another, and how to best perform such determination and effect corresponding motion remains an open problem. In this paper, we show an algorithm for such coordination of robotic swarms. Our methods allow seamless transition from one configuration to another, leveraging geometric formulations that are mapped to the physical domain through appropriate control, localization, and mapping techniques. This paves the way for novel applications of robotic swarms by enabling more sophisticated distributed behaviors.

</details>


### [12] [Latent-Space Autoregressive World Model for Efficient and Robust Image-Goal Navigation](https://arxiv.org/abs/2511.11011)
*Zhiwei Zhang,Hui Zhang,Xieyuanli Chen,Kaihong Huang,Chenghao Shi,Huimin Lu*

Main category: cs.RO

TL;DR: 提出LS-NWM，一种轻量级潜在空间导航世界模型，在潜在空间中训练和运行，相比基线方法训练时间减少3.2倍，规划时间减少447倍，同时导航性能提升35% SR和11% SPL。


<details>
  <summary>Details</summary>
Motivation: 传统导航方法依赖精确定位和建图，而世界模型在潜在空间中捕捉环境动态为导航任务提供了新视角，但现有世界模型存在训练和推理计算成本高的问题。

Method: 模型基于当前观测特征和动作输入预测未来潜在状态，在紧凑表示中进行路径规划和决策，采用自回归多帧预测策略捕捉长期时空依赖关系。

Result: 实验结果显示，该方法在保持显著效率优势的同时，在复杂场景中实现了最先进的导航性能。

Conclusion: 准确的像素级环境预测对导航并非必要，在潜在空间中进行预测和决策能显著提高计算效率并提升导航性能。

Abstract: Traditional navigation methods rely heavily on accurate localization and mapping. In contrast, world models that capture environmental dynamics in latent space have opened up new perspectives for navigation tasks, enabling systems to move beyond traditional multi-module pipelines. However, world model often suffers from high computational costs in both training and inference. To address this, we propose LS-NWM - a lightweight latent space navigation world model that is trained and operates entirely in latent space, compared to the state-of-the-art baseline, our method reduces training time by approximately 3.2x and planning time by about 447x,while further improving navigation performance with a 35% higher SR and an 11% higher SPL. The key idea is that accurate pixel-wise environmental prediction is unnecessary for navigation. Instead, the model predicts future latent states based on current observational features and action inputs, then performs path planning and decision-making within this compact representation, significantly improving computational efficiency. By incorporating an autoregressive multi-frame prediction strategy during training, the model effectively captures long-term spatiotemporal dependencies, thereby enhancing navigation performance in complex scenarios. Experimental results demonstrate that our method achieves state-of-the-art navigation performance while maintaining a substantial efficiency advantage over existing approaches.

</details>


### [13] [Miniature Testbed for Validating Multi-Agent Cooperative Autonomous Driving](https://arxiv.org/abs/2511.11022)
*Hyunchul Bae,Eunjae Lee,Jehyeop Han,Minhee Kang,Jaehyeon Kim,Junggeun Seo,Minkyun Noh,Heejin Ahn*

Main category: cs.RO

TL;DR: 设计并实现了一个1:15比例的微型测试平台CIVAT，用于验证协同自动驾驶，包含按比例缩小的城市地图、配备车载传感器的自动驾驶车辆和智能基础设施。


<details>
  <summary>Details</summary>
Motivation: 现有的测试平台都没有采用配备感知、边缘计算和通信能力的智能基础设施，而协同自动驾驶通过车辆与智能路边基础设施的实时协作来扩展车辆自主性，仍然是一个具有挑战性但至关重要的问题。

Method: 通过共享Wi-Fi和ROS2框架，采用发布-订阅模式集成V2V和V2I通信，实现车辆与基础设施之间的信息交换，从而实现协同驾驶功能。

Result: 通过基于基础设施的感知和交叉口管理实验验证了该系统。

Conclusion: CIVAT测试平台填补了现有测试平台缺乏智能基础设施的空白，为协同自动驾驶的验证提供了有效的解决方案。

Abstract: Cooperative autonomous driving, which extends vehicle autonomy by enabling real-time collaboration between vehicles and smart roadside infrastructure, remains a challenging yet essential problem. However, none of the existing testbeds employ smart infrastructure equipped with sensing, edge computing, and communication capabilities. To address this gap, we design and implement a 1:15-scale miniature testbed, CIVAT, for validating cooperative autonomous driving, consisting of a scaled urban map, autonomous vehicles with onboard sensors, and smart infrastructure. The proposed testbed integrates V2V and V2I communication with the publish-subscribe pattern through a shared Wi-Fi and ROS2 framework, enabling information exchange between vehicles and infrastructure to realize cooperative driving functionality. As a case study, we validate the system through infrastructure-based perception and intersection management experiments.

</details>


### [14] [AdaptPNP: Integrating Prehensile and Non-Prehensile Skills for Adaptive Robotic Manipulation](https://arxiv.org/abs/2511.11052)
*Jinxuan Zhu,Chenrui Tie,Xinyi Cao,Yuran Wang,Jingxiang Guo,Zixuan Chen,Haonan Chen,Junting Chen,Yangyu Xiao,Ruihai Wu,Lin Shao*

Main category: cs.RO

TL;DR: ApaptPNP是一个基于视觉语言模型的任务和运动规划框架，通过系统选择并结合抓取和非抓取操作技能来完成多样化操作任务。


<details>
  <summary>Details</summary>
Motivation: 非抓取操作（如推、戳、滑动）在抓取不可行或不充分时能显著扩展机器人操作能力，但构建一个能跨任务、物体和环境泛化，并无缝集成抓取和非抓取操作的统一框架仍具挑战性。

Method: 利用VLM解释视觉场景和文本任务描述生成高级规划骨架，通过数字孪生对象中心中间层预测目标物体位姿进行心理预演，控制模块合成低级机器人指令并通过连续执行反馈实现在线任务规划优化。

Result: 在仿真和真实环境中评估了代表性抓取与非抓取混合操作任务，结果表明混合操作是迈向通用、人类水平机器人操作能力的关键步骤。

Conclusion: ApaptPNP展示了混合抓取与非抓取操作的潜力，为通用机器人操作能力的发展提供了重要方向。

Abstract: Non-prehensile (NP) manipulation, in which robots alter object states without forming stable grasps (for example, pushing, poking, or sliding), significantly broadens robotic manipulation capabilities when grasping is infeasible or insufficient. However, enabling a unified framework that generalizes across different tasks, objects, and environments while seamlessly integrating non-prehensile and prehensile (P) actions remains challenging: robots must determine when to invoke NP skills, select the appropriate primitive for each context, and compose P and NP strategies into robust, multi-step plans. We introduce ApaptPNP, a vision-language model (VLM)-empowered task and motion planning framework that systematically selects and combines P and NP skills to accomplish diverse manipulation objectives. Our approach leverages a VLM to interpret visual scene observations and textual task descriptions, generating a high-level plan skeleton that prescribes the sequence and coordination of P and NP actions. A digital-twin based object-centric intermediate layer predicts desired object poses, enabling proactive mental rehearsal of manipulation sequences. Finally, a control module synthesizes low-level robot commands, with continuous execution feedback enabling online task plan refinement and adaptive replanning through the VLM. We evaluate ApaptPNP across representative P&NP hybrid manipulation tasks in both simulation and real-world environments. These results underscore the potential of hybrid P&NP manipulation as a crucial step toward general-purpose, human-level robotic manipulation capabilities. Project Website: https://sites.google.com/view/adaptpnp/home

</details>


### [15] [Humanoid Whole-Body Badminton via Multi-Stage Reinforcement Learning](https://arxiv.org/abs/2511.11218)
*Chenhao Liu,Leyun Jiang,Yibo Wang,Kairan Yao,Jinchen Fu,Xiaoyu Ren*

Main category: cs.RO

TL;DR: 提出基于强化学习的仿人机器人羽毛球控制器，通过三阶段训练课程实现无运动先验的全身协调控制，在仿真和真实环境中验证了动态击球能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界是动态的，准静态交互不足以应对各种环境条件，需要开发能够处理更动态交互场景的仿人机器人控制方法。

Method: 三阶段强化学习训练课程：第一阶段学习步法，第二阶段生成精准球拍挥动，第三阶段任务精炼；部署时使用扩展卡尔曼滤波器预测羽毛球轨迹，也提出了无需预测的变体。

Result: 仿真中两个机器人连续击球21次；无预测变体性能与已知目标策略相当；真实测试中击球速度达10m/s，平均回球落点距离3.5米。

Conclusion: 仿人机器人能够在羽毛球中实现高度动态且精准的目标击球，并可适应更多动态关键领域。

Abstract: Humanoid robots have demonstrated strong capability for interacting with deterministic scenes across locomotion, manipulation, and more challenging loco-manipulation tasks. Yet the real world is dynamic, quasi-static interactions are insufficient to cope with the various environmental conditions. As a step toward more dynamic interaction scenario, we present a reinforcement-learning-based training pipeline that produces a unified whole-body controller for humanoid badminton, enabling coordinated lower-body footwork and upper-body striking without any motion priors or expert demonstrations. Training follows a three-stage curriculum: first footwork acquisition, then precision-guided racket swing generation, and finally task-focused refinement, yielding motions in which both legs and arms serve the hitting objective. For deployment, we incorporate an Extended Kalman Filter (EKF) to estimate and predict shuttlecock trajectories for target striking. We also introduce a prediction-free variant that dispenses with EKF and explicit trajectory prediction. To validate the framework, we conduct five sets of experiment in both simulation and the real world. In simulation, two robots sustain a rally of 21 consecutive hits. Moreover, the prediction-free variant achieves successful hits with comparable performance relative to the target-known policy. In real-world tests, both the prediction and controller module exhibit high accuracy, and on-court hitting achieves an outgoing shuttle speed up to 10 m/s with a mean return landing distance of 3.5 m. These experiment results show that our humanoid robot can deliver highly dynamic while precise goal striking in badminton, and can be adapted to more dynamism critical domains.

</details>


### [16] [Sashimi-Bot: Autonomous Tri-manual Advanced Manipulation and Cutting of Deformable Objects](https://arxiv.org/abs/2511.11223)
*Sverre Herland,Amit Parag,Elling Ruud Øye,Fangyi Zhang,Fouad Makiyeh,Aleksander Lillienskiold,Abhaya Pal Singh,Edward H. Adelson,Francois Chaumette,Alexandre Krupa,Peter Corke,Ekrem Misimi*

Main category: cs.RO

TL;DR: Sashimi-Bot是一个自主多机器人系统，专门用于处理可变形的体积物体（如三文鱼鱼柳）的切割操作，结合了深度强化学习、视觉触觉反馈和协同机器人控制。


<details>
  <summary>Details</summary>
Motivation: 由于可变形体积物体的柔韧性、脆弱性、可变性和交互过程中的不确定性，机器人对其的高级操作仍然是一个重大挑战。

Method: 使用三个机器人协同工作：一个拉直鱼柳，一个握持刀具，一个在切割时稳定鱼柳。系统结合深度强化学习、工具形状操作、工具切割以及视觉和触觉信息反馈。

Result: 系统能够自主完成三文鱼鱼柳的切割操作，包括拉直、握持刀具、切片动作切割以及在切割过程中协同稳定鱼柳。

Conclusion: 这项工作代表了机器人操作可变形体积物体的一个重要里程碑，可能激发和实现各种其他现实世界应用。

Abstract: Advanced robotic manipulation of deformable, volumetric objects remains one of the greatest challenges due to their pliancy, frailness, variability, and uncertainties during interaction. Motivated by these challenges, this article introduces Sashimi-Bot, an autonomous multi-robotic system for advanced manipulation and cutting, specifically the preparation of sashimi. The objects that we manipulate, salmon loins, are natural in origin and vary in size and shape, they are limp and deformable with poorly characterized elastoplastic parameters, while also being slippery and hard to hold. The three robots straighten the loin; grasp and hold the knife; cut with the knife in a slicing motion while cooperatively stabilizing the loin during cutting; and pick up the thin slices from the cutting board or knife blade. Our system combines deep reinforcement learning with in-hand tool shape manipulation, in-hand tool cutting, and feedback of visual and tactile information to achieve robustness to the variabilities inherent in this task. This work represents a milestone in robotic manipulation of deformable, volumetric objects that may inspire and enable a wide range of other real-world applications.

</details>


### [17] [Experiences from Benchmarking Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/abs/2511.11298)
*Yihao Zhang,Yuankai Qi,Xi Zheng*

Main category: cs.RO

TL;DR: 本文对四种代表性的视觉-语言-动作模型（ACT、OpenVLA-OFT、RDT-1B、π₀）在机器人操作任务中进行了系统评估，建立了包含准确性、适应性和指令遵循能力的标准化评估框架，揭示了不同模型在精度、泛化能力和部署成本之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作模型在机器人领域具有巨大潜力，但缺乏系统的真实世界评估和跨模型比较，需要建立标准化的评估方法来指导模型选择和应用部署。

Method: 在仿真和ALOHA Mobile平台上对四种VLA模型进行基准测试，建立包含准确性效率、适应性和语言指令遵循准确性的三维评估框架，分析计算需求、数据扩展行为和常见失败模式。

Result: π₀在分布外场景中表现出更好的适应性，ACT在分布内场景中稳定性最高，不同模型在精度、泛化能力和部署成本方面存在明显权衡。

Conclusion: 研究揭示了VLA模型架构在平衡精度、泛化能力和部署成本方面的实际权衡，为在实际机器人操作任务中选择和部署VLA模型提供了可操作的见解。

Abstract: Foundation models applied in robotics, particularly \textbf{Vision--Language--Action (VLA)} models, hold great promise for achieving general-purpose manipulation. Yet, systematic real-world evaluations and cross-model comparisons remain scarce. This paper reports our \textbf{empirical experiences} from benchmarking four representative VLAs -- \textbf{ACT}, \textbf{OpenVLA--OFT}, \textbf{RDT-1B}, and \boldmath{$π_0$} -- across four manipulation tasks conducted in both simulation and on the \textbf{ALOHA Mobile} platform. We establish a \textbf{standardized evaluation framework} that measures performance along three key dimensions: (1) \textit{accuracy and efficiency} (success rate and time-to-success), (2) \textit{adaptability} across in-distribution, spatial out-of-distribution, and instance-plus-spatial out-of-distribution settings, and (3) \textit{language instruction-following accuracy}. Through this process, we observe that \boldmath{$π_0$} demonstrates superior adaptability in out-of-distribution scenarios, while \textbf{ACT} provides the highest stability in-distribution. Further analysis highlights differences in computational demands, data-scaling behavior, and recurring failure modes such as near-miss grasps, premature releases, and long-horizon state drift. These findings reveal practical trade-offs among VLA model architectures in balancing precision, generalization, and deployment cost, offering actionable insights for selecting and deploying VLAs in real-world robotic manipulation tasks.

</details>


### [18] [Simulating an Autonomous System in CARLA using ROS 2](https://arxiv.org/abs/2511.11310)
*Joseph Abdo,Aditya Shibu,Moaiz Saeed,Abdul Maajid Aga,Apsara Sivaprazad,Mohamed Al-Musleh*

Main category: cs.RO

TL;DR: 开发用于CARLA模拟器的自动驾驶赛车软件栈，针对FS-AI 2025竞赛，结合多种传感器实现赛道边界检测和优化轨迹规划


<details>
  <summary>Details</summary>
Motivation: 在高速和不确定性条件下测试自动驾驶系统的感知、规划和控制能力，为Formula Student UK Driverless 2025竞赛做准备

Method: 使用360° LiDAR、立体相机、GNSS和IMU传感器通过ROS 2系统，可靠检测赛道边界锥桶，考虑车辆动力学和环境因素计算优化轨迹

Result: 系统能在35米距离内可靠检测锥桶，完整的自动驾驶栈在CARLA中广泛验证后移植到实际硬件平台

Conclusion: 提出的方法成功实现了用于自动驾驶赛车的完整软件栈，在模拟环境中验证后能够部署到实际硬件平台

Abstract: Autonomous racing offers a rigorous setting to stress test perception, planning, and control under high speed and uncertainty. This paper proposes an approach to design and evaluate a software stack for an autonomous race car in CARLA: Car Learning to Act simulator, targeting competitive driving performance in the Formula Student UK Driverless (FS-AI) 2025 competition. By utilizing a 360° light detection and ranging (LiDAR), stereo camera, global navigation satellite system (GNSS), and inertial measurement unit (IMU) sensor via ROS 2 (Robot Operating System), the system reliably detects the cones marking the track boundaries at distances of up to 35 m. Optimized trajectories are computed considering vehicle dynamics and simulated environmental factors such as visibility and lighting to navigate the track efficiently. The complete autonomous stack is implemented in ROS 2 and validated extensively in CARLA on a dedicated vehicle (ADS-DV) before being ported to the actual hardware, which includes the Jetson AGX Orin 64GB, ZED2i Stereo Camera, Robosense Helios 16P LiDAR, and CHCNAV Inertial Navigation System (INS).

</details>


### [19] [SimTac: A Physics-Based Simulator for Vision-Based Tactile Sensing with Biomorphic Structures](https://arxiv.org/abs/2511.11456)
*Xuyang Zhang,Jiaqi Jiang,Zhuo Chen,Yongqiang Zhao,Tianqi Yang,Daniel Fernandes Gomes,Jianan Wang,Shan Luo*

Main category: cs.RO

TL;DR: SimTac是一个基于物理的仿真框架，用于设计和验证仿生触觉传感器，通过粒子变形建模、光场渲染和神经网络预测机械响应，实现多种几何形状和材料的准确高效仿真。


<details>
  <summary>Details</summary>
Motivation: 生物触觉感知与形态结构密切相关，而机器人视觉触觉传感器局限于简单平面几何，仿生设计未被充分探索。

Method: SimTac包含粒子变形建模、光场渲染生成真实触觉图像、神经网络预测机械响应，支持多种几何形状和材料仿真。

Result: 成功设计并验证了受生物触觉结构启发的物理传感器原型，在多个Sim2Real触觉任务中表现出色，包括物体分类、滑动检测和接触安全评估。

Conclusion: 该框架弥合了仿生设计与实际实现之间的差距，扩展了触觉传感器的设计空间，为在非结构化环境中实现稳健交互的触觉感知系统铺平道路。

Abstract: Tactile sensing in biological organisms is deeply intertwined with morphological form, such as human fingers, cat paws, and elephant trunks, which enables rich and adaptive interactions through a variety of geometrically complex structures. In contrast, vision-based tactile sensors in robotics have been limited to simple planar geometries, with biomorphic designs remaining underexplored. To address this gap, we present SimTac, a physics-based simulation framework for the design and validation of biomorphic tactile sensors. SimTac consists of particle-based deformation modeling, light-field rendering for photorealistic tactile image generation, and a neural network for predicting mechanical responses, enabling accurate and efficient simulation across a wide range of geometries and materials. We demonstrate the versatility of SimTac by designing and validating physical sensor prototypes inspired by biological tactile structures and further demonstrate its effectiveness across multiple Sim2Real tactile tasks, including object classification, slip detection, and contact safety assessment. Our framework bridges the gap between bio-inspired design and practical realisation, expanding the design space of tactile sensors and paving the way for tactile sensing systems that integrate morphology and sensing to enable robust interaction in unstructured environments.

</details>


### [20] [Rethinking Progression of Memory State in Robotic Manipulation: An Object-Centric Perspective](https://arxiv.org/abs/2511.11478)
*Nhat Chung,Taisei Hanyu,Toan Nguyen,Huy Le,Frederick Bumgarner,Duy Minh Ho Nguyen,Khoa Vo,Kashu Yamazaki,Chase Rainwater,Tung Kieu,Anh Nguyen,Ngan Le*

Main category: cs.RO

TL;DR: 提出了LIBERO-Mem任务套件来测试机器人操作中的非马尔可夫推理能力，并开发了Embodied-SlotSSM框架来解决视觉-语言-动作模型在长时序任务中的扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，机器人需要感知、跟踪和推理单个物体实例随时间的变化，特别是在需要与视觉相似物体进行序列交互的任务中。当前模型在非马尔可夫设置下往往失败，因为它们缺乏对先前交互的持久记忆。

Method: 提出了Embodied-SlotSSM框架，采用槽中心方法，通过两种机制实现：1）槽状态空间建模用于重建短期历史；2）关系编码器将输入令牌与动作解码对齐，以保持时空一致的槽身份。

Result: 实验表明Embodied-SlotSSM在LIBERO-Mem和通用任务上表现出基准性能，为非马尔可夫推理提供了可扩展的解决方案。

Conclusion: Embodied-SlotSSM框架为解决对象中心机器人策略中的非马尔可夫推理问题提供了可扩展的解决方案，特别是在需要长期时序推理的任务中。

Abstract: As embodied agents operate in increasingly complex environments, the ability to perceive, track, and reason about individual object instances over time becomes essential, especially in tasks requiring sequenced interactions with visually similar objects. In these non-Markovian settings, key decision cues are often hidden in object-specific histories rather than the current scene. Without persistent memory of prior interactions (what has been interacted with, where it has been, or how it has changed) visuomotor policies may fail, repeat past actions, or overlook completed ones. To surface this challenge, we introduce LIBERO-Mem, a non-Markovian task suite for stress-testing robotic manipulation under object-level partial observability. It combines short- and long-horizon object tracking with temporally sequenced subgoals, requiring reasoning beyond the current frame. However, vision-language-action (VLA) models often struggle in such settings, with token scaling quickly becoming intractable even for tasks spanning just a few hundred frames. We propose Embodied-SlotSSM, a slot-centric VLA framework built for temporal scalability. It maintains spatio-temporally consistent slot identities and leverages them through two mechanisms: (1) slot-state-space modeling for reconstructing short-term history, and (2) a relational encoder to align the input tokens with action decoding. Together, these components enable temporally grounded, context-aware action prediction. Experiments show Embodied-SlotSSM's baseline performance on LIBERO-Mem and general tasks, offering a scalable solution for non-Markovian reasoning in object-centric robotic policies.

</details>


### [21] [A Comparative Evaluation of Prominent Methods in Autonomous Vehicle Certification](https://arxiv.org/abs/2511.11484)
*Mustafa Erdem Kırmızıgül,Hasan Feyzi Doğruyol,Haluk Bayram*

Main category: cs.RO

TL;DR: 本文比较评估了自动驾驶汽车认证过程中的主要方法，开发了认证流程管道，确定了应用这些方法的阶段、参与者和领域。


<details>
  <summary>Details</summary>
Motivation: 瑞典议会1997年提出的"零愿景"政策旨在消除交通事故导致的死亡和重伤，但自动驾驶汽车的基本安全要求如何验证和认证以及使用哪些方法仍不明确。

Method: 比较评估认证过程中的主要方法，开发自动驾驶汽车认证流程管道，确定应用方法的阶段、参与者和领域。

Result: 建立了自动驾驶汽车认证流程的完整框架，明确了不同认证方法的应用场景和参与主体。

Conclusion: 为自动驾驶汽车的认证提供了系统化的方法论框架，支持"零愿景"政策的实施。

Abstract: The "Vision Zero" policy, introduced by the Swedish Parliament in 1997, aims to eliminate fatalities and serious injuries resulting from traffic accidents. To achieve this goal, the use of self-driving vehicles in traffic is envisioned and a roadmap for the certification of self-driving vehicles is aimed to be determined. However, it is still unclear how the basic safety requirements that autonomous vehicles must meet will be verified and certified, and which methods will be used. This paper focuses on the comparative evaluation of the prominent methods planned to be used in the certification process of autonomous vehicles. It examines the prominent methods used in the certification process, develops a pipeline for the certification process of autonomous vehicles, and determines the stages, actors, and areas where the addressed methods can be applied.

</details>


### [22] [Collaborative Representation Learning for Alignment of Tactile, Language, and Vision Modalities](https://arxiv.org/abs/2511.11512)
*Yiyun Zhou,Mingjing Xu,Jingwei Shi,Quanjiang Li,Jingyuan Chen*

Main category: cs.RO

TL;DR: 提出了TLV-CoRe方法，通过传感器感知调制器和触觉无关解耦学习来统一不同触觉传感器的特征表示，并使用统一桥接适配器增强触觉-语言-视觉三模态交互，显著提升了传感器无关表示学习和跨模态对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有触觉传感器缺乏标准化，导致冗余特征阻碍跨传感器泛化，且现有方法未能充分整合触觉、语言和视觉模态之间的中间通信。

Method: 基于CLIP的触觉-语言-视觉协作表示学习方法，包含传感器感知调制器统一触觉特征、触觉无关解耦学习分离无关特征，以及统一桥接适配器增强三模态交互。

Result: 实验结果表明TLV-CoRe显著改善了传感器无关表示学习和跨模态对齐，为多模态触觉表示提供了新方向。

Conclusion: TLV-CoRe方法有效解决了触觉传感器标准化和多模态融合问题，同时提出了RSS评估框架来公平评估触觉模型的鲁棒性、协同性和稳定性。

Abstract: Tactile sensing offers rich and complementary information to vision and language, enabling robots to perceive fine-grained object properties. However, existing tactile sensors lack standardization, leading to redundant features that hinder cross-sensor generalization. Moreover, existing methods fail to fully integrate the intermediate communication among tactile, language, and vision modalities. To address this, we propose TLV-CoRe, a CLIP-based Tactile-Language-Vision Collaborative Representation learning method. TLV-CoRe introduces a Sensor-Aware Modulator to unify tactile features across different sensors and employs tactile-irrelevant decoupled learning to disentangle irrelevant tactile features. Additionally, a Unified Bridging Adapter is introduced to enhance tri-modal interaction within the shared representation space. To fairly evaluate the effectiveness of tactile models, we further propose the RSS evaluation framework, focusing on Robustness, Synergy, and Stability across different methods. Experimental results demonstrate that TLV-CoRe significantly improves sensor-agnostic representation learning and cross-modal alignment, offering a new direction for multimodal tactile representation.

</details>


### [23] [Scalable Coverage Trajectory Synthesis on GPUs as Statistical Inference](https://arxiv.org/abs/2511.11514)
*Max M. Sun,Jueun Kwon,Todd Murphey*

Main category: cs.RO

TL;DR: 该论文将覆盖运动规划问题重新表述为基于流匹配的统计推断问题，统一了常用统计差异度量与线性二次调节器问题，并通过并行化实现计算加速。


<details>
  <summary>Details</summary>
Motivation: 传统运动规划方法在处理覆盖运动规划时计算效率有限，难以利用现代并行化框架，因为覆盖规划需要考虑整个轨迹的空间分布而非时间序列状态。

Method: 采用流匹配的生成建模技术，将覆盖运动规划表述为统计推断问题，解耦轨迹梯度生成与非线性系统动态下的控制合成。

Result: 该方法能够显著加速计算，特别适合在现代GPU架构上并行化，相比基于航点跟踪的传统方法具有计算优势。

Conclusion: 提出的基于流匹配的统计推断公式为覆盖运动规划提供了可扩展的解决方案，通过并行化实现了计算效率的显著提升。

Abstract: Coverage motion planning is essential to a wide range of robotic tasks. Unlike conventional motion planning problems, which reason over temporal sequences of states, coverage motion planning requires reasoning over the spatial distribution of entire trajectories, making standard motion planning methods limited in computational efficiency and less amenable to modern parallelization frameworks. In this work, we formulate the coverage motion planning problem as a statistical inference problem from the perspective of flow matching, a generative modeling technique that has gained significant attention in recent years. The proposed formulation unifies commonly used statistical discrepancy measures, such as Kullback-Leibler divergence and Sinkhorn divergence, with a standard linear quadratic regulator problem. More importantly, it decouples the generation of trajectory gradients for coverage from the synthesis of control under nonlinear system dynamics, enabling significant acceleration through parallelization on modern computational architectures, particularly Graphics Processing Units (GPUs). This paper focuses on the advantages of this formulation in terms of scalability through parallelization, highlighting its computational benefits compared to conventional methods based on waypoint tracking.

</details>


### [24] [Scalable Policy Evaluation with Video World Models](https://arxiv.org/abs/2511.11520)
*Wei-Cheng Tseng,Jinwei Gu,Qinsheng Zhang,Hanzi Mao,Ming-Yu Liu,Florian Shkurti,Lin Yen-Chen*

Main category: cs.RO

TL;DR: 使用动作条件视频生成模型作为可扩展的世界模型来评估机器人操作策略，无需真实世界交互


<details>
  <summary>Details</summary>
Motivation: 评估通用机器人操作策略在真实世界中成本高、耗时且存在安全风险，而传统仿真方法存在工程量大和仿真到真实差距的问题

Method: 将动作条件集成到预训练视频生成模型中，利用互联网规模的在线视频进行预训练，避免收集昂贵的配对视频-动作数据

Result: 实验表明，在策略排序和实际策略值与预测策略值相关性等指标上，该模型为无真实交互的策略评估提供了有前景的方法

Conclusion: 动作条件视频生成模型为机器人策略评估提供了一种可扩展的解决方案，能够有效利用互联网视频数据并减少对昂贵配对数据的需求

Abstract: Training generalist policies for robotic manipulation has shown great promise, as they enable language-conditioned, multi-task behaviors across diverse scenarios. However, evaluating these policies remains difficult because real-world testing is expensive, time-consuming, and labor-intensive. It also requires frequent environment resets and carries safety risks when deploying unproven policies on physical robots. Manually creating and populating simulation environments with assets for robotic manipulation has not addressed these issues, primarily due to the significant engineering effort required and the often substantial sim-to-real gap, both in terms of physics and rendering. In this paper, we explore the use of action-conditional video generation models as a scalable way to learn world models for policy evaluation. We demonstrate how to incorporate action conditioning into existing pre-trained video generation models. This allows leveraging internet-scale in-the-wild online videos during the pre-training stage, and alleviates the need for a large dataset of paired video-action data, which is expensive to collect for robotic manipulation. Our paper examines the effect of dataset diversity, pre-trained weight and common failure cases for the proposed evaluation pipeline.Our experiments demonstrate that, across various metrics, including policy ranking and the correlation between actual policy values and predicted policy values, these models offer a promising approach for evaluating policies without requiring real-world interactions.

</details>


### [25] [Terrain Costmap Generation via Scaled Preference Conditioning](https://arxiv.org/abs/2511.11529)
*Luisa Mao,Garret Warnell,Peter Stone,Joydeep Biswas*

Main category: cs.RO

TL;DR: SPACER是一种新型地形成本图生成方法，利用合成数据进行训练以泛化到新地形，并通过用户指定的缩放偏好上下文实现快速测试时成本调整。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时实现快速测试时成本适应和泛化到新地形类型，需要一种能兼顾两者的地形成本图生成方法。

Method: 使用合成数据进行训练以泛化到新地形，通过用户指定的缩放偏好上下文实现快速测试时成本调整。

Result: 在七个环境中的五个环境中，SPACER在全局路径规划的各种偏好下实现了最低的后悔值，优于其他方法。

Conclusion: SPACER能够生成高质量的地形成本图，既能泛化到各种地形，又能快速适应测试时的相对成本需求。

Abstract: Successful autonomous robot navigation in off-road domains requires the ability to generate high-quality terrain costmaps that are able to both generalize well over a wide variety of terrains and rapidly adapt relative costs at test time to meet mission-specific needs. Existing approaches for costmap generation allow for either rapid test-time adaptation of relative costs (e.g., semantic segmentation methods) or generalization to new terrain types (e.g., representation learning methods), but not both. In this work, we present scaled preference conditioned all-terrain costmap generation (SPACER), a novel approach for generating terrain costmaps that leverages synthetic data during training in order to generalize well to new terrains, and allows for rapid test-time adaptation of relative costs by conditioning on a user-specified scaled preference context. Using large-scale aerial maps, we provide empirical evidence that SPACER outperforms other approaches at generating costmaps for terrain navigation, with the lowest measured regret across varied preferences in five of seven environments for global path planning.

</details>


### [26] [Volumetric Ergodic Control](https://arxiv.org/abs/2511.11533)
*Jueun Kwon,Max M. Sun,Todd Murphey*

Main category: cs.RO

TL;DR: 提出了一种新的体积状态表示的遍历控制方法，优化空间覆盖效率，相比标准方法提升超过两倍，同时保持100%任务完成率


<details>
  <summary>Details</summary>
Motivation: 现有遍历控制方法将机器人建模为无体积的点，但实际中机器人通过具有物理体积的身体和传感器与环境交互

Method: 引入基于体积状态表示的遍历控制公式，支持任意基于采样的体积模型，计算开销最小，适合实时控制

Result: 在搜索和操作任务中，覆盖效率提升超过两倍，所有实验保持100%任务完成率，优于标准遍历控制方法

Conclusion: 该方法在机械擦除任务中展示了有效性，保持了遍历控制的渐近覆盖保证

Abstract: Ergodic control synthesizes optimal coverage behaviors over spatial distributions for nonlinear systems. However, existing formulations model the robot as a non-volumetric point, but in practice a robot interacts with the environment through its body and sensors with physical volume. In this work, we introduce a new ergodic control formulation that optimizes spatial coverage using a volumetric state representation. Our method preserves the asymptotic coverage guarantees of ergodic control, adds minimal computational overhead for real-time control, and supports arbitrary sample-based volumetric models. We evaluate our method across search and manipulation tasks -- with multiple robot dynamics and end-effector geometries or sensor models -- and show that it improves coverage efficiency by more than a factor of two while maintaining a 100% task completion rate across all experiments, outperforming the standard ergodic control method. Finally, we demonstrate the effectiveness of our method on a robot arm performing mechanical erasing tasks.

</details>
