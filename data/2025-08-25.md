<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 11]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning](https://arxiv.org/abs/2508.15874)
*Yijun Liu,Yuwei Liu,Yuan Meng,Jieheng Zhang,Yuwei Zhou,Ye Li,Jiacheng Jiang,Kangye Ji,Shijia Ge,Zhi Wang,Wenwu Zhu*

Main category: cs.RO

TL;DR: 提出了Spatial Policy (SP)框架，通过显式空间建模和推理来解决现有视觉层次化具身模型缺乏空间感知能力的问题，在11个多样化任务中达到86.7%的平均成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉中心层次化具身模型缺乏空间感知能力，限制了其在复杂环境中将视觉计划转化为可执行控制的有效性。

Method: 设计了三个核心模块：1) 空间条件具身视频生成模块，通过空间计划表进行空间引导预测；2) 基于空间的动作预测模块，协调推理可执行动作；3) 空间推理反馈策略，通过双阶段重规划优化空间计划表。

Result: SP显著优于现有最佳基线方法，平均提升33.0%，在11个多样化任务中达到86.7%的平均成功率。

Conclusion: SP通过显式空间建模和推理，大幅提升了具身模型在机器人控制应用中的实用性。

Abstract: Vision-centric hierarchical embodied models have demonstrated strong
potential for long-horizon robotic control. However, existing methods lack
spatial awareness capabilities, limiting their effectiveness in bridging visual
plans to actionable control in complex environments. To address this problem,
we propose Spatial Policy (SP), a unified spatial-aware visuomotor robotic
manipulation framework via explicit spatial modeling and reasoning.
Specifically, we first design a spatial-conditioned embodied video generation
module to model spatially guided predictions through a spatial plan table.
Then, we propose a spatial-based action prediction module to infer executable
actions with coordination. Finally, we propose a spatial reasoning feedback
policy to refine the spatial plan table via dual-stage replanning. Extensive
experiments show that SP significantly outperforms state-of-the-art baselines,
achieving a 33.0% average improvement over the best baseline. With an 86.7%
average success rate across 11 diverse tasks, SP substantially enhances the
practicality of embodied models for robotic control applications. Code and
checkpoints are maintained at
https://plantpotatoonmoon.github.io/SpatialPolicy/.

</details>


### [2] [UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation](https://arxiv.org/abs/2508.15972)
*Zhaodong Jiang,Ashish Sinha,Tongtong Cao,Yuan Ren,Bingbing Liu,Binbin Xu*

Main category: cs.RO

TL;DR: UnPose是一个零样本、无模型的6D物体姿态估计和重建框架，利用预训练扩散模型的3D先验和不确定性估计，通过3D高斯泼溅表示和增量优化实现高精度姿态估计和3D重建


<details>
  <summary>Details</summary>
Motivation: 传统6D姿态估计依赖CAD模型，但获取成本高且不实用。现有方法虽然尝试利用基础模型绕过这一需求，但通常需要额外训练或产生幻觉几何。需要一种无需CAD模型、无需额外训练的零样本解决方案

Method: 使用预训练多视角扩散模型从单视角RGB-D图像估计初始3D高斯泼溅模型和不确定性。随着新观测的加入，基于不确定性指导增量优化3D模型，并通过位姿图优化确保全局一致性

Result: 在6D姿态估计精度和3D重建质量方面显著优于现有方法，并在真实机器人操作任务中展示了实际应用价值

Conclusion: UnPose成功实现了无需CAD模型和额外训练的零样本6D姿态估计与重建，通过扩散模型先验和不确定性指导的增量优化，为机器人视觉感知提供了实用解决方案

Abstract: Estimating the 6D pose of novel objects is a fundamental yet challenging
problem in robotics, often relying on access to object CAD models. However,
acquiring such models can be costly and impractical. Recent approaches aim to
bypass this requirement by leveraging strong priors from foundation models to
reconstruct objects from single or multi-view images, but typically require
additional training or produce hallucinated geometry. To this end, we propose
UnPose, a novel framework for zero-shot, model-free 6D object pose estimation
and reconstruction that exploits 3D priors and uncertainty estimates from a
pre-trained diffusion model. Specifically, starting from a single-view RGB-D
frame, UnPose uses a multi-view diffusion model to estimate an initial 3D model
using 3D Gaussian Splatting (3DGS) representation, along with pixel-wise
epistemic uncertainty estimates. As additional observations become available,
we incrementally refine the 3DGS model by fusing new views guided by the
diffusion model's uncertainty, thereby continuously improving the pose
estimation accuracy and 3D reconstruction quality. To ensure global
consistency, the diffusion prior-generated views and subsequent observations
are further integrated in a pose graph and jointly optimized into a coherent
3DGS field. Extensive experiments demonstrate that UnPose significantly
outperforms existing approaches in both 6D pose estimation accuracy and 3D
reconstruction quality. We further showcase its practical applicability in
real-world robotic manipulation tasks.

</details>


### [3] [GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System](https://arxiv.org/abs/2508.15990)
*Hung-Jui Huang,Mohammad Amin Mirzaee,Michael Kaess,Wenzhen Yuan*

Main category: cs.RO

TL;DR: GelSLAM是一个仅使用触觉传感的实时3D SLAM系统，能够长时间估计物体姿态并以高保真度重建物体形状，具有亚毫米级精度和低漂移特性


<details>
  <summary>Details</summary>
Motivation: 相比视觉方法，触觉传感在精确性和抗遮挡方面具有优势，特别适合手内操作等高精度任务，需要将触觉感知从局部接触扩展到全局空间感知

Method: 使用触觉衍生的表面法线和曲率进行鲁棒跟踪和闭环检测，而不是传统的点云方法

Result: 能够实时跟踪物体运动且误差低、漂移小，即使对于木质工具等低纹理物体也能实现亚毫米精度的形状重建

Conclusion: GelSLAM将触觉感知扩展到全局、长时程的空间感知，为涉及手内物体交互的精确操作任务奠定了基础

Abstract: Accurately perceiving an object's pose and shape is essential for precise
grasping and manipulation. Compared to common vision-based methods, tactile
sensing offers advantages in precision and immunity to occlusion when tracking
and reconstructing objects in contact. This makes it particularly valuable for
in-hand and other high-precision manipulation tasks. In this work, we present
GelSLAM, a real-time 3D SLAM system that relies solely on tactile sensing to
estimate object pose over long periods and reconstruct object shapes with high
fidelity. Unlike traditional point cloud-based approaches, GelSLAM uses
tactile-derived surface normals and curvatures for robust tracking and loop
closure. It can track object motion in real time with low error and minimal
drift, and reconstruct shapes with submillimeter accuracy, even for low-texture
objects such as wooden tools. GelSLAM extends tactile sensing beyond local
contact to enable global, long-horizon spatial perception, and we believe it
will serve as a foundation for many precise manipulation tasks involving
interaction with objects in hand. The video demo is available on our website:
https://joehjhuang.github.io/gelslam.

</details>


### [4] [Self-Aligning EPM Connector: A Versatile Solution for Adaptive and Multi-Modal Interfaces](https://arxiv.org/abs/2508.16008)
*Bingchao Wang,Adam A. Stokes*

Main category: cs.RO

TL;DR: 基于电永磁技术的多功能连接器，集成了自对准、机械耦合、流体传输和数据通信功能，适用于模块化机器人、电动汽车充电等多种应用场景


<details>
  <summary>Details</summary>
Motivation: 开发一种紧凑型多功能连接器，解决传统连接器在自对准、多介质传输和能量效率方面的局限性，满足现代机器人系统和电动设备对集成化连接解决方案的需求

Method: 采用电永磁（EPM）技术，通过SLA 3D打印制造紧凑结构，集成自对准机构、流体传输通道和数据通信电子控制系统

Result: 实验证明连接器具有可靠的自对准性能、高效的流体传输能力（单回路和双通道模式）、稳健的数据传输，并能适应轴向、角度和横向偏差，同时保持低能耗

Conclusion: 该电永磁多功能连接器技术成熟，具有高度灵活性和低能耗特点，非常适合模块化机器人、电动汽车充电、家用机器人平台和航空航天对接等应用领域

Abstract: This paper presents a multifunctional connector based on electro-permanent
magnet (EPM) technology, integrating self-alignment, mechanical coupling, fluid
transfer, and data communication within a compact SLA-3D printed structure.
Experimental results demonstrate reliable self-alignment, efficient fluid
transfer in single-loop and dual-channel modes, and robust data transmission
via integrated electronic control. The connector exhibits high flexibility in
accommodating axial, angular, and lateral misalignments while maintaining low
energy consumption. These features make it highly suitable for modular
robotics, electric vehicle charging, household robotic platforms, and aerospace
docking applications.

</details>


### [5] [Take That for Me: Multimodal Exophora Resolution with Interactive Questioning for Ambiguous Out-of-View Instructions](https://arxiv.org/abs/2508.16143)
*Akira Oyama,Shoichi Hasegawa,Akira Taniguchi,Yoshinobu Hagiwara,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: MIEL是一个多模态外指消解框架，通过声音定位、语义地图和交互式提问来解决机器人视野外物体的指代问题，性能比现有方法提升1.3-2.0倍


<details>
  <summary>Details</summary>
Motivation: 现有外指消解方法主要依赖视觉数据，无法处理用户或物体不在机器人视野内的真实场景，需要解决模糊语言指令的解读问题

Method: 结合声音源定位(SSL)确定用户位置，构建语义环境地图，利用视觉语言模型(VLMs)和GPT-4o进行交互式提问来消除歧义

Result: 在真实环境实验中，用户可见时性能提升约1.3倍，用户不可见时性能提升约2.0倍，相比不使用SSL和交互提问的方法

Conclusion: MIEL框架通过多模态融合和主动交互，有效解决了日常服务机器人处理视野外物体指代指令的挑战，显著提升了外指消解的准确性

Abstract: Daily life support robots must interpret ambiguous verbal instructions
involving demonstratives such as ``Bring me that cup,'' even when objects or
users are out of the robot's view. Existing approaches to exophora resolution
primarily rely on visual data and thus fail in real-world scenarios where the
object or user is not visible. We propose Multimodal Interactive Exophora
resolution with user Localization (MIEL), which is a multimodal exophora
resolution framework leveraging sound source localization (SSL), semantic
mapping, visual-language models (VLMs), and interactive questioning with
GPT-4o. Our approach first constructs a semantic map of the environment and
estimates candidate objects from a linguistic query with the user's skeletal
data. SSL is utilized to orient the robot toward users who are initially
outside its visual field, enabling accurate identification of user gestures and
pointing directions. When ambiguities remain, the robot proactively interacts
with the user, employing GPT-4o to formulate clarifying questions. Experiments
in a real-world environment showed results that were approximately 1.3 times
better when the user was visible to the robot and 2.0 times better when the
user was not visible to the robot, compared to the methods without SSL and
interactive questioning. The project website is
https://emergentsystemlabstudent.github.io/MIEL/.

</details>


### [6] [GPL-SLAM: A Laser SLAM Framework with Gaussian Process Based Extended Landmarks](https://arxiv.org/abs/2508.16459)
*Ali Emre Balcı,Erhan Ege Keyvan,Emre Özkan*

Main category: cs.RO

TL;DR: 提出了一种基于高斯过程的SLAM方法，使用GP轮廓表示物体地标，在贝叶斯框架下实现机器人位姿和物体地图的联合推断。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法使用网格地图或点云配准，缺乏语义信息和物体级别的环境表示。需要一种能够提供物体数量、面积等语义信息，同时支持概率测量关联的方法。

Method: 采用高斯过程(GP)基于轮廓的物体表示，通过递归方案在线更新轮廓。在完全贝叶斯框架下制定SLAM问题，实现机器人位姿和物体地图的联合推断。

Result: 在合成和真实世界实验中验证了方法的有效性，能够在多样化结构化环境中提供准确的定位和建图性能。

Conclusion: GP轮廓表示不仅提供准确的SLAM性能，还能产生物体形状的置信边界，为安全导航和探索等下游任务提供有价值的信息。

Abstract: We present a novel Simultaneous Localization and Mapping (SLAM) method that
employs Gaussian Process (GP) based landmark (object) representations. Instead
of conventional grid maps or point cloud registration, we model the environment
on a per object basis using GP based contour representations. These contours
are updated online through a recursive scheme, enabling efficient memory usage.
The SLAM problem is formulated within a fully Bayesian framework, allowing
joint inference over the robot pose and object based map. This representation
provides semantic information such as the number of objects and their areas,
while also supporting probabilistic measurement to object associations.
Furthermore, the GP based contours yield confidence bounds on object shapes,
offering valuable information for downstream tasks like safe navigation and
exploration. We validate our method on synthetic and real world experiments,
and show that it delivers accurate localization and mapping performance across
diverse structured environments.

</details>


### [7] [Swarming Without an Anchor (SWA): Robot Swarms Adapt Better to Localization Dropouts Then a Single Robot](https://arxiv.org/abs/2508.16460)
*Jiri Horyna,Roland Jung,Stephan Weiss,Eliseo Ferrante,Martin Saska*

Main category: cs.RO

TL;DR: SWA方法通过融合分散状态估计、鲁棒相互感知和机载传感器数据，使无人机群在个体定位丢失时仅使用相对信息维持横向稳定和群体一致性。


<details>
  <summary>Details</summary>
Motivation: 解决无人机群在个体定位失效时的状态估计问题，提高多无人机系统在不可靠定位环境下的可靠性和韧性。

Method: 提出无锚点群集(SWA)方法，结合分散状态估计、鲁棒相互感知和机载传感器数据融合，通过相对信息实现横向状态估计和群体速度一致性。

Result: 仿真和真实实验验证了方法的有效性，能够在不可靠定位条件下维持群体凝聚行为，仅存在整体平移漂移。

Conclusion: SWA方法为多无人机系统在挑战性定位条件下的紧密协作提供了新机会，增强了系统的可靠性和韧性。

Abstract: In this paper, we present the Swarming Without an Anchor (SWA) approach to
state estimation in swarms of Unmanned Aerial Vehicles (UAVs) experiencing
ego-localization dropout, where individual agents are laterally stabilized
using relative information only. We propose to fuse decentralized state
estimation with robust mutual perception and onboard sensor data to maintain
accurate state awareness despite intermittent localization failures. Thus, the
relative information used to estimate the lateral state of UAVs enables the
identification of the unambiguous state of UAVs with respect to the local
constellation. The resulting behavior reaches velocity consensus, as this task
can be referred to as the double integrator synchronization problem. All
disturbances and performance degradations except a uniform translation drift of
the swarm as a whole is attenuated which is enabling new opportunities in using
tight cooperation for increasing reliability and resilience of multi-UAV
systems. Simulations and real-world experiments validate the effectiveness of
our approach, demonstrating its capability to sustain cohesive swarm behavior
in challenging conditions of unreliable or unavailable primary localization.

</details>


### [8] [Terrain Classification for the Spot Quadrupedal Mobile Robot Using Only Proprioceptive Sensing](https://arxiv.org/abs/2508.16504)
*Sophie Villemure,Jefferson Silveira,Joshua A. Marshall*

Main category: cs.RO

TL;DR: 为波士顿动力Spot机器人开发的基于本体感知信号的复杂地形分类器，能够以97%的准确率识别三种不同地形类型，用于创建可通行性地图和路径规划


<details>
  <summary>Details</summary>
Motivation: 四足机器人在复杂地形上容易发生下沉和打滑等不良行为，需要地形分类器来提供地形类型信息，以便规划更安全的导航路径

Method: 利用Spot机器人提供的100多个本体感知信号（足部穿透、力、关节角度等），结合降维技术提取相关信息，然后应用分类技术根据可通行性区分地形

Result: 在代表性现场测试中，地形分类器能够以约97%的准确率识别三种不同地形类型

Conclusion: 所开发的地形分类器能够有效识别不同地形类型，为四足机器人提供可靠的地形信息，有助于提高在复杂地形上的导航安全性

Abstract: Quadrupedal mobile robots can traverse a wider range of terrain types than
their wheeled counterparts but do not perform the same on all terrain types.
These robots are prone to undesirable behaviours like sinking and slipping on
challenging terrains. To combat this issue, we propose a terrain classifier
that provides information on terrain type that can be used in robotic systems
to create a traversability map to plan safer paths for the robot to navigate.
The work presented here is a terrain classifier developed for a Boston Dynamics
Spot robot. Spot provides over 100 measured proprioceptive signals describing
the motions of the robot and its four legs (e.g., foot penetration, forces,
joint angles, etc.). The developed terrain classifier combines dimensionality
reduction techniques to extract relevant information from the signals and then
applies a classification technique to differentiate terrain based on
traversability. In representative field testing, the resulting terrain
classifier was able to identify three different terrain types with an accuracy
of approximately 97%

</details>


### [9] [On Kinodynamic Global Planning in a Simplicial Complex Environment: A Mixed Integer Approach](https://arxiv.org/abs/2508.16511)
*Otobong Jerome,Alexandr Klimchik,Alexander Maloletov,Geesara Kulathunga*

Main category: cs.RO

TL;DR: 提出了一种针对类车车辆的动力学规划方法，通过优化计算最小时间轨迹和速度剖面，同时优化空间路径和控制序列，在复杂3D地形中高效运行。


<details>
  <summary>Details</summary>
Motivation: 解决类车车辆在复杂地形中的动力学规划问题，需要同时满足边界条件约束并避免局部最优解。

Method: 将问题建模为混合整数分数规划，通过变量变换转化为混合整数双线性目标，再使用McCormick包络松弛为混合整数线性规划。

Result: 相比MPPI和log-MPPI等规划器，该方法生成解的速度快104倍，且严格满足所有约束条件。

Conclusion: 该方法在复杂3D地形中实现了高效且约束满足的动力学轨迹规划，计算效率显著优于现有方法。

Abstract: This work casts the kinodynamic planning problem for car-like vehicles as an
optimization task to compute a minimum-time trajectory and its associated
velocity profile, subject to boundary conditions on velocity, acceleration, and
steering. The approach simultaneously optimizes both the spatial path and the
sequence of acceleration and steering controls, ensuring continuous motion from
a specified initial position and velocity to a target end position and
velocity.The method analyzes the admissible control space and terrain to avoid
local minima. The proposed method operates efficiently in simplicial complex
environments, a preferred terrain representation for capturing intricate 3D
landscapes. The problem is initially posed as a mixed-integer fractional
program with quadratic constraints, which is then reformulated into a
mixed-integer bilinear objective through a variable transformation and
subsequently relaxed to a mixed-integer linear program using McCormick
envelopes. Comparative simulations against planners such as MPPI and log-MPPI
demonstrate that the proposed approach generates solutions 104 times faster
while strictly adhering to the specified constraints

</details>


### [10] [Comparative Analysis of UAV Path Planning Algorithms for Efficient Navigation in Urban 3D Environments](https://arxiv.org/abs/2508.16515)
*Hichem Cheriet,Khellat Kihel Badra,Chouraqui Samira*

Main category: cs.RO

TL;DR: 本文比较了A*、RRT*和PSO三种路径规划算法在3D城市环境中的性能，实验表明A*在计算效率和路径质量方面表现最佳


<details>
  <summary>Details</summary>
Motivation: 无人机路径规划面临诸多挑战，现有算法存在局限性，需要系统评估不同算法在复杂城市环境中的表现

Method: 在3D城市环境中设计三组实验，测试A*、RRT*和PSO算法在不同地图大小、高度、障碍物密度和尺寸条件下的性能

Result: A*算法在计算效率和路径质量方面表现最优；PSO适合密集环境和急转弯；RRT*在所有实验中表现均衡

Conclusion: A*是最佳选择，PSO适合特定场景，RRT*提供平衡的解决方案，算法选择应根据具体应用需求

Abstract: The most crucial challenges for UAVs are planning paths and avoiding
obstacles in their way. In recent years, a wide variety of path-planning
algorithms have been developed. These algorithms have successfully solved
path-planning problems; however, they suffer from multiple challenges and
limitations. To test the effectiveness and efficiency of three widely used
algorithms, namely A*, RRT*, and Particle Swarm Optimization (PSO), this paper
conducts extensive experiments in 3D urban city environments cluttered with
obstacles. Three experiments were designed with two scenarios each to test the
aforementioned algorithms. These experiments consider different city map sizes,
different altitudes, and varying obstacle densities and sizes in the
environment. According to the experimental results, the A* algorithm
outperforms the others in both computation efficiency and path quality. PSO is
especially suitable for tight turns and dense environments, and RRT* offers a
balance and works well across all experiments due to its randomized approach to
finding solutions.

</details>


### [11] [Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems](https://arxiv.org/abs/2508.16574)
*Yizhi Wang,Degang Xu,Yongfang Xie,Shuzhong Tan,Xianan Zhou,Peng Chen*

Main category: cs.RO

TL;DR: 提出了一种用于四轮独立转向驱动系统的分层决策框架，结合深度强化学习和模糊逻辑控制，实现高效稳定的自主导航


<details>
  <summary>Details</summary>
Motivation: 为了解决传统导航方法在4WISD系统中存在的训练效率低、稳定性差以及机械约束难以保证的问题，需要一种既能保证任务性能又能确保物理可行性的解决方案

Method: 采用分层决策框架：高层使用深度强化学习生成全局运动指令，低层使用模糊逻辑控制器强制执行运动学约束，防止机械应变和车轮打滑

Result: 仿真实验表明该框架优于传统导航方法，具有更高的训练效率和稳定性，相比纯DRL方案减少了异常行为。真实环境验证证实了在动态工业场景中的安全有效导航能力

Conclusion: 该工作为在复杂真实场景中部署4WISD移动机器人提供了一个可扩展且可靠的解决方案，成功结合了DRL的智能决策能力和模糊逻辑的约束保障优势

Abstract: This paper presents a hierarchical decision-making framework for autonomous
navigation in four-wheel independent steering and driving (4WISD) systems. The
proposed approach integrates deep reinforcement learning (DRL) for high-level
navigation with fuzzy logic for low-level control to ensure both task
performance and physical feasibility. The DRL agent generates global motion
commands, while the fuzzy logic controller enforces kinematic constraints to
prevent mechanical strain and wheel slippage. Simulation experiments
demonstrate that the proposed framework outperforms traditional navigation
methods, offering enhanced training efficiency and stability and mitigating
erratic behaviors compared to purely DRL-based solutions. Real-world
validations further confirm the framework's ability to navigate safely and
effectively in dynamic industrial settings. Overall, this work provides a
scalable and reliable solution for deploying 4WISD mobile robots in complex,
real-world scenarios.

</details>
