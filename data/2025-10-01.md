<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 43]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [When and How to Express Empathy in Human-Robot Interaction Scenarios](https://arxiv.org/abs/2509.25200)
*Christian Arzate Cruz,Edwin C. Montiel-Vazquez,Chikara Maeda,Randy Gomez*

Main category: cs.RO

TL;DR: 提出了whEE框架，使社交机器人能够检测何时需要表达同理心并生成适当回应


<details>
  <summary>Details</summary>
Motivation: 在机器人中融入同理心行为可以提高其社交效果和互动质量

Method: 使用大型语言模型识别人类互动中的关键行为同理心线索，通过whEE框架检测同理心需求并生成回应

Result: 在与人形机器人Haru的人机交互场景中评估，whEE能有效识别和回应同理心线索

Conclusion: 为设计能够在不同互动情境中自适应调节同理心水平的社交机器人提供了有价值的见解

Abstract: Incorporating empathetic behavior into robots can improve their social
effectiveness and interaction quality. In this paper, we present whEE (when and
how to express empathy), a framework that enables social robots to detect when
empathy is needed and generate appropriate responses. Using large language
models, whEE identifies key behavioral empathy cues in human interactions. We
evaluate it in human-robot interaction scenarios with our social robot, Haru.
Results show that whEE effectively identifies and responds to empathy cues,
providing valuable insights for designing social robots capable of adaptively
modulating their empathy levels across various interaction contexts.

</details>


### [2] [BEV-VLM: Trajectory Planning via Unified BEV Abstraction](https://arxiv.org/abs/2509.25249)
*Guancheng Chen,Sheng Yang,Tong Zhan,Jian Wang*

Main category: cs.RO

TL;DR: BEV-VLM是一个用于自动驾驶轨迹规划的新框架，它利用鸟瞰图特征作为视觉语言模型的视觉输入，相比传统方法显著提升了规划精度和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅依赖原始视觉数据（如相机图像）进行轨迹规划存在局限性，需要更高效和几何一致的场景表示来提升规划准确性。

Method: 使用融合多模态传感器数据（相机和LiDAR）并与高清地图对齐生成的BEV特征图作为视觉语言模型的输入，提供统一的BEV-HD Map格式。

Result: 在nuScenes数据集上的实验结果显示，规划精度提升了44.8%，并实现了完全的碰撞避免。

Conclusion: 视觉语言模型能够有效解释处理过的视觉表示（如BEV特征），扩展了它们在轨迹规划中超越原始图像的应用范围。

Abstract: This paper introduces BEV-VLM, a novel framework for trajectory planning in
autonomous driving that leverages Vision-Language Models (VLMs) with Bird's-Eye
View (BEV) feature maps as visual inputs. Unlike conventional approaches that
rely solely on raw visual data such as camera images, our method utilizes
highly compressed and informative BEV representations, which are generated by
fusing multi-modal sensor data (e.g., camera and LiDAR) and aligning them with
HD Maps. This unified BEV-HD Map format provides a geometrically consistent and
rich scene description, enabling VLMs to perform accurate trajectory planning.
Experimental results on the nuScenes dataset demonstrate 44.8% improvements in
planning accuracy and complete collision avoidance. Our work highlights that
VLMs can effectively interpret processed visual representations like BEV
features, expanding their applicability beyond raw images in trajectory
planning.

</details>


### [3] [SRMP: Search-Based Robot Motion Planning Library](https://arxiv.org/abs/2509.25352)
*Itamar Mishani,Yorai Shaoul,Ramkumar Natarajan,Jiaoyang Li,Maxim Likhachev*

Main category: cs.RO

TL;DR: SRMP是一个专为机器人操作设计的运动规划软件框架，通过生成一致可靠的轨迹，满足工业和安全关键应用的需求，并首次提供多机器人操作任务的运动规划算法。


<details>
  <summary>Details</summary>
Motivation: 现有运动规划框架在高风险应用中缺乏足够的可预测性和可重复性，无法满足工业安全环境和高质量运动数据集创建的需求。

Method: 开发了SRMP框架，提供Python和C++ API，与MuJoCo、Sapien等主流模拟器集成，包含MoveIt!插件，支持多机器人操作任务规划。

Result: SRMP能够生成一致可靠的轨迹，满足工业和安全关键应用的严格要求，在多样化机器人系统中为运动规划的一致性设立了新标准。

Conclusion: SRMP填补了现有运动规划工具在可预测性和可重复性方面的不足，为机器人操作提供了可靠的解决方案，特别适用于多机器人系统和安全关键应用。

Abstract: Motion planning is a critical component in any robotic system. Over the
years, powerful tools like the Open Motion Planning Library (OMPL) have been
developed, offering numerous motion planning algorithms. However, existing
frameworks often struggle to deliver the level of predictability and
repeatability demanded by high-stakes applications -- ranging from ensuring
safety in industrial environments to the creation of high-quality motion
datasets for robot learning. Complementing existing tools, we introduce SRMP
(Search-based Robot Motion Planning), a new software framework tailored for
robotic manipulation. SRMP distinguishes itself by generating consistent and
reliable trajectories, and is the first software tool to offer motion planning
algorithms for multi-robot manipulation tasks. SRMP easily integrates with
major simulators, including MuJoCo, Sapien, Genesis, and PyBullet via a Python
and C++ API. SRMP includes a dedicated MoveIt! plugin that enables immediate
deployment on robot hardware and seamless integration with existing pipelines.
Through extensive evaluations, we demonstrate in this paper that SRMP not only
meets the rigorous demands of industrial and safety-critical applications but
also sets a new standard for consistency in motion planning across diverse
robotic systems. Visit srmp.readthedocs.io for SRMP documentation and
tutorials.

</details>


### [4] [SARM: Stage-Aware Reward Modeling for Long Horizon Robot Manipulation](https://arxiv.org/abs/2509.25358)
*Qianzhong Chen,Justin Yu,Mac Schwager,Pieter Abbeel,Fred Shentu,Philipp Wu*

Main category: cs.RO

TL;DR: 提出了一个阶段感知的视频奖励建模框架，通过联合预测高级任务阶段和细粒度进度来改进长时程接触式操作任务的学习效果，并基于此提出了奖励对齐的行为克隆方法。


<details>
  <summary>Details</summary>
Motivation: 解决大规模机器人学习在长时程、接触丰富的操作任务（如可变形物体处理）中因演示质量不一致而面临的挑战，通过奖励建模提供稳定的进度信号。

Method: 使用阶段感知的视频奖励建模框架，自动从自然语言子任务注释中推导奖励标签，并提出了奖励对齐的行为克隆方法，通过奖励过滤高质量数据并重新加权样本。

Result: 奖励模型在验证和真实机器人测试中优于基线方法，RA-BC方法在折叠T恤任务中，从平整状态达到83%成功率，从皱褶状态达到67%成功率，远超传统行为克隆的8%和0%成功率。

Conclusion: 奖励建模是实现可扩展、标注高效且鲁棒的长时程操作模仿学习的关键推动因素。

Abstract: Large-scale robot learning has recently shown promise for enabling robots to
perform complex tasks by integrating perception, control, and language
understanding. Yet, it struggles with long-horizon, contact-rich manipulation
such as deformable object handling, where demonstration quality is
inconsistent. Reward modeling offers a natural solution: by providing grounded
progress signals, it transforms noisy demonstrations into stable supervision
that generalizes across diverse trajectories. We introduce a stage-aware,
video-based reward modeling framework that jointly predicts high-level task
stages and fine-grained progress. Reward labels are automatically derived from
natural language subtask annotations, ensuring consistent progress estimation
across variable-length demonstrations. This design overcomes frame-index
labeling, which fails in variable-duration tasks like folding a T-shirt. Our
reward model demonstrates robustness to variability, generalization to
out-of-distribution settings, and strong utility for policy training. Building
on it, we propose Reward-Aligned Behavior Cloning (RA-BC), which filters
high-quality data and reweights samples by reward. Experiments show the reward
model alone outperforms baselines on validation and real robot rollouts.
Integrated into RA-BC, our approach achieves 83\% success on folding T-shirts
from the flattened state and 67\% from the crumpled state -- far surpassing
vanilla behavior cloning, which attains only 8\% and 0\% success. Overall, our
results highlight reward modeling as a key enabler for scalable,
annotation-efficient, and robust imitation learning in long-horizon
manipulation.

</details>


### [5] [Parallel Heuristic Search as Inference for Actor-Critic Reinforcement Learning Models](https://arxiv.org/abs/2509.25402)
*Hanlan Yang,Itamar Mishani,Luca Pivetti,Zachary Kingston,Maxim Likhachev*

Main category: cs.RO

TL;DR: 提出P-ACHS算法，一种基于Actor-Critic架构的并行最佳优先搜索方法，用于提升强化学习在机器人任务中的推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Actor-Critic模型部署策略过于简单，通常仅依赖直接的动作策略展开，未能充分利用Actor-Critic架构的潜力来提升推理效率。

Method: 采用并行最佳优先搜索算法，利用Actor网络生成动作，Critic网络提供代价估计来指导搜索。实现动作和代价估计的批量生成，以及图扩展的多线程并行化。

Result: 在机器人操作任务中表现出有效性，包括无碰撞运动规划和接触丰富的交互任务（如非抓取推动）。

Conclusion: P-ACHS算法通过充分利用Actor-Critic架构的两个组件，实现了高效的并行推理，在复杂机器人任务中具有显著优势。

Abstract: Actor-Critic models are a class of model-free deep reinforcement learning
(RL) algorithms that have demonstrated effectiveness across various robot
learning tasks. While considerable research has focused on improving training
stability and data sampling efficiency, most deployment strategies have
remained relatively simplistic, typically relying on direct actor policy
rollouts. In contrast, we propose \pachs{} (\textit{P}arallel
\textit{A}ctor-\textit{C}ritic \textit{H}euristic \textit{S}earch), an
efficient parallel best-first search algorithm for inference that leverages
both components of the actor-critic architecture: the actor network generates
actions, while the critic network provides cost-to-go estimates to guide the
search. Two levels of parallelism are employed within the search -- actions and
cost-to-go estimates are generated in batches by the actor and critic networks
respectively, and graph expansion is distributed across multiple threads. We
demonstrate the effectiveness of our approach in robotic manipulation tasks,
including collision-free motion planning and contact-rich interactions such as
non-prehensile pushing. Visit p-achs.github.io for demonstrations and examples.

</details>


### [6] [CoTaP: Compliant Task Pipeline and Reinforcement Learning of Its Controller with Compliance Modulation](https://arxiv.org/abs/2509.25443)
*Zewen He,Chenyuan Chen,Dilshod Azizov,Yoshihiko Nakamura*

Main category: cs.RO

TL;DR: 提出了Compliant Task Pipeline (CoTaP)，一个结合基于学习的控制和基于模型合规控制的人形机器人全身运动控制框架，通过两阶段强化学习实现可调节的合规性。


<details>
  <summary>Details</summary>
Motivation: 解决当前基于人类运动数据的学习控制方法缺乏力数据，导致机器人难以在真实环境中实现适当合规性的问题。

Method: 采用两阶段双智能体强化学习框架：第一阶段训练基于位置控制的基础策略；第二阶段将上半身策略与基于模型的合规控制结合，下半身由基础策略指导，通过SPD流形上的合规调制确保系统稳定性。

Result: 在仿真中验证了策略的可行性，主要比较了不同合规设置下对外部扰动的响应。

Conclusion: CoTaP框架能够有效整合基于学习的控制和合规控制，为人形机器人提供可调节的交互合规性。

Abstract: Humanoid whole-body locomotion control is a critical approach for humanoid
robots to leverage their inherent advantages. Learning-based control methods
derived from retargeted human motion data provide an effective means of
addressing this issue. However, because most current human datasets lack
measured force data, and learning-based robot control is largely
position-based, achieving appropriate compliance during interaction with real
environments remains challenging. This paper presents Compliant Task Pipeline
(CoTaP): a pipeline that leverages compliance information in the learning-based
structure of humanoid robots. A two-stage dual-agent reinforcement learning
framework combined with model-based compliance control for humanoid robots is
proposed. In the training process, first a base policy with a position-based
controller is trained; then in the distillation, the upper-body policy is
combined with model-based compliance control, and the lower-body agent is
guided by the base policy. In the upper-body control, adjustable task-space
compliance can be specified and integrated with other controllers through
compliance modulation on the symmetric positive definite (SPD) manifold,
ensuring system stability. We validated the feasibility of the proposed
strategy in simulation, primarily comparing the responses to external
disturbances under different compliance settings.

</details>


### [7] [Online Mapping for Autonomous Driving: Addressing Sensor Generalization and Dynamic Map Updates in Campus Environments](https://arxiv.org/abs/2509.25542)
*Zihan Zhang,Abhijit Ravichandran,Pragnya Korti,Luobin Wang,Henrik I. Christensen*

Main category: cs.RO

TL;DR: 在校园高尔夫球车平台上部署的实时在线地图生成系统，使用双前摄像头和LiDAR传感器，能够自动生成和更新高精地图，解决传统HD地图制作成本高、维护困难的问题。


<details>
  <summary>Details</summary>
Motivation: 传统高精地图制作劳动密集、成本高昂，且在动态环境中难以维护，需要开发在线地图生成系统来应对这些挑战。

Method: 在配备双前摄像头和LiDAR传感器的校园高尔夫球车平台上部署在线地图系统，通过校园特定数据微调SemVecMap模型，实现增量生成和更新预测的HD地图。

Result: 该系统能够生成准确的地图预测，并支持持续更新，成功捕捉环境变化，在真实自动驾驶场景中展现出实用价值。

Conclusion: 该在线地图系统为自动驾驶提供了可行的实时地图生成解决方案，能够适应动态环境变化，具有重要的实际应用价值。

Abstract: High-definition (HD) maps are essential for autonomous driving, providing
precise information such as road boundaries, lane dividers, and crosswalks to
enable safe and accurate navigation. However, traditional HD map generation is
labor-intensive, expensive, and difficult to maintain in dynamic environments.
To overcome these challenges, we present a real-world deployment of an online
mapping system on a campus golf cart platform equipped with dual front cameras
and a LiDAR sensor. Our work tackles three core challenges: (1) labeling a 3D
HD map for campus environment; (2) integrating and generalizing the SemVecMap
model onboard; and (3) incrementally generating and updating the predicted HD
map to capture environmental changes. By fine-tuning with campus-specific data,
our pipeline produces accurate map predictions and supports continual updates,
demonstrating its practical value in real-world autonomous driving scenarios.

</details>


### [8] [Exhaustive-Serve-Longest Control for Multi-robot Scheduling Systems](https://arxiv.org/abs/2509.25556)
*Mohammad Merati,David Castañón*

Main category: cs.RO

TL;DR: 提出了ESL策略用于多机器人多队列系统的在线任务分配，该策略在当前位置非空时进行穷尽服务，空闲时切换到最长未占用的非空位置，并被证明是最优策略。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人多队列系统中存在随机到达和切换延迟的在线任务分配问题，需要设计简单实用的实时调度策略。

Method: 建立了折扣成本马尔可夫决策过程模型，提出了ESL策略：当前位置非空时穷尽服务，空闲时切换到最长未占用的非空位置。

Result: 在不同服务器-位置比例和负载下，ESL始终产生更低的折扣持有成本和更小的平均队列长度，行动时间分数显示更多服务和受限的切换。

Conclusion: ESL策略的简单性和鲁棒性使其成为实时多机器人调度系统的实用默认选择。

Abstract: We study online task allocation for multi-robot, multi-queue systems with
stochastic arrivals and switching delays. Time is slotted; each location can
host at most one robot per slot; service consumes one slot; switching between
locations incurs a one-slot travel delay; and arrivals are independent
Bernoulli processes. We formulate a discounted-cost Markov decision process and
propose Exhaustive-Serve-Longest (ESL), a simple real-time policy that serves
exhaustively when the current location is nonempty and, when idle, switches to
a longest unoccupied nonempty location, and we prove the optimality of this
policy. As baselines, we tune a fixed-dwell cyclic policy via a discrete-time
delay expression and implement a first-come-first-serve policy. Across
server-to-location ratios and loads, ESL consistently yields lower discounted
holding cost and smaller mean queue lengths, with action-time fractions showing
more serving and restrained switching. Its simplicity and robustness make ESL a
practical default for real-time multi-robot scheduling systems.

</details>


### [9] [Field Calibration of Hyperspectral Cameras for Terrain Inference](https://arxiv.org/abs/2509.25663)
*Nathaniel Hanson,Benjamin Pyatski,Samuel Hibbard,Gary Lvov,Oscar De La Garza,Charles DiMarzio,Kristen L. Dorsey,Taşkın Padır*

Main category: cs.RO

TL;DR: 提出了一种移动机器人多波长高光谱成像系统HYPER DRIVE，能够通过反射率校准在不同光照条件下进行光谱分析，用于识别植被健康指数和土壤含水量。


<details>
  <summary>Details</summary>
Motivation: RGB视觉系统难以区分地形内部差异（如含水量），而近红外光谱能提供有用的类内识别信息，但准确分析高度依赖环境光照条件。

Method: 开发了收集和配准多波长高光谱图像的系统架构，描述了在变化光照条件下对相机进行反射率校准的方法。

Result: 展示了系统能够从移动机器人平台计算植被健康指数和土壤含水量。

Conclusion: HYPER DRIVE系统为移动机器人提供了实用的多波长高光谱成像能力，能够有效分析地形内部差异特性。

Abstract: Intra-class terrain differences such as water content directly influence a
vehicle's ability to traverse terrain, yet RGB vision systems may fail to
distinguish these properties. Evaluating a terrain's spectral content beyond
red-green-blue wavelengths to the near infrared spectrum provides useful
information for intra-class identification. However, accurate analysis of this
spectral information is highly dependent on ambient illumination. We
demonstrate a system architecture to collect and register multi-wavelength,
hyperspectral images from a mobile robot and describe an approach to
reflectance calibrate cameras under varying illumination conditions. To
showcase the practical applications of our system, HYPER DRIVE, we demonstrate
the ability to calculate vegetative health indices and soil moisture content
from a mobile robot platform.

</details>


### [10] [dVLA: Diffusion Vision-Language-Action Model with Multimodal Chain-of-Thought](https://arxiv.org/abs/2509.25681)
*Junjie Wen,Minjie Zhu,Jiaming Liu,Zhiyuan Liu,Yicun Yang,Linfeng Zhang,Shanghang Zhang,Yichen Zhu,Yi Xu*

Main category: cs.RO

TL;DR: dVLA是一个基于扩散的视觉-语言-动作模型，通过多模态思维链统一视觉感知、语言推理和机器人控制，在单一扩散目标下联合优化，实现了卓越的跨模态推理能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型正在成为下一代机器人范式，需要统一视觉感知、语言理解和机器人控制，以增强跨模态推理和对新指令、新物体的泛化能力。

Method: 采用扩散模型框架，结合多模态思维链，在单一扩散目标下联合优化感知、语言理解和动作。通过前缀注意力掩码和KV缓存两种加速策略降低推理延迟。

Result: 在LIBERO基准测试中达到96.4%的平均成功率，超越离散和连续动作策略；在真实Franka机器人上成功完成包括需要多步规划的复杂分拣任务在内的多样化任务套件。

Conclusion: 统一的扩散框架为实用、高性能的视觉-语言-动作机器人系统展现了巨大潜力。

Abstract: Vision-Language-Action (VLA) models are emerging as a next-generation
paradigm for robotics. We introduce dVLA, a diffusion-based VLA that leverages
a multimodal chain-of-thought to unify visual perception, language reasoning,
and robotic control in a single system. dVLA jointly optimizes perception,
language understanding, and action under a single diffusion objective, enabling
stronger cross-modal reasoning and better generalization to novel instructions
and objects. For practical deployment, we mitigate inference latency by
incorporating two acceleration strategies, a prefix attention mask and KV
caching, yielding up to around times speedup at test-time inference. We
evaluate dVLA in both simulation and the real world: on the LIBERO benchmark,
it achieves state-of-the-art performance with a 96.4% average success rate,
consistently surpassing both discrete and continuous action policies; on a real
Franka robot, it succeeds across a diverse task suite, including a challenging
bin-picking task that requires multi-step planning, demonstrating robust
real-world performance. Together, these results underscore the promise of
unified diffusion frameworks for practical, high-performance VLA robotics.

</details>


### [11] [Hierarchical Diffusion Motion Planning with Task-Conditioned Uncertainty-Aware Priors](https://arxiv.org/abs/2509.25685)
*Amelie Minji Kim,Anqi Wu,Ye Zhao*

Main category: cs.RO

TL;DR: 提出了一种新颖的分层扩散规划器，将任务和运动结构直接嵌入到噪声模型中，使用任务条件化的结构化高斯噪声代替标准各向同性高斯噪声，提高了规划成功率和轨迹质量。


<details>
  <summary>Details</summary>
Motivation: 标准扩散规划器使用零均值各向同性高斯噪声，缺乏对任务和运动结构的建模能力。本文旨在通过结构化噪声模型更好地捕捉任务相关的轨迹特征。

Method: 将稀疏的任务关键状态或时间作为噪声观测，生成高斯过程运动规划先验。采用分层结构：上层实例化任务条件化结构化高斯，下层在该固定先验下对完整轨迹进行去噪。

Result: 在Maze2D目标到达和KUKA积木堆叠任务中，相比各向同性基线方法，获得了更高的成功率、更平滑的轨迹和更强的任务对齐性。消融研究表明结构化噪声过程提供了超越神经网络条件化的额外优势。

Conclusion: 该方法将先验概率质量集中在可行、平滑且语义有意义的轨迹附近，同时保持了可处理性，为扩散规划提供了更有效的结构化噪声建模方法。

Abstract: We propose a novel hierarchical diffusion planner that embeds task and motion
structure directly in the noise model. Unlike standard diffusion-based planners
that use zero-mean, isotropic Gaussian noise, we employ a family of
task-conditioned structured Gaussians whose means and covariances are derived
from Gaussian Process Motion Planning (GPMP): sparse, task-centric key states
or their associated timings (or both) are treated as noisy observations to
produce a prior instance. We first generalize the standard diffusion process to
biased, non-isotropic corruption with closed-form forward and posterior
expressions. Building on this, our hierarchy separates prior instantiation from
trajectory denoising: the upper level instantiates a task-conditioned
structured Gaussian (mean and covariance), and the lower level denoises the
full trajectory under that fixed prior. Experiments on Maze2D goal-reaching and
KUKA block stacking show improved success rates, smoother trajectories, and
stronger task alignment compared to isotropic baselines. Ablation studies
indicate that explicitly structuring the corruption process offers benefits
beyond simply conditioning the neural network. Overall, our method concentrates
probability mass of prior near feasible, smooth, and semantically meaningful
trajectories while maintaining tractability. Our project page is available at
https://hta-diffusion.github.io.

</details>


### [12] [OmniNav: A Unified Framework for Prospective Exploration and Visual-Language Navigation](https://arxiv.org/abs/2509.25687)
*Xinda Xue,Junjun Hu,Minghua Luo,Xie Shichao,Jintao Chen,Zixun Xie,Quan Kuichen,Guo Wei,Mu Xu,Zedong Chu*

Main category: cs.RO

TL;DR: OmniNav是一个统一的机器人导航框架，能够处理指令目标、物体目标、点目标和前沿探索等多种导航范式，通过快速-慢速模块协作和连续空间路径点预测实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 现有导航模型在统一处理多样化导航范式方面存在不足，导致成功率低和泛化能力有限。需要开发一个能够同时处理多种导航任务的统一框架。

Method: 采用快速-慢速系统设计：快速模块使用短时域视觉上下文和子任务生成路径点，慢速模块进行深思熟虑的规划；集成大规模通用训练数据集进行多任务联合训练。

Result: OmniNav在各种导航基准测试中达到最先进性能，支持高达5Hz的控制频率，在真实世界部署中验证了其有效性。

Conclusion: OmniNav为具身导航提供了实用见解，为开发多功能、高度可泛化的机器人智能开辟了可扩展路径。

Abstract: Embodied navigation presents a core challenge for intelligent robots,
requiring the comprehension of visual environments, natural language
instructions, and autonomous exploration. Existing models often fall short in
offering a unified solution across diverse navigation paradigms, resulting in
low success rates and limited generalization. We introduce OmniNav, a unified
framework addressing instruct-goal, object-goal, point-goal navigation, and
frontier-based exploration within a single architecture. Our approach features
a lightweight, low-latency policy that accurately predicts continuous-space
waypoints (coordinates and orientations). This policy surpasses action-chunk
methods in precision and supports real-world deployment at control frequencies
up to 5 Hz. Architecturally, OmniNav employs a fast-slow system design: a fast
module generates waypoints using short-horizon visual context and subtasks,
while a slow module performs deliberative planning with long-horizon
observations and candidate frontiers to select subsequent subgoals and
subtasks. This collaboration enhances path efficiency and maintains trajectory
coherence, particularly in exploration and memory-intensive scenarios.
Crucially, we identify that the primary bottleneck isn't merely navigation
policy learning, but a robust understanding of general instructions and
objects. To boost generalization, OmniNav integrates large-scale,
general-purpose training datasets, including those for image captioning and
visual recognition, into a joint multi-task regimen. This significantly
improves success rates and robustness. Extensive experiments confirm OmniNav's
state-of-the-art performance across various navigation benchmarks, with
real-world deployment further validating its efficacy. OmniNav provides
practical insights for embodied navigation, charting a scalable path towards
versatile, highly generalizable robotic intelligence.

</details>


### [13] [VLA Model Post-Training via Action-Chunked PPO and Self Behavior Cloning](https://arxiv.org/abs/2509.25718)
*Si-Cheng Wang,Tian-Yu Xiang,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Shuang-Yi Wang,Ao-Qun Jin,Zeng-Guang Hou*

Main category: cs.RO

TL;DR: 提出了一种基于动作分块的PPO强化学习方法，结合行为克隆来解决VLA模型后训练中的稀疏奖励和不稳定训练问题，在MetaWorld基准测试中取得了93%的成功率和42.17步的平均成功步数。


<details>
  <summary>Details</summary>
Motivation: 强化学习是视觉-语言-动作模型后训练的有前景方向，但实际部署受到稀疏奖励和不稳定训练的阻碍。

Method: 使用动作分块的近端策略优化方法，结合自收集演示的行为克隆。通过聚合连续动作为分块来改善策略的时间一致性和反馈密度，并应用动态更新的演示缓冲区和自适应权重调整。

Result: 在MetaWorld基准测试中表现优于监督微调，达到0.93的高成功率和42.17步的平均成功步数。

Conclusion: 证明了强化学习在VLA后训练中的可行性，为下游VLA应用奠定了基础。

Abstract: Reinforcement learning (RL) is a promising avenue for post-training
vision-language-action (VLA) models, but practical deployment is hindered by
sparse rewards and unstable training. This work mitigates these challenges by
introducing an action chunk based on proximal policy optimization (PPO) with
behavior cloning using self-collected demonstrations. Aggregating consecutive
actions into chunks improves the temporal consistency of the policy and the
density of informative feedback. In addition, an auxiliary behavior cloning
loss is applied with a dynamically updated demonstration buffer that
continually collects high-quality task trials during training. The relative
weight between the action-chunked PPO objective and the self behavior clone
auxiliary loss is adapted online to stabilize the post-training process.
Experiments on the MetaWorld benchmark indicate improved performance over
supervised fine-tuning, achieving a high success rate (0.93) and few steps to
success (42.17). These results demonstrate the viability of RL for VLA
post-training and help lay the groundwork for downstream VLA applications.

</details>


### [14] [TacRefineNet: Tactile-Only Grasp Refinement Between Arbitrary In-Hand Object Poses](https://arxiv.org/abs/2509.25746)
*Shuaijun Wang,Haoran Zhou,Diyun Xiang,Yangwei You*

Main category: cs.RO

TL;DR: 提出了TacRefineNet，一个仅使用触觉的框架，通过多指指尖传感实现已知物体在任意目标姿态下的精细手内姿态精炼。该方法基于触觉反馈迭代调整末端执行器姿态，将物体对齐到期望配置。


<details>
  <summary>Details</summary>
Motivation: 尽管传统灵巧抓取流程和最近的视觉-语言-动作方法都有进展，但抓取执行阶段仍然容易受到姿态不准确的影响，特别是在长时程任务中，这削弱了整体性能。为了解决这个"最后一英里"挑战。

Method: 设计了一个多分支策略网络，融合来自多个手指的触觉输入以及本体感知来预测精确的控制更新。通过结合基于物理的触觉模型在MuJoCo中的大规模模拟数据和物理系统收集的真实数据来训练该策略。

Result: 比较实验表明，在模拟数据上预训练并用少量真实数据微调，相比仅使用模拟训练显著提高了性能。大量真实世界实验验证了该方法的有效性，仅使用触觉输入实现了毫米级的抓取精度。

Conclusion: 据我们所知，这是第一个仅通过多指触觉传感实现任意手内姿态精炼的方法。

Abstract: Despite progress in both traditional dexterous grasping pipelines and recent
Vision-Language-Action (VLA) approaches, the grasp execution stage remains
prone to pose inaccuracies, especially in long-horizon tasks, which undermines
overall performance. To address this "last-mile" challenge, we propose
TacRefineNet, a tactile-only framework that achieves fine in-hand pose
refinement of known objects in arbitrary target poses using multi-finger
fingertip sensing. Our method iteratively adjusts the end-effector pose based
on tactile feedback, aligning the object to the desired configuration. We
design a multi-branch policy network that fuses tactile inputs from multiple
fingers along with proprioception to predict precise control updates. To train
this policy, we combine large-scale simulated data from a physics-based tactile
model in MuJoCo with real-world data collected from a physical system.
Comparative experiments show that pretraining on simulated data and fine-tuning
with a small amount of real data significantly improves performance over
simulation-only training. Extensive real-world experiments validate the
effectiveness of the method, achieving millimeter-level grasp accuracy using
only tactile input. To our knowledge, this is the first method to enable
arbitrary in-hand pose refinement via multi-finger tactile sensing alone.
Project website is available at https://sites.google.com/view/tacrefinenet

</details>


### [15] [Best of Sim and Real: Decoupled Visuomotor Manipulation via Learning Control in Simulation and Perception in Real](https://arxiv.org/abs/2509.25747)
*Jialei Huang,Zhaoheng Yin,Yingdong Hu,Shuo Wang,Xingyu Lin,Yang Gao*

Main category: cs.RO

TL;DR: 提出解耦框架，在模拟中训练控制策略，在部署时适配感知，仅需10-20个真实演示即可实现高效的sim-to-real迁移


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中感知与控制纠缠导致的sim-to-real迁移难题

Method: 在模拟中用特权状态训练控制策略，在真实环境中仅适配感知模块，将复杂问题简化为结构化感知对齐任务

Result: 在桌面操作任务中表现出卓越的数据效率和分布外泛化能力，能够处理超出训练分布的对象位置和尺度

Conclusion: 解耦感知与控制从根本上改善了sim-to-real迁移效果

Abstract: Sim-to-real transfer remains a fundamental challenge in robot manipulation
due to the entanglement of perception and control in end-to-end learning. We
present a decoupled framework that learns each component where it is most
reliable: control policies are trained in simulation with privileged state to
master spatial layouts and manipulation dynamics, while perception is adapted
only at deployment to bridge real observations to the frozen control policy.
Our key insight is that control strategies and action patterns are universal
across environments and can be learned in simulation through systematic
randomization, while perception is inherently domain-specific and must be
learned where visual observations are authentic. Unlike existing end-to-end
approaches that require extensive real-world data, our method achieves strong
performance with only 10-20 real demonstrations by reducing the complex
sim-to-real problem to a structured perception alignment task. We validate our
approach on tabletop manipulation tasks, demonstrating superior data efficiency
and out-of-distribution generalization compared to end-to-end baselines. The
learned policies successfully handle object positions and scales beyond the
training distribution, confirming that decoupling perception from control
fundamentally improves sim-to-real transfer.

</details>


### [16] [SAC Flow: Sample-Efficient Reinforcement Learning of Flow-Based Policies via Velocity-Reparameterized Sequential Modeling](https://arxiv.org/abs/2509.25756)
*Yixian Zhang,Shu'ang Yu,Tonghe Zhang,Mo Guang,Haojia Hui,Kaiwen Long,Yu Wang,Chao Yu,Wenbo Ding*

Main category: cs.RO

TL;DR: 提出两种稳定的流策略架构（Flow-G和Flow-T），通过重新参数化速度网络解决流策略训练中的梯度问题，开发了基于SAC的实用算法，在连续控制和机器人操作任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 基于流的策略在离策略强化学习中训练不稳定，这是由于多步动作采样过程中的梯度病态问题，类似于RNN中的梯度消失和爆炸问题。

Method: 将流展开重新参数化为残差循环计算，引入两种稳定架构：Flow-G（门控速度）和Flow-T（解码速度），开发基于SAC的算法，使用噪声增强展开实现端到端训练。

Result: 在连续控制和机器人操作基准测试中达到最先进性能，消除了策略蒸馏或替代目标等常见变通方法的需求。

Conclusion: 通过重新参数化速度网络，成功解决了流策略训练中的梯度不稳定问题，实现了稳定高效的端到端训练。

Abstract: Training expressive flow-based policies with off-policy reinforcement
learning is notoriously unstable due to gradient pathologies in the multi-step
action sampling process. We trace this instability to a fundamental connection:
the flow rollout is algebraically equivalent to a residual recurrent
computation, making it susceptible to the same vanishing and exploding
gradients as RNNs. To address this, we reparameterize the velocity network
using principles from modern sequential models, introducing two stable
architectures: Flow-G, which incorporates a gated velocity, and Flow-T, which
utilizes a decoded velocity. We then develop a practical SAC-based algorithm,
enabled by a noise-augmented rollout, that facilitates direct end-to-end
training of these policies. Our approach supports both from-scratch and
offline-to-online learning and achieves state-of-the-art performance on
continuous control and robotic manipulation benchmarks, eliminating the need
for common workarounds like policy distillation or surrogate objectives.

</details>


### [17] [Act to See, See to Act: Diffusion-Driven Perception-Action Interplay for Adaptive Policies](https://arxiv.org/abs/2509.25822)
*Jing Wang,Weiting Peng,Jing Tang,Zeyu Gong,Xihua Wang,Bo Tao,Li Cheng*

Main category: cs.RO

TL;DR: 提出Action-Guided Diffusion Policy (DP-AG)，通过概率潜在动力学统一建模感知与动作的因果关系，使用动作引导的SDE和循环一致性对比损失来增强感知-动作循环的连续性。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法将感知和动作解耦，忽视了感官表示与动作执行之间的因果互惠关系，而人类自然利用这种关系实现自适应行为。

Method: DP-AG通过变分推理将潜在观察编码为高斯后验，使用动作引导的SDE演化潜在状态，其中扩散策略的噪声预测的向量-雅可比积作为结构化随机力驱动潜在更新。引入循环一致性对比损失组织噪声预测器的梯度流为连贯的感知-动作循环。

Result: 在模拟基准和真实世界UR5操作任务中，DP-AG显著优于最先进方法。

Conclusion: DP-AG为连接生物适应性和人工策略学习提供了有前景的一步。

Abstract: Existing imitation learning methods decouple perception and action, which
overlooks the causal reciprocity between sensory representations and action
execution that humans naturally leverage for adaptive behaviors. To bridge this
gap, we introduce Action--Guided Diffusion Policy (DP--AG), a unified
representation learning that explicitly models a dynamic interplay between
perception and action through probabilistic latent dynamics. DP--AG encodes
latent observations into a Gaussian posterior via variational inference and
evolves them using an action-guided SDE, where the Vector-Jacobian Product
(VJP) of the diffusion policy's noise predictions serves as a structured
stochastic force driving latent updates. To promote bidirectional learning
between perception and action, we introduce a cycle--consistent contrastive
loss that organizes the gradient flow of the noise predictor into a coherent
perception--action loop, enforcing mutually consistent transitions in both
latent updates and action refinements. Theoretically, we derive a variational
lower bound for the action-guided SDE, and prove that the contrastive objective
enhances continuity in both latent and action trajectories. Empirically, DP--AG
significantly outperforms state--of--the--art methods across simulation
benchmarks and real-world UR5 manipulation tasks. As a result, our DP--AG
offers a promising step toward bridging biological adaptability and artificial
policy learning.

</details>


### [18] [Reinforced Embodied Planning with Verifiable Reward for Real-World Robotic Manipulation](https://arxiv.org/abs/2509.25852)
*Zitong Bo,Yue Hu,Jinming Ma,Mingliang Zhou,Junhui Yin,Yachen Kang,Yuqi Liu,Tong Wu,Diyun Xiang,Hao Chen*

Main category: cs.RO

TL;DR: 提出了REVER框架，通过训练RoboFarseer视觉语言模型来解决机器人执行自然语言长时程操作任务的挑战，该模型能够生成和验证物理可行、逻辑连贯的操作计划。


<details>
  <summary>Details</summary>
Motivation: 解决机器人从自由形式语言指令执行长时程操作任务的两个关键问题：缺乏大规模顺序操作数据，以及缺乏用于微调视觉语言模型的密集可解释奖励。

Method: 使用Universal Manipulation Interface框架捕获硬件无关的原子技能演示，通过自动标注引擎生成视觉-指令-计划三元组数据，训练RoboFarseer模型进行时空推理，并引入可验证的奖励函数来评估生成计划的质量。

Result: RoboFarseer在性能上匹配或超越了规模大得多的专有模型，在开放规划任务上比最佳基线高出40%以上。在实际长时程任务中，完整系统相比没有规划器的低级控制器将整体成功率提高了约60%。

Conclusion: REVER框架通过结合规划与验证，显著提升了机器人执行自然语言长时程操作任务的能力，证明了在真实世界场景中部署视觉语言模型的可行性。

Abstract: Enabling robots to execute long-horizon manipulation tasks from free-form
language instructions remains a fundamental challenge in embodied AI. While
vision-language models (VLMs) have shown promise as high-level planners, their
deployment in the real world is hindered by two gaps: (i) the scarcity of
large-scale, sequential manipulation data that couples natural language with
multi-step action plans, and (ii) the absence of dense, interpretable rewards
for fine-tuning VLMs on planning objectives. To address these issues, we
propose REVER, a framework that empowers VLMs to generate and validate
long-horizon manipulation plans from natural language instructions in
real-world scenarios. Under REVER we train and release RoboFarseer, a VLM
incentivized to emit chain-of-thought that perform temporal and spatial
reasoning, ensuring physically plausible and logically coherent plans. To
obtain training data, we leverage the Universal Manipulation Interface
framework to capture hardware-agnostic demonstrations of atomic skills. An
automated annotation engine converts each demonstration into
vision-instruction-plan triplet. We introduce a verifiable reward that scores
the generated plan by its ordered bipartite matching overlap with the
ground-truth skill sequence. At run time, the fine-tuned VLM functions both as
a planner and as a monitor, verifying step-wise completion. RoboFarseer matches
or exceeds the performance of proprietary models that are orders of magnitude
larger, while on open-ended planning it surpasses the best baseline by more
than 40%. In real-world, long-horizon tasks, the complete system boosts overall
success by roughly 60% compared with the same low-level controller without the
planner. We will open-source both the dataset and the trained model upon
publication.

</details>


### [19] [State Estimation for Compliant and Morphologically Adaptive Robots](https://arxiv.org/abs/2509.25945)
*Valentin Yuryev,Max Polzin,Josie Hughes*

Main category: cs.RO

TL;DR: 提出了一种用于具有主动或被动柔顺性的移动机器人的状态估计方法，能够同时估计典型刚体状态和柔顺相关状态（如软机器人形状），在GOAT平台上测试显示良好性能。


<details>
  <summary>Details</summary>
Motivation: 具有柔顺性的移动机器人在不确定场景中表现出鲁棒性，但由于缺乏刚体假设和形态变化导致的运动学变化，这些机器人的状态估计具有挑战性。

Method: 基于神经网络的状态估计器，使用状态历史记录和直接影响不可靠传感器的机制，在考虑形态相关状态的柔顺中心框架中训练。

Result: 预测形状相关测量在机器人尺寸的4.2%以内，线速度和角速度分别在前速度的6.3%和2.4%以内，方向在1.5度以内。在电机故障时使用该估计器进行闭环自主户外操作，行驶范围增加了300%。

Conclusion: 该方法成功解决了柔顺机器人的状态估计挑战，显著提高了机器人在极端户外地形中的自主操作能力。

Abstract: Locomotion robots with active or passive compliance can show robustness to
uncertain scenarios, which can be promising for agricultural, research and
environmental industries. However, state estimation for these robots is
challenging due to the lack of rigid-body assumptions and kinematic changes
from morphing. We propose a method to estimate typical rigid-body states
alongside compliance-related states, such as soft robot shape in different
morphologies and locomotion modes. Our neural network-based state estimator
uses a history of states and a mechanism to directly influence unreliable
sensors. We test our framework on the GOAT platform, a robot capable of passive
compliance and active morphing for extreme outdoor terrain. The network is
trained on motion capture data in a novel compliance-centric frame that
accounts for morphing-related states. Our method predicts shape-related
measurements within 4.2% of the robot's size, velocities within 6.3% and 2.4%
of the top linear and angular speeds, respectively, and orientation within 1.5
degrees. We also demonstrate a 300% increase in travel range during a motor
malfunction when using our estimator for closed-loop autonomous outdoor
operation.

</details>


### [20] [Towards Intuitive Human-Robot Interaction through Embodied Gesture-Driven Control with Woven Tactile Skins](https://arxiv.org/abs/2509.25951)
*ChunPing Lam,Xiangjia Chen,Chenming Wu,Hao Chen,Binzhi Sun,Guoxin Fang,Charlie C. L. Wang,Chengkai Dai,Yeung Yam*

Main category: cs.RO

TL;DR: 提出了一种基于电容式编织触觉皮肤的人机交互框架，通过手势控制实现直观的机器人操作，相比传统面板和示教器将任务完成时间减少高达57%。


<details>
  <summary>Details</summary>
Motivation: 传统人机交互界面依赖面板或手持设备，无法与机器人曲面无缝集成，限制了直观的交互体验。需要缩小人类意图与机器人响应之间的差距。

Method: 开发编织触觉皮肤，结合织物柔性和结构稳定性，通过交织导电线程实现密集多通道传感。定义了14种单点和多点触控手势，并设计轻量级卷积-Transformer模型进行实时手势识别。

Result: 手势识别准确率接近100%，优于现有基线方法。在机器人手臂任务（如抓取放置和倾倒）中，相比键盘面板和示教器，任务完成时间最多减少57%。

Conclusion: 该框架为实现更自然高效的具身人机交互提供了实用途径，通过编织触觉皮肤和直观手势控制显著提升了交互体验。

Abstract: This paper presents a novel human-robot interaction (HRI) framework that
enables intuitive gesture-driven control through a capacitance-based woven
tactile skin. Unlike conventional interfaces that rely on panels or handheld
devices, the woven tactile skin integrates seamlessly with curved robot
surfaces, enabling embodied interaction and narrowing the gap between human
intent and robot response. Its woven design combines fabric-like flexibility
with structural stability and dense multi-channel sensing through the
interlaced conductive threads. Building on this capability, we define a
gesture-action mapping of 14 single- and multi-touch gestures that cover
representative robot commands, including task-space motion and auxiliary
functions. A lightweight convolution-transformer model designed for gesture
recognition in real time achieves an accuracy of near-100%, outperforming prior
baseline approaches. Experiments on robot arm tasks, including pick-and-place
and pouring, demonstrate that our system reduces task completion time by up to
57% compared with keyboard panels and teach pendants. Overall, our proposed
framework demonstrates a practical pathway toward more natural and efficient
embodied HRI.

</details>


### [21] [MUVLA: Learning to Explore Object Navigation via Map Understanding](https://arxiv.org/abs/2509.25966)
*Peilong Han,Fan Jia,Min Zhang,Yutao Qiu,Hongyao Tang,Yan Zheng,Tiancai Wang,Jianye Hao*

Main category: cs.RO

TL;DR: MUVLA是一个针对物体导航的视觉-语言-动作模型，利用语义地图抽象统一历史信息，通过三阶段训练实现有效的探索行为。


<details>
  <summary>Details</summary>
Motivation: 为了解决物体导航中历史信息整合和探索策略优化的问题，需要一种能够统一结构化空间信息并最大化奖励的模型。

Method: 采用语义地图抽象编码空间上下文，通过三阶段训练：学习地图级空间理解、混合质量演示的行为模仿、奖励放大的回报建模。

Result: 在HM3D和Gibson基准测试中，MUVLA展现出优秀的泛化能力，即使从低质量或部分成功的轨迹中也能学习有效的探索行为。

Conclusion: MUVLA通过语义地图抽象和三阶段训练策略，成功实现了对物体导航任务的鲁棒空间表示和理性探索策略生成。

Abstract: In this paper, we present MUVLA, a Map Understanding Vision-Language-Action
model tailored for object navigation. It leverages semantic map abstractions to
unify and structure historical information, encoding spatial context in a
compact and consistent form. MUVLA takes the current and history observations,
as well as the semantic map, as inputs and predicts the action sequence based
on the description of goal object. Furthermore, it amplifies supervision
through reward-guided return modeling based on dense short-horizon progress
signals, enabling the model to develop a detailed understanding of action value
for reward maximization. MUVLA employs a three-stage training pipeline:
learning map-level spatial understanding, imitating behaviors from
mixed-quality demonstrations, and reward amplification. This strategy allows
MUVLA to unify diverse demonstrations into a robust spatial representation and
generate more rational exploration strategies. Experiments on HM3D and Gibson
benchmarks demonstrate that MUVLA achieves great generalization and learns
effective exploration behaviors even from low-quality or partially successful
trajectories.

</details>


### [22] [S$^3$E: Self-Supervised State Estimation for Radar-Inertial System](https://arxiv.org/abs/2509.25984)
*Shengpeng Wang,Yulong Xie,Qing Liao,Wei Wang*

Main category: cs.RO

TL;DR: S³E是一个自监督状态估计器，通过融合毫米波雷达信号频谱和惯性数据来解决雷达点云稀疏性、多径效应和角度分辨率限制的问题，实现准确的无监督定位。


<details>
  <summary>Details</summary>
Motivation: 现有基于雷达点云的定位方案面临点云稀疏、多径效应产生的虚影点以及单啁啾雷达角度分辨率有限等问题，严重影响了状态估计性能。

Method: 提出S³E自监督状态估计器，使用更丰富的雷达信号频谱替代稀疏点云，融合互补的惯性信息，并引入跨融合技术通过利用异构数据间的旋转偏移相关性来增强空间结构信息。

Result: 实验结果表明该方法在不依赖定位真值监督的情况下实现了鲁棒且准确的性能。

Conclusion: 这是首次尝试以互补自监督方式融合雷达频谱和惯性数据来实现状态估计的方法。

Abstract: Millimeter-wave radar for state estimation is gaining significant attention
for its affordability and reliability in harsh conditions. Existing
localization solutions typically rely on post-processed radar point clouds as
landmark points. Nonetheless, the inherent sparsity of radar point clouds,
ghost points from multi-path effects, and limited angle resolution in
single-chirp radar severely degrade state estimation performance. To address
these issues, we propose S$^3$E, a \textbf{S}elf-\textbf{S}upervised
\textbf{S}tate \textbf{E}stimator that employs more richly informative radar
signal spectra to bypass sparse points and fuses complementary inertial
information to achieve accurate localization. S$^3$E fully explores the
association between \textit{exteroceptive} radar and \textit{proprioceptive}
inertial sensor to achieve complementary benefits. To deal with limited angle
resolution, we introduce a novel cross-fusion technique that enhances spatial
structure information by exploiting subtle rotational shift correlations across
heterogeneous data. The experimental results demonstrate our method achieves
robust and accurate performance without relying on localization ground truth
supervision. To the best of our knowledge, this is the first attempt to achieve
state estimation by fusing radar spectra and inertial data in a complementary
self-supervised manner.

</details>


### [23] [Emotionally Expressive Robots: Implications for Children's Behavior toward Robot](https://arxiv.org/abs/2509.25986)
*Elisabetta Zibetti,Sureya Waheed Palmer,Rebecca Stower,Salvatore M Anzalone*

Main category: cs.RO

TL;DR: 研究探索机器人情感表达对儿童行为的影响，发现儿童会调整行为以适应机器人情绪状态，但更高表达水平并未增强这种对齐效应。


<details>
  <summary>Details</summary>
Motivation: 随着具有人工情感表达能力的机器人发展，需要探讨其说服潜力对儿童行为的影响，特别是在机器人表达性如何影响儿童共情反应方面。

Method: 对22名7-11岁儿童进行试点研究，使用人形机器人QTRobot展示不同表达水平（仅身体、仅面部、身体和面部）的基本情绪（快乐和悲伤），观察儿童在合作轮流游戏中的行为变化。

Result: 儿童会调整自己的行为以匹配机器人推断的情绪状态，但更高的表达水平并未导致更强的行为对齐效果。

Conclusion: 这些初步结果为思考机器人表达性及其在未来塑造儿童对机器人作为社交同伴的社会情感行为提供了起点。

Abstract: The growing development of robots with artificial emotional expressiveness
raises important questions about their persuasive potential in children's
behavior. While research highlights the pragmatic value of emotional
expressiveness in human social communication, the extent to which robotic
expressiveness can or should influence empathic responses in children is
grounds for debate. In a pilot study with 22 children (aged 7-11) we begin to
explore the ways in which different levels of embodied expressiveness (body
only, face only, body and face) of two basic emotions (happiness and sadness)
displayed by an anthropomorphic robot (QTRobot) might modify children's
behavior in a child-robot cooperative turn-taking game. We observed that
children aligned their behavior to the robot's inferred emotional state.
However, higher levels of expressiveness did not result in increased alignment.
The preliminary results reported here provide a starting point for reflecting
on robotic expressiveness and its role in shaping children's social-emotional
behavior toward robots as social peers in the near future.

</details>


### [24] [On the Conic Complementarity of Planar Contacts](https://arxiv.org/abs/2509.25999)
*Yann de Mont-Marin,Louis Montaut,Jean Ponce,Martial Hebert,Justin Carpentier*

Main category: cs.RO

TL;DR: 本文提出了平面Signorini条件，将点接触的Signorini定律与中心压力概念统一起来，为刚体平面接触提供了数学一致的计算框架。


<details>
  <summary>Details</summary>
Motivation: 连接机器人学中两个基础原理：防止物体穿透的Signorini定律和用于运动控制优化的中心压力概念，弥散离散与连续接触模型之间的差距。

Method: 提出平面Signorini条件的锥互补公式，证明其等效于在整个接触面上执行点状Signorini定律，并建立几何解释来统一捕捉三种物理状态。

Result: 开发了扩展中心压力概念，为平面接触提供了数学一致且计算可行的基础，能够准确模拟接触动力学并支持高级控制算法设计。

Conclusion: 该工作为处理平面接触建立了统一的理论框架，对接触动力学模拟以及运动控制和操作中的优化算法设计具有重要意义。

Abstract: We present a unifying theoretical result that connects two foundational
principles in robotics: the Signorini law for point contacts, which underpins
many simulation methods for preventing object interpenetration, and the center
of pressure (also known as the zero-moment point), a key concept used in, for
instance, optimization-based locomotion control. Our contribution is the planar
Signorini condition, a conic complementarity formulation that models general
planar contacts between rigid bodies. We prove that this formulation is
equivalent to enforcing the punctual Signorini law across an entire contact
surface, thereby bridging the gap between discrete and continuous contact
models. A geometric interpretation reveals that the framework naturally
captures three physical regimes -sticking, separating, and tilting-within a
unified complementarity structure. This leads to a principled extension of the
classical center of pressure, which we refer to as the extended center of
pressure. By establishing this connection, our work provides a mathematically
consistent and computationally tractable foundation for handling planar
contacts, with implications for both the accurate simulation of contact
dynamics and the design of advanced control and optimization algorithms in
locomotion and manipulation.

</details>


### [25] [Conflict-Based Search and Prioritized Planning for Multi-Agent Path Finding Among Movable Obstacles](https://arxiv.org/abs/2509.26050)
*Shaoli Hu,Shizhe Zhao,Zhongqiang Ren*

Main category: cs.RO

TL;DR: 本文研究了多智能体可移动障碍物路径规划问题，结合了冲突搜索和优先规划方法来解决物流场景中多机器人路径规划挑战。


<details>
  <summary>Details</summary>
Motivation: 在物流和仓库环境中，移动机器人需要在不预期的可移动障碍物之间规划路径，而现有的多智能体路径规划和单智能体可移动障碍物规划方法无法直接解决这一复杂问题。

Method: 融合了冲突搜索、优先规划和PAMO*单智能体规划器，首次尝试将这些方法结合来解决多智能体可移动障碍物路径规划问题。

Result: 在最多20个智能体和数百个可移动障碍物的场景下进行了性能比较，展示了不同方法的优缺点。

Conclusion: 成功开发了解决M-PAMO问题的方法框架，为物流环境中的多机器人路径规划提供了有效解决方案。

Abstract: This paper investigates Multi-Agent Path Finding Among Movable Obstacles
(M-PAMO), which seeks collision-free paths for multiple agents from their start
to goal locations among static and movable obstacles. M-PAMO arises in
logistics and warehouses where mobile robots are among unexpected movable
objects. Although Multi-Agent Path Finding (MAPF) and single-agent Path
planning Among Movable Obstacles (PAMO) were both studied, M-PAMO remains
under-explored. Movable obstacles lead to new fundamental challenges as the
state space, which includes both agents and movable obstacles, grows
exponentially with respect to the number of agents and movable obstacles. In
particular, movable obstacles often closely couple agents together spatially
and temporally. This paper makes a first attempt to adapt and fuse the popular
Conflict-Based Search (CBS) and Prioritized Planning (PP) for MAPF, and a
recent single-agent PAMO planner called PAMO*, together to address M-PAMO. We
compare their performance with up to 20 agents and hundreds of movable
obstacles, and show the pros and cons of these approaches.

</details>


### [26] [Evolutionary Continuous Adaptive RL-Powered Co-Design for Humanoid Chin-Up Performance](https://arxiv.org/abs/2509.26082)
*Tianyi Jin,Melya Boukheddimi,Rohit Kumar,Gabriele Fadini,Frank Kirchner*

Main category: cs.RO

TL;DR: EA-CoRL框架结合强化学习和进化策略，实现机器人硬件设计与控制策略的协同优化，在RH5人形机器人的动态引体向上任务中取得突破性进展。


<details>
  <summary>Details</summary>
Motivation: 传统机器人设计采用顺序流程（先硬件后控制），限制了硬件潜力的充分发挥。需要并行优化设计和控制来最大化机器人能力。

Method: EA-CoRL框架包含两个核心组件：设计进化（使用进化算法探索硬件配置）和策略持续适应（在演化设计中微调任务特定控制策略）。

Result: 在RH5人形机器人的动态引体向上任务中，EA-CoRL相比现有RL协同设计方法获得更高适应度分数和更广的设计空间探索。

Conclusion: 策略持续适应在机器人协同设计中发挥关键作用，EA-CoRL框架成功解决了因执行器限制而无法完成的动态任务。

Abstract: Humanoid robots have seen significant advancements in both design and
control, with a growing emphasis on integrating these aspects to enhance
overall performance. Traditionally, robot design has followed a sequential
process, where control algorithms are developed after the hardware is
finalized. However, this can be myopic and prevent robots to fully exploit
their hardware capabilities. Recent approaches advocate for co-design,
optimizing both design and control in parallel to maximize robotic
capabilities. This paper presents the Evolutionary Continuous Adaptive RL-based
Co-Design (EA-CoRL) framework, which combines reinforcement learning (RL) with
evolutionary strategies to enable continuous adaptation of the control policy
to the hardware. EA-CoRL comprises two key components: Design Evolution, which
explores the hardware choices using an evolutionary algorithm to identify
efficient configurations, and Policy Continuous Adaptation, which fine-tunes a
task-specific control policy across evolving designs to maximize performance
rewards. We evaluate EA-CoRL by co-designing the actuators (gear ratios) and
control policy of the RH5 humanoid for a highly dynamic chin-up task,
previously unfeasible due to actuator limitations. Comparative results against
state-of-the-art RL-based co-design methods show that EA-CoRL achieves higher
fitness score and broader design space exploration, highlighting the critical
role of continuous policy adaptation in robot co-design.

</details>


### [27] [Autonomous Multi-Robot Infrastructure for AI-Enabled Healthcare Delivery and Diagnostics](https://arxiv.org/abs/2509.26106)
*Nakhul Kalaivanan,Senthil Arumugam Muthukumaraswamy,Girish Balasubramanian*

Main category: cs.RO

TL;DR: 开发了一个基于群体智能的多机器人住院护理系统，集成了可穿戴健康传感器、RF通信和AI决策支持，在模拟医院环境中实现了患者监护、药物配送和紧急援助功能。


<details>
  <summary>Details</summary>
Motivation: 旨在通过群体智能和机器人技术提高医院自动化水平和患者安全，提供成本效益高的住院护理解决方案。

Method: 采用领导者-跟随者群体配置，使用Arduino、树莓派、NRF24L01 RF模块和HuskyLens AI相机实现硬件系统，通过可穿戴传感器采集生理参数并协调机器人任务。

Result: 系统传感器准确率超过94%，任务成功率92%，通信可靠性96%，AI决策支持能够提供异常健康状况的早期预警。

Conclusion: 该系统展示了作为医院自动化和患者安全成本效益解决方案的潜力，群体智能策略提高了通信可靠性和持续监护能力。

Abstract: This research presents a multi-robot system for inpatient care, designed
using swarm intelligence principles and incorporating wearable health sensors,
RF-based communication, and AI-driven decision support. Within a simulated
hospital environment, the system adopts a leader-follower swarm configuration
to perform patient monitoring, medicine delivery, and emergency assistance. Due
to ethical constraints, live patient trials were not conducted; instead,
validation was carried out through controlled self-testing with wearable
sensors. The Leader Robot acquires key physiological parameters, including
temperature, SpO2, heart rate, and fall detection, and coordinates other robots
when required. The Assistant Robot patrols corridors for medicine delivery,
while a robotic arm provides direct drug administration. The swarm-inspired
leader-follower strategy enhanced communication reliability and ensured
continuous monitoring, including automated email alerts to healthcare staff.
The system hardware was implemented using Arduino, Raspberry Pi, NRF24L01 RF
modules, and a HuskyLens AI camera. Experimental evaluation showed an overall
sensor accuracy above 94%, a 92% task-level success rate, and a 96%
communication reliability rate, demonstrating system robustness. Furthermore,
the AI-enabled decision support was able to provide early warnings of abnormal
health conditions, highlighting the potential of the system as a cost-effective
solution for hospital automation and patient safety.

</details>


### [28] [Side Scan Sonar-based SLAM for Autonomous Algae Farm Monitoring](https://arxiv.org/abs/2509.26121)
*Julian Valdez,Ignacio Torroba,John Folkesson,Ivan Stenius*

Main category: cs.RO

TL;DR: 提出了一种基于侧扫声纳的SLAM框架，用于自主水下航行器在海藻养殖场中的导航，通过将结构绳索建模为单个地标序列而非组合成延伸表示，提高了定位和建图的准确性。


<details>
  <summary>Details</summary>
Motivation: 海藻养殖向工业化规模发展需要自动化过程，自主水下航行器是实现自动化作物和结构检查的关键，但目前部署的瓶颈是在养殖场内确保安全导航，需要准确的在线姿态估计和基础设施地图。

Method: 开发了高效的侧扫声纳SLAM框架，利用海藻养殖场的几何结构，在后端将结构绳索建模为每个侧扫声纳检测的单个地标序列，而不是将检测组合成延伸表示。

Result: 在真实海藻养殖场的AUV调查中进行的硬件在环实验表明，该方法优于现有解决方案。

Conclusion: 提出的侧扫声纳SLAM框架能够有效解决海藻养殖场中AUV导航的瓶颈问题，为智能养殖提供技术支持。

Abstract: The transition of seaweed farming to an alternative food source on an
industrial scale relies on automating its processes through smart farming,
equivalent to land agriculture. Key to this process are autonomous underwater
vehicles (AUVs) via their capacity to automate crop and structural inspections.
However, the current bottleneck for their deployment is ensuring safe
navigation within farms, which requires an accurate, online estimate of the AUV
pose and map of the infrastructure. To enable this, we propose an efficient
side scan sonar-based (SSS) simultaneous localization and mapping (SLAM)
framework that exploits the geometry of kelp farms via modeling structural
ropes in the back-end as sequences of individual landmarks from each SSS ping
detection, instead of combining detections into elongated representations. Our
method outperforms state of the art solutions in hardware in the loop (HIL)
experiments on a real AUV survey in a kelp farm. The framework and dataset can
be found at https://github.com/julRusVal/sss_farm_slam.

</details>


### [29] [Terrain-Awared LiDAR-Inertial Odometry for Legged-Wheel Robots Based on Radial Basis Function Approximation](https://arxiv.org/abs/2509.26222)
*Yizhe Liu,Han Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于径向基函数(RBF)的地形感知LiDAR-惯性里程计框架，通过自适应选择RBF中心并递归更新权重来近似地形，从而在机器人机动过程中缓解z轴姿态漂移问题。


<details>
  <summary>Details</summary>
Motivation: 解决腿轮机器人在非结构化地形（如颠簸道路和楼梯）运行时，现有方法由于忽略地形几何而导致的姿态漂移问题。

Method: 使用径向基函数(RBF)近似地形，自适应选择RBF中心并递归更新权重，生成平滑地形流形，在里程计优化中施加软约束。通过GPU并行化确保实时性能。

Result: 在非结构化地形上的实验表明，该方法比现有最先进基线方法具有更高的定位精度，特别是在连续高度变化或特征稀疏且发生急剧高度变化的场景中。

Conclusion: 所提出的地形感知LiDAR-惯性里程计框架通过RBF地形建模有效缓解了姿态漂移问题，在复杂地形下实现了更准确的定位。

Abstract: An accurate odometry is essential for legged-wheel robots operating in
unstructured terrains such as bumpy roads and staircases. Existing methods
often suffer from pose drift due to their ignorance of terrain geometry. We
propose a terrain-awared LiDAR-Inertial odometry (LIO) framework that
approximates the terrain using Radial Basis Functions (RBF) whose centers are
adaptively selected and weights are recursively updated. The resulting smooth
terrain manifold enables ``soft constraints" that regularize the odometry
optimization and mitigates the $z$-axis pose drift under abrupt elevation
changes during robot's maneuver. To ensure the LIO's real-time performance, we
further evaluate the RBF-related terms and calculate the inverse of the sparse
kernel matrix with GPU parallelization. Experiments on unstructured terrains
demonstrate that our method achieves higher localization accuracy than the
state-of-the-art baselines, especially in the scenarios that have continuous
height changes or sparse features when abrupt height changes occur.

</details>


### [30] [ISyHand: A Dexterous Multi-finger Robot Hand with an Articulated Palm](https://arxiv.org/abs/2509.26236)
*Benjamin A. Richardson,Felix Grüninger,Lukas Mack,Joerg Stueckler,Katherine J. Kuchenbecker*

Main category: cs.RO

TL;DR: ISyHand是一个开源、低成本、易于制造的机器人手，采用独特的关节式手掌设计，在保持人形特征的同时提高了灵巧性，在模拟和真实环境中都展示了出色的操作能力。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人和定制制造解决方案的快速发展，灵巧操作成为现代机器人学的关键。现有灵巧手要么价格昂贵，要么在提高灵巧性时牺牲了人形特征，需要开发低成本、高灵巧性的解决方案。

Method: 使用现成的Dynamixel电机、紧固件和3D打印部件，设计具有独特关节式手掌的ISyHand机器人手。通过强化学习在模拟环境中训练手执行立方体重定向任务，并与同类产品进行比较。

Result: ISyHand总材料成本约1300美元，可在4小时内组装完成。模拟实验显示，ISyHand在早期训练阶段优于两个最可比的手，收敛后性能相似，且显著优于固定手掌版本。真实环境部署也成功执行了立方体重定向任务。

Conclusion: ISyHand证明了通过关节式手掌设计可以在保持人形特征的同时显著提高灵巧性，为低成本、高灵巧性机器人手的开发提供了可行方案。

Abstract: The rapid increase in the development of humanoid robots and customized
manufacturing solutions has brought dexterous manipulation to the forefront of
modern robotics. Over the past decade, several expensive dexterous hands have
come to market, but advances in hardware design, particularly in servo motors
and 3D printing, have recently facilitated an explosion of cheaper open-source
hands. Most hands are anthropomorphic to allow use of standard human tools, and
attempts to increase dexterity often sacrifice anthropomorphism. We introduce
the open-source ISyHand (pronounced easy-hand), a highly dexterous, low-cost,
easy-to-manufacture, on-joint servo-driven robot hand. Our hand uses
off-the-shelf Dynamixel motors, fasteners, and 3D-printed parts, can be
assembled within four hours, and has a total material cost of about 1,300 USD.
The ISyHands's unique articulated-palm design increases overall dexterity with
only a modest sacrifice in anthropomorphism. To demonstrate the utility of the
articulated palm, we use reinforcement learning in simulation to train the hand
to perform a classical in-hand manipulation task: cube reorientation. Our
novel, systematic experiments show that the simulated ISyHand outperforms the
two most comparable hands in early training phases, that all three perform
similarly well after policy convergence, and that the ISyHand significantly
outperforms a fixed-palm version of its own design. Additionally, we deploy a
policy trained on cube reorientation on the real hand, demonstrating its
ability to perform real-world dexterous manipulation.

</details>


### [31] [Anomaly detection for generic failure monitoring in robotic assembly, screwing and manipulation](https://arxiv.org/abs/2509.26308)
*Niklas Grambow,Lisa-Marie Fenner,Felipe Kempkes,Philip Hotz,Dingyuan Wan,Jörg Krüger,Kevin Haninger*

Main category: cs.RO

TL;DR: 该论文研究了基于自编码器的异常检测方法在机器人操作任务中的泛化能力，在三种工业任务（布线、拧螺丝、打磨）中验证了方法的跨任务和跨控制策略的适用性。


<details>
  <summary>Details</summary>
Motivation: 机器人操作中的分布外状态会导致不可预测行为或任务失败，需要异常检测来触发安全行为和恢复策略。现有方法在特定任务中有效，但跨控制策略和任务类型的可转移性尚未得到验证。

Method: 构建了三种工业机器人任务的测试场景，收集多模态时间序列数据，比较了几种基于自编码器的异常检测方法，评估了它们在扩散策略、位置控制和阻抗控制等不同控制方法下的泛化能力。

Result: 在布线和拧螺丝任务中，AUROC超过0.93，能可靠检测错误零件、错位目标和阻塞目标等故障。在打磨任务中，仅能可靠检测严重故障，更细微的故障类型未被检测到。

Conclusion: 基于自编码器的异常检测方法在多种机器人操作任务中具有良好泛化能力，特别是在布线和拧螺丝任务中表现优异，但在检测细微故障方面仍有改进空间。

Abstract: Out-of-distribution states in robot manipulation often lead to unpredictable
robot behavior or task failure, limiting success rates and increasing risk of
damage. Anomaly detection (AD) can identify deviations from expected patterns
in data, which can be used to trigger failsafe behaviors and recovery
strategies. Prior work has applied data-driven AD to time series data in
specific robotic tasks, but its transferability across control strategies and
task types has not been shown. Leveraging time series data, such as
force/torque signals, allows to directly capture robot-environment
interactions, crucial for manipulation and online failure detection. Their
broad availability, high sampling rates, and low dimensionality enable high
temporal resolution and efficient processing. As robotic tasks can have widely
signal characteristics and requirements, AD methods which can be applied in the
same way to a wide range of tasks is needed, ideally with good data efficiency.
We examine three industrial robotic tasks, each presenting several anomalies.
Test scenarios in robotic cabling, screwing, and sanding are built, and
multimodal time series data is gathered. Several autoencoder-based methods are
compared, evaluating generalization across tasks and control methods (diffusion
policy, position, and impedance control). This allows us to validate the
integration of AD in complex tasks involving tighter tolerances and variation
from both the robot and its environment. Additionally, we evaluate data
efficiency, detection latency, and task characteristics which support robust
detection. The results indicate reliable detection with AUROC exceeding 0.93 in
failures in the cabling and screwing task, such as incorrect or misaligned
parts and obstructed targets. In the polishing task, only severe failures were
reliably detected, while more subtle failure types remained undetected.

</details>


### [32] [LLM-MCoX: Large Language Model-based Multi-robot Coordinated Exploration and Search](https://arxiv.org/abs/2509.26324)
*Ruiyang Wang,Haolun Tsu,David Hunt,Shaocheng Luo,Jiwoo Kim,Miroslav Pajic*

Main category: cs.RO

TL;DR: LLM-MCoX是一个基于大语言模型的多机器人协调探索与搜索框架，通过结合实时LiDAR处理和GPT-4o等多模态LLM推理，在未知室内环境中实现高效探索和目标搜索。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人系统在未知室内环境中的自主探索和对象搜索存在挑战，通常采用贪婪前沿分配策略且机器人间协调有限。

Method: 结合实时LiDAR扫描处理进行前沿聚类提取和门道检测，利用多模态LLM（如GPT-4o）基于共享环境地图和机器人状态生成协调的航点分配。

Result: 相比现有方法（包括贪婪和Voronoi规划器），在6个机器人的大型环境中实现了22.7%更快的探索时间和50%的搜索效率提升，支持自然语言对象搜索。

Conclusion: LLM-MCoX框架在未知室内环境中为多机器人系统提供了高效的协调探索和对象搜索能力，特别支持自然语言语义指导，这是传统算法无法实现的。

Abstract: Autonomous exploration and object search in unknown indoor environments
remain challenging for multi-robot systems (MRS). Traditional approaches often
rely on greedy frontier assignment strategies with limited inter-robot
coordination. In this work, we introduce LLM-MCoX (LLM-based Multi-robot
Coordinated Exploration and Search), a novel framework that leverages Large
Language Models (LLMs) for intelligent coordination of both homogeneous and
heterogeneous robot teams tasked with efficient exploration and target object
search. Our approach combines real-time LiDAR scan processing for frontier
cluster extraction and doorway detection with multimodal LLM reasoning (e.g.,
GPT-4o) to generate coordinated waypoint assignments based on shared
environment maps and robot states. LLM-MCoX demonstrates superior performance
compared to existing methods, including greedy and Voronoi-based planners,
achieving 22.7% faster exploration times and 50% improved search efficiency in
large environments with 6 robots. Notably, LLM-MCoX enables natural
language-based object search capabilities, allowing human operators to provide
high-level semantic guidance that traditional algorithms cannot interpret.

</details>


### [33] [Kinodynamic Motion Planning for Mobile Robot Navigation across Inconsistent World Models](https://arxiv.org/abs/2509.26339)
*Eric R. Damm,Thomas M. Howard*

Main category: cs.RO

TL;DR: 该论文提出了三种处理移动机器人环境建模不确定性的路径规划方法（PEH、GEH、GEGRH），通过跟踪历史世界模型来处理障碍物识别不一致的问题。GEGRH方法在保持保守性的同时，找到了比VEH方法成本更低的轨迹，且规划时间更快。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在未知环境中运行时，由于传感器噪声和算法限制，障碍物识别可能不一致，导致规划系统难以生成安全运动。需要解决成本地图中区域在连续规划周期内被标记为障碍物和自由空间之间切换的问题。

Method: 提出了三种迭代方法：PEH在节点扩展时调用子搜索；GEH和GEGRH将子搜索推迟到边扩展到目标区域后；GEGRH额外增加了基于不同世界中分歧节点的图修订步骤。

Result: PEH和GEH虽然比VEH找到更乐观的解，但规划时间超过1秒，不符合现场部署要求。GEGRH在野外实验中找到了比VEH成本更低的轨迹，平均规划时间更快。与单假设搜索相比，GEGRH生成更保守的规划，平均规划时间略有增加。

Conclusion: GEGRH方法通过推迟子搜索和增加图修订步骤，在保持规划保守性的同时，实现了比VEH更好的性能，平衡了规划质量和计算效率的需求。

Abstract: Mobile ground robots lacking prior knowledge of an environment must rely on
sensor data to develop a model of their surroundings. In these scenarios,
consistent identification of obstacles and terrain features can be difficult
due to noise and algorithmic shortcomings, which can make it difficult for
motion planning systems to generate safe motions. One particular difficulty to
overcome is when regions of the cost map switch between being marked as
obstacles and free space through successive planning cycles. One potential
solution to this, which we refer to as Valid in Every Hypothesis (VEH), is for
the planning system to plan motions that are guaranteed to be safe through a
history of world models. Another approach is to track a history of world
models, and adjust node costs according to the potential penalty of needing to
reroute around previously hazardous areas. This work discusses three major
iterations on this idea. The first iteration, called PEH, invokes a sub-search
for every node expansion that crosses through a divergence point in the world
models. The second and third iterations, called GEH and GEGRH respectively,
defer the sub-search until after an edge expands into the goal region. GEGRH
uses an additional step to revise the graph based on divergent nodes in each
world. Initial results showed that, although PEH and GEH find more optimistic
solutions than VEH, they are unable to generate solutions in less than
one-second, which exceeds our requirements for field deployment. Analysis of
results from a field experiment in an unstructured, off-road environment on a
Clearpath Robotics Warthog UGV indicate that GEGRH finds lower cost
trajectories and has faster average planning times than VEH. Compared to
single-hypothesis (SH) search, where only the latest world model is considered,
GEGRH generates more conservative plans with a small increase in average
planning time.

</details>


### [34] [SDA-PLANNER: State-Dependency Aware Adaptive Planner for Embodied Task Planning](https://arxiv.org/abs/2509.26375)
*Zichao Shen,Chen Gao,Jiaqi Yuan,Tianchen Zhu,Xingcheng Fu,Qingyun Sun*

Main category: cs.RO

TL;DR: SDA-PLANNER是一个用于具身任务规划的新型LLM架构，通过状态依赖图和错误自适应重规划机制，解决了现有方法在规划范式固定、缺乏动作序列约束和错误处理方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的具身任务规划方法存在三个主要限制：固定的规划范式、缺乏动作序列约束以及错误不可知。这些限制影响了智能体在真实环境中的执行效果和适应性。

Method: 提出SDA-PLANNER方法，包含状态依赖图来显式建模动作前提条件和效果，指导动态修订；采用错误自适应重规划策略，包括错误回溯与诊断以及自适应动作子树生成，基于当前环境状态局部重建受影响的部分计划。

Result: 实验表明SDA-PLANNER在成功率和目标完成率方面持续优于基线方法，特别是在各种错误条件下表现更加突出。

Conclusion: SDA-PLANNER通过自适应规划范式、状态依赖感知和错误感知机制，为全面的具身任务规划提供了有效解决方案，显著提升了规划性能和对执行错误的鲁棒性。

Abstract: Embodied task planning requires agents to produce executable actions in a
close-loop manner within the environment. With progressively improving
capabilities of LLMs in task decomposition, planning, and generalization,
current embodied task planning methods adopt LLM-based architecture.However,
existing LLM-based planners remain limited in three aspects, i.e., fixed
planning paradigms, lack of action sequence constraints, and error-agnostic. In
this work, we propose SDA-PLANNER, enabling an adaptive planning paradigm,
state-dependency aware and error-aware mechanisms for comprehensive embodied
task planning. Specifically, SDA-PLANNER introduces a State-Dependency Graph to
explicitly model action preconditions and effects, guiding the dynamic
revision. To handle execution error, it employs an error-adaptive replanning
strategy consisting of Error Backtrack and Diagnosis and Adaptive Action
SubTree Generation, which locally reconstructs the affected portion of the plan
based on the current environment state. Experiments demonstrate that
SDA-PLANNER consistently outperforms baselines in success rate and goal
completion, particularly under diverse error conditions.

</details>


### [35] [Real-time Velocity Profile Optimization for Time-Optimal Maneuvering with Generic Acceleration Constraints](https://arxiv.org/abs/2509.26428)
*Mattia Piazza,Mattia Piccinini,Sebastiano Taddei,Francesco Biral,Enrico Bertolazzi*

Main category: cs.RO

TL;DR: 提出FBGA算法，用于在给定路径上计算时间最优速度剖面，支持通用加速度约束，兼顾高精度和低计算时间。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么支持任意加速度约束但计算成本高，要么使用保守的箱式约束以提高计算效率，需要一种能同时满足高精度和低计算时间的方法。

Method: FBGA采用前向-后向算法，在短离散路径段上最大化速度剖面，同时满足用户定义的性能限制，支持复杂非凸加速度约束。

Result: 在五个赛道和两种车辆类别上测试，FBGA与最优控制基准的圈时误差在0.11%-0.36%之间，计算速度快三个数量级，即使在粗离散化下仍保持高精度。

Conclusion: FBGA适用于在线多查询轨迹规划，提供了开源C++实现。

Abstract: The computation of time-optimal velocity profiles along prescribed paths,
subject to generic acceleration constraints, is a crucial problem in robot
trajectory planning, with particular relevance to autonomous racing. However,
the existing methods either support arbitrary acceleration constraints at high
computational cost or use conservative box constraints for computational
efficiency. We propose FBGA, a new \underline{F}orward-\underline{B}ackward
algorithm with \underline{G}eneric \underline{A}cceleration constraints, which
achieves both high accuracy and low computation time. FBGA operates forward and
backward passes to maximize the velocity profile in short, discretized path
segments, while satisfying user-defined performance limits. Tested on five
racetracks and two vehicle classes, FBGA handles complex, non-convex
acceleration constraints with custom formulations. Its maneuvers and lap times
closely match optimal control baselines (within $0.11\%$-$0.36\%$), while being
up to three orders of magnitude faster. FBGA maintains high accuracy even with
coarse discretization, making it well-suited for online multi-query trajectory
planning. Our open-source \texttt{C++} implementation is available at:
https://anonymous.4open.science/r/FB_public_RAL.

</details>


### [36] [Unwinding Rotations Reduces VR Sickness in Nonsimulated Immersive Telepresence](https://arxiv.org/abs/2509.26439)
*Filip Kulisiewicz,Basak Sakcak,Evan G. Center,Juho Kalliokoski,Katherine J. Mimnaugh,Steven M. LaValle,Timo Ojala*

Main category: cs.RO

TL;DR: 本文研究了在沉浸式机器人远程临场系统中，通过解耦机器人旋转与用户视角旋转的方法来减少VR晕动症，并在真实环境中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在沉浸式机器人远程临场系统中，机器人运动会导致用户产生VR晕动症，影响用户体验。虽然之前的研究表明解耦机器人旋转可以增加用户舒适度，但这些研究是在虚拟环境和模拟机器人中进行的，需要在真实环境中验证这一假设。

Method: 进行了用户研究(n=36)，在安装在机械臂上的全景相机任务中，比较了解耦旋转方法与耦合旋转方法。在涉及三维平移和旋转的检查任务中，测试了解耦机器人旋转对用户表现的影响。

Result: 用户认为解耦旋转方法更舒适且更受青睐，可以在不显著影响任务表现的情况下实现VR晕动症的减少。

Conclusion: 解耦机器人旋转的方法能够有效提高用户舒适度并减少VR晕动症，同时不会显著影响任务性能，在真实环境中验证了该方法的有效性。

Abstract: Immersive telepresence, when a user views the video stream of a $360^\circ$
camera in a remote environment using a Head Mounted Display (HMD), has great
potential to improve the sense of being in a remote environment. In most cases
of immersive robotic telepresence, the camera is mounted on a mobile robot
which increases the portion of the environment that the remote user can
explore. However, robot motions can induce unpleasant symptoms associated with
Virtual Reality (VR) sickness, degrading the overall user experience. Previous
research has shown that unwinding the rotations of the robot, that is,
decoupling the rotations that the camera undergoes due to robot motions from
what is seen by the user, can increase user comfort and reduce VR sickness.
However, that work considered a virtual environment and a simulated robot. In
this work, to test whether the same hypotheses hold when the video stream from
a real camera is used, we carried out a user study $(n=36)$ in which the
unwinding rotations method was compared against coupled rotations in a task
completed through a panoramic camera mounted on a robotic arm. Furthermore,
within an inspection task which involved translations and rotations in three
dimensions, we tested whether unwinding the robot rotations impacted the
performance of users. The results show that the users found the unwinding
rotations method to be more comfortable and preferable, and that a reduced
level of VR sickness can be achieved without a significant impact on task
performance.

</details>


### [37] [Analytic Conditions for Differentiable Collision Detection in Trajectory Optimization](https://arxiv.org/abs/2509.26459)
*Akshay Jaitly,Devesh K. Jha,Kei Ota,Yuki Shirai*

Main category: cs.RO

TL;DR: 提出了一种高效执行集合非穿透约束的优化方法，适用于碰撞感知轨迹优化等任务，通过引入可微条件和光滑半代数集近似多面体来实现。


<details>
  <summary>Details</summary>
Motivation: 基于优化的方法在复杂任务中广泛应用，但需要强制执行物体间的非穿透约束，导致计算成本高昂，限制了其在规划和控制中的应用。

Method: 引入具有解析表达式的可微条件来执行非穿透约束，并提出将多面体近似为光滑半代数集的方法来处理非光滑物体的非碰撞问题。

Result: 通过多个数值实验验证了所提方法的性能，并与文献中其他基线方法进行了比较。

Conclusion: 该方法能够高效地在配置优化过程中执行非穿透约束，为碰撞感知轨迹优化等应用提供了可行的解决方案。

Abstract: Optimization-based methods are widely used for computing fast, diverse
solutions for complex tasks such as collision-free movement or planning in the
presence of contacts. However, most of these methods require enforcing
non-penetration constraints between objects, resulting in a non-trivial and
computationally expensive problem. This makes the use of optimization-based
methods for planning and control challenging. In this paper, we present a
method to efficiently enforce non-penetration of sets while performing
optimization over their configuration, which is directly applicable to problems
like collision-aware trajectory optimization. We introduce novel differentiable
conditions with analytic expressions to achieve this. To enforce non-collision
between non-smooth bodies using these conditions, we introduce a method to
approximate polytopes as smooth semi-algebraic sets. We present several
numerical experiments to demonstrate the performance of the proposed method and
compare the performance with other baseline methods recently proposed in the
literature.

</details>


### [38] [Learning from Hallucinating Critical Points for Navigation in Dynamic Environments](https://arxiv.org/abs/2509.26513)
*Saad Abdul Ghani,Kameron Lee,Xuesu Xiao*

Main category: cs.RO

TL;DR: 提出LfH-CP自监督框架，通过识别关键点并生成多样化轨迹来创建动态障碍物数据集，无需专家演示或试错探索。


<details>
  <summary>Details</summary>
Motivation: 在动态障碍物环境中学习运动规划需要大量多样的数据集，但传统方法生成成本高且多样性不足。

Method: 将幻觉分解为两个阶段：识别关键点（障碍物必须出现的时间和位置），然后程序化生成通过这些点且避免碰撞的多样化轨迹。

Result: LfH-CP生成的数据集比现有基线方法更加多样化，训练出的规划器在模拟实验中成功率更高。

Conclusion: LfH-CP框架能够有效生成丰富多样的动态障碍物数据集，提升运动规划器的性能。

Abstract: Generating large and diverse obstacle datasets to learn motion planning in
environments with dynamic obstacles is challenging due to the vast space of
possible obstacle trajectories. Inspired by hallucination-based data synthesis
approaches, we propose Learning from Hallucinating Critical Points (LfH-CP), a
self-supervised framework for creating rich dynamic obstacle datasets based on
existing optimal motion plans without requiring expensive expert demonstrations
or trial-and-error exploration. LfH-CP factorizes hallucination into two
stages: first identifying when and where obstacles must appear in order to
result in an optimal motion plan, i.e., the critical points, and then
procedurally generating diverse trajectories that pass through these points
while avoiding collisions. This factorization avoids generative failures such
as mode collapse and ensures coverage of diverse dynamic behaviors. We further
introduce a diversity metric to quantify dataset richness and show that LfH-CP
produces substantially more varied training data than existing baselines.
Experiments in simulation demonstrate that planners trained on LfH-CP datasets
achieves higher success rates compared to a prior hallucination method.

</details>


### [39] [Memory-Efficient 2D/3D Shape Assembly of Robot Swarms](https://arxiv.org/abs/2509.26518)
*Shuoyu Yue,Pengpeng Li,Yang Xu,Kunrui Ze,Xingjian Long,Huazi Cao,Guibin Sun*

Main category: cs.RO

TL;DR: 提出了一种基于树形图表示的记忆高效方法，用于机器人群体形状组装，显著降低内存使用并提高形状进入速度。


<details>
  <summary>Details</summary>
Motivation: 现有的基于均值漂移的机器人群体形状组装方法使用图像表示目标形状，导致高内存开销，特别是在高分辨率或3D形状时变得不可行。

Method: 开发了分层编码用户指定形状的树形图表示，并设计了基于行为的分布式控制器，实现无分配的形状组装。

Result: 与最先进的均值漂移算法相比，内存使用降低1-2个数量级，形状进入速度快2-3倍，同时保持相当的均匀性。物理实验验证了其实际可行性。

Conclusion: 所提出的树形图表示和分布式控制器为机器人群体形状组装提供了高效实用的解决方案，特别适用于内存受限的场景。

Abstract: Mean-shift-based approaches have recently emerged as the most effective
methods for robot swarm shape assembly tasks. These methods rely on image-based
representations of target shapes to compute local density gradients and perform
mean-shift exploration, which constitute their core mechanism. However, such
image representations incur substantial memory overhead, which can become
prohibitive for high-resolution or 3D shapes. To overcome this limitation, we
propose a memory-efficient tree map representation that hierarchically encodes
user-specified shapes and is applicable to both 2D and 3D scenarios. Building
on this representation, we design a behavior-based distributed controller that
enables assignment-free shape assembly. Comparative 2D and 3D simulations
against a state-of-the-art mean-shift algorithm demonstrate one to two orders
of magnitude lower memory usage and two to three times faster shape entry while
maintaining comparable uniformity. Finally, we validate the framework through
physical experiments with 6 to 7 UAVs, confirming its real-world practicality.

</details>


### [40] [Radio-based Multi-Robot Odometry and Relative Localization](https://arxiv.org/abs/2509.26558)
*Andrés Martínez-Silva,David Alejo,Luis Merino,Fernando Caballero*

Main category: cs.RO

TL;DR: 提出了一种基于UWB和雷达的多机器人UGV-UAV相对定位系统，通过非线性优化和位姿图优化框架实现空中机器人相对于地面机器人的精确定位。


<details>
  <summary>Details</summary>
Motivation: 利用UWB和雷达在恶劣环境和杂乱环境中的鲁棒性优势，开发低成本、易获取的多机器人相对定位系统。

Method: 采用两阶段方法：第一阶段使用非线性优化框架进行UWB三边定位和雷达预处理；第二阶段使用位姿图优化框架融合里程计和机器人间约束。

Result: 系统在SITL仿真和真实数据集上验证，性能优于现有闭式方法，对噪声更鲁棒。

Conclusion: 提出的相对定位模块具有优越性能，因子图公式易于扩展到完整SLAM系统，所有代码和数据已开源。

Abstract: Radio-based methods such as Ultra-Wideband (UWB) and RAdio Detection And
Ranging (radar), which have traditionally seen limited adoption in robotics,
are experiencing a boost in popularity thanks to their robustness to harsh
environmental conditions and cluttered environments. This work proposes a
multi-robot UGV-UAV localization system that leverages the two technologies
with inexpensive and readily-available sensors, such as Inertial Measurement
Units (IMUs) and wheel encoders, to estimate the relative position of an aerial
robot with respect to a ground robot. The first stage of the system pipeline
includes a nonlinear optimization framework to trilaterate the location of the
aerial platform based on UWB range data, and a radar pre-processing module with
loosely coupled ego-motion estimation which has been adapted for a multi-robot
scenario. Then, the pre-processed radar data as well as the relative
transformation are fed to a pose-graph optimization framework with odometry and
inter-robot constraints. The system, implemented for the Robotic Operating
System (ROS 2) with the Ceres optimizer, has been validated in
Software-in-the-Loop (SITL) simulations and in a real-world dataset. The
proposed relative localization module outperforms state-of-the-art closed-form
methods which are less robust to noise. Our SITL environment includes a custom
Gazebo plugin for generating realistic UWB measurements modeled after real
data. Conveniently, the proposed factor graph formulation makes the system
readily extensible to full Simultaneous Localization And Mapping (SLAM).
Finally, all the code and experimental data is publicly available to support
reproducibility and to serve as a common open dataset for benchmarking.

</details>


### [41] [Graphite: A GPU-Accelerated Mixed-Precision Graph Optimization Framework](https://arxiv.org/abs/2509.26581)
*Shishir Gopinath,Karthik Dantu,Steven Y. Ko*

Main category: cs.RO

TL;DR: Graphite是一个GPU加速的非线性图优化框架，提供CUDA C++接口，支持内存优化技术，在保持通用性的同时达到与专用求解器相似的性能，并在大规模优化中实现显著加速。


<details>
  <summary>Details</summary>
Motivation: 现有的GPU加速优化框架通常缺乏通用性，或者需要大量内存。Graphite旨在提供一个既高效又通用的GPU加速非线性优化框架，支持实时应用如SLAM系统。

Method: 采用CUDA C++接口实现代码共享，支持内存优化技术包括原位优化、多浮点类型和混合精度模式、动态计算雅可比矩阵。

Result: 在捆绑调整问题上与专用求解器MegBA性能相当但内存使用更少；在立体惯性SLAM数据集上的全局视觉惯性捆绑调整中，相比CPU基线实现高达59倍的加速。

Conclusion: Graphite能够在保持通用性的同时实现高效的大规模优化，适用于桌面和资源受限设备，为实时优化应用提供了可行的解决方案。

Abstract: We present Graphite, a GPU-accelerated nonlinear graph optimization
framework. It provides a CUDA C++ interface to enable the sharing of code
between a realtime application, such as a SLAM system, and its optimization
tasks. The framework supports techniques to reduce memory usage, including
in-place optimization, support for multiple floating point types and
mixed-precision modes, and dynamically computed Jacobians. We evaluate Graphite
on well-known bundle adjustment problems and find that it achieves similar
performance to MegBA, a solver specialized for bundle adjustment, while
maintaining generality and using less memory. We also apply Graphite to global
visual-inertial bundle adjustment on maps generated from stereo-inertial SLAM
datasets, and observe speed ups of up to 59x compared to a CPU baseline. Our
results indicate that our solver enables faster large-scale optimization on
both desktop and resource-constrained devices.

</details>


### [42] [OmniRetarget: Interaction-Preserving Data Generation for Humanoid Whole-Body Loco-Manipulation and Scene Interaction](https://arxiv.org/abs/2509.26633)
*Lujie Yang,Xiaoyu Huang,Zhen Wu,Angjoo Kanazawa,Pieter Abbeel,Carmelo Sferrazza,C. Karen Liu,Rocky Duan,Guanya Shi*

Main category: cs.RO

TL;DR: OmniRetarget是一个基于交互网格的运动重定向系统，能够保留人-物体-环境之间的关键交互关系，生成高质量的机器人运动轨迹，用于训练强化学习策略。


<details>
  <summary>Details</summary>
Motivation: 现有的运动重定向方法存在显著的具身差距问题，会产生脚滑和穿透等物理上不可行的伪影，且忽略了人-物体和环境交互对于表达性运动和操作的重要性。

Method: 通过最小化人类和机器人网格之间的拉普拉斯变形，同时强制执行运动学约束，生成运动学可行的轨迹。使用交互网格显式建模并保留代理、地形和操作对象之间的空间和接触关系。

Result: 从OMOMO、LAFAN1和内部MoCap数据集重定向运动，生成了超过8小时的轨迹，在运动学约束满足和接触保持方面优于广泛使用的基线方法。

Conclusion: 高质量的数据使本体感知强化学习策略能够在Unitree G1人形机器人上成功执行长达30秒的跑酷和运动操作技能，仅使用5个奖励项和简单的领域随机化，无需任何学习课程。

Abstract: A dominant paradigm for teaching humanoid robots complex skills is to
retarget human motions as kinematic references to train reinforcement learning
(RL) policies. However, existing retargeting pipelines often struggle with the
significant embodiment gap between humans and robots, producing physically
implausible artifacts like foot-skating and penetration. More importantly,
common retargeting methods neglect the rich human-object and human-environment
interactions essential for expressive locomotion and loco-manipulation. To
address this, we introduce OmniRetarget, an interaction-preserving data
generation engine based on an interaction mesh that explicitly models and
preserves the crucial spatial and contact relationships between an agent, the
terrain, and manipulated objects. By minimizing the Laplacian deformation
between the human and robot meshes while enforcing kinematic constraints,
OmniRetarget generates kinematically feasible trajectories. Moreover,
preserving task-relevant interactions enables efficient data augmentation, from
a single demonstration to different robot embodiments, terrains, and object
configurations. We comprehensively evaluate OmniRetarget by retargeting motions
from OMOMO, LAFAN1, and our in-house MoCap datasets, generating over 8-hour
trajectories that achieve better kinematic constraint satisfaction and contact
preservation than widely used baselines. Such high-quality data enables
proprioceptive RL policies to successfully execute long-horizon (up to 30
seconds) parkour and loco-manipulation skills on a Unitree G1 humanoid, trained
with only 5 reward terms and simple domain randomization shared by all tasks,
without any learning curriculum.

</details>


### [43] [MLA: A Multisensory Language-Action Model for Multimodal Understanding and Forecasting in Robotic Manipulation](https://arxiv.org/abs/2509.26642)
*Zhuoyang Liu,Jiaming Liu,Jiadong Xu,Nuowei Han,Chenyang Gu,Hao Chen,Kaichen Zhou,Renrui Zhang,Kai Chin Hsieh,Kun Wu,Zhengping Che,Jian Tang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 提出了一种多感官语言-动作（MLA）模型，通过协同感知异构感官模态并预测未来多感官目标来增强物理世界建模能力，在复杂接触丰富的机器人任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型主要关注视觉和语言解释来生成动作，但机器人在空间物理世界中需要感知和交互，缺乏对机器人特定多感官信息的全面理解，这对于实现复杂接触控制至关重要。

Method: 1）提出无编码器的多模态对齐方案，将大语言模型本身作为感知模块，通过位置对应直接解释2D图像、3D点云和触觉令牌；2）设计未来多感官生成后训练策略，使MLA能够推理语义、几何和交互信息。

Result: 在复杂接触丰富的真实世界任务中，MLA模型分别比之前最先进的2D和3D VLA方法提高了12%和24%，同时在未见配置下表现出更好的泛化能力。

Conclusion: MLA模型通过多感官感知和未来目标预测有效增强了物理世界建模能力，为机器人复杂控制任务提供了更稳健的条件。

Abstract: Vision-language-action models (VLAs) have shown generalization capabilities
in robotic manipulation tasks by inheriting from vision-language models (VLMs)
and learning action generation. Most VLA models focus on interpreting vision
and language to generate actions, whereas robots must perceive and interact
within the spatial-physical world. This gap highlights the need for a
comprehensive understanding of robotic-specific multisensory information, which
is crucial for achieving complex and contact-rich control. To this end, we
introduce a multisensory language-action (MLA) model that collaboratively
perceives heterogeneous sensory modalities and predicts future multisensory
objectives to facilitate physical world modeling. Specifically, to enhance
perceptual representations, we propose an encoder-free multimodal alignment
scheme that innovatively repurposes the large language model itself as a
perception module, directly interpreting multimodal cues by aligning 2D images,
3D point clouds, and tactile tokens through positional correspondence. To
further enhance MLA's understanding of physical dynamics, we design a future
multisensory generation post-training strategy that enables MLA to reason about
semantic, geometric, and interaction information, providing more robust
conditions for action generation. For evaluation, the MLA model outperforms the
previous state-of-the-art 2D and 3D VLA methods by 12% and 24% in complex,
contact-rich real-world tasks, respectively, while also demonstrating improved
generalization to unseen configurations. Project website:
https://sites.google.com/view/open-mla

</details>
