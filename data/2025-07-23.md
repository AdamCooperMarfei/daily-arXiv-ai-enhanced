<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 24]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Fast Task Planning with Neuro-Symbolic Relaxation](https://arxiv.org/abs/2507.15975)
*Qiwei Du,Bowen Li,Yi Du,Shaoshu Su,Taimeng Fu,Zitong Zhan,Zhipeng Zhao,Chen Wang*

Main category: cs.RO

TL;DR: 本文提出了Flax，一种神经符号松弛策略，通过结合神经重要性预测和符号扩展来实现快速可靠的长期任务规划，在迷宫导航基准测试中相比基线方法平均成功率提升20.82%，规划时间减少17.65%。


<details>
  <summary>Details</summary>
Motivation: 现实世界的任务规划需要对具有复杂关系和属性的大量实体进行长期推理，这导致经典符号规划器面临组合爆炸问题。现有的神经符号集成方法通过神经网络预测"重要"实体来简化任务，但这种方法存在遗漏关键实体和在不可解的简化任务上浪费资源的风险。

Method: 提出Flax神经符号松弛策略，包含四个步骤：1）使用图神经网络预测实体重要性创建简化任务；2）使用符号规划器求解简化任务；3）求解规则松弛任务获得粗略计划，并将所有引用实体重新整合到简化任务中以恢复被忽略的关键元素；4）应用互补规则细化更新后的任务，保持其可靠性和紧凑性。

Result: 在合成和真实世界迷宫导航基准测试中进行了广泛实验，结果显示Flax相比最先进的神经符号基线方法，平均成功率提升了20.82%，平均时钟规划时间减少了17.65%。

Conclusion: Flax为复杂环境中的快速、可扩展、长期任务规划提供了一条实用路径，通过神经重要性预测与符号扩展的结合，有效解决了现有方法的局限性，实现了更高的成功率和更短的规划时间。

Abstract: Real-world task planning requires long-horizon reasoning over large sets of
entities with complex relationships and attributes, leading to a combinatorial
explosion for classical symbolic planners. To prune the search space, recent
methods prioritize searching on a simplified task only containing a few
"important" entities predicted by a neural network. However, such a simple
neuro-symbolic (NeSy) integration risks omitting critical entities and wasting
resources on unsolvable simplified tasks. To enable Fast and reliable planning,
we introduce a NeSy relaxation strategy (Flax), combining neural importance
prediction with symbolic expansion. Specifically, we first learn a graph neural
network to predict entity importance to create a simplified task and solve it
with a symbolic planner. Then, we solve a rule-relaxed task to obtain a quick
rough plan, and reintegrate all referenced entities into the simplified task to
recover any overlooked but essential elements. Finally, we apply complementary
rules to refine the updated task, keeping it both reliable and compact.
Extensive experiments are conducted on both synthetic and real-world maze
navigation benchmarks where a robot must traverse through a maze and interact
with movable objects. The results show that Flax boosts the average success
rate by 20.82% and cuts mean wall-clock planning time by 17.65% compared with
the state-of-the-art NeSy baseline. We expect that Flax offers a practical path
toward fast, scalable, long-horizon task planning in complex environments.

</details>


### [2] [A Comprehensive Evaluation of LiDAR Odometry Techniques](https://arxiv.org/abs/2507.16000)
*Easton Potokar,Michael Kaess*

Main category: cs.RO

TL;DR: 本文对激光雷达里程计(LO)管道的各个组成模块进行了系统性的消融研究和实证评估，并基于大量数据集实验为未来LO管道设计提供了实证支持的建议。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR里程计研究主要关注整体"管道"间的比较，缺乏对LO管道各个构建模块的系统性消融研究和深入分析，难以为未来设计提供明确指导。

Method: 总结LO管道的各种技术组件，在跨环境、LiDAR类型和车辆运动的大量数据集上对这些LO组件进行实证评估和消融研究。

Result: 通过广泛的实验评估，识别出了LO管道中各个组件的性能表现，为不同应用场景下的最优组件选择提供了数据支持。

Conclusion: 基于实证研究结果，为未来LO管道的设计提供了具有实证支持的建议，以实现最准确和可靠的性能表现。

Abstract: Light Detection and Ranging (LiDAR) sensors have become the sensor of choice
for many robotic state estimation tasks. Because of this, in recent years there
has been significant work done to fine the most accurate method to perform
state estimation using these sensors. In each of these prior works, an
explosion of possible technique combinations has occurred, with each work
comparing LiDAR Odometry (LO) "pipelines" to prior "pipelines". Unfortunately,
little work up to this point has performed the significant amount of ablation
studies comparing the various building-blocks of a LO pipeline. In this work,
we summarize the various techniques that go into defining a LO pipeline and
empirically evaluate these LO components on an expansive number of datasets
across environments, LiDAR types, and vehicle motions. Finally, we make
empirically-backed recommendations for the design of future LO pipelines to
provide the most accurate and reliable performance.

</details>


### [3] [Improved Semantic Segmentation from Ultra-Low-Resolution RGB Images Applied to Privacy-Preserving Object-Goal Navigation](https://arxiv.org/abs/2507.16034)
*Xuying Huang,Sicong Pan,Olga Zatsarynna,Juergen Gall,Maren Bennewitz*

Main category: cs.RO

TL;DR: 本文提出了一种在超低分辨率设置下进行语义分割的联合学习方法，实现了保护隐私的移动机器人语义导航，在保障用户隐私的同时提升了机器人任务执行效果。


<details>
  <summary>Details</summary>
Motivation: 现有移动机器人方法通常只关注下游任务性能或隐私保护其中之一，隐私保护往往会限制任务执行的有效性。因此需要同时解决机器人任务性能和用户视觉隐私保护两个目标。

Method: 引入了一种新颖的完全联合学习方法，集成了聚合特征提取器和分割感知判别器，用于解决超低分辨率语义分割问题，从而实现保护隐私的语义目标导航。

Result: 该方法在超低分辨率语义分割任务上优于不同基线方法，改进的分割结果提高了真实世界隐私约束场景下语义目标导航的成功率。

Conclusion: 通过超低分辨率设置和联合学习方法，成功实现了在保护用户视觉隐私的同时提升机器人语义导航性能的双重目标。

Abstract: User privacy in mobile robotics has become a critical concern. Existing
methods typically prioritize either the performance of downstream robotic tasks
or privacy protection, with the latter often constraining the effectiveness of
task execution. To jointly address both objectives, we study semantic-based
robot navigation in an ultra-low-resolution setting to preserve visual privacy.
A key challenge in such scenarios is recovering semantic segmentation from
ultra-low-resolution RGB images. In this work, we introduce a novel fully
joint-learning method that integrates an agglomerative feature extractor and a
segmentation-aware discriminator to solve ultra-low-resolution semantic
segmentation, thereby enabling privacy-preserving, semantic object-goal
navigation. Our method outperforms different baselines on ultra-low-resolution
semantic segmentation and our improved segmentation results increase the
success rate of the semantic object-goal navigation in a real-world
privacy-constrained scenario.

</details>


### [4] [Therapist-Exoskeleton-Patient Interaction: An Immersive Gait Therapy](https://arxiv.org/abs/2507.16059)
*Emek Barış Küçüktabak,Matthew R. Short,Lorenzo Vianello,Daniel Ludvig,Levi Hargrove,Kevin Lynch,Jose Pons*

Main category: cs.RO

TL;DR: 本研究提出了一种基于物理人-机器人-人交互(pHRHI)的新型步态康复范式，通过虚拟弹簧阻尼元件连接治疗师和中风患者的下肢外骨骼，实现双向交互指导和触觉反馈，在8名慢性中风患者的研究中显示出比传统治疗师指导步行更好的康复效果。


<details>
  <summary>Details</summary>
Motivation: 中风后患者常因下肢无力和关节控制缺失而出现运动和平衡障碍。传统康复训练需要治疗师高强度人工辅助，既费力又限制了多关节同时干预的能力。现有机器人外骨骼虽能提供多关节支持和客观反馈，但控制策略往往限制了治疗师的参与度和适应性。

Method: 提出基于物理人-机器人-人交互(pHRHI)的步态康复新范式。治疗师和中风患者都穿戴下肢外骨骼，通过虚拟弹簧-阻尼元件在髋关节和膝关节处连接。这种设计实现了双向交互，允许治疗师引导运动并接收触觉反馈。

Result: 对8名慢性中风患者的研究显示，pHRHI训练相比传统治疗师指导的跑步机步行训练效果更佳，表现为关节活动范围增加、步态指标改善、肌肉激活增强以及患者积极性提高。

Conclusion: pHRHI具有将机器人精确性与治疗师直觉相结合的潜力，能够改善康复效果。这种新范式为中风后步态康复提供了一种创新的解决方案。

Abstract: Following a stroke, individuals often experience mobility and balance
impairments due to lower-limb weakness and loss of independent joint control.
Gait recovery is a key goal of rehabilitation, traditionally achieved through
high-intensity therapist-led training. However, manual assistance can be
physically demanding and limits the therapist's ability to interact with
multiple joints simultaneously. Robotic exoskeletons offer multi-joint support,
reduce therapist strain, and provide objective feedback, but current control
strategies often limit therapist involvement and adaptability.
  We present a novel gait rehabilitation paradigm based on physical
Human-Robot-Human Interaction (pHRHI), where both the therapist and the
post-stroke individual wear lower-limb exoskeletons virtually connected at the
hips and knees via spring-damper elements. This enables bidirectional
interaction, allowing the therapist to guide movement and receive haptic
feedback. In a study with eight chronic stroke patients, pHRHI training
outperformed conventional therapist-guided treadmill walking, leading to
increased joint range of motion, step metrics, muscle activation, and
motivation. These results highlight pHRHI's potential to combine robotic
precision with therapist intuition for improved rehabilitation outcomes.

</details>


### [5] [Compositional Coordination for Multi-Robot Teams with Large Language Models](https://arxiv.org/abs/2507.16068)
*Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: 提出了LAN2CB框架，利用大语言模型将自然语言任务描述直接转换为多机器人系统的可执行Python代码，简化了传统的专家驱动的多机器人协调流程


<details>
  <summary>Details</summary>
Motivation: 传统多机器人协调依赖任务特定的专家驱动流程，需要领域专家手动将自然语言任务描述转换为数学公式、算法设计和可执行代码，这个过程劳动密集、非专家难以使用且对任务需求变化缺乏灵活性

Method: LAN2CB框架包含两个核心组件：(1)任务分解模块，将任务解析为带依赖关系的任务图；(2)代码生成模块，使用任务图和结构化知识库生成可部署的机器人控制代码。同时构建了自然语言任务规范数据集用于开发和基准测试

Result: 在仿真和真实世界环境中的实验结果表明，LAN2CB能够从自然语言有效且灵活地实现多机器人协调，显著减少了手动工程需求，并支持跨任务类型的泛化

Conclusion: LAN2CB成功利用大语言模型简化了多机器人协调流程，实现了从自然语言到可执行代码的直接转换，提高了系统的可访问性和灵活性，为多机器人系统的部署提供了更便捷的解决方案

Abstract: Multi-robot coordination has traditionally relied on a task-specific and
expert-driven pipeline, where natural language mission descriptions are
manually translated by domain experts into mathematical formulation, algorithm
design, and executable code. This conventional process is labor-intensive,
inaccessible to non-experts, and inflexible to changes in mission requirements.
Here, we propose LAN2CB (Language to Collective Behavior), a novel framework
that leverages large language models (LLMs) to streamline and generalize the
multi-robot coordination pipeline. LAN2CB directly converts natural language
mission descriptions into executable Python code for multi-robot systems
through two key components: (1) Mission Decomposition for Task Representation,
which parses the mission into a task graph with dependencies, and (2) Code
Generation, which uses the task graph and a structured knowledge base to
generate deployable robot control code. We further introduce a dataset of
natural language mission specifications to support development and
benchmarking. Experimental results in both simulation and real-world settings
show that LAN2CB enables effective and flexible multi-robot coordination from
natural language, significantly reducing the need for manual engineering while
supporting generalization across mission types. Website:
https://sites.google.com/view/lan2cb.

</details>


### [6] [FTIN: Frequency-Time Integration Network for Inertial Odometry](https://arxiv.org/abs/2507.16120)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 本文提出了一种结合频域和时域信息的新型网络架构，用于改进惯性里程计的定位精度，通过频域学习建模长期依赖性并结合Scalar LSTM捕获时序依赖性，在多个公开数据集上取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的惯性里程计方法主要依赖时域CNN，难以捕获IMU数据中的长期依赖关系，从而限制了定位精度的进一步提升。

Method: 提出了一种集成频域和时域信息的新型网络架构：1）利用频域学习的全局视角和能量压缩特性来有效建模长期依赖性并减少IMU数据冗余；2）引入Scalar LSTM捕获时域序列依赖性，实现跨域信息融合，为定位提供稳定可靠的参考。

Result: 在多个公开数据集（RIDI、RoNIN、OxIOD、RNIN、TLIO和IMUNet）上验证了频域-时域融合策略的有效性。在RoNIN数据集上，相比RoNIN ResNet，该方法实现了43.0%的绝对轨迹误差降低和13.1%的相对轨迹误差降低。

Conclusion: 频域-时域融合架构能够有效解决传统基于CNN的惯性里程计方法在长期依赖建模方面的局限性，显著提升了定位精度，为惯性导航系统的发展提供了新的技术路径。

Abstract: In recent years, machine learning has achieved significant advancements in
inertial odometry. However, most existing inertial odometry methods primarily
rely on CNNs in the time domain. These methods often struggle to capture
long-term dependency in inertial measurement unit data, thereby constraining
the potential for further improvements in localization accuracy. To address
these issues, we propose a novel network architecture that integrates both
frequency-domain and time-domain information. Specifically, we leverage the
global view and energy compaction properties of frequency-domain learning to
effectively model long-term dependency and reduce redundancy in IMU data.
Additionally, we introduce a Scalar LSTM to capture sequential dependencies in
the time domain, enabling cross-domain information fusion and providing a
stable and reliable reference for localization. Experimental evaluations on
multiple public datasets (e.g., RIDI, RoNIN, OxIOD, RNIN, TLIO, and IMUNet)
demonstrate the effectiveness of the proposed frequency-time domain fusion
strategy. Notably, on the RoNIN dataset, our method achieves a 43.0% reduction
in absolute trajectory error and a 13.1% reduction in relative trajectory error
compared to RoNIN ResNet.

</details>


### [7] [DWSFormer: A Lightweight Inertial Odometry Network for Complex Motion Modeling](https://arxiv.org/abs/2507.16121)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 本文提出了一个轻量级惯性里程计(IO)框架，通过Star Operation方法将惯性数据投影到高维隐式非线性特征空间，结合协作注意力机制和多尺度门控卷积单元，有效解决了复杂运动模式（如转弯）导致的漂移误差问题，在六个惯性数据集上均超越了现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有惯性里程计方法虽然能准确重建简单和近线性运动轨迹，但在处理转弯等复杂运动模式时经常无法处理漂移误差，这严重降低了定位精度并限制了IO系统在真实世界场景中的适用性。

Method: 提出轻量级IO框架，包含三个核心组件：1）使用Star Operation方法将惯性数据投影到高维隐式非线性特征空间以提取复杂运动特征；2）引入协作注意力机制联合建模通道和时间维度的全局运动动态；3）设计多尺度门控卷积单元捕获运动过程中的细粒度动态变化。

Result: 在六个广泛使用的惯性数据集上进行的大量实验表明，该方法consistently超越了现有最佳基线方法。在RoNIN数据集上，与基线模型相比，ATE（绝对轨迹误差）降低了2.26%到65.78%。

Conclusion: 该方法在惯性里程计领域建立了新的基准，有效解决了复杂运动模式下的漂移误差问题，显著提升了定位精度，为消费级定位系统的广泛部署提供了核心技术支撑。

Abstract: Inertial odometry (IO) directly estimates the position of a carrier from
inertial sensor measurements and serves as a core technology for the widespread
deployment of consumer grade localization systems. While existing IO methods
can accurately reconstruct simple and near linear motion trajectories, they
often fail to account for drift errors caused by complex motion patterns such
as turning. This limitation significantly degrades localization accuracy and
restricts the applicability of IO systems in real world scenarios. To address
these challenges, we propose a lightweight IO framework. Specifically, inertial
data is projected into a high dimensional implicit nonlinear feature space
using the Star Operation method, enabling the extraction of complex motion
features that are typically overlooked. We further introduce a collaborative
attention mechanism that jointly models global motion dynamics across both
channel and temporal dimensions. In addition, we design Multi Scale Gated
Convolution Units to capture fine grained dynamic variations throughout the
motion process, thereby enhancing the model's ability to learn rich and
expressive motion representations. Extensive experiments demonstrate that our
proposed method consistently outperforms SOTA baselines across six widely used
inertial datasets. Compared to baseline models on the RoNIN dataset, it
achieves reductions in ATE ranging from 2.26% to 65.78%, thereby establishing a
new benchmark in the field.

</details>


### [8] [Benchmarking LLM Privacy Recognition for Social Robot Decision Making](https://arxiv.org/abs/2507.16124)
*Dakota Sullivan,Shirley Zhang,Jennica Li,Heather Kirkorian,Bilge Mutlu,Kassem Fawaz*

Main category: cs.RO

TL;DR: 研究评估大语言模型在家庭社交机器人场景中的隐私感知能力，发现人类和LLM在隐私偏好上存在较大分歧，并探讨了不同提示策略对提升LLM隐私控制能力的影响。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在社交机器人中的应用增加，机器人需要收集大量敏感个人信息（音频、图像、视频、位置等），特别是在家庭环境中。这引发了实用性与隐私风险之间的矛盾，因此需要评估当前LLM在处理敏感数据时的隐私感知能力。

Method: 基于情境完整性理论设计隐私相关场景，首先调研用户对家庭社交机器人行为的隐私偏好（N=450），然后将相同场景提供给最先进的LLM（N=10）进行比较分析。此外，实施了四种额外的提示策略来评估LLM作为隐私控制器的潜力。

Result: 发现人类和LLM在隐私偏好方面的一致性很低，表明现有的开箱即用LLM在家庭社交机器人场景中缺乏足够的隐私感知能力。通过不同提示策略的测试，探索了提升LLM隐私控制能力的可能性。

Conclusion: 当前LLM在家庭社交机器人应用中的隐私感知能力有限，与人类隐私偏好存在显著差异。研究强调了在人机交互中发展AI隐私感知能力的重要性和潜力，为未来隐私保护机制的设计提供了重要见解。

Abstract: Social robots are embodied agents that interact with people while following
human communication norms. These robots interact using verbal and non-verbal
cues, and share the physical environments of people. While social robots have
previously utilized rule-based systems or probabilistic models for user
interaction, the rapid evolution of large language models (LLMs) presents new
opportunities to develop LLM-empowered social robots for enhanced human-robot
interaction. To fully realize these capabilities, however, robots need to
collect data such as audio, fine-grained images, video, and locations. As a
result, LLMs often process sensitive personal information, particularly within
home environments. Given the tension between utility and privacy risks,
evaluating how current LLMs manage sensitive data is critical. Specifically, we
aim to explore the extent to which out-of-the-box LLMs are privacy-aware in the
context of household social robots. In this study, we present a set of
privacy-relevant scenarios crafted through the lens of Contextual Integrity
(CI). We first survey users' privacy preferences regarding in-home social robot
behaviors and then examine how their privacy orientation affects their choices
of these behaviors (N = 450). We then provide the same set of scenarios and
questions to state-of-the-art LLMs (N = 10) and find that the agreement between
humans and LLMs is low. To further investigate the capabilities of LLMs as a
potential privacy controller, we implement four additional prompting strategies
and compare their results. Finally, we discuss the implications and potential
of AI privacy awareness in human-robot interaction.

</details>


### [9] [Equivariant Goal Conditioned Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.16139)
*Arsh Tangri,Nichols Crawford Taylor,Haojie Huang,Robert Platt*

Main category: cs.RO

TL;DR: 本文提出了等变对比强化学习(ECRL)，通过利用目标条件操作任务中的固有对称性来改进对比强化学习，在样本效率和空间泛化能力方面都有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统的对比强化学习虽然能够从无标签交互中学习有用的结构化表示，但没有充分利用机器人操作任务中固有的对称性特征，限制了其在样本效率和空间泛化方面的表现。

Method: 提出等变对比强化学习(ECRL)方法：1)形式化定义目标条件群不变马尔可夫决策过程来刻画旋转对称的机器人操作任务；2)引入旋转不变的评价函数表示和旋转等变的执行器；3)将等变约束融入对比强化学习框架中。

Result: 在多个模拟任务的状态和图像设置中，ECRL方法始终优于强基线方法，并成功扩展到离线强化学习设置，在多个任务上展现了有效性。

Conclusion: 通过在对比强化学习中引入等变约束和利用任务的旋转对称性，ECRL能够显著提高样本效率和空间泛化能力，为无奖励强化学习提供了一个更有效的框架。

Abstract: Contrastive Reinforcement Learning (CRL) provides a promising framework for
extracting useful structured representations from unlabeled interactions. By
pulling together state-action pairs and their corresponding future states,
while pushing apart negative pairs, CRL enables learning nontrivial policies
without manually designed rewards. In this work, we propose Equivariant CRL
(ECRL), which further structures the latent space using equivariant
constraints. By leveraging inherent symmetries in goal-conditioned manipulation
tasks, our method improves both sample efficiency and spatial generalization.
Specifically, we formally define Goal-Conditioned Group-Invariant MDPs to
characterize rotation-symmetric robotic manipulation tasks, and build on this
by introducing a novel rotation-invariant critic representation paired with a
rotation-equivariant actor for Contrastive RL. Our approach consistently
outperforms strong baselines across a range of simulated tasks in both
state-based and image-based settings. Finally, we extend our method to the
offline RL setting, demonstrating its effectiveness across multiple tasks.

</details>


### [10] [Scanning Bot: Efficient Scan Planning using Panoramic Cameras](https://arxiv.org/abs/2507.16175)
*Euijeong Lee,Kyung Min Han,Young J. Kim*

Main category: cs.RO

TL;DR: 提出了一种全自动扫描规划方法，为全景RGB-D相机生成高效的环境扫描路径，实现无碰撞导航和充分的视点重叠，在真实环境中达到99%的扫描覆盖率，扫描速度比现有方法快3倍。


<details>
  <summary>Details</summary>
Motivation: 全景RGB-D相机虽然能产生高质量的3D场景重建，但需要手动选择视点和物理搬运相机，使得3D模型生成过程耗时且繁琐。对新手用户而言，由于空间约束（如确保视点帧间有足够的特征重叠）使得操作更加困难。

Method: 提出了一种全自动扫描规划方法，能够为环境扫描生成高效的巡视计划，确保无碰撞导航和规划内视点间的充分重叠。

Result: 在合成和真实环境中进行的大量实验验证了该规划器相对于最先进视点规划器的性能。在真实环境实验中，该方法实现了平均99%的扫描覆盖率，总扫描时间比最先进规划器快3倍。

Conclusion: 该全自动扫描规划方法成功解决了全景RGB-D相机手动操作的问题，显著提高了扫描效率和覆盖率，为3D场景重建提供了更加便捷和高效的解决方案。

Abstract: Panoramic RGB-D cameras are known for their ability to produce high quality
3D scene reconstructions. However, operating these cameras involves manually
selecting viewpoints and physically transporting the camera, making the
generation of a 3D model time consuming and tedious. Additionally, the process
can be challenging for novice users due to spatial constraints, such as
ensuring sufficient feature overlap between viewpoint frames. To address these
challenges, we propose a fully autonomous scan planning that generates an
efficient tour plan for environment scanning, ensuring collision-free
navigation and adequate overlap between viewpoints within the plan. Extensive
experiments conducted in both synthetic and real-world environments validate
the performance of our planner against state-of-the-art view planners. In
particular, our method achieved an average scan coverage of 99 percent in the
real-world experiment, with our approach being up to 3 times faster than
state-of-the-art planners in total scan time.

</details>


### [11] [Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers](https://arxiv.org/abs/2507.16214)
*Batu Candan,Simone Servadio*

Main category: cs.RO

TL;DR: 本文提出了一个完整的计算机视觉与自适应非线性滤波相结合的管道，用于解决主动碎片移除(ADR)任务中翻滚失效卫星的精确相对位姿估计问题


<details>
  <summary>Details</summary>
Motivation: 准确且鲁棒的相对位姿估计对于执行具有挑战性的主动碎片移除(ADR)任务至关重要，特别是针对像ESA的ENVISAT这样的翻滚失效卫星目标

Method: 采用卷积神经网络(CNN)检测结构标记点，将2D坐标转换为3D测量；在无迹卡尔曼滤波器(UKF)框架内融合这些测量数据；提出双重自适应策略：动态调整测量噪声协方差以补偿CNN测量不确定性变化，以及利用测量残差分析自适应调整过程噪声协方差来在线处理未建模动力学或机动

Result: 通过使用真实ENVISAT模型的高保真仿真评估了所提出的自适应集成系统性能，在各种条件下（包括测量中断）将估计结果与真实值进行比较，证明了系统的有效性

Conclusion: 这种综合方法为鲁棒的星载相对导航提供了增强解决方案，显著提升了ADR任务中安全近距离操作所需的能力

Abstract: Accurate and robust relative pose estimation is crucial for enabling
challenging Active Debris Removal (ADR) missions targeting tumbling derelict
satellites such as ESA's ENVISAT. This work presents a complete pipeline
integrating advanced computer vision techniques with adaptive nonlinear
filtering to address this challenge. A Convolutional Neural Network (CNN),
enhanced with image preprocessing, detects structural markers (corners) from
chaser imagery, whose 2D coordinates are converted to 3D measurements using
camera modeling. These measurements are fused within an Unscented Kalman Filter
(UKF) framework, selected for its ability to handle nonlinear relative
dynamics, to estimate the full relative pose. Key contributions include the
integrated system architecture and a dual adaptive strategy within the UKF:
dynamic tuning of the measurement noise covariance compensates for varying CNN
measurement uncertainty, while adaptive tuning of the process noise covariance,
utilizing measurement residual analysis, accounts for unmodeled dynamics or
maneuvers online. This dual adaptation enhances robustness against both
measurement imperfections and dynamic model uncertainties. The performance of
the proposed adaptive integrated system is evaluated through high-fidelity
simulations using a realistic ENVISAT model, comparing estimates against ground
truth under various conditions, including measurement outages. This
comprehensive approach offers an enhanced solution for robust onboard relative
navigation, significantly advancing the capabilities required for safe
proximity operations during ADR missions.

</details>


### [12] [GFM-Planner: Perception-Aware Trajectory Planning with Geometric Feature Metric](https://arxiv.org/abs/2507.16233)
*Yue Lin,Xiaoxuan Zhang,Yang Liu,Dong Wang,Huchuan Lu*

Main category: cs.RO

TL;DR: 本文提出了GFM-Planner，一个基于几何特征度量的感知感知轨迹规划框架，通过引导机器人避开退化区域来提高LiDAR定位精度


<details>
  <summary>Details</summary>
Motivation: 自主机器人需要依赖特征丰富的环境进行准确定位，但现有方法缺乏感知感知的轨迹规划能力，无法主动避开LiDAR定位性能退化的区域

Method: 1) 从基础LiDAR定位问题推导出几何特征度量(GFM)；2) 设计基于2D网格的度量编码地图(MEM)高效存储环境中的GFM值；3) 提出常数时间解码算法从MEM中检索任意姿态的GFM值；4) 开发感知感知轨迹规划算法，通过引导机器人选择通过特征丰富区域的轨迹来提高LiDAR定位能力

Result: 仿真和真实世界实验都证明该方法能够使机器人主动选择显著提高LiDAR定位精度的轨迹

Conclusion: GFM-Planner框架成功实现了感知感知的轨迹规划，通过避开几何特征退化区域，有效提升了机器人LiDAR定位系统的准确性和鲁棒性

Abstract: Like humans who rely on landmarks for orientation, autonomous robots depend
on feature-rich environments for accurate localization. In this paper, we
propose the GFM-Planner, a perception-aware trajectory planning framework based
on the geometric feature metric, which enhances LiDAR localization accuracy by
guiding the robot to avoid degraded areas. First, we derive the Geometric
Feature Metric (GFM) from the fundamental LiDAR localization problem. Next, we
design a 2D grid-based Metric Encoding Map (MEM) to efficiently store GFM
values across the environment. A constant-time decoding algorithm is further
proposed to retrieve GFM values for arbitrary poses from the MEM. Finally, we
develop a perception-aware trajectory planning algorithm that improves LiDAR
localization capabilities by guiding the robot in selecting trajectories
through feature-rich areas. Both simulation and real-world experiments
demonstrate that our approach enables the robot to actively select trajectories
that significantly enhance LiDAR localization accuracy.

</details>


### [13] [Trajectory Planning of a Curtain Wall Installation Robot Based on Biomimetic Mechanisms](https://arxiv.org/abs/2507.16305)
*Xiao Liu,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 该研究提出了一种仿生轨迹规划框架，通过模拟人类上肢举重动作的力学机制来降低建筑机器人的能耗，在幕墙安装任务中实现了48.4%的能耗降低。


<details>
  <summary>Details</summary>
Motivation: 随着机器人市场快速发展，能耗问题成为关键挑战，特别是限制了建筑机器人的应用。为解决这一问题，研究从人类上肢举重动作的力学机制中汲取灵感。

Method: 通过收集哑铃弯举过程中的运动轨迹和肌电图(EMG)信号，构建融合人类发力模式和能耗模式的仿人轨迹规划。利用粒子群优化(PSO)算法，基于类人运动特征实现机械臂轨迹规划的动态负载分配。

Result: 仿真结果显示，通过动能和势能之间的智能转换，该方法实现了48.4%的能耗降低。在幕墙安装任务的实际应用中验证了轨迹规划方法的正确性和优越性。

Conclusion: 该仿生运动特征方法为幕墙安装机器人在实际搬运任务中的能耗优化提供了新的见解和理论支持，证明了生物启发式轨迹规划在建筑机器人节能方面的有效性。

Abstract: As the robotics market rapidly evolves, energy consumption has become a
critical issue, particularly restricting the application of construction
robots. To tackle this challenge, our study innovatively draws inspiration from
the mechanics of human upper limb movements during weight lifting, proposing a
bio-inspired trajectory planning framework that incorporates human energy
conversion principles. By collecting motion trajectories and electromyography
(EMG) signals during dumbbell curls, we construct an anthropomorphic trajectory
planning that integrates human force exertion patterns and energy consumption
patterns. Utilizing the Particle Swarm Optimization (PSO) algorithm, we achieve
dynamic load distribution for robotic arm trajectory planning based on
human-like movement features. In practical application, these bio-inspired
movement characteristics are applied to curtain wall installation tasks,
validating the correctness and superiority of our trajectory planning method.
Simulation results demonstrate a 48.4% reduction in energy consumption through
intelligent conversion between kinetic and potential energy. This approach
provides new insights and theoretical support for optimizing energy use in
curtain wall installation robots during actual handling tasks.

</details>


### [14] [Design and Dimensional Optimization of Legged Structures for Construction Robots](https://arxiv.org/abs/2507.16328)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文提出了一种面向建筑场景的仿生腿足机器人腿部构型设计与优化方法，通过运动学建模、工作空间分析和虚拟样机仿真，建立了腿部运动性能的多维定量评价框架，为腿足建筑机器人在复杂地形中实现自主移动提供了结构设计基础。


<details>
  <summary>Details</summary>
Motivation: 面对复杂非结构化的建筑环境，轮式和履带式机器人在地形适应性和灵活性方面存在显著局限性，难以满足自主作业要求。受自然界蚂蚁启发，需要开发专门针对建筑场景的腿足机器人腿部构型设计方法，以提升建筑机器人的自主移动能力。

Method: 基于运动学建模和多维工作空间分析，引入"改进工作空间"概念，采用图形化方法优化摆动相腿部尺寸；基于速度雅可比矩阵引入"平均可操作性"概念，通过数值求解获得使可操作性最大化的腿段比例；在ADAMS中进行虚拟样机仿真，探索机器人本体最优灵活性与腿段比例的关系。

Result: 获得了具有最佳综合运动性能的腿段比例配置，建立了首个面向建筑环境的腿部运动性能多维定量评价框架，为腿足建筑机器人的结构设计提供了科学依据。

Conclusion: 本研究成功开发了面向建筑场景的腿足机器人腿部构型设计与优化方法，通过多维定量评价框架确定了最优腿段比例，为腿足建筑机器人在复杂地形中实现自主移动奠定了结构设计基础，克服了传统轮式和履带式机器人在建筑环境中的适应性局限。

Abstract: Faced with complex and unstructured construction environments, wheeled and
tracked robots exhibit significant limitations in terrain adaptability and
flexibility, making it difficult to meet the requirements of autonomous
operation. Inspired by ants in nature, this paper proposes a leg configuration
design and optimization method tailored for construction scenarios, aiming to
enhance the autonomous mobility of construction robots. This paper analyzes the
full operational motion performance of the leg during both swing and stance
phases. First, based on kinematic modeling and multi-dimensional workspace
analysis, the concept of an "improved workspace" is introduced, and graphical
methods are used to optimize the leg dimensions during the swing phase.
Furthermore, a new concept of "average manipulability" is introduced based on
the velocity Jacobian matrix, and numerical solutions are applied to obtain the
leg segment ratio that maximizes manipulability. To overcome the difficulties
associated with traditional analytical methods, virtual prototype simulations
are conducted in ADAMS to explore the relationship between the robot body's
optimal flexibility and leg segment proportions. In summary, the leg segment
proportions with the best comprehensive motion performance are obtained. This
study presents the first multi-dimensional quantitative evaluation framework
for leg motion performance tailored for construction environments, providing a
structural design foundation for legged construction robots to achieve
autonomous mobility in complex terrains.

</details>


### [15] [Topology Optimization of Leg Structures for Construction Robots Based on Variable Density Method](https://arxiv.org/abs/2507.16335)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本研究针对复杂地形建筑环境中机器人腿部结构进行拓扑优化，采用SIMP变密度方法对股骨部分进行优化设计，实现了19.45%的股骨质量减少和7.92%的整体腿部质量减少，在保证结构性能的同时实现了轻量化设计目标。


<details>
  <summary>Details</summary>
Motivation: 在复杂地形建筑环境中，机器人需要同时具备高负载能力和移动灵活性。作为关键承载部件，机器人腿部结构的优化具有特别重要的意义，因此需要对建筑机器人的腿部结构进行优化研究。

Method: 提出了基于SIMP（固体各向同性微结构惩罚）变密度方法的拓扑优化策略以及结构重新设计方法。首先进行静态和模态分析评估初始设计的合理性，然后对占腿部重量最大比例的股骨部分应用基于SIMP的变密度拓扑优化，通过迭代计算对股骨进行二次结构重构，最后使用ANSYS有限元分析验证设计性能。

Result: 优化后股骨质量减少19.45%，整体腿部质量减少7.92%，达到了轻量化设计目标。静态和模态分析结果表明，优化后的腿部仍然满足结构性能要求，验证了轻量化设计的可行性。

Conclusion: 本研究为轻量化建筑机器人设计提供了强有力的理论和技术支持，为机器人在复杂建筑环境中的高效运行奠定了基础。拓扑优化方法成功实现了在保证结构性能的前提下的显著减重效果。

Abstract: In complex terrain construction environments, there are high demands for
robots to achieve both high payload capacity and mobility flexibility. As the
key load-bearing component, the optimization of robotic leg structures is of
particular importance. Therefore, this study focuses on the optimization of leg
structures for construction robots, proposing a topology optimization strategy
based on the SIMP (Solid Isotropic Microstructures with Penalization) variable
density method along with a structural re-design approach. The design
performance is comprehensively validated through finite element analysis using
ANSYS. First, static and modal analyses are conducted to evaluate the
rationality of the initial design. Then, topology optimization using the
SIMP-based variable density method is applied to the femur section, which
accounts for the largest proportion of the leg's weight. Based on iterative
calculations, the femur undergoes secondary structural reconstruction. After
optimization, the mass of the femur is reduced by 19.45\%, and the overall leg
mass decreases by 7.92\%, achieving the goal of lightweight design. Finally,
static and modal analyses are conducted on the reconstructed leg. The results
demonstrate that the optimized leg still meets structural performance
requirements, validating the feasibility of lightweight design. This research
provides robust theoretical and technical support for lightweight construction
robot design and lays a foundation for their efficient operation in complex
construction environments.

</details>


### [16] [Humanoid Robot Whole-body Geometric Calibration with Embedded Sensors and a Single Plane](https://arxiv.org/abs/2507.16369)
*Thanh D V Nguyen,Vincent Bonnet,Pierre Fernbach,David Daney,Florent Lamiraux*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的人形机器人全身几何标定方法，使用单平面、嵌入式力传感器和导纳控制器，并开发了IROC算法来选择最优标定姿态，在TALOS人形机器人上验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的人形机器人全身几何标定方法耗时且实验负担重，在人形机器人领域常被忽视，但对准确控制和仿真具有重要意义。需要开发一种实用的、无需人工干预的标定方法。

Method: 提出了一种利用单平面、嵌入式力传感器和导纳控制器的新型标定方法。开发了IROC（信息排序算法）来选择最优标定姿态，该算法通过构建归一化加权信息矩阵来确定最少数量的最优姿态。

Result: 在TALOS人形机器人上进行实验验证，仅使用31个最优姿态（机器人抓手与桌面3点接触）就完成了全身运动学链标定。交叉验证实验显示，相比制造商模型，平均均方根误差降低了2.3倍。

Conclusion: 提出的单平面标定方法和IROC算法能够有效地完成人形机器人全身运动学标定，显著提高了标定精度，为人形机器人的准确控制和仿真提供了实用的解决方案。

Abstract: Whole-body geometric calibration of humanoid robots using classical robot
calibration methods is a timeconsuming and experimentally burdensome task.
However, despite its significance for accurate control and simulation, it is
often overlooked in the humanoid robotics community. To address this issue, we
propose a novel practical method that utilizes a single plane, embedded force
sensors, and an admittance controller to calibrate the whole-body kinematics of
humanoids without requiring manual intervention. Given the complexity of
humanoid robots, it is crucial to generate and determine a minimal set of
optimal calibration postures. To do so, we propose a new algorithm called IROC
(Information Ranking algorithm for selecting Optimal Calibration postures).
IROC requires a pool of feasible candidate postures to build a normalized
weighted information matrix for each posture. Then, contrary to other
algorithms from the literature, IROC will determine the minimal number of
optimal postures that are to be played onto a robot for its calibration. Both
IROC and the single-plane calibration method were experimentally validated on a
TALOS humanoid robot. The total whole-body kinematics chain was calibrated
using solely 31 optimal postures with 3-point contacts on a table by the robot
gripper. In a cross-validation experiment, the average root-mean-square (RMS)
error was reduced by a factor of 2.3 compared to the manufacturer's model.

</details>


### [17] [Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance](https://arxiv.org/abs/2507.16382)
*Chenhao Yao,Zike Yuan,Xiaoxu Liu,Chi Zhu*

Main category: cs.RO

TL;DR: 本文提出了一个基于大语言模型的新框架，用于解决多智能体强化学习中编队控制与避障问题的奖励函数设计难题，通过动态调整奖励函数实现更高效的学习收敛。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习中，编队控制与避障（FCCA）任务面临的主要挑战是设计有效的奖励函数，使策略网络能够快速收敛到最优解。传统方法在处理这一复杂目标时存在困难。

Method: 提出一个基于大语言模型（LLMs）的新框架，通过让LLMs理解任务优先级和各智能体可观察信息，生成能够基于评估结果进行在线动态调整的奖励函数，使用更先进的评估指标而非奖励本身来指导调整。

Result: 实验结果表明该方法能够使多智能体系统在动态环境中同时实现编队控制和障碍物避障，显著提高效率，用更少的迭代次数达到更优的性能水平。仿真和真实世界环境的实验都验证了方法的有效性。

Conclusion: 所提出的基于大语言模型的动态奖励函数调整框架成功解决了多智能体强化学习中编队控制与避障问题的奖励函数设计挑战，在仿真和真实环境中都展现出良好的实用性和有效性，为多智能体系统的协同控制提供了新的解决方案。

Abstract: Multi-Agent Systems (MAS) excel at accomplishing complex objectives through
the collaborative efforts of individual agents. Among the methodologies
employed in MAS, Multi-Agent Reinforcement Learning (MARL) stands out as one of
the most efficacious algorithms. However, when confronted with the complex
objective of Formation Control with Collision Avoidance (FCCA): designing an
effective reward function that facilitates swift convergence of the policy
network to an optimal solution. In this paper, we introduce a novel framework
that aims to overcome this challenge. By giving large language models (LLMs) on
the prioritization of tasks and the observable information available to each
agent, our framework generates reward functions that can be dynamically
adjusted online based on evaluation outcomes by employing more advanced
evaluation metrics rather than the rewards themselves. This mechanism enables
the MAS to simultaneously achieve formation control and obstacle avoidance in
dynamic environments with enhanced efficiency, requiring fewer iterations to
reach superior performance levels. Our empirical studies, conducted in both
simulation and real-world settings, validate the practicality and effectiveness
of our proposed approach.

</details>


### [18] [AI or Human? Understanding Perceptions of Embodied Robots with LLMs](https://arxiv.org/abs/2507.16398)
*Lavinia Hriscu,Alberto Sanfeliu,Anais Garrell*

Main category: cs.RO

TL;DR: 研究通过在机器人平台上进行图灵测试，探索了人们对具身机器人智能感知的问题。34名参与者需要区分AI操控和人类操控的机器人，结果显示参与者无法可靠地区分两者。


<details>
  <summary>Details</summary>
Motivation: 图灵测试作为评估系统智能的手段，其在人机交互领域的相关性和应用仍未得到充分探索。需要研究人们如何感知具身机器人的智能水平。

Method: 在机器人平台上进行图灵测试，招募34名参与者，让他们在两个交互任务（信息检索和包裹交接）中区分AI操控和人类操控的机器人。这些任务评估机器人在静态和动态条件下的感知和导航能力。

Result: 参与者无法可靠地区分AI操控和人类操控的机器人，区分准确率仅接近随机水平。通过分析参与者的反应，识别出影响人们对人工智能与人类智能感知的关键因素。

Conclusion: 研究为未来交互机器人的设计提供了见解，并为AI驱动系统中的智能评估持续讨论做出了贡献。结果表明当前的具身机器人在某些交互任务中已经能够达到接近人类操控的表现水平。

Abstract: The pursuit of artificial intelligence has long been associated to the the
challenge of effectively measuring intelligence. Even if the Turing Test was
introduced as a means of assessing a system intelligence, its relevance and
application within the field of human-robot interaction remain largely
underexplored. This study investigates the perception of intelligence in
embodied robots by performing a Turing Test within a robotic platform. A total
of 34 participants were tasked with distinguishing between AI- and
human-operated robots while engaging in two interactive tasks: an information
retrieval and a package handover. These tasks assessed the robot perception and
navigation abilities under both static and dynamic conditions. Results indicate
that participants were unable to reliably differentiate between AI- and
human-controlled robots beyond chance levels. Furthermore, analysis of
participant responses reveals key factors influencing the perception of
artificial versus human intelligence in embodied robotic systems. These
findings provide insights into the design of future interactive robots and
contribute to the ongoing discourse on intelligence assessment in AI-driven
systems.

</details>


### [19] [Distributed Oscillatory Guidance for Formation Flight of Fixed-Wing Drones](https://arxiv.org/abs/2507.16458)
*Yang Xu,Jesús Bautista,José Hinojosa,Héctor García de Marina*

Main category: cs.RO

TL;DR: 本文提出了一种无需调节飞行速度的固定翼无人机编队飞行算法，通过在引导向量场上叠加振荡行为来控制平均速度，实现无人机间的协调


<details>
  <summary>Details</summary>
Motivation: 固定翼无人机编队飞行中，由于飞行速度受限且主要设计为在标准空速下飞行，通过速度驱动实现协调控制存在困难

Method: 引导所有无人机沿特定路径飞行（如平行直线），在引导向量场上叠加振荡行为来控制沿路径的平均速度；每架无人机通过与邻近代理通信，在无向连通图中分布式调整振荡幅度；引入基于非负非对称饱和函数的新型一致性算法

Result: 算法通过严格的理论分析得到验证，并通过数值仿真和真实世界编队飞行实验进行了验证

Conclusion: 提出的算法成功实现了无需速度调节的固定翼无人机编队飞行，通过振荡幅度的分布式调整和新型一致性算法保证了编队的稳定性和有效性

Abstract: The autonomous formation flight of fixed-wing drones is hard when the
coordination requires the actuation over their speeds since they are critically
bounded and aircraft are mostly designed to fly at a nominal airspeed. This
paper proposes an algorithm to achieve formation flights of fixed-wing drones
without requiring any actuation over their speed. In particular, we guide all
the drones to travel over specific paths, e.g., parallel straight lines, and we
superpose an oscillatory behavior onto the guiding vector field that drives the
drones to the paths. This oscillation enables control over the average velocity
along the path, thereby facilitating inter-drone coordination. Each drone
adjusts its oscillation amplitude distributively in a closed-loop manner by
communicating with neighboring agents in an undirected and connected graph. A
novel consensus algorithm is introduced, leveraging a non-negative, asymmetric
saturation function. This unconventional saturation is justified since negative
amplitudes do not make drones travel backward or have a negative velocity along
the path. Rigorous theoretical analysis of the algorithm is complemented by
validation through numerical simulations and a real-world formation flight.

</details>


### [20] [Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots](https://arxiv.org/abs/2507.16480)
*Sabrina Livanec,Laura Londoño,Michael Gorki,Adrian Röfer,Abhinav Valada,Andrea Kiesel*

Main category: cs.RO

TL;DR: 研究通过在线实验评估了112名参与者对人机协作机器人行为的看法，发现反社会机器人行为评价最低，与老年人协作时评价更敏感，物体交接场景评价更积极，强调了亲社会设计的重要性


<details>
  <summary>Details</summary>
Motivation: 目前缺乏关于参与者如何评估不同机器人行为与多样化人类需求结合的研究，特别是在与残疾人或老年人等受保护群体互动时，需要探索负责任和包容性的辅助机器人设计

Method: 采用在线研究方法，112名参与者（实验组和对照组）评估了28种人机协作类型中的7个视频。实验组在评分前先完成认知-情感映射(CAM)练习，以支持有意义的反思

Result: 虽然CAM反思对总体评分没有显著影响，但在某些机器人行为和人类条件组合下产生了更明显的评估。反社会机器人行为评价最低，与老年人的协作引发更敏感的评价，涉及物体交接的场景比没有交接的场景评价更积极

Conclusion: 人类特征和互动范式都会影响协作机器人的可接受性感知，突出了亲社会设计的重要性。反思性方法如CAM有潜力引出细致的反馈，支持开发以用户为中心、面向不同人群的社会责任机器人系统

Abstract: The development of assistive robots for social collaboration raises critical
questions about responsible and inclusive design, especially when interacting
with individuals from protected groups such as those with disabilities or
advanced age. Currently, research is scarce on how participants assess varying
robot behaviors in combination with diverse human needs, likely since
participants have limited real-world experience with advanced domestic robots.
In the current study, we aim to address this gap while using methods that
enable participants to assess robot behavior, as well as methods that support
meaningful reflection despite limited experience. In an online study, 112
participants (from both experimental and control groups) evaluated 7 videos
from a total of 28 variations of human-robot collaboration types. The
experimental group first completed a cognitive-affective mapping (CAM) exercise
on human-robot collaboration before providing their ratings. Although CAM
reflection did not significantly affect overall ratings, it led to more
pronounced assessments for certain combinations of robot behavior and human
condition. Most importantly, the type of human-robot collaboration influences
the assessment. Antisocial robot behavior was consistently rated as the lowest,
while collaboration with aged individuals elicited more sensitive evaluations.
Scenarios involving object handovers were viewed more positively than those
without them. These findings suggest that both human characteristics and
interaction paradigms influence the perceived acceptability of collaborative
robots, underscoring the importance of prosocial design. They also highlight
the potential of reflective methods, such as CAM, to elicit nuanced feedback,
supporting the development of user-centered and socially responsible robotic
systems tailored to diverse populations.

</details>


### [21] [Guided Reinforcement Learning for Omnidirectional 3D Jumping in Quadruped Robots](https://arxiv.org/abs/2507.16481)
*Riccardo Bussola,Michele Focchi,Giulio Turrisi,Claudio Semini,Luigi Palopoli*

Main category: cs.RO

TL;DR: 本文提出了一种新颖的引导式强化学习方法，结合贝塞尔曲线和匀加速直线运动模型，用于四足机器人的高效可解释跳跃控制，克服了传统优化方法耗时和端到端强化学习样本复杂度高的问题。


<details>
  <summary>Details</summary>
Motivation: 四足机器人跳跃控制面临重大挑战：传统优化方法耗时且需要大量机器人和地形参数知识，在真实场景中鲁棒性差；传统端到端强化学习方法样本复杂度高，需要大量仿真训练，且最终运动的可预测性差，难以保证安全性。

Method: 提出了一种新颖的引导式强化学习方法，通过结合贝塞尔曲线和匀加速直线运动(UARM)模型来利用物理直觉，实现高效且可解释的跳跃控制。该方法将物理知识融入强化学习框架中。

Result: 大量的仿真和实验结果清楚地证明了该方法相比现有替代方案的优势，在效率和可解释性方面都有显著提升。

Conclusion: 所提出的引导式强化学习方法成功解决了四足机器人跳跃控制中的关键问题，通过融合物理直觉实现了更高效、更安全、更可解释的跳跃运动控制，为四足机器人在复杂操作场景中的应用提供了有效解决方案。

Abstract: Jumping poses a significant challenge for quadruped robots, despite being
crucial for many operational scenarios. While optimisation methods exist for
controlling such motions, they are often time-consuming and demand extensive
knowledge of robot and terrain parameters, making them less robust in
real-world scenarios. Reinforcement learning (RL) is emerging as a viable
alternative, yet conventional end-to-end approaches lack efficiency in terms of
sample complexity, requiring extensive training in simulations, and
predictability of the final motion, which makes it difficult to certify the
safety of the final motion. To overcome these limitations, this paper
introduces a novel guided reinforcement learning approach that leverages
physical intuition for efficient and explainable jumping, by combining B\'ezier
curves with a Uniformly Accelerated Rectilinear Motion (UARM) model. Extensive
simulation and experimental results clearly demonstrate the advantages of our
approach over existing alternatives.

</details>


### [22] [A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System](https://arxiv.org/abs/2507.16621)
*Lorenzo Gentilini,Pierpaolo Serio,Valentina Donzella,Lorenzo Pollini*

Main category: cs.RO

TL;DR: 提出了一种基于目标的外参标定系统，用于多激光雷达和多相机传感器套件的交叉标定，使用定制的ChArUco板和非线性优化方法，在仓库环境中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中外参标定的准确性对感知管道至关重要，任何误差都会影响车辆安全。现代传感器系统收集不同类型的环境数据，使数据对齐变得更加困难，因此需要一种有效的多传感器标定方法。

Method: 提出了一种基于目标的外参标定系统，专门针对多激光雷达和多相机传感器套件设计。使用定制的ChArUco板作为标定目标，结合量身定制的非线性优化方法，在有限先验知识的情况下实现激光雷达和相机之间的交叉标定。

Result: 在仓库环境中收集的真实世界数据上测试了该系统，结果证明了所提出方法的有效性，突出了针对各种类型传感器的独特管道的可行性。

Conclusion: 该研究成功开发了一种多传感器外参标定系统，能够有效处理多激光雷达和多相机的标定问题，为自动驾驶系统中的传感器融合提供了可靠的解决方案。

Abstract: Extrinsic Calibration represents the cornerstone of autonomous driving. Its
accuracy plays a crucial role in the perception pipeline, as any errors can
have implications for the safety of the vehicle. Modern sensor systems collect
different types of data from the environment, making it harder to align the
data. To this end, we propose a target-based extrinsic calibration system
tailored for a multi-LiDAR and multi-camera sensor suite. This system enables
cross-calibration between LiDARs and cameras with limited prior knowledge using
a custom ChArUco board and a tailored nonlinear optimization method. We test
the system with real-world data gathered in a warehouse. Results demonstrated
the effectiveness of the proposed method, highlighting the feasibility of a
unique pipeline tailored for various types of sensors.

</details>


### [23] [Morpheus: A Neural-driven Animatronic Face with Hybrid Actuation and Diverse Emotion Control](https://arxiv.org/abs/2507.16645)
*Zongzheng Zhang,Jiawen Yang,Ziqiao Peng,Meng Yang,Jianzhu Ma,Lin Cheng,Huazhe Xu,Hang Zhao,Hao Zhao*

Main category: cs.RO

TL;DR: 该论文提出了一种混合驱动的动画机器人面部系统，结合刚性和腱驱动机制，通过自建模网络实现从语音输入到情感面部表情的自动控制


<details>
  <summary>Details</summary>
Motivation: 现有的动画机器人面部在表达情感方面存在局限性：刚性驱动机制控制精确但难以在有限空间内设计，腱驱动机制节省空间但控制困难，且缺乏能够从语音输入生成特定情感表情的自动化系统

Method: 提出混合驱动方法：眼部和嘴部采用刚性机制实现精确控制，鼻部和脸颊采用绳索驱动实现微表情；开发自建模网络将电机动作映射到面部关键点，通过梯度反向传播建立混合形状系数与电机控制信号的关系；训练神经网络将语音输入映射到相应的混合形状控制

Result: 系统能够从任意给定句子生成不同的情感表情（快乐、恐惧、厌恶、愤怒等），每种情感都具有细致入微的特定控制信号，这是之前系统未能实现的功能

Conclusion: 该混合驱动方法成功结合了两种驱动机制的优势，构建了紧凑且多功能的硬件平台，配合自建模网络实现了从语音到情感面部表情的自动化控制，为动画机器人面部表情技术提供了新的解决方案

Abstract: Previous animatronic faces struggle to express emotions effectively due to
hardware and software limitations. On the hardware side, earlier approaches
either use rigid-driven mechanisms, which provide precise control but are
difficult to design within constrained spaces, or tendon-driven mechanisms,
which are more space-efficient but challenging to control. In contrast, we
propose a hybrid actuation approach that combines the best of both worlds. The
eyes and mouth-key areas for emotional expression-are controlled using rigid
mechanisms for precise movement, while the nose and cheek, which convey subtle
facial microexpressions, are driven by strings. This design allows us to build
a compact yet versatile hardware platform capable of expressing a wide range of
emotions. On the algorithmic side, our method introduces a self-modeling
network that maps motor actions to facial landmarks, allowing us to
automatically establish the relationship between blendshape coefficients for
different facial expressions and the corresponding motor control signals
through gradient backpropagation. We then train a neural network to map speech
input to corresponding blendshape controls. With our method, we can generate
distinct emotional expressions such as happiness, fear, disgust, and anger,
from any given sentence, each with nuanced, emotion-specific control signals-a
feature that has not been demonstrated in earlier systems. We release the
hardware design and code at https://github.com/ZZongzheng0918/Morpheus-Hardware
and https://github.com/ZZongzheng0918/Morpheus-Software.

</details>


### [24] [Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory](https://arxiv.org/abs/2507.16713)
*Guowei Lan,Kaixian Qu,René Zurbrügg,Changan Chen,Christopher E. Mower,Haitham Bou-Ammar,Marco Hutter*

Main category: cs.RO

TL;DR: ExpTeach是一个通过构建自生成的真实世界经验记忆来将视觉语言模型(VLM)应用于物理机器人的框架，通过反思学习和长期记忆检索显著提升了机器人任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型虽然在机器人自主规划中被广泛采用，但将原本在互联网数据上训练的VLM应用到多样化的真实世界机器人仍然是一个挑战，需要有效的接地方法。

Method: ExpTeach框架让VLM在闭环中自主规划动作、验证结果、反思失败并调整机器人行为。自生成的经验被总结为长期记忆，通过检索增强生成(RAG)指导未来任务。此外还包含按需图像标注模块来增强VLM的空间理解能力。

Result: 反思机制将四个挑战性机器人任务的成功率从36%提升到84%，并观察到智能物体交互和创造性工具使用的涌现。在12个真实世界场景(包括8个未见过的场景)的广泛测试中，长期记忆接地将单次试验成功率从22%提升到80%。

Conclusion: ExpTeach有效解决了VLM在真实世界机器人应用中的接地问题，通过自生成经验记忆和反思学习机制显著提升了机器人任务执行的成功率和泛化能力。

Abstract: Vision-language models (VLMs) have been widely adopted in robotics to enable
autonomous planning. However, grounding VLMs, originally trained on internet
data, to diverse real-world robots remains a challenge. This paper presents
ExpTeach, a framework that grounds VLMs to physical robots by building a
self-generated memory of real-world experiences. In ExpTeach, the VLM
autonomously plans actions, verifies outcomes, reflects on failures, and adapts
robot behaviors in a closed loop. The self-generated experiences during this
process are then summarized into a long-term memory, enabling retrieval of
learned knowledge to guide future tasks via retrieval-augmented generation
(RAG). Additionally, ExpTeach enhances the spatial understanding of VLMs with
an on-demand image annotation module. In experiments, we show that reflection
improves success rates from 36% to 84% on four challenging robotic tasks and
observe the emergence of intelligent object interactions, including creative
tool use. Across extensive tests on 12 real-world scenarios (including eight
unseen ones), we find that grounding with long-term memory boosts single-trial
success rates from 22% to 80%, demonstrating the effectiveness and
generalizability of ExpTeach.

</details>
