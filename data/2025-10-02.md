<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 32]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [RoboPilot: Generalizable Dynamic Robotic Manipulation with Dual-thinking Modes](https://arxiv.org/abs/2510.00154)
*Xinyi Liu,Mohammadreza Fani Sani,Zewei Zhou,Julius Wirbel,Bahram Zarrin,Roberto Galeazzi*

Main category: cs.RO

TL;DR: RoboPilot是一个用于机器人操作的双思维闭环框架，通过结合快速和慢速思维模式，在动态环境中实现自适应推理和任务执行。


<details>
  <summary>Details</summary>
Motivation: 当前自主机器人系统在执行复杂或长期任务时存在局限性，主要采用开环范式，缺乏推理和反馈机制，导致对环境变化的鲁棒性差和错误累积严重。

Method: RoboPilot利用原始动作进行结构化任务规划和灵活动作生成，引入反馈机制以应对动态变化和执行错误，通过思维链推理增强高层任务规划并指导低层动作生成，动态切换快速和慢速思维模式以平衡效率和准确性。

Result: 实验表明RoboPilot在任务成功率上比最先进基线方法高出25.9%，在工业机器人的真实世界部署进一步证明了其在现实环境中的鲁棒性。

Conclusion: RoboPilot框架通过闭环反馈和双思维模式有效解决了复杂机器人操作任务的鲁棒性问题，在动态环境中表现出优越性能。

Abstract: Despite rapid progress in autonomous robotics, executing complex or
long-horizon tasks remains a fundamental challenge. Most current approaches
follow an open-loop paradigm with limited reasoning and no feedback, resulting
in poor robustness to environmental changes and severe error accumulation. We
present RoboPilot, a dual-thinking closed-loop framework for robotic
manipulation that supports adaptive reasoning for complex tasks in real-world
dynamic environments. RoboPilot leverages primitive actions for structured task
planning and flexible action generation, while introducing feedback to enable
replanning from dynamic changes and execution errors. Chain-of-Thought
reasoning further enhances high-level task planning and guides low-level action
generation. The system dynamically switches between fast and slow thinking to
balance efficiency and accuracy. To systematically evaluate the robustness of
RoboPilot in diverse robot manipulation scenarios, we introduce
RoboPilot-Bench, a benchmark spanning 21 tasks across 10 categories, including
infeasible-task recognition and failure recovery. Experiments show that
RoboPilot outperforms state-of-the-art baselines by 25.9\% in task success
rate, and the real-world deployment on an industrial robot further demonstrates
its robustness in real-world settings.

</details>


### [2] [A Systematic Study of Large Language Models for Task and Motion Planning With PDDLStream](https://arxiv.org/abs/2510.00182)
*Jorge Mendez-Mendez*

Main category: cs.RO

TL;DR: 本文研究了在任务与运动规划(TAMP)系统中集成大语言模型(LLMs)的16种算法，发现基于Gemini的规划器在成功率和规划时间上都不如传统工程方法，几何细节会增加任务规划错误，且非推理型LLM变体表现优于推理型变体。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在复杂机器人问题中的规划能力范围，以及如何将LLMs的语义知识与TAMP的形式推理能力有效整合，解决集成方法选择过多的问题。

Method: 开发了16种使用Gemini 2.5 Flash替代关键TAMP组件的算法，在4,950个问题和三个领域中进行零样本实验，比较不同集成方法的效果。

Result: 基于Gemini的规划器相比工程化对应方法成功率更低、规划时间更长；提供几何细节会增加任务规划错误；非推理型LLM变体在多数情况下优于推理型变体，因为TAMP系统可以指导LLM纠正错误。

Conclusion: 当前LLMs在TAMP系统中的集成效果有限，需要更精细的设计来充分利用LLMs的语义能力，同时避免引入额外的规划错误和延迟。

Abstract: Using large language models (LLMs) to solve complex robotics problems
requires understanding their planning capabilities. Yet while we know that LLMs
can plan on some problems, the extent to which these planning capabilities
cover the space of robotics tasks is unclear. One promising direction is to
integrate the semantic knowledge of LLMs with the formal reasoning of task and
motion planning (TAMP). However, the myriad of choices for how to integrate
LLMs within TAMP complicates the design of such systems. We develop 16
algorithms that use Gemini 2.5 Flash to substitute key TAMP components. Our
zero-shot experiments across 4,950 problems and three domains reveal that the
Gemini-based planners exhibit lower success rates and higher planning times
than their engineered counterparts. We show that providing geometric details
increases the number of task-planning errors compared to pure PDDL
descriptions, and that (faster) non-reasoning LLM variants outperform (slower)
reasoning variants in most cases, since the TAMP system can direct the LLM to
correct its mistakes.

</details>


### [3] [A Novel Robust Control Method Combining DNN-Based NMPC Approximation and PI Control: Application to Exoskeleton Squat Movements](https://arxiv.org/abs/2510.00188)
*Alireza Aliyari,Gholamreza Vossoughi*

Main category: cs.RO

TL;DR: 提出了一种混合NMPC-DNN-PI控制器，将神经网络近似NMPC与PI控制器结合，解决了传统NMPC计算量大和NMPC-DNN在未知条件下鲁棒性差的问题。


<details>
  <summary>Details</summary>
Motivation: 传统NMPC计算负载重，难以在机器人系统中应用；而基于深度神经网络的NMPC近似方法在面对意外干扰或与训练数据不同的操作条件时缺乏鲁棒性。

Method: 开发了混合NMPC-DNN-PI控制器，将NMPC-DNN输出与PI控制器结合，应用于具有三个主动关节（踝、膝、髋）的外骨骼机器人下蹲运动控制。

Result: 在DNN未见条件下，混合控制器的跟踪误差显著低于纯NMPC-DNN；使用外骨骼后人体关节扭矩大幅降低（踝关节30.9%、膝关节41.8%、髋关节29.7%）；计算成本比NMPC降低99.93%。

Conclusion: 混合NMPC-DNN-PI控制器在保持计算效率的同时显著提高了鲁棒性，有效解决了外骨骼机器人的非线性控制问题。

Abstract: Nonlinear Model Predictive Control (NMPC) is a precise controller, but its
heavy computational load often prevents application in robotic systems. Some
studies have attempted to approximate NMPC using deep neural networks
(NMPC-DNN). However, in the presence of unexpected disturbances or when
operating conditions differ from training data, this approach lacks robustness,
leading to large tracking errors. To address this issue, for the first time,
the NMPC-DNN output is combined with a PI controller (Hybrid NMPC-DNN-PI). The
proposed controller is validated by applying it to an exoskeleton robot during
squat movement, which has a complex dynamic model and has received limited
attention regarding robust nonlinear control design. A human-robot dynamic
model with three active joints (ankle, knee, hip) is developed, and more than
5.3 million training samples are used to train the DNN. The results show that,
under unseen conditions for the DNN, the tracking error in Hybrid NMPC-DNN-PI
is significantly lower compared to NMPC-DNN. Moreover, human joint torques are
greatly reduced with the use of the exoskeleton, with RMS values for the
studied case reduced by 30.9%, 41.8%, and 29.7% at the ankle, knee, and hip,
respectively. In addition, the computational cost of Hybrid NMPC-DNN-PI is
99.93% lower than that of NMPC.

</details>


### [4] [TGPO: Temporal Grounded Policy Optimization for Signal Temporal Logic Tasks](https://arxiv.org/abs/2510.00225)
*Yue Meng,Fei Chen,Chuchu Fan*

Main category: cs.RO

TL;DR: TGPO提出了一种分层强化学习方法来解决信号时序逻辑任务，通过将STL分解为时序子目标和不变约束，使用高层时间分配和低层策略学习，显著提升了复杂长时程任务的性能。


<details>
  <summary>Details</summary>
Motivation: 信号时序逻辑虽然能表达复杂的机器人任务，但其非马尔可夫性和稀疏奖励特性使得标准强化学习方法难以有效解决。现有方法要么只能处理有限的STL片段，要么只能使用稀疏的终端奖励。

Method: TGPO采用分层框架：高层组件为子目标分配具体时间，低层时间条件策略使用密集的阶段奖励学习实现序列化子目标。在推理时采样多种时间分配方案，并利用学习到的critic通过Metropolis-Hastings采样指导高层时间搜索。

Result: 在五个环境（从低维导航到操作、无人机和四足机器人运动）的广泛STL任务测试中，TGPO显著优于现有最佳基线方法，任务成功率平均提升31.6%，特别是在高维和长时程情况下表现更优。

Conclusion: TGPO通过时序分解和分层学习框架，有效解决了复杂STL任务的强化学习问题，为机器人复杂长时程任务的控制策略学习提供了有效的解决方案。

Abstract: Learning control policies for complex, long-horizon tasks is a central
challenge in robotics and autonomous systems. Signal Temporal Logic (STL)
offers a powerful and expressive language for specifying such tasks, but its
non-Markovian nature and inherent sparse reward make it difficult to be solved
via standard Reinforcement Learning (RL) algorithms. Prior RL approaches focus
only on limited STL fragments or use STL robustness scores as sparse terminal
rewards. In this paper, we propose TGPO, Temporal Grounded Policy Optimization,
to solve general STL tasks. TGPO decomposes STL into timed subgoals and
invariant constraints and provides a hierarchical framework to tackle the
problem. The high-level component of TGPO proposes concrete time allocations
for these subgoals, and the low-level time-conditioned policy learns to achieve
the sequenced subgoals using a dense, stage-wise reward signal. During
inference, we sample various time allocations and select the most promising
assignment for the policy network to rollout the solution trajectory. To foster
efficient policy learning for complex STL with multiple subgoals, we leverage
the learned critic to guide the high-level temporal search via
Metropolis-Hastings sampling, focusing exploration on temporally feasible
solutions. We conduct experiments on five environments, ranging from
low-dimensional navigation to manipulation, drone, and quadrupedal locomotion.
Under a wide range of STL tasks, TGPO significantly outperforms
state-of-the-art baselines (especially for high-dimensional and long-horizon
cases), with an average of 31.6% improvement in task success rate compared to
the best baseline. The code will be available at
https://github.com/mengyuest/TGPO

</details>


### [5] [BC-MPPI: A Probabilistic Constraint Layer for Safe Model-Predictive Path-Integral Control](https://arxiv.org/abs/2510.00272)
*Odichimnma Ezeji,Michael Ziegltrum,Giulio Turrisi,Tommaso Belvedere,Valerio Modugno*

Main category: cs.RO

TL;DR: BC-MPPI是一种轻量级安全层，为MPPI控制添加概率约束保证，通过概率替代模型评估轨迹可行性，无需手动调整惩罚成本或显式样本拒绝。


<details>
  <summary>Details</summary>
Motivation: MPPI控制在高度非线性机器人任务中表现出色，但缺乏硬性约束保证，需要一种轻量级方法来确保安全性。

Method: 为每个状态和输入约束附加概率替代模型，在重新规划时返回候选轨迹的可行性概率，自动降低可能违反约束的轨迹权重。

Result: 在四旋翼无人机仿真中，BC-MPPI在保持安全裕度的同时满足规定的违反概率要求，适用于100-1500个采样点范围。

Conclusion: 该方法提供了一种可验证的自主系统认证途径，替代模型作为独立、版本控制的构件，运行时安全评分是单一标量。

Abstract: Model Predictive Path Integral (MPPI) control has recently emerged as a fast,
gradient-free alternative to model-predictive control in highly non-linear
robotic tasks, yet it offers no hard guarantees on constraint satisfaction. We
introduce Bayesian-Constraints MPPI (BC-MPPI), a lightweight safety layer that
attaches a probabilistic surrogate to every state and input constraint. At each
re-planning step the surrogate returns the probability that a candidate
trajectory is feasible; this joint probability scales the weight given to a
candidate, automatically down-weighting rollouts likely to collide or exceed
limits and pushing the sampling distribution toward the safe subset; no
hand-tuned penalty costs or explicit sample rejection required. We train the
surrogate from 1000 offline simulations and deploy the controller on a
quadrotor in MuJoCo with both static and moving obstacles. Across K in
[100,1500] rollouts BC-MPPI preserves safety margins while satisfying the
prescribed probability of violation. Because the surrogate is a stand-alone,
version-controlled artefact and the runtime safety score is a single scalar,
the approach integrates naturally with verification-and-validation pipelines
for certifiable autonomous systems.

</details>


### [6] [Learning Human Reaching Optimality Principles from Minimal Observation Inverse Reinforcement Learning](https://arxiv.org/abs/2510.00329)
*Sarmad Mehrdad,Maxime Sabbah,Vincent Bonnet,Ludovic Righetti*

Main category: cs.RO

TL;DR: MO-IRL方法通过分段学习时变成本权重，显著减少所需演示数据和收敛时间，成功预测人类手臂伸展运动，在关节角度预测上达到6.4-8度的RMSE精度。


<details>
  <summary>Details</summary>
Motivation: 研究人类运动控制中的动态成本结构，传统IRL方法需要大量演示数据且收敛慢，MO-IRL旨在更高效地学习时变成本权重。

Method: 使用平面双连杆生物力学模型，将轨迹分段并学习阶段特定的7个候选成本函数组合，通过缩放观测和生成轨迹迭代优化成本权重。

Result: 训练10次试验后，6段和8段权重分割的关节角度RMSE分别为6.4度和5.6度，优于静态权重的10.4度。跨被试验证在未见被试上达到约8度RMSE。

Conclusion: MO-IRL能有效揭示人类运动控制中动态、被试独立的成本结构，学习到的权重在运动开始和结束时强调关节加速度最小化，符合生物运动平滑性原则。

Abstract: This paper investigates the application of Minimal Observation Inverse
Reinforcement Learning (MO-IRL) to model and predict human arm-reaching
movements with time-varying cost weights. Using a planar two-link biomechanical
model and high-resolution motion-capture data from subjects performing a
pointing task, we segment each trajectory into multiple phases and learn
phase-specific combinations of seven candidate cost functions. MO-IRL
iteratively refines cost weights by scaling observed and generated trajectories
in the maximum entropy IRL formulation, greatly reducing the number of required
demonstrations and convergence time compared to classical IRL approaches.
Training on ten trials per posture yields average joint-angle Root Mean Squared
Errors (RMSE) of 6.4 deg and 5.6 deg for six- and eight-segment weight
divisions, respectively, versus 10.4 deg using a single static weight.
Cross-validation on remaining trials and, for the first time, inter-subject
validation on an unseen subject's 20 trials, demonstrates comparable predictive
accuracy, around 8 deg RMSE, indicating robust generalization. Learned weights
emphasize joint acceleration minimization during movement onset and
termination, aligning with smoothness principles observed in biological motion.
These results suggest that MO-IRL can efficiently uncover dynamic,
subject-independent cost structures underlying human motor control, with
potential applications for humanoid robots.

</details>


### [7] [DiSA-IQL: Offline Reinforcement Learning for Robust Soft Robot Control under Distribution Shifts](https://arxiv.org/abs/2510.00358)
*Linjin He,Xinda Qi,Dong Chen,Zhaojian Li,Xiaobo Tan*

Main category: cs.RO

TL;DR: 提出DiSA-IQL方法，通过惩罚不可靠的状态-动作对来缓解分布偏移问题，在软蛇机器人的目标到达任务中优于基线模型


<details>
  <summary>Details</summary>
Motivation: 软蛇机器人控制存在高度非线性动力学挑战，现有方法依赖简化假设限制了性能。离线强化学习虽然安全但存在分布偏移问题，影响泛化能力

Method: 基于隐式Q学习(IQL)扩展的DiSA-IQL方法，通过鲁棒性调节机制惩罚不可靠的状态-动作对来缓解分布偏移

Result: 在分布内和分布外评估中，DiSA-IQL在成功率、轨迹平滑性和鲁棒性方面均优于BC、CQL和标准IQL等基线模型

Conclusion: DiSA-IQL有效解决了软机器人控制中的分布偏移问题，为离线强化学习在软机器人控制中的应用提供了可行方案

Abstract: Soft snake robots offer remarkable flexibility and adaptability in complex
environments, yet their control remains challenging due to highly nonlinear
dynamics. Existing model-based and bio-inspired controllers rely on simplified
assumptions that limit performance. Deep reinforcement learning (DRL) has
recently emerged as a promising alternative, but online training is often
impractical because of costly and potentially damaging real-world interactions.
Offline RL provides a safer option by leveraging pre-collected datasets, but it
suffers from distribution shift, which degrades generalization to unseen
scenarios. To overcome this challenge, we propose DiSA-IQL
(Distribution-Shift-Aware Implicit Q-Learning), an extension of IQL that
incorporates robustness modulation by penalizing unreliable state-action pairs
to mitigate distribution shift. We evaluate DiSA-IQL on goal-reaching tasks
across two settings: in-distribution and out-of-distribution evaluation.
Simulation results show that DiSA-IQL consistently outperforms baseline models,
including Behavior Cloning (BC), Conservative Q-Learning (CQL), and vanilla
IQL, achieving higher success rates, smoother trajectories, and improved
robustness. The codes are open-sourced to support reproducibility and to
facilitate further research in offline RL for soft robot control.

</details>


### [8] [Physics-Informed Neural Controlled Differential Equations for Scalable Long Horizon Multi-Agent Motion Forecasting](https://arxiv.org/abs/2510.00401)
*Shounak Sural,Charles Kekeh,Wenliang Liu,Federico Pecora,Mouhacine Benosman*

Main category: cs.RO

TL;DR: 提出了PINCoDE模型，一种基于神经控制微分方程的物理信息多机器人长时程轨迹预测方法，能够从10个机器人扩展到100个机器人而无需额外参数，在1分钟预测范围内平均ADE低于0.5米。


<details>
  <summary>Details</summary>
Motivation: 解决多自主机器人长时程运动预测的挑战，包括非线性智能体交互、预测误差累积和连续时间动态演化，为旅行时间预测、预测引导规划和生成仿真等应用提供支持。

Method: 基于神经控制微分方程(CDEs)开发PINCoDE模型，结合物理信息约束和偏置来联合建模多机器人动态，从初始条件预测多智能体系统轨迹，并基于未来目标进行条件化。

Result: 模型可从10个机器人扩展到100个机器人而无需额外参数，1分钟预测范围内平均ADE低于0.5米，通过课程学习的渐进训练在4分钟预测范围内相比分析模型减少了2.7倍的姿态误差。

Conclusion: PINCoDE通过结合物理约束和神经CDEs，有效解决了多机器人长时程轨迹预测问题，展示了良好的可扩展性和预测精度。

Abstract: Long-horizon motion forecasting for multiple autonomous robots is challenging
due to non-linear agent interactions, compounding prediction errors, and
continuous-time evolution of dynamics. Learned dynamics of such a system can be
useful in various applications such as travel time prediction,
prediction-guided planning and generative simulation. In this work, we aim to
develop an efficient trajectory forecasting model conditioned on multi-agent
goals. Motivated by the recent success of physics-guided deep learning for
partially known dynamical systems, we develop a model based on neural
Controlled Differential Equations (CDEs) for long-horizon motion forecasting.
Unlike discrete-time methods such as RNNs and transformers, neural CDEs operate
in continuous time, allowing us to combine physics-informed constraints and
biases to jointly model multi-robot dynamics. Our approach, named PINCoDE
(Physics-Informed Neural Controlled Differential Equations), learns
differential equation parameters that can be used to predict the trajectories
of a multi-agent system starting from an initial condition. PINCoDE is
conditioned on future goals and enforces physics constraints for robot motion
over extended periods of time. We adopt a strategy that scales our model from
10 robots to 100 robots without the need for additional model parameters, while
producing predictions with an average ADE below 0.5 m for a 1-minute horizon.
Furthermore, progressive training with curriculum learning for our PINCoDE
model results in a 2.7X reduction of forecasted pose error over 4 minute
horizons compared to analytical models.

</details>


### [9] [VLA-RFT: Vision-Language-Action Reinforcement Fine-tuning with Verified Rewards in World Simulators](https://arxiv.org/abs/2510.00406)
*Hengtao Li,Pengxiang Ding,Runze Suo,Yihao Wang,Zirui Ge,Dongyuan Zang,Kexian Yu,Mingyang Sun,Hongyin Zhang,Donglin Wang,Weihua Su*

Main category: cs.RO

TL;DR: VLA-RFT是一个强化学习微调框架，利用数据驱动的世界模型作为可控模拟器，通过少量微调步骤显著提升VLA模型的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型主要依赖模仿学习，存在复合误差和分布偏移下的鲁棒性问题。强化学习可以缓解这些问题，但通常需要昂贵的真实世界交互或面临模拟到现实的差距。

Method: 使用从真实交互数据训练的世界模型作为可控模拟器，该模拟器根据动作预测未来视觉观察，允许使用从目标达成参考中获得的密集轨迹级奖励进行策略推演。

Result: 仅需少于400次微调步骤，VLA-RFT就超越了强监督基线，比基于模拟器的RL更高效，并在扰动条件下表现出强大的鲁棒性，维持稳定的任务执行。

Conclusion: 基于世界模型的RFT是一种实用的后训练范式，可以有效增强VLA模型的泛化性和鲁棒性。

Abstract: Vision-Language-Action (VLA) models enable embodied decision-making but rely
heavily on imitation learning, leading to compounding errors and poor
robustness under distribution shift. Reinforcement learning (RL) can mitigate
these issues yet typically demands costly real-world interactions or suffers
from sim-to-real gaps. We introduce VLA-RFT, a reinforcement fine-tuning
framework that leverages a data-driven world model as a controllable simulator.
Trained from real interaction data, the simulator predicts future visual
observations conditioned on actions, allowing policy rollouts with dense,
trajectory-level rewards derived from goal-achieving references. This design
delivers an efficient and action-aligned learning signal, drastically lowering
sample requirements. With fewer than 400 fine-tuning steps, VLA-RFT surpasses
strong supervised baselines and achieves greater efficiency than
simulator-based RL. Moreover, it exhibits strong robustness under perturbed
conditions, sustaining stable task execution. Our results establish
world-model-based RFT as a practical post-training paradigm to enhance the
generalization and robustness of VLA models. For more details, please refer to
https://vla-rft.github.io/.

</details>


### [10] [Seeing through Uncertainty: Robust Task-Oriented Optimization in Visual Navigation](https://arxiv.org/abs/2510.00441)
*Yiyuan Pan,Yunzhe Xu,Zhe Liu,Hesheng Wang*

Main category: cs.RO

TL;DR: NeuRO是一个集成学习优化框架，将感知网络与下游任务级鲁棒优化紧密耦合，通过将视觉预测转化为凸不确定性集，解决了数据稀缺下视觉导航的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 视觉导航是具身AI的基础问题，但实际部署需要长时程规划能力来处理多目标任务。主要瓶颈是数据稀缺：从有限数据学习的策略容易过拟合，无法泛化到分布外场景。现有神经网络智能体通常增加架构复杂度，但在小样本场景下反而适得其反。

Method: NeuRO使用部分输入凸神经网络(PICNNs)和保形校准，将数据稀缺下的噪声视觉预测转化为凸不确定性集，直接参数化优化约束；并将部分可观测性下的规划重新表述为鲁棒优化问题，实现跨环境可转移的不确定性感知策略。

Result: 在无序和顺序多目标导航任务上的广泛实验表明，NeuRO建立了最先进的性能，特别是在未见环境的泛化方面表现突出。

Conclusion: 这项工作为开发鲁棒、可泛化的自主智能体提供了重要进展。

Abstract: Visual navigation is a fundamental problem in embodied AI, yet practical
deployments demand long-horizon planning capabilities to address
multi-objective tasks. A major bottleneck is data scarcity: policies learned
from limited data often overfit and fail to generalize OOD. Existing neural
network-based agents typically increase architectural complexity that
paradoxically become counterproductive in the small-sample regime. This paper
introduce NeuRO, a integrated learning-to-optimize framework that tightly
couples perception networks with downstream task-level robust optimization.
Specifically, NeuRO addresses core difficulties in this integration: (i) it
transforms noisy visual predictions under data scarcity into convex uncertainty
sets using Partially Input Convex Neural Networks (PICNNs) with conformal
calibration, which directly parameterize the optimization constraints; and (ii)
it reformulates planning under partial observability as a robust optimization
problem, enabling uncertainty-aware policies that transfer across environments.
Extensive experiments on both unordered and sequential multi-object navigation
tasks demonstrate that NeuRO establishes SoTA performance, particularly in
generalization to unseen environments. Our work thus presents a significant
advancement for developing robust, generalizable autonomous agents.

</details>


### [11] [Integrating Offline Pre-Training with Online Fine-Tuning: A Reinforcement Learning Approach for Robot Social Navigation](https://arxiv.org/abs/2510.00466)
*Run Su,Hao Fu,Shuai Zhou,Yingao Fu*

Main category: cs.RO

TL;DR: 提出一种用于机器人社交导航的离线到在线微调强化学习算法，通过将Return-to-Go预测集成到因果Transformer架构中，解决离线训练与在线部署之间的分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习在机器人社交导航中存在局限性，包括行人行为的不确定性和训练期间环境交互有限，导致次优探索和分布偏移。

Method: 设计了一个时空融合模型，通过联合编码时间行人运动模式和空间人群动态来实时精确估计RTG值，并构建混合离线-在线经验采样机制来稳定策略更新。

Result: 在模拟社交导航环境中的广泛实验表明，该方法相比最先进的基线方法实现了更高的成功率和更低的碰撞率。

Conclusion: 该算法在增强导航策略的鲁棒性和适应性方面具有显著效果，为现实世界应用中更可靠和自适应的机器人导航系统铺平了道路。

Abstract: Offline reinforcement learning (RL) has emerged as a promising framework for
addressing robot social navigation challenges. However, inherent uncertainties
in pedestrian behavior and limited environmental interaction during training
often lead to suboptimal exploration and distributional shifts between offline
training and online deployment. To overcome these limitations, this paper
proposes a novel offline-to-online fine-tuning RL algorithm for robot social
navigation by integrating Return-to-Go (RTG) prediction into a causal
Transformer architecture. Our algorithm features a spatiotem-poral fusion model
designed to precisely estimate RTG values in real-time by jointly encoding
temporal pedestrian motion patterns and spatial crowd dynamics. This RTG
prediction framework mitigates distribution shift by aligning offline policy
training with online environmental interactions. Furthermore, a hybrid
offline-online experience sampling mechanism is built to stabilize policy
updates during fine-tuning, ensuring balanced integration of pre-trained
knowledge and real-time adaptation. Extensive experiments in simulated social
navigation environments demonstrate that our method achieves a higher success
rate and lower collision rate compared to state-of-the-art baselines. These
results underscore the efficacy of our algorithm in enhancing navigation policy
robustness and adaptability. This work paves the way for more reliable and
adaptive robotic navigation systems in real-world applications.

</details>


### [12] [From Human Hands to Robot Arms: Manipulation Skills Transfer via Trajectory Alignment](https://arxiv.org/abs/2510.00491)
*Han Zhou,Jinjin Cao,Liyuan Ma,Xueji Fang,Guo-jun Qi*

Main category: cs.RO

TL;DR: Traj2Action是一个通过3D轨迹作为中间表示来弥合人-机器人形态差距的框架，将人类操作知识转移到机器人动作中，在真实机器人实验中性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 解决机器人多样化操作技能学习依赖昂贵遥操作演示的问题，利用可扩展的人类视频数据，但面临人-机器人形态差距的挑战。

Method: 使用操作端点的3D轨迹作为统一中间表示，先学习生成粗略轨迹作为高层运动规划，然后在协同去噪框架中合成精确的机器人特定动作。

Result: 在Franka机器人上的真实世界实验显示，相比基线性能提升高达27%（短时任务）和22.25%（长时任务），且随着人类数据规模增加性能显著提升。

Conclusion: Traj2Action有效解决了人-机器人形态差距问题，通过轨迹中间表示成功实现了从人类到机器人的操作知识迁移。

Abstract: Learning diverse manipulation skills for real-world robots is severely
bottlenecked by the reliance on costly and hard-to-scale teleoperated
demonstrations. While human videos offer a scalable alternative, effectively
transferring manipulation knowledge is fundamentally hindered by the
significant morphological gap between human and robotic embodiments. To address
this challenge and facilitate skill transfer from human to robot, we introduce
Traj2Action,a novel framework that bridges this embodiment gap by using the 3D
trajectory of the operational endpoint as a unified intermediate
representation, and then transfers the manipulation knowledge embedded in this
trajectory to the robot's actions. Our policy first learns to generate a coarse
trajectory, which forms an high-level motion plan by leveraging both human and
robot data. This plan then conditions the synthesis of precise, robot-specific
actions (e.g., orientation and gripper state) within a co-denoising framework.
Extensive real-world experiments on a Franka robot demonstrate that Traj2Action
boosts the performance by up to 27% and 22.25% over $\pi_0$ baseline on short-
and long-horizon real-world tasks, and achieves significant gains as human data
scales in robot policy learning. Our project website, featuring code and video
demonstrations, is available at
https://anonymous.4open.science/w/Traj2Action-4A45/.

</details>


### [13] [Two stage GNSS outlier detection for factor graph optimization based GNSS-RTK/INS/odometer fusion](https://arxiv.org/abs/2510.00524)
*Baoshan Song,Penggao Yan,Xiao Xia,Yihan Zhong,Weisong Wen,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 提出一种两阶段异常值检测方法，用于紧密耦合的GNSS-RTK/INS/里程计组合导航系统，通过多普勒测量和预积分IMU/里程计约束来检测和消除伪距异常值，提高复杂环境下的定位精度。


<details>
  <summary>Details</summary>
Motivation: 复杂环境中的GNSS定位面临非视距传播、多径效应和信号遮挡等挑战，这些因素会导致伪距测量出现大异常值，严重影响GNSS-RTK定位性能和紧密耦合组合导航系统的有效性。

Method: 采用两阶段异常值检测：第一阶段使用对多径和NLOS效应不敏感的多普勒测量来检测伪距异常值；第二阶段利用预积分IMU和里程计约束生成预测的双差伪距测量，进行更精细的异常值识别和剔除。

Result: 实验结果表明，该两阶段检测框架显著减少了伪距异常值的影响，提高了定位精度和一致性。在深度城市峡谷测试中，异常值抑制方法将GNSS-RTK/INS/里程计融合的RMSE从0.52米降低到0.30米，提升了42.3%。

Conclusion: 通过结合两个互补的检测阶段，该系统对粗大伪距误差和退化卫星测量质量具有更好的鲁棒性，在复杂环境中实现了更可靠的GNSS定位性能。

Abstract: Reliable GNSS positioning in complex environments remains a critical
challenge due to non-line-of-sight (NLOS) propagation, multipath effects, and
frequent signal blockages. These effects can easily introduce large outliers
into the raw pseudo-range measurements, which significantly degrade the
performance of global navigation satellite system (GNSS) real-time kinematic
(RTK) positioning and limit the effectiveness of tightly coupled GNSS-based
integrated navigation system. To address this issue, we propose a two-stage
outlier detection method and apply the method in a tightly coupled GNSS-RTK,
inertial navigation system (INS), and odometer integration based on factor
graph optimization (FGO). In the first stage, Doppler measurements are employed
to detect pseudo-range outliers in a GNSS-only manner, since Doppler is less
sensitive to multipath and NLOS effects compared with pseudo-range, making it a
more stable reference for detecting sudden inconsistencies. In the second
stage, pre-integrated inertial measurement units (IMU) and odometer constraints
are used to generate predicted double-difference pseudo-range measurements,
which enable a more refined identification and rejection of remaining outliers.
By combining these two complementary stages, the system achieves improved
robustness against both gross pseudo-range errors and degraded satellite
measuring quality. The experimental results demonstrate that the two-stage
detection framework significantly reduces the impact of pseudo-range outliers,
and leads to improved positioning accuracy and consistency compared with
representative baseline approaches. In the deep urban canyon test, the outlier
mitigation method has limits the RMSE of GNSS-RTK/INS/odometer fusion from 0.52
m to 0.30 m, with 42.3% improvement.

</details>


### [14] [GRITS: A Spillage-Aware Guided Diffusion Policy for Robot Food Scooping Tasks](https://arxiv.org/abs/2510.00573)
*Yen-Ling Tai,Yi-Ru Yang,Kuan-Ting Yu,Yu-Wei Chao,Yi-Ting Chen*

Main category: cs.RO

TL;DR: GRITS是一个基于引导扩散策略的机器人食物舀取框架，通过溢出预测器减少食物溢出，在真实机器人平台上验证有效。


<details>
  <summary>Details</summary>
Motivation: 现有机器人学习算法在处理多样化和动态的食物状态时表现不佳，容易导致食物溢出和可靠性降低。

Method: 设计溢出预测器估计当前观测和动作序列下的溢出概率，在推理时作为可微分引导信号指导扩散采样过程。

Result: 在6种食物类别上训练，在10种未见类别上评估，任务成功率达82%，溢出率仅4%，相比无引导基线溢出率降低40%以上。

Conclusion: GRITS框架能有效减少食物舀取过程中的溢出，提高任务可靠性，在真实机器人平台上验证了其有效性。

Abstract: Robotic food scooping is a critical manipulation skill for food preparation
and service robots. However, existing robot learning algorithms, especially
learn-from-demonstration methods, still struggle to handle diverse and dynamic
food states, which often results in spillage and reduced reliability. In this
work, we introduce GRITS: A Spillage-Aware Guided Diffusion Policy for Robot
Food Scooping Tasks. This framework leverages guided diffusion policy to
minimize food spillage during scooping and to ensure reliable transfer of food
items from the initial to the target location. Specifically, we design a
spillage predictor that estimates the probability of spillage given current
observation and action rollout. The predictor is trained on a simulated dataset
with food spillage scenarios, constructed from four primitive shapes (spheres,
cubes, cones, and cylinders) with varied physical properties such as mass,
friction, and particle size. At inference time, the predictor serves as a
differentiable guidance signal, steering the diffusion sampling process toward
safer trajectories while preserving task success. We validate GRITS on a
real-world robotic food scooping platform. GRITS is trained on six food
categories and evaluated on ten unseen categories with different shapes and
quantities. GRITS achieves an 82% task success rate and a 4% spillage rate,
reducing spillage by over 40% compared to baselines without guidance, thereby
demonstrating its effectiveness.

</details>


### [15] [Hybrid Training for Vision-Language-Action Models](https://arxiv.org/abs/2510.00600)
*Pietro Mazzaglia,Cansu Sancaktar,Markus Peschl,Daniel Dijkman*

Main category: cs.RO

TL;DR: 本文提出混合训练(HyT)框架，使视觉-语言-动作模型能在推理时跳过思维链生成，同时保持性能提升，支持灵活输出预测。


<details>
  <summary>Details</summary>
Motivation: 思维链(CoT)技术虽然能提升复杂任务性能，但会显著增加推理时间，影响机器人在实时操作中的实用性。

Method: 采用混合训练框架，让模型同时学习生成思维链和直接预测动作，在推理时可选择是否生成CoT。

Result: 在模拟基准测试和真实世界实验中验证了方法的有效性，模型能在不生成CoT的情况下保持性能。

Conclusion: HyT框架提供了推理时的灵活性，使VLAs模型既能受益于CoT训练，又能在实际应用中避免推理延迟。

Abstract: Using Large Language Models to produce intermediate thoughts, a.k.a.
Chain-of-thought (CoT), before providing an answer has been a successful recipe
for solving complex language tasks. In robotics, similar embodied CoT
strategies, generating thoughts before actions, have also been shown to lead to
improved performance when using Vision-Language-Action models (VLAs). As these
techniques increase the length of the model's generated outputs to include the
thoughts, the inference time is negatively affected. Delaying an agent's
actions in real-world executions, as in robotic manipulation settings, strongly
affects the usability of a method, as tasks require long sequences of actions.
However, is the generation of long chains-of-thought a strong prerequisite for
achieving performance improvements? In this work, we explore the idea of Hybrid
Training (HyT), a framework that enables VLAs to learn from thoughts and
benefit from the associated performance gains, while enabling the possibility
to leave out CoT generation during inference. Furthermore, by learning to
conditionally predict a diverse set of outputs, HyT supports flexibility at
inference time, enabling the model to either predict actions directly, generate
thoughts or follow instructions. We evaluate the proposed method in a series of
simulated benchmarks and real-world experiments.

</details>


### [16] [What Did I Learn? Operational Competence Assessment for AI-Based Trajectory Planners](https://arxiv.org/abs/2510.00619)
*Michiel Braat,Maren Buermann,Marijke van Weperen,Jan-Pieter Paardekooper*

Main category: cs.RO

TL;DR: 提出了一种基于知识图谱的方法来识别自动驾驶车辆未充分训练的场景，通过分析训练数据集中子场景配置的覆盖率和复杂性来评估模型能力。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶功能越来越依赖机器学习，但模型性能取决于训练数据与任务的匹配程度。为确保可靠运行，需要了解数据集内容以评估训练模型的运行风险。

Method: 将驾驶数据建模为知识图谱，表示驾驶场景中的实体及其关系。通过查询特定子场景配置来检查其在数据集中的出现情况，并根据训练集中子场景配置的覆盖率和复杂性来估计车辆在驾驶场景中的能力。

Result: 该方法应用于NuPlan数据集，成功建模为知识图谱并分析了特定驾驶场景的覆盖情况。

Conclusion: 该方法有助于监控基于数据集训练的机器学习模型的能力，这对于在自动驾驶中部署可信AI至关重要。

Abstract: Automated driving functions increasingly rely on machine learning for tasks
like perception and trajectory planning, requiring large, relevant datasets.
The performance of these algorithms depends on how closely the training data
matches the task. To ensure reliable functioning, it is crucial to know what is
included in the dataset to assess the trained model's operational risk. We aim
to enhance the safe use of machine learning in automated driving by developing
a method to recognize situations that an automated vehicle has not been
sufficiently trained on. This method also improves explainability by describing
the dataset at a human-understandable level. We propose modeling driving data
as knowledge graphs, representing driving scenes with entities and their
relationships. These graphs are queried for specific sub-scene configurations
to check their occurrence in the dataset. We estimate a vehicle's competence in
a driving scene by considering the coverage and complexity of sub-scene
configurations in the training set. Higher complexity scenes require greater
coverage for high competence. We apply this method to the NuPlan dataset,
modeling it with knowledge graphs and analyzing the coverage of specific
driving scenes. This approach helps monitor the competence of machine learning
models trained on the dataset, which is essential for trustworthy AI to be
deployed in automated driving.

</details>


### [17] [Trajectory Based Observer Design: A Framework for Lightweight Sensor Fusion](https://arxiv.org/abs/2510.00630)
*Federico Oliva,Tom Shaked,Daniele Carnevale,Amir Degani*

Main category: cs.RO

TL;DR: 提出一种基于轨迹的优化设计(TBOD)方法，用于非线性系统和多传感器设置的观测器设计，通过数值优化调整观测器参数，在陆地漫游车定位问题中验证性能。


<details>
  <summary>Details</summary>
Motivation: 高效观测器设计和精确传感器融合在状态估计中至关重要，需要一种简单易用的方法来设计通用非线性系统和多传感器设置的观测器。

Method: 从参数化观测器动力学出发，利用预先记录的测量轨迹，通过数值优化调整观测器参数，结合经典观测器理论和移动水平估计器方法。

Result: 在陆地漫游车定位问题中测试，结合IMU和超宽带天线测距传感器，与扩展卡尔曼滤波器相比，位置估计精度相当，但方向估计显著改善。

Conclusion: TBOD提供了一种轻量级、通用的传感器融合方法，能够高效、模块化地处理各种传感器，并具有简单的调参过程。

Abstract: Efficient observer design and accurate sensor fusion are key in state
estimation. This work proposes an optimization-based methodology, termed
Trajectory Based Optimization Design (TBOD), allowing the user to easily design
observers for general nonlinear systems and multi-sensor setups. Starting from
parametrized observer dynamics, the proposed method considers a finite set of
pre-recorded measurement trajectories from the nominal plant and exploits them
to tune the observer parameters through numerical optimization. This research
hinges on the classic observer's theory and Moving Horizon Estimators
methodology. Optimization is exploited to ease the observer's design, providing
the user with a lightweight, general-purpose sensor fusion methodology. TBOD's
main characteristics are the capability to handle general sensors efficiently
and in a modular way and, most importantly, its straightforward tuning
procedure. The TBOD's performance is tested on a terrestrial rover localization
problem, combining IMU and ranging sensors provided by Ultra Wide Band
antennas, and validated through a motion-capture system. Comparison with an
Extended Kalman Filter is also provided, matching its position estimation
accuracy and significantly improving in the orientation.

</details>


### [18] [Enabling High-Frequency Cross-Modality Visual Positioning Service for Accurate Drone Landing](https://arxiv.org/abs/2510.00646)
*Haoyang Wang,Xinyu Luo,Wenhua Ding,Jingao Xu,Xuecheng Chen,Ruiyang Duan,Jialong Chen,Haitao Zhang,Yunhao Liu,Xinlei Chen*

Main category: cs.RO

TL;DR: EV-Pose是一个基于事件相机的视觉定位系统，用于实现无人机精确着陆的6自由度姿态跟踪，通过时空特征指导的姿态估计和运动感知的层次融合优化，显著提升了跟踪精度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统GPS在城区环境中由于信号衰减和多径传播不可靠，现有视觉定位服务(VPS)在无人机上部署时存在精度和效率限制，需要重新设计面向无人机的VPS系统。

Method: 引入事件相机，设计时空特征指导的姿态估计模块提取时序距离场进行3D点云地图匹配；采用运动感知的层次融合优化方案，在事件过滤早期和姿态优化后期利用无人机运动信息。

Result: EV-Pose实现了1.34度的旋转精度和6.9毫米的平移精度，跟踪延迟仅10.08毫秒，性能优于基线方法50%以上。

Conclusion: EV-Pose能够实现精确的无人机着陆，为无人机物流提供了可靠的姿态跟踪解决方案。

Abstract: After years of growth, drone-based delivery is transforming logistics. At its
core, real-time 6-DoF drone pose tracking enables precise flight control and
accurate drone landing. With the widespread availability of urban 3D maps, the
Visual Positioning Service (VPS), a mobile pose estimation system, has been
adapted to enhance drone pose tracking during the landing phase, as
conventional systems like GPS are unreliable in urban environments due to
signal attenuation and multi-path propagation. However, deploying the current
VPS on drones faces limitations in both estimation accuracy and efficiency. In
this work, we redesign drone-oriented VPS with the event camera and introduce
EV-Pose to enable accurate, high-frequency 6-DoF pose tracking for accurate
drone landing. EV-Pose introduces a spatio-temporal feature-instructed pose
estimation module that extracts a temporal distance field to enable 3D point
map matching for pose estimation; and a motion-aware hierarchical fusion and
optimization scheme to enhance the above estimation in accuracy and efficiency,
by utilizing drone motion in the \textit{early stage} of event filtering and
the \textit{later stage} of pose optimization. Evaluation shows that EV-Pose
achieves a rotation accuracy of 1.34$\degree$ and a translation accuracy of
6.9$mm$ with a tracking latency of 10.08$ms$, outperforming baselines by
$>$50\%, \tmcrevise{thus enabling accurate drone landings.} Demo:
https://ev-pose.github.io/

</details>


### [19] [Shared Object Manipulation with a Team of Collaborative Quadrupeds](https://arxiv.org/abs/2510.00682)
*Shengzhi Wang,Niels Dehio,Xuanqi Zeng,Xian Yang,Lingwei Zhang,Yun-Hui Liu,K. W. Samuel Au*

Main category: cs.RO

TL;DR: 将经典混合运动-力控制器扩展到腿式操纵器团队，实现刚性物体的协作移动操作


<details>
  <summary>Details</summary>
Motivation: 多机器人团队处理笨重物体具有优势，但现有多操纵器系统受限于工作空间约束

Method: 扩展经典混合运动-力控制器到腿式操纵器系统，采用力闭合抓取实现协作移动操作

Result: 机器人能够灵活协调运动，实现高效稳定的物体协作操作和运输，通过仿真和真实实验验证

Conclusion: 该方法成功实现了腿式操纵器团队的协作移动操作，克服了传统多操纵器系统的工作空间限制

Abstract: Utilizing teams of multiple robots is advantageous for handling bulky
objects. Many related works focus on multi-manipulator systems, which are
limited by workspace constraints. In this paper, we extend a classical hybrid
motion-force controller to a team of legged manipulator systems, enabling
collaborative loco-manipulation of rigid objects with a force-closed grasp. Our
novel approach allows the robots to flexibly coordinate their movements,
achieving efficient and stable object co-manipulation and transport, validated
through extensive simulations and real-world experiments.

</details>


### [20] [HAMLET: Switch your Vision-Language-Action Model into a History-Aware Policy](https://arxiv.org/abs/2510.00695)
*Myungkyu Koo,Daewon Choi,Taeyoung Kim,Kyungmin Lee,Changyeon Kim,Youngyo Seo,Jinwoo Shin*

Main category: cs.RO

TL;DR: HAMLET是一个可扩展框架，用于使视觉-语言-动作模型能够利用历史上下文进行动作预测，通过引入时刻令牌和轻量级记忆模块，在历史依赖任务上显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 机器人操作任务本质上是历史依赖的，但现有视觉-语言-动作模型仅依赖当前观测，忽略了历史上下文信息，这限制了它们在需要历史背景的任务上的表现。

Method: 提出HAMLET框架：1）引入时刻令牌紧凑编码每个时间步的感知信息；2）使用时序对比学习初始化时刻令牌表示；3）采用轻量级记忆模块整合历史时刻令牌生成记忆特征，用于动作预测。

Result: 在GR00T N1.5上，HAMLET在历史依赖任务上达到76.4%的平均成功率，比基线提升47.2%；在RoboCasa Kitchen上从64.1%提升到66.4%；在LIBERO上从95.6%提升到97.7%。

Conclusion: HAMLET成功将最先进的VLA模型转变为历史感知策略，特别是在需要历史上下文的长时程任务上表现显著改善，证明了利用历史信息对机器人操作任务的重要性。

Abstract: Inherently, robotic manipulation tasks are history-dependent: leveraging past
context could be beneficial. However, most existing Vision-Language-Action
models (VLAs) have been designed without considering this aspect, i.e., they
rely solely on the current observation, ignoring preceding context. In this
paper, we propose HAMLET, a scalable framework to adapt VLAs to attend to the
historical context during action prediction. Specifically, we introduce moment
tokens that compactly encode perceptual information at each timestep. Their
representations are initialized with time-contrastive learning, allowing them
to better capture temporally distinctive aspects. Next, we employ a lightweight
memory module that integrates the moment tokens across past timesteps into
memory features, which are then leveraged for action prediction. Through
empirical evaluation, we show that HAMLET successfully transforms a
state-of-the-art VLA into a history-aware policy, especially demonstrating
significant improvements on long-horizon tasks that require historical context.
In particular, on top of GR00T N1.5, HAMLET achieves an average success rate of
76.4% on history-dependent real-world tasks, surpassing the baseline
performance by 47.2%. Furthermore, HAMLET pushes prior art performance from
64.1% to 66.4% on RoboCasa Kitchen (100-demo setup) and from 95.6% to 97.7% on
LIBERO, highlighting its effectiveness even under generic robot-manipulation
benchmarks.

</details>


### [21] [MultiPhysio-HRC: Multimodal Physiological Signals Dataset for industrial Human-Robot Collaboration](https://arxiv.org/abs/2510.00703)
*Andrea Bussolan,Stefano Baraldo,Oliver Avram,Pablo Urcola,Luis Montesano,Luca Maria Gambardella,Anna Valente*

Main category: cs.RO

TL;DR: MultiPhysio-HRC是一个多模态数据集，包含在真实人机协作场景中收集的生理、音频和面部数据，用于支持情感计算和人类感知机器人研究。


<details>
  <summary>Details</summary>
Motivation: 工业5.0中人机协作需要感知人类心理生理状态（如压力和认知负荷），以实现自适应和人类感知的机器人系统。

Method: 创建包含EEG、ECG、EDA、RESP、EMG、语音记录和面部动作单元的多模态数据集，结合受控认知任务、沉浸式虚拟现实体验和工业拆卸活动，并通过验证的心理自我评估问卷获得丰富的地面真实标注。

Result: 评估了压力和认知负荷分类的基线模型，证明了该数据集在情感计算和人类感知机器人研究中的潜力。

Conclusion: MultiPhysio-HRC数据集已公开可用，支持以人为中心的自动化、工作场所福祉和智能机器人系统的研究。

Abstract: Human-robot collaboration (HRC) is a key focus of Industry 5.0, aiming to
enhance worker productivity while ensuring well-being. The ability to perceive
human psycho-physical states, such as stress and cognitive load, is crucial for
adaptive and human-aware robotics. This paper introduces MultiPhysio-HRC, a
multimodal dataset containing physiological, audio, and facial data collected
during real-world HRC scenarios. The dataset includes electroencephalography
(EEG), electrocardiography (ECG), electrodermal activity (EDA), respiration
(RESP), electromyography (EMG), voice recordings, and facial action units. The
dataset integrates controlled cognitive tasks, immersive virtual reality
experiences, and industrial disassembly activities performed manually and with
robotic assistance, to capture a holistic view of the participants' mental
states. Rich ground truth annotations were obtained using validated
psychological self-assessment questionnaires. Baseline models were evaluated
for stress and cognitive load classification, demonstrating the dataset's
potential for affective computing and human-aware robotics research.
MultiPhysio-HRC is publicly available to support research in human-centered
automation, workplace well-being, and intelligent robotic systems.

</details>


### [22] [CroSTAta: Cross-State Transition Attention Transformer for Robotic Manipulation](https://arxiv.org/abs/2510.00726)
*Giovanni Minelli,Giulio Turrisi,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 提出Cross-State Transition Attention Transformer，通过State Transition Attention机制基于学习的状态演化模式来调节标准注意力权重，使策略能更好地根据执行历史调整行为。


<details>
  <summary>Details</summary>
Motivation: 通过监督学习从演示中学习机器人操作策略时，当策略遇到训练中未明确涵盖的执行变化时仍具挑战性。标准方法处理序列中所有过去状态时没有显式建模演示中可能包含的时间结构（如失败和恢复模式）。

Method: 结合结构化注意力与训练时的时序掩码，随机移除最近时间步的视觉信息以鼓励从历史上下文进行时序推理。

Result: 在仿真评估中，STA在所有任务上始终优于标准交叉注意力和时序建模方法（如TCN和LSTM网络），在精度关键任务上比交叉注意力提升超过2倍。

Conclusion: 提出的State Transition Attention机制能有效提升机器人操作策略对执行变化的适应能力，通过显式建模状态演化模式改善策略的鲁棒性。

Abstract: Learning robotic manipulation policies through supervised learning from
demonstrations remains challenging when policies encounter execution variations
not explicitly covered during training. While incorporating historical context
through attention mechanisms can improve robustness, standard approaches
process all past states in a sequence without explicitly modeling the temporal
structure that demonstrations may include, such as failure and recovery
patterns. We propose a Cross-State Transition Attention Transformer that
employs a novel State Transition Attention (STA) mechanism to modulate standard
attention weights based on learned state evolution patterns, enabling policies
to better adapt their behavior based on execution history. Our approach
combines this structured attention with temporal masking during training, where
visual information is randomly removed from recent timesteps to encourage
temporal reasoning from historical context. Evaluation in simulation shows that
STA consistently outperforms standard cross-attention and temporal modeling
approaches like TCN and LSTM networks across all tasks, achieving more than 2x
improvement over cross-attention on precision-critical tasks.

</details>


### [23] [Tele-rehabilitation with online skill transfer and adaptation in $\mathbb{R}^3 \times \mathit{S}^3$](https://arxiv.org/abs/2510.00770)
*Tianle Ni,Xiao Chen,Hamid Sadeghian,Sami Haddadin*

Main category: cs.RO

TL;DR: 提出了一种用于机器人辅助远程康复的远程教学框架，通过双边遥操作连接治疗师和患者端的机器人，实现康复训练的远程演示和自适应调整。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够实现远程康复训练的系统，让治疗师可以远程指导患者进行康复训练，同时支持治疗师引导和患者被动训练之间的平滑切换。

Method: 使用双边遥操作连接治疗师和患者端的机器人，采用6自由度动态运动基元在$\mathbb{R}^3 \times \mathit{S}^3$空间中编码平移和旋转运动，确保轨迹的准确再现。

Result: 使用7自由度机械臂进行的实验验证了该方法的可行性，展示了其在个性化和远程监督康复中的潜力。

Conclusion: 该框架为机器人辅助远程康复提供了一种有效的解决方案，支持治疗师远程指导患者进行康复训练，并允许根据患者情况进行自适应调整。

Abstract: This paper proposes a tele-teaching framework for the domain of
robot-assisted tele-rehabilitation. The system connects two robotic
manipulators on therapist and patient side via bilateral teleoperation,
enabling a therapist to remotely demonstrate rehabilitation exercises that are
executed by the patient-side robot. A 6-DoF Dynamical Movement Primitives
formulation is employed to jointly encode translational and rotational motions
in $\mathbb{R}^3 \times \mathit{S}^3$ space, ensuring accurate trajectory
reproduction. The framework supports smooth transitions between therapist-led
guidance and patient passive training, while allowing adaptive adjustment of
motion. Experiments with 7-DoF manipulators demonstrate the feasibility of the
approach, highlighting its potential for personalized and remotely supervised
rehabilitation.

</details>


### [24] [Semantic Visual Simultaneous Localization and Mapping: A Survey on State of the Art, Challenges, and Future Directions](https://arxiv.org/abs/2510.00783)
*Thanh Nguyen Canh,Haolan Zhang,Xiem HoangVan,Nak Young Chong*

Main category: cs.RO

TL;DR: 这是一篇关于语义SLAM的综述性研究论文，系统梳理了语义同时定位与建图领域的发展现状、技术框架、挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 语义SLAM在机器人和计算机视觉领域至关重要，但缺乏涵盖最新进展和持续挑战的全面综述。该研究旨在填补这一空白，为研究者提供该领域的系统性指导。

Method: 采用文献综述方法，深入探讨视觉SLAM的演变历程，提出统一的问题表述和模块化解决方案框架，包括视觉定位、语义特征提取、建图、数据关联和闭环优化等阶段，并研究了深度学习和大型语言模型等替代方法。

Result: 构建了语义SLAM的完整技术框架，系统评估了现有方法的优缺点，分析了相关数据集，为研究者提供了该领域的全面技术路线图。

Conclusion: 该研究为语义SLAM领域提供了宝贵的综述资源，指出了未来研究方向，有助于推动该领域的技术发展和应用创新。

Abstract: Semantic Simultaneous Localization and Mapping (SLAM) is a critical area of
research within robotics and computer vision, focusing on the simultaneous
localization of robotic systems and associating semantic information to
construct the most accurate and complete comprehensive model of the surrounding
environment. Since the first foundational work in Semantic SLAM appeared more
than two decades ago, this field has received increasing attention across
various scientific communities. Despite its significance, the field lacks
comprehensive surveys encompassing recent advances and persistent challenges.
In response, this study provides a thorough examination of the state-of-the-art
of Semantic SLAM techniques, with the aim of illuminating current trends and
key obstacles. Beginning with an in-depth exploration of the evolution of
visual SLAM, this study outlines its strengths and unique characteristics,
while also critically assessing previous survey literature. Subsequently, a
unified problem formulation and evaluation of the modular solution framework is
proposed, which divides the problem into discrete stages, including visual
localization, semantic feature extraction, mapping, data association, and loop
closure optimization. Moreover, this study investigates alternative
methodologies such as deep learning and the utilization of large language
models, alongside a review of relevant research about contemporary SLAM
datasets. Concluding with a discussion on potential future research directions,
this study serves as a comprehensive resource for researchers seeking to
navigate the complex landscape of Semantic SLAM.

</details>


### [25] [RTFF: Random-to-Target Fabric Flattening Policy using Dual-Arm Manipulator](https://arxiv.org/abs/2510.00814)
*Kai Tang,Dipankar Bhattacharya,Hang Xu,Fuyuki Tokuda,Norman C. Tien,Kazuhiro Kosuge*

Main category: cs.RO

TL;DR: 提出首个随机到目标织物展平策略(RTFF)，通过混合模仿学习-视觉伺服框架，将随机褶皱织物状态对齐到任意无褶皱目标状态。


<details>
  <summary>Details</summary>
Motivation: 解决织物生产中因织物可变形性、无限自由度以及褶皱、折叠和机械臂遮挡带来的织物展平和对齐挑战。

Method: 采用混合IL-VS框架：IL使用显式织物模型进行粗对齐，VS进行细对齐；核心是基于模板的网格表示，并提出MACT Transformer策略。

Result: 在真实双臂遥操作系统上验证，展示了对不同目标的零样本对齐、高精度以及跨织物和尺度的强泛化能力。

Conclusion: RTFF策略成功解决了织物展平对齐问题，实现了对不同目标状态的高精度零样本对齐和强泛化性能。

Abstract: Robotic fabric manipulation in garment production for sewing, cutting, and
ironing requires reliable flattening and alignment, yet remains challenging due
to fabric deformability, effectively infinite degrees of freedom, and frequent
occlusions from wrinkles, folds, and the manipulator's End-Effector (EE) and
arm. To address these issues, this paper proposes the first Random-to-Target
Fabric Flattening (RTFF) policy, which aligns a random wrinkled fabric state to
an arbitrary wrinkle-free target state. The proposed policy adopts a hybrid
Imitation Learning-Visual Servoing (IL-VS) framework, where IL learns with
explicit fabric models for coarse alignment of the wrinkled fabric toward a
wrinkle-free state near the target, and VS ensures fine alignment to the
target. Central to this framework is a template-based mesh that offers precise
target state representation, wrinkle-aware geometry prediction, and consistent
vertex correspondence across RTFF manipulation steps, enabling robust
manipulation and seamless IL-VS switching. Leveraging the power of mesh, a
novel IL solution for RTFF-Mesh Action Chunking Transformer (MACT)-is then
proposed by conditioning the mesh information into a Transformer-based policy.
The RTFF policy is validated on a real dual-arm tele-operation system, showing
zero-shot alignment to different targets, high accuracy, and strong
generalization across fabrics and scales. Project website:
https://kaitang98.github.io/RTFF_Policy/

</details>


### [26] [Product-oriented Product-Process-Resource Asset Network and its Representation in AutomationML for Asset Administration Shell](https://arxiv.org/abs/2510.00933)
*Sara Strakosova,Petr Novak,Petr Kadera*

Main category: cs.RO

TL;DR: 提出了一种基于PPR建模范式的产品生命周期管理方法PoPAN，将产品生命周期末端阶段影响纳入工程阶段，支持产品在工业4.0环境下的维修、再制造和升级改造。


<details>
  <summary>Details</summary>
Motivation: 当前工业标准主要关注生产阶段，缺乏完整产品生命周期覆盖，且侧重生产过程而非产品本身。需要将产品生命周期末端阶段（如报废、回收）的影响纳入工程阶段考虑。

Method: 基于产品-过程-资源(PPR)建模范式，提出PoPAN模型作为产品的数字影子，封装在资产管理壳中，支持产品全生命周期管理，并使用AutomationML数据格式进行序列化。

Result: 开发了PoPAN模型并在电动汽车电池拆卸用例中验证，支持电池再制造用于固定储能应用。

Conclusion: PoPAN模型能够有效支持产品全生命周期管理，特别是在工业4.0环境下实现产品的维修、再制造和升级循环。

Abstract: Current products, especially in the automotive sector, pose complex technical
systems having a multi-disciplinary mechatronic nature. Industrial standards
supporting system engineering and production typically (i) address the
production phase only, but do not cover the complete product life cycle, and
(ii) focus on production processes and resources rather than the products
themselves. The presented approach is motivated by incorporating impacts of
end-of-life phase of the product life cycle into the engineering phase. This
paper proposes a modelling approach coming up from the Product-Process-Resource
(PPR) modeling paradigm. It combines requirements on (i) respecting the product
structure as a basis for the model, and (ii) it incorporates repairing,
remanufacturing, or upcycling within cyber-physical production systems. The
proposed model called PoPAN should accompany the product during the entire life
cycle as a digital shadow encapsulated within the Asset Administration Shell of
a product. To facilitate the adoption of the proposed paradigm, the paper also
proposes serialization of the model in the AutomationML data format. The model
is demonstrated on a use-case for disassembling electric vehicle batteries to
support their remanufacturing for stationary battery applications.

</details>


### [27] [Non-submodular Visual Attention for Robot Navigation](https://arxiv.org/abs/2510.00942)
*Reza Vafaee,Kian Behzad,Milad Siami,Luca Carlone,Ali Jadbabaie*

Main category: cs.RO

TL;DR: 提出了一个任务导向的计算框架来增强机器人视觉惯性导航，通过战略性地选择视觉特征来解决时间和能量资源限制问题，并开发了四种多项式时间近似算法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在视觉惯性导航中面临的有限时间和能量资源挑战，提高导航效率。

Method: 使用基于均方误差的非子模目标函数和简化动态预测模型来选择视觉特征，提出了四种近似算法：经典贪心法、低秩贪心变体、随机贪心采样器和基于一阶泰勒展开的线性化选择器。

Result: 在标准化基准和自定义控制感知平台上的广泛实验验证了理论结果，这些方法实现了强近似保证并支持实时部署。

Conclusion: 该框架通过有效的特征选择算法显著提升了视觉惯性导航性能，在保证理论性能的同时实现了实时应用。

Abstract: This paper presents a task-oriented computational framework to enhance
Visual-Inertial Navigation (VIN) in robots, addressing challenges such as
limited time and energy resources. The framework strategically selects visual
features using a Mean Squared Error (MSE)-based, non-submodular objective
function and a simplified dynamic anticipation model. To address the
NP-hardness of this problem, we introduce four polynomial-time approximation
algorithms: a classic greedy method with constant-factor guarantees; a low-rank
greedy variant that significantly reduces computational complexity; a
randomized greedy sampler that balances efficiency and solution quality; and a
linearization-based selector based on a first-order Taylor expansion for
near-constant-time execution. We establish rigorous performance bounds by
leveraging submodularity ratios, curvature, and element-wise curvature
analyses. Extensive experiments on both standardized benchmarks and a custom
control-aware platform validate our theoretical results, demonstrating that
these methods achieve strong approximation guarantees while enabling real-time
deployment.

</details>


### [28] [ROSflight 2.0: Lean ROS 2-Based Autopilot for Unmanned Aerial Vehicles](https://arxiv.org/abs/2510.00995)
*Jacob Moore,Phil Tokumaru,Ian Reid,Brandon Sutherland,Joseph Ritchie,Gabe Snow,Tim McLain*

Main category: cs.RO

TL;DR: ROSflight是一个轻量级开源无人机自动驾驶生态系统，专为研究人员设计，旨在降低无人机研究门槛并加速从仿真到硬件实验的过渡。


<details>
  <summary>Details</summary>
Motivation: 降低无人机研究门槛，加速从仿真到硬件实验的过渡，为研究人员提供轻量级、文档完善且模块化的解决方案。

Method: 从ROS 1迁移到ROS 2，改进架构模块化和可用性，包括支持硬件、底层执行器混合和仿真环境。

Result: ROSflight能够通过串行连接以400Hz频率控制多旋翼无人机，并在配套计算机上完成所有控制回路闭环。

Conclusion: 这些改进提升了ROSflight的可用性，使其能够加速先进空中机动性等领域的研究。

Abstract: ROSflight is a lean, open-source autopilot ecosystem for unmanned aerial
vehicles (UAVs). Designed by researchers for researchers, it is built to lower
the barrier to entry to UAV research and accelerate the transition from
simulation to hardware experiments by maintaining a lean (not full-featured),
well-documented, and modular codebase. This publication builds on previous
treatments and describes significant additions to the architecture that improve
the modularity and usability of ROSflight, including the transition from ROS 1
to ROS 2, supported hardware, low-level actuator mixing, and the simulation
environment. We believe that these changes improve the usability of ROSflight
and enable ROSflight to accelerate research in areas like advanced-air
mobility. Hardware results are provided, showing that ROSflight is able to
control a multirotor over a serial connection at 400 Hz while closing all
control loops on the companion computer.

</details>


### [29] [Prometheus: Universal, Open-Source Mocap-Based Teleoperation System with Force Feedback for Dataset Collection in Robot Learning](https://arxiv.org/abs/2510.01023)
*S. Satsevich,A. Bazhenov,S. Egorov,A. Erkhov,M. Gromakov,A. Fedoseev,D. Tsetserukou*

Main category: cs.RO

TL;DR: 提出了一种基于消费级HTC Vive追踪器的新型力反馈遥操作系统，用于增强任务成功率和低成本模仿学习数据收集。


<details>
  <summary>Details</summary>
Motivation: 开发一种低成本但有效的力反馈遥操作系统，使操作者能够感知抓取力，同时为大规模模仿学习提供经济实惠的数据收集解决方案。

Method: 集成HTC Vive Trackers 2.0、定制控制器、UR3机械臂和配备定制手指的Robotiq夹爪，通过嵌入式力传感器实现均匀压力分布和实时力数据反馈。

Result: 实验结果表明，该系统提高了任务成功率，并为大规模模仿学习数据收集提供了低成本解决方案。

Conclusion: 该系统成功实现了经济高效的力反馈遥操作，在保持低成本的同时提升了操作性能，为模仿学习应用提供了实用工具。

Abstract: This paper presents a novel teleoperation system with force feedback,
utilizing consumer-grade HTC Vive Trackers 2.0. The system integrates a
custom-built controller, a UR3 robotic arm, and a Robotiq gripper equipped with
custom-designed fingers to ensure uniform pressure distribution on an embedded
force sensor. Real-time compression force data is transmitted to the
controller, enabling operators to perceive the gripping force applied to
objects. Experimental results demonstrate that the system enhances task success
rates and provides a low-cost solution for large-scale imitation learning data
collection without compromising affordability.

</details>


### [30] [ROSplane 2.0: A Fixed-Wing Autopilot for Research](https://arxiv.org/abs/2510.01041)
*Ian Reid,Joseph Ritchie,Jacob Moore,Brandon Sutherland,Gabe Snow,Phillip Tokumaru,Tim McLain*

Main category: cs.RO

TL;DR: ROSplane是一个专为研究人员设计的开源固定翼无人机自主系统，基于ROS 2构建，旨在加速无人机研究，提供易于修改的框架和清晰的接口定义。


<details>
  <summary>Details</summary>
Motivation: 无人机研究需要将前沿技术集成到现有自动驾驶框架中，这个过程通常需要大量资源、时间和系统知识，因此需要一个能够降低研究门槛的解决方案。

Method: 开发了基于ROS 2的轻量级开源固定翼自主系统ROSplane，提供清晰定义的接口和易于修改的框架，支持快速集成控制、路径规划或估计算法。

Result: ROSplane显著降低了研究人员进入无人机领域的门槛，通过从ROS 1迁移到ROS 2、增强估计算法和控制算法、提高模块化程度以及改进空气动力学建模流程，加速了从仿真到真实世界测试的过渡。

Conclusion: ROSplane架构显著减少了集成新研究工具和方法所需的工作量，加快了硬件实验进程，为无人机研究提供了高效的研究平台。

Abstract: Unmanned aerial vehicle (UAV) research requires the integration of
cutting-edge technology into existing autopilot frameworks. This process can be
arduous, requiring extensive resources, time, and detailed knowledge of the
existing system. ROSplane is a lean, open-source fixed-wing autonomy stack
built by researchers for researchers. It is designed to accelerate research by
providing clearly defined interfaces with an easily modifiable framework.
Powered by ROS 2, ROSplane allows for rapid integration of low or high-level
control, path planning, or estimation algorithms. A focus on lean, easily
understood code and extensive documentation lowers the barrier to entry for
researchers. Recent developments to ROSplane improve its capacity to accelerate
UAV research, including the transition from ROS 1 to ROS 2, enhanced estimation
and control algorithms, increased modularity, and an improved aerodynamic
modeling pipeline. This aerodynamic modeling pipeline significantly reduces the
effort of transitioning from simulation to real-world testing without requiring
expensive system identification or computational fluid dynamics tools.
ROSplane's architecture reduces the effort required to integrate new research
tools and methods, expediting hardware experimentation.

</details>


### [31] [Compose Your Policies! Improving Diffusion-based or Flow-based Robot Policies via Test-time Distribution-level Composition](https://arxiv.org/abs/2510.01068)
*Jiahang Cao,Yize Huang,Hanzhong Guo,Rui Zhang,Mu Nan,Weijian Mai,Jiaxu Wang,Hao Cheng,Jingkai Sun,Gang Han,Wen Zhao,Qiang Zhang,Yijie Guo,Qihao Zheng,Chunfeng Song,Xiao Li,Ping Luo,Andrew F. Luo*

Main category: cs.RO

TL;DR: 提出了一种无需额外训练即可提升机器人控制策略性能的新方法GPC，通过组合多个预训练扩散模型的分布分数来获得优于单个策略的性能


<details>
  <summary>Details</summary>
Motivation: 扩散模型在机器人控制中表现出色，但大规模交互数据集获取成本高昂，需要找到不依赖额外训练就能提升性能的方法

Method: 提出通用策略组合(GPC)方法，通过凸组合和测试时搜索来组合多个预训练策略的分布分数，支持异构策略的组合

Result: 在Robomimic、PushT、RoboTwin等基准测试和真实机器人评估中，GPC一致提升了性能和适应性

Conclusion: GPC是一种简单有效的提升控制性能的方法，能够利用现有策略实现性能改进

Abstract: Diffusion-based models for robotic control, including vision-language-action
(VLA) and vision-action (VA) policies, have demonstrated significant
capabilities. Yet their advancement is constrained by the high cost of
acquiring large-scale interaction datasets. This work introduces an alternative
paradigm for enhancing policy performance without additional model training.
Perhaps surprisingly, we demonstrate that the composed policies can exceed the
performance of either parent policy. Our contribution is threefold. First, we
establish a theoretical foundation showing that the convex composition of
distributional scores from multiple diffusion models can yield a superior
one-step functional objective compared to any individual score. A
Gr\"onwall-type bound is then used to show that this single-step improvement
propagates through entire generation trajectories, leading to systemic
performance gains. Second, motivated by these results, we propose General
Policy Composition (GPC), a training-free method that enhances performance by
combining the distributional scores of multiple pre-trained policies via a
convex combination and test-time search. GPC is versatile, allowing for the
plug-and-play composition of heterogeneous policies, including VA and VLA
models, as well as those based on diffusion or flow-matching, irrespective of
their input visual modalities. Third, we provide extensive empirical
validation. Experiments on Robomimic, PushT, and RoboTwin benchmarks, alongside
real-world robotic evaluations, confirm that GPC consistently improves
performance and adaptability across a diverse set of tasks. Further analysis of
alternative composition operators and weighting strategies offers insights into
the mechanisms underlying the success of GPC. These results establish GPC as a
simple yet effective method for improving control performance by leveraging
existing policies.

</details>


### [32] [Real-Time Trajectory Generation and Hybrid Lyapunov-Based Control for Hopping Robots](https://arxiv.org/abs/2510.01138)
*Matthew Woodward*

Main category: cs.RO

TL;DR: 提出了一种实时计算高效的非线性阻力补偿轨迹生成方法和李雅普诺夫控制器，使跳跃机器人能够执行复杂空中轨迹并控制着陆姿态


<details>
  <summary>Details</summary>
Motivation: 现有跳跃机器人无法直接控制空中轨迹或过渡到飞行状态，丧失了跳跃系统的效率优势，需要开发能够控制复杂空中行为的系统

Method: 开发了实时计算高效的非线性阻力补偿轨迹生成方法，配合李雅普诺夫稳定性控制器

Result: 系统能够从起飞到触地在水平和垂直表面上创建并跟踪复杂空中轨迹，同时严格控制着陆时的姿态

Conclusion: 该计算高效方法适用于各种尺寸的跳跃机器人，并具有对四旋翼无人机的普遍适用性

Abstract: The advent of rotor-based hopping robots has created very capable hopping
platforms with high agility and efficiency, and similar controllability, as
compared to their purely flying quadrotor counterparts. Advances in robot
performance have increased the hopping height to greater than 4 meters and
opened up the possibility for more complex aerial trajectories (i.e.,
behaviors). However, currently hopping robots do not directly control their
aerial trajectory or transition to flight, eliminating the efficiency benefits
of a hopping system. Here we show a real-time, computationally efficiency,
non-linear drag compensated, trajectory generation methodology and accompanying
Lyapunov-based controller. The combined system can create and follow complex
aerial trajectories from liftoff to touchdown on horizontal and vertical
surfaces, while maintaining strick control over the orientation at touchdown.
The computational efficiency provides broad applicability across all size
scales of hopping robots while maintaining applicability to quadrotors in
general.

</details>
