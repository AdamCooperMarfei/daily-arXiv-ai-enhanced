<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 18]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [IMA-Catcher: An IMpact-Aware Nonprehensile Catching Framework based on Combined Optimization and Learning](https://arxiv.org/abs/2506.20801)
*Francesco Tassi,Jianzhuang Zhao,Gustavo J. G. Lahr,Luna Gava,Marco Monforte,Arren Glover,Chiara Bartolozzi,Arash Ajoudani*

Main category: cs.RO

TL;DR: 论文提出了一种隐式冲击感知框架，用于机器人在捕获飞行物体时减少冲击力和反弹，分为预捕获和后捕获两个阶段。


<details>
  <summary>Details</summary>
Motivation: 解决机器人捕获飞行物体时因高冲击力导致的任务失败和硬件损坏问题，尤其是当物体质量与机器人负载比增加时。

Method: 预捕获阶段通过实时最优规划器生成轨迹以减少冲击力；后捕获阶段基于人类演示生成轨迹以平滑消散物体能量。使用分层二次规划控制器满足约束并最小化反射质量。

Result: 实验表明，无速度匹配的任务因冲击力过大而不可行；反射质量最小化增加了方法的鲁棒性；多轴捕获验证了方法的泛化能力。

Conclusion: 提出的框架有效减少了捕获过程中的冲击力和反弹，提高了任务可行性和硬件安全性。

Abstract: Robotic catching of flying objects typically generates high impact forces
that might lead to task failure and potential hardware damages. This is
accentuated when the object mass to robot payload ratio increases, given the
strong inertial components characterizing this task. This paper aims to address
this problem by proposing an implicitly impact-aware framework that
accomplishes the catching task in both pre- and post-catching phases. In the
first phase, a motion planner generates optimal trajectories that minimize
catching forces, while in the second, the object's energy is dissipated
smoothly, minimizing bouncing. In particular, in the pre-catching phase, a
real-time optimal planner is responsible for generating trajectories of the
end-effector that minimize the velocity difference between the robot and the
object to reduce impact forces during catching. In the post-catching phase, the
robot's position, velocity, and stiffness trajectories are generated based on
human demonstrations when catching a series of free-falling objects with
unknown masses. A hierarchical quadratic programming-based controller is used
to enforce the robot's constraints (i.e., joint and torque limits) and create a
stack of tasks that minimizes the reflected mass at the end-effector as a
secondary objective. The initial experiments isolate the problem along one
dimension to accurately study the effects of each contribution on the metrics
proposed. We show how the same task, without velocity matching, would be
infeasible due to excessive joint torques resulting from the impact. The
addition of reflected mass minimization is then investigated, and the catching
height is increased to evaluate the method's robustness. Finally, the setup is
extended to catching along multiple Cartesian axes, to prove its generalization
in space.

</details>


### [2] [Online Planning for Cooperative Air-Ground Robot Systems with Unknown Fuel Requirements](https://arxiv.org/abs/2506.20804)
*Ritvik Agarwal,Behnoushsadat Hatami,Alvika Gautam,Parikshit Maini*

Main category: cs.RO

TL;DR: 论文提出了一种在线燃料受限无人机路径规划方法，结合地面移动加油站的动态调整策略。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在未知燃料消耗情况下的路径规划问题，确保任务完成。

Method: 采用两阶段解决方案：离线启发式规划初始路径，在线动态调整会合点。

Result: Gazebo模拟验证了方法的可行性，确保无人机与地面车辆路径有效性。

Conclusion: 方法能有效应对未知燃料消耗，保障任务顺利完成。

Abstract: We consider an online variant of the fuel-constrained UAV routing problem
with a ground-based mobile refueling station (FCURP-MRS), where targets incur
unknown fuel costs. We develop a two-phase solution: an offline heuristic-based
planner computes initial UAV and UGV paths, and a novel online planning
algorithm that dynamically adjusts rendezvous points based on real-time fuel
consumption during target processing. Preliminary Gazebo simulations
demonstrate the feasibility of our approach in maintaining UAV-UGV path
validity, ensuring mission completion. Link to video:
https://youtu.be/EmpVj-fjqNY

</details>


### [3] [Model-Based Real-Time Pose and Sag Estimation of Overhead Power Lines Using LiDAR for Drone Inspection](https://arxiv.org/abs/2506.20812)
*Alexandre Girard,Steven A. Parkison,Philippe Hamelin*

Main category: cs.RO

TL;DR: 论文提出了一种基于LiDAR的无人机电力线检测方法，通过最小化LiDAR测量值与整体几何模型的误差，解决了导体点少、检测不一致和干扰物区分的问题。


<details>
  <summary>Details</summary>
Motivation: 无人机检测电力线时，LiDAR传感器面临导体点少、检测不一致和干扰物区分困难等挑战。

Method: 提出一种估计方法，最小化LiDAR测量值与整体导体几何模型的误差，而非单独跟踪每根导体。

Result: 实验表明，该方法在部分观测、噪声和异常值情况下仍能准确跟踪，求解器每帧收敛时间小于50毫秒。

Conclusion: 该方法对异常点的容忍度是有效导体测量点的两倍，具有实用性和鲁棒性。

Abstract: Drones can inspect overhead power lines while they remain energized,
significantly simplifying the inspection process. However, localizing a drone
relative to all conductors using an onboard LiDAR sensor presents several
challenges: (1) conductors provide minimal surface for LiDAR beams limiting the
number of conductor points in a scan, (2) not all conductors are consistently
detected, and (3) distinguishing LiDAR points corresponding to conductors from
other objects, such as trees and pylons, is difficult. This paper proposes an
estimation approach that minimizes the error between LiDAR measurements and a
single geometric model representing the entire conductor array, rather than
tracking individual conductors separately. Experimental results, using data
from a power line drone inspection, demonstrate that this method achieves
accurate tracking, with a solver converging under 50 ms per frame, even in the
presence of partial observations, noise, and outliers. A sensitivity analysis
shows that the estimation approach can tolerate up to twice as many outlier
points as valid conductors measurements.

</details>


### [4] [Cooperative Circumnavigation for Multi-Quadrotor Systems via Onboard Sensing](https://arxiv.org/abs/2506.20954)
*Xueming Liu,Lin Li,Xiang Zhou,Qingrui Zhang,Tianjiang Hu*

Main category: cs.RO

TL;DR: 提出了一种多四旋翼系统的协作环绕框架，用于在不依赖外部定位系统的情况下包围和跟踪移动目标。


<details>
  <summary>Details</summary>
Motivation: 解决多四旋翼系统在视觉遮挡环境下对移动目标的协作跟踪问题，并提升定位和状态估计的鲁棒性。

Method: 采用异构感知策略和状态估计算法，开发改进的卡尔曼滤波器融合视觉惯性里程计和距离测量，设计事件触发的分布式卡尔曼滤波器实现目标状态估计。

Result: 通过广泛的室内外实验验证了框架在遮挡环境中的有效性，并展示了其固有的容错特性。

Conclusion: 该框架在搜索和救援等实际应用中具有潜在部署价值。

Abstract: A cooperative circumnavigation framework is proposed for multi-quadrotor
systems to enclose and track a moving target without reliance on external
localization systems. The distinct relationships between quadrotor-quadrotor
and quadrotor-target interactions are evaluated using a heterogeneous
perception strategy and corresponding state estimation algorithms. A modified
Kalman filter is developed to fuse visual-inertial odometry with range
measurements to enhance the accuracy of inter-quadrotor relative localization.
An event-triggered distributed Kalman filter is designed to achieve robust
target state estimation under visual occlusion by incorporating neighbor
measurements and estimated inter-quadrotor relative positions. Using the
estimation results, a cooperative circumnavigation controller is constructed,
leveraging an oscillator-based autonomous formation flight strategy. We conduct
extensive indoor and outdoor experiments to validate the efficiency of the
proposed circumnavigation framework in occluded environments. Furthermore, a
quadrotor failure experiment highlights the inherent fault tolerance property
of the proposed framework, underscoring its potential for deployment in
search-and-rescue operations.

</details>


### [5] [Parallels Between VLA Model Post-Training and Human Motor Learning: Progress, Challenges, and Trends](https://arxiv.org/abs/2506.20966)
*Tian-Yu Xiang,Ao-Qun Jin,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Shuang-Yi Wang,Sheng-Bin Duan,Fu-Chao Xie,Wen-Kai Wang,Si-Cheng Wang,Ling-Yun Li,Tian Tu,Zeng-Guang Hou*

Main category: cs.RO

TL;DR: 本文综述了视觉-语言-动作（VLA）模型的后训练策略，从人类运动学习的角度提出了四个维度的分类，并总结了关键挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: VLA模型在机器人操作任务中展现出泛化能力，但在高精度需求任务中存在性能差距，需通过后训练进一步优化。

Method: 通过人类运动学习的视角，提出环境、体现和任务三个维度的后训练策略分类，包括环境感知增强、体现意识提升、任务理解深化和多组件整合。

Result: 建立了VLA模型后训练的概念框架，总结了当前方法和未来趋势。

Conclusion: 本文为VLA模型的后训练提供了全面的综述和实践指导，为未来研究奠定了基础。

Abstract: Vision-language-action (VLA) models extend vision-language models (VLM) by
integrating action generation modules for robotic manipulation. Leveraging
strengths of VLM in vision perception and instruction understanding, VLA models
exhibit promising generalization across diverse manipulation tasks. However,
applications demanding high precision and accuracy reveal performance gaps
without further adaptation. Evidence from multiple domains highlights the
critical role of post-training to align foundational models with downstream
applications, spurring extensive research on post-training VLA models. VLA
model post-training aims to address the challenge of improving an embodiment's
ability to interact with the environment for the given tasks, analogous to the
process of humans motor skills acquisition. Accordingly, this paper reviews
post-training strategies for VLA models through the lens of human motor
learning, focusing on three dimensions: environments, embodiments, and tasks. A
structured taxonomy is introduced aligned with human learning mechanisms: (1)
enhancing environmental perception, (2) improving embodiment awareness, (3)
deepening task comprehension, and (4) multi-component integration. Finally, key
challenges and trends in post-training VLA models are identified, establishing
a conceptual framework to guide future research. This work delivers both a
comprehensive overview of current VLA model post-training methods from a human
motor learning perspective and practical insights for VLA model development.
(Project website: https://github.com/AoqunJin/Awesome-VLA-Post-Training)

</details>


### [6] [ThermalDiffusion: Visual-to-Thermal Image-to-Image Translation for Autonomous Navigation](https://arxiv.org/abs/2506.20969)
*Shruti Bansal,Wenshan Wang,Yifei Liu,Parv Maheshwari*

Main category: cs.RO

TL;DR: 论文提出使用条件扩散模型将RGB图像转换为热成像图像，以解决热成像数据不足的问题，促进热像仪在机器人领域的广泛应用。


<details>
  <summary>Details</summary>
Motivation: 热像仪在夜间或恶劣环境下能提供有价值的信息，但缺乏相关数据限制了其在机器人领域的应用。

Method: 采用条件扩散模型，利用自注意力机制学习真实物体的热特性，将RGB图像转换为热成像图像。

Result: 通过合成热成像数据，扩充了现有数据集，支持热像仪在场景分割、目标检测和深度估计等任务中的应用。

Conclusion: 该方法为热像仪的快速适应和广泛应用提供了可行的解决方案。

Abstract: Autonomous systems rely on sensors to estimate the environment around them.
However, cameras, LiDARs, and RADARs have their own limitations. In nighttime
or degraded environments such as fog, mist, or dust, thermal cameras can
provide valuable information regarding the presence of objects of interest due
to their heat signature. They make it easy to identify humans and vehicles that
are usually at higher temperatures compared to their surroundings. In this
paper, we focus on the adaptation of thermal cameras for robotics and
automation, where the biggest hurdle is the lack of data. Several multi-modal
datasets are available for driving robotics research in tasks such as scene
segmentation, object detection, and depth estimation, which are the cornerstone
of autonomous systems. However, they are found to be lacking in thermal
imagery. Our paper proposes a solution to augment these datasets with synthetic
thermal data to enable widespread and rapid adaptation of thermal cameras. We
explore the use of conditional diffusion models to convert existing RGB images
to thermal images using self-attention to learn the thermal properties of
real-world objects.

</details>


### [7] [Fault-Tolerant Spacecraft Attitude Determination using State Estimation Techniques](https://arxiv.org/abs/2506.21016)
*B. Chidambaram,A. Hilbert,M. Silva*

Main category: cs.RO

TL;DR: 比较扩展卡尔曼滤波、无迹卡尔曼滤波和粒子滤波在低地球轨道大型卫星姿态估计中的性能，并分析基于这些滤波器的故障检测、隔离和恢复技术。


<details>
  <summary>Details</summary>
Motivation: 研究不同滤波方法在大型卫星姿态估计中的表现，以及如何应对传感器测量中的故障问题。

Method: 使用扩展卡尔曼滤波、无迹卡尔曼滤波和粒子滤波进行姿态估计，并分析基于这些滤波器的故障检测、隔离和恢复技术。

Result: 提供了不同滤波方法在多种故障模式下的性能表现。

Conclusion: 扩展卡尔曼滤波、无迹卡尔曼滤波和粒子滤波为卫星姿态估计提供了鲁棒框架，故障检测和恢复技术进一步增强了系统的可靠性。

Abstract: The extended and unscented Kalman filter, and the particle filter provide a
robust framework for fault-tolerant attitude estimation on spacecraft. This
paper explores how each filter performs for a large satellite in a low earth
orbit. Additionally, various techniques, built on these filters, for fault
detection, isolation and recovery from erroneous sensor measurements, are
analyzed. Key results from this analysis include filter performance for various
fault modes.

</details>


### [8] [STEP Planner: Constructing cross-hierarchical subgoal tree as an embodied long-horizon task planner](https://arxiv.org/abs/2506.21030)
*Zhou Tianxing,Wang Zhirui,Ao Haojia,Chen Guangyan,Xing Boyang,Cheng Jingwen,Yang Yi,Yue Yufeng*

Main category: cs.RO

TL;DR: STEP框架通过子目标分解模型和叶节点终止模型构建子目标树，提升长时程任务规划的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在长时程任务规划中推理能力不足导致低成功率的问题。

Method: 采用分层树结构，利用基础LLM分解复杂目标为子目标，并通过实时反馈终止树扩展。

Result: 在VirtualHome WAH-NL基准和真实机器人实验中，成功率分别达到34%和25%，优于现有方法。

Conclusion: STEP框架有效提升了长时程任务规划的成功率，展示了在真实环境中的实用性。

Abstract: The ability to perform reliable long-horizon task planning is crucial for
deploying robots in real-world environments. However, directly employing Large
Language Models (LLMs) as action sequence generators often results in low
success rates due to their limited reasoning ability for long-horizon embodied
tasks. In the STEP framework, we construct a subgoal tree through a pair of
closed-loop models: a subgoal decomposition model and a leaf node termination
model. Within this framework, we develop a hierarchical tree structure that
spans from coarse to fine resolutions. The subgoal decomposition model
leverages a foundation LLM to break down complex goals into manageable
subgoals, thereby spanning the subgoal tree. The leaf node termination model
provides real-time feedback based on environmental states, determining when to
terminate the tree spanning and ensuring each leaf node can be directly
converted into a primitive action. Experiments conducted in both the
VirtualHome WAH-NL benchmark and on real robots demonstrate that STEP achieves
long-horizon embodied task completion with success rates up to 34% (WAH-NL) and
25% (real robot) outperforming SOTA methods.

</details>


### [9] [V2X-REALM: Vision-Language Model-Based Robust End-to-End Cooperative Autonomous Driving with Adaptive Long-Tail Modeling](https://arxiv.org/abs/2506.21041)
*Junwei You,Pei Li,Zhuoyu Jiang,Zilin Huang,Rui Gan,Haotian Shi,Bin Ran*

Main category: cs.RO

TL;DR: V2X-REALM是一个基于视觉语言模型的框架，用于解决自动驾驶在长尾场景中的鲁棒性问题，通过多模态学习和创新模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶在罕见、多样且视觉退化的长尾场景中的规划和决策问题，特别是在协同环境中。

Method: 提出V2X-REALM框架，包括长尾场景生成与评估、门控多场景自适应注意力模块和多任务场景感知对比学习目标。

Result: 实验表明，V2X-REALM在鲁棒性、语义推理、安全性和规划准确性上显著优于现有基线。

Conclusion: V2X-REALM提升了端到端协同自动驾驶的可扩展性，适用于复杂挑战性驾驶条件。

Abstract: Ensuring robust planning and decision-making under rare, diverse, and
visually degraded long-tail scenarios remains a fundamental challenge for
autonomous driving in urban environments. This issue becomes more critical in
cooperative settings, where vehicles and infrastructure jointly perceive and
reason across complex environments. To address this challenge, we propose
V2X-REALM, a vision-language model (VLM)-based framework with adaptive
multimodal learning for robust cooperative autonomous driving under long-tail
scenarios. V2X-REALM introduces three core innovations: (i) a prompt-driven
long-tail scenario generation and evaluation pipeline that leverages foundation
models to synthesize realistic long-tail conditions such as snow and fog across
vehicle- and infrastructure-side views, enriching training diversity
efficiently; (ii) a gated multi-scenario adaptive attention module that
modulates the visual stream using scenario priors to recalibrate ambiguous or
corrupted features; and (iii) a multi-task scenario-aware contrastive learning
objective that improves multimodal alignment and promotes cross-scenario
feature separability. Extensive experiments demonstrate that V2X-REALM
significantly outperforms existing baselines in robustness, semantic reasoning,
safety, and planning accuracy under complex, challenging driving conditions,
advancing the scalability of end-to-end cooperative autonomous driving.

</details>


### [10] [Knowledge-Driven Imitation Learning: Enabling Generalization Across Diverse Conditions](https://arxiv.org/abs/2506.21057)
*Zhuochen Miao,Jun Lv,Hongjie Fang,Yang Jin,Cewu Lu*

Main category: cs.RO

TL;DR: 提出了一种知识驱动的模仿学习框架，利用外部语义知识提升机器人操作的泛化能力，并通过语义关键点图和模板匹配算法优化性能。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在机器人操作中表现强大，但其泛化能力受限于专家演示中的对象特定依赖。

Method: 引入语义关键点图作为知识模板，开发粗到细的模板匹配算法，优化结构和语义一致性。

Result: 在三个真实机器人操作任务中表现优异，仅需四分之一的专家演示即超越基于图像的扩散策略。

Conclusion: 该工作开创了知识驱动的数据高效机器人学习方法，适用于真实场景。

Abstract: Imitation learning has emerged as a powerful paradigm in robot manipulation,
yet its generalization capability remains constrained by object-specific
dependencies in limited expert demonstrations. To address this challenge, we
propose knowledge-driven imitation learning, a framework that leverages
external structural semantic knowledge to abstract object representations
within the same category. We introduce a novel semantic keypoint graph as a
knowledge template and develop a coarse-to-fine template-matching algorithm
that optimizes both structural consistency and semantic similarity. Evaluated
on three real-world robotic manipulation tasks, our method achieves superior
performance, surpassing image-based diffusion policies with only one-quarter of
the expert demonstrations. Extensive experiments further demonstrate its
robustness across novel objects, backgrounds, and lighting conditions. This
work pioneers a knowledge-driven approach to data-efficient robotic learning in
real-world settings. Code and more materials are available on
https://knowledge-driven.github.io/.

</details>


### [11] [Control of Marine Robots in the Era of Data-Driven Intelligence](https://arxiv.org/abs/2506.21063)
*Lin Hong,Lu Liu,Zhouhua Peng,Fumin Zhang*

Main category: cs.RO

TL;DR: 综述了数据驱动智能在海洋机器人控制中的最新进展，总结了开源资源，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的控制方法在非线性、不确定性和复杂海洋环境中存在局限性，机器学习的发展为海洋机器人控制提供了新思路。

Method: 通过文献综述，分析数据驱动控制在个体和协作海洋机器人系统中的成就和开源资源。

Result: 总结了数据驱动控制在海洋机器人中的显著成果，并提供了相关开源资源。

Conclusion: 未来研究应致力于实现海洋机器人在实际应用中的高级自主性，推动数据驱动智能控制框架的发展。

Abstract: The control of marine robots has long relied on model-based methods grounded
in classical and modern control theory. However, the nonlinearity and
uncertainties inherent in robot dynamics, coupled with the complexity of marine
environments, have revealed the limitations of conventional control methods.
The rapid evolution of machine learning has opened new avenues for
incorporating data-driven intelligence into control strategies, prompting a
paradigm shift in the control of marine robots. This paper provides a review of
recent progress in marine robot control through the lens of this emerging
paradigm. The review covers both individual and cooperative marine robotic
systems, highlighting notable achievements in data-driven control of marine
robots and summarizing open-source resources that support the development and
validation of advanced control methods. Finally, several future perspectives
are outlined to guide research toward achieving high-level autonomy for marine
robots in real-world applications. This paper aims to serve as a roadmap toward
the next-generation control framework of marine robots in the era of
data-driven intelligence.

</details>


### [12] [CURL-SLAM: Continuous and Compact LiDAR Mapping](https://arxiv.org/abs/2506.21077)
*Kaicheng Zhang,Shida Xu,Yining Ding,Xianwen Kong,Sen Wang*

Main category: cs.RO

TL;DR: 提出了一种基于CURL的新型LiDAR SLAM方法CURL-SLAM，通过球形谐波隐式编码实现紧凑、连续且一致的3D地图，并在CPU上达到实时性能。


<details>
  <summary>Details</summary>
Motivation: 传统LiDAR SLAM依赖点云地图，存储需求大且难以保持一致性，CURL-SLAM旨在解决这些问题。

Method: 利用CURL的球形谐波隐式编码，将LiDAR位姿估计优化问题扩展为局部Bundle Adjustment，实现地图修正与位姿优化。

Result: 实验表明CURL-SLAM在3D地图质量和轨迹精度上达到先进水平，CPU上实现10Hz实时性能。

Conclusion: CURL-SLAM为LiDAR SLAM提供了一种高效、紧凑且一致的解决方案，并开源实现。

Abstract: This paper studies 3D LiDAR mapping with a focus on developing an updatable
and localizable map representation that enables continuity, compactness and
consistency in 3D maps. Traditional LiDAR Simultaneous Localization and Mapping
(SLAM) systems often rely on 3D point cloud maps, which typically require
extensive storage to preserve structural details in large-scale environments.
In this paper, we propose a novel paradigm for LiDAR SLAM by leveraging the
Continuous and Ultra-compact Representation of LiDAR (CURL) introduced in [1].
Our proposed LiDAR mapping approach, CURL-SLAM, produces compact 3D maps
capable of continuous reconstruction at variable densities using CURL's
spherical harmonics implicit encoding, and achieves global map consistency
after loop closure. Unlike popular Iterative Closest Point (ICP)-based LiDAR
odometry techniques, CURL-SLAM formulates LiDAR pose estimation as a unique
optimization problem tailored for CURL and extends it to local Bundle
Adjustment (BA), enabling simultaneous pose refinement and map correction.
Experimental results demonstrate that CURL-SLAM achieves state-of-the-art 3D
mapping quality and competitive LiDAR trajectory accuracy, delivering
sensor-rate real-time performance (10 Hz) on a CPU. We will release the
CURL-SLAM implementation to the community.

</details>


### [13] [UAIbot: Beginner-friendly web-based simulator for interactive robotics learning and research](https://arxiv.org/abs/2506.21178)
*Johnata Brayan,Armando Alves Neto,Pavel Petrovič,Gustavo M Freitas,Vinicius Mariano Gonçalves*

Main category: cs.RO

TL;DR: UAIbot是一个免费开源的基于网络的机器人模拟器，旨在解决传统模拟平台在教育与研究中的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决传统模拟平台在教育与研究中的不足，提供更便捷的学习与研究工具。

Method: 通过Python和JavaScript接口实现无需繁琐安装的交互式学习体验，涵盖从机械臂运动学到行人流动力学的基本原理。

Result: UAIbot成为深化学生理解、促进快速实验和增强研究传播的有效工具。

Conclusion: UAIbot为教育和研究提供了一个高效、易用的模拟平台。

Abstract: This paper presents UAIbot, a free and open-source web-based robotics
simulator designed to address the educational and research challenges
conventional simulation platforms generally face. The Python and JavaScript
interfaces of UAIbot enable accessible hands-on learning experiences without
cumbersome installations. By allowing users to explore fundamental mathematical
and physical principles interactively, ranging from manipulator kinematics to
pedestrian flow dynamics, UAIbot provides an effective tool for deepening
student understanding, facilitating rapid experimentation, and enhancing
research dissemination.

</details>


### [14] [Dynamic Risk-Aware MPPI for Mobile Robots in Crowds via Efficient Monte Carlo Approximations](https://arxiv.org/abs/2506.21205)
*Elia Trevisan,Khaled A. Mustafa,Godert Notten,Xinwei Wang,Javier Alonso-Mora*

Main category: cs.RO

TL;DR: 提出了一种动态风险感知模型预测路径积分控制（DRA-MPPI），用于实时处理动态障碍物的不确定性轨迹规划，避免机器人冻结问题并提高安全性。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以处理动态障碍物的非高斯预测轨迹和实时约束，需要一种更高效的规划方法。

Method: 利用MPPI的无梯度特性，通过蒙特卡洛方法实时近似多动态障碍物的联合碰撞概率（CP），并将其作为导航成本函数的加权目标。

Result: 实验表明，DRA-MPPI在真实和模拟环境中优于现有方法（如S-MPC、Frenet规划和原始MPPI）。

Conclusion: DRA-MPPI有效解决了动态障碍物轨迹规划中的不确定性问题，提升了安全性和实时性能。

Abstract: Deploying mobile robots safely among humans requires the motion planner to
account for the uncertainty in the other agents' predicted trajectories. This
remains challenging in traditional approaches, especially with arbitrarily
shaped predictions and real-time constraints. To address these challenges, we
propose a Dynamic Risk-Aware Model Predictive Path Integral control (DRA-MPPI),
a motion planner that incorporates uncertain future motions modelled with
potentially non-Gaussian stochastic predictions. By leveraging MPPI's
gradient-free nature, we propose a method that efficiently approximates the
joint Collision Probability (CP) among multiple dynamic obstacles for several
hundred sampled trajectories in real-time via a Monte Carlo (MC) approach. This
enables the rejection of samples exceeding a predefined CP threshold or the
integration of CP as a weighted objective within the navigation cost function.
Consequently, DRA-MPPI mitigates the freezing robot problem while enhancing
safety. Real-world and simulated experiments with multiple dynamic obstacles
demonstrate DRA-MPPI's superior performance compared to state-of-the-art
approaches, including Scenario-based Model Predictive Control (S-MPC), Frenet
planner, and vanilla MPPI.

</details>


### [15] [ACTLLM: Action Consistency Tuned Large Language Model](https://arxiv.org/abs/2506.21250)
*Jing Bi,Lianggong Bruce Wen,Zhang Liu,Chenliang Xu*

Main category: cs.RO

TL;DR: ACTLLM是一种通过语言指令增强机器人动态环境操作能力的新方法，结合视觉感知与动作一致性约束，提升任务执行效果。


<details>
  <summary>Details</summary>
Motivation: 传统视觉系统在动态环境中难以同时优化任务执行和空间推理，ACTLLM旨在通过语言接口解决这一问题。

Method: 利用语言生成结构化场景描述，引入动作一致性约束，并将马尔可夫决策过程重构为多轮视觉对话框架。

Result: ACTLLM在多样化场景中表现优异，显著提升了视觉机器人操作任务的性能。

Conclusion: ACTLLM通过语言和视觉的融合，为动态环境中的机器人操作提供了高效且适应性强的解决方案。

Abstract: This paper introduces ACTLLM (Action Consistency Tuned Large Language Model),
a novel approach for robot manipulation in dynamic environments. Traditional
vision-based systems often struggle to learn visual representations that excel
in both task execution and spatial reasoning, thereby limiting their
adaptability in dynamic environments. ACTLLM addresses these challenges by
harnessing language to craft structured scene descriptors, providing a uniform
interface for both spatial understanding and task performance through flexible
language instructions. Moreover, we introduce a novel action consistency
constraint that aligns visual perception with corresponding actions, thereby
enhancing the learning of actionable visual representations. Additionally, we
have reformulated the Markov decision process for manipulation tasks into a
multi-turn visual dialogue framework. This approach enables the modeling of
long-term task execution with enhanced contextual relevance derived from the
history of task execution. During our evaluation, ACTLLM excels in diverse
scenarios, proving its effectiveness on challenging vision-based robot
manipulation tasks.

</details>


### [16] [Active Disturbance Rejection Control for Trajectory Tracking of a Seagoing USV: Design, Simulation, and Field Experiments](https://arxiv.org/abs/2506.21265)
*Jelmer van der Saag,Elia Trevisan,Wouter Falkena,Javier Alonso-Mora*

Main category: cs.RO

TL;DR: 论文提出了一种基于ADRC的轨迹跟踪控制器，用于解决USV在不确定环境扰动下的控制问题，并通过仿真和实地测试验证其性能。


<details>
  <summary>Details</summary>
Motivation: USV在波浪和洋流等环境扰动下面临控制挑战，需要更有效的控制器。

Method: 采用ADRC方法，开发了包含真实波浪和洋流扰动的仿真模型，并在荷兰Scheveningen港和海上进行了实地测试。

Result: ADRC显著减少了轨迹跟踪误差，但增加了控制努力和能耗，海上试验中能耗进一步增加。

Conclusion: ADRC在轨迹跟踪性能上优于PID，但需权衡能耗问题。

Abstract: Unmanned Surface Vessels (USVs) face significant control challenges due to
uncertain environmental disturbances like waves and currents. This paper
proposes a trajectory tracking controller based on Active Disturbance Rejection
Control (ADRC) implemented on the DUS V2500. A custom simulation incorporating
realistic waves and current disturbances is developed to validate the
controller's performance, supported by further validation through field tests
in the harbour of Scheveningen, the Netherlands, and at sea. Simulation results
demonstrate that ADRC significantly reduces cross-track error across all tested
conditions compared to a baseline PID controller but increases control effort
and energy consumption. Field trials confirm these findings while revealing a
further increase in energy consumption during sea trials compared to the
baseline.

</details>


### [17] [Real-time Terrain Analysis for Off-road Autonomous Vehicles](https://arxiv.org/abs/2506.21347)
*Edwina Lewis,Aditya Parameshwaran,Laura Redmond,Yue Wang*

Main category: cs.RO

TL;DR: 该研究提出了一种基于贝叶斯校准的实时道路粗糙度估计系统，用于解决自动驾驶车辆因道路粗糙度变化导致的控制问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 道路粗糙度的变化会导致自动驾驶车辆偏离路线或失去路面接触，影响控制和安全。研究旨在通过实时估计粗糙度来优化车辆控制。

Method: 采用贝叶斯校准方法，结合高斯过程代理模型和半车辆模型，通过处理车辆速度和路面粗糙度参数生成轴加速度响应，并利用拉丁超立方采样生成训练数据。

Result: 实验表明，该系统能实时准确预测道路粗糙度，并通过集成的Simplex控制器动态调整车速限制，提升车辆操作安全性。

Conclusion: 该贝叶斯框架为自动驾驶车辆提供了减少粗糙度相关风险的基础，同时提高了效率和安全性。

Abstract: This research addresses critical autonomous vehicle control challenges
arising from road roughness variation, which induces course deviations and
potential loss of road contact during steering operations. We present a novel
real-time road roughness estimation system employing Bayesian calibration
methodology that processes axle accelerations to predict terrain roughness with
quantifiable confidence measures. The technical framework integrates a Gaussian
process surrogate model with a simulated half-vehicle model, systematically
processing vehicle velocity and road surface roughness parameters to generate
corresponding axle acceleration responses. The Bayesian calibration routine
performs inverse estimation of road roughness from observed accelerations and
velocities, yielding posterior distributions that quantify prediction
uncertainty for adaptive risk management. Training data generation utilizes
Latin Hypercube sampling across comprehensive velocity and roughness parameter
spaces, while the calibrated model integrates seamlessly with a Simplex
controller architecture to dynamically adjust velocity limits based on
real-time roughness predictions. Experimental validation on stochastically
generated surfaces featuring varying roughness regions demonstrates robust
real-time characterization capabilities, with the integrated Simplex control
strategy effectively enhancing autonomous vehicle operational safety through
proactive surface condition response. This innovative Bayesian framework
establishes a comprehensive foundation for mitigating roughness-related
operational risks while simultaneously improving efficiency and safety margins
in autonomous vehicle systems.

</details>


### [18] [WorldVLA: Towards Autoregressive Action World Model](https://arxiv.org/abs/2506.21539)
*Jun Cen,Chaohui Yu,Hangjie Yuan,Yuming Jiang,Siteng Huang,Jiayan Guo,Xin Li,Yibing Song,Hao Luo,Fan Wang,Deli Zhao,Hao Chen*

Main category: cs.RO

TL;DR: WorldVLA是一个自回归动作世界模型，结合了视觉-语言-动作（VLA）模型和世界模型，通过动作和图像理解预测未来图像，同时生成后续动作。实验表明其优于独立模型，但自回归动作生成性能下降，提出注意力掩码策略以改善。


<details>
  <summary>Details</summary>
Motivation: 统一动作和图像的理解与生成，通过世界模型学习环境物理特性以改进动作生成，同时利用动作模型增强视觉理解。

Method: 整合VLA模型和世界模型，利用动作和图像理解预测未来图像，生成后续动作；提出注意力掩码策略以减少自回归动作生成的误差传播。

Result: WorldVLA优于独立模型，但自回归动作生成性能下降；注意力掩码策略显著改善了动作块生成任务的表现。

Conclusion: WorldVLA展示了世界模型与动作模型的相互增强，注意力掩码策略有效解决了自回归动作生成的误差传播问题。

Abstract: We present WorldVLA, an autoregressive action world model that unifies action
and image understanding and generation. Our WorldVLA intergrates
Vision-Language-Action (VLA) model and world model in one single framework. The
world model predicts future images by leveraging both action and image
understanding, with the purpose of learning the underlying physics of the
environment to improve action generation. Meanwhile, the action model generates
the subsequent actions based on image observations, aiding in visual
understanding and in turn helps visual generation of the world model. We
demonstrate that WorldVLA outperforms standalone action and world models,
highlighting the mutual enhancement between the world model and the action
model. In addition, we find that the performance of the action model
deteriorates when generating sequences of actions in an autoregressive manner.
This phenomenon can be attributed to the model's limited generalization
capability for action prediction, leading to the propagation of errors from
earlier actions to subsequent ones. To address this issue, we propose an
attention mask strategy that selectively masks prior actions during the
generation of the current action, which shows significant performance
improvement in the action chunk generation task.

</details>
