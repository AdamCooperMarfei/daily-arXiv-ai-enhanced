<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 73]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [A Robotic Stirring Method with Trajectory Optimization and Adaptive Speed Control for Accurate Pest Counting in Water Traps](https://arxiv.org/abs/2510.21732)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.RO

TL;DR: 提出了一种基于机器人搅拌的轨迹优化和自适应速度控制方法，用于水陷阱中害虫的精确计数，通过改变害虫分布来解决遮挡问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于图像的害虫计数方法在处理害虫遮挡情况时存在局限性，需要一种能够改善害虫分布以提高计数准确性的解决方案。

Method: 开发了基于机械臂的自动搅拌系统，设计了六种代表性搅拌轨迹，通过比较计数误差和置信度选择最优轨迹，并提出了基于计数置信度的闭环控制系统实现自适应速度搅拌。

Result: 实验结果表明该方法能够有效提高害虫计数的准确性，特别是在处理遮挡情况时表现优异。

Conclusion: 这是首个研究不同搅拌轨迹对动态液体环境中物体计数影响的工作，成功实现了自适应速度搅拌，为精确农业中的害虫监测提供了有效解决方案。

Abstract: Accurate monitoring of pest population dynamics is crucial for informed
decision-making in precision agriculture. Currently, mainstream image-based
pest counting methods primarily rely on image processing combined with machine
learning or deep learning for pest counting. However, these methods have
limitations and struggle to handle situations involving pest occlusion. To
address this issue, this paper proposed a robotic stirring method with
trajectory optimization and adaptive speed control for accurate pest counting
in water traps. First, we developed an automated stirring system for pest
counting in yellow water traps based on a robotic arm. Stirring alters the
distribution of pests in the yellow water trap, making some of the occluded
individuals visible for detection and counting. Then, we investigated the
impact of different stirring trajectories on pest counting performance and
selected the optimal trajectory for pest counting. Specifically, we designed
six representative stirring trajectories, including circle, square, triangle,
spiral, four small circles, and random lines, for the robotic arm to stir. And
by comparing the overall average counting error and counting confidence of
different stirring trajectories across various pest density scenarios, we
determined the optimal trajectory. Finally, we proposed a counting
confidence-driven closed-loop control system to achieve adaptive-speed
stirring. It uses changes in pest counting confidence between consecutive
frames as feedback to adjust the stirring speed. To the best of our knowledge,
this is the first study dedicated to investigating the effects of different
stirring trajectories on object counting in the dynamic liquid environment and
to implement adaptive-speed stirring for this type of task. Experimental
results show ...

</details>


### [2] [Force-Displacement Profiling for Robot-Assisted Deployment of a Left Atrial Appendage Occluder Using FBG-EM Distal Sensing](https://arxiv.org/abs/2510.21734)
*Giovanni Battista Regazzo,Wim-Alexander Beckers,Xuan Thao Ha,Mouloud Ourak,Johan Vlekken,Emmanuel Vander Poorten*

Main category: cs.RO

TL;DR: 提出了一种基于力传感导管和电磁跟踪的机器人辅助左心耳封堵术新方法，通过力-位移分析实现无辐射的手术步骤识别，减少对传统成像方式的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统左心耳封堵术依赖荧光透视和经食道超声心动图，存在辐射暴露和定位精度有限的问题，需要更安全精确的术中反馈方法。

Method: 使用集成光纤布拉格光栅的力传感导管结合电磁跟踪，在解剖模型中进行机器人辅助封堵器部署，通过力-位移分析识别手术步骤。

Result: 力剖面显示低幅度的相互作用力，表明对周围解剖结构机械应力最小，该方法能有效识别关键手术步骤。

Conclusion: 该传感策略有望为临床医生提供增强的术中反馈，改善部署结果，未来将专注于自动化步骤分类和在动态环境中的验证。

Abstract: Atrial fibrillation (AF) increases the risk of thromboembolic events due to
impaired function of the left atrial appendage (LAA). Left atrial appendage
closure (LAAC) is a minimally invasive intervention designed to reduce stroke
risk by sealing the LAA with an expandable occluder device. Current deployment
relies on manual catheter control and imaging modalities like fluoroscopy and
transesophageal echocardiography, which carry limitations including radiation
exposure and limited positioning precision. In this study, we leverage a
previously developed force-sensing delivery sheath integrating fiber Bragg
gratings (FBGs) at the interface between the catheter and the occluder.
Combined with electromagnetic (EM) tracking, this setup enables real-time
measurement of interaction forces and catheter tip position during
robot-assisted LAAC deployment in an anatomical phantom. We present a novel
force-displacement profiling method that characterizes occluder deployment
dynamics and identifies key procedural steps without relying on ionizing
radiation. The force profiles reveal low-magnitude interaction forces,
suggesting minimal mechanical stress on the surrounding anatomy. This approach
shows promise in providing clinicians with enhanced intraoperative feedback,
improving deployment outcome. Future work will focus on automating deployment
steps classification and validating the sensing strategy in dynamic, realistic
environments.

</details>


### [3] [A phase-aware AI car-following model for electric vehicles with adaptive cruise control: Development and validation using real-world data](https://arxiv.org/abs/2510.21735)
*Yuhui Liu,Shian Wang,Ansel Panicker,Kate Embry,Ayana Asanova,Tianyi Li*

Main category: cs.RO

TL;DR: 开发并验证了针对电动汽车的相位感知AI跟车模型，该模型结合物理基础和AI组件，能识别并适应不同驾驶阶段，显著提高了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统微观模型能有效描述内燃机车辆驾驶行为，但缺乏准确描述电动汽车独特跟车动力学的建模框架。随着电动汽车在交通中的日益普及，开发易于使用且准确的分析模型至关重要。

Method: 提出相位感知AI跟车模型，在传统物理基础框架上增强AI组件，识别和适应快速加速和再生制动等不同驾驶阶段。使用配备自适应巡航控制车辆的真实轨迹数据进行全面仿真验证。

Result: 数值结果表明，PAAI模型相比传统跟车模型显著提高了预测准确性，为交通仿真中准确表示电动汽车行为提供了有效工具。

Conclusion: 该研究成功开发了专门针对电动汽车的相位感知AI跟车模型，填补了现有建模框架的空白，为准确模拟电动汽车在交通中的行为提供了有效解决方案。

Abstract: Internal combustion engine (ICE) vehicles and electric vehicles (EVs) exhibit
distinct vehicle dynamics. EVs provide rapid acceleration, with electric motors
producing peak power across a wider speed range, and achieve swift deceleration
through regenerative braking. While existing microscopic models effectively
capture the driving behavior of ICE vehicles, a modeling framework that
accurately describes the unique car-following dynamics of EVs is lacking.
Developing such a model is essential given the increasing presence of EVs in
traffic, yet creating an easy-to-use and accurate analytical model remains
challenging.
  To address these gaps, this study develops and validates a Phase-Aware AI
(PAAI) car-following model specifically for EVs. The proposed model enhances
traditional physics-based frameworks with an AI component that recognizes and
adapts to different driving phases, such as rapid acceleration and regenerative
braking. Using real-world trajectory data from vehicles equipped with adaptive
cruise control (ACC), we conduct comprehensive simulations to validate the
model's performance. The numerical results demonstrate that the PAAI model
significantly improves prediction accuracy over traditional car-following
models, providing an effective tool for accurately representing EV behavior in
traffic simulations.

</details>


### [4] [Learn2Drive: A neural network-based framework for socially compliant automated vehicle control](https://arxiv.org/abs/2510.21736)
*Yuhui Liu,Samannita Halder,Shian Wang,Tianyi Li*

Main category: cs.RO

TL;DR: 提出基于LSTM网络和物理约束的自适应巡航控制框架，通过社会价值取向(SVO)使自动驾驶车辆考虑对人工驾驶车辆和交通流的影响，作为移动交通调节器提升整体交通效率。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶控制策略主要关注单个车辆或车队的性能优化，忽略了与人工驾驶车辆的交互及对整体交通流的影响，这可能导致拥堵加剧和系统效率降低。

Method: 采用神经网络基础的社会合规自动驾驶控制框架，结合社会价值取向(SVO)，为自动驾驶车辆和人工驾驶车辆定义效用函数，基于SVO平衡控制目标与交通流考虑。

Result: 当自动驾驶车辆控制模式从优先考虑能耗转向优化交通流效率时，跟随车队车辆的个体能耗至少增加58.99%，同时个体平均速度至少提升38.39%，表明交通动态显著改善。

Conclusion: 所提出的方法能有效适应不同交通条件，通过自动驾驶车辆作为移动交通调节器，促进适应性驾驶行为，减少拥堵、提高交通效率并降低能耗。

Abstract: This study introduces a novel control framework for adaptive cruise control
(ACC) in automated driving, leveraging Long Short-Term Memory (LSTM) networks
and physics-informed constraints. As automated vehicles (AVs) adopt advanced
features like ACC, transportation systems are becoming increasingly intelligent
and efficient. However, existing AV control strategies primarily focus on
optimizing the performance of individual vehicles or platoons, often neglecting
their interactions with human-driven vehicles (HVs) and the broader impact on
traffic flow. This oversight can exacerbate congestion and reduce overall
system efficiency. To address this critical research gap, we propose a neural
network-based, socially compliant AV control framework that incorporates social
value orientation (SVO). This framework enables AVs to account for their
influence on HVs and traffic dynamics. By leveraging AVs as mobile traffic
regulators, the proposed approach promotes adaptive driving behaviors that
reduce congestion, improve traffic efficiency, and lower energy consumption.
Within this framework, we define utility functions for both AVs and HVs, which
are optimized based on the SVO of each AV to balance its own control objectives
with broader traffic flow considerations. Numerical results demonstrate the
effectiveness of the proposed method in adapting to varying traffic conditions,
thereby enhancing system-wide efficiency. Specifically, when the AV's control
mode shifts from prioritizing energy consumption to optimizing traffic flow
efficiency, vehicles in the following platoon experience at least a 58.99%
increase in individual energy consumption alongside at least a 38.39%
improvement in individual average speed, indicating significant enhancements in
traffic dynamics.

</details>


### [5] [Next-Generation LLM for UAV: From Natural Language to Autonomous Flight](https://arxiv.org/abs/2510.21739)
*Liangqi Yuan,Chuhao Deng,Dong-Jun Han,Inseok Hwang,Sabine Brunswicker,Christopher G. Brinton*

Main category: cs.RO

TL;DR: 本文提出了NeLV系统，将大语言模型集成到多尺度无人机操作中，通过五个技术组件处理自然语言指令来协调短、中、长距离无人机任务，并建立了五级自动化分类法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在无人机应用中的研究主要局限于小规模应用，缺乏对中长距离无人机系统在真实操作环境中的全面研究，大型无人机平台面临起降程序、法规遵从和特殊操作能力等独特挑战。

Method: NeLV系统包含五个关键技术组件：LLM解析器用于指令解释、路线规划器确定兴趣点、路径规划器生成航点、控制平台实现可执行轨迹、无人机监控。通过三个代表性用例验证系统可行性。

Result: 系统通过多无人机巡逻、多兴趣点配送和多跳迁移三个用例证明了可行性，并建立了从当前LLM解析器能力到完全自主LLM自动驾驶系统的五级自动化演进路径。

Conclusion: NeLV系统展示了LLM在多尺度无人机操作中的集成潜力，提出的五级自动化分类法为未来LLM在无人机领域的自主化发展提供了路线图和技术挑战识别。

Abstract: With the rapid advancement of Large Language Models (LLMs), their
capabilities in various automation domains, particularly Unmanned Aerial
Vehicle (UAV) operations, have garnered increasing attention. Current research
remains predominantly constrained to small-scale UAV applications, with most
studies focusing on isolated components such as path planning for toy drones,
while lacking comprehensive investigation of medium- and long-range UAV systems
in real-world operational contexts. Larger UAV platforms introduce distinct
challenges, including stringent requirements for airport-based take-off and
landing procedures, adherence to complex regulatory frameworks, and specialized
operational capabilities with elevated mission expectations. This position
paper presents the Next-Generation LLM for UAV (NeLV) system -- a comprehensive
demonstration and automation roadmap for integrating LLMs into multi-scale UAV
operations. The NeLV system processes natural language instructions to
orchestrate short-, medium-, and long-range UAV missions through five key
technical components: (i) LLM-as-Parser for instruction interpretation, (ii)
Route Planner for Points of Interest (POI) determination, (iii) Path Planner
for waypoint generation, (iv) Control Platform for executable trajectory
implementation, and (v) UAV monitoring. We demonstrate the system's feasibility
through three representative use cases spanning different operational scales:
multi-UAV patrol, multi-POI delivery, and multi-hop relocation. Beyond the
current implementation, we establish a five-level automation taxonomy that
charts the evolution from current LLM-as-Parser capabilities (Level 1) to fully
autonomous LLM-as-Autopilot systems (Level 5), identifying technical
prerequisites and research challenges at each stage.

</details>


### [6] [FORGE-Tree: Diffusion-Forcing Tree Search for Long-Horizon Robot Manipulation](https://arxiv.org/abs/2510.21744)
*Yanjia Huang,Shuo Liu,Sheng Liu,Qingxiao Xu,Mingyang Wu,Xiangbo Gao,Zhengzhong Tu*

Main category: cs.RO

TL;DR: FORGE-Tree通过结合阶段对齐的扩散强制头和测试时蒙特卡洛树扩散，解决了VLA策略在长程机器人操作任务中的漂移和暴露偏差问题，将轨迹优化转化为局部编辑序列。


<details>
  <summary>Details</summary>
Motivation: 长程机器人操作任务中，VLA策略面临漂移和暴露偏差问题，现有方法使用固定超参数对整个轨迹去噪，导致小几何误差在阶段间累积，且无法在紧约束区域分配额外计算资源。

Method: FORGE-Tree包含阶段对齐的扩散强制头和测试时蒙特卡洛树扩散，使用冻结的VLA编码器将时间步对齐到子任务阶段，在推理时仅对目标片段进行部分去噪，同时保持其他标记冻结。通过场景图提供先验进行扩展和基于几何关系的评分。

Result: 在LIBERO基准测试中，FORGE-Tree相比原生VLA基线（OpenVLA和Octo-Base）将成功率提高了13.4到17.2个百分点，在可比较的计算预算下增益保持一致，特别是在长程变体上表现突出。

Conclusion: FORGE-Tree通过树结构去噪方法有效解决了VLA策略在长程机器人操作中的轨迹优化问题，其性能随搜索预算扩展而提升，同时保持已执行前缀不变。

Abstract: Long-horizon robot manipulation tasks remain challenging for
Vision-Language-Action (VLA) policies due to drift and exposure bias, often
denoise the entire trajectory with fixed hyperparameters, causing small
geometric errors to compound across stages and offering no mechanism to
allocate extra test-time compute where clearances are tight. To address these
challenges, we introduce FORGE-Tree, a plug-in control layer that couples a
stage-aligned Diffusion Forcing (DF) head with test-time Monte Carlo Tree
Diffusion (MCTD). With a frozen VLA encoder, DF aligns timesteps to subtask
stages; during inference we partially denoise only a target segment while
keeping other tokens frozen, turning trajectory refinement into a sequence of
local edits. We then apply Monte Carlo Tree Diffusion to select the next
segment to refine. A scene graph supplies priors for expansion and geometry
relation-aware scoring for rollouts, yielding tree-structured denoising whose
performance scales with search budget while preserving the executed prefix.
Evaluation on LIBERO, FORGE-Tree improves success rate by 13.4 to 17.2 pp over
the native VLA baselines with both OpenVLA and Octo-Base. Gains remain
consistent under comparable compute budgets, especially on long-horizon
variants. Videos available at: https://taco-group.github.io/FORGE-Tree/

</details>


### [7] [Avi: Action from Volumetric Inference](https://arxiv.org/abs/2510.21746)
*Harris Song,Long Le*

Main category: cs.RO

TL;DR: Avi是一种新颖的3D视觉-语言-动作架构，将机器人动作生成重新定义为3D感知和空间推理问题，而非低级策略学习。它利用3D点云和语言基础场景理解，通过经典几何变换计算动作。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要基于2D视觉输入，通过端到端训练学习特定任务的动作策略。Avi旨在通过3D表示和结构化推理，弥合高级语言指令与低级执行之间的差距，无需不透明的策略学习。

Method: 基于3D多模态大语言模型生成下一个点云，通过经典几何变换显式计算动作。不训练动作标记，而是利用3D感知和空间推理来推导动作。

Result: 该方法能够产生对遮挡、相机姿态变化和视角变化具有鲁棒性的泛化行为。初步结果显示了3D视觉语言推理作为可扩展、鲁棒机器人系统基础的潜力。

Conclusion: Avi通过将机器人决策过程视为对3D表示的结构化推理任务，为构建可扩展、鲁棒的机器人系统提供了新的基础框架。

Abstract: We propose Avi, a novel 3D Vision-Language-Action (VLA) architecture that
reframes robotic action generation as a problem of 3D perception and spatial
reasoning, rather than low-level policy learning. While existing VLA models
primarily operate on 2D visual inputs and are trained end-to-end on
task-specific action policies, Avi leverages 3D point clouds and
language-grounded scene understanding to compute actions through classical
geometric transformations. Most notably, Avi does not train on previous action
tokens, rather, we build upon a 3D Multi-modal Large Language Model (MLLM) to
generate the next point cloud and explicitly calculate the actions through
classical transformations. This approach enables generalizable behaviors that
are robust to occlusions, camera pose variations, and changes in viewpoint. By
treating the robotic decision-making process as a structured reasoning task
over 3D representations, Avi bridges the gap between high-level language
instructions and low-level actuation without requiring opaque policy learning.
Our preliminary results highlight the potential of 3D vision-language reasoning
as a foundation for scalable, robust robotic systems. Check it out at
https://avi-3drobot.github.io/.

</details>


### [8] [Real-time Mixed-Integer Quadratic Programming for Driving Behavior-Inspired Speed Bump Optimal Trajectory Planning](https://arxiv.org/abs/2510.21751)
*Van Nam Dinh,Van Vy Phan,Thai Son Dang,Van Du Phan,The Anh Mai,Van Chuong Le,Sy Phuong Ho,Dinh Tu Duong,Hung Cuong Ta*

Main category: cs.RO

TL;DR: 提出了一种基于混合整数二次规划和模型预测控制的自动驾驶轨迹规划方法，专门优化车辆通过减速带时的乘客舒适度和行驶效率。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶车辆在城市环境中通过减速带时的轨迹规划挑战，需要同时考虑乘客舒适度、行驶效率和人类驾驶行为模拟。

Method: 使用混合整数二次规划框架和模型预测控制，开发了模拟人类驾驶行为的减速带处理约束，并将其与道路导航要求无缝集成。

Result: 在多种城市驾驶环境中的模拟测试表明，该方法能够确保车辆平稳通过减速带，同时保持适合实时部署的计算效率。

Conclusion: 该方法能够同时处理静态道路特征和动态约束，并模拟专家人类驾驶行为，代表了城市轨迹规划领域的重要进展。

Abstract: This paper proposes a novel methodology for trajectory planning in autonomous
vehicles (AVs), addressing the complex challenge of negotiating speed bumps
within a unified Mixed-Integer Quadratic Programming (MIQP) framework. By
leveraging Model Predictive Control (MPC), we develop trajectories that
optimize both the traversal of speed bumps and overall passenger comfort. A key
contribution of this work is the formulation of speed bump handling constraints
that closely emulate human driving behavior, seamlessly integrating these with
broader road navigation requirements. Through extensive simulations in varied
urban driving environments, we demonstrate the efficacy of our approach,
highlighting its ability to ensure smooth speed transitions over speed bumps
while maintaining computational efficiency suitable for real-time deployment.
The method's capability to handle both static road features and dynamic
constraints, alongside expert human driving, represents a significant step
forward in trajectory planning for urban

</details>


### [9] [Taxonomy and Trends in Reinforcement Learning for Robotics and Control Systems: A Structured Review](https://arxiv.org/abs/2510.21758)
*Kumater Ter,RexCharles Donatus,Ore-Ofe Ajayi,Daniel Udekwe*

Main category: cs.RO

TL;DR: 本文对强化学习在机器人领域的应用进行了全面回顾，涵盖了从MDP基础到深度强化学习算法的理论原理、算法分类和应用领域。


<details>
  <summary>Details</summary>
Motivation: 随着强化学习在动态不确定环境中展现智能机器人行为的潜力日益增长，需要系统梳理RL的理论进展与实际机器人应用的结合点。

Method: 采用结构化分类法，基于马尔可夫决策过程形式化，分析actor-critic方法、基于价值的学习和策略梯度等核心算法，重点研究DDPG、TD3、PPO、SAC等现代深度强化学习技术。

Result: 建立了涵盖运动控制、操作任务、多智能体协调和人机交互等领域的RL应用分类体系，总结了训练方法和部署成熟度评估框架。

Conclusion: 该综述工作旨在连接理论进展与实际实现，为强化学习在自主机器人系统中的发展提供了整合性视角，展示了RL在真实世界机器人应用中的日益成熟。

Abstract: Reinforcement learning (RL) has become a foundational approach for enabling
intelligent robotic behavior in dynamic and uncertain environments. This work
presents an in-depth review of RL principles, advanced deep reinforcement
learning (DRL) algorithms, and their integration into robotic and control
systems. Beginning with the formalism of Markov Decision Processes (MDPs), the
study outlines essential elements of the agent-environment interaction and
explores core algorithmic strategies including actor-critic methods,
value-based learning, and policy gradients. Emphasis is placed on modern DRL
techniques such as DDPG, TD3, PPO, and SAC, which have shown promise in solving
high-dimensional, continuous control tasks. A structured taxonomy is introduced
to categorize RL applications across domains such as locomotion, manipulation,
multi-agent coordination, and human-robot interaction, along with training
methodologies and deployment readiness levels. The review synthesizes recent
research efforts, highlighting technical trends, design patterns, and the
growing maturity of RL in real-world robotics. Overall, this work aims to
bridge theoretical advances with practical implementations, providing a
consolidated perspective on the evolving role of RL in autonomous robotic
systems.

</details>


### [10] [J-ORA: A Framework and Multimodal Dataset for Japanese Object Identification, Reference, Action Prediction in Robot Perception](https://arxiv.org/abs/2510.21761)
*Jesse Atuhurra,Hidetaka Kamigaito,Taro Watanabe,Koichiro Yoshino*

Main category: cs.RO

TL;DR: J-ORA是一个新颖的多模态数据集，通过提供日语人机对话场景中的详细物体属性标注，填补了机器人感知领域的空白，显著提升了多模态感知性能。


<details>
  <summary>Details</summary>
Motivation: 解决机器人感知中缺乏详细物体属性标注的问题，特别是在日语人机对话场景下，支持物体识别、指代消解和下一动作预测等关键任务。

Method: 创建J-ORA数据集，包含详细的物体属性模板（类别、颜色、形状、大小、材质和空间关系），并使用专有和开源视觉语言模型进行广泛评估。

Result: 加入详细物体属性显著提升了多模态感知性能，但专有模型和开源模型之间仍存在差距；不同模型在理解物体功能和上下文关系方面能力各异。

Conclusion: 丰富、上下文敏感的属性标注对于推进动态环境中的机器人感知至关重要，J-ORA数据集为此提供了重要资源。

Abstract: We introduce J-ORA, a novel multimodal dataset that bridges the gap in robot
perception by providing detailed object attribute annotations within Japanese
human-robot dialogue scenarios. J-ORA is designed to support three critical
perception tasks, object identification, reference resolution, and next-action
prediction, by leveraging a comprehensive template of attributes (e.g.,
category, color, shape, size, material, and spatial relations). Extensive
evaluations with both proprietary and open-source Vision Language Models (VLMs)
reveal that incorporating detailed object attributes substantially improves
multimodal perception performance compared to without object attributes.
Despite the improvement, we find that there still exists a gap between
proprietary and open-source VLMs. In addition, our analysis of object
affordances demonstrates varying abilities in understanding object
functionality and contextual relationships across different VLMs. These
findings underscore the importance of rich, context-sensitive attribute
annotations in advancing robot perception in dynamic environments. See project
page at https://jatuhurrra.github.io/J-ORA/.

</details>


### [11] [Improving the performance of AI-powered Affordable Robotics for Assistive Tasks](https://arxiv.org/abs/2510.21771)
*Dharunish Yugeswardeenoo*

Main category: cs.RO

TL;DR: 开发低成本机器人手臂，通过模仿学习实现辅助护理任务，使用PACT和TE方法提升性能，在真实测试中达到90%以上任务准确率


<details>
  <summary>Details</summary>
Motivation: 到2050年全球辅助护理需求将达到35亿人，远超人类护理人员供应，现有机器人方案昂贵且需要专业技术，限制了可及性

Method: 使用模仿学习从演示视频学习，无需任务特定编程；采用PACT捕捉时间依赖性和分割运动动态，TE方法优化轨迹；包含6个伺服电机、双摄像头和3D打印夹爪

Result: 在五个模型规模和四种架构评估中，系统达到超过90%任务准确率，比基线高40%；PACT实现5倍模型大小缩减同时保持75%准确率；显著性分析显示依赖关键视觉线索

Conclusion: 该系统为低成本辅助护理机器人提供了可行方案，未来将探索双手操作和移动性以扩展辅助能力

Abstract: By 2050, the global demand for assistive care is expected to reach 3.5
billion people, far outpacing the availability of human caregivers. Existing
robotic solutions remain expensive and require technical expertise, limiting
accessibility. This work introduces a low-cost robotic arm for assistive tasks
such as feeding, cleaning spills, and fetching medicine. The system uses
imitation learning from demonstration videos, requiring no task-specific
programming or manual labeling. The robot consists of six servo motors, dual
cameras, and 3D-printed grippers. Data collection via teleoperation with a
leader arm yielded 50,000 video frames across the three tasks. A novel Phased
Action Chunking Transformer (PACT) captures temporal dependencies and segments
motion dynamics, while a Temporal Ensemble (TE) method refines trajectories to
improve accuracy and smoothness. Evaluated across five model sizes and four
architectures, with ten hours of real-world testing, the system achieved over
90% task accuracy, up to 40% higher than baselines. PACT enabled a 5x model
size reduction while maintaining 75% accuracy. Saliency analysis showed
reliance on key visual cues, and phase token gradients peaked at critical
trajectory moments, indicating effective temporal reasoning. Future work will
explore bimanual manipulation and mobility for expanded assistive capabilities.

</details>


### [12] [Real-Time QP Solvers: A Concise Review and Practical Guide Towards Legged Robots](https://arxiv.org/abs/2510.21773)
*Van Nam Dinh*

Main category: cs.RO

TL;DR: 本文对腿式机器人中使用的二次规划求解器进行了全面分析和基准测试，比较了四种主要算法方法在不同性能指标下的表现，为求解器选择提供实用指导。


<details>
  <summary>Details</summary>
Motivation: 二次规划在腿式机器人的实时状态估计、运动规划和控制中至关重要，需要在嵌入式平台上满足严格的时间、能耗和计算限制，因此需要可靠的求解器。

Method: 将求解器分为内点法、活动集策略、算子分裂方案和增广拉格朗日方法四类，分析算法结构、计算特性、问题结构利用和热启动能力，使用公开基准测试评估性能。

Result: 性能评估显示不同求解器在计算时间、约束满足和扰动鲁棒性方面各有优劣，稀疏内点法适合长时域MPC，密集活动集方法适合高频WBC。

Conclusion: 研究强调了求解器、任务和硬件之间的协同作用，为敏捷自主腿式系统的发展提供了求解器选择指导，并扩展到非凸和分布式二次规划问题。

Abstract: Quadratic programming (QP) underpins real-time robotics by enabling
efficient, constrained optimization in state estimation, motion planning, and
control. In legged locomotion and manipulation, essential modules like inverse
dynamics, Model Predictive Control (MPC), and Whole-Body Control (WBC) are
inherently QP-based, demanding reliable solutions amid tight timing, energy,
and computational limits on embedded platforms. This paper presents a
comprehensive analysis and benchmarking study of cutting-edge QP solvers for
legged robotics. We begin by formulating the standard convex QP and classify
solvers into four principal algorithmic approaches, including interior-point
methods, active-set strategies, operator splitting schemes, and augmented
Lagrangian approaches. Each solver is examined in terms of algorithmic
structure, computational characteristics, and its ability to exploit problem
structure and warm-starting. Performance is evaluated using publicly available
benchmarks, focusing on metrics such as computation time, constraint
satisfaction, and robustness under perturbations. Feature tables and
comparisons yield practical guidance for solver selection, underscoring
trade-offs in speed, accuracy, and energy efficiency. Our findings emphasize
the synergy between solver, task, and hardware, sparse IPMs for long-horizon
MPC, and dense active-set for high frequency WBC to advance agile, autonomous
legged systems, with emerging extensions to nonconvex and distributed QP.

</details>


### [13] [VITA-E: Natural Embodied Interaction with Concurrent Seeing, Hearing, Speaking, and Acting](https://arxiv.org/abs/2510.21817)
*Xiaoyu Liu,Chaoyou Fu,Chi Yan,Chu Wu,Haihan Gao,Yi-Fan Zhang,Shaoqi Dong,Cheng Qian,Bin Luo,Xiuyong Yang,Guanwu Li,Yusheng Cai,Yunhang Shen,Deqiang Jiang,Haoyu Cao,Xing Sun,Caifeng Shan,Ran He*

Main category: cs.RO

TL;DR: VITA-E是一个支持行为并发和实时中断的具身交互框架，采用双模型架构实现观察、聆听、说话和执行的并行处理。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型受限于僵化的静态交互范式，无法同时观察、聆听、说话和执行动作，也不能处理实时用户中断，导致具身协作体验不流畅。

Method: 采用双模型架构，两个并行VLA实例分别作为“活动模型”和“待机模型”，并提出了“模型即控制器”范式，通过微调VLM生成特殊令牌作为系统级命令。

Result: 在物理人形平台上进行的实验表明，VITA-E能可靠处理复杂交互场景，在紧急停止和语音中断方面达到极高成功率，并能成功执行并发语音和动作。

Conclusion: 该框架代表了向更自然、更强大的具身助手迈出的重要一步，兼容多种双系统VLA模型。

Abstract: Current Vision-Language-Action (VLA) models are often constrained by a rigid,
static interaction paradigm, which lacks the ability to see, hear, speak, and
act concurrently as well as handle real-time user interruptions dynamically.
This hinders seamless embodied collaboration, resulting in an inflexible and
unresponsive user experience. To address these limitations, we introduce
VITA-E, a novel embodied interaction framework designed for both behavioral
concurrency and nearly real-time interruption. The core of our approach is a
dual-model architecture where two parallel VLA instances operate as an ``Active
Model'' and a ``Standby Model'', allowing the embodied agent to observe its
environment, listen to user speech, provide verbal responses, and execute
actions, all concurrently and interruptibly, mimicking human-like multitasking
capabilities. We further propose a ``model-as-controller'' paradigm, where we
fine-tune the VLM to generate special tokens that serve as direct system-level
commands, coupling the model's reasoning with the system's behavior.
Experiments conducted on a physical humanoid platform demonstrate that VITA-E
can reliably handle complex interactive scenarios. Our framework is compatible
with various dual-system VLA models, achieving an extremely high success rate
on emergency stops and speech interruptions while also successfully performing
concurrent speech and action. This represents a significant step towards more
natural and capable embodied assistants.

</details>


### [14] [A Literature Review On Stewart-Gough Platform Calibrations A Literature Review On Stewart-Gough Platform Calibrations](https://arxiv.org/abs/2510.21854)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本文综述了Stewart-Gough平台（六足平台）的校准方法，重点关注基于逆运动学的校准技术，分析了各种校准方法的优缺点和考虑的关键误差源。


<details>
  <summary>Details</summary>
Motivation: Stewart-Gough平台在医疗、工程、空间研究等关键应用中需要微米和纳米级别的精确运动控制，因此高精度校准至关重要。传统的正向运动学校准方法过于复杂，而逆运动学校准则更为简便有效。

Method: 通过使用外部仪器、约束系统运动、添加额外传感器等多种校准方法进行实验，重点关注基于逆运动学的并行机器人校准技术。

Result: 研究发现研究人员主要关注提高平台位置和方向精度，考虑单一或多个误差源，主要误差源包括运动学和结构误差，在某些情况下也考虑环境因素，但校准通常在无负载条件下进行。

Conclusion: 本文综述了Stewart-Gough平台校准领域的最新技术进展，重点突出了校准过程中考虑的关键流程和误差因素。

Abstract: Researchers have studied Stewart-Gough platforms, also known as Gough-Stewart
platforms or hexapod platforms extensively for their inherent fine control
characteristics. Their studies led to the potential deployment opportunities of
Stewart-Gough Platforms in many critical applications such as the medical
field, engineering machines, space research, electronic chip manufacturing,
automobile manufacturing, etc. Some of these applications need micro and
nano-level movement control in 3D space for the motions to be precise,
complicated, and repeatable; a Stewart-Gough platform fulfills these challenges
smartly. For this, the platform must be more accurate than the specified
application accuracy level and thus proper calibration for a parallel robot is
crucial. Forward kinematics-based calibration for these hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To experiment with different calibration techniques, various
calibration approaches were implemented by using external instruments,
constraining one or more motions of the system, and using extra sensors for
auto or self-calibration. This survey paid attention to those key
methodologies, their outcome, and important details related to inverse
kinematic-based parallel robot calibrations. It was observed during this study
that the researchers focused on improving the accuracy of the platform position
and orientation considering the errors contributed by one source or multiple
sources. The error sources considered are mainly kinematic and structural, in
some cases, environmental factors also are reviewed, however, those
calibrations are done under no-load conditions. This study aims to review the
present state of the art in this field and highlight the processes and errors
considered for the calibration of Stewart-Gough platforms.

</details>


### [15] [Butter-Bench: Evaluating LLM Controlled Robots for Practical Intelligence](https://arxiv.org/abs/2510.21860)
*Callum Sharrock,Lukas Petersson,Hanna Petersson,Axel Backlund,Axel Wennström,Kristoffer Nordström,Elias Aronsson*

Main category: cs.RO

TL;DR: Butter-Bench是一个评估大语言模型控制机器人实际智能的基准测试，发现人类表现（95%）远超最佳LLM（40%），特别是在多步骤空间规划和社交理解方面。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在物理世界实际智能中的表现，当前机器人系统采用分层架构，但LLM在需要处理物理世界复杂性的任务中表现如何尚不清楚。

Method: 开发Butter-Bench基准测试，将LLM与视觉语言动作模型分离，单独评估LLM在机器人控制中的高层推理能力。

Result: 人类平均得分95%，最佳LLM仅得40%，LLM在多步骤空间规划和社交理解方面表现最差，专门针对具身推理的微调也未能提升性能。

Conclusion: LLM在实际物理世界智能方面仍远落后于人类，特别是在空间规划和社交理解等关键领域需要进一步改进。

Abstract: We present Butter-Bench, a benchmark evaluating large language model (LLM)
controlled robots for practical intelligence, defined as the ability to
navigate the messiness of the physical world. Current state-of-the-art robotic
systems use a hierarchical architecture with LLMs in charge of high-level
reasoning, and a Vision Language Action (VLA) model for low-level control.
Butter-Bench evaluates the LLM part in isolation from the VLA. Although LLMs
have repeatedly surpassed humans in evaluations requiring analytical
intelligence, we find humans still outperform LLMs on Butter-Bench. The best
LLMs score 40% on Butter-Bench, while the mean human score is 95%. LLMs
struggled the most with multi-step spatial planning and social understanding.
We also evaluate LLMs that are fine-tuned for embodied reasoning and conclude
that this training does not improve their score on Butter-Bench.

</details>


### [16] [A Physics-Informed Neural Network Approach for UAV Path Planning in Dynamic Environments](https://arxiv.org/abs/2510.21874)
*Shuning Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于物理信息神经网络(PINN)的无人机轨迹规划框架，能够在不依赖监督数据的情况下生成动态可行且无碰撞的轨迹，在控制能量、平滑度和安全裕度方面优于传统规划器。


<details>
  <summary>Details</summary>
Motivation: 传统规划器如A*和Kino-RRT*在动态风场中由于离散化和采样限制，往往产生次优或不平滑的路径，需要一种能够嵌入无人机动力学、风扰和避障约束的统一规划框架。

Method: 使用物理信息神经网络(PINN)框架，将无人机动力学、风扰和避障约束直接嵌入学习过程，通过最小化物理残差和风险感知目标来学习轨迹，无需监督数据。

Result: 对比仿真显示，该方法在控制能量、平滑度和安全裕度方面优于A*和Kino-RRT*，同时保持相似的飞行效率。

Conclusion: 物理信息学习有潜力统一基于模型和数据驱动的规划方法，为无人机轨迹优化提供可扩展且物理一致的框架。

Abstract: Unmanned aerial vehicles (UAVs) operating in dynamic wind fields must
generate safe and energy-efficient trajectories under physical and
environmental constraints. Traditional planners, such as A* and kinodynamic
RRT*, often yield suboptimal or non-smooth paths due to discretization and
sampling limitations. This paper presents a physics-informed neural network
(PINN) framework that embeds UAV dynamics, wind disturbances, and obstacle
avoidance directly into the learning process. Without requiring supervised
data, the PINN learns dynamically feasible and collision-free trajectories by
minimizing physical residuals and risk-aware objectives. Comparative
simulations show that the proposed method outperforms A* and Kino-RRT* in
control energy, smoothness, and safety margin, while maintaining similar flight
efficiency. The results highlight the potential of physics-informed learning to
unify model-based and data-driven planning, providing a scalable and physically
consistent framework for UAV trajectory optimization.

</details>


### [17] [Two-Steps Diffusion Policy for Robotic Manipulation via Genetic Denoising](https://arxiv.org/abs/2510.21991)
*Mateo Clemente,Leo Brunswic,Rui Heng Yang,Xuan Zhao,Yasser Khalil,Haoyu Lei,Amir Rasouli,Yinchuan Li*

Main category: cs.RO

TL;DR: 本文提出了一种针对机器人控制任务优化的扩散模型推理方法，通过遗传去噪策略在仅需2-5次神经网络评估的情况下实现高性能控制。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型推理策略直接从视觉任务迁移到控制领域，没有针对机器人控制任务中动作分布的结构化和低维特性进行优化。

Method: 提出基于种群的采样策略——遗传去噪，通过选择具有低分布外风险的去噪轨迹来提升性能和稳定性。

Result: 在D4RL和Robomimic的14个机器人操作任务中，该方法仅需2次神经网络评估就能解决挑战性任务，性能提升达20%，在200万次评估中持续优于标准扩散策略。

Conclusion: 通过针对具体任务特性优化扩散模型的去噪过程，可以在极少的推理步骤下实现高效且稳定的机器人控制。

Abstract: Diffusion models, such as diffusion policy, have achieved state-of-the-art
results in robotic manipulation by imitating expert demonstrations. While
diffusion models were originally developed for vision tasks like image and
video generation, many of their inference strategies have been directly
transferred to control domains without adaptation. In this work, we show that
by tailoring the denoising process to the specific characteristics of embodied
AI tasks -- particularly structured, low-dimensional nature of action
distributions -- diffusion policies can operate effectively with as few as 5
neural function evaluations (NFE).
  Building on this insight, we propose a population-based sampling strategy,
genetic denoising, which enhances both performance and stability by selecting
denoising trajectories with low out-of-distribution risk. Our method solves
challenging tasks with only 2 NFE while improving or matching performance. We
evaluate our approach across 14 robotic manipulation tasks from D4RL and
Robomimic, spanning multiple action horizons and inference budgets. In over 2
million evaluations, our method consistently outperforms standard
diffusion-based policies, achieving up to 20\% performance gains with
significantly fewer inference steps.

</details>


### [18] [Estimation of Minimum Stride Frequency for the Frontal Plane Stability of Bipedal Systems](https://arxiv.org/abs/2510.22030)
*Harsha Karunanayaka,Siavash Rezazadeh*

Main category: cs.RO

TL;DR: 研究分析了双足系统在额状面的稳定性机制，发现通过调整步态时间和腿部伸缩的前馈控制可以实现稳定振荡，无需反馈控制。


<details>
  <summary>Details</summary>
Motivation: 目前对关键参数（质量、刚度、腿长、髋部宽度）如何影响稳定性和维持稳定性所需的最小步频理解有限，本研究旨在填补这些空白。

Method: 通过分析单个模型参数和系统固有频率对维持稳定周期所需最小步频的影响，提出预测最小步频的方法，并与随机生成模型的实际值进行比较。

Result: 研究提供了预测最小步频的方法，并验证了该方法与随机模型实际值的匹配程度。

Conclusion: 这项工作增进了对额状面稳定性机制的理解，展示了如何利用前馈稳定化来减少控制努力和能量消耗。

Abstract: Stability of bipedal systems in frontal plane is affected by the hip offset,
to the extent that adjusting stride time using feedforward retraction and
extension of the legs can lead to stable oscillations without feedback control.
This feedforward stabilization can be leveraged to reduce the control effort
and energy expenditure and increase the locomotion robustness. However, there
is limited understanding of how key parameters, such as mass, stiffness, leg
length, and hip width, affect stability and the minimum stride frequency needed
to maintain it. This study aims to address these gaps through analyzing how
individual model parameters and the system's natural frequency influence the
minimum stride frequency required to maintain a stable cycle. We propose a
method to predict the minimum stride frequency, and compare the predicted
stride frequencies with actual values for randomly generated models. The
findings of this work provide a better understanding of the frontal plane
stability mechanisms and how feedforward stabilization can be leveraged to
reduce the control effort.

</details>


### [19] [RaycastGrasp: Eye-Gaze Interaction with Wearable Devices for Robotic Manipulation](https://arxiv.org/abs/2510.22113)
*Zitiantao Lin,Yongpeng Sang,Yang Ye*

Main category: cs.RO

TL;DR: 提出了一种基于混合现实头显的以自我为中心的注视引导机器人操纵界面，通过自然注视固定实现直观的物体交互，显著提高了操纵精度和系统响应速度。


<details>
  <summary>Details</summary>
Motivation: 传统操纵杆控制界面精度要求高且参考框架不直观，现有解决方案依赖外部屏幕或限制性控制方案，限制了直观性和可访问性。

Method: 利用可穿戴混合现实头显，从第一人称视角通过自然注视固定与真实世界物体交互，提供增强视觉线索确认意图，结合预训练视觉模型和机械臂进行意图识别和物体操纵。

Result: 实验结果显示该方法显著提高了操纵精度，减少了系统延迟，在多个真实场景中单次意图和物体识别准确率超过88%。

Conclusion: 该系统有效增强了直观性和可访问性，在辅助机器人应用中具有重要的实际意义。

Abstract: Robotic manipulators are increasingly used to assist individuals with
mobility impairments in object retrieval. However, the predominant
joystick-based control interfaces can be challenging due to high precision
requirements and unintuitive reference frames. Recent advances in human-robot
interaction have explored alternative modalities, yet many solutions still rely
on external screens or restrictive control schemes, limiting their
intuitiveness and accessibility. To address these challenges, we present an
egocentric, gaze-guided robotic manipulation interface that leverages a
wearable Mixed Reality (MR) headset. Our system enables users to interact
seamlessly with real-world objects using natural gaze fixation from a
first-person perspective, while providing augmented visual cues to confirm
intent and leveraging a pretrained vision model and robotic arm for intent
recognition and object manipulation. Experimental results demonstrate that our
approach significantly improves manipulation accuracy, reduces system latency,
and achieves single-pass intention and object recognition accuracy greater than
88% across multiple real-world scenarios. These results demonstrate the
system's effectiveness in enhancing intuitiveness and accessibility,
underscoring its practical significance for assistive robotics applications.

</details>


### [20] [EasyUUV: An LLM-Enhanced Universal and Lightweight Sim-to-Real Reinforcement Learning Framework for UUV Attitude Control](https://arxiv.org/abs/2510.22126)
*Guanwen Xie,Jingzehua Xu,Jiwei Tang,Yubo Huang,Shuai Zhang,Xiaofan Li*

Main category: cs.RO

TL;DR: EasyUUV是一个基于大语言模型增强的轻量级仿真到现实强化学习框架，用于无人水下航行器的鲁棒姿态控制，结合并行RL训练和混合控制架构。


<details>
  <summary>Details</summary>
Motivation: 解决现有UUV姿态控制方法在泛化性、对真实世界扰动的鲁棒性以及高效部署方面的不足。

Method: 结合并行化RL训练与混合控制架构，学习策略输出高层姿态校正，由自适应S-Surface控制器执行；集成多模态LLM根据视觉和文本反馈自适应调整控制器参数。

Result: 广泛的仿真和真实世界实验验证了EasyUUV在不同水下条件下实现鲁棒和自适应UUV姿态控制的有效性和优异性能。

Conclusion: EasyUUV框架在UUV姿态控制方面表现出色，能够实现训练免费的动态适应，源代码已公开。

Abstract: Despite recent advances in Unmanned Underwater Vehicle (UUV) attitude
control, existing methods still struggle with generalizability, robustness to
real-world disturbances, and efficient deployment. To address the above
challenges, this paper presents EasyUUV, a Large Language Model (LLM)-enhanced,
universal, and lightweight simulation-to-reality reinforcement learning (RL)
framework for robust attitude control of UUVs. EasyUUV combines parallelized RL
training with a hybrid control architecture, where a learned policy outputs
high-level attitude corrections executed by an adaptive S-Surface controller. A
multimodal LLM is further integrated to adaptively tune controller parameters
at runtime using visual and textual feedback, enabling training-free adaptation
to unmodeled dynamics. Also, we have developed a low-cost 6-DoF UUV platform
and applied an RL policy trained through efficient parallelized simulation.
Extensive simulation and real-world experiments validate the effectiveness and
outstanding performance of EasyUUV in achieving robust and adaptive UUV
attitude control across diverse underwater conditions. The source code is
available from the following website: https://360zmem.github.io/easyuuv/

</details>


### [21] [LT-Exosense: A Vision-centric Multi-session Mapping System for Lifelong Safe Navigation of Exoskeletons](https://arxiv.org/abs/2510.22164)
*Jianeng Wang,Matias Mattamala,Christina Kassab,Nived Chebrolu,Guillaume Burger,Fabio Elnecave,Marine Petriaux,Maurice Fallon*

Main category: cs.RO

TL;DR: LT-Exosense是一个面向外骨骼用户的视觉中心多会话建图系统，支持长期（半）自主导航，通过跨会话融合空间知识、检测环境变化和更新持久全局地图来实现智能路径规划。


<details>
  <summary>Details</summary>
Motivation: 为下肢残疾人士提供可靠长期运行的自平衡外骨骼需要能在变化环境中有效工作的感知系统。

Method: 扩展单会话建图能力，通过增量融合多个会话的空间知识、检测环境变化并更新持久全局地图，实现智能路径规划。

Result: 在真实世界实验中验证了可扩展的多会话地图，与地面真实激光扫描相比，平均点对点误差低于5厘米，展示了在动态变化室内环境中自适应路径规划的应用潜力。

Conclusion: LT-Exosense系统能够有效支持外骨骼用户的长期自主导航，在动态环境中实现可靠的路径规划和环境适应。

Abstract: Self-balancing exoskeletons offer a promising mobility solution for
individuals with lower-limb disabilities. For reliable long-term operation,
these exoskeletons require a perception system that is effective in changing
environments. In this work, we introduce LT-Exosense, a vision-centric,
multi-session mapping system designed to support long-term (semi)-autonomous
navigation for exoskeleton users. LT-Exosense extends single-session mapping
capabilities by incrementally fusing spatial knowledge across multiple
sessions, detecting environmental changes, and updating a persistent global
map. This representation enables intelligent path planning, which can adapt to
newly observed obstacles and can recover previous routes when obstructions are
removed. We validate LT-Exosense through several real-world experiments,
demonstrating a scalable multi-session map that achieves an average
point-to-point error below 5 cm when compared to ground-truth laser scans. We
also illustrate the potential application of adaptive path planning in
dynamically changing indoor environments.

</details>


### [22] [ACG: Action Coherence Guidance for Flow-based VLA models](https://arxiv.org/abs/2510.22201)
*Minho Park,Kinam Kim,Junha Hyung,Hyojin Jang,Hoiyeong Jin,Jooyeol Yun,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: 提出Action Coherence Guidance (ACG)算法，无需训练即可在测试时提升VLA模型的动作连贯性，解决模仿学习中人类演示数据噪声导致的动作不连贯问题。


<details>
  <summary>Details</summary>
Motivation: 扩散和流匹配模型作为机器人策略时，其高生成能力使其对人类演示数据中的噪声（如抖动、停顿等）敏感，导致动作不连贯，在需要精度的精细操作中造成不稳定和轨迹漂移。

Method: ACG是一种无需训练、在测试时应用的指导算法，通过提升动作连贯性来改善VLA模型的性能。

Result: 在RoboCasa、DexMimicGen和真实世界SO-101任务上的评估显示，ACG能持续提升动作连贯性，并在多样化操作任务中提高成功率。

Conclusion: ACG算法能有效解决VLA模型在模仿学习中的动作不连贯问题，提升机器人操作的稳定性和精度。

Abstract: Diffusion and flow matching models have emerged as powerful robot policies,
enabling Vision-Language-Action (VLA) models to generalize across diverse
scenes and instructions. Yet, when trained via imitation learning, their high
generative capacity makes them sensitive to noise in human demonstrations:
jerks, pauses, and jitter which reduce action coherence. Reduced action
coherence causes instability and trajectory drift during deployment, failures
that are catastrophic in fine-grained manipulation where precision is crucial.
In this paper, we present Action Coherence Guidance (ACG) for VLA models, a
training-free test-time guidance algorithm that improves action coherence and
thereby yields performance gains. Evaluated on RoboCasa, DexMimicGen, and
real-world SO-101 tasks, ACG consistently improves action coherence and boosts
success rates across diverse manipulation tasks. Code and project page are
available at https://github.com/DAVIAN-Robotics/ACG and
https://DAVIAN-Robotics.github.io/ACG , respectively.

</details>


### [23] [Bridging Perception and Reasoning: Dual-Pipeline Neuro-Symbolic Landing for UAVs in Cluttered Environments](https://arxiv.org/abs/2510.22204)
*Weixian Qian,Sebastian Schroder,Yao Deng,Jiaohong Yao,Linfeng Liang,Xiao Cheng,Richard Han,Xi Zheng*

Main category: cs.RO

TL;DR: NeuroSymLand是一个神经符号框架，通过结合LLM生成的符号知识和轻量级基础模型的感知能力，实现无人机在非结构化环境中的自主安全着陆。


<details>
  <summary>Details</summary>
Motivation: 解决纯视觉或深度学习模型在无人机自主着陆任务中存在的协变量偏移问题和可解释性不足的挑战。

Method: 采用双管道设计：离线管道使用LLM和人工精炼生成可验证的符号知识；在线管道通过语义分割生成概率事实，结合几何计算构建语义场景图进行实时推理。

Result: 在多个数据集、仿真环境和真实无人机硬件上的评估显示，NeuroSymLand在准确性、鲁棒性和效率方面均优于现有最先进方法。

Conclusion: 该框架将轻量级基础模型的感知优势与符号推理的可解释性和可验证性相结合，显著提升了无人机在应急响应、监视和配送任务中的安全性和可靠性。

Abstract: Autonomous landing in unstructured (cluttered, uneven, and map-poor)
environments is a core requirement for Unmanned Aerial Vehicles (UAVs), yet
purely vision-based or deep learning models often falter under covariate shift
and provide limited interpretability. We propose NeuroSymLand, a neuro-symbolic
framework that tightly couples two complementary pipelines: (i) an offline
pipeline, where Large Language Models (LLMs) and human-in-the-loop refinement
synthesize Scallop code from diverse landing scenarios, distilling
generalizable and verifiable symbolic knowledge; and (ii) an online pipeline,
where a compact foundation-based semantic segmentation model generates
probabilistic Scallop facts that are composed into semantic scene graphs for
real-time deductive reasoning. This design combines the perceptual strengths of
lightweight foundation models with the interpretability and verifiability of
symbolic reasoning. Node attributes (e.g., flatness, area) and edge relations
(adjacency, containment, proximity) are computed with geometric routines rather
than learned, avoiding the data dependence and latency of train-time graph
builders. The resulting Scallop program encodes landing principles (avoid water
and obstacles; prefer large, flat, accessible regions) and yields calibrated
safety scores with ranked Regions of Interest (ROIs) and human-readable
justifications. Extensive evaluations across datasets, diverse simulation maps,
and real UAV hardware show that NeuroSymLand achieves higher accuracy, stronger
robustness to covariate shift, and superior efficiency compared with
state-of-the-art baselines, while advancing UAV safety and reliability in
emergency response, surveillance, and delivery missions.

</details>


### [24] [Breaking the Static Assumption: A Dynamic-Aware LIO Framework Via Spatio-Temporal Normal Analysis](https://arxiv.org/abs/2510.22313)
*Chen Zhiqiang,Le Gentil Cedric,Lin Fuling,Lu Minghao,Qiao Qiyuan,Xu Bowen,Qi Yuhua,Lu Peng*

Main category: cs.RO

TL;DR: 提出了一种动态感知的激光雷达-惯性里程计方法，通过将动态感知直接集成到点云配准过程中，解决了传统LIO在动态环境中性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 传统LIO方法在动态环境中表现不佳，特别是在几何稀疏场景中，因为其基于静态世界假设。现有动态LIO方法面临循环依赖问题：精确定位需要可靠的静态特征识别，而区分动态对象又需要精确的位姿估计。

Method: 开发了动态感知的迭代最近点算法，利用时空法向量分析，并辅以高效的空间一致性验证方法来增强静态地图构建。

Result: 实验评估表明，在具有有限几何结构的挑战性动态环境中，该方法相比最先进的LIO系统有显著性能提升。

Conclusion: 该方法通过打破循环依赖，成功解决了动态环境中的LIO定位问题，在几何稀疏的动态场景中表现出优越性能。

Abstract: This paper addresses the challenge of Lidar-Inertial Odometry (LIO) in
dynamic environments, where conventional methods often fail due to their
static-world assumptions. Traditional LIO algorithms perform poorly when
dynamic objects dominate the scenes, particularly in geometrically sparse
environments. Current approaches to dynamic LIO face a fundamental challenge:
accurate localization requires a reliable identification of static features,
yet distinguishing dynamic objects necessitates precise pose estimation. Our
solution breaks this circular dependency by integrating dynamic awareness
directly into the point cloud registration process. We introduce a novel
dynamic-aware iterative closest point algorithm that leverages spatio-temporal
normal analysis, complemented by an efficient spatial consistency verification
method to enhance static map construction. Experimental evaluations demonstrate
significant performance improvements over state-of-the-art LIO systems in
challenging dynamic environments with limited geometric structure. The code and
dataset are available at https://github.com/thisparticle/btsa.

</details>


### [25] [Toward Humanoid Brain-Body Co-design: Joint Optimization of Control and Morphology for Fall Recovery](https://arxiv.org/abs/2510.22336)
*Bo Yue,Sheng Xu,Kui Jia,Guiliang Liu*

Main category: cs.RO

TL;DR: RoboCraft是一个可扩展的人形机器人协同设计框架，通过控制策略和形态学的耦合更新迭代提升跌倒恢复性能，在7个公开人形机器人上平均性能提升44.55%。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在人类工作空间具有天然部署优势，脑体协同设计通过联合优化控制策略和物理形态来实现这一潜力，其中跌倒恢复作为关键能力可增强安全性和自主性。

Method: 提出RoboCraft框架：在多设计上预训练共享策略，在高效形态上逐步微调；形态搜索受人类启发先验和优化算法指导，使用优先级缓冲区平衡有前景候选的重新评估和新设计的探索。

Result: 在7个公开人形机器人上平均性能提升44.55%，形态优化在4个人形机器人协同设计中贡献至少40%的改进。

Conclusion: 形态优化在协同设计中发挥关键作用，证明了人形机器人协同设计的重要性。

Abstract: Humanoid robots represent a central frontier in embodied intelligence, as
their anthropomorphic form enables natural deployment in humans' workspace.
Brain-body co-design for humanoids presents a promising approach to realizing
this potential by jointly optimizing control policies and physical morphology.
Within this context, fall recovery emerges as a critical capability. It not
only enhances safety and resilience but also integrates naturally with
locomotion systems, thereby advancing the autonomy of humanoids. In this paper,
we propose RoboCraft, a scalable humanoid co-design framework for fall recovery
that iteratively improves performance through the coupled updates of control
policy and morphology. A shared policy pretrained across multiple designs is
progressively finetuned on high-performing morphologies, enabling efficient
adaptation without retraining from scratch. Concurrently, morphology search is
guided by human-inspired priors and optimization algorithms, supported by a
priority buffer that balances reevaluation of promising candidates with the
exploration of novel designs. Experiments show that \ourmethod{} achieves an
average performance gain of 44.55% on seven public humanoid robots, with
morphology optimization drives at least 40% of improvements in co-designing
four humanoid robots, underscoring the critical role of humanoid co-design.

</details>


### [26] [Estimating Continuum Robot Shape under External Loading using Spatiotemporal Neural Networks](https://arxiv.org/abs/2510.22339)
*Enyi Wang,Zhen Deng,Chuanchuan Pan,Bingwei He,Jianwei Zhang*

Main category: cs.RO

TL;DR: 提出了一种基于学习的柔性连续体机器人3D形状估计方法，使用时空神经网络融合多模态输入（肌腱位移数据和RGB图像）来生成表示机器人变形配置的点云。


<details>
  <summary>Details</summary>
Motivation: 准确估计受外部载荷作用的柔性连续体机器人的3D形状，特别是在加载条件下的精确形状感知。

Method: 采用时空神经网络架构，包含用于时间特征提取的循环神经网络模块、空间特征提取编码模块，以及多模态融合模块来结合视觉数据的空间特征和历史执行器输入的时间依赖性。通过拟合Bézier曲线到预测的点云实现连续3D形状重建。

Result: 实验验证显示该方法达到高精度，平均形状估计误差为0.08毫米（无负载）和0.22毫米（有负载），在TDCRs形状感知方面优于现有最先进方法。

Conclusion: 深度学习基础的时空数据融合在加载条件下实现精确形状估计具有显著效果。

Abstract: This paper presents a learning-based approach for accurately estimating the
3D shape of flexible continuum robots subjected to external loads. The proposed
method introduces a spatiotemporal neural network architecture that fuses
multi-modal inputs, including current and historical tendon displacement data
and RGB images, to generate point clouds representing the robot's deformed
configuration. The network integrates a recurrent neural module for temporal
feature extraction, an encoding module for spatial feature extraction, and a
multi-modal fusion module to combine spatial features extracted from visual
data with temporal dependencies from historical actuator inputs. Continuous 3D
shape reconstruction is achieved by fitting B\'ezier curves to the predicted
point clouds. Experimental validation demonstrates that our approach achieves
high precision, with mean shape estimation errors of 0.08 mm (unloaded) and
0.22 mm (loaded), outperforming state-of-the-art methods in shape sensing for
TDCRs. The results validate the efficacy of deep learning-based spatiotemporal
data fusion for precise shape estimation under loading conditions.

</details>


### [27] [BLIP-FusePPO: A Vision-Language Deep Reinforcement Learning Framework for Lane Keeping in Autonomous Vehicles](https://arxiv.org/abs/2510.22370)
*Seyed Ahmad Hosseini Miangoleh,Amin Jalal Aghdasian,Farzaneh Abdollahi*

Main category: cs.RO

TL;DR: BLIP-FusePPO是一种用于自动驾驶车道保持的多模态强化学习框架，通过融合视觉语言模型的语义嵌入、几何状态、LiDAR观测和PID控制反馈，提升策略学习的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常仅使用语义模型来塑造奖励函数，这会导致昂贵的运行时推理成本，且语义指导不能持续可用。本文旨在直接将语义特征嵌入状态表示中，以降低推理成本并确保语义指导的持续可用性。

Method: 提出BLIP-FusePPO框架，将视觉语言模型生成的语义嵌入与几何状态、LiDAR观测和PID控制反馈在智能体观测空间中进行直接融合。采用包含语义对齐、车道保持精度、障碍物避让和速度调节的混合奖励函数。

Result: 仿真结果表明，在多种复杂驾驶场景下，所提模型在车道保持稳定性和适应性方面优于最佳基于视觉和多模态强化学习的基线方法。

Conclusion: BLIP-FusePPO通过直接融合语义特征到状态表示中，有效提升了自动驾驶车道保持任务的性能，同时降低了推理成本并确保了语义指导的持续可用性。

Abstract: In this paper, we propose Bootstrapped Language-Image Pretraining-driven
Fused State Representation in Proximal Policy Optimization (BLIP-FusePPO), a
novel multimodal reinforcement learning (RL) framework for autonomous
lane-keeping (LK), in which semantic embeddings generated by a vision-language
model (VLM) are directly fused with geometric states, LiDAR observations, and
Proportional-Integral-Derivative-based (PID) control feedback within the agent
observation space. The proposed method lets the agent learn driving rules that
are aware of their surroundings and easy to understand by combining high-level
scene understanding from the VLM with low-level control and spatial signals.
Our architecture brings together semantic, geometric, and control-aware
representations to make policy learning more robust. A hybrid reward function
that includes semantic alignment, LK accuracy, obstacle avoidance, and speed
regulation helps learning to be more efficient and generalizable. Our method is
different from the approaches that only use semantic models to shape rewards.
Instead, it directly embeds semantic features into the state representation.
This cuts down on expensive runtime inference and makes sure that semantic
guidance is always available. The simulation results show that the proposed
model is better at LK stability and adaptability than the best vision-based and
multimodal RL baselines in a wide range of difficult driving situations. We
make our code publicly available.

</details>


### [28] [A Novel Multi-Timescale Stability-Preserving Hierarchical Reinforcement Learning Controller Framework for Adaptive Control in High-Dimensional Dynamical Systems](https://arxiv.org/abs/2510.22420)
*Mohammad Ali Labbaf Khaniki,Fateme Taroodi,Benyamin Safizadeh*

Main category: cs.RO

TL;DR: 提出了MTLHRL框架，通过分层策略和Lyapunov稳定性约束解决高维随机系统的控制问题，在超混沌系统和机器人控制中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决高维随机系统控制面临的维度灾难、缺乏时间抽象和随机稳定性保证不足的问题。

Method: 基于半马尔可夫决策过程的分层强化学习框架，包含高层策略规划和低层反应控制，通过神经Lyapunov函数和拉格朗日松弛确保稳定性。

Result: 在8D超混沌系统和5-DOF机器人上的实验显示，MTLHRL在稳定性和性能上显著优于基线方法，获得最低误差指标（IAE：3.912和1.623）。

Conclusion: MTLHRL为复杂随机系统的鲁棒控制提供了理论严谨且实际可行的解决方案。

Abstract: Controlling high-dimensional stochastic systems, critical in robotics,
autonomous vehicles, and hyperchaotic systems, faces the curse of
dimensionality, lacks temporal abstraction, and often fails to ensure
stochastic stability. To overcome these limitations, this study introduces the
Multi-Timescale Lyapunov-Constrained Hierarchical Reinforcement Learning
(MTLHRL) framework. MTLHRL integrates a hierarchical policy within a
semi-Markov Decision Process (SMDP), featuring a high-level policy for
strategic planning and a low-level policy for reactive control, which
effectively manages complex, multi-timescale decision-making and reduces
dimensionality overhead. Stability is rigorously enforced using a neural
Lyapunov function optimized via Lagrangian relaxation and multi-timescale
actor-critic updates, ensuring mean-square boundedness or asymptotic stability
in the face of stochastic dynamics. The framework promotes efficient and
reliable learning through trust-region constraints and decoupled optimization.
Extensive simulations on an 8D hyperchaotic system and a 5-DOF robotic
manipulator demonstrate MTLHRL's empirical superiority. It significantly
outperforms baseline methods in both stability and performance, recording the
lowest error indices (e.g., Integral Absolute Error (IAE): 3.912 in
hyperchaotic control and IAE: 1.623 in robotics), achieving faster convergence,
and exhibiting superior disturbance rejection. MTLHRL offers a theoretically
grounded and practically viable solution for robust control of complex
stochastic systems.

</details>


### [29] [A short methodological review on social robot navigation benchmarking](https://arxiv.org/abs/2510.22448)
*Pranup Chhetri,Alejandro Torrejon,Sergio Eslava,Luis J. Manso*

Main category: cs.RO

TL;DR: 本文综述了2020年1月至2025年7月期间社会机器人导航领域的基准测试趋势，分析了85篇相关论文，重点关注基准测试指标、算法、人类调查使用情况以及结论推导方式。


<details>
  <summary>Details</summary>
Motivation: 社会机器人导航领域缺乏统一的基准测试标准，这阻碍了该领域的发展并可能导致相互矛盾的结论。

Method: 通过IEEE Xplore搜索识别了130篇论文，最终分析了符合标准的85篇论文，系统回顾了基准测试指标、算法、人类调查使用情况。

Result: 研究发现社会机器人导航领域在基准测试方面存在标准化不足的问题，不同研究使用的指标和方法差异较大。

Conclusion: 需要建立统一的社会机器人导航基准测试标准，以促进该领域的科学发展和可靠比较。

Abstract: Social Robot Navigation is the skill that allows robots to move efficiently
in human-populated environments while ensuring safety, comfort, and trust.
Unlike other areas of research, the scientific community has not yet achieved
an agreement on how Social Robot Navigation should be benchmarked. This is
notably important, as the lack of a de facto standard to benchmark Social Robot
Navigation can hinder the progress of the field and may lead to contradicting
conclusions. Motivated by this gap, we contribute with a short review focused
exclusively on benchmarking trends in the period from January 2020 to July
2025. Of the 130 papers identified by our search using IEEE Xplore, we analysed
the 85 papers that met the criteria of the review. This review addresses the
metrics used in the literature for benchmarking purposes, the algorithms
employed in such benchmarks, the use of human surveys for benchmarking, and how
conclusions are drawn from the benchmarking results, when applicable.

</details>


### [30] [Forward Kinematics Solution For A General Stewart Platform Through Iteration Based Simulation](https://arxiv.org/abs/2510.22465)
*Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 提出一种为通用Stewart平台生成可行、唯一正向运动学解的方法，使用逆运动学获取有效工作空间数据和对应的执行器长度，通过改进的Denavit-Hartenberg约定实现简单迭代算法。


<details>
  <summary>Details</summary>
Motivation: 对于Stewart平台等并联运动机构，逆运动学简单直接，但正向运动学由于运动链的闭环结构而复杂且产生多解，需要手动验证。

Method: 使用改进的Denavit-Hartenberg约定的简单迭代算法，通过逆运动学获取有效工作空间数据和执行器长度。

Result: 该方法为每个有效位姿生成单一可行的正向运动学解，无需手动验证即可直接用于进一步计算。

Conclusion: 该方法对于作者实验室开发的六自由度材料测试系统至关重要，能够通过原位校准实现高精度力控制，用于增材制造材料在复杂多载荷条件下的表征。

Abstract: This paper presents a method to generate feasible, unique forward-kinematic
solutions for a general Stewart platform. This is done by using inverse
kinematics to obtain valid workspace data and corresponding actuator lengths
for the moving platform. For parallel kinematic machines, such as the Stewart
Platform, inverse kinematics are straight forward, but the forward kinematics
are complex and generates multiple solutions due to the closed loop structure
of the kinematic links. In this research, a simple iterative algorithm has been
used employing modified Denavit-Hartenberg convention. The outcome is
encouraging as this method generates a single feasible forward kinematic
solution for each valid pose with the solved DH parameters and unlike earlier
forward kinematics solutions, this unique solution does not need to be manually
verified. Therefore, the forward kinematic solutions can be used directly for
further calculations without the need for manual pose verification. This
capability is essential for the six degree of freedom materials testing system
developed by the authors in their laboratory. The developed system is aimed at
characterizing additively manufactured materials under complex combined
multiple loading conditions. The material characterization is done by enabling
high precision force control on the moving platform via in situ calibration of
the as-built kinematics of the Stewart Gough Platform.

</details>


### [31] [On Steerability Factors for Growing Vine Robots](https://arxiv.org/abs/2510.22504)
*Ciera McFarland,Antonio Alvarez,Sarah Taher,Nathaniel Hanson,Margaret McGuinness*

Main category: cs.RO

TL;DR: 该研究探讨了藤蔓机器人的转向性能如何受尖端负载、压力、长度、直径和制造方法的影响，发现适中的腔室压力、较长的长度和集成式执行器设计能提升转向能力。


<details>
  <summary>Details</summary>
Motivation: 藤蔓机器人具有在复杂环境中导航的潜力，但其性能受附加传感器重量、设计选择和控制参数的限制，需要系统研究这些因素对转向性能的影响。

Method: 进行两组实验：第一组研究在重力支撑下尖端负载、腔室压力、长度和直径的影响；第二组研究地面支撑下制造方法和执行器与腔室压力比的影响。

Result: 转向性能随尖端负载增加而降低，在适中腔室压力下最佳，随长度增加而提升，直径影响不大。外置执行器在低压比时开始弯曲但饱和，集成执行器需要更高压力但能达到更大曲率。

Conclusion: 基于这些原理优化的机器人在涉及最大化向上和水平曲率的移动任务中表现优于临时参数设置的机器人。

Abstract: Vine robots extend their tubular bodies by everting material from the tip,
enabling navigation in complex environments with a minimalist soft body.
Despite their promise for field applications, especially in the urban search
and rescue domain, performance is constrained by the weight of attached sensors
or tools, as well as other design and control choices. This work investigates
how tip load, pressure, length, diameter, and fabrication method shape vine
robot steerability--the ability to maneuver with controlled curvature--for
robots that steer with series pouch motor-style pneumatic actuators. We conduct
two groups of experiments: (1) studying tip load, chamber pressure, length, and
diameter in a robot supporting itself against gravity, and (2) studying
fabrication method and ratio of actuator to chamber pressure in a robot
supported on the ground. Results show that steerability decreases with
increasing tip load, is best at moderate chamber pressure, increases with
length, and is largely unaffected by diameter. Robots with actuators attached
on their exterior begin curving at low pressure ratios, but curvature saturates
at high pressure ratios; those with actuators integrated into the robot body
require higher pressure ratios to begin curving but achieve higher curvature
overall. We demonstrate that robots optimized with these principles outperform
those with ad hoc parameters in a mobility task that involves maximizing upward
and horizontal curvatures.

</details>


### [32] [Ant-inspired Walling Strategies for Scalable Swarm Separation: Reinforcement Learning Approaches Based on Finite State Machines](https://arxiv.org/abs/2510.22524)
*Shenbagaraj Kannapiran,Elena Oikonomou,Albert Chu,Spring Berman,Theodore P. Pavlic*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In natural systems, emergent structures often arise to balance competing
demands. Army ants, for example, form temporary "walls" that prevent
interference between foraging trails. Inspired by this behavior, we developed
two decentralized controllers for heterogeneous robotic swarms to maintain
spatial separation while executing concurrent tasks. The first is a
finite-state machine (FSM)-based controller that uses encounter-triggered
transitions to create rigid, stable walls. The second integrates FSM states
with a Deep Q-Network (DQN), dynamically optimizing separation through emergent
"demilitarized zones." In simulation, both controllers reduce mixing between
subgroups, with the DQN-enhanced controller improving adaptability and reducing
mixing by 40-50% while achieving faster convergence.

</details>


### [33] [SPIRAL: Self-Play Incremental Racing Algorithm for Learning in Multi-Drone Competitions](https://arxiv.org/abs/2510.22568)
*Onur Akgün*

Main category: cs.RO

TL;DR: SPIRAL是一种用于训练自主无人机在多智能体竞赛中的自博弈增量学习算法，通过无人机与不断进化的自身版本竞争来逐步培养复杂竞赛行为。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够在动态环境中自主生成适当挑战、培养复杂竞赛策略的多智能体无人机训练框架，解决传统方法难以处理竞争环境复杂性的问题。

Method: 采用自博弈机制，让无人机与越来越熟练的自身版本持续竞争，逐步提升竞争难度。该方法可集成任何最先进的深度强化学习算法。

Result: 仿真实验证明了SPIRAL的显著优势，并对各种深度强化学习算法在其框架内的性能进行了基准测试。

Conclusion: SPIRAL提供了一个多功能、可扩展且自我改进的学习框架，为开发多智能体环境中稳健和自适应的竞赛策略开辟了有前景的方向。

Abstract: This paper introduces SPIRAL (Self-Play Incremental Racing Algorithm for
Learning), a novel approach for training autonomous drones in multi-agent
racing competitions. SPIRAL distinctively employs a self-play mechanism to
incrementally cultivate complex racing behaviors within a challenging, dynamic
environment. Through this self-play core, drones continuously compete against
increasingly proficient versions of themselves, naturally escalating the
difficulty of competitive interactions. This progressive learning journey
guides agents from mastering fundamental flight control to executing
sophisticated cooperative multi-drone racing strategies. Our method is designed
for versatility, allowing integration with any state-of-the-art Deep
Reinforcement Learning (DRL) algorithms within its self-play framework.
Simulations demonstrate the significant advantages of SPIRAL and benchmark the
performance of various DRL algorithms operating within it. Consequently, we
contribute a versatile, scalable, and self-improving learning framework to the
field of autonomous drone racing. SPIRAL's capacity to autonomously generate
appropriate and escalating challenges through its self-play dynamic offers a
promising direction for developing robust and adaptive racing strategies in
multi-agent environments. This research opens new avenues for enhancing the
performance and reliability of autonomous racing drones in increasingly complex
and competitive scenarios.

</details>


### [34] [Curriculum-Based Iterative Self-Play for Scalable Multi-Drone Racing](https://arxiv.org/abs/2510.22570)
*Onur Akgün*

Main category: cs.RO

TL;DR: CRUISE是一个基于课程学习和自我博弈的强化学习框架，专门用于解决多无人机竞速中的可扩展性问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多自主智能体在高速竞争环境中的协调挑战，特别是在多无人机竞速这一要求极高的领域。

Method: 结合渐进难度课程和高效自我博弈机制，通过高保真仿真验证，使用强化学习方法训练竞争性行为。

Result: 性能显著优于标准强化学习基线和最先进的博弈论规划器，平均竞速速度接近后者的两倍，在高密度智能体环境下仍保持高成功率和鲁棒性。

Conclusion: CRUISE为动态竞争任务提供了可扩展有效的训练方法，课程结构是性能提升的关键因素，为未来实际部署提供了蓝图。

Abstract: The coordination of multiple autonomous agents in high-speed, competitive
environments represents a significant engineering challenge. This paper
presents CRUISE (Curriculum-Based Iterative Self-Play for Scalable Multi-Drone
Racing), a reinforcement learning framework designed to solve this challenge in
the demanding domain of multi-drone racing. CRUISE overcomes key scalability
limitations by synergistically combining a progressive difficulty curriculum
with an efficient self-play mechanism to foster robust competitive behaviors.
Validated in high-fidelity simulation with realistic quadrotor dynamics, the
resulting policies significantly outperform both a standard reinforcement
learning baseline and a state-of-the-art game-theoretic planner. CRUISE
achieves nearly double the planner's mean racing speed, maintains high success
rates, and demonstrates robust scalability as agent density increases. Ablation
studies confirm that the curriculum structure is the critical component for
this performance leap. By providing a scalable and effective training
methodology, CRUISE advances the development of autonomous systems for dynamic,
competitive tasks and serves as a blueprint for future real-world deployment.

</details>


### [35] [RoGER-SLAM: A Robust Gaussian Splatting SLAM System for Noisy and Low-light Environment Resilience](https://arxiv.org/abs/2510.22600)
*Huilin Yin,Zhaolin Yang,Linchuan Zhang,Gerhard Rigoll,Johannes Betz*

Main category: cs.RO

TL;DR: RoGER-SLAM是一种针对噪声和低光环境优化的鲁棒3D高斯泼溅SLAM系统，通过结构保持融合机制、自适应跟踪目标和CLIP增强模块，在恶劣成像条件下显著提升轨迹精度和重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统3DGS SLAM系统在视觉输入存在噪声和低光照的环境下可靠性严重受限，原始3DGS渲染管道作为隐式低通滤波器，虽然衰减高频噪声但可能导致过度平滑。

Method: 提出三个创新：结构保持鲁棒融合机制（耦合渲染外观、深度和边缘线索）、带残差平衡正则化的自适应跟踪目标、以及基于CLIP的选择性增强模块（在复合退化条件下激活以恢复语义和结构保真度）。

Result: 在Replica、TUM和真实世界序列上的综合实验表明，RoGER-SLAM相比其他3DGS-SLAM系统，在恶劣成像条件下持续改善轨迹精度和重建质量。

Conclusion: RoGER-SLAM通过创新的融合机制和增强策略，有效解决了3DGS SLAM在噪声和低光环境中的脆弱性问题，显著提升了系统的鲁棒性。

Abstract: The reliability of Simultaneous Localization and Mapping (SLAM) is severely
constrained in environments where visual inputs suffer from noise and low
illumination. Although recent 3D Gaussian Splatting (3DGS) based SLAM
frameworks achieve high-fidelity mapping under clean conditions, they remain
vulnerable to compounded degradations that degrade mapping and tracking
performance. A key observation underlying our work is that the original 3DGS
rendering pipeline inherently behaves as an implicit low-pass filter,
attenuating high-frequency noise but also risking over-smoothing. Building on
this insight, we propose RoGER-SLAM, a robust 3DGS SLAM system tailored for
noise and low-light resilience. The framework integrates three innovations: a
Structure-Preserving Robust Fusion (SP-RoFusion) mechanism that couples
rendered appearance, depth, and edge cues; an adaptive tracking objective with
residual balancing regularization; and a Contrastive Language-Image Pretraining
(CLIP)-based enhancement module, selectively activated under compounded
degradations to restore semantic and structural fidelity. Comprehensive
experiments on Replica, TUM, and real-world sequences show that RoGER-SLAM
consistently improves trajectory accuracy and reconstruction quality compared
with other 3DGS-SLAM systems, especially under adverse imaging conditions.

</details>


### [36] [Uncertainty-Aware Autonomous Vehicles: Predicting the Road Ahead](https://arxiv.org/abs/2510.22680)
*Shireen Kudukkil Manchingal,Armand Amaritei,Mihir Gohad,Maryam Sultana,Julian F. P. Kooij,Fabio Cuzzolin,Andrew Bradley*

Main category: cs.RO

TL;DR: 该研究将随机集神经网络(RS-NNs)集成到自动驾驶车辆软件栈中，使车辆能够量化预测不确定性，在不确定场景下动态调整车速以提高安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶感知系统在罕见事件或样本外数据情况下容易产生过度自信的预测错误，需要让车辆能够'知道何时不确定'。

Method: 使用随机集神经网络(RS-NNs)作为图像分类器，预测类别集合上的置信函数，与传统CNN和贝叶斯神经网络进行对比测试。

Result: RS-NN在多种道路条件下实现了显著更高的准确率和更优的不确定性校准，能够通过预测不确定性动态调节车辆速度。

Conclusion: 不确定性感知神经网络，特别是RS-NNs，是实现更安全、更鲁棒自动驾驶的实用解决方案。

Abstract: Autonomous Vehicle (AV) perception systems have advanced rapidly in recent
years, providing vehicles with the ability to accurately interpret their
environment. Perception systems remain susceptible to errors caused by
overly-confident predictions in the case of rare events or out-of-sample data.
This study equips an autonomous vehicle with the ability to 'know when it is
uncertain', using an uncertainty-aware image classifier as part of the AV
software stack. Specifically, the study exploits the ability of Random-Set
Neural Networks (RS-NNs) to explicitly quantify prediction uncertainty. Unlike
traditional CNNs or Bayesian methods, RS-NNs predict belief functions over sets
of classes, allowing the system to identify and signal uncertainty clearly in
novel or ambiguous scenarios. The system is tested in a real-world autonomous
racing vehicle software stack, with the RS-NN classifying the layout of the
road ahead and providing the associated uncertainty of the prediction.
Performance of the RS-NN under a range of road conditions is compared against
traditional CNN and Bayesian neural networks, with the RS-NN achieving
significantly higher accuracy and superior uncertainty calibration. This
integration of RS-NNs into Robot Operating System (ROS)-based vehicle control
pipeline demonstrates that predictive uncertainty can dynamically modulate
vehicle speed, maintaining high-speed performance under confident predictions
while proactively improving safety through speed reductions in uncertain
scenarios. These results demonstrate the potential of uncertainty-aware neural
networks - in particular RS-NNs - as a practical solution for safer and more
robust autonomous driving.

</details>


### [37] [RL-AVIST: Reinforcement Learning for Autonomous Visual Inspection of Space Targets](https://arxiv.org/abs/2510.22699)
*Matteo El-Hariry,Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: RL-AVIST是一个基于强化学习的自主视觉检查框架，用于航天器在轨道目标周围进行3D近距离机动操作，使用DreamerV3等算法在SRB模拟器中训练智能体。


<details>
  <summary>Details</summary>
Motivation: 传统控制系统在模型不确定性、多航天器配置或动态任务情境下适应性不足，需要智能航天器来支持轨道检查、维护和态势感知等自主服务。

Method: 利用Space Robotics Bench模拟高保真6自由度航天器动力学，使用DreamerV3（基于模型的RL算法）以及PPO和TD3（无模型基线算法）训练智能体，研究3D近距离机动任务。

Result: 基于模型的强化学习在轨迹保真度和样本效率方面表现出有前景的能力，能够适应多种航天器形态和任务领域。

Conclusion: 该方法为未来空间操作提供了可扩展、可重新训练的控制解决方案路径。

Abstract: The growing need for autonomous on-orbit services such as inspection,
maintenance, and situational awareness calls for intelligent spacecraft capable
of complex maneuvers around large orbital targets. Traditional control systems
often fall short in adaptability, especially under model uncertainties,
multi-spacecraft configurations, or dynamically evolving mission contexts. This
paper introduces RL-AVIST, a Reinforcement Learning framework for Autonomous
Visual Inspection of Space Targets. Leveraging the Space Robotics Bench (SRB),
we simulate high-fidelity 6-DOF spacecraft dynamics and train agents using
DreamerV3, a state-of-the-art model-based RL algorithm, with PPO and TD3 as
model-free baselines. Our investigation focuses on 3D proximity maneuvering
tasks around targets such as the Lunar Gateway and other space assets. We
evaluate task performance under two complementary regimes: generalized agents
trained on randomized velocity vectors, and specialized agents trained to
follow fixed trajectories emulating known inspection orbits. Furthermore, we
assess the robustness and generalization of policies across multiple spacecraft
morphologies and mission domains. Results demonstrate that model-based RL
offers promising capabilities in trajectory fidelity, and sample efficiency,
paving the way for scalable, retrainable control solutions for future space
operations

</details>


### [38] [SCAL for Pinch-Lifting: Complementary Rotational and Linear Prototypes for Environment-Adaptive Grasping](https://arxiv.org/abs/2510.22738)
*Wentao Guo,Wenzeng Zhang*

Main category: cs.RO

TL;DR: 提出了两种基于槽约束自适应连杆(SCAL)的环境自适应夹持手指：SCAL-R（旋转驱动，接触后主动折叠形成包络）和SCAL-L（线性驱动，接触时被动张开以抓取宽大或弱特征物体），实现了无需复杂传感和控制的薄型物体夹持提升。


<details>
  <summary>Details</summary>
Motivation: 解决在有限传感和控制条件下，机器人如何自适应地抓取和提升各种形状的物体，特别是薄型、低轮廓或具有弱特征的目标物体。

Method: 开发了两种互补的SCAL手指设计：SCAL-R采用旋转驱动和主动指尖折叠机制，SCAL-L采用线性驱动和被动张开机制。两种设计都将表面跟随转换为向上提升运动，同时保持指尖方向。

Result: 实验表明两种设计在桌面滑动夹持、斜坡协商提升以及大体积物体处理方面均能实现一致的抓取效果，在数十次小零件、盒子、罐子和胶带卷的试验中表现稳定。

Conclusion: SCAL-R和SCAL-L具有互补的工作区域，为使用简单驱动的鲁棒环境自适应抓取提供了实用路径，准静态分析提供了几何感知的设计和操作指导。

Abstract: This paper presents environment-adaptive pinch-lifting built on a
slot-constrained adaptive linkage (SCAL) and instantiated in two complementary
fingers: SCAL-R, a rotational-drive design with an active fingertip that folds
inward after contact to form an envelope, and SCAL-L, a linear-drive design
that passively opens on contact to span wide or weak-feature objects. Both
fingers convert surface following into an upward lifting branch while
maintaining fingertip orientation, enabling thin or low-profile targets to be
raised from supports with minimal sensing and control. Two-finger grippers are
fabricated via PLA-based 3D printing. Experiments evaluate (i)
contact-preserving sliding and pinch-lifting on tabletops, (ii) ramp
negotiation followed by lift, and (iii) handling of bulky objects via active
enveloping (SCAL-R) or contact-triggered passive opening (SCAL-L). Across
dozens of trials on small parts, boxes, jars, and tape rolls, both designs
achieve consistent grasps with limited tuning. A quasi-static analysis provides
closed-form fingertip-force models for linear parallel pinching and two-point
enveloping, offering geometry-aware guidance for design and operation. Overall,
the results indicate complementary operating regimes and a practical path to
robust, environment-adaptive grasping with simple actuation.

</details>


### [39] [Policies over Poses: Reinforcement Learning based Distributed Pose-Graph Optimization for Multi-Robot SLAM](https://arxiv.org/abs/2510.22740)
*Sai Krishna Ghanta,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: 提出基于多智能体强化学习(MARL)的分布式位姿图优化框架，通过图神经网络编码器和混合策略实现噪声边缘去噪和位姿优化，相比现有方法平均减少37.5%的全局目标函数，推理效率提升至少6倍。


<details>
  <summary>Details</summary>
Motivation: 传统迭代方法需要重复求解正规方程，容易陷入局部最小值产生次优估计，需要更鲁棒和高效的分布式PGO解决方案。

Method: 将分布式PGO建模为部分可观测马尔可夫博弈，使用图分割器分解全局位姿图，每个机器人运行带自适应边缘门控的循环图神经网络编码器去噪，通过混合策略结合先验动作记忆和图嵌入来优化位姿，最后通过共识方案协调机器人间差异。

Result: 在合成和真实数据集上评估显示，相比最先进的分布式PGO框架，该方法平均减少37.5%的全局目标函数，推理效率提升至少6倍，且单一学习策略可无需重新训练扩展到更大机器人团队。

Conclusion: 基于MARL的分布式PGO框架在精度和效率上均优于现有方法，具有良好的可扩展性和鲁棒性。

Abstract: We consider the distributed pose-graph optimization (PGO) problem, which is
fundamental in accurate trajectory estimation in multi-robot simultaneous
localization and mapping (SLAM). Conventional iterative approaches linearize a
highly non-convex optimization objective, requiring repeated solving of normal
equations, which often converge to local minima and thus produce suboptimal
estimates. We propose a scalable, outlier-robust distributed planar PGO
framework using Multi-Agent Reinforcement Learning (MARL). We cast distributed
PGO as a partially observable Markov game defined on local pose-graphs, where
each action refines a single edge's pose estimate. A graph partitioner
decomposes the global pose graph, and each robot runs a recurrent
edge-conditioned Graph Neural Network (GNN) encoder with adaptive edge-gating
to denoise noisy edges. Robots sequentially refine poses through a hybrid
policy that utilizes prior action memory and graph embeddings. After local
graph correction, a consensus scheme reconciles inter-robot disagreements to
produce a globally consistent estimate. Our extensive evaluations on a
comprehensive suite of synthetic and real-world datasets demonstrate that our
learned MARL-based actors reduce the global objective by an average of 37.5%
more than the state-of-the-art distributed PGO framework, while enhancing
inference efficiency by at least 6X. We also demonstrate that actor replication
allows a single learned policy to scale effortlessly to substantially larger
robot teams without any retraining. Code is publicly available at
https://github.com/herolab-uga/policies-over-poses.

</details>


### [40] [TWC-SLAM: Multi-Agent Cooperative SLAM with Text Semantics and WiFi Features Integration for Similar Indoor Environments](https://arxiv.org/abs/2510.22754)
*Chunyu Li,Shoubin Chen,Dong Li,Weixing Xue,Qingquan Li*

Main category: cs.RO

TL;DR: TWC-SLAM是一个多智能体协同SLAM框架，通过整合文本语义和WiFi信号特征来提升在重复结构室内环境中的位置识别和闭环检测性能。


<details>
  <summary>Details</summary>
Motivation: 在具有重复结构（如走廊和房间）的相似室内环境中，基于点云的多智能体协同SLAM技术存在共享位置识别不准确的问题。

Method: 基于FAST-LIO2的单智能体前端里程计模块；利用文本语义和WiFi特征的位置识别与闭环检测模块；全局建图模块。智能体配备能够捕获文本信息和检测WiFi信号的传感器。

Result: 在包含相似走廊、房间和文本标志的室内数据集上评估，结果显示TWC-SLAM显著提升了在具有重复建筑特征的复杂环境中协同SLAM系统的性能。

Conclusion: TWC-SLAM通过整合文本语义和WiFi信号特征，有效解决了重复结构室内环境中多智能体协同SLAM的位置识别和地图对齐问题。

Abstract: Multi-agent cooperative SLAM often encounters challenges in similar indoor
environments characterized by repetitive structures, such as corridors and
rooms. These challenges can lead to significant inaccuracies in shared location
identification when employing point cloud-based techniques. To mitigate these
issues, we introduce TWC-SLAM, a multi-agent cooperative SLAM framework that
integrates text semantics and WiFi signal features to enhance location
identification and loop closure detection. TWC-SLAM comprises a single-agent
front-end odometry module based on FAST-LIO2, a location identification and
loop closure detection module that leverages text semantics and WiFi features,
and a global mapping module. The agents are equipped with sensors capable of
capturing textual information and detecting WiFi signals. By correlating these
data sources, TWC-SLAM establishes a common location, facilitating point cloud
alignment across different agents' maps. Furthermore, the system employs loop
closure detection and optimization modules to achieve global optimization and
cohesive mapping. We evaluated our approach using an indoor dataset featuring
similar corridors, rooms, and text signs. The results demonstrate that TWC-SLAM
significantly improves the performance of cooperative SLAM systems in complex
environments with repetitive architectural features.

</details>


### [41] [PIP-LLM: Integrating PDDL-Integer Programming with LLMs for Coordinating Multi-Robot Teams Using Natural Language](https://arxiv.org/abs/2510.22784)
*Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: PIP-LLM是一个基于语言的多机器人协调框架，通过PDDL团队级规划和整数规划机器人级规划的结合，解决了多机器人协调中的任务分解、可扩展性和协调效率问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM和PDDL的方法在单机器人场景中表现良好，但在多机器人协调中存在任务分解脆弱、可扩展性差和协调效率低的问题。

Method: PIP-LLM首先将自然语言命令翻译为团队级PDDL问题并求解，获得抽象掉机器人分配的团队级计划；然后将该计划转换为依赖图，指导机器人级规划，其中每个子任务节点都表述为基于整数规划的任务分配问题。

Result: 在多样化任务上的实验表明，PIP-LLM相比最先进基线方法提高了计划成功率，降低了最大和平均旅行成本，并实现了更好的负载均衡。

Conclusion: PIP-LLM通过将规划与分配分离，避免了基于语法分解的缺陷，能够扩展到更大的团队规模，为多机器人协调提供了有效的解决方案。

Abstract: Enabling robot teams to execute natural language commands requires
translating high-level instructions into feasible, efficient multi-robot plans.
While Large Language Models (LLMs) combined with Planning Domain Description
Language (PDDL) offer promise for single-robot scenarios, existing approaches
struggle with multi-robot coordination due to brittle task decomposition, poor
scalability, and low coordination efficiency.
  We introduce PIP-LLM, a language-based coordination framework that consists
of PDDL-based team-level planning and Integer Programming (IP) based
robot-level planning. PIP-LLMs first decomposes the command by translating the
command into a team-level PDDL problem and solves it to obtain a team-level
plan, abstracting away robot assignment. Each team-level action represents a
subtask to be finished by the team. Next, this plan is translated into a
dependency graph representing the subtasks' dependency structure. Such a
dependency graph is then used to guide the robot-level planning, in which each
subtask node will be formulated as an IP-based task allocation problem,
explicitly optimizing travel costs and workload while respecting robot
capabilities and user-defined constraints. This separation of planning from
assignment allows PIP-LLM to avoid the pitfalls of syntax-based decomposition
and scale to larger teams. Experiments across diverse tasks show that PIP-LLM
improves plan success rate, reduces maximum and average travel costs, and
achieves better load balancing compared to state-of-the-art baselines.

</details>


### [42] [Learning Neural Observer-Predictor Models for Limb-level Sampling-based Locomotion Planning](https://arxiv.org/abs/2510.22789)
*Abhijeet M. Kulkarni,Ioannis Poulakakis,Guoquan Huang*

Main category: cs.RO

TL;DR: 提出了一种基于学习的观测器-预测器框架，用于准确预测四足机器人的全身运动，解决了简化运动学模型无法捕捉复杂闭环动态的问题。


<details>
  <summary>Details</summary>
Motivation: 精确的全身运动预测对于腿式机器人的安全自主导航至关重要，特别是在杂乱环境中进行肢体级碰撞检测。现有简化运动学模型无法准确捕捉机器人和底层控制器的复杂闭环动态。

Method: 采用学习型观测器-预测器框架，包括具有可证明UUB保证的神经观测器，从本体感知测量历史中提供可靠的潜在状态估计，然后初始化计算高效的预测器进行快速轨迹评估。

Result: 在Vision 60四足机器人上集成神经预测器到MPPI规划器中，硬件实验成功展示了在挑战性狭窄通道和小物体上的有效肢体感知运动规划。

Conclusion: 该系统为动态机器人平台上的高性能、碰撞感知规划提供了稳健基础，能够实现肢体级的精确运动预测和规划。

Abstract: Accurate full-body motion prediction is essential for the safe, autonomous
navigation of legged robots, enabling critical capabilities like limb-level
collision checking in cluttered environments. Simplified kinematic models often
fail to capture the complex, closed-loop dynamics of the robot and its
low-level controller, limiting their predictions to simple planar motion. To
address this, we present a learning-based observer-predictor framework that
accurately predicts this motion. Our method features a neural observer with
provable UUB guarantees that provides a reliable latent state estimate from a
history of proprioceptive measurements. This stable estimate initializes a
computationally efficient predictor, designed for the rapid, parallel
evaluation of thousands of potential trajectories required by modern
sampling-based planners. We validated the system by integrating our neural
predictor into an MPPI-based planner on a Vision 60 quadruped. Hardware
experiments successfully demonstrated effective, limb-aware motion planning in
a challenging, narrow passage and over small objects, highlighting our system's
ability to provide a robust foundation for high-performance, collision-aware
planning on dynamic robotic platforms.

</details>


### [43] [Analytical Swarm Chemistry: Characterization and Analysis of Emergent Swarm Behaviors](https://arxiv.org/abs/2510.22821)
*Ricardo Vega,Connor Mattson,Kevin Zhu,Daniel S. Brown,Cameron Nowzari*

Main category: cs.RO

TL;DR: 提出了Analytical Swarm Chemistry框架，将工程学、基于代理的研究和化学概念结合，通过相图分析系统探索群体参数对涌现行为的影响。


<details>
  <summary>Details</summary>
Motivation: 群体机器人技术应用广泛，但实际部署稀少，因为难以预测简单局部交互产生的涌现行为。传统工程方法在理想条件下设计控制器，而基于代理的研究则自下而上探索涌现现象。

Method: 结合宏观状态定义和相图分析，将参数视为热力学变量，可视化参数空间中产生特定行为的区域。应用于具有最小可行能力的代理，识别产生特定行为（如旋转和扩散）的充分条件。

Result: 识别了可靠产生旋转和扩散等行为的参数空间区域。在真实机器人上的初步验证表明这些区域在实践中对应可观察的行为。

Conclusion: 该框架为现实世界群体系统提供了可预测和可靠的涌现行为的基础，通过提供原则性、可解释的方法。

Abstract: Swarm robotics has potential for a wide variety of applications, but
real-world deployments remain rare due to the difficulty of predicting emergent
behaviors arising from simple local interactions. Traditional engineering
approaches design controllers to achieve desired macroscopic outcomes under
idealized conditions, while agent-based and artificial life studies explore
emergent phenomena in a bottom-up, exploratory manner. In this work, we
introduce Analytical Swarm Chemistry, a framework that integrates concepts from
engineering, agent-based and artificial life research, and chemistry. This
framework combines macrostate definitions with phase diagram analysis to
systematically explore how swarm parameters influence emergent behavior.
Inspired by concepts from chemistry, the framework treats parameters like
thermodynamic variables, enabling visualization of regions in parameter space
that give rise to specific behaviors. Applying this framework to agents with
minimally viable capabilities, we identify sufficient conditions for behaviors
such as milling and diffusion and uncover regions of the parameter space that
reliably produce these behaviors. Preliminary validation on real robots
demonstrates that these regions correspond to observable behaviors in practice.
By providing a principled, interpretable approach, this framework lays the
groundwork for predictable and reliable emergent behavior in real-world swarm
systems.

</details>


### [44] [Kinematically Controllable Cable Robots with Reconfigurable End-effectors](https://arxiv.org/abs/2510.22825)
*Nan Zhang*

Main category: cs.RO

TL;DR: 设计可重构末端执行器解决缆绳驱动机器人的旋转工作空间受限和张力解不唯一问题，通过弹簧、螺旋槽轴和螺母将线性运动转换为旋转运动，并引入轴承提供额外旋转自由度。


<details>
  <summary>Details</summary>
Motivation: 增加缆绳数量会扩大平移工作空间，但会带来两个问题：(1)缆绳干涉显著减少旋转工作空间，(2)缆绳张力解不唯一，给机器人运动控制带来困难。

Method: 设计结构简单的可重构末端执行器，包含弹簧、螺旋槽轴和匹配螺母，将末端执行器组件间的相对线性运动转换为相对旋转运动，同时引入轴承提供额外旋转自由度。

Result: 扩展了机构的旋转工作空间，使机构非冗余，机器人运动可以通过纯运动学控制，无需额外的张力传感和控制。

Conclusion: 所提出的可重构末端执行器设计有效解决了缆绳驱动机器人的旋转工作空间受限和控制问题，实现了纯运动学控制。

Abstract: To enlarge the translational workspace of cable-driven robots, one common
approach is to increase the number of cables. However, this introduces two
challenges: (1) cable interference significantly reduces the rotational
workspace, and (2) the solution of tensions in cables becomes non-unique,
resulting in difficulties for kinematic control of the robot. In this work, we
design structurally simple reconfigurable end-effectors for cable robots. By
incorporating a spring, a helical-grooved shaft, and a matching nut, relative
linear motions between end-effector components are converted into relative
rotations, thereby expanding the rotational workspace of the mechanism.
Meanwhile, a bearing is introduced to provide an additional rotational degree
of freedom, making the mechanism non-redundant. As a result, the robot's motion
can be controlled purely through kinematics without additional tension sensing
and control.

</details>


### [45] [Never Too Rigid to Reach: Adaptive Virtual Model Control with LLM- and Lyapunov-Based Reinforcement Learning](https://arxiv.org/abs/2510.22892)
*Jingzehua Xu,Yangyang Li,Yangfei Chen,Guanwen Xie,Shuai Zhang*

Main category: cs.RO

TL;DR: 提出自适应虚拟模型控制，结合大语言模型和Lyapunov强化学习，在保持物理可解释性的同时实现稳定性保证的在线适应。


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制方法在不确定环境中变得僵化和脆弱，虚拟模型控制虽然能实现柔顺行为，但依赖固定参数且虚拟组件间协调有限，限制了适应性和稳定性。

Method: 使用LLM提供结构化先验和高层推理来增强虚拟组件协调，结合Lyapunov强化学习强制执行理论稳定性约束，确保不确定环境下的安全适应。

Result: 在7自由度Panda机械臂上的大量仿真表明，该方法在动态任务中有效平衡了竞争目标，实现了优越性能。

Conclusion: 该方法展示了LLM引导和Lyapunov约束适应的协同效益，为不确定环境下的机器人控制提供了新的解决方案。

Abstract: Robotic arms are increasingly deployed in uncertain environments, yet
conventional control pipelines often become rigid and brittle when exposed to
perturbations or incomplete information. Virtual Model Control (VMC) enables
compliant behaviors by embedding virtual forces and mapping them into joint
torques, but its reliance on fixed parameters and limited coordination among
virtual components constrains adaptability and may undermine stability as task
objectives evolve. To address these limitations, we propose Adaptive VMC with
Large Language Model (LLM)- and Lyapunov-Based Reinforcement Learning (RL),
which preserves the physical interpretability of VMC while supporting
stability-guaranteed online adaptation. The LLM provides structured priors and
high-level reasoning that enhance coordination among virtual components,
improve sample efficiency, and facilitate flexible adjustment to varying task
requirements. Complementarily, Lyapunov-based RL enforces theoretical stability
constraints, ensuring safe and reliable adaptation under uncertainty. Extensive
simulations on a 7-DoF Panda arm demonstrate that our approach effectively
balances competing objectives in dynamic tasks, achieving superior performance
while highlighting the synergistic benefits of LLM guidance and
Lyapunov-constrained adaptation.

</details>


### [46] [HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment](https://arxiv.org/abs/2510.22917)
*Zecheng Yin,Hao Zhao,Zhen Li*

Main category: cs.RO

TL;DR: 提出了HyPerNav方法，利用视觉语言模型融合局部RGB-D观测和全局俯视图，提升未知环境中的目标导向导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多只关注单一感知源，很少整合互补的局部和全局信息，而人类自然同时关注这两种感知模态。

Method: 利用视觉语言模型的强大推理和视觉语言理解能力，联合感知局部RGB-D观测和实时俯视图，实现混合感知导航。

Result: 在大规模仿真评估和真实世界验证中，方法达到了最先进的性能，混合感知方法能捕获更丰富的线索并更有效地找到目标物体。

Conclusion: 混合感知方法通过同时利用第一人称观测和俯视图的信息理解，显著提升了导航性能，消融研究证明两种感知源都对导航性能有贡献。

Abstract: Objective-oriented navigation(ObjNav) enables robot to navigate to target
object directly and autonomously in an unknown environment. Effective
perception in navigation in unknown environment is critical for autonomous
robots. While egocentric observations from RGB-D sensors provide abundant local
information, real-time top-down maps offer valuable global context for ObjNav.
Nevertheless, the majority of existing studies focus on a single source, seldom
integrating these two complementary perceptual modalities, despite the fact
that humans naturally attend to both. With the rapid advancement of
Vision-Language Models(VLMs), we propose Hybrid Perception Navigation
(HyPerNav), leveraging VLMs' strong reasoning and vision-language understanding
capabilities to jointly perceive both local and global information to enhance
the effectiveness and intelligence of navigation in unknown environments. In
both massive simulation evaluation and real-world validation, our methods
achieved state-of-the-art performance against popular baselines. Benefiting
from hybrid perception approach, our method captures richer cues and finds the
objects more effectively, by simultaneously leveraging information
understanding from egocentric observations and the top-down map. Our ablation
study further proved that either of the hybrid perception contributes to the
navigation performance.

</details>


### [47] [End-to-End Design and Validation of a Low-Cost Stewart Platform with Nonlinear Estimation and Control](https://arxiv.org/abs/2510.22949)
*Benedictus C. G. Cinun,Tua A. Tamba,Immanuel R. Santjoko,Xiaofeng Wang,Michael A. Gunarso,Bin Hu*

Main category: cs.RO

TL;DR: 本文介绍了一个低成本Stewart平台原型的设计、控制和实验验证，该平台结合现成组件和3D打印部件，实现了六自由度运动控制，并集成了动态建模、数据采集和实时控制的统一软件框架。


<details>
  <summary>Details</summary>
Motivation: 开发一个经济实惠但功能齐全的机器人测试平台，用于研究和教育应用，弥补现有工作只关注建模或控制等孤立方面的不足。

Method: 使用现成组件与3D打印定制部件构建硬件平台，采用基于反馈线性化和LQR方案的鲁棒轨迹跟踪控制器，结合扩展卡尔曼滤波器融合IMU和执行器编码器数据进行状态估计。

Result: 通过静态和动态轨迹的仿真和实验验证，平台实现了有效的轨迹跟踪和实时状态估计，展示了其作为成本效益高且多功能工具的潜力。

Conclusion: 该工作提供了一个完整的硬件-软件平台，证明了其在高级研究和教育应用中的可行性和有效性。

Abstract: This paper presents the complete design, control, and experimental validation
of a low-cost Stewart platform prototype developed as an affordable yet capable
robotic testbed for research and education. The platform combines off the shelf
components with 3D printed and custom fabricated parts to deliver full six
degrees of freedom motions using six linear actuators connecting a moving
platform to a fixed base. The system software integrates dynamic modeling, data
acquisition, and real time control within a unified framework. A robust
trajectory tracking controller based on feedback linearization, augmented with
an LQR scheme, compensates for the platform's nonlinear dynamics to achieve
precise motion control. In parallel, an Extended Kalman Filter fuses IMU and
actuator encoder feedback to provide accurate and reliable state estimation
under sensor noise and external disturbances. Unlike prior efforts that
emphasize only isolated aspects such as modeling or control, this work delivers
a complete hardware-software platform validated through both simulation and
experiments on static and dynamic trajectories. Results demonstrate effective
trajectory tracking and real-time state estimation, highlighting the platform's
potential as a cost effective and versatile tool for advanced research and
educational applications.

</details>


### [48] [An Intelligent Water-Saving Irrigation System Based on Multi-Sensor Fusion and Visual Servoing Control](https://arxiv.org/abs/2510.23003)
*ZhengKai Huang,YiKun Wang,ChenYu Hui,XiaoCheng*

Main category: cs.RO

TL;DR: 开发了一套智能节水灌溉系统，通过计算机视觉、机器人控制和实时稳定技术，实现精准灌溉，在三种模拟农业环境中节水30-50%，用水效率超过92%。


<details>
  <summary>Details</summary>
Motivation: 解决精准农业中的水资源浪费和地形适应性差等关键挑战，提高灌溉效率和水资源利用率。

Method: 采用多传感器融合方法，集成轻量级YOLO模型（部署在K210嵌入式视觉处理器上）进行实时植物容器检测，简化手眼标定算法实现精确定位，以及基于STM32F103ZET6和JY901S惯性测量的主动调平系统。

Result: 植物容器检测准确率超过96%，末端执行器定位成功率超过90%，在10度坡度上稳定平台响应时间1.8秒，相比传统漫灌节水30-50%，所有测试案例用水效率超过92%。

Conclusion: 该系统成功实现了高效精准灌溉，显著提高了水资源利用效率，为现代农业提供了可行的智能灌溉解决方案。

Abstract: This paper introduces an intelligent water-saving irrigation system designed
to address critical challenges in precision agriculture, such as inefficient
water use and poor terrain adaptability. The system integrates advanced
computer vision, robotic control, and real-time stabilization technologies via
a multi-sensor fusion approach. A lightweight YOLO model, deployed on an
embedded vision processor (K210), enables real-time plant container detection
with over 96% accuracy under varying lighting conditions. A simplified hand-eye
calibration algorithm-designed for 'handheld camera' robot arm
configurations-ensures that the end effector can be precisely positioned, with
a success rate exceeding 90%. The active leveling system, driven by the
STM32F103ZET6 main control chip and JY901S inertial measurement data, can
stabilize the irrigation platform on slopes up to 10 degrees, with a response
time of 1.8 seconds. Experimental results across three simulated agricultural
environments (standard greenhouse, hilly terrain, complex lighting) demonstrate
a 30-50% reduction in water consumption compared to conventional flood
irrigation, with water use efficiency exceeding 92% in all test cases.

</details>


### [49] [ManiDP: Manipulability-Aware Diffusion Policy for Posture-Dependent Bimanual Manipulation](https://arxiv.org/abs/2510.23016)
*Zhuo Li,Junjia Liu,Dianxi Li,Tao Teng,Miao Li,Sylvain Calinon,Darwin Caldwell,Fei Chen*

Main category: cs.RO

TL;DR: 提出ManiDP方法，通过提取双手机器人的可操作性特征并整合到扩散模型中，优化双臂配置以满足姿态相关的任务需求，在6个真实世界任务中显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了姿态相关任务特征的学习，而这些特征对于适应双臂配置以满足灵巧双手操作中的特定力和速度要求至关重要。

Method: 从专家演示中提取双手可操作性，使用基于黎曼的概率模型编码姿态特征，并将其整合到条件扩散过程中指导生成任务兼容的双手运动序列。

Result: 在6个真实世界双手任务中，平均操作成功率提高39.33%，任务兼容性提升0.45，相比基线方法有显著改进。

Conclusion: 将姿态相关的机器人先验知识整合到双手技能扩散中，能够实现类人的适应性和灵巧性。

Abstract: Recent work has demonstrated the potential of diffusion models in robot
bimanual skill learning. However, existing methods ignore the learning of
posture-dependent task features, which are crucial for adapting dual-arm
configurations to meet specific force and velocity requirements in dexterous
bimanual manipulation. To address this limitation, we propose
Manipulability-Aware Diffusion Policy (ManiDP), a novel imitation learning
method that not only generates plausible bimanual trajectories, but also
optimizes dual-arm configurations to better satisfy posture-dependent task
requirements. ManiDP achieves this by extracting bimanual manipulability from
expert demonstrations and encoding the encapsulated posture features using
Riemannian-based probabilistic models. These encoded posture features are then
incorporated into a conditional diffusion process to guide the generation of
task-compatible bimanual motion sequences. We evaluate ManiDP on six real-world
bimanual tasks, where the experimental results demonstrate a 39.33$\%$ increase
in average manipulation success rate and a 0.45 improvement in task
compatibility compared to baseline methods. This work highlights the importance
of integrating posture-relevant robotic priors into bimanual skill diffusion to
enable human-like adaptability and dexterity.

</details>


### [50] [Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot Navigation](https://arxiv.org/abs/2510.23057)
*Oskar Natan,Jun Miura*

Main category: cs.RO

TL;DR: Seq-DeepIPC是一个用于腿式机器人导航的序列化端到端感知-控制模型，整合多模态感知（RGB-D+GNSS）与时间融合，在边缘设备上高效部署，在真实环境中验证了性能。


<details>
  <summary>Details</summary>
Motivation: 将端到端导航从轮式机器人扩展到更通用、具有时间感知能力的腿式机器人系统，通过紧密集成多模态感知和控制来提升腿式机器人在真实环境中的导航能力。

Method: 使用EfficientNet-B0作为编码器减少计算量，通过连续GNSS位置直接计算航向角替代噪声IMU，联合预测语义分割和深度估计，采用序列化输入进行时间融合。

Result: 在机器人狗上验证，序列化输入改善了感知和控制性能，模型大小合理且结果具有竞争力，在开放区域GNSS航向估计稳健，但在高楼附近可靠性较低。

Conclusion: Seq-DeepIPC成功将端到端导航扩展到腿式机器人，展示了序列化多模态感知与控制集成的有效性，为更通用的时间感知导航系统奠定了基础。

Abstract: We present Seq-DeepIPC, a sequential end-to-end perception-to-control model
for legged robot navigation in realworld environments. Seq-DeepIPC advances
intelligent sensing for autonomous legged navigation by tightly integrating
multi-modal perception (RGB-D + GNSS) with temporal fusion and control. The
model jointly predicts semantic segmentation and depth estimation, giving
richer spatial features for planning and control. For efficient deployment on
edge devices, we use EfficientNet-B0 as the encoder, reducing computation while
maintaining accuracy. Heading estimation is simplified by removing the noisy
IMU and instead computing the bearing angle directly from consecutive GNSS
positions. We collected a larger and more diverse dataset that includes both
road and grass terrains, and validated Seq-DeepIPC on a robot dog. Comparative
and ablation studies show that sequential inputs improve perception and control
in our models, while other baselines do not benefit. Seq-DeepIPC achieves
competitive or better results with reasonable model size; although GNSS-only
heading is less reliable near tall buildings, it is robust in open areas.
Overall, Seq-DeepIPC extends end-to-end navigation beyond wheeled robots to
more versatile and temporally-aware systems. To support future research, we
will release the codes to our GitHub repository at
https://github.com/oskarnatan/Seq-DeepIPC.

</details>


### [51] [Awakening Facial Emotional Expressions in Human-Robot](https://arxiv.org/abs/2510.23059)
*Yongtong Zhu,Lei Li,Iggy Qian,WenBin Zhou,Ye Yuan,Qingdu Li,Na Liu,Jianwei Zhang*

Main category: cs.RO

TL;DR: 提出基于KAN和注意力机制的端到端学习框架，使人形社交机器人能够通过自训练学习人类表情，实现准确多样的面部模仿。


<details>
  <summary>Details</summary>
Motivation: 解决人形社交机器人面部表情生成依赖预编程行为模式的问题，降低人工编码成本，使机器人能够自主获取通用的表达能力。

Method: 设计高度仿生的机器人面部，开发基于KAN和注意力机制的端到端学习框架，并构建基于面部运动基元专家策略的自动化数据收集系统。

Result: 实现了跨不同测试对象的准确多样的面部模仿，并创建了首个开源的人形社交机器人面部数据集。

Conclusion: 该方法有效提升了人形社交机器人的面部表情生成能力，为实现自然的人机交互提供了可行方案。

Abstract: The facial expression generation capability of humanoid social robots is
critical for achieving natural and human-like interactions, playing a vital
role in enhancing the fluidity of human-robot interactions and the accuracy of
emotional expression. Currently, facial expression generation in humanoid
social robots still relies on pre-programmed behavioral patterns, which are
manually coded at high human and time costs. To enable humanoid robots to
autonomously acquire generalized expressive capabilities, they need to develop
the ability to learn human-like expressions through self-training. To address
this challenge, we have designed a highly biomimetic robotic face with
physical-electronic animated facial units and developed an end-to-end learning
framework based on KAN (Kolmogorov-Arnold Network) and attention mechanisms.
Unlike previous humanoid social robots, we have also meticulously designed an
automated data collection system based on expert strategies of facial motion
primitives to construct the dataset. Notably, to the best of our knowledge,
this is the first open-source facial dataset for humanoid social robots.
Comprehensive evaluations indicate that our approach achieves accurate and
diverse facial mimicry across different test subjects.

</details>


### [52] [Breaking the Circle: An Autonomous Control-Switching Strategy for Stable Orographic Soaring in MAVs](https://arxiv.org/abs/2510.23084)
*Sunyou Hwang,Christophe De Wagter,Bart Remes,Guido de Croon*

Main category: cs.RO

TL;DR: 提出SAOS切换控制方法，通过选择性控制水平或垂直轴来减轻地形翱翔中的盘旋行为，将系统从欠驱动转变为全驱动状态，提高能量效率和飞行稳定性。


<details>
  <summary>Details</summary>
Motivation: 地形翱翔可显著延长微型飞行器的续航时间，但盘旋行为会导致能量消耗增加和发散风险，需要解决纵向和垂直轴之间的控制冲突问题。

Method: 采用切换控制方法SAOS，选择性控制水平或垂直轴，将系统从欠驱动转变为全驱动；在INDI控制器中引入攻角以改进力估计。

Result: 仿真和风洞实验表明，SAOS改善了位置收敛，减少了油门使用，减轻了俯仰-滚转耦合引起的滚转振荡。

Conclusion: SAOS方法在受限翱翔环境中提高了能量效率和飞行稳定性，有效解决了盘旋行为问题。

Abstract: Orographic soaring can significantly extend the endurance of micro aerial
vehicles (MAVs), but circling behavior, arising from control conflicts between
the longitudinal and vertical axes, increases energy consumption and the risk
of divergence. We propose a control switching method, named SAOS: Switched
Control for Autonomous Orographic Soaring, which mitigates circling behavior by
selectively controlling either the horizontal or vertical axis, effectively
transforming the system from underactuated to fully actuated during soaring.
Additionally, the angle of attack is incorporated into the INDI controller to
improve force estimation. Simulations with randomized initial positions and
wind tunnel experiments on two MAVs demonstrate that the SAOS improves position
convergence, reduces throttle usage, and mitigates roll oscillations caused by
pitch-roll coupling. These improvements enhance energy efficiency and flight
stability in constrained soaring environments.

</details>


### [53] [An Automated Tape Laying System Employing a Uniaxial Force Control Device](https://arxiv.org/abs/2510.23109)
*Bernhard Rameder,Hubert Gattringer,Ronald Naderer,Andreas Mueller*

Main category: cs.RO

TL;DR: 设计具有集成单轴力控制和精确温度控制的成本效益型自动铺带系统，通过特殊机器人控制概念实现复杂形状处理，使用碳纤维增强HDPE胶带验证系统功能


<details>
  <summary>Details</summary>
Motivation: 确保铺带过程中必要的压实力和适当的胶带熔化温度，控制基材和胶带达到特定温度水平以实现产品不同层之间的最佳固结

Method: 将系统分为胶带存储卷轴、导向辊、处理单元、加热区和固结单元等模块，采用特殊机器人控制概念（胶带铺设装置空间固定，通过机器人移动形状），使用碳纤维增强HDPE胶带进行实验验证

Result: 子系统功能和铺带过程在实验中得到验证，系统能够处理紧凑和复杂形状

Conclusion: 开发的ATL系统成功实现了成本效益型自动化铺带，集成了力控制和温度控制，通过特殊机器人控制方案有效处理复杂几何形状

Abstract: This paper deals with the design of a cost effective automated tape laying
system (ATL system) with integrated uniaxial force control to ensure the
necessary compaction forces as well as with an accurate temperature control to
guarantee the used tape being melted appropriate. It is crucial to control the
substrate and the oncoming tape onto a specific temperature level to ensure an
optimal consolidation between the different layers of the product. Therefore,
it takes several process steps from the spooled tape on the coil until it is
finally tacked onto the desired mold. The different modules are divided into
the tape storage spool, a tape-guiding roller, a tape processing unit, a
heating zone and the consolidation unit. Moreover, a special robot control
concept for testing the ATL system is presented. In contrast to many other
systems, with this approach, the tape laying device is spatially fixed and the
shape is moved accordingly by the robot, which allows for handling of rather
compact and complex shapes. The functionality of the subsystems and the taping
process itself was finally approved in experimental results using a carbon
fiber reinforced HDPE tape.

</details>


### [54] [OmniDexGrasp: Generalizable Dexterous Grasping via Foundation Model and Force Feedback](https://arxiv.org/abs/2510.23119)
*Yi-Lin Wei,Zhexi Luo,Yuhao Lin,Mu Lin,Zhizhao Liang,Shuoyu Chen,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: OmniDexGrasp是一个通用框架，通过结合基础模型与转移控制策略，实现了用户提示、灵巧体现和抓取任务的全面能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在不同物体或任务间泛化，基础模型提供了增强泛化的新途径，但直接利用它们生成可行的机器人动作仍存在挑战。

Method: 集成三个关键模块：使用基础模型生成人类抓取图像以增强泛化；人类图像到机器人动作转移策略；力感知自适应抓取策略。

Result: 仿真和真实机器人实验验证了OmniDexGrasp在不同用户提示、抓取任务和灵巧手上的有效性，并展示了其在灵巧操作任务上的可扩展性。

Conclusion: OmniDexGrasp通过结合基础模型与转移控制策略，成功实现了通用化的灵巧抓取和操作能力。

Abstract: Enabling robots to dexterously grasp and manipulate objects based on human
commands is a promising direction in robotics. However, existing approaches are
challenging to generalize across diverse objects or tasks due to the limited
scale of semantic dexterous grasp datasets. Foundation models offer a new way
to enhance generalization, yet directly leveraging them to generate feasible
robotic actions remains challenging due to the gap between abstract model
knowledge and physical robot execution. To address these challenges, we propose
OmniDexGrasp, a generalizable framework that achieves omni-capabilities in user
prompting, dexterous embodiment, and grasping tasks by combining foundation
models with the transfer and control strategies. OmniDexGrasp integrates three
key modules: (i) foundation models are used to enhance generalization by
generating human grasp images supporting omni-capability of user prompt and
task; (ii) a human-image-to-robot-action transfer strategy converts human
demonstrations into executable robot actions, enabling omni dexterous
embodiment; (iii) force-aware adaptive grasp strategy ensures robust and stable
grasp execution. Experiments in simulation and on real robots validate the
effectiveness of OmniDexGrasp on diverse user prompts, grasp task and dexterous
hands, and further results show its extensibility to dexterous manipulation
tasks.

</details>


### [55] [Reliable Robotic Task Execution in the Face of Anomalies](https://arxiv.org/abs/2510.23121)
*Bharath Santhanam,Alex Mitrevski,Santosh Thoduka,Sebastian Houben,Teena Hassan*

Main category: cs.RO

TL;DR: 提出一个结合学习策略与视觉异常检测的框架，通过三级恢复过程处理执行失败，提高机器人在开放环境中的可靠性和安全性。


<details>
  <summary>Details</summary>
Motivation: 学习到的机器人策略虽然通用，但在开放环境中容易因无法识别和处理异常而失败，导致不可靠和不安全的行为。

Method: 训练异常检测模型识别策略执行中的视觉异常，并集成三级恢复过程：暂停执行、局部状态扰动、从学习到的执行成功模型中重置到安全状态。

Result: 在两个场景（门把手到达任务和物体放置任务）中验证，集成异常检测和恢复机制显著提高了在存在轨迹偏差和人为干扰等异常情况下的执行成功率。

Conclusion: 将策略执行与异常检测和恢复相结合，能够有效提升机器人在复杂环境中的可靠性和安全性。

Abstract: Learned robot policies have consistently been shown to be versatile, but they
typically have no built-in mechanism for handling the complexity of open
environments, making them prone to execution failures; this implies that
deploying policies without the ability to recognise and react to failures may
lead to unreliable and unsafe robot behaviour. In this paper, we present a
framework that couples a learned policy with a method to detect visual
anomalies during policy deployment and to perform recovery behaviours when
necessary, thereby aiming to prevent failures. Specifically, we train an
anomaly detection model using data collected during nominal executions of a
trained policy. This model is then integrated into the online policy execution
process, so that deviations from the nominal execution can trigger a
three-level sequential recovery process that consists of (i) pausing the
execution temporarily, (ii) performing a local perturbation of the robot's
state, and (iii) resetting the robot to a safe state by sampling from a learned
execution success model. We verify our proposed method in two different
scenarios: (i) a door handle reaching task with a Kinova Gen3 arm using a
policy trained in simulation and transferred to the real robot, and (ii) an
object placing task with a UFactory xArm 6 using a general-purpose policy
model. Our results show that integrating policy execution with anomaly
detection and recovery increases the execution success rate in environments
with various anomalies, such as trajectory deviations and adversarial human
interventions.

</details>


### [56] [Combining High Level Scheduling and Low Level Control to Manage Fleets of Mobile Robots](https://arxiv.org/abs/2510.23129)
*Sabino Francesco Roselli,Ze Zhang,Knut Åkesson*

Main category: cs.RO

TL;DR: 提出一个用于工业环境中大规模移动机器人车队协调的两层框架，结合高层调度和低层控制，确保安全无碰撞操作并支持快速重调度。


<details>
  <summary>Details</summary>
Motivation: 工业环境中移动机器人物料搬运需要在大规模动态环境下进行可扩展的协调，应对机器人故障和环境变化等干扰。

Method: 使用ComSat算法进行任务分配和调度，生成时间参数化路径，然后通过分布式模型预测控制(MPC)实时计算局部参考轨迹，考虑静态和动态障碍物。

Result: 在模拟2D环境中评估，展示了高任务完成率和在拥堵情况下的鲁棒行为，框架的模块化结构保证了计算可行性和灵活性。

Conclusion: 该框架适用于复杂现实工业场景，能够有效协调大规模机器人车队，确保安全操作并快速响应干扰。

Abstract: The deployment of mobile robots for material handling in industrial
environments requires scalable coordination of large fleets in dynamic
settings. This paper presents a two-layer framework that combines high-level
scheduling with low-level control. Tasks are assigned and scheduled using the
compositional algorithm ComSat, which generates time-parameterized routes for
each robot. These schedules are then used by a distributed Model Predictive
Control (MPC) system in real time to compute local reference trajectories,
accounting for static and dynamic obstacles. The approach ensures safe,
collision-free operation, and supports rapid rescheduling in response to
disruptions such as robot failures or environmental changes. We evaluate the
method in simulated 2D environments with varying road capacities and traffic
conditions, demonstrating high task completion rates and robust behavior even
under congestion. The modular structure of the framework allows for
computational tractability and flexibility, making it suitable for deployment
in complex, real-world industrial scenarios.

</details>


### [57] [TARC: Time-Adaptive Robotic Control](https://arxiv.org/abs/2510.23176)
*Arnav Sukhija,Lenart Treven,Jin Cheng,Florian Dörfler,Stelian Coros,Andreas Krause*

Main category: cs.RO

TL;DR: 提出了一种强化学习方法，让机器人能够自主调整控制频率以适应不同情境需求，在两种硬件平台上验证了该方法优于固定频率控制。


<details>
  <summary>Details</summary>
Motivation: 固定频率控制在机器人领域存在效率与鲁棒性的权衡，而生物系统能够自适应调整控制频率，这启发了研究可变频率控制方法。

Method: 使用强化学习策略，联合选择控制动作及其应用持续时间，使机器人能够根据情境需求自主调节控制频率。

Result: 在高速遥控车和四足机器人上的零样本仿真到真实实验表明，该方法在奖励方面匹配或优于固定频率基线，同时显著降低控制频率并在真实条件下表现出自适应频率控制能力。

Conclusion: 该方法成功解决了固定频率控制的局限性，实现了类似生物系统的自适应控制频率调节，在真实机器人平台上验证了其有效性。

Abstract: Fixed-frequency control in robotics imposes a trade-off between the
efficiency of low-frequency control and the robustness of high-frequency
control, a limitation not seen in adaptable biological systems. We address this
with a reinforcement learning approach in which policies jointly select control
actions and their application durations, enabling robots to autonomously
modulate their control frequency in response to situational demands. We
validate our method with zero-shot sim-to-real experiments on two distinct
hardware platforms: a high-speed RC car and a quadrupedal robot. Our method
matches or outperforms fixed-frequency baselines in terms of rewards while
significantly reducing the control frequency and exhibiting adaptive frequency
control under real-world conditions.

</details>


### [58] [If They Disagree, Will You Conform? Exploring the Role of Robots' Value Awareness in a Decision-Making Task](https://arxiv.org/abs/2510.23204)
*Giulia Pusceddu,Giulio Antonio Abbo,Francesco Rea,Tony Belpaeme,Alessandra Sciutti*

Main category: cs.RO

TL;DR: 研究表明，当机器人表现出对人类价值观的理解时，其意见更容易影响人类决策。参与者能区分价值观感知型和非感知型机器人，更关注前者并认为其更忠诚。当两个机器人同时反对参与者时，约1/4的试验中出现从众行为，且决策时间延长。


<details>
  <summary>Details</summary>
Motivation: 探究机器人是否在表现出对人类价值观的理解时，能更有效地影响人类决策，以及这种影响可能带来的伦理风险与积极意义。

Method: 设计实验让参与者与两个Furhat机器人互动：一个被编程为价值观感知型，另一个为非感知型。在图像标注任务中观察参与者的选择、注视行为和决策时间。

Result: 参与者能区分两种机器人类型；虽然明确选择无显著偏好，但更关注价值观感知型机器人；认为价值观感知型机器人更忠诚；当两个机器人同时反对时，约25%试验出现从众行为，且决策时间延长。

Conclusion: 机器人对人类价值观的感知能力能增强其影响力，可能被滥用于不道德目的，但也可能在模糊情境中促使用户反思，帮助避免受骗。

Abstract: This study investigates whether the opinions of robotic agents are more
likely to influence human decision-making when the robots are perceived as
value-aware (i.e., when they display an understanding of human principles). We
designed an experiment in which participants interacted with two Furhat robots
- one programmed to be Value-Aware and the other Non-Value-Aware - during a
labeling task for images representing human values. Results indicate that
participants distinguished the Value-Aware robot from the Non-Value-Aware one.
Although their explicit choices did not indicate a clear preference for one
robot over the other, participants directed their gaze more toward the
Value-Aware robot. Additionally, the Value-Aware robot was perceived as more
loyal, suggesting that value awareness in a social robot may enhance its
perceived commitment to the group. Finally, when both robots disagreed with the
participant, conformity occurred in about one out of four trials, and
participants took longer to confirm their responses, suggesting that two robots
expressing dissent may introduce hesitation in decision-making. On one hand,
this highlights the potential risk that robots, if misused, could manipulate
users for unethical purposes. On the other hand, it reinforces the idea that
social robots might encourage reflection in ambiguous situations and help users
avoid scams.

</details>


### [59] [Workspace Registration and Collision Detection for Industrial Robotics Applications](https://arxiv.org/abs/2510.23227)
*Klaus Zauner,Josef El Dib,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 比较不同传感器在机器人运动规划中的应用，展示从环境检测到完整碰撞环境的处理流程，并检测机器人与环境的碰撞。


<details>
  <summary>Details</summary>
Motivation: 机器人运动规划需要精确的环境知识来定义限制区域和考虑碰撞物体，通过获取环境点云数据来实现这一目标。

Method: 使用各种传感器获取环境点云，通过区域生长分割和VCCS算法识别碰撞物体，然后对点簇进行近似处理。

Result: 建立了从环境检测到碰撞环境构建的完整流程，能够有效识别碰撞物体并检测机器人与环境的碰撞。

Conclusion: 该研究提供了一套完整的机器人运动规划环境感知和碰撞检测方法，为机器人安全操作提供了技术基础。

Abstract: Motion planning for robotic manipulators relies on precise knowledge of the
environment in order to be able to define restricted areas and to take
collision objects into account. To capture the workspace, point clouds of the
environment are acquired using various sensors. The collision objects are
identified by region growing segmentation and VCCS algorithm. Subsequently the
point clusters are approximated. The aim of the present paper is to compare
different sensors, to illustrate the process from detection to the finished
collision environment and to detect collisions between the robot and this
environment.

</details>


### [60] [Optimal Dimensioning of Elastic-Link Manipulators regarding Lifetime Estimation](https://arxiv.org/abs/2510.23234)
*Klaus Zauner,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种用于估计弹性连杆机器人操作臂寿命的方法，并将其应用于执行拾放操作的柔性串联机械臂的几何优化，优化目标是总体重量和振动幅度的组合。


<details>
  <summary>Details</summary>
Motivation: 轻量化设计和时间能量最优控制是实现可持续工业自动化的关键，而这类系统的设计和控制相互关联，控制必须考虑固有的机械柔顺性，设计必须满足控制所需的动态要求。

Method: 采用雨流计数算法和临界切割平面法进行疲劳分析，使用Tresca假设制定等效应力，并假设线性损伤累积。从帕累托前沿选择最终机器人几何形状，作为寿命和振动特性之间的权衡。

Result: 该方法在一个三自由度铰接式机器人操作臂上进行了说明验证。

Conclusion: 该方法为机器人设计优化提供了基础，能够实现轻量化设计和最优控制的协同优化。

Abstract: Resourceful operation and design of robots is key for sustainable industrial
automation. This will be enabled by lightweight design along with time and
energy optimal control of robotic manipulators. Design and control of such
systems is intertwined as the control must take into account inherent
mechanical compliance while the design must accommodate the dynamic
requirements demanded by the control. As basis for such design optimization, a
method for estimating the lifetime of elastic link robotic manipulators is
presented. This is applied to the geometry optimization of flexible serial
manipulators performing pick-and-place operations, where the optimization
objective is a combination of overall weight and vibration amplitudes. The
lifetime estimation draws from a fatigue analysis combining the rainflow
counting algorithm and the method of critical cutting plane. Tresca hypothesis
is used to formulate an equivalent stress, and linear damage accumulation is
assumed. The final robot geometry is selected from a Pareto front as a tradeoff
of lifetime and vibration characteristic. The method is illustrated for a three
degrees of freedom articulated robotic manipulator.

</details>


### [61] [Deep Active Inference with Diffusion Policy and Multiple Timescale World Model for Real-World Exploration and Navigation](https://arxiv.org/abs/2510.23258)
*Riko Yokozawa,Kentaro Fujii,Yuta Nomura,Shingo Murata*

Main category: cs.RO

TL;DR: 提出了一个基于主动推理的深度框架，通过扩散策略和多时间尺度状态空间模型，在真实世界机器人导航中统一探索和目标导向导航。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的自主机器人导航需要同时进行环境探索获取信息和目标导向导航到达指定目标，需要一个统一框架来结合这两种行为。

Method: 集成扩散策略作为策略模型和多时间尺度循环状态空间模型作为世界模型，通过潜在想象预测动作的长期后果，选择最小化期望自由能量的动作。

Result: 真实世界导航实验显示，该框架相比基线方法实现了更高的成功率和更少的碰撞，特别是在需要探索的场景中表现更优。

Conclusion: 基于期望自由能量最小化的主动推理能够有效统一真实世界机器人设置中的探索和目标导向导航。

Abstract: Autonomous robotic navigation in real-world environments requires exploration
to acquire environmental information as well as goal-directed navigation in
order to reach specified targets. Active inference (AIF) based on the
free-energy principle provides a unified framework for these behaviors by
minimizing the expected free energy (EFE), thereby combining epistemic and
extrinsic values. To realize this practically, we propose a deep AIF framework
that integrates a diffusion policy as the policy model and a multiple timescale
recurrent state-space model (MTRSSM) as the world model. The diffusion policy
generates diverse candidate actions while the MTRSSM predicts their
long-horizon consequences through latent imagination, enabling action selection
that minimizes EFE. Real-world navigation experiments demonstrated that our
framework achieved higher success rates and fewer collisions compared with the
baselines, particularly in exploration-demanding scenarios. These results
highlight how AIF based on EFE minimization can unify exploration and
goal-directed navigation in real-world robotic settings.

</details>


### [62] [Precise Time Delay Measurement and Compensation for Tightly Coupled Underwater SINS/piUSBL Navigation](https://arxiv.org/abs/2510.23286)
*Jin Huang,Yingqiang Wang,Haoda Li,Zichen Liu,Zhikun Wang,Ying Chen*

Main category: cs.RO

TL;DR: 提出了一种紧密耦合的水下导航框架，通过精确时间同步集成piUSBL声学定位系统、SINS和深度计，将时间延迟重新定义为可量化参数，显著提高了导航精度。


<details>
  <summary>Details</summary>
Motivation: 多传感器系统中的时间同步是重大挑战，特别是在包含声学定位的水下集成导航系统中。时间延迟会显著降低精度，当测量和融合时刻不对齐时影响尤为严重。

Method: 引入紧密耦合导航框架，融合piUSBL的方位角和斜距与深度数据；提出新颖的延迟测量策略，结合同步定时和声学信号处理，将延迟重新定义为可量化参数；能够显式估计声学传播和系统处理延迟。

Result: 仿真和现场实验证实了方法的可行性，延迟补偿导航使RMSE降低了40.45%，最大误差降低了32.55%。

Conclusion: 精确的延迟测量和补偿不仅提高了水下导航精度，还为声学定位集成建立了可推广的框架，为延迟敏感的多传感器系统中的时间对齐和数据融合提供了宝贵见解。

Abstract: In multi-sensor systems, time synchronization between sensors is a
significant challenge, and this issue is particularly pronounced in underwater
integrated navigation systems incorporating acoustic positioning. Such systems
are highly susceptible to time delay, which can significantly degrade accuracy
when measurement and fusion moments are misaligned. To address this challenge,
this paper introduces a tightly coupled navigation framework that integrates a
passive inverted ultra-short baseline (piUSBL) acoustic positioning system, a
strapdown inertial navigation system (SINS), and a depth gauge under precise
time synchronization. The framework fuses azimuth and slant range from the
piUSBL with depth data, thereby avoiding poor vertical-angle observability in
planar arrays. A novel delay measurement strategy is introduced, combining
synchronized timing with acoustic signal processing, which redefines
delay-traditionally an unobservable error-into a quantifiable parameter,
enabling explicit estimation of both acoustic propagation and system processing
delays. Simulations and field experiments confirm the feasibility of the
proposed method, with delay-compensated navigation reducing RMSE by 40.45% and
maximum error by 32.55%. These findings show that precise delay measurement and
compensation not only enhance underwater navigation accuracy but also establish
a generalizable framework for acoustic positioning integration, offering
valuable insights into time alignment and data fusion in latency-sensitive
multi-sensor systems.

</details>


### [63] [Transferable Deep Reinforcement Learning for Cross-Domain Navigation: from Farmland to the Moon](https://arxiv.org/abs/2510.23329)
*Shreya Santra,Thomas Robbins,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 该研究探索了深度强化学习策略在视觉和地形不同的模拟域之间的泛化能力，通过在陆地环境中训练策略并在月球环境中进行零样本验证，证明了跨域策略转移的可行性。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中的自主导航对于野外和行星机器人至关重要，但传统方法需要大量环境特定调优，限制了在新领域的可扩展性。深度强化学习提供了一种数据驱动的替代方案。

Method: 开发了农业漫游车的3D模拟器，使用近端策略优化（PPO）在农田环境中训练目标导向导航和避障策略，然后在月球模拟环境中进行零样本评估。

Result: 在陆地条件下训练的策略在月球模拟中保持了较高的有效性，无需额外训练和微调即可达到接近50%的成功率。

Conclusion: 跨域DRL策略转移是开发适应性强、高效自主导航的有前景方法，有助于未来行星探索任务，并能最小化再训练成本。

Abstract: Autonomous navigation in unstructured environments is essential for field and
planetary robotics, where robots must efficiently reach goals while avoiding
obstacles under uncertain conditions. Conventional algorithmic approaches often
require extensive environment-specific tuning, limiting scalability to new
domains. Deep Reinforcement Learning (DRL) provides a data-driven alternative,
allowing robots to acquire navigation strategies through direct interactions
with their environment. This work investigates the feasibility of DRL policy
generalization across visually and topographically distinct simulated domains,
where policies are trained in terrestrial settings and validated in a zero-shot
manner in extraterrestrial environments. A 3D simulation of an agricultural
rover is developed and trained using Proximal Policy Optimization (PPO) to
achieve goal-directed navigation and obstacle avoidance in farmland settings.
The learned policy is then evaluated in a lunar-like simulated environment to
assess transfer performance. The results indicate that policies trained under
terrestrial conditions retain a high level of effectiveness, achieving close to
50\% success in lunar simulations without the need for additional training and
fine-tuning. This underscores the potential of cross-domain DRL-based policy
transfer as a promising approach to developing adaptable and efficient
autonomous navigation for future planetary exploration missions, with the added
benefit of minimizing retraining costs.

</details>


### [64] [Large language model-based task planning for service robots: A review](https://arxiv.org/abs/2510.23357)
*Shaohan Bian,Ying Zhang,Guohui Tian,Zhiqiang Miao,Edmond Q. Wu,Simon X. Yang,Changchun Hua*

Main category: cs.RO

TL;DR: 本文综述了大语言模型（LLMs）在服务机器人任务规划中的应用，分析了LLMs作为机器人认知核心的作用，探讨了多模态输入下的任务规划进展，并指出了当前挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和机器人技术的快速发展，服务机器人在复杂环境中提供多样化服务变得越来越重要。为了实现智能高效的服务交付，需要强大准确的任务规划能力。

Method: 回顾了LLMs的基础技术（预训练、微调、检索增强生成、提示工程），探讨了LLMs作为服务机器人认知核心的应用，分析了基于文本、视觉、音频和多模态输入的LLM驱动任务规划进展。

Result: LLMs能够显著提升服务机器人的自主性和决策能力，在多模态任务规划方面展现出良好潜力，为复杂非结构化家庭环境中的机器人应用提供了新的可能性。

Conclusion: LLMs在服务机器人任务规划中具有重要价值，但当前研究仍面临挑战，需要进一步探索以提升在复杂环境中的规划能力。本文为人工智能和机器人领域的研究者提供了有价值的参考。

Abstract: With the rapid advancement of large language models (LLMs) and robotics,
service robots are increasingly becoming an integral part of daily life,
offering a wide range of services in complex environments. To deliver these
services intelligently and efficiently, robust and accurate task planning
capabilities are essential. This paper presents a comprehensive overview of the
integration of LLMs into service robotics, with a particular focus on their
role in enhancing robotic task planning. First, the development and
foundational techniques of LLMs, including pre-training, fine-tuning,
retrieval-augmented generation (RAG), and prompt engineering, are reviewed. We
then explore the application of LLMs as the cognitive core-`brain'-of service
robots, discussing how LLMs contribute to improved autonomy and
decision-making. Furthermore, recent advancements in LLM-driven task planning
across various input modalities are analyzed, including text, visual, audio,
and multimodal inputs. Finally, we summarize key challenges and limitations in
current research and propose future directions to advance the task planning
capabilities of service robots in complex, unstructured domestic environments.
This review aims to serve as a valuable reference for researchers and
practitioners in the fields of artificial intelligence and robotics.

</details>


### [65] [T-ESKF: Transformed Error-State Kalman Filter for Consistent Visual-Inertial Navigation](https://arxiv.org/abs/2510.23359)
*Chungeng Tian,Ning Hao,Fenghua He*

Main category: cs.RO

TL;DR: 提出一种新的变换误差状态卡尔曼滤波器(T-ESKF)，通过线性时变变换解决视觉惯性导航系统中的可观测性失配问题，确保系统一致性并提高性能。


<details>
  <summary>Details</summary>
Motivation: 解决视觉惯性导航系统中由可观测性失配引起的不一致性问题，这是影响状态估计精度的关键挑战。

Method: 在误差状态卡尔曼滤波器中应用线性时变变换到误差状态，使变换后误差状态系统的不可观测子空间独立于状态，保持正确的可观测性。开发了高效的协方差传播技术。

Result: 通过大量仿真和实验验证，相比最先进方法表现出更好或至少相当的性能。

Conclusion: T-ESKF是一种一致的VINS估计器，有效解决了可观测性失配问题，提高了状态估计的准确性和鲁棒性。

Abstract: This paper presents a novel approach to address the inconsistency problem
caused by observability mismatch in visual-inertial navigation systems (VINS).
The key idea involves applying a linear time-varying transformation to the
error-state within the Error-State Kalman Filter (ESKF). This transformation
ensures that \textrr{the unobservable subspace of the transformed error-state
system} becomes independent of the state, thereby preserving the correct
observability of the transformed system against variations in linearization
points. We introduce the Transformed ESKF (T-ESKF), a consistent VINS estimator
that performs state estimation using the transformed error-state system.
Furthermore, we develop an efficient propagation technique to accelerate the
covariance propagation based on the transformation relationship between the
transition and accumulated matrices of T-ESKF and ESKF. We validate the
proposed method through extensive simulations and experiments, demonstrating
better (or competitive at least) performance compared to state-of-the-art
methods. The code is available at github.com/HITCSC/T-ESKF.

</details>


### [66] [Full-Dynamics Real-Time Nonlinear Model Predictive Control of Heavy-Duty Hydraulic Manipulator for Trajectory Tracking Tasks](https://arxiv.org/abs/2510.23386)
*Alvaro Paz,Mahdi Hejrati,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出了一种用于重型液压机械臂的非线性模型预测控制框架，能够在1kHz实时控制频率下保证关节和末端执行器的约束满足。


<details>
  <summary>Details</summary>
Motivation: 重型液压机械臂由于尺寸大、功率高和复杂的非线性动力学，需要在严格物理和安全关键约束下运行，但实时控制框架中确保关节级和末端执行器轨迹符合执行器能力的研究仍不足。

Method: 结合多射击策略与实时传感器反馈的非线性模型预测控制框架，并采用基于虚拟分解控制的鲁棒底层控制器进行精确关节跟踪。

Result: 在全尺寸液压机械臂上的实验验证表明，该框架不仅能在关节级强制执行器约束，还能确保末端执行器在笛卡尔空间中的约束合规运动。

Conclusion: 该方法能够在严格尊重安全关键限制的同时实现高精度轨迹跟踪，为大型液压系统的实时控制设定了新基准。

Abstract: Heavy-duty hydraulic manipulators (HHMs) operate under strict physical and
safety-critical constraints due to their large size, high power, and complex
nonlinear dynamics. Ensuring that both joint-level and end-effector
trajectories remain compliant with actuator capabilities, such as force,
velocity, and position limits, is essential for safe and reliable operation,
yet remains largely underexplored in real-time control frameworks. This paper
presents a nonlinear model predictive control (NMPC) framework designed to
guarantee constraint satisfaction throughout the full nonlinear dynamics of
HHMs, while running at a real-time control frequency of 1 kHz. The proposed
method combines a multiple-shooting strategy with real-time sensor feedback,
and is supported by a robust low-level controller based on virtual
decomposition control (VDC) for precise joint tracking. Experimental validation
on a full-scale hydraulic manipulator shows that the NMPC framework not only
enforces actuator constraints at the joint level, but also ensures
constraint-compliant motion in Cartesian space for the end-effector. These
results demonstrate the method's capability to deliver high-accuracy trajectory
tracking while strictly respecting safety-critical limits, setting a new
benchmark for real-time control in large-scale hydraulic systems.

</details>


### [67] [COOPERA: Continual Open-Ended Human-Robot Assistance](https://arxiv.org/abs/2510.23495)
*Chenyang Ma,Kai Lu,Ruta Desai,Xavier Puig,Andrew Markham,Niki Trigoni*

Main category: cs.RO

TL;DR: COOPERA是一个持续开放人机协作框架，通过模拟具有心理特征和长期意图的人类，在复杂环境中实现个性化机器人协作。


<details>
  <summary>Details</summary>
Motivation: 现有机器人助手主要关注结构化环境中的预定义任务，缺乏从人类模型中学习的能力，无法适应个体人类特征、习惯和长期活动。

Method: 集成持续人类反馈，模拟具有心理特征和长期意图的人类，在复杂环境中进行交互，并学习人类特征和情境依赖意图来个性化机器人协作行为。

Result: 实验验证模拟人类行为反映真实人类行为的程度，并证明推断和个性化人类意图对开放长期人机协作的价值。

Conclusion: COOPERA框架首次实现了在不同时间尺度上研究长期开放人机协作，为个性化机器人助手提供了有效方法。

Abstract: To understand and collaborate with humans, robots must account for individual
human traits, habits, and activities over time. However, most robotic
assistants lack these abilities, as they primarily focus on predefined tasks in
structured environments and lack a human model to learn from. This work
introduces COOPERA, a novel framework for COntinual, OPen-Ended human-Robot
Assistance, where simulated humans, driven by psychological traits and
long-term intentions, interact with robots in complex environments. By
integrating continuous human feedback, our framework, for the first time,
enables the study of long-term, open-ended human-robot collaboration (HRC) in
different collaborative tasks across various time-scales. Within COOPERA, we
introduce a benchmark and an approach to personalize the robot's collaborative
actions by learning human traits and context-dependent intents. Experiments
validate the extent to which our simulated humans reflect realistic human
behaviors and demonstrate the value of inferring and personalizing to human
intents for open-ended and long-term HRC. Project Page:
https://dannymcy.github.io/coopera/

</details>


### [68] [Deductive Chain-of-Thought Augmented Socially-aware Robot Navigation World Model](https://arxiv.org/abs/2510.23509)
*Weizheng Wang,Obi Ike,Soyun Choi,Sungeun Hong,Byung-Cheol Min*

Main category: cs.RO

TL;DR: NaviWM是一个社交感知的机器人导航世界模型，通过结合结构化世界模型和逻辑驱动的思维链过程来增强LLM推理，解决LLM在动态人类空间中导航时的不安全行为问题。


<details>
  <summary>Details</summary>
Motivation: 当前依赖LLM进行社交机器人导航规划存在不可预测和不安全行为的问题，主要原因是缺乏物理基础和逻辑一致性。

Method: NaviWM包含两个主要组件：1）捕捉环境中智能体位置、速度和活动的时空世界模型；2）通过多步骤、基于逻辑的推理过程引导LLM的演绎推理模块。

Result: 实验表明NaviWM提高了成功率并减少了社交违规行为，特别是在拥挤环境中。

Conclusion: 将形式推理与LLM结合能够实现更稳健的社交导航，NaviWM展示了这种结合的优势。

Abstract: Social robot navigation increasingly relies on large language models for
reasoning, path planning, and enabling movement in dynamic human spaces.
However, relying solely on LLMs for planning often leads to unpredictable and
unsafe behaviors, especially in dynamic human spaces, due to limited physical
grounding and weak logical consistency. In this work, we introduce NaviWM, a
socially-aware robot Navigation World Model that augments LLM reasoning with a
structured world model and a logic-driven chain-of-thought process. NaviWM
consists of two main components: (1) a spatial-temporal world model that
captures the positions, velocities, and activities of agents in the
environment, and (2) a deductive reasoning module that guides LLMs through a
multi-step, logic-based inference process. This integration enables the robot
to generate navigation decisions that are both socially compliant and
physically safe, under well-defined constraints such as personal space,
collision avoidance, and timing. Unlike previous methods based on prompting or
fine-tuning, NaviWM encodes social norms as first-order logic, enabling
interpretable and verifiable reasoning. Experiments show that NaviWM improves
success rates and reduces social violations, particularly in crowded
environments. These results demonstrate the benefit of combining formal
reasoning with LLMs for robust social navigation. Additional experimental
details and demo videos for this work can be found at:
https://sites.google.com/view/NaviWM.

</details>


### [69] [Dexbotic: Open-Source Vision-Language-Action Toolbox](https://arxiv.org/abs/2510.23511)
*Bin Xie,Erjin Zhou,Fan Jia,Hao Shi,Haoqiang Fan,Haowei Zhang,Hebei Li,Jianjian Sun,Jie Bin,Junwen Huang,Kai Liu,Kaixin Liu,Kefan Gu,Lin Sun,Meng Zhang,Peilong Han,Ruitao Hao,Ruitao Zhang,Saike Huang,Songhan Xie,Tiancai Wang,Tianle Liu,Wenbin Tang,Wenqi Zhu,Yang Chen,Yingfei Liu,Yizhuang Zhou,Yu Liu,Yucheng Zhao,Yunchao Ma,Yunfei Wei,Yuxiang Chen,Ze Chen,Zeming Li,Zhao Wu,Ziheng Zhang,Ziming Liu,Ziwei Yan,Ziyu Zhang*

Main category: cs.RO

TL;DR: Dexbotic是一个基于PyTorch的开源视觉-语言-动作模型工具箱，为具身智能领域提供一站式VLA研究服务，支持多种主流VLA策略，并提供更强的预训练模型。


<details>
  <summary>Details</summary>
Motivation: 为具身智能领域的研究人员提供一个统一的VLA研究平台，简化实验环境设置，支持多种VLA方法的复现和快速开发新实验。

Method: 基于PyTorch构建实验中心的工具箱，用户只需修改Exp脚本即可快速开发新VLA实验，同时提供更强的预训练模型。

Result: 工具箱支持多种主流VLA策略的复现，通过单一环境设置即可实现，并提供性能更强的预训练模型。

Conclusion: Dexbotic将持续更新，纳入更多最新的预训练基础模型和前沿VLA模型，为VLA研究提供持续支持。

Abstract: In this paper, we present Dexbotic, an open-source Vision-Language-Action
(VLA) model toolbox based on PyTorch. It aims to provide a one-stop VLA
research service for professionals in the field of embodied intelligence. It
offers a codebase that supports multiple mainstream VLA policies
simultaneously, allowing users to reproduce various VLA methods with just a
single environment setup. The toolbox is experiment-centric, where the users
can quickly develop new VLA experiments by simply modifying the Exp script.
Moreover, we provide much stronger pretrained models to achieve great
performance improvements for state-of-the-art VLA policies. Dexbotic will
continuously update to include more of the latest pre-trained foundation models
and cutting-edge VLA models in the industry.

</details>


### [70] [Localising under the drape: proprioception in the era of distributed surgical robotic system](https://arxiv.org/abs/2510.23512)
*Martin Huber,Nicola A. Cavalcanti,Ayoob Davoodi,Ruixuan Li,Christopher E. Mower,Fabio Carrillo,Christoph J. Laux,Francois Teyssere,Thibault Chandanson,Antoine Harlé,Elie Saghbiny,Mazda Farshad,Guillaume Morel,Emmanuel Vander Poorten,Philipp Fürnstahl,Sébastien Ourselin,Christos Bergeles,Tom Vercauteren*

Main category: cs.RO

TL;DR: 提出了一种无标记的机器人本体感知方法，使用轻量级立体RGB相机和基于transformer的深度学习模型，能够在无菌覆盖下精确定位手术机器人，无需传统红外标记系统。


<details>
  <summary>Details</summary>
Motivation: 解决手术机器人缺乏空间感知能力的问题，避免碰撞和系统恢复，减少手术室硬件负担，为分布式多机器人系统提供支持。

Method: 基于最大规模的多中心空间机器人手术数据集（140万张自标注图像），使用轻量级立体RGB相机和新型transformer深度学习模型，追踪整个机器人和手术场景而非单个标记。

Result: 消除了标记需求，将追踪可见性提高了25%，在体内呼吸补偿中展示了临床效益，能够准确追踪多机器人系统中的位置。

Conclusion: 这是首个针对完全覆盖无菌布的手术机器人的无标记本体感知演示，降低了设置复杂性，提高了安全性，为模块化和自主机器人手术铺平了道路。

Abstract: Despite their mechanical sophistication, surgical robots remain blind to
their surroundings. This lack of spatial awareness causes collisions, system
recoveries, and workflow disruptions, issues that will intensify with the
introduction of distributed robots with independent interacting arms. Existing
tracking systems rely on bulky infrared cameras and reflective markers,
providing only limited views of the surgical scene and adding hardware burden
in crowded operating rooms. We present a marker-free proprioception method that
enables precise localisation of surgical robots under their sterile draping
despite associated obstruction of visual cues. Our method solely relies on
lightweight stereo-RGB cameras and novel transformer-based deep learning
models. It builds on the largest multi-centre spatial robotic surgery dataset
to date (1.4M self-annotated images from human cadaveric and preclinical in
vivo studies). By tracking the entire robot and surgical scene, rather than
individual markers, our approach provides a holistic view robust to occlusions,
supporting surgical scene understanding and context-aware control. We
demonstrate an example of potential clinical benefits during in vivo breathing
compensation with access to tissue dynamics, unobservable under state of the
art tracking, and accurately locate in multi-robot systems for future
intelligent interaction. In addition, and compared with existing systems, our
method eliminates markers and improves tracking visibility by 25%. To our
knowledge, this is the first demonstration of marker-free proprioception for
fully draped surgical robots, reducing setup complexity, enhancing safety, and
paving the way toward modular and autonomous robotic surgery.

</details>


### [71] [Explicit Memory through Online 3D Gaussian Splatting Improves Class-Agnostic Video Segmentation](https://arxiv.org/abs/2510.23521)
*Anthony Opipari,Aravindhan K Krishnan,Shreekant Gayaka,Min Sun,Cheng-Hao Kuo,Arnie Sen,Odest Chadwicke Jenkins*

Main category: cs.RO

TL;DR: 该论文提出了一种使用显式3D高斯泼溅(3DGS)记忆来改进视频分割模型的方法，开发了FastSAM-Splat和SAM2-Splat两种融合技术，通过存储历史预测的物体片段来提高分割的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视频分割算法要么不使用物体级记忆（如FastSAM），要么仅使用循环神经网络特征的隐式记忆（如SAM2）。为了获得更准确和一致的分割结果，需要开发显式的物体级记忆机制。

Method: 开发了在线3D高斯泼溅(3DGS)技术来存储视频过程中预测的物体级片段，基于此3DGS表示，提出了FastSAM-Splat和SAM2-Splat两种融合技术，利用显式3DGS记忆来改进各自基础模型的预测。

Result: 消融实验验证了所提技术的设计和超参数设置。在真实世界和模拟基准测试中，使用显式3D记忆的模型比不使用记忆或仅使用隐式神经网络记忆的模型产生了更准确和一致的分割结果。

Conclusion: 显式3D高斯泼溅记忆能够有效提升视频分割模型的性能，为类无关视频分割提供了更可靠的技术方案。

Abstract: Remembering where object segments were predicted in the past is useful for
improving the accuracy and consistency of class-agnostic video segmentation
algorithms. Existing video segmentation algorithms typically use either no
object-level memory (e.g. FastSAM) or they use implicit memories in the form of
recurrent neural network features (e.g. SAM2). In this paper, we augment both
types of segmentation models using an explicit 3D memory and show that the
resulting models have more accurate and consistent predictions. For this, we
develop an online 3D Gaussian Splatting (3DGS) technique to store predicted
object-level segments generated throughout the duration of a video. Based on
this 3DGS representation, a set of fusion techniques are developed, named
FastSAM-Splat and SAM2-Splat, that use the explicit 3DGS memory to improve
their respective foundation models' predictions. Ablation experiments are used
to validate the proposed techniques' design and hyperparameter settings.
Results from both real-world and simulated benchmarking experiments show that
models which use explicit 3D memories result in more accurate and consistent
predictions than those which use no memory or only implicit neural network
memories. Project Page: https://topipari.com/projects/FastSAM-Splat/

</details>


### [72] [RobotArena $\infty$: Scalable Robot Benchmarking via Real-to-Sim Translation](https://arxiv.org/abs/2510.23571)
*Yash Jangir,Yidi Zhang,Kashu Yamazaki,Chenyu Zhang,Kuan-Hsun Tu,Tsung-Wei Ke,Lei Ke,Yonatan Bisk,Katerina Fragkiadaki*

Main category: cs.RO

TL;DR: 提出了一个用于评估机器人通用智能体的新基准框架，通过大规模模拟环境和在线人类反馈来解决真实世界测试的限制。


<details>
  <summary>Details</summary>
Motivation: 真实世界机器人策略测试存在劳动密集、缓慢、不安全且难以复现的问题，现有模拟基准也无法评估从真实世界演示训练的模型，需要更有效的评估方法。

Method: 利用视觉语言模型、2D到3D生成建模和可微分渲染，将机器人数据集中的视频演示自动转换为模拟对应物，并通过VLM引导评分和众包人类偏好判断来评估策略。

Result: 创建了一个持续演化、可复现且可扩展的机器人操作策略基准，能够系统性地测试策略在受控变化下的鲁棒性。

Conclusion: 该框架解决了当前机器人领域的关键缺失能力，为评估真实世界训练的机器人策略提供了有效的解决方案。

Abstract: The pursuit of robot generalists - instructable agents capable of performing
diverse tasks across diverse environments - demands rigorous and scalable
evaluation. Yet real-world testing of robot policies remains fundamentally
constrained: it is labor-intensive, slow, unsafe at scale, and difficult to
reproduce. Existing simulation benchmarks are similarly limited, as they train
and test policies within the same synthetic domains and cannot assess models
trained from real-world demonstrations or alternative simulation environments.
As policies expand in scope and complexity, these barriers only intensify,
since defining "success" in robotics often hinges on nuanced human judgments of
execution quality. In this paper, we introduce a new benchmarking framework
that overcomes these challenges by shifting VLA evaluation into large-scale
simulated environments augmented with online human feedback. Leveraging
advances in vision-language models, 2D-to-3D generative modeling, and
differentiable rendering, our approach automatically converts video
demonstrations from widely used robot datasets into simulated counterparts.
Within these digital twins, we assess VLA policies using both automated
VLM-guided scoring and scalable human preference judgments collected from
crowdworkers, transforming human involvement from tedious scene setup,
resetting, and safety supervision into lightweight preference comparisons. To
measure robustness, we systematically perturb simulated environments along
multiple axes, such as textures and object placements, stress-testing policy
generalization under controlled variation. The result is a continuously
evolving, reproducible, and scalable benchmark for real-world trained robot
manipulation policies, addressing a critical missing capability in today's
robotics landscape.

</details>


### [73] [UrbanVLA: A Vision-Language-Action Model for Urban Micromobility](https://arxiv.org/abs/2510.23576)
*Anqi Li,Zhiyong Wang,Jiazhao Zhang,Minghan Li,Yunpeng Qi,Zhibo Chen,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: UrbanVLA是一个用于城市微移动导航的视觉-语言-动作框架，通过两阶段训练在模拟和真实数据上实现大规模城市环境中的可靠导航。


<details>
  <summary>Details</summary>
Motivation: 现有的导航方法主要针对小规模和可控场景，而城市微移动应用（如配送机器人）需要在动态、非结构化的城市环境中进行长距离可靠导航。

Method: 提出UrbanVLA框架，显式对齐噪声路径点与视觉观察，然后规划轨迹。采用两阶段训练：先用模拟环境和网络视频轨迹进行监督微调，再用模拟和真实数据混合进行强化微调。

Result: 在MetaUrban的SocialNav任务中超越强基线55%以上，在真实世界中实现可靠导航，展现了对大规模城市环境的可扩展性和对真实世界不确定性的鲁棒性。

Conclusion: UrbanVLA框架成功解决了城市微移动导航的挑战，实现了大规模城市环境中的可靠导航，为动态非结构化环境中的机器人导航提供了有效解决方案。

Abstract: Urban micromobility applications, such as delivery robots, demand reliable
navigation across large-scale urban environments while following long-horizon
route instructions. This task is particularly challenging due to the dynamic
and unstructured nature of real-world city areas, yet most existing navigation
methods remain tailored to short-scale and controllable scenarios. Effective
urban micromobility requires two complementary levels of navigation skills:
low-level capabilities such as point-goal reaching and obstacle avoidance, and
high-level capabilities, such as route-visual alignment. To this end, we
propose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework
designed for scalable urban navigation. Our method explicitly aligns noisy
route waypoints with visual observations during execution, and subsequently
plans trajectories to drive the robot. To enable UrbanVLA to master both levels
of navigation, we employ a two-stage training pipeline. The process begins with
Supervised Fine-Tuning (SFT) using simulated environments and trajectories
parsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on
a mixture of simulation and real-world data, which enhances the model's safety
and adaptability in real-world settings. Experiments demonstrate that UrbanVLA
surpasses strong baselines by more than 55% in the SocialNav task on MetaUrban.
Furthermore, UrbanVLA achieves reliable real-world navigation, showcasing both
scalability to large-scale urban environments and robustness against real-world
uncertainties.

</details>
