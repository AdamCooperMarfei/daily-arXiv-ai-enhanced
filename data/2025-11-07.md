<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 21]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Dynamic Shape Control of Soft Robots Enabled by Data-Driven Model Reduction](https://arxiv.org/abs/2511.03931)
*Iman Adibnazari,Harsh Sharma,Myungsun Park,Jacobo Cervera-Torralba,Boris Kramer,Michael T. Tolley*

Main category: cs.RO

TL;DR: 比较三种数据驱动模型降阶方法（ERA、DMDc、LOpInf）在鳗鱼仿生软体机器人动态形状控制中的效果，发现LOpInf方法在所有实验中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 软体机器人需要动态形状控制，但缺乏适用于控制的通用建模工具，因此研究数据驱动的模型降阶技术来生成适合控制的线性模型。

Method: 使用三种模型降阶方法（ERA、DMDc、LOpInf）构建线性模型，在模拟的鳗鱼仿生软体机器人上进行模型预测控制，包括三个实验：跟踪可行参考轨迹、生物模型生成轨迹和物理模拟生成轨迹。

Result: 在所有实验中，基于LOpInf的控制策略产生的跟踪误差均低于其他模型。

Conclusion: LOpInf方法在软体机器人动态形状控制中表现最优，为软体机器人控制提供了有效的建模工具。

Abstract: Soft robots have shown immense promise in settings where they can leverage
dynamic control of their entire bodies. However, effective dynamic shape
control requires a controller that accounts for the robot's high-dimensional
dynamics--a challenge exacerbated by a lack of general-purpose tools for
modeling soft robots amenably for control. In this work, we conduct a
comparative study of data-driven model reduction techniques for generating
linear models amendable to dynamic shape control. We focus on three
methods--the eigensystem realization algorithm, dynamic mode decomposition with
control, and the Lagrangian operator inference (LOpInf) method. Using each
class of model, we explored their efficacy in model predictive control policies
for the dynamic shape control of a simulated eel-inspired soft robot in three
experiments: 1) tracking simulated reference trajectories guaranteed to be
feasible, 2) tracking reference trajectories generated from a biological model
of eel kinematics, and 3) tracking reference trajectories generated by a
reduced-scale physical analog. In all experiments, the LOpInf-based policies
generated lower tracking errors than policies based on other models.

</details>


### [2] [Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots](https://arxiv.org/abs/2511.03996)
*Yushi Wang,Changsheng Luo,Penghui Chen,Jianran Liu,Weijian Sun,Tong Guo,Kechang Yang,Biao Hu,Yangang Zhang,Mingguo Zhao*

Main category: cs.RO

TL;DR: 提出了一个统一的强化学习控制器，让仿人机器人通过直接整合视觉感知和运动控制来获得反应式足球技能，解决了现有系统模块解耦导致的延迟响应问题。


<details>
  <summary>Details</summary>
Motivation: 现有仿人足球系统通常依赖解耦模块，导致动态环境中响应延迟和行为不连贯，同时真实世界的感知限制进一步加剧了这些问题。

Method: 扩展了对抗运动先验到真实世界动态环境的感知设置，结合编码器-解码器架构和虚拟感知系统，模拟真实世界视觉特征，使策略能从非完美观察中恢复特权状态。

Result: 控制器表现出强大的反应能力，在各种场景下（包括真实RoboCup比赛）持续执行连贯且稳健的足球行为。

Conclusion: 该方法成功建立了感知与动作之间的主动协调，为仿人机器人在动态环境中的智能控制提供了有效解决方案。

Abstract: Humanoid soccer poses a representative challenge for embodied intelligence,
requiring robots to operate within a tightly coupled perception-action loop.
However, existing systems typically rely on decoupled modules, resulting in
delayed responses and incoherent behaviors in dynamic environments, while
real-world perceptual limitations further exacerbate these issues. In this
work, we present a unified reinforcement learning-based controller that enables
humanoid robots to acquire reactive soccer skills through the direct
integration of visual perception and motion control. Our approach extends
Adversarial Motion Priors to perceptual settings in real-world dynamic
environments, bridging motion imitation and visually grounded dynamic control.
We introduce an encoder-decoder architecture combined with a virtual perception
system that models real-world visual characteristics, allowing the policy to
recover privileged states from imperfect observations and establish active
coordination between perception and action. The resulting controller
demonstrates strong reactivity, consistently executing coherent and robust
soccer behaviors across various scenarios, including real RoboCup matches.

</details>


### [3] [Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration](https://arxiv.org/abs/2511.04009)
*Chenzui Li,Yiming Chen,Xi Wu,Giacinto Barresi,Fei Chen*

Main category: cs.RO

TL;DR: 提出一种上肢姿态优化方法，用于提升双臂人机协同搬运任务中的物理工效学和力操纵能力，通过优化人体关节角度和机器人末端执行器位姿来增强协作效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常只关注人类安全或操作效率，而该方法独特地将这两个方面结合起来，以在不同条件下（如不同的人类抓握姿势和不同形状的物体）加强协作。

Method: 通过最小化成本函数来优化简化人体骨骼模型的关节角度，优先考虑安全性和操纵能力；通过变换模块生成机器人末端执行器的参考位姿；提出双臂模型预测阻抗控制器（MPIC）来重新校准末端执行器位姿。

Result: 在人与人协作（HHC）和人机协作（HRC）中通过多个受试者和物体进行了验证，实验结果显示目标肌肉激活在优化前后有显著改善。

Conclusion: 所提出的方法在改善肌肉状况方面表现出显著效果，验证了其在提升人机协作物理工效学和力操纵能力方面的有效性。

Abstract: This paper introduces an upper limb postural optimization method for
enhancing physical ergonomics and force manipulability during bimanual
human-robot co-carrying tasks. Existing research typically emphasizes human
safety or manipulative efficiency, whereas our proposed method uniquely
integrates both aspects to strengthen collaboration across diverse conditions
(e.g., different grasping postures of humans, and different shapes of objects).
Specifically, the joint angles of a simplified human skeleton model are
optimized by minimizing the cost function to prioritize safety and manipulative
capability. To guide humans towards the optimized posture, the reference
end-effector poses of the robot are generated through a transformation module.
A bimanual model predictive impedance controller (MPIC) is proposed for our
human-like robot, CURI, to recalibrate the end effector poses through planned
trajectories. The proposed method has been validated through various subjects
and objects during human-human collaboration (HHC) and human-robot
collaboration (HRC). The experimental results demonstrate significant
improvement in muscle conditions by comparing the activation of target muscles
before and after optimization.

</details>


### [4] [An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue](https://arxiv.org/abs/2511.04042)
*Kailun Ji,Xiaoyu Hu,Xinyu Zhang,Jun Chen*

Main category: cs.RO

TL;DR: 提出了一种基于大语言模型(LLM)的人机协同系统，通过自然交互方式解决无人机群在灾难搜救中的"意图到行动差距"问题，显著提升了任务效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 大规模灾难搜救行动面临复杂地形和通信中断的挑战，无人机群虽然能执行广域搜索和物资投递任务，但其有效协调给人类操作员带来了巨大的认知负担。核心瓶颈在于"意图到行动差距"——在高强度压力下将高层救援目标转化为低层群控命令的易出错过程。

Method: 提出LLM-CRF系统，利用大语言模型建模和增强人机群组认知。通过语音或图形标注等自然多模态交互捕获操作员意图，使用LLM作为认知引擎进行意图理解、分层任务分解和无人机群任务规划，形成闭环框架使无人机群成为主动合作伙伴。

Result: 在模拟搜救场景中的实验结果显示，相比传统命令接口，LLM驱动方法将任务完成时间减少约64.2%，任务成功率提高7%，NASA-TLX主观认知负荷评分下降42.9%。

Conclusion: 这项工作确立了LLM在高风险场景中创建更直观有效的人机群组协作的潜力。

Abstract: Large-scale disaster Search And Rescue (SAR) operations are persistently
challenged by complex terrain and disrupted communications. While Unmanned
Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area
search and supply delivery, yet their effective coordination places a
significant cognitive burden on human operators. The core human-machine
collaboration bottleneck lies in the ``intention-to-action gap'', which is an
error-prone process of translating a high-level rescue objective into a
low-level swarm command under high intensity and pressure. To bridge this gap,
this study proposes a novel LLM-CRF system that leverages Large Language Models
(LLMs) to model and augment human-swarm teaming cognition. The proposed
framework initially captures the operator's intention through natural and
multi-modal interactions with the device via voice or graphical annotations. It
then employs the LLM as a cognitive engine to perform intention comprehension,
hierarchical task decomposition, and mission planning for the UAV swarm. This
closed-loop framework enables the swarm to act as a proactive partner,
providing active feedback in real-time while reducing the need for manual
monitoring and control, which considerably advances the efficacy of the SAR
task. We evaluate the proposed framework in a simulated SAR scenario.
Experimental results demonstrate that, compared to traditional order and
command-based interfaces, the proposed LLM-driven approach reduced task
completion time by approximately $64.2\%$ and improved task success rate by
$7\%$. It also leads to a considerable reduction in subjective cognitive
workload, with NASA-TLX scores dropping by $42.9\%$. This work establishes the
potential of LLMs to create more intuitive and effective human-swarm
collaborations in high-stakes scenarios.

</details>


### [5] [Enhancing Fault-Tolerant Space Computing: Guidance Navigation and Control (GNC) and Landing Vision System (LVS) Implementations on Next-Gen Multi-Core Processors](https://arxiv.org/abs/2511.04052)
*Kyongsik Yun,David Bayard,Gerik Kubiak,Austin Owens,Andrew Johnson,Ryan Johnson,Dan Scharf,Thomas Lu*

Main category: cs.RO

TL;DR: 本文评估了下一代多核处理器在行星探测任务中的GNC和LVS算法部署，展示了显著的性能提升，并提出了ARBITER故障检测机制来确保计算可靠性。


<details>
  <summary>Details</summary>
Motivation: 未来行星探测任务需要高性能、容错的计算系统来实现自主的制导导航控制和着陆视觉系统操作，特别是在进入、下降和着陆阶段。

Method: 在HPSC、Snapdragon VOXL2和AMD Xilinx Versal等多核处理器上部署GNC和LVS算法，并开发ARBITER多核投票机制进行实时故障检测和纠正。

Result: LVS图像处理实现15倍加速，GFOLD轨迹优化实现250倍以上加速；ARBITER在静态优化和动态闭环控制中验证有效；故障注入研究识别了GFOLD梯度计算阶段对位级错误最敏感。

Conclusion: 这项工作为火星样本返回、土卫二轨道着陆器和谷神星样本返回等未来任务建立了可扩展且节能的架构，其中机载自主性、低延迟和容错能力至关重要。

Abstract: Future planetary exploration missions demand high-performance, fault-tolerant
computing to enable autonomous Guidance, Navigation, and Control (GNC) and
Lander Vision System (LVS) operations during Entry, Descent, and Landing (EDL).
This paper evaluates the deployment of GNC and LVS algorithms on
next-generation multi-core processors--HPSC, Snapdragon VOXL2, and AMD Xilinx
Versal--demonstrating up to 15x speedup for LVS image processing and over 250x
speedup for Guidance for Fuel-Optimal Large Divert (GFOLD) trajectory
optimization compared to legacy spaceflight hardware. To ensure computational
reliability, we present ARBITER (Asynchronous Redundant Behavior Inspection for
Trusted Execution and Recovery), a Multi-Core Voting (MV) mechanism that
performs real-time fault detection and correction across redundant cores.
ARBITER is validated in both static optimization tasks (GFOLD) and dynamic
closed-loop control (Attitude Control System). A fault injection study further
identifies the gradient computation stage in GFOLD as the most sensitive to
bit-level errors, motivating selective protection strategies and vector-based
output arbitration. This work establishes a scalable and energy-efficient
architecture for future missions, including Mars Sample Return, Enceladus
Orbilander, and Ceres Sample Return, where onboard autonomy, low latency, and
fault resilience are critical.

</details>


### [6] [CBMC-V3: A CNS-inspired Control Framework Towards Manipulation Agility with SNN](https://arxiv.org/abs/2511.04109)
*Yanbo Pang,Qingkai Li,Mingguo Zhao*

Main category: cs.RO

TL;DR: 提出基于脉冲神经网络的仿生控制框架，模拟人类中枢神经系统，实现机器人手臂在复杂环境中的敏捷控制


<details>
  <summary>Details</summary>
Motivation: 随着机器人手臂应用扩展到医疗、服务和日常生活，现有控制算法难以在具有动态轨迹、不可预测交互和多样化物体的复杂环境中实现敏捷操作

Method: 采用五模块（大脑皮层、小脑、丘脑、脑干、脊髓）、三层次控制（一阶、二阶、三阶）和双信息通路（上行、下行）的仿生框架，各模块均使用SNN实现，包括脊髓的反馈控制、脑干的参数调节、丘脑的扭矩调整和小脑的前馈补偿

Result: 在仿真和真实机器人平台上验证，结果表明该方法在操作敏捷性方面优于工业级位置控制

Conclusion: 基于SNN的仿生控制框架能够有效提升机器人手臂在复杂环境中的敏捷操作性能

Abstract: As robotic arm applications extend beyond industrial settings into
healthcare, service, and daily life, existing control algorithms struggle to
achieve the agile manipulation required for complex environments with dynamic
trajectories, unpredictable interactions, and diverse objects. This paper
presents a biomimetic control framework based on Spiking Neural Networks (SNN),
inspired by the human Central Nervous System (CNS), to achieve agile control in
such environments. The proposed framework features five control modules
(cerebral cortex, cerebellum, thalamus, brainstem, spinal cord), three
hierarchical control levels (first-order, second-order, third-order), and two
information pathways (ascending, descending). Each module is fully implemented
using SNN. The spinal cord module uses spike encoding and Leaky
Integrate-and-Fire (LIF) neurons for feedback control. The brainstem module
employs a network of LIF and non-spiking LIF neurons to dynamically adjust
spinal cord parameters via reinforcement learning. The thalamus module
similarly adjusts the cerebellum's torque outputs. The cerebellum module uses a
recurrent SNN to learn the robotic arm's dynamics through regression, providing
feedforward gravity compensation torques. The framework is validated both in
simulation and on real-world robotic arm platform under various loads and
trajectories. Results demonstrate that our method outperforms the
industrial-grade position control in manipulation agility.

</details>


### [7] [BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning](https://arxiv.org/abs/2511.04131)
*Yitang Li,Zhengyi Luo,Tonghe Zhang,Cunxi Dai,Anssi Kanervisto,Andrea Tirinzoni,Haoyang Weng,Kris Kitani,Mateusz Guzek,Ahmed Touati,Alessandro Lazaric,Matteo Pirotta,Guanya Shi*

Main category: cs.RO

TL;DR: BFM-Zero是一个用于人形机器人的行为基础模型框架，通过共享潜在表示学习，使单一策略能够处理多种任务而无需重新训练，在真实世界人形机器人上实现了零样本运动跟踪、目标到达和奖励优化等能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么仅部署在模拟人形角色上，要么专门针对特定任务如跟踪。需要开发一个统一的、可提示的通用策略来处理多样化的控制任务。

Method: 基于无监督强化学习和前向-后向模型，学习嵌入运动、目标和奖励的共享潜在表示空间，结合关键奖励塑造、领域随机化和历史依赖非对称学习来弥合模拟到真实的差距。

Result: 在真实世界的Unitree G1人形机器人上实现了多功能和鲁棒的全身体技能，包括零样本运动跟踪、目标到达、奖励优化和少量样本优化适应。

Conclusion: BFM-Zero是首个此类模型，为可扩展、可提示的全身体人形控制行为基础模型迈出了重要一步。

Abstract: Building Behavioral Foundation Models (BFMs) for humanoid robots has the
potential to unify diverse control tasks under a single, promptable generalist
policy. However, existing approaches are either exclusively deployed on
simulated humanoid characters, or specialized to specific tasks such as
tracking. We propose BFM-Zero, a framework that learns an effective shared
latent representation that embeds motions, goals, and rewards into a common
space, enabling a single policy to be prompted for multiple downstream tasks
without retraining. This well-structured latent space in BFM-Zero enables
versatile and robust whole-body skills on a Unitree G1 humanoid in the real
world, via diverse inference methods, including zero-shot motion tracking, goal
reaching, and reward optimization, and few-shot optimization-based adaptation.
Unlike prior on-policy reinforcement learning (RL) frameworks, BFM-Zero builds
upon recent advancements in unsupervised RL and Forward-Backward (FB) models,
which offer an objective-centric, explainable, and smooth latent representation
of whole-body motions. We further extend BFM-Zero with critical reward shaping,
domain randomization, and history-dependent asymmetric learning to bridge the
sim-to-real gap. Those key design choices are quantitatively ablated in
simulation. A first-of-its-kind model, BFM-Zero establishes a step toward
scalable, promptable behavioral foundation models for whole-body humanoid
control.

</details>


### [8] [PUL-SLAM: Path-Uncertainty Co-Optimization with Lightweight Stagnation Detection for Efficient Robotic Exploration](https://arxiv.org/abs/2511.04180)
*Yizhen Yin,Dapeng Feng,Hongbo Chen,Yuhua Qi*

Main category: cs.RO

TL;DR: 提出了一种结合路径-不确定性协同优化深度强化学习和轻量级停滞检测机制的混合框架，显著提升了主动SLAM的探索效率和路径质量。


<details>
  <summary>Details</summary>
Motivation: 现有的主动SLAM方法存在探索速度慢和路径次优的问题，需要一种能够同时优化路径距离和地图不确定性的高效解决方案。

Method: 采用路径-不确定性协同优化深度强化学习框架，通过双目标奖励函数平衡探索与利用；结合轻量级停滞检测机制，包括激光雷达静态异常检测和地图更新停滞检测，减少冗余探索。

Result: 与前沿方法和RRT方法相比，探索时间缩短达65%，路径距离减少达42%，在复杂环境中显著提升探索效率，同时保持可靠的地图完整性。

Conclusion: 该混合框架有效解决了主动SLAM的探索效率问题，消融研究证实了协同机制的加速收敛效果，物理机器人平台验证了算法从仿真到现实环境的成功迁移性。

Abstract: Existing Active SLAM methodologies face issues such as slow exploration speed
and suboptimal paths. To address these limitations, we propose a hybrid
framework combining a Path-Uncertainty Co-Optimization Deep Reinforcement
Learning framework and a Lightweight Stagnation Detection mechanism. The
Path-Uncertainty Co-Optimization framework jointly optimizes travel distance
and map uncertainty through a dual-objective reward function, balancing
exploration and exploitation. The Lightweight Stagnation Detection reduces
redundant exploration through Lidar Static Anomaly Detection and Map Update
Stagnation Detection, terminating episodes on low expansion rates. Experimental
results show that compared with the frontier-based method and RRT method, our
approach shortens exploration time by up to 65% and reduces path distance by up
to 42%, significantly improving exploration efficiency in complex environments
while maintaining reliable map completeness. Ablation studies confirm that the
collaborative mechanism accelerates training convergence. Empirical validation
on a physical robotic platform demonstrates the algorithm's practical
applicability and its successful transferability from simulation to real-world
environments.

</details>


### [9] [GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments](https://arxiv.org/abs/2511.04199)
*Shenglin Wang,Mingtong Dai,Jingxuan Su,Lingbo Liu,Chunjie Chen,Xinyu Wu,Liang Lin*

Main category: cs.RO

TL;DR: GraspView是一个仅使用RGB相机的机器人抓取系统，通过多视角重建、主动感知和在线标定，在杂乱环境中实现精确抓取，特别适用于透明物体和遮挡严重的情况。


<details>
  <summary>Details</summary>
Motivation: 传统基于RGB-D相机的抓取系统在透明物体、反光表面和近距离感知时表现不佳，深度信息不可靠。需要开发仅使用RGB相机的可靠抓取方案。

Method: 1) 全局感知场景重建：从单视角RGB图像生成局部一致的几何信息，融合多视角投影；2) 渲染-评分主动感知：动态选择最佳视角揭示遮挡区域；3) 在线度量对齐：校准VGGT预测与机器人运动学，确保物理尺度一致性。

Result: 在多种桌面物体上的实验表明，GraspView显著优于RGB-D和单视角RGB基线方法，特别是在严重遮挡、近场感知和透明物体情况下表现突出。

Conclusion: GraspView提供了一个实用且通用的RGB-D管道替代方案，能够在非结构化真实环境中实现可靠的抓取操作。

Abstract: Robotic grasping is a fundamental capability for autonomous manipulation, yet
remains highly challenging in cluttered environments where occlusion, poor
perception quality, and inconsistent 3D reconstructions often lead to unstable
or failed grasps. Conventional pipelines have widely relied on RGB-D cameras to
provide geometric information, which fail on transparent or glossy objects and
degrade at close range. We present GraspView, an RGB-only robotic grasping
pipeline that achieves accurate manipulation in cluttered environments without
depth sensors. Our framework integrates three key components: (i) global
perception scene reconstruction, which provides locally consistent, up-to-scale
geometry from a single RGB view and fuses multi-view projections into a
coherent global 3D scene; (ii) a render-and-score active perception strategy,
which dynamically selects next-best-views to reveal occluded regions; and (iii)
an online metric alignment module that calibrates VGGT predictions against
robot kinematics to ensure physical scale consistency. Building on these
tailor-designed modules, GraspView performs best-view global grasping, fusing
multi-view reconstructions and leveraging GraspNet for robust execution.
Experiments on diverse tabletop objects demonstrate that GraspView
significantly outperforms both RGB-D and single-view RGB baselines, especially
under heavy occlusion, near-field sensing, and with transparent objects. These
results highlight GraspView as a practical and versatile alternative to RGB-D
pipelines, enabling reliable grasping in unstructured real-world environments.

</details>


### [10] [Can Context Bridge the Reality Gap? Sim-to-Real Transfer of Context-Aware Policies](https://arxiv.org/abs/2511.04249)
*Marco Iannotta,Yuxuan Yang,Johannes A. Stork,Erik Schaffernicht,Todor Stoyanov*

Main category: cs.RO

TL;DR: 该论文提出在基于域随机化的强化学习框架中集成上下文估计模块，通过让策略感知动态参数来改进模拟到现实的迁移性能。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在机器人应用中模拟到现实迁移的挑战，传统域随机化方法虽然能提高泛化性但会降低性能，因此研究通过让策略感知动态参数来改进迁移效果。

Method: 在基于域随机化的强化学习框架中集成上下文估计模块，系统比较了最先进的监督策略，让策略能够根据估计的动态参数进行条件化。

Result: 在标准控制基准和真实世界Franka Emika Panda机器人推任务中，上下文感知策略在所有设置下都优于上下文无关基线，但最佳监督策略取决于具体任务。

Conclusion: 上下文感知策略能有效改进模拟到现实的迁移性能，但需要根据具体任务选择适当的监督策略。

Abstract: Sim-to-real transfer remains a major challenge in reinforcement learning (RL)
for robotics, as policies trained in simulation often fail to generalize to the
real world due to discrepancies in environment dynamics. Domain Randomization
(DR) mitigates this issue by exposing the policy to a wide range of randomized
dynamics during training, yet leading to a reduction in performance. While
standard approaches typically train policies agnostic to these variations, we
investigate whether sim-to-real transfer can be improved by conditioning the
policy on an estimate of the dynamics parameters -- referred to as context. To
this end, we integrate a context estimation module into a DR-based RL framework
and systematically compare SOTA supervision strategies. We evaluate the
resulting context-aware policies in both a canonical control benchmark and a
real-world pushing task using a Franka Emika Panda robot. Results show that
context-aware policies outperform the context-agnostic baseline across all
settings, although the best supervision strategy depends on the task.

</details>


### [11] [Design and Control of a Coaxial Dual-rotor Reconfigurable Tailsitter UAV Based on Swashplateless Mechanism](https://arxiv.org/abs/2511.04251)
*Jinfeng Liang,Haocheng Guo,Ximin Lyu*

Main category: cs.RO

TL;DR: 本文提出了一种可重构机翼的尾座式垂直起降无人机，通过机翼伸缩设计、同轴异构双旋翼配置和无斜盘机构，解决了传统尾座式无人机在多旋翼模式下易受风扰、功耗高和结构复杂的问题。


<details>
  <summary>Details</summary>
Motivation: 传统尾座式VTOL无人机在多旋翼模式下暴露较大的前机身面积，容易受到风扰，同时存在功耗高和结构复杂的问题。

Method: 采用可伸缩机翼设计（多旋翼模式收起，固定翼模式展开）、同轴异构双旋翼配置降低功耗、改进的无斜盘机构控制俯仰和滚转，并增加挥舞铰链优化结构以减少振动。

Result: 通过全面的过渡飞行测试验证了无人机在整个飞行包线内的稳定飞行性能。

Conclusion: 所提出的可重构机翼尾座式无人机设计有效解决了风扰、功耗和结构复杂度问题，实现了稳定的全包线飞行。

Abstract: The tailsitter vertical takeoff and landing (VTOL) UAV is widely used due to
its lower dead weight, which eliminates the actuators and mechanisms for
tilting. However, the tailsitter UAV is susceptible to wind disturbances in
multi-rotor mode, as it exposes a large frontal fuselage area. To address this
issue, our tailsitter UAV features a reconfigurable wing design, allowing wings
to retract in multi-rotor mode and extend in fixed- wing mode. Considering
power efficiency, we design a coaxial heterogeneous dual-rotor configuration,
which significantly re- duces the total power consumption. To reduce structural
weight and simplify structural complexity, we employ a swashplateless mechanism
with an improved design to control pitch and roll in multi-rotor mode. We
optimize the structure of the swashplateless mechanism by adding flapping
hinges, which reduces vibration during cyclic acceleration and deceleration.
Finally, we perform comprehensive transition flight tests to validate stable
flight performance across the entire flight envelope of the tailsitter UAV.

</details>


### [12] [MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments](https://arxiv.org/abs/2511.04320)
*Kuankuan Sima,Longbin Tang,Haozhe Ma,Lin Zhao*

Main category: cs.RO

TL;DR: MacroNav是一个基于学习的导航框架，通过轻量级上下文编码器和强化学习策略，在未知环境中实现高效导航，显著提升了成功率和路径效率。


<details>
  <summary>Details</summary>
Motivation: 解决未知环境中自主导航需要紧凑而富有表现力的空间理解，现有方法难以平衡丰富的上下文表示与导航效率的问题。

Method: 包含两个关键组件：(1) 通过多任务自监督学习训练的轻量级上下文编码器，捕捉多尺度、导航中心的空间表示；(2) 强化学习策略，将这些表示与基于图的推理无缝集成以进行高效动作选择。

Result: 实验表明上下文编码器具有高效和鲁棒的环境理解能力。真实世界部署验证了MacroNav的有效性，在成功率和路径长度加权成功率方面显著优于最先进的导航方法，同时保持低计算成本。

Conclusion: MacroNav框架在未知环境中实现了高效导航，平衡了表示丰富性和导航效率，为自主导航提供了有效的解决方案。

Abstract: Autonomous navigation in unknown environments requires compact yet expressive
spatial understanding under partial observability to support high-level
decision making. Existing approaches struggle to balance rich contextual
representation with navigation efficiency. We present MacroNav, a
learning-based navigation framework featuring two key components: (1) a
lightweight context encoder trained via multi-task self-supervised learning to
capture multi-scale, navigation-centric spatial representations; and (2) a
reinforcement learning policy that seamlessly integrates these representations
with graph-based reasoning for efficient action selection. Extensive
experiments demonstrate the context encoder's efficient and robust
environmental understanding. Real-world deployments further validate MacroNav's
effectiveness, yielding significant gains over state-of-the-art navigation
methods in both Success Rate (SR) and Success weighted by Path Length (SPL),
while maintaining low computational cost. Code will be released upon
acceptance.

</details>


### [13] [GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies](https://arxiv.org/abs/2511.04357)
*Maëlic Neau,Zoe Falomir,Paulo E. Santos,Anne-Gwenn Bosser,Cédric Buche*

Main category: cs.RO

TL;DR: GraSP-VLA是一个神经符号框架，使用连续场景图表示从人类演示生成符号表示，用于推理时生成新的规划域，并协调低层VLA策略以扩展连续执行的动作数量。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案存在局限性：端到端模仿学习的VLA模型缺乏高层符号规划能力，影响长时程任务表现；符号方法的AML缺乏泛化性和可扩展性。需要结合两者优势的新方法。

Method: 提出GraSP-VLA神经符号框架，使用连续场景图表示生成人类演示的符号表示，在推理时生成新规划域，并作为低层VLA策略的协调器。

Result: GraSP-VLA在自动规划域生成任务中有效建模符号表示，真实世界实验显示连续场景图表示在协调长时程任务中VLA策略的潜力。

Conclusion: GraSP-VLA框架成功结合了神经和符号方法的优势，在长时程任务中表现出色，为机器人技能学习提供了有效的解决方案。

Abstract: Deploying autonomous robots that can learn new skills from demonstrations is
an important challenge of modern robotics. Existing solutions often apply
end-to-end imitation learning with Vision-Language Action (VLA) models or
symbolic approaches with Action Model Learning (AML). On the one hand, current
VLA models are limited by the lack of high-level symbolic planning, which
hinders their abilities in long-horizon tasks. On the other hand, symbolic
approaches in AML lack generalization and scalability perspectives. In this
paper we present a new neuro-symbolic approach, GraSP-VLA, a framework that
uses a Continuous Scene Graph representation to generate a symbolic
representation of human demonstrations. This representation is used to generate
new planning domains during inference and serves as an orchestrator for
low-level VLA policies, scaling up the number of actions that can be reproduced
in a row. Our results show that GraSP-VLA is effective for modeling symbolic
representations on the task of automatic planning domain generation from
observations. In addition, results on real-world experiments show the potential
of our Continuous Scene Graph representation to orchestrate low-level VLA
policies in long-horizon tasks.

</details>


### [14] [Studying the Effect of Explicit Interaction Representations on Learning Scene-level Distributions of Human Trajectories](https://arxiv.org/abs/2511.04375)
*Anna Mészáros,Javier Alonso-Mora,Jens Kober*

Main category: cs.RO

TL;DR: 研究比较了自动驾驶场景中不同交互表示方法对联合分布学习的影响，发现明确定义的交互比数据驱动的隐式学习效果更好。


<details>
  <summary>Details</summary>
Motivation: 有效捕捉场景中所有智能体的联合分布对自动驾驶决策至关重要，但目前对如何最佳表示智能体间交互缺乏共识——是通过神经网络隐式学习还是基于时空关系显式建模。

Method: 在同一网络结构中研究不同交互描述方式，比较隐式数据驱动连接与明确定义交互（如路口谁先通过）的效果。

Result: 研究发现，仅让网络基于数据建立交互连接通常对性能有负面影响，而明确定义的交互能显著提升性能。

Conclusion: 在自动驾驶场景建模中，基于人类决策逻辑的显式交互建模优于纯粹的数据驱动隐式学习。

Abstract: Effectively capturing the joint distribution of all agents in a scene is
relevant for predicting the true evolution of the scene and in turn providing
more accurate information to the decision processes of autonomous vehicles.
While new models have been developed for this purpose in recent years, it
remains unclear how to best represent the joint distributions particularly from
the perspective of the interactions between agents. Thus far there is no clear
consensus on how best to represent interactions between agents; whether they
should be learned implicitly from data by neural networks, or explicitly
modeled using the spatial and temporal relations that are more grounded in
human decision-making. This paper aims to study various means of describing
interactions within the same network structure and their effect on the final
learned joint distributions. Our findings show that more often than not, simply
allowing a network to establish interactive connections between agents based on
data has a detrimental effect on performance. Instead, having well defined
interactions (such as which agent of an agent pair passes first at an
intersection) can often bring about a clear boost in performance.

</details>


### [15] [ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation](https://arxiv.org/abs/2511.04381)
*Dexin wang,Faliang Chang,Chunsheng Liu*

Main category: cs.RO

TL;DR: ForeRobo是一个生成式机器人代理，通过生成模拟自主获取操作技能，结合生成范式与经典控制，实现零样本模拟到真实世界的迁移。


<details>
  <summary>Details</summary>
Motivation: 高效利用模拟获取高级操作技能具有挑战性但意义重大，传统端到端策略学习方法缺乏可解释性和执行效率。

Method: 采用自引导的'提议-生成-学习-执行'循环：提议技能并构建模拟环境，生成技能一致的目标状态(ForeGen)，训练状态生成模型(ForeFormer)建立点对点对应关系，使用经典控制算法执行动作。

Result: 在多种刚体和关节物体操作任务中，ForeFormer比最先进的状态生成模型平均提升56.32%，在20多个真实世界任务中实现零样本迁移，平均成功率79.28%。

Conclusion: ForeRobo展示了生成模拟与经典控制结合的有效性，提供更好的可解释性和执行效率，在多种操作任务中表现出强大的泛化能力。

Abstract: Efficiently leveraging simulation to acquire advanced manipulation skills is
both challenging and highly significant. We introduce \textit{ForeRobo}, a
generative robotic agent that utilizes generative simulations to autonomously
acquire manipulation skills driven by envisioned goal states. Instead of
directly learning low-level policies, we advocate integrating generative
paradigms with classical control. Our approach equips a robotic agent with a
self-guided \textit{propose-generate-learn-actuate} cycle. The agent first
proposes the skills to be acquired and constructs the corresponding simulation
environments; it then configures objects into appropriate arrangements to
generate skill-consistent goal states (\textit{ForeGen}). Subsequently, the
virtually infinite data produced by ForeGen are used to train the proposed
state generation model (\textit{ForeFormer}), which establishes point-wise
correspondences by predicting the 3D goal position of every point in the
current state, based on the scene state and task instructions. Finally,
classical control algorithms are employed to drive the robot in real-world
environments to execute actions based on the envisioned goal states. Compared
with end-to-end policy learning methods, ForeFormer offers superior
interpretability and execution efficiency. We train and benchmark ForeFormer
across a variety of rigid-body and articulated-object manipulation tasks, and
observe an average improvement of 56.32\% over the state-of-the-art state
generation models, demonstrating strong generality across different
manipulation patterns. Moreover, in real-world evaluations involving more than
20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits
remarkable generalization capabilities, attaining an average success rate of
79.28\%.

</details>


### [16] [Temporal Action Selection for Action Chunking](https://arxiv.org/abs/2511.04421)
*Yueyang Weng,Xiaopeng Zhang,Yongjin Mu,Yingcong Zhu,Yanjie Li,Qi Liu*

Main category: cs.RO

TL;DR: 提出Temporal Action Selector (TAS)算法解决动作分块方法在反应性方面的不足，通过缓存多时间步预测的动作块并动态选择最优动作，在反应性、决策一致性和运动连贯性之间实现平衡优化。


<details>
  <summary>Details</summary>
Motivation: 动作分块方法虽然增强了建模能力，但降低了决策频率，限制了近期观测的利用，导致反应性不足，特别是在应对传感器噪声和环境动态变化时表现不佳。现有方法需要在反应性和决策一致性之间权衡，无法同时兼顾。

Method: 提出TAS算法，缓存多个时间步预测的动作块，通过轻量级选择器网络动态选择最优动作。将TAS与残差强化学习结合，进一步提升训练效率和性能上限。

Result: 在多个任务和不同基础策略上的实验表明，TAS显著提高了成功率，绝对增益最高达73.3%。与残差强化学习结合后，训练效率大幅提升，性能上限提高。仿真和物理机器人实验均验证了方法的有效性。

Conclusion: TAS算法成功解决了动作分块方法的反应性不足问题，在保持决策一致性和运动连贯性的同时显著提升了反应性，为学习演示提供了更优的解决方案。

Abstract: Action chunking is a widely adopted approach in Learning from Demonstration
(LfD). By modeling multi-step action chunks rather than single-step actions,
action chunking significantly enhances modeling capabilities for human expert
policies. However, the reduced decision frequency restricts the utilization of
recent observations, degrading reactivity - particularly evident in the
inadequate adaptation to sensor noise and dynamic environmental changes.
Existing efforts to address this issue have primarily resorted to trading off
reactivity against decision consistency, without achieving both. To address
this limitation, we propose a novel algorithm, Temporal Action Selector (TAS),
which caches predicted action chunks from multiple timesteps and dynamically
selects the optimal action through a lightweight selector network. TAS achieves
balanced optimization across three critical dimensions: reactivity, decision
consistency, and motion coherence. Experiments across multiple tasks with
diverse base policies show that TAS significantly improves success rates -
yielding an absolute gain of up to 73.3%. Furthermore, integrating TAS as a
base policy with residual reinforcement learning (RL) substantially enhances
training efficiency and elevates the performance plateau. Experiments in both
simulation and physical robots confirm the method's efficacy.

</details>


### [17] [Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment](https://arxiv.org/abs/2511.04555)
*Tao Lin,Yilei Zhong,Yuxin Du,Jingjing Zhang,Jiting Liu,Yinxinyu Chen,Encheng Gu,Ziyan Liu,Hongyi Cai,Yanwen Zou,Lixing Zou,Zhaoye Zhou,Gen Li,Bo Zhao*

Main category: cs.RO

TL;DR: Evo-1是一个轻量级的视觉-语言-动作模型，通过新颖的跨调制扩散变换器和优化的集成模块，在减少计算量和提高部署效率的同时保持强大性能，无需机器人数据预训练。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型参数量大，依赖大规模机器人数据预训练，导致训练计算成本高、实时推理部署受限，且训练范式会降低视觉语言骨干网络的感知表示，导致过拟合和泛化能力差。

Method: 基于原生多模态视觉语言模型，引入跨调制扩散变换器和优化集成模块，采用两阶段训练范式逐步对齐动作与感知，保留VLM的表示能力。

Result: 仅0.77亿参数，在Meta-World和RoboTwin套件上分别超越之前最佳模型12.4%和6.9%，在LIBERO上达到94.8%的竞争性结果，真实世界评估达到78%成功率，推理频率高且内存开销低。

Conclusion: Evo-1展示了轻量级高效VLA模型的可行性，在保持性能的同时显著降低计算和部署成本，为未来研究提供了有价值的参考。

Abstract: Vision-Language-Action (VLA) models have emerged as a powerful framework that
unifies perception, language, and control, enabling robots to perform diverse
tasks through multimodal understanding. However, current VLA models typically
contain massive parameters and rely heavily on large-scale robot data
pretraining, leading to high computational costs during training, as well as
limited deployability for real-time inference. Moreover, most training
paradigms often degrade the perceptual representations of the vision-language
backbone, resulting in overfitting and poor generalization to downstream tasks.
In this work, we present Evo-1, a lightweight VLA model that reduces
computation and improves deployment efficiency, while maintaining strong
performance without pretraining on robot data. Evo-1 builds on a native
multimodal Vision-Language model (VLM), incorporating a novel cross-modulated
diffusion transformer along with an optimized integration module, together
forming an effective architecture. We further introduce a two-stage training
paradigm that progressively aligns action with perception, preserving the
representations of the VLM. Notably, with only 0.77 billion parameters, Evo-1
achieves state-of-the-art results on the Meta-World and RoboTwin suite,
surpassing the previous best models by 12.4% and 6.9%, respectively, and also
attains a competitive result of 94.8% on LIBERO. In real-world evaluations,
Evo-1 attains a 78% success rate with high inference frequency and low memory
overhead, outperforming all baseline methods. We release code, data, and model
weights to facilitate future research on lightweight and efficient VLA models.

</details>


### [18] [SAFe-Copilot: Unified Shared Autonomy Framework](https://arxiv.org/abs/2511.04664)
*Phat Nguyen,Erfan Aasi,Shiva Sreeram,Guy Rosman,Andrew Silva,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: 提出一个基于视觉语言模型的共享自治框架，在语义层面整合人类输入和自主规划器，通过多模态线索推断驾驶员意图，在Bench2Drive基准测试中显著降低碰撞率并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶系统在罕见、模糊和分布外场景中的脆弱性，通过共享自治方法在自主系统不确定时融入人类输入，但现有方法局限于低层轨迹层面，无法保持驾驶意图。

Method: 利用视觉语言模型从驾驶员动作和环境上下文等多模态线索推断驾驶员意图，在更高抽象层面合成协调策略，调解人类和自主控制。

Result: 在模拟人类设置中实现完美召回率、高准确率和精确度；人类受试者调查显示92%情况下参与者同意仲裁结果；在Bench2Drive基准测试中显著降低碰撞率并提升整体性能。

Conclusion: 基于语义、语言表示的仲裁层是共享自治的设计原则，使系统能够运用常识推理并保持与人类意图的连续性。

Abstract: Autonomous driving systems remain brittle in rare, ambiguous, and
out-of-distribution scenarios, where human driver succeed through contextual
reasoning. Shared autonomy has emerged as a promising approach to mitigate such
failures by incorporating human input when autonomy is uncertain. However, most
existing methods restrict arbitration to low-level trajectories, which
represent only geometric paths and therefore fail to preserve the underlying
driving intent. We propose a unified shared autonomy framework that integrates
human input and autonomous planners at a higher level of abstraction. Our
method leverages Vision Language Models (VLMs) to infer driver intent from
multi-modal cues -- such as driver actions and environmental context -- and to
synthesize coherent strategies that mediate between human and autonomous
control. We first study the framework in a mock-human setting, where it
achieves perfect recall alongside high accuracy and precision. A human-subject
survey further shows strong alignment, with participants agreeing with
arbitration outcomes in 92% of cases. Finally, evaluation on the Bench2Drive
benchmark demonstrates a substantial reduction in collision rate and
improvement in overall performance compared to pure autonomy. Arbitration at
the level of semantic, language-based representations emerges as a design
principle for shared autonomy, enabling systems to exercise common-sense
reasoning and maintain continuity with human intent.

</details>


### [19] [Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions](https://arxiv.org/abs/2511.04665)
*Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li*

Main category: cs.RO

TL;DR: 提出了一个基于真实世界视频构建软体数字孪生体的真实到仿真策略评估框架，使用3D高斯泼溅技术实现逼真渲染，用于评估涉及可变形物体的机器人操作策略。


<details>
  <summary>Details</summary>
Motivation: 真实世界中直接评估机器人操作策略成本高、耗时长且难以复现，特别是涉及可变形物体的任务。现有模拟器难以捕捉软体交互的视觉和物理复杂性。

Method: 从真实世界视频构建软体数字孪生体，使用3D高斯泼溅技术实现机器人、物体和环境的逼真渲染，结合物理信息重建技术。

Result: 在代表性可变形操作任务（毛绒玩具打包、绳索布线、T型块推动）上验证，模拟运行与现实执行性能高度相关，并能揭示学习策略的关键行为模式。

Conclusion: 结合物理信息重建和高质量渲染技术，能够实现可重复、可扩展且准确的机器人操作策略评估。

Abstract: Robotic manipulation policies are advancing rapidly, but their direct
evaluation in the real world remains costly, time-consuming, and difficult to
reproduce, particularly for tasks involving deformable objects. Simulation
provides a scalable and systematic alternative, yet existing simulators often
fail to capture the coupled visual and physical complexity of soft-body
interactions. We present a real-to-sim policy evaluation framework that
constructs soft-body digital twins from real-world videos and renders robots,
objects, and environments with photorealistic fidelity using 3D Gaussian
Splatting. We validate our approach on representative deformable manipulation
tasks, including plush toy packing, rope routing, and T-block pushing,
demonstrating that simulated rollouts correlate strongly with real-world
execution performance and reveal key behavioral patterns of learned policies.
Our results suggest that combining physics-informed reconstruction with
high-quality rendering enables reproducible, scalable, and accurate evaluation
of robotic manipulation policies. Website: https://real2sim-eval.github.io/

</details>


### [20] [X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations](https://arxiv.org/abs/2511.04671)
*Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia*

Main category: cs.RO

TL;DR: X-Diffusion是一个利用人类视频数据训练机器人策略的扩散框架，通过噪声注入解决人机动作执行差异问题，在五个操作任务中比最佳基线平均成功率提高16%。


<details>
  <summary>Details</summary>
Motivation: 人类视频数据丰富易得，但人机在动作执行上存在根本性差异，直接使用人类动作会导致机器人学习到物理不可行的动作。需要一种方法既能利用人类动作的高层任务指导，又避免学习不可行的低层执行细节。

Method: 提出X-Diffusion框架：首先训练分类器区分人类和机器人执行的动作；然后在策略训练中，只有当人类动作添加足够噪声使分类器无法区分其执行体时，才将其纳入训练。机器人动作在低噪声水平下提供精细去噪监督，人类动作仅在高噪声水平下提供粗略指导。

Result: 实验表明，在存在执行不匹配的情况下，简单共同训练会降低策略性能，而X-Diffusion能持续提升性能。在五个操作任务中，X-Diffusion比最佳基线平均成功率提高16%。

Conclusion: X-Diffusion提供了一个原则性框架，能够最大化利用人类数据而不学习动态不可行的动作，有效解决了人机动作执行差异问题。

Abstract: Human videos can be recorded quickly and at scale, making them an appealing
source of training data for robot learning. However, humans and robots differ
fundamentally in embodiment, resulting in mismatched action execution. Direct
kinematic retargeting of human hand motion can therefore produce actions that
are physically infeasible for robots. Despite these low-level differences,
human demonstrations provide valuable motion cues about how to manipulate and
interact with objects. Our key idea is to exploit the forward diffusion
process: as noise is added to actions, low-level execution differences fade
while high-level task guidance is preserved. We present X-Diffusion, a
principled framework for training diffusion policies that maximally leverages
human data without learning dynamically infeasible motions. X-Diffusion first
trains a classifier to predict whether a noisy action is executed by a human or
robot. Then, a human action is incorporated into policy training only after
adding sufficient noise such that the classifier cannot discern its embodiment.
Actions consistent with robot execution supervise fine-grained denoising at low
noise levels, while mismatched human actions provide only coarse guidance at
higher noise levels. Our experiments show that naive co-training under
execution mismatches degrades policy performance, while X-Diffusion
consistently improves it. Across five manipulation tasks, X-Diffusion achieves
a 16% higher average success rate than the best baseline. The project website
is available at https://portal-cornell.github.io/X-Diffusion/.

</details>


### [21] [GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction](https://arxiv.org/abs/2511.04679)
*Qingzhou Lu,Yao Feng,Baiyu Shi,Michael Piseno,Zhenan Bao,C. Karen Liu*

Main category: cs.RO

TL;DR: GentleHumanoid是一个将阻抗控制集成到全身运动跟踪策略中的框架，旨在实现人形机器人上半身的柔顺性，通过统一的弹簧模型处理阻力和引导力，在保持任务成功率的同时显著降低接触力峰值。


<details>
  <summary>Details</summary>
Motivation: 当前大多数强化学习策略强调刚性跟踪并抑制外力，现有的阻抗增强方法通常仅限于基座或末端执行器控制，且主要关注抵抗极端力而非实现柔顺性。人形机器人需要在以人为中心的环境中安全自然地交互。

Method: 提出统一的基于弹簧的公式，同时建模阻力接触（按压表面时的恢复力）和引导接触（从人类运动数据采样的推拉力），确保肩、肘、腕关节的动力学一致性力，并通过任务可调力阈值增强安全性。

Result: 在仿真和Unitree G1人形机器人上的评估显示，相比基线方法，该策略在保持任务成功率的同时持续降低接触力峰值，实现了更平滑自然的交互，包括轻柔拥抱、坐站辅助和安全物体操作等任务。

Conclusion: 该研究向能够安全有效与人类协作并在真实环境中处理物体的人形机器人迈出了一步，展示了通过阻抗控制实现柔顺交互的可行性。

Abstract: Humanoid robots are expected to operate in human-centered environments where
safe and natural physical interaction is essential. However, most recent
reinforcement learning (RL) policies emphasize rigid tracking and suppress
external forces. Existing impedance-augmented approaches are typically
restricted to base or end-effector control and focus on resisting extreme
forces rather than enabling compliance. We introduce GentleHumanoid, a
framework that integrates impedance control into a whole-body motion tracking
policy to achieve upper-body compliance. At its core is a unified spring-based
formulation that models both resistive contacts (restoring forces when pressing
against surfaces) and guiding contacts (pushes or pulls sampled from human
motion data). This formulation ensures kinematically consistent forces across
the shoulder, elbow, and wrist, while exposing the policy to diverse
interaction scenarios. Safety is further supported through task-adjustable
force thresholds. We evaluate our approach in both simulation and on the
Unitree G1 humanoid across tasks requiring different levels of compliance,
including gentle hugging, sit-to-stand assistance, and safe object
manipulation. Compared to baselines, our policy consistently reduces peak
contact forces while maintaining task success, resulting in smoother and more
natural interactions. These results highlight a step toward humanoid robots
that can safely and effectively collaborate with humans and handle objects in
real-world environments.

</details>
