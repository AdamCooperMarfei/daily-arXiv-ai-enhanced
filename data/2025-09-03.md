<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 83]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Robotic Fire Risk Detection based on Dynamic Knowledge Graph Reasoning: An LLM-Driven Approach with Graph Chain-of-Thought](https://arxiv.org/abs/2509.00054)
*Haimei Pan,Jiyun Zhang,Qinxi Wei,Xiongnan Jin,Chen Xinkai,Jie Cheng*

Main category: cs.RO

TL;DR: 该论文提出了Insights-on-Graph(IOG)框架，通过结合知识图谱和大规模多模态模型，实现火灾场景的智能感知和应急响应规划。


<details>
  <summary>Details</summary>
Motivation: 当前火灾预防和救援研究面临感知不完整、态势认知不足和响应延迟等挑战，需要提升机器人在火灾场景中的智能感知和响应能力。

Method: 首先利用大语言模型构建火灾领域知识图谱，然后提出IOG框架整合知识图谱的结构化信息和大规模多模态模型，从实时场景图像生成感知驱动的风险图谱。

Result: 大量仿真和真实实验表明，IOG在火灾风险检测和救援决策方面具有良好的适用性和实际应用价值。

Conclusion: IOG框架能够实现早期火灾风险检测，并根据不断变化的风险情况为任务模块和机器人组件配置提供可解释的应急响应。

Abstract: Fire is a highly destructive disaster, but effective prevention can
significantly reduce its likelihood of occurrence. When it happens, deploying
emergency robots in fire-risk scenarios can help minimize the danger to human
responders. However, current research on pre-disaster warnings and
disaster-time rescue still faces significant challenges due to incomplete
perception, inadequate fire situational awareness, and delayed response. To
enhance intelligent perception and response planning for robots in fire
scenarios, we first construct a knowledge graph (KG) by leveraging large
language models (LLMs) to integrate fire domain knowledge derived from fire
prevention guidelines and fire rescue task information from robotic emergency
response documents. We then propose a new framework called Insights-on-Graph
(IOG), which integrates the structured fire information of KG and Large
Multimodal Models (LMMs). The framework generates perception-driven risk graphs
from real-time scene imagery to enable early fire risk detection and provide
interpretable emergency responses for task module and robot component
configuration based on the evolving risk situation. Extensive simulations and
real-world experiments show that IOG has good applicability and practical
application value in fire risk detection and rescue decision-making.

</details>


### [2] [U2UData-2: A Scalable Swarm UAVs Autonomous Flight Dataset for Long-horizon Tasks](https://arxiv.org/abs/2509.00055)
*Tongtong Feng,Xin Wang,Feilin Han,Leping Zhang,Wenwu Zhu*

Main category: cs.RO

TL;DR: U2UData-2是首个面向长时域任务的大规模无人机集群自主飞行数据集和在线数据收集平台，包含12个场景、720条轨迹、120小时数据，支持野生动物保护等复杂任务验证。


<details>
  <summary>Details</summary>
Motivation: 现有无人机数据集仅关注特定基础任务，无法满足长时域任务的真实部署需求。长时域任务需要处理长期依赖关系、维持持久状态并适应动态目标变化，而现有数据集存在局限性。

Method: 通过15架无人机自主协同飞行采集数据，构建包含12个场景、720条轨迹、120小时飞行数据的大规模数据集。平台支持模拟器、无人机、传感器、飞行算法、编队模式和长时域任务的定制化配置，提供一键在线部署和闭环仿真验证。

Result: 数据集包含432万帧LiDAR数据和1296万帧RGB图像，覆盖所有飞行路线的亮度、温度、湿度、烟雾和气流值。平台成功实现了野生动物保护等长时域任务的验证，并对9个最先进模型进行了全面基准测试。

Conclusion: U2UData-2填补了长时域无人机集群自主飞行数据集的空白，提供了可扩展的数据收集和算法验证平台，为推进低空经济发展提供了重要基础设施支持。

Abstract: Swarm UAV autonomous flight for Long-Horizon (LH) tasks is crucial for
advancing the low-altitude economy. However, existing methods focus only on
specific basic tasks due to dataset limitations, failing in real-world
deployment for LH tasks. LH tasks are not mere concatenations of basic tasks,
requiring handling long-term dependencies, maintaining persistent states, and
adapting to dynamic goal shifts. This paper presents U2UData-2, the first
large-scale swarm UAV autonomous flight dataset for LH tasks and the first
scalable swarm UAV data online collection and algorithm closed-loop
verification platform. The dataset is captured by 15 UAVs in autonomous
collaborative flights for LH tasks, comprising 12 scenes, 720 traces, 120
hours, 600 seconds per trajectory, 4.32M LiDAR frames, and 12.96M RGB frames.
This dataset also includes brightness, temperature, humidity, smoke, and
airflow values covering all flight routes. The platform supports the
customization of simulators, UAVs, sensors, flight algorithms, formation modes,
and LH tasks. Through a visual control window, this platform allows users to
collect customized datasets through one-click deployment online and to verify
algorithms by closed-loop simulation. U2UData-2 also introduces an LH task for
wildlife conservation and provides comprehensive benchmarks with 9 SOTA models.
U2UData-2 can be found at https://fengtt42.github.io/U2UData-2/.

</details>


### [3] [Correspondence-Free, Function-Based Sim-to-Real Learning for Deformable Surface Control](https://arxiv.org/abs/2509.00060)
*Yingjun Tian,Guoxin Fang,Renbo Su,Aoran Lyu,Neelotpal Dutta,Simeon Gill,Andrew Weightman,Charlie C. L. Wang*

Main category: cs.RO

TL;DR: 提出了一种基于函数的无对应点模拟到真实学习方法，用于控制可变形自由曲面，通过神经网络同时学习变形函数空间和置信度映射，支持点云和标记点输入。


<details>
  <summary>Details</summary>
Motivation: 传统模拟到真实迁移方法严重依赖具有完整对应关系的标记点，限制了在无对应点或标记点缺失情况下的应用。

Method: 同时学习由神经网络参数化的变形函数空间和置信度映射，将模拟形状映射到真实对应物，支持3D扫描点云和运动捕捉标记点输入。

Result: 方法在视觉设备和四种气动软机器人上展示了多功能性和适应性，包括可变形膜、机器人模型和两个软操作器。

Conclusion: 该方法实现了无缝的模拟到真实迁移，可集成到基于神经网络的计算流程中，用于逆向运动学和形状控制。

Abstract: This paper presents a correspondence-free, function-based sim-to-real
learning method for controlling deformable freeform surfaces. Unlike
traditional sim-to-real transfer methods that strongly rely on marker points
with full correspondences, our approach simultaneously learns a deformation
function space and a confidence map -- both parameterized by a neural network
-- to map simulated shapes to their real-world counterparts. As a result, the
sim-to-real learning can be conducted by input from either a 3D scanner as
point clouds (without correspondences) or a motion capture system as marker
points (tolerating missed markers). The resultant sim-to-real transfer can be
seamlessly integrated into a neural network-based computational pipeline for
inverse kinematics and shape control. We demonstrate the versatility and
adaptability of our method on both vision devices and across four pneumatically
actuated soft robots: a deformable membrane, a robotic mannequin, and two soft
manipulators.

</details>


### [4] [OpenTie: Open-vocabulary Sequential Rebar Tying System](https://arxiv.org/abs/2509.00064)
*Mingze Liu,Sai Fan,Haozhen Li,Haobo Liang,Yixing Yuan,Yanke Wang*

Main category: cs.RO

TL;DR: OpenTie是一个无需训练的3D钢筋绑扎框架，通过RGB到点云生成和开放词汇检测技术，实现高精度的水平和垂直钢筋绑扎任务。


<details>
  <summary>Details</summary>
Motivation: 现有钢筋绑扎产品和研究主要集中于平面钢筋设置且需要模型训练，无法满足复杂场景需求。

Method: 采用双目相机和机械臂，结合RGB到点云生成、开放词汇检测和基于提示的目标检测方法，通过后处理程序过滤图像。

Result: 在真实世界钢筋设置实验中验证了系统的有效性，实现了高精度绑扎。

Conclusion: OpenTie框架为复杂钢筋绑扎场景提供了灵活、高效的解决方案，无需模型训练即可实现高精度操作。

Abstract: Robotic practices on the construction site emerge as an attention-attracting
manner owing to their capability of tackle complex challenges, especially in
the rebar-involved scenarios. Most of existing products and research are mainly
focused on flat rebar setting with model training demands. To fulfill this gap,
we propose OpenTie, a 3D training-free rebar tying framework utilizing a
RGB-to-point-cloud generation and an open-vocabulary detection. We implements
the OpenTie via a robotic arm with a binocular camera and guarantees a high
accuracy by applying the prompt-based object detection method on the image
filtered by our propose post-processing procedure based a image to point cloud
generation framework. The system is flexible for horizontal and vertical rebar
tying tasks and the experiments on the real-world rebar setting verifies that
the effectiveness of the system in practice.

</details>


### [5] [Hybrid Perception and Equivariant Diffusion for Robust Multi-Node Rebar Tying](https://arxiv.org/abs/2509.00065)
*Zhitao Wang,Yirong Xiong,Roberto Horowitz,Yanke Wang,Yuxing Han*

Main category: cs.RO

TL;DR: 提出了一种结合几何感知和SE(3)等变去噪扩散的混合方法，用于自动化钢筋绑扎任务，仅需少量训练数据即可实现多节点绑扎


<details>
  <summary>Details</summary>
Motivation: 钢筋绑扎是混凝土施工中重复性高且具有人体工程学风险的任务，现有机器人方法在拥挤钢筋节点中难以准确估计绑扎姿态

Method: 使用DBSCAN聚类、几何特征提取和PCA进行钢筋分割和节点识别，结合Diffusion-EDFs运动规划器，仅需5-10个演示样本训练

Result: 在单层、多层和杂乱配置的钢筋网中验证，展示了高成功率的节点检测和准确的顺序绑扎性能

Conclusion: 该方法相比传统方法显著减少数据需求，实现了鲁棒、高效和自适应的多节点绑扎，有望提高施工现场自动化的安全性和劳动效率

Abstract: Rebar tying is a repetitive but critical task in reinforced concrete
construction, typically performed manually at considerable ergonomic risk.
Recent advances in robotic manipulation hold the potential to automate the
tying process, yet face challenges in accurately estimating tying poses in
congested rebar nodes. In this paper, we introduce a hybrid perception and
motion planning approach that integrates geometry-based perception with
Equivariant Denoising Diffusion on SE(3) (Diffusion-EDFs) to enable robust
multi-node rebar tying with minimal training data. Our perception module
utilizes density-based clustering (DBSCAN), geometry-based node feature
extraction, and principal component analysis (PCA) to segment rebar bars,
identify rebar nodes, and estimate orientation vectors for sequential ranking,
even in complex, unstructured environments. The motion planner, based on
Diffusion-EDFs, is trained on as few as 5-10 demonstrations to generate
sequential end-effector poses that optimize collision avoidance and tying
efficiency. The proposed system is validated on various rebar meshes, including
single-layer, multi-layer, and cluttered configurations, demonstrating high
success rates in node detection and accurate sequential tying. Compared with
conventional approaches that rely on large datasets or extensive manual
parameter tuning, our method achieves robust, efficient, and adaptable
multi-node tying while significantly reducing data requirements. This result
underscores the potential of hybrid perception and diffusion-driven planning to
enhance automation in on-site construction tasks, improving both safety and
labor efficiency.

</details>


### [6] [A Comparative Study of Spline-Based Trajectory Reconstruction Methods Across Varying Automatic Vehicle Location Data Densities](https://arxiv.org/abs/2509.00119)
*Jake Robbennolt,Sirajum Munira,Stephen D. Boyles*

Main category: cs.RO

TL;DR: 这篇论文评估了13种轨迹重建方法，发现速度感知方法更优市，特别是VCHIP-ME方法在准确性和计算效率之间取得最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 自动车辆定位(AVL)数据的更新频率不一致影响了轨迹分析的有效性，需要研究最佳的轨迹重建方法来提高数据利用率。

Method: 使用得克萨斯州高分辨率AVL数据，评估13种轨迹重建方法，分析速度、位置、平滑和数据密度四个关键因素的影响。评价框架结合了数学错误指标和实际物理实际性考虑。

Result: 速度感知方法在各种情况下都显著优于仅依靠位置的方法。平滑方法在复杂城市环境中可能降低性能，但单调性约束仍很重要。VCHIP-ME方法表现最佳，具有高准确性和计算效率。

Conclusion: 研究为轨迹重建系统的实施提供了实用指南，并强调投资高频率AVL数据采集对改善分析质量的重要性。VCHIP-ME方法适合历史分析和实时应用。

Abstract: Automatic vehicle location (AVL) data offers insights into transit dynamics,
but its effectiveness is often hampered by inconsistent update frequencies,
necessitating trajectory reconstruction. This research evaluates 13 trajectory
reconstruction methods, including several novel approaches, using
high-resolution AVL data from Austin, Texas. We examine the interplay of four
critical factors -- velocity, position, smoothing, and data density -- on
reconstruction performance. A key contribution of this study is evaluation of
these methods across sparse and dense datasets, providing insights into the
trade-off between accuracy and resource allocation. Our evaluation framework
combines traditional mathematical error metrics for positional and velocity
with practical considerations, such as physical realism (e.g., aligning
velocity and acceleration with stopped states, deceleration rates, and speed
variability). In addition, we provide insight into the relative value of each
method in calculating realistic metrics for infrastructure evaluations. Our
findings indicate that velocity-aware methods consistently outperform
position-only approaches. Interestingly, we discovered that smoothing-based
methods can degrade overall performance in complex, congested urban
environments, although enforcing monotonicity remains critical. The velocity
constrained Hermite interpolation with monotonicity enforcement (VCHIP-ME)
yields optimal results, offering a balance between high accuracy and
computational efficiency. Its minimal overhead makes it suitable for both
historical analysis and real-time applications, providing significant
predictive power when combined with dense datasets. These findings offer
practical guidance for researchers and practitioners implementing trajectory
reconstruction systems and emphasize the importance of investing in
higher-frequency AVL data collection for improved analysis.

</details>


### [7] [Poke and Strike: Learning Task-Informed Exploration Policies](https://arxiv.org/abs/2509.00178)
*Marina Y. Aoyama,Joao Moura,Juan Del Aguila Ferrandis,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 提出基于强化学习的任务感知探索方法，通过特权任务策略对属性估计误差的敏感性自动生成奖励，训练探索策略来识别物体物理属性，在击球任务中达到90%成功率，平均探索时间低于1.2秒


<details>
  <summary>Details</summary>
Motivation: 在动态机器人任务中，机器人需要准确识别物体的物理属性才能成功执行任务，但由于无法从失败中恢复或重试，需要高效的探索方法来快速估计关键属性

Method: 基于强化学习的任务感知探索方法，使用特权任务策略对属性估计误差的敏感性自动生成奖励来训练探索策略，并引入基于不确定性的机制来决定何时从探索过渡到任务执行

Result: 在击球任务中达到90%的成功率，平均探索时间低于1.2秒，显著优于基线方法（最多40%成功率），并在物理实验中使用KUKA iiwa机械臂验证了方法的有效性

Conclusion: 该方法能够高效地识别物体物理属性，通过任务感知奖励捕获不同属性的相对重要性，在动态机器人任务中实现了快速准确的属性估计和任务执行

Abstract: In many dynamic robotic tasks, such as striking pucks into a goal outside the
reachable workspace, the robot must first identify the relevant physical
properties of the object for successful task execution, as it is unable to
recover from failure or retry without human intervention. To address this
challenge, we propose a task-informed exploration approach, based on
reinforcement learning, that trains an exploration policy using rewards
automatically generated from the sensitivity of a privileged task policy to
errors in estimated properties. We also introduce an uncertainty-based
mechanism to determine when to transition from exploration to task execution,
ensuring sufficient property estimation accuracy with minimal exploration time.
Our method achieves a 90% success rate on the striking task with an average
exploration time under 1.2 seconds, significantly outperforming baselines that
achieve at most 40% success or require inefficient querying and retraining in a
simulator at test time. Additionally, we demonstrate that our task-informed
rewards capture the relative importance of physical properties in both the
striking task and the classical CartPole example. Finally, we validate our
approach by demonstrating its ability to identify object properties and adjust
task execution in a physical setup using the KUKA iiwa robot arm.

</details>


### [8] [First Order Model-Based RL through Decoupled Backpropagation](https://arxiv.org/abs/2509.00215)
*Joseph Amigo,Rooholla Khorrambakht,Elliot Chane-Sane,Nicolas Mansard,Ludovic Righetti*

Main category: cs.RO

TL;DR: 提出了一种混合强化学习方法，将轨迹生成与梯度计算解耦：使用模拟器展开轨迹，同时通过学习的可微分模型进行反向传播计算梯度，实现了高效且一致的一阶策略优化。


<details>
  <summary>Details</summary>
Motivation: 传统基于梯度的RL方法需要模拟器梯度，但实际中往往难以获取；基于模型的RL方法存在预测误差累积问题，影响策略性能。需要一种既能保持样本效率又能避免梯度不可用问题的方法。

Method: 采用混合设计：轨迹生成使用模拟器执行，梯度计算通过学习的可微分模型进行反向传播。即使模拟器梯度不可用，也能实现高效的一阶策略优化，并能从模拟rollouts中学习更准确的critic。

Result: 在基准控制任务上验证了算法的有效性，并在真实的Go2四足机器人上成功实现了四足和双足运动任务。方法达到了SHAC等专用优化器的样本效率和速度，同时保持了PPO等标准方法的通用性。

Conclusion: 该方法成功解决了模拟器梯度不可用的问题，避免了其他一阶MBRL方法的不良行为，在保持高效学习的同时实现了良好的策略性能，在实际机器人任务中表现出色。

Abstract: There is growing interest in reinforcement learning (RL) methods that
leverage the simulator's derivatives to improve learning efficiency. While
early gradient-based approaches have demonstrated superior performance compared
to derivative-free methods, accessing simulator gradients is often impractical
due to their implementation cost or unavailability. Model-based RL (MBRL) can
approximate these gradients via learned dynamics models, but the solver
efficiency suffers from compounding prediction errors during training rollouts,
which can degrade policy performance. We propose an approach that decouples
trajectory generation from gradient computation: trajectories are unrolled
using a simulator, while gradients are computed via backpropagation through a
learned differentiable model of the simulator. This hybrid design enables
efficient and consistent first-order policy optimization, even when simulator
gradients are unavailable, as well as learning a critic from simulation
rollouts, which is more accurate. Our method achieves the sample efficiency and
speed of specialized optimizers such as SHAC, while maintaining the generality
of standard approaches like PPO and avoiding ill behaviors observed in other
first-order MBRL methods. We empirically validate our algorithm on benchmark
control tasks and demonstrate its effectiveness on a real Go2 quadruped robot,
across both quadrupedal and bipedal locomotion tasks.

</details>


### [9] [Embodied AI in Social Spaces: Responsible and Adaptive Robots in Complex Setting - UKAIRS 2025 (Copy)](https://arxiv.org/abs/2509.00218)
*Aleksandra Landowska,Aislinn D Gomez Bergin,Ayodeji O. Abioye,Jayati Deshmukh,Andriana Bouadouki,Maria Wheadon,Athina Georgara,Dominic Price,Tuyen Nguyen,Shuang Ao,Lokesh Singh,Yi Long,Raffaele Miele,Joel E. Fischer,Sarvapali D. Ramchurn*

Main category: cs.RO

TL;DR: 多人多机器人系统的负责任和适应性研究，通过多模态感知和伦理框架开发情感响应和上下文感知的AI驱动机器人


<details>
  <summary>Details</summary>
Motivation: 为复杂动态环境开发负责任、适应性强的多人多机器人系统，满足多样化用户需求，实现可持续、伦理和以人为本的未来

Method: 采用多学科协同设计方法，整合伦理框架和多模态感知技术，开发具体化AI系统

Result: 展示了项目的初期成果，证明了具体化AI如何支持可持续发展和以人为本的未来

Conclusion: 该多学科项目为开发负责任、适应性强的多人多机器人系统提供了有效框架，通过情感响应和上下文感知技术实现了更人性化的机器人交互

Abstract: This paper introduces and overviews a multidisciplinary project aimed at
developing responsible and adaptive multi-human multi-robot (MHMR) systems for
complex, dynamic settings. The project integrates co-design, ethical
frameworks, and multimodal sensing to create AI-driven robots that are
emotionally responsive, context-aware, and aligned with the needs of diverse
users. We outline the project's vision, methodology, and early outcomes,
demonstrating how embodied AI can support sustainable, ethical, and
human-centred futures.

</details>


### [10] [Learn from What We HAVE: History-Aware VErifier that Reasons about Past Interactions Online](https://arxiv.org/abs/2509.00271)
*Yishu Li,Xinyi Mao,Ying Yuan,Kyutae Sim,Ben Eisner,David Held*

Main category: cs.RO

TL;DR: 提出HAVE方法，通过历史感知验证器解决机器人操作中的视觉模糊问题，将动作生成与验证分离，利用扩散模型生成候选动作并通过历史感知验证选择最优动作


<details>
  <summary>Details</summary>
Motivation: 机器人在操作视觉模糊物体时，即使基于动作历史，生成模型在模糊情况下性能仍不理想，需要更好的方法来处理不确定性

Method: 使用无条件扩散生成器提出多个候选动作，然后通过历史感知验证器基于过去交互历史选择最有希望的动作

Result: 理论分析表明验证器显著提高动作质量期望，多个仿真和真实环境实验证实方法有效性并优于基线

Conclusion: HAVE方法通过解耦动作生成和验证，有效解决了机器人操作中的视觉模糊问题，提高了在不确定场景下的操作性能

Abstract: We introduce a novel History-Aware VErifier (HAVE) to disambiguate uncertain
scenarios online by leveraging past interactions. Robots frequently encounter
visually ambiguous objects whose manipulation outcomes remain uncertain until
physically interacted with. While generative models alone could theoretically
adapt to such ambiguity, in practice they obtain suboptimal performance in
ambiguous cases, even when conditioned on action history. To address this, we
propose explicitly decoupling action generation from verification: we use an
unconditional diffusion-based generator to propose multiple candidate actions
and employ our history-aware verifier to select the most promising action by
reasoning about past interactions. Through theoretical analysis, we demonstrate
that employing a verifier significantly improves expected action quality.
Empirical evaluations and analysis across multiple simulated and real-world
environments including articulated objects, multi-modal doors, and uneven
object pick-up confirm the effectiveness of our method and improvements over
baselines. Our project website is available at:
https://liy1shu.github.io/HAVE_CoRL25/

</details>


### [11] [TReF-6: Inferring Task-Relevant Frames from a Single Demonstration for One-Shot Skill Generalization](https://arxiv.org/abs/2509.00310)
*Yuxuan Ding,Shuangge Wang,Tesca Fitzgerald*

Main category: cs.RO

TL;DR: TReF-6是一种从单次演示中推断6自由度任务相关框架的方法，通过轨迹几何识别影响点来定义局部坐标系，结合视觉语言模型实现语义理解和跨场景泛化。


<details>
  <summary>Details</summary>
Motivation: 机器人通常难以从单次演示中泛化，因为缺乏可转移和可解释的空间表示。需要一种能够从轨迹中提取任务相关空间结构的方法。

Method: 从轨迹几何中识别影响点来定义局部坐标系的原点，作为动态运动基元(DMP)的参数化参考。通过视觉语言模型进行语义接地，使用Grounded-SAM在新场景中定位框架。

Result: 在仿真中验证了TReF-6的有效性，对轨迹噪声具有鲁棒性。在真实世界操作任务中展示了端到端管道，支持一次性模仿学习并在不同物体配置中保持任务意图。

Conclusion: TReF-6提供了一种可解释的空间表示方法，能够从单次演示中提取任务相关框架，实现功能一致的技能泛化，为机器人模仿学习提供了有效的解决方案。

Abstract: Robots often struggle to generalize from a single demonstration due to the
lack of a transferable and interpretable spatial representation. In this work,
we introduce TReF-6, a method that infers a simplified, abstracted 6DoF
Task-Relevant Frame from a single trajectory. Our approach identifies an
influence point purely from the trajectory geometry to define the origin for a
local frame, which serves as a reference for parameterizing a Dynamic Movement
Primitive (DMP). This influence point captures the task's spatial structure,
extending the standard DMP formulation beyond start-goal imitation. The
inferred frame is semantically grounded via a vision-language model and
localized in novel scenes by Grounded-SAM, enabling functionally consistent
skill generalization. We validate TReF-6 in simulation and demonstrate
robustness to trajectory noise. We further deploy an end-to-end pipeline on
real-world manipulation tasks, showing that TReF-6 supports one-shot imitation
learning that preserves task intent across diverse object configurations.

</details>


### [12] [A Framework for Task and Motion Planning based on Expanding AND/OR Graphs](https://arxiv.org/abs/2509.00317)
*Fulvio Mastrogiovanni,Antony Thomas*

Main category: cs.RO

TL;DR: 提出了基于扩展AND/OR图的TMP-EAOG框架，用于空间机器人任务与运动规划，具有鲁棒性、可控自主性和有界灵活性


<details>
  <summary>Details</summary>
Motivation: 空间环境中机器人自主性面临感知和运动不确定性、严格运动学约束以及有限人工干预机会等独特挑战，需要任务与运动规划(TMP)来支持自主服务任务

Method: TMP-EAOG框架在AND/OR图中编码任务级抽象，迭代扩展图结构，并在循环中执行运动规划可行性评估

Result: 在模拟移动机械臂上的评估表明，TMP-EAOG能够处理基准测试中的各种挑战，展现出对不确定性的鲁棒性和灵活性

Conclusion: TMP-EAOG框架为空间自主机器人提供了有效的任务与运动规划解决方案，具备适应不同场景的能力和良好性能

Abstract: Robot autonomy in space environments presents unique challenges, including
high perception and motion uncertainty, strict kinematic constraints, and
limited opportunities for human intervention. Therefore, Task and Motion
Planning (TMP) may be critical for autonomous servicing, surface operations, or
even in-orbit missions, just to name a few, as it models tasks as discrete
action sequencing integrated with continuous motion feasibility assessments. In
this paper, we introduce a TMP framework based on expanding AND/OR graphs,
referred to as TMP-EAOG, and demonstrate its adaptability to different
scenarios. TMP-EAOG encodes task-level abstractions within an AND/OR graph,
which expands iteratively as the plan is executed, and performs in-the-loop
motion planning assessments to ascertain their feasibility. As a consequence,
TMP-EAOG is characterised by the desirable properties of (i) robustness to a
certain degree of uncertainty, because AND/OR graph expansion can accommodate
for unpredictable information about the robot environment, (ii) controlled
autonomy, since an AND/OR graph can be validated by human experts, and (iii)
bounded flexibility, in that unexpected events, including the assessment of
unfeasible motions, can lead to different courses of action as alternative
paths in the AND/OR graph. We evaluate TMP-EAOG on two benchmark domains. We
use a simulated mobile manipulator as a proxy for space-grade autonomous
robots. Our evaluation shows that TMP-EAOG can deal with a wide range of
challenges in the benchmarks.

</details>


### [13] [Contact-Aided Navigation of Flexible Robotic Endoscope Using Deep Reinforcement Learning in Dynamic Stomach](https://arxiv.org/abs/2509.00319)
*Chi Kit Ng,Huxin Gao,Tian-Ao Ren,Jiewen Lai,Hongliang Ren*

Main category: cs.RO

TL;DR: 基于深度强化学习的接触辅助导航策略，利用接触力反馈提升柔性内窥镜在动态胃环境中的导航精度和稳定性，在仿真环境中实现100%成功率。


<details>
  <summary>Details</summary>
Motivation: 柔性内窥镜在动态胃环境中导航具有挑战性，需要有效利用与可变形胃壁的接触来达到目标位置，传统方法难以处理这种复杂交互。

Method: 采用深度强化学习（DRL）和近端策略优化（PPO）算法，基于物理有限元法（FEM）仿真建立可变形胃环境，利用接触力反馈进行训练。

Result: 在静态和动态胃环境中实现100%导航成功率（平均误差1.6mm），在具有更强外部干扰的未见场景中保持85%成功率，显著优于基线策略。

Conclusion: 基于DRL的接触辅助导航策略显著提升了柔性内窥镜的导航性能，验证了该方法在复杂动态环境中的有效性和鲁棒性。

Abstract: Navigating a flexible robotic endoscope (FRE) through the gastrointestinal
tract is critical for surgical diagnosis and treatment. However, navigation in
the dynamic stomach is particularly challenging because the FRE must learn to
effectively use contact with the deformable stomach walls to reach target
locations. To address this, we introduce a deep reinforcement learning (DRL)
based Contact-Aided Navigation (CAN) strategy for FREs, leveraging contact
force feedback to enhance motion stability and navigation precision. The
training environment is established using a physics-based finite element method
(FEM) simulation of a deformable stomach. Trained with the Proximal Policy
Optimization (PPO) algorithm, our approach achieves high navigation success
rates (within 3 mm error between the FRE's end-effector and target) and
significantly outperforms baseline policies. In both static and dynamic stomach
environments, the CAN agent achieved a 100% success rate with 1.6 mm average
error, and it maintained an 85% success rate in challenging unseen scenarios
with stronger external disturbances. These results validate that the DRL-based
CAN strategy substantially enhances FRE navigation performance over prior
methods.

</details>


### [14] [Mechanistic interpretability for steering vision-language-action models](https://arxiv.org/abs/2509.00328)
*Bear Häon,Kaylene Stocking,Ian Chuang,Claire Tomlin*

Main category: cs.RO

TL;DR: 提出了首个通过内部表示解释和引导视觉-语言-动作模型的框架，能够在推理时直接干预模型行为，实现零样本行为控制


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型缺乏机械性洞察，难以在需要鲁棒性和可解释性的真实机器人部署中使用，而大语言模型的机械可解释性进展为此提供了启发

Method: 将transformer层的前馈激活投影到token嵌入基上，识别稀疏语义方向（如速度和方向），并开发通用的激活引导方法实时调节行为

Result: 在Pi0和OpenVLA两个开源VLA模型上验证，在仿真环境(LIBERO)和物理机器人(UR5)上实现了零样本行为控制

Conclusion: 这项工作证明可解释的VLA组件可被系统性地用于控制，为机器人领域建立透明和可引导的基础模型新范式

Abstract: Vision-Language-Action (VLA) models are a promising path to realizing
generalist embodied agents that can quickly adapt to new tasks, modalities, and
environments. However, methods for interpreting and steering VLAs fall far
short of classical robotics pipelines, which are grounded in explicit models of
kinematics, dynamics, and control. This lack of mechanistic insight is a
central challenge for deploying learned policies in real-world robotics, where
robustness and explainability are critical. Motivated by advances in
mechanistic interpretability for large language models, we introduce the first
framework for interpreting and steering VLAs via their internal
representations, enabling direct intervention in model behavior at inference
time. We project feedforward activations within transformer layers onto the
token embedding basis, identifying sparse semantic directions - such as speed
and direction - that are causally linked to action selection. Leveraging these
findings, we introduce a general-purpose activation steering method that
modulates behavior in real time, without fine-tuning, reward signals, or
environment interaction. We evaluate this method on two recent open-source
VLAs, Pi0 and OpenVLA, and demonstrate zero-shot behavioral control in
simulation (LIBERO) and on a physical robot (UR5). This work demonstrates that
interpretable components of embodied VLAs can be systematically harnessed for
control - establishing a new paradigm for transparent and steerable foundation
models in robotics.

</details>


### [15] [Jacobian Exploratory Dual-Phase Reinforcement Learning for Dynamic Endoluminal Navigation of Deformable Continuum Robots](https://arxiv.org/abs/2509.00329)
*Yu Tian,Chi Kit Ng,Hongliang Ren*

Main category: cs.RO

TL;DR: JEDP-RL框架通过分阶段雅可比估计和策略执行，解决了可变形连续体机器人的规划挑战，在收敛速度、导航效率和泛化能力方面显著优于PPO基线方法。


<details>
  <summary>Details</summary>
Motivation: 可变形连续体机器人(DCRs)由于非线性变形力学和部分状态可观测性，违反了传统强化学习方法的马尔可夫假设，而基于雅可比的方法在DCRs上的直接应用受到时变运动学和欠驱动变形动力学的限制。

Method: 提出Jacobian Exploratory Dual-Phase RL (JEDP-RL)框架，将规划分解为分阶段的雅可比估计和策略执行：首先执行小规模局部探索动作估计变形雅可比矩阵，然后用雅可比特征增强状态表示以恢复近似马尔可夫性。

Result: 在SOFA外科动态仿真中，JEDP-RL相比PPO基线表现出三大优势：1)收敛速度快3.2倍；2)导航效率提高25%（到达目标所需步数减少25%）；3)泛化能力强（材料属性变化下达到92%成功率，在未见组织环境中达到83%成功率，比PPO高33%）。

Conclusion: JEDP-RL框架通过整合局部探索和雅可比特征增强，有效解决了DCRs规划中的非马尔可夫挑战，在仿真环境中展现出优异的性能表现和泛化能力。

Abstract: Deformable continuum robots (DCRs) present unique planning challenges due to
nonlinear deformation mechanics and partial state observability, violating the
Markov assumptions of conventional reinforcement learning (RL) methods. While
Jacobian-based approaches offer theoretical foundations for rigid manipulators,
their direct application to DCRs remains limited by time-varying kinematics and
underactuated deformation dynamics. This paper proposes Jacobian Exploratory
Dual-Phase RL (JEDP-RL), a framework that decomposes planning into phased
Jacobian estimation and policy execution. During each training step, we first
perform small-scale local exploratory actions to estimate the deformation
Jacobian matrix, then augment the state representation with Jacobian features
to restore approximate Markovianity. Extensive SOFA surgical dynamic
simulations demonstrate JEDP-RL's three key advantages over proximal policy
optimization (PPO) baselines: 1) Convergence speed: 3.2x faster policy
convergence, 2) Navigation efficiency: requires 25% fewer steps to reach the
target, and 3) Generalization ability: achieve 92% success rate under material
property variations and achieve 83% (33% higher than PPO) success rate in the
unseen tissue environment.

</details>


### [16] [Autonomous Aggregate Sorting in Construction and Mining via Computer Vision-Aided Robotic Arm Systems](https://arxiv.org/abs/2509.00339)
*Md. Taherul Islam Shawon,Yuan Li,Yincai Cai,Junjie Niu,Ting Peng*

Main category: cs.RO

TL;DR: 这篇论文提出了一种基于计算机视觉和机器人手臂的智能矿物分类系统，解决了传统分类方法的精度低、灵活性差和适应性差等问题，实验验证了高达97.5%的成功率。


<details>
  <summary>Details</summary>
Motivation: 传统矿物分类方法（手工或机械）存在精度低、灵活性差、对不同材料特性（大小、形状、岩性等）适应性差等问题，需要一种更有效的解决方案。

Method: 系统集成了六自由度机器人手臂、双目立体摄像头进行3D感知、基于ROS的控制框架。核心技术包括关注增强YOLOv8模型进行检测、立体匹配进行3D定位、Denavit-Hartenberg运动学模型控制手臂运动、最小外接矩形分析估计大小、手眼检定确保坐标系对齐精度。

Result: 对四种矿物进行实验验证，平均抓取和分类成功率达到97.5%，分类准确性相当。仍存在小型矿物处理和纹理基础错误分类的挑战。

Conclusion: 该系统显示出在提高生产效率、降低运营成本、改善安全性方面的巨大潜力，为建筑、矿业和回收行业的智能自动化提供了可扩展的框架。

Abstract: Traditional aggregate sorting methods, whether manual or mechanical, often
suffer from low precision, limited flexibility, and poor adaptability to
diverse material properties such as size, shape, and lithology. To address
these limitations, this study presents a computer vision-aided robotic arm
system designed for autonomous aggregate sorting in construction and mining
applications. The system integrates a six-degree-of-freedom robotic arm, a
binocular stereo camera for 3D perception, and a ROS-based control framework.
Core techniques include an attention-augmented YOLOv8 model for aggregate
detection, stereo matching for 3D localization, Denavit-Hartenberg kinematic
modeling for arm motion control, minimum enclosing rectangle analysis for size
estimation, and hand-eye calibration for precise coordinate alignment.
Experimental validation with four aggregate types achieved an average grasping
and sorting success rate of 97.5%, with comparable classification accuracy.
Remaining challenges include the reliable handling of small aggregates and
texture-based misclassification. Overall, the proposed system demonstrates
significant potential to enhance productivity, reduce operational costs, and
improve safety in aggregate handling, while providing a scalable framework for
advancing smart automation in construction, mining, and recycling industries.

</details>


### [17] [Generative Visual Foresight Meets Task-Agnostic Pose Estimation in Robotic Table-Top Manipulation](https://arxiv.org/abs/2509.00361)
*Chuye Zhang,Xiaoxiong Zhang,Wei Pan,Linfang Zheng,Wei Zhang*

Main category: cs.RO

TL;DR: GVF-TAPE是一个结合生成视觉预测和任务无关位姿估计的闭环框架，通过单视角RGB图像和任务描述预测未来RGB-D帧，实现可扩展的机器人操作


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中的机器人操作需要能够泛化到多样化任务并保持鲁棒性能的系统，现有方法对任务特定动作数据的依赖限制了可扩展性

Method: 使用生成视频模型从单视角RGB图像和任务描述预测未来RGB-D帧，通过解耦的位姿估计模型从预测帧中提取末端执行器位姿，通过低级控制器转换为可执行命令，在闭环中迭代集成视频预测和位姿估计

Result: 在仿真和真实环境的大量实验表明，该方法减少了对任务特定动作数据的依赖，能够有效泛化，为智能机器人系统提供了实用且可扩展的解决方案

Conclusion: GVF-TAPE框架通过结合生成视觉预测和任务无关位姿估计，实现了实时自适应的机器人操作，为可扩展的智能机器人系统提供了有效解决方案

Abstract: Robotic manipulation in unstructured environments requires systems that can
generalize across diverse tasks while maintaining robust and reliable
performance. We introduce {GVF-TAPE}, a closed-loop framework that combines
generative visual foresight with task-agnostic pose estimation to enable
scalable robotic manipulation. GVF-TAPE employs a generative video model to
predict future RGB-D frames from a single side-view RGB image and a task
description, offering visual plans that guide robot actions. A decoupled pose
estimation model then extracts end-effector poses from the predicted frames,
translating them into executable commands via low-level controllers. By
iteratively integrating video foresight and pose estimation in a closed loop,
GVF-TAPE achieves real-time, adaptive manipulation across a broad range of
tasks. Extensive experiments in both simulation and real-world settings
demonstrate that our approach reduces reliance on task-specific action data and
generalizes effectively, providing a practical and scalable solution for
intelligent robotic systems.

</details>


### [18] [Embodied Spatial Intelligence: from Implicit Scene Modeling to Spatial Reasoning](https://arxiv.org/abs/2509.00465)
*Jiading Fang*

Main category: cs.RO

TL;DR: 这篇论文提出"体验式空间智能"概念，通过隐式神经场景表征和增强大语言模型的空间推理能力，解决机器人根据自然语言指令识别和操作环境的挑战。


<details>
  <summary>Details</summary>
Motivation: 克服大语言模型与物理体验之间的差距，创建能够根据自然语言指令在现实世界中感知和行动的机器人。

Method: 在感知方面使用隐式神经模型建立健壮、可扩展、准确的场景表征，包括自监督相机标定、高保真深度场生成和大规模重建。在空间推理方面通过引入新导航基准、语言在3D环境中的基础化方法以及状态反馈机制来增强大语言模型的空间能力。

Result: 为机器人提供了能够健壮感知周围环境并智能地执行复杂语言命令的基础框架。

Conclusion: 该研究为实现根据自然语言指令进行环境感知和行动的机器人系统奠定了重要基础。

Abstract: This thesis introduces "Embodied Spatial Intelligence" to address the
challenge of creating robots that can perceive and act in the real world based
on natural language instructions. To bridge the gap between Large Language
Models (LLMs) and physical embodiment, we present contributions on two fronts:
scene representation and spatial reasoning. For perception, we develop robust,
scalable, and accurate scene representations using implicit neural models, with
contributions in self-supervised camera calibration, high-fidelity depth field
generation, and large-scale reconstruction. For spatial reasoning, we enhance
the spatial capabilities of LLMs by introducing a novel navigation benchmark, a
method for grounding language in 3D, and a state-feedback mechanism to improve
long-horizon decision-making. This work lays a foundation for robots that can
robustly perceive their surroundings and intelligently act upon complex,
language-based commands.

</details>


### [19] [Extended Diffeomorphism for Real-Time Motion Replication in Workspaces with Different Spatial Arrangements](https://arxiv.org/abs/2509.00491)
*Masaki Saito,Shunki Itadera,Toshiyuki Murakami*

Main category: cs.RO

TL;DR: 提出两种扩展微分同胚设计来补偿机器人工作空间之间的空间位置差异，实现多机器人遥操作中的平滑运动映射


<details>
  <summary>Details</summary>
Motivation: 多机器人遥操作需要实时复制机器人运动以高效执行相似任务，但面临机器人工作空间中目标关键点空间排列误差的补偿挑战

Method: 基于预定义关键点的平滑映射方法，将主机器人姿态转换为跟随机器人姿态，通过扩展微分同胚设计实现空间变换

Result: 双UR5机械臂拾取任务实验表明，该方法能够在精确操作的低映射误差和平滑复制的低映射梯度之间取得平衡

Conclusion: 提出的映射生成方法有效解决了多机器人工作空间差异补偿问题，实现了精确且平滑的运动复制

Abstract: This paper presents two types of extended diffeomorphism designs to
compensate for spatial placement differences between robot workspaces.
Teleoperation of multiple robots is attracting attention to expand the
utilization of the robot embodiment. Real-time reproduction of robot motion
would facilitate the efficient execution of similar tasks by multiple robots. A
challenge in the motion reproduction is compensating for the spatial
arrangement errors of target keypoints in robot workspaces. This paper proposes
a methodology for smooth mappings that transform primary robot poses into
follower robot poses based on the predefined key points in each workspace.
Through a picking task experiment using a dual-arm UR5 robot, this study
demonstrates that the proposed mapping generation method can balance lower
mapping errors for precise operation and lower mapping gradients for smooth
replicated movement.

</details>


### [20] [FLUID: A Fine-Grained Lightweight Urban Signalized-Intersection Dataset of Dense Conflict Trajectories](https://arxiv.org/abs/2509.00497)
*Yiyang Chen,Zhigang Wu,Guohong Zheng,Xuesong Wu,Liwen Xu,Haoyuan Tang,Zhaocheng He,Haipeng Zeng*

Main category: cs.RO

TL;DR: FLUID是一个基于无人机采集的精细化交通轨迹数据集，包含三种典型城市信号交叉口的高密度冲突数据，提供超过20,000个交通参与者的轨迹、信号灯、地图和原始视频数据。


<details>
  <summary>Details</summary>
Motivation: 现有交通轨迹数据集在场景代表性、信息丰富度和数据保真度方面存在局限，需要更全面的数据集来支持交通状况评估和政策优化。

Method: 使用无人机采集数据，开发轻量级全流程框架处理轨迹数据，涵盖三种不同类型交叉口，记录约5小时数据，包含8类交通参与者。

Result: 数据集平均每分钟发生两次车辆冲突，涉及约25%的机动车辆，与DataFromSky平台和地面真值测量相比具有高时空精度。

Conclusion: FLUID数据集通过详细的机动车辆冲突和违规分类，揭示了多样化的交互行为，对人类偏好挖掘、交通行为建模和自动驾驶研究具有重要价值。

Abstract: The trajectory data of traffic participants (TPs) is a fundamental resource
for evaluating traffic conditions and optimizing policies, especially at urban
intersections. Although data acquisition using drones is efficient, existing
datasets still have limitations in scene representativeness, information
richness, and data fidelity. This study introduces FLUID, comprising a
fine-grained trajectory dataset that captures dense conflicts at typical urban
signalized intersections, and a lightweight, full-pipeline framework for
drone-based trajectory processing. FLUID covers three distinct intersection
types, with approximately 5 hours of recording time and featuring over 20,000
TPs across 8 categories. Notably, the dataset averages two vehicle conflicts
per minute, involving roughly 25% of all motor vehicles. FLUID provides
comprehensive data, including trajectories, traffic signals, maps, and raw
videos. Comparison with the DataFromSky platform and ground-truth measurements
validates its high spatio-temporal accuracy. Through a detailed classification
of motor vehicle conflicts and violations, FLUID reveals a diversity of
interactive behaviors, demonstrating its value for human preference mining,
traffic behavior modeling, and autonomous driving research.

</details>


### [21] [NeuralSVCD for Efficient Swept Volume Collision Detection](https://arxiv.org/abs/2509.00499)
*Dongwon Son,Hojin Jung,Beomjoon Kim*

Main category: cs.RO

TL;DR: 提出NeuralSVCD神经网络架构，解决机器人运动规划中扫掠体积碰撞检测在效率和精度之间的权衡问题


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中的机器人操作需要高效可靠的扫掠体积碰撞检测，传统离散方法可能遗漏碰撞点，现有方法在效率和精度之间存在权衡限制

Method: 采用神经编码器-解码器架构，通过分布式几何表示和时间优化来利用形状局部性和时间局部性

Result: 综合实验表明NeuralSVCD在碰撞检测精度和计算效率方面均优于现有最先进方法

Conclusion: 该方法在不牺牲精度的情况下提高了计算效率，在多样化机器人操作场景中展现出强大的适用性

Abstract: Robot manipulation in unstructured environments requires efficient and
reliable Swept Volume Collision Detection (SVCD) for safe motion planning.
Traditional discrete methods potentially miss collisions between these points,
whereas SVCD continuously checks for collisions along the entire trajectory.
Existing SVCD methods typically face a trade-off between efficiency and
accuracy, limiting practical use. In this paper, we introduce NeuralSVCD, a
novel neural encoder-decoder architecture tailored to overcome this trade-off.
Our approach leverages shape locality and temporal locality through distributed
geometric representations and temporal optimization. This enhances
computational efficiency without sacrificing accuracy. Comprehensive
experiments show that NeuralSVCD consistently outperforms existing
state-of-the-art SVCD methods in terms of both collision detection accuracy and
computational efficiency, demonstrating its robust applicability across diverse
robotic manipulation scenarios. Code and videos are available at
https://neuralsvcd.github.io/.

</details>


### [22] [Needle Biopsy And Fiber-Optic Compatible Robotic Insertion Platform](https://arxiv.org/abs/2509.00530)
*Fanxin Wang,Yikun Cheng,Chuyuan Tao,Rohit Bhargava,Thenkurussi Kesavadas*

Main category: cs.RO

TL;DR: 这篇论文提出了一种细小、准确、可机动的机器人插入平台，用于改善传统组织检查的限制，支持多种工具的精确导航和插入。


<details>
  <summary>Details</summary>
Motivation: 传统组织检查存在两个主要问题：手工取样准确性低，以及病理检查耗时较长。需要一种更准确、高效的方法来改善疾病诊断。

Method: 设计了一种细小、准确、可机动的机器人插入平台，能够控制各种不同尺寸的工具（如钉头和光导纤），通过机械设计和控制策略实现精确导航和插入。

Result: 通过一系列测试验证了系统的性能，包括定位精度、宽度性能和工具插入效果，证明了该平台的可靠性和有效性。

Conclusion: 该机器人插入平台能够有效克服传统组织检查的限制，提高了取样的准确性和效率，为多模态诊断提供了新的技术支持。

Abstract: Tissue biopsy is the gold standard for diagnosing many diseases, involving
the extraction of diseased tissue for histopathology analysis by expert
pathologists. However, this procedure has two main limitations: 1) Manual
sampling through tissue biopsy is prone to inaccuracies; 2) The extraction
process is followed by a time-consuming pathology test. To address these
limitations, we present a compact, accurate, and maneuverable robotic insertion
platform to overcome the limitations in traditional histopathology. Our
platform is capable of steering a variety of tools with different sizes,
including needle for tissue extraction and optical fibers for vibrational
spectroscopy applications. This system facilitates the guidance of end-effector
to the tissue and assists surgeons in navigating to the biopsy target area for
multi-modal diagnosis. In this paper, we outline the general concept of our
device, followed by a detailed description of its mechanical design and control
scheme. We conclude with the validation of the system through a series of
tests, including positioning accuracy, admittance performance, and tool
insertion efficacy.

</details>


### [23] [Reinforcement Learning of Dolly-In Filming Using a Ground-Based Robot](https://arxiv.org/abs/2509.00564)
*Philip Lorimer,Jack Saunders,Alan Hunter,Wenbin Li*

Main category: cs.RO

TL;DR: 采用强化学习自动化控制自由移动拍摄机棱车进行拍摄运动，经测试表明效果超过传统控制方法


<details>
  <summary>Details</summary>
Motivation: 解决自由移动拍摄机棱车在自动化摄像控制方面的挑战，提升电影制作中的动态运动拍摄能力

Method: 应用强化学习(RL)算法，对比结合控制和独立控制策略，在修改的ROSBot 2.0平台上进行真实世界测试

Result: RL流水线在模拟和真实环境中都超越了传统比例-微分控制器的性能，验证了方法的实用性

Conclusion: 该研究为复杂拍摄场景的进一步研究奠定了基础，有效绑定了技术进步与创意电影制作之间的差距

Abstract: Free-roaming dollies enhance filmmaking with dynamic movement, but challenges
in automated camera control remain unresolved. Our study advances this field by
applying Reinforcement Learning (RL) to automate dolly-in shots using
free-roaming ground-based filming robots, overcoming traditional control
hurdles. We demonstrate the effectiveness of combined control for precise film
tasks by comparing it to independent control strategies. Our robust RL pipeline
surpasses traditional Proportional-Derivative controller performance in
simulation and proves its efficacy in real-world tests on a modified ROSBot 2.0
platform equipped with a camera turret. This validates our approach's
practicality and sets the stage for further research in complex filming
scenarios, contributing significantly to the fusion of technology with
cinematic creativity. This work presents a leap forward in the field and opens
new avenues for research and development, effectively bridging the gap between
technological advancement and creative filmmaking.

</details>


### [24] [ConceptBot: Enhancing Robot's Autonomy through Task Decomposition with Large Language Models and Knowledge Graph](https://arxiv.org/abs/2509.00570)
*Alessandro Leanza,Angelo Moroncelli,Giuseppe Vizzari,Francesco Braghin,Loris Roveda,Blerina Spahiu*

Main category: cs.RO

TL;DR: ConceptBot是一个结合大型语言模型和知识图谱的模块化机器人规划框架，能够处理自然语言指令的模糊性并生成可行且风险感知的计划，在多项任务中显著优于Google SayCan基准。


<details>
  <summary>Details</summary>
Motivation: 解决自然语言指令中的模糊性和缺乏常识推理导致的机器人规划问题，提高在非结构化环境中的可靠性和安全性。

Method: 采用模块化设计：1)对象属性提取模块(OPE)利用ConceptNet丰富场景理解；2)用户请求处理模块(URP)消歧和结构化指令；3)规划器生成上下文感知的抓放策略。

Result: 在显式任务上达到100%成功率，隐式任务87%准确率(对比SayCan的31%)，风险感知任务76%(对比15%)，材料分类70%(对比20%)，毒性检测86%(对比36%)，SafeAgentBench总体得分80%(对比次优基准46%)。

Conclusion: ConceptBot无需领域特定训练即可泛化，显著提高了非结构化环境中机器人策略的可靠性，验证了结合语言模型和知识图谱的有效性。

Abstract: ConceptBot is a modular robotic planning framework that combines Large
Language Models and Knowledge Graphs to generate feasible and risk-aware plans
despite ambiguities in natural language instructions and correctly analyzing
the objects present in the environment - challenges that typically arise from a
lack of commonsense reasoning. To do that, ConceptBot integrates (i) an Object
Property Extraction (OPE) module that enriches scene understanding with
semantic concepts from ConceptNet, (ii) a User Request Processing (URP) module
that disambiguates and structures instructions, and (iii) a Planner that
generates context-aware, feasible pick-and-place policies. In comparative
evaluations against Google SayCan, ConceptBot achieved 100% success on explicit
tasks, maintained 87% accuracy on implicit tasks (versus 31% for SayCan),
reached 76% on risk-aware tasks (versus 15%), and outperformed SayCan in
application-specific scenarios, including material classification (70% vs. 20%)
and toxicity detection (86% vs. 36%). On SafeAgentBench, ConceptBot achieved an
overall score of 80% (versus 46% for the next-best baseline). These results,
validated in both simulation and laboratory experiments, demonstrate
ConceptBot's ability to generalize without domain-specific training and to
significantly improve the reliability of robotic policies in unstructured
environments. Website: https://sites.google.com/view/conceptbot

</details>


### [25] [Gray-Box Computed Torque Control for Differential-Drive Mobile Robot Tracking](https://arxiv.org/abs/2509.00571)
*Arman Javan Sekhavat Pishkhani*

Main category: cs.RO

TL;DR: 提出一种基于学习的非线性跟踪控制算法，将深度强化学习的黑盒策略网络替换为灰盒计算力矩控制器，提高样本效率并确保闭环稳定性


<details>
  <summary>Details</summary>
Motivation: 计算力矩方法(CTM)存在系统参数不准确的缺陷，而深度强化学习(DRL)算法样本效率低且稳定性保证弱，需要结合两者优势

Method: 使用TD3算法寻找最优控制器参数，约束参数在物理合理范围内，并强制临界阻尼闭环时间响应

Result: 在MuJoCo物理引擎中模拟差速移动机器人，与原始CTC和传统运动学控制器进行性能比较

Conclusion: 该方法仅需少量学习回合即可为任意奖励函数找到最优控制器参数集，提高了样本效率和稳定性

Abstract: This study presents a learning-based nonlinear algorithm for tracking control
of differential-drive mobile robots. The Computed Torque Method (CTM) suffers
from inaccurate knowledge of system parameters, while Deep Reinforcement
Learning (DRL) algorithms are known for sample inefficiency and weak stability
guarantees. The proposed method replaces the black-box policy network of a DRL
agent with a gray-box Computed Torque Controller (CTC) to improve sample
efficiency and ensure closed-loop stability. This approach enables finding an
optimal set of controller parameters for an arbitrary reward function using
only a few short learning episodes. The Twin-Delayed Deep Deterministic Policy
Gradient (TD3) algorithm is used for this purpose. Additionally, some
controller parameters are constrained to lie within known value ranges,
ensuring the RL agent learns physically plausible values. A technique is also
applied to enforce a critically damped closed-loop time response. The
controller's performance is evaluated on a differential-drive mobile robot
simulated in the MuJoCo physics engine and compared against the raw CTC and a
conventional kinematic controller.

</details>


### [26] [Learning Dolly-In Filming From Demonstration Using a Ground-Based Robot](https://arxiv.org/abs/2509.00574)
*Philip Lorimer,Alan Hunter,Wenbin Li*

Main category: cs.RO

TL;DR: 通过使用生成对抗仿生学习(GAIL)的示范学习方法，自动化电影摄像机控制，实现了不依赖手工奖励函数的精准艺术化摄像运动控制。


<details>
  <summary>Details</summary>
Motivation: 电影摄像控制需要精确性和艺术性的平衡，但手工设计奖励函数困难且限制创造性。强化学习方法依赖于豪华的奖励设计和调参，影响了实际创作使用。

Method: 采用生成对抗仿生学习(GAIL)方法，通过模拟环境中手控道具收集专家示范轨迹，学习流畅表达性的运动控制。与PPO基线方法进行对比。

Result: 在模拟中超越PPO基线，获得更高奖励、更快收敛和更低方差。无需微调直接迁移到实际机器人，在取景构图和主体对齐方面比之前的TD3方法更一致。

Conclusion: 示范学习提供了一种健壮、无需奖励函数的替代方案，能够在实时部署中以最小技术苦工实现艺术化摄像控制，缩小了艺术意图与机器人自主性之间的差距。

Abstract: Cinematic camera control demands a balance of precision and artistry -
qualities that are difficult to encode through handcrafted reward functions.
While reinforcement learning (RL) has been applied to robotic filmmaking, its
reliance on bespoke rewards and extensive tuning limits creative usability. We
propose a Learning from Demonstration (LfD) approach using Generative
Adversarial Imitation Learning (GAIL) to automate dolly-in shots with a
free-roaming, ground-based filming robot. Expert trajectories are collected via
joystick teleoperation in simulation, capturing smooth, expressive motion
without explicit objective design.
  Trained exclusively on these demonstrations, our GAIL policy outperforms a
PPO baseline in simulation, achieving higher rewards, faster convergence, and
lower variance. Crucially, it transfers directly to a real-world robot without
fine-tuning, achieving more consistent framing and subject alignment than a
prior TD3-based method. These results show that LfD offers a robust,
reward-free alternative to RL in cinematic domains, enabling real-time
deployment with minimal technical effort. Our pipeline brings intuitive,
stylized camera control within reach of creative professionals, bridging the
gap between artistic intent and robotic autonomy.

</details>


### [27] [Galaxea Open-World Dataset and G0 Dual-System VLA Model](https://arxiv.org/abs/2509.00576)
*Tao Jiang,Tianyuan Yuan,Yicheng Liu,Chenhao Lu,Jianning Cui,Xiao Liu,Shuiqi Cheng,Jiyang Gao,Huazhe Xu,Hang Zhao*

Main category: cs.RO

TL;DR: 提出了Galaxea开放世界数据集和G0双系统框架，通过三阶段课程学习在真实环境中实现机器人行为学习，在多项任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人在真实人类生活和工作环境中执行复杂任务的需求，需要大规模、多样化的数据集和有效的学习框架。

Method: 构建Galaxea开放世界数据集，包含精确的子任务级语言标注；提出G0双系统框架，结合VLM进行多模态规划和VLA进行细粒度执行；采用三阶段课程学习：跨本体预训练、单本体预训练和任务特定后训练。

Result: 在桌面操作、少样本学习和长时程移动操作等综合基准测试中表现出有效性，特别是单本体预训练阶段与Galaxea数据集对实现强劲性能起到关键作用。

Conclusion: Galaxea数据集和G0框架为机器人在真实环境中的行为学习提供了有效解决方案，三阶段训练方法特别是单本体预训练对性能提升至关重要。

Abstract: We present Galaxea Open-World Dataset, a large-scale, diverse collection of
robot behaviors recorded in authentic human living and working environments.
All demonstrations are gathered using a consistent robotic embodiment, paired
with precise subtask-level language annotations to facilitate both training and
evaluation. Building on this dataset, we introduce G0, a dual-system framework
that couples a Vision-Language Model (VLM) for multimodal planning with a
Vision-Language-Action (VLA) model for fine-grained execution. G0 is trained
using a three-stage curriculum: cross-embodiment pre-training,
single-embodiment pre-training, and task-specific post-training. A
comprehensive benchmark spanning tabletop manipulation, few-shot learning, and
long-horizon mobile manipulation, demonstrates the effectiveness of our
approach. In particular, we find that the single-embodiment pre-training stage,
together with the Galaxea Open-World Dataset, plays a critical role in
achieving strong performance.

</details>


### [28] [Safe and Efficient Lane-Changing for Autonomous Vehicles: An Improved Double Quintic Polynomial Approach with Time-to-Collision Evaluation](https://arxiv.org/abs/2509.00582)
*Rui Bai,Rui Xu,Teng Rui,Jiale Liu,Qi Wei Oung,Hoi Leong Lee,Zhen Tian,Fujiang Yuan*

Main category: cs.RO

TL;DR: 提出一种改进的双五次多项式方法，通过将TTC碰撞时间评估直接集成到轨迹优化中，实现混合交通环境下的安全高效车道变换


<details>
  <summary>Details</summary>
Motivation: 自动驾驶在与人类驾驶车辆交互时，特别是在车道变换场景中，仍面临安全和舒适性的挑战，需要更有效的轨迹规划方法

Method: 采用双五次多项式轨迹生成，结合实时TTC计算和自适应轨迹评估，将解析TTC惩罚直接嵌入闭式双五次多项式求解器

Result: 在多种交通场景下的仿真表明，该方法相比传统方法（五次多项式、贝塞尔曲线、B样条）在安全性、效率和舒适性方面表现更优

Conclusion: 该方法填补了基于模型和自适应轨迹规划方法之间的空白，为实际自动驾驶应用提供了稳定的解决方案

Abstract: Autonomous driving technology has made significant advancements in recent
years, yet challenges remain in ensuring safe and comfortable interactions with
human-driven vehicles (HDVs), particularly during lane-changing maneuvers. This
paper proposes an improved double quintic polynomial approach for safe and
efficient lane-changing in mixed traffic environments. The proposed method
integrates a time-to-collision (TTC) based evaluation mechanism directly into
the trajectory optimization process, ensuring that the ego vehicle proactively
maintains a safe gap from surrounding HDVs throughout the maneuver. The
framework comprises state estimation for both the autonomous vehicle (AV) and
HDVs, trajectory generation using double quintic polynomials, real-time TTC
computation, and adaptive trajectory evaluation. To the best of our knowledge,
this is the first work to embed an analytic TTC penalty directly into the
closed-form double-quintic polynomial solver, enabling real-time safety-aware
trajectory generation without post-hoc validation. Extensive simulations
conducted under diverse traffic scenarios demonstrate the safety, efficiency,
and comfort of the proposed approach compared to conventional methods such as
quintic polynomials, Bezier curves, and B-splines. The results highlight that
the improved method not only avoids collisions but also ensures smooth
transitions and adaptive decision-making in dynamic environments. This work
bridges the gap between model-based and adaptive trajectory planning
approaches, offering a stable solution for real-world autonomous driving
applications.

</details>


### [29] [Vehicle-in-Virtual-Environment (VVE) Method for Developing and Evaluating VRU Safety of Connected and Autonomous Driving with Focus on Bicyclist Safety](https://arxiv.org/abs/2509.00624)
*Haochong Chen,Xincheng Cao,Bilin Aksun-Guvenc,Levent Guvenc*

Main category: cs.RO

TL;DR: 该项目应用VVE方法开发自动驾驶系统的安全功能，重点关注弱势道路使用者（特别是自行车骑行者）的安全，通过自动转向和制动技术来提升VRU保护


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶研究在统一规划避障系统、延迟容忍控制策略和标准化测试方法方面存在不足，VRU安全仍是自动驾驶在动态不可预测环境中的关键挑战

Method: 采用车辆在虚拟环境（VVE）方法，通过自动转向和制动技术来开发和评估ADS的安全功能

Result: 在第二年项目中重点提升了上一年成果，并特别考虑了自行车骑行者的安全

Conclusion: VVE方法为开发和完善自动驾驶系统的VRU安全功能提供了有效途径，特别是在自行车骑行者保护方面取得了进展

Abstract: Extensive research has already been conducted in the autonomous driving field
to help vehicles navigate safely and efficiently. At the same time, plenty of
current research on vulnerable road user (VRU) safety is performed which
largely concentrates on perception, localization, or trajectory prediction of
VRUs. However, existing research still exhibits several gaps, including the
lack of a unified planning and collision avoidance system for autonomous
vehicles, limited investigation into delay tolerant control strategies, and the
absence of an efficient and standardized testing methodology. Ensuring VRU
safety remains one of the most pressing challenges in autonomous driving,
particularly in dynamic and unpredictable environments. In this two year
project, we focused on applying the Vehicle in Virtual Environment (VVE) method
to develop, evaluate, and demonstrate safety functions for Vulnerable Road
Users (VRUs) using automated steering and braking of ADS. In this current
second year project report, our primary focus was on enhancing the previous
year results while also considering bicyclist safety.

</details>


### [30] [A Risk-aware Spatial-temporal Trajectory Planning Framework for Autonomous Vehicles Using QP-MPC and Dynamic Hazard Fields](https://arxiv.org/abs/2509.00643)
*Zhen Tian,Zhihao Lin,Dezong Zhao,Christos Anagnostopoulos,Qiyuan Wang,Wenjing Zhao,Xiaodan Wang,Chongfeng Wei*

Main category: cs.RO

TL;DR: 提出了一种基于QP-MPC的增强型轨迹规划框架，通过动态危险场(DHF)成本函数、时空安全规划和多目标集成，在动态环境中实现了更高效、稳定和舒适的自动驾驶轨迹规划。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹规划方法存在计算成本高、动态环境下性能不稳定、多样化场景验证有限等问题，需要开发更高效稳定的规划框架。

Method: 采用QP-MPC框架，集成动态危险场(DHF)进行风险评估，结合时空图进行时间安全规划，使用五次多项式采样和舒适度子奖励确保换道舒适性，通过效率子奖励保持驾驶效率。

Result: 大量仿真实验表明，该框架在换道、超车、交叉口通行等多种场景下，在效率、稳定性和舒适性方面均优于基准优化方法。

Conclusion: 提出的DHF增强QP-MPC框架有效解决了自动驾驶轨迹规划中的关键挑战，为动态环境下的安全高效规划提供了可靠解决方案。

Abstract: Trajectory planning is a critical component in ensuring the safety,
stability, and efficiency of autonomous vehicles. While existing trajectory
planning methods have achieved progress, they often suffer from high
computational costs, unstable performance in dynamic environments, and limited
validation across diverse scenarios. To overcome these challenges, we propose
an enhanced QP-MPC-based framework that incorporates three key innovations: (i)
a novel cost function designed with a dynamic hazard field, which explicitly
balances safety, efficiency, and comfort; (ii) seamless integration of this
cost function into the QP-MPC formulation, enabling direct optimization of
desired driving behaviors; and (iii) extensive validation of the proposed
framework across complex tasks. The spatial safe planning is guided by a
dynamic hazard field (DHF) for risk assessment, while temporal safe planning is
based on a space-time graph. Besides, the quintic polynomial sampling and
sub-reward of comforts are used to ensure comforts during lane-changing. The
sub-reward of efficiency is used to maintain driving efficiency. Finally, the
proposed DHF-enhanced objective function integrates multiple objectives,
providing a proper optimization tasks for QP-MPC. Extensive simulations
demonstrate that the proposed framework outperforms benchmark optimization
methods in terms of efficiency, stability, and comfort across a variety of
scenarios likes lane-changing, overtaking, and crossing intersections.

</details>


### [31] [CARIS: A Context-Adaptable Robot Interface System for Personalized and Scalable Human-Robot Interaction](https://arxiv.org/abs/2509.00660)
*Felipe Arias-Russi,Yuanchen Bai,Angelique Taylor*

Main category: cs.RO

TL;DR: 开发了一个名为CARIS的上下文自适应机器人接口系统，解决了传统Wizard-of-Oz工具在跨场景适应性方面的局限性，支持远程操作、人类感知、人机对话和多模态数据记录等功能。


<details>
  <summary>Details</summary>
Motivation: 传统Wizard-of-Oz控制的机器人工具通常局限于单一场景，难以适应不同的设置、用户和机器人平台，限制了人机交互研究的灵活性和可扩展性。

Method: 开发了CARIS系统，集成了远程操作、人类感知、人机对话和多模态数据记录等先进机器人能力，并通过在两个不同场景（心理健康伴侣和导游）中的试点研究进行验证。

Result: 试点研究表明CARIS在多种场景下具有潜力，同时识别了需要改进的领域，包括运动与通信的平滑集成、功能分离清晰度、推荐提示词和单键通信选项等。

Conclusion: CARIS为HRI研究社区提供了一个公开可用的上下文自适应工具，使研究人员能够更高效地采用数据驱动的方法来开发智能机器人行为。

Abstract: The human-robot interaction (HRI) field has traditionally used Wizard-of-Oz
(WoZ) controlled robots to explore navigation, conversational dynamics,
human-in-the-loop interactions, and more to explore appropriate robot behaviors
in everyday settings. However, existing WoZ tools are often limited to one
context, making them less adaptable across different settings, users, and
robotic platforms. To mitigate these issues, we introduce a Context-Adaptable
Robot Interface System (CARIS) that combines advanced robotic capabilities such
teleoperation, human perception, human-robot dialogue, and multimodal data
recording. Through pilot studies, we demonstrate the potential of CARIS to WoZ
control a robot in two contexts: 1) mental health companion and as a 2) tour
guide. Furthermore, we identified areas of improvement for CARIS, including
smoother integration between movement and communication, clearer functionality
separation, recommended prompts, and one-click communication options to enhance
the usability wizard control of CARIS. This project offers a publicly
available, context-adaptable tool for the HRI community, enabling researchers
to streamline data-driven approaches to intelligent robot behavior.

</details>


### [32] [DyPho-SLAM : Real-time Photorealistic SLAM in Dynamic Environments](https://arxiv.org/abs/2509.00741)
*Yi Liu,Keyu Fan,Bin Lan,Houde Liu*

Main category: cs.RO

TL;DR: DyPho-SLAM是一个实时高效的视觉SLAM系统，专门针对动态环境设计，通过集成先验图像信息生成精细化掩码，并采用自适应特征提取策略，在动态场景中实现了最先进的相机位姿估计和稠密地图重建性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉SLAM算法在静态环境中表现可靠，但在处理动态物体干扰时经常遇到相机跟踪漂移和模糊映射的问题，需要开发能够有效处理动态环境的SLAM系统。

Method: 系统集成先验图像信息生成精细化掩码以减少误判噪声，设计自适应特征提取策略增强去除动态障碍物后的优化约束，提高系统鲁棒性。

Result: 在公开动态RGB-D数据集上的实验表明，该系统在相机位姿估计和稠密地图重建方面达到了最先进的性能，同时能够在动态场景中实时运行。

Conclusion: DyPho-SLAM成功解决了动态环境中的SLAM挑战，通过创新的掩码生成和特征提取策略，实现了实时高效的动态场景定位和逼真地图重建。

Abstract: Visual SLAM algorithms have been enhanced through the exploration of Gaussian
Splatting representations, particularly in generating high-fidelity dense maps.
While existing methods perform reliably in static environments, they often
encounter camera tracking drift and fuzzy mapping when dealing with the
disturbances caused by moving objects. This paper presents DyPho-SLAM, a
real-time, resource-efficient visual SLAM system designed to address the
challenges of localization and photorealistic mapping in environments with
dynamic objects. Specifically, the proposed system integrates prior image
information to generate refined masks, effectively minimizing noise from mask
misjudgment. Additionally, to enhance constraints for optimization after
removing dynamic obstacles, we devise adaptive feature extraction strategies
significantly improving the system's resilience. Experiments conducted on
publicly dynamic RGB-D datasets demonstrate that the proposed system achieves
state-of-the-art performance in camera pose estimation and dense map
reconstruction, while operating in real-time in dynamic scenes.

</details>


### [33] [Inverse Kinematics for a 6-Degree-of-Freedom Robot Manipulator Using Comprehensive Gröbner Systems](https://arxiv.org/abs/2509.00823)
*Takumu Okazaki,Akira Terui,Masahiko Mikawa*

Main category: cs.RO

TL;DR: 提出使用计算机代数解决6自由度机械臂逆运动学问题的方法，扩展了可求解的机械臂类别，通过综合Gröbner系统避免重复计算


<details>
  <summary>Details</summary>
Motivation: 传统方法要求三个连续旋转关节轴线相交才能分解位置和姿态问题，希望扩展到更一般的两个连续关节轴线相交的情况，扩大可求解机械臂的范围

Method: 使用综合Gröbner系统（CGS），将机器人关节参数作为系数中的参数，避免重复计算Gröbner基

Result: 实验验证了所提方法的有效性，能够成功解决更广泛类别的6自由度机械臂逆运动学问题

Conclusion: 该方法扩展了可求解逆运动学问题的机械臂类别，通过CGS方法提高了计算效率，为更广泛的机器人应用提供了有效的解决方案

Abstract: We propose an effective method for solving the inverse kinematic problem of a
specific model of 6-degree-of-freedom (6-DOF) robot manipulator using computer
algebra. It is known that when the rotation axes of three consecutive
rotational joints of a manipulator intersect at a single point, the inverse
kinematics problem can be divided into determining position and orientation. We
extend this method to more general manipulators in which the rotational axes of
two consecutive joints intersect. This extension broadens the class of 6-DOF
manipulators for which the inverse kinematics problem can be solved, and is
expected to enable more efficient solutions. The inverse kinematic problem is
solved using the Comprehensive Gr\"obner System (CGS) with joint parameters of
the robot appearing as parameters in the coefficients to prevent repetitive
calculations of the Gr\"obner bases. The effectiveness of the proposed method
is shown by experiments.

</details>


### [34] [An Effective Trajectory Planning and an Optimized Path Planning for a 6-Degree-of-Freedom Robot Manipulator](https://arxiv.org/abs/2509.00828)
*Takumu Okazaki,Akira Terui,Masahiko Mikawa*

Main category: cs.RO

TL;DR: 提出了一种基于计算机代数的6自由度机器人路径规划优化方法，通过逆运动学求解、可行区域计算和Dijkstra算法寻找最优关节配置序列


<details>
  <summary>Details</summary>
Motivation: 为了解决6自由度机器人末端执行器沿指定线段轨迹运动时的最优路径规划问题，需要找到在轨迹各路径点上逆运动学解的最优组合，以减少运动过程中的关节变化和能量消耗

Method: 方法分为三步：1) 计算末端执行器特定配置下机器人的可行区域；2) 在线段轨迹上寻找末端执行器运动轨迹和对应的关节配置序列；3) 将问题转化为图的最短路径问题，应用Dijkstra算法寻找各路径点逆运动学解的最优组合

Result: 通过实验验证了所提方法的有效性，能够成功找到6自由度机器人沿指定线段轨迹运动的最优关节配置序列

Conclusion: 该方法为6自由度机器人的路径规划提供了一种有效的优化解决方案，通过计算机代数和图算法相结合的方式，实现了在复杂运动轨迹下的最优运动规划

Abstract: An effective method for optimizing path planning for a specific model of a
6-degree-of-freedom (6-DOF) robot manipulator is presented as part of the
motion planning of the manipulator using computer algebra. We assume that we
are given a path in the form of a set of line segments that the end-effector
should follow. We also assume that we have a method to solve the inverse
kinematic problem of the manipulator at each via-point of the trajectory. The
proposed method consists of three steps. First, we calculate the feasible
region of the manipulator under a specific configuration of the end-effector.
Next, we aim to find a trajectory on the line segments and a sequence of joint
configurations the manipulator should follow to move the end-effector along the
specified trajectory. Finally, we find the optimal combination of solutions to
the inverse kinematic problem at each via-point along the trajectory by
reducing the problem to a shortest-path problem of the graph and applying
Dijkstra's algorithm. We show the effectiveness of the proposed method by
experiments.

</details>


### [35] [One-Step Model Predictive Path Integral for Manipulator Motion Planning Using Configuration Space Distance Fields](https://arxiv.org/abs/2509.00836)
*Yulin Li,Tetsuro Miyazaki,Kenji Kawashima*

Main category: cs.RO

TL;DR: 提出CDF-MPPI框架，将配置空间距离场(CDF)与模型预测路径积分(MPPI)控制结合，实现高效高维运动规划


<details>
  <summary>Details</summary>
Motivation: 传统基于优化的方法依赖SDF梯度但容易陷入局部极小值，而梯度自由方法如MPPI计算成本高且需要设计复杂代价函数

Method: 利用CDF的梯度信息统一MPPI在关节空间的代价函数，将规划时域缩减到单步，大幅降低计算量同时保持避障能力

Result: 在2D环境中达到近100%成功率，在7自由度Franka机械臂复杂障碍物仿真中保持高成功率，控制频率超过750Hz

Conclusion: CDF-MPPI框架在高效性和有效性方面显著优于传统优化方法和标准MPPI基线，适用于高维运动规划

Abstract: Motion planning for robotic manipulators is a fundamental problem in
robotics. Classical optimization-based methods typically rely on the gradients
of signed distance fields (SDFs) to impose collision-avoidance constraints.
However, these methods are susceptible to local minima and may fail when the
SDF gradients vanish. Recently, Configuration Space Distance Fields (CDFs) have
been introduced, which directly model distances in the robot's configuration
space. Unlike workspace SDFs, CDFs are differentiable almost everywhere and
thus provide reliable gradient information. On the other hand, gradient-free
approaches such as Model Predictive Path Integral (MPPI) control leverage
long-horizon rollouts to achieve collision avoidance. While effective, these
methods are computationally expensive due to the large number of trajectory
samples, repeated collision checks, and the difficulty of designing cost
functions with heterogeneous physical units. In this paper, we propose a
framework that integrates CDFs with MPPI to enable direct navigation in the
robot's configuration space. Leveraging CDF gradients, we unify the MPPI cost
in joint-space and reduce the horizon to one step, substantially cutting
computation while preserving collision avoidance in practice. We demonstrate
that our approach achieves nearly 100% success rates in 2D environments and
consistently high success rates in challenging 7-DOF Franka manipulator
simulations with complex obstacles. Furthermore, our method attains control
frequencies exceeding 750 Hz, substantially outperforming both
optimization-based and standard MPPI baselines. These results highlight the
effectiveness and efficiency of the proposed CDF-MPPI framework for
high-dimensional motion planning.

</details>


### [36] [Enhanced Mean Field Game for Interactive Decision-Making with Varied Stylish Multi-Vehicles](https://arxiv.org/abs/2509.00981)
*Liancheng Zheng,Zhen Tian,Yangfan He,Shuo Liu,Ke Gong,Huilin Chen,Zhihao Lin*

Main category: cs.RO

TL;DR: 基于MFG的自动驾驶决策框架，通过量化驾驶风格表示和空间影响场模型处理异构交通，结合安全关键换道算法实现零碰撞性能


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶在异构交通环境中处理多样化人类驾驶行为的挑战，需要能够准确捕捉和响应不同驾驶风格的决策框架

Method: 提出量化驾驶风格表示方法，将抽象特征映射到速度、安全因子和反应时间等参数；通过空间影响场模型将这些参数嵌入到MFG中；开发安全关键换道算法，利用动态安全边界、碰撞时间分析和多层约束

Result: 在六种风格组合、两个15辆车场景和NGSIM数据试验中实现零碰撞，持续优于传统博弈论基准方法

Conclusion: 该方法为现实世界自动驾驶应用提供了一个可扩展、可解释且行为感知的规划框架

Abstract: This paper presents an MFG-based decision-making framework for autonomous
driving in heterogeneous traffic. To capture diverse human behaviors, we
propose a quantitative driving style representation that maps abstract traits
to parameters such as speed, safety factors, and reaction time. These
parameters are embedded into the MFG through a spatial influence field model.
To ensure safe operation in dense traffic, we introduce a safety-critical
lane-changing algorithm that leverages dynamic safety margins,
time-to-collision analysis, and multi-layered constraints. Real-world NGSIM
data is employed for style calibration and empirical validation. Experimental
results demonstrate zero collisions across six style combinations, two
15-vehicle scenarios, and NGSIM-based trials, consistently outperforming
conventional game-theoretic baselines. Overall, our approach provides a
scalable, interpretable, and behavior-aware planning framework for real-world
autonomous driving applications.

</details>


### [37] [A Robust Numerical Method for Solving Trigonometric Equations in Robotic Kinematics](https://arxiv.org/abs/2509.01010)
*Hai-Jun Su*

Main category: cs.RO

TL;DR: 提出了一种用于求解机器人运动学中三角方程组的鲁棒数值方法，通过多项式替换和特征值分解处理奇异矩阵和边缘情况，具有优异的数值稳定性。


<details>
  <summary>Details</summary>
Motivation: 机器人运动学中经常遇到三角方程组求解问题，传统方法在数值稳定性和处理奇异矩阵方面存在不足，需要开发更鲁棒的求解器。

Method: 采用多项式替换技术结合特征值分解，对非奇异矩阵使用Weierstrass替换转换为四次多项式，对奇异矩阵使用基于SVD分析的几何约束方法。

Result: 求解器达到机器精度（误差<10^{-15}），在大量测试案例中成功率100%，已实现为开源Python包。

Conclusion: 该方法在数值稳定性和准确性方面优于传统方法，特别适用于机器人逆运动学等应用场景。

Abstract: This paper presents a robust numerical method for solving systems of
trigonometric equations commonly encountered in robotic kinematics. Our
approach employs polynomial substitution techniques combined with eigenvalue
decomposition to handle singular matrices and edge cases effectively. The
method demonstrates superior numerical stability compared to traditional
approaches and has been implemented as an open-source Python package. For
non-singular matrices, we employ Weierstrass substitution to transform the
system into a quartic polynomial, ensuring all analytical solutions are found.
For singular matrices, we develop specialized geometric constraint methods
using SVD analysis. The solver demonstrates machine precision accuracy ($<
10^{-15}$ error) with 100\% success rate on extensive test cases, making it
particularly valuable for robotics applications such as inverse kinematics
problems.

</details>


### [38] [TARA: A Low-Cost 3D-Printed Robotic Arm for Accessible Robotics Education](https://arxiv.org/abs/2509.01043)
*Thays Leach Mitre*

Main category: cs.RO

TL;DR: TARA是一个低成本3D打印机械臂，价格约200美元，旨在解决机器人教育成本高的问题，提供开源设计和代码，注重教育可复现性而非性能基准测试。


<details>
  <summary>Details</summary>
Motivation: 机器人平台的高成本限制了学生获得实际技能的能力，需要开发低成本、易获取的机器人教育平台。

Method: 开发TARA低成本3D打印机械臂，包含开源设计文件、组装说明和基础代码，平衡经济性和功能性。

Result: 实验验证显示在基本操作任务中具有准确性能，成本显著低于数千美元的工业系统。

Conclusion: 该工作优先考虑教育可复现性，为学生和教育者提供可可靠复制和扩展的平台，而非追求性能基准测试。

Abstract: The high cost of robotic platforms limits students' ability to gain practical
skills directly applicable in real-world scenarios. To address this challenge,
this paper presents TARA, a low-cost, 3D-printed robotic arm designed for
accessible robotics education. TARA includes an open-source repository with
design files, assembly instructions, and baseline code, enabling users to build
and customize the platform. The system balances affordability and
functionality, offering a highly capable robotic arm for approximately 200 USD,
significantly lower than industrial systems that often cost thousands of
dollars. Experimental validation confirmed accurate performance in basic
manipulation tasks. Rather than focusing on performance benchmarking, this work
prioritizes educational reproducibility, providing a platform that students and
educators can reliably replicate and extend.

</details>


### [39] [A Reactive Grasping Framework for Multi-DoF Grippers via Task Space Velocity Fields and Joint Space QP](https://arxiv.org/abs/2509.01044)
*Yonghyeon Lee,Tzu-Yuan Lin,Alexander Alexiev,Sangbae Kim*

Main category: cs.RO

TL;DR: 提出了一种结合任务空间速度场和关节空间二次规划的分层框架，用于高自由度抓手的快速反应式抓取，通过低维任务空间全局规划和全关节空间局部跟踪实现实时无碰撞运动


<details>
  <summary>Details</summary>
Motivation: 高自由度系统的反应式无碰撞全局运动规划面临状态维度和规划时域同时增加导致的搜索空间组合爆炸问题，使得实时规划变得不可行

Method: 在多个任务空间坐标（或部分关节坐标）中构建速度场，通过加权关节空间二次规划计算关节速度来跟踪这些速度场，并分配适当的优先级

Result: 通过仿真实验和基于FoundationPose姿态跟踪算法的真实世界测试验证，该方法能使高自由度臂手系统执行实时无碰撞到达运动，并能适应动态环境和外部干扰

Conclusion: 该分层框架成功解决了高自由度系统的实时反应式运动规划问题，实现了在复杂环境中的高效抓取操作

Abstract: We present a fast and reactive grasping framework for multi-DoF grippers that
combines task-space velocity fields with a joint-space Quadratic Program (QP)
in a hierarchical structure. Reactive, collision-free global motion planning is
particularly challenging for high-DoF systems, since simultaneous increases in
state dimensionality and planning horizon trigger a combinatorial explosion of
the search space, making real-time planning intractable. To address this, we
plan globally in a lower-dimensional task space, such as fingertip positions,
and track locally in the full joint space while enforcing all constraints. This
approach is realized by constructing velocity fields in multiple task-space
coordinates (or in some cases a subset of joint coordinates) and solving a
weighted joint-space QP to compute joint velocities that track these fields
with appropriately assigned priorities. Through simulation experiments with
privileged knowledge and real-world tests using the recent pose-tracking
algorithm FoundationPose, we verify that our method enables high-DoF arm-hand
systems to perform real-time, collision-free reaching motions while adapting to
dynamic environments and external disturbances.

</details>


### [40] [Model Predictive Control for a Soft Robotic Finger with Stochastic Behavior based on Fokker-Planck Equation](https://arxiv.org/abs/2509.01065)
*Sumitaka Honji,Takahiro Wada*

Main category: cs.RO

TL;DR: 提出基于Fokker-Planck方程的随机控制策略FPE-MPC，用于解决软体机器人因柔性和非线性带来的不确定性控制问题


<details>
  <summary>Details</summary>
Motivation: 软体机器人的柔韧性带来了适应性和安全性优势，但也引入了高度不确定性和非线性运动控制挑战，特别是开环控制缺乏反馈机制，确定性模型难以处理这种不确定性

Method: 使用Fokker-Planck方程（随机过程的主方程）来控制概率分布而非状态本身，提出并实现了基于FPE的模型预测控制方法（FPE-MPC）

Result: 通过两个数值模拟案例研究验证了该控制方法的性能和特性，证明其能有效管理软体机器人系统中的不确定性

Conclusion: FPE-MPC方法在软体机器人手指控制中展现出良好效果，为解决软体机器人不确定性控制问题提供了有效解决方案

Abstract: The inherent flexibility of soft robots offers numerous advantages, such as
enhanced adaptability and improved safety. However, this flexibility can also
introduce challenges regarding highly uncertain and nonlinear motion. These
challenges become particularly problematic when using open-loop control
methods, which lack a feedback mechanism and are commonly employed in soft
robot control. Though one potential solution is model-based control, typical
deterministic models struggle with uncertainty as mentioned above. The idea is
to use the Fokker-Planck Equation (FPE), a master equation of a stochastic
process, to control not the state of soft robots but the probabilistic
distribution. In this study, we propose and implement a stochastic-based
control strategy, termed FPE-based Model Predictive Control (FPE-MPC), for a
soft robotic finger. Two numerical simulation case studies examine the
performance and characteristics of this control method, revealing its efficacy
in managing the uncertainty inherent in soft robotic systems.

</details>


### [41] [SR-SLAM: Scene-reliability Based RGB-D SLAM in Diverse Environments](https://arxiv.org/abs/2509.01111)
*Haolan Zhang,Chenghao Li,Thanh Nguyen Canh,Lijun Wang,Nak Young Chong*

Main category: cs.RO

TL;DR: SRR-SLAM是一个基于场景可靠性的视觉SLAM框架，通过环境感知处理提升特征提取和位姿估计的适应性，在动态环境中实现高达90%的精度提升。


<details>
  <summary>Details</summary>
Motivation: 传统特征SLAM方法在动态环境中面临两个主要挑战：特征剔除和位姿估计的适应性有限，以及评估优化策略的环境感知不足。需要一种能够根据环境变化自适应调整的SLAM系统。

Method: 提出统一的场景可靠性评估机制，包含多指标和历史观测；开发自适应动态区域选择、深度辅助自调整聚类、可靠性感知位姿细化；以及基于可靠性的关键帧选择和加权优化方案。

Result: 在公开数据集和真实场景中的广泛实验表明，SRR-SLAM优于最先进的动态SLAM方法，在不同环境中实现了高达90%的精度和鲁棒性提升。

Conclusion: SRR-SLAM通过环境感知的可靠性评估和自适应处理，显著提高了自主机器人传感系统的测量精度和可靠性，为动态环境下的视觉SLAM提供了有效解决方案。

Abstract: Visual simultaneous localization and mapping (SLAM) plays a critical role in
autonomous robotic systems, especially where accurate and reliable measurements
are essential for navigation and sensing. In feature-based SLAM, the
quantityand quality of extracted features significantly influence system
performance. Due to the variations in feature quantity and quality across
diverse environments, current approaches face two major challenges: (1) limited
adaptability in dynamic feature culling and pose estimation, and (2)
insufficient environmental awareness in assessment and optimization strategies.
To address these issues, we propose SRR-SLAM, a scene-reliability based
framework that enhances feature-based SLAM through environment-aware
processing. Our method introduces a unified scene reliability assessment
mechanism that incorporates multiple metrics and historical observations to
guide system behavior. Based on this assessment, we develop: (i) adaptive
dynamic region selection with flexible geometric constraints, (ii)
depth-assisted self-adjusting clustering for efficient dynamic feature removal
in high-dimensional settings, and (iii) reliability-aware pose refinement that
dynamically integrates direct methods when features are insufficient.
Furthermore, we propose (iv) reliability-based keyframe selection and a
weighted optimization scheme to reduce computational overhead while improving
estimation accuracy. Extensive experiments on public datasets and real world
scenarios show that SRR-SLAM outperforms state-of-the-art dynamic SLAM methods,
achieving up to 90% improvement in accuracy and robustness across diverse
environments. These improvements directly contribute to enhanced measurement
precision and reliability in autonomous robotic sensing systems.

</details>


### [42] [A novel parameter estimation method for pneumatic soft hand control applying logarithmic decrement for pseudo rigid body modeling](https://arxiv.org/abs/2509.01113)
*Haiyun Zhang,Kelvin HoLam Heung,Gabrielle J. Naquila,Ashwin Hingwe,Ashish D. Deshpande*

Main category: cs.RO

TL;DR: 提出PRBM+LDM方法，结合伪刚体建模和对数衰减法，为软体机器人提供高效参数估计和精确控制，在位置和力控制方面均优于传统方法


<details>
  <summary>Details</summary>
Motivation: 软体机器人控制面临连续变形带来的挑战，现有模型计算效率低且参数识别复杂，限制了实时应用

Method: 结合伪刚体建模(PRBM)和对数衰减法(LDM)进行参数估计，在软体机械手测试平台上验证位置和力输出预测，并实现闭环控制

Result: 位置控制误差显著降低(4.37° vs 20.38°)，力控制在精细物体抓取中表现优异(薯片86 vs 82.5，螺丝刀74.42 vs 70，铜币64.75 vs 35)

Conclusion: PRBM+LDM是一种计算高效、精确的软体执行器建模技术，能够实现稳定灵活的抓取和精确的力调节

Abstract: The rapid advancement in physical human-robot interaction (HRI) has
accelerated the development of soft robot designs and controllers. Controlling
soft robots, especially soft hand grasping, is challenging due to their
continuous deformation, motivating the use of reduced model-based controllers
for real-time dynamic performance. Most existing models, however, suffer from
computational inefficiency and complex parameter identification, limiting their
real-time applicability. To address this, we propose a paradigm coupling
Pseudo-Rigid Body Modeling with the Logarithmic Decrement Method for parameter
estimation (PRBM plus LDM). Using a soft robotic hand test bed, we validate
PRBM plus LDM for predicting position and force output from pressure input and
benchmark its performance. We then implement PRBM plus LDM as the basis for
closed-loop position and force controllers. Compared to a simple PID
controller, the PRBM plus LDM position controller achieves lower error (average
maximum error across all fingers: 4.37 degrees versus 20.38 degrees). For force
control, PRBM plus LDM outperforms constant pressure grasping in pinching tasks
on delicate objects: potato chip 86 versus 82.5, screwdriver 74.42 versus 70,
brass coin 64.75 versus 35. These results demonstrate PRBM plus LDM as a
computationally efficient and accurate modeling technique for soft actuators,
enabling stable and flexible grasping with precise force regulation.

</details>


### [43] [Novel bio-inspired soft actuators for upper-limb exoskeletons: design, fabrication and feasibility study](https://arxiv.org/abs/2509.01145)
*Haiyun Zhang,Gabrielle Naquila,Jung Hyun Bae,Zonghuan Wu,Ashwin Hingwe,Ashish Deshpande*

Main category: cs.RO

TL;DR: 这篇论文提出了一种上胎软体机器人设计范式，包括龙虾受启发的脐部气动器LISPER和扇象受启发的肩部气动器SCASPER，以解决现有软体机器人在康复中的响应慢、运动范围小和输出力不足等问题。


<details>
  <summary>Details</summary>
Motivation: 现有软体机器人在康复应用中存在响应速度慢、运动范围受限、输出力较低等问题，且缺乏对气动器设计的定量分析和精确控制研究。

Method: 设计了两种新型气动器：LISPER（龙虾受启发的硅胶气动机器）用于脐部，具有高带宽、高输出力/矩和高线性性；SCASPER（扇象形气动器）用于肩部，具有高输出力/矩和简化制造过程。建立了完整的分析模型来描述压力、弯曲角度和输出力之间的关系。

Result: 通过分析模型可以根据气动器的几何配置来调整运动范围和输出力。在模拟手臂上进行了初步测试，验证了气动器的性能能力。

Conclusion: 该研究提出的新型软体机器人设计范式有望解决现有康复软机器人的性能限制，为上胎康复提供更高性能的软体机器人解决方案。

Abstract: Soft robots have been increasingly utilized as sophisticated tools in
physical rehabilitation, particularly for assisting patients with neuromotor
impairments. However, many soft robotics for rehabilitation applications are
characterized by limitations such as slow response times, restricted range of
motion, and low output force. There are also limited studies on the precise
position and force control of wearable soft actuators. Furthermore, not many
studies articulate how bellow-structured actuator designs quantitatively
contribute to the robots' capability. This study introduces a paradigm of upper
limb soft actuator design. This paradigm comprises two actuators: the
Lobster-Inspired Silicone Pneumatic Robot (LISPER) for the elbow and the
Scallop-Shaped Pneumatic Robot (SCASPER) for the shoulder. LISPER is
characterized by higher bandwidth, increased output force/torque, and high
linearity. SCASPER is characterized by high output force/torque and simplified
fabrication processes. Comprehensive analytical models that describe the
relationship between pressure, bending angles, and output force for both
actuators were presented so the geometric configuration of the actuators can be
set to modify the range of motion and output forces. The preliminary test on a
dummy arm is conducted to test the capability of the actuators.

</details>


### [44] [OpenMulti: Open-Vocabulary Instance-Level Multi-Agent Distributed Implicit Mapping](https://arxiv.org/abs/2509.01228)
*Jianyu Dou,Yinan Deng,Jiahui Wang,Xingsi Tang,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: OpenMulti是一个开词汇实例级多智能体分布式隐式建图框架，通过跨智能体实例对齐和交叉渲染监督解决现有方法缺乏实例级感知和语义理解的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体分布式协作建图方法缺乏实例级感知和环境语义理解，限制了在下游应用中的有效性。

Method: 提出跨智能体实例对齐模块构建实例协作图，确保跨智能体的一致实例理解；利用交叉渲染监督增强场景的分布式学习，避免盲区优化陷阱导致的建图精度下降。

Result: 实验结果表明，OpenMulti在细粒度几何精度和零样本语义精度方面均优于相关算法，并支持实例级检索任务，为下游应用提供语义标注。

Conclusion: OpenMulti框架有效解决了多智能体分布式建图中的实例级语义理解问题，在几何和语义精度方面表现出色，具有实际应用价值。

Abstract: Multi-agent distributed collaborative mapping provides comprehensive and
efficient representations for robots. However, existing approaches lack
instance-level awareness and semantic understanding of environments, limiting
their effectiveness for downstream applications. To address this issue, we
propose OpenMulti, an open-vocabulary instance-level multi-agent distributed
implicit mapping framework. Specifically, we introduce a Cross-Agent Instance
Alignment module, which constructs an Instance Collaborative Graph to ensure
consistent instance understanding across agents. To alleviate the degradation
of mapping accuracy due to the blind-zone optimization trap, we leverage Cross
Rendering Supervision to enhance distributed learning of the scene.
Experimental results show that OpenMulti outperforms related algorithms in both
fine-grained geometric accuracy and zero-shot semantic accuracy. In addition,
OpenMulti supports instance-level retrieval tasks, delivering semantic
annotations for downstream applications. The project website of OpenMulti is
publicly available at https://openmulti666.github.io/.

</details>


### [45] [Towards Data-Driven Metrics for Social Robot Navigation Benchmarking](https://arxiv.org/abs/2509.01251)
*Pilar Bachiller-Burgos,Ulysses Bernardet,Luis V. Calderita,Pranup Chhetri,Anthony Francis,Noriaki Hirose,Noé Pérez,Dhruv Shah,Phani T. Singamaneni,Xuesu Xiao,Luis J. Manso*

Main category: cs.RO

TL;DR: 这篇论文提出了一种数据驱动的社交机器人导航评量标准，包含数据集编试和基准模型训练，所有资源公开可用。


<details>
  <summary>Details</summary>
Motivation: 为了提供标准化的社交机器人导航评估方法，促进性能测试策略优化和基准比较。

Method: 编试4427条实际和模拟导航轨迹数据集，通过人工评分获得4402条评分数据，基于RNN训练基准评量模型。

Result: 获得了大规模评分数据集，并实现了定量和定性的评估结果，所有数据和模型都公开可用。

Conclusion: 该方法为社交机器人导航预测提供了可靠的评量标准，有助于预测模型的发展和基准比较。

Abstract: This paper presents a joint effort towards the development of a data-driven
Social Robot Navigation metric to facilitate benchmarking and policy
optimization. We provide our motivations for our approach and describe our
proposal for storing rated social navigation trajectory datasets. Following
these guidelines, we compiled a dataset with 4427 trajectories -- 182 real and
4245 simulated -- and presented it to human raters, yielding a total of 4402
rated trajectories after data quality assurance. We also trained an RNN-based
baseline metric on the dataset and present quantitative and qualitative
results. All data, software, and model weights are publicly available.

</details>


### [46] [Toward a Holistic Multi-Criteria Trajectory Evaluation Framework for Autonomous Driving in Mixed Traffic Environment](https://arxiv.org/abs/2509.01291)
*Nouhed Naidja,Stéphane Font,Marc Revilloud,Guillaume Sandou*

Main category: cs.RO

TL;DR: 提出一个统一框架来评估和优化自动驾驶车辆轨迹，整合安全性、舒适性和效率标准，使用自适应椭圆安全区域分析和PSO算法进行优化。


<details>
  <summary>Details</summary>
Motivation: 需要统一的评估框架来同时考虑自动驾驶车辆轨迹的安全性、舒适性和效率，以提升整体性能。

Method: 使用自适应椭圆分析安全区域，应用鞋带公式计算不对齐和时间变化配置的交叉面积，建立纵向和横向急动度的舒适性指标，采用PSO算法优化综合目标函数。

Result: 方法在真实交通条件下成功验证，包括城市交叉路口自动驾驶车辆与人工驾驶车辆的交互实验，以及基于真实交通数据的仿真。

Conclusion: 该框架有效整合了多维度评估标准，为自动驾驶车辆轨迹优化提供了实用的解决方案。

Abstract: This paper presents a unified framework for the evaluation and optimization
of autonomous vehicle trajectories, integrating formal safety, comfort, and
efficiency criteria. An innovative geometric indicator, based on the analysis
of safety zones using adaptive ellipses, is used to accurately quantify
collision risks. Our method applies the Shoelace formula to compute the
intersection area in the case of misaligned and time-varying configurations.
Comfort is modeled using indicators centered on longitudinal and lateral jerk,
while efficiency is assessed by overall travel time. These criteria are
aggregated into a comprehensive objective function solved using a PSO based
algorithm. The approach was successfully validated under real traffic
conditions via experiments conducted in an urban intersection involving an
autonomous vehicle interacting with a human-operated vehicle, and in simulation
using data recorded from human driving in real traffic.

</details>


### [47] [Disentangled Multi-Context Meta-Learning: Unlocking robust and Generalized Task Learning](https://arxiv.org/abs/2509.01297)
*Seonsoo Kim,Jun-Gill Kang,Taehong Kim,Seongil Hong*

Main category: cs.RO

TL;DR: 本文提出了一种解耦多上下文元学习框架，通过显式分配任务因素到独立上下文向量，提升了模型的可解释性和演化性能。


<details>
  <summary>Details</summary>
Motivation: 现有元学习方法多依赖隐式适应任务变化，多个因素混合在单一缠绕表征中，影响了模型的可解释性和演化性能。

Method: 设计了解耦多上下文元学习框架，将每个任务因素显式分配给独立的上下文向量，支持上下文向量在共享因素的任务间共享。

Result: 在正弦回归任务中在分布外任务上超过基线，通过共享幅值或相位移的上下文向量实现了对未见正弦函数的演化。在四足机器人行走任务中，通过解耦机器人特定属性和地形特征，在分布外条件下实现了更好的稳健性，并仅用20秒平坦地形实际数据就完成了具有分布外机器人特性的具有挑战性地形的模拟到实际的策略转移。

Conclusion: 解耦多上下文元学习框架能够显著提升模型的可解释性、演化性能和稳健性，在多个领域都取得了超过基线的效果，尤其在模拟到实际转移中显示出了显著优势。

Abstract: In meta-learning and its downstream tasks, many methods rely on implicit
adaptation to task variations, where multiple factors are mixed together in a
single entangled representation. This makes it difficult to interpret which
factors drive performance and can hinder generalization. In this work, we
introduce a disentangled multi-context meta-learning framework that explicitly
assigns each task factor to a distinct context vector. By decoupling these
variations, our approach improves robustness through deeper task understanding
and enhances generalization by enabling context vector sharing across tasks
with shared factors. We evaluate our approach in two domains. First, on a
sinusoidal regression task, our model outperforms baselines on
out-of-distribution tasks and generalizes to unseen sine functions by sharing
context vectors associated with shared amplitudes or phase shifts. Second, in a
quadruped robot locomotion task, we disentangle the robot-specific properties
and the characteristics of the terrain in the robot dynamics model. By
transferring disentangled context vectors acquired from the dynamics model into
reinforcement learning, the resulting policy achieves improved robustness under
out-of-distribution conditions, surpassing the baselines that rely on a single
unified context. Furthermore, by effectively sharing context, our model enables
successful sim-to-real policy transfer to challenging terrains with
out-of-distribution robot-specific properties, using just 20 seconds of real
data from flat terrain, a result not achievable with single-task adaptation.

</details>


### [48] [TopoNav: Topological Graphs as a Key Enabler for Advanced Object Navigation](https://arxiv.org/abs/2509.01364)
*Peiran Liu,Qiang Zhang,Daojie Peng,Lingfeng Zhang,Yihao Qin,Hang Zhou,Jun Ma,Renjing Xu,Yiding Ji*

Main category: cs.RO

TL;DR: TopoNav是一个利用拓扑结构作为空间记忆的新框架，通过构建和更新拓扑图来捕捉场景连接、邻近关系和语义信息，在物体导航任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 物体导航在大型语言模型推动下取得进展，但在长时程任务和动态场景中的记忆管理仍面临挑战，需要更好的空间记忆机制。

Method: 提出TopoNav框架，利用拓扑结构作为空间记忆，构建和更新拓扑图来捕获场景连接、邻近关系和语义含义，帮助智能体积累空间知识、检索关键信息并进行有效推理。

Result: 在基准物体导航数据集上实现了最先进的性能，具有更高的成功率和更高效的路径，在多样化和复杂环境中表现尤为出色。

Conclusion: TopoNav通过将临时视觉输入与持久空间理解相连接，为物体导航提供了有效的拓扑空间记忆解决方案，显著提升了导航性能。

Abstract: Object Navigation (ObjectNav) has made great progress with large language
models (LLMs), but still faces challenges in memory management, especially in
long-horizon tasks and dynamic scenes. To address this, we propose TopoNav, a
new framework that leverages topological structures as spatial memory. By
building and updating a topological graph that captures scene connections,
adjacency, and semantic meaning, TopoNav helps agents accumulate spatial
knowledge over time, retrieve key information, and reason effectively toward
distant goals. Our experiments show that TopoNav achieves state-of-the-art
performance on benchmark ObjectNav datasets, with higher success rates and more
efficient paths. It particularly excels in diverse and complex environments, as
it connects temporary visual inputs with lasting spatial understanding.

</details>


### [49] [Analyzing Reluctance to Ask for Help When Cooperating With Robots: Insights to Integrate Artificial Agents in HRC](https://arxiv.org/abs/2509.01450)
*Ane San Martin,Michael Hagenow,Julie Shah,Johan Kildal,Elena Lazkano*

Main category: cs.RO

TL;DR: 这篇论文研究了人机协作任务中的帮助系统设计，通过用户研究分析了远程人类帮助的影响，以及用户对未来人工智能帮助代理的认知和偏好。


<details>
  <summary>Details</summary>
Motivation: 随着机器人技术的发展，人机协作在工业任务中将更加普遍。当人类遇到问题时，依赖人工智能帮助代理或机器人提供支持成为可能的未来方向。研究识别了设计未来用户帮助代理的关键因素。

Method: 通过用户研究，分析在人机协作组装任务中接受远程人类帮助的数据（包括定量和定性数据）。研究用户需要帮助的场景，评估他们请求和接受帮助的体验，以及对未来非人类帮助代理的看法和帮助方式的偏好。

Result: 分析了不同设计选择（人类或人工智能帮助者，需求帮助或主动帮助）对人机协作任务中人类情感响应、生产力和偏好的影响。

Conclusion: 研究为未来人机协作任务中的帮助系统设计提供了重要的设计参考，确定了帮助代理类型和帮助方式等关键设计决策对用户体验的重要影响。

Abstract: As robot technology advances, collaboration between humans and robots will
become more prevalent in industrial tasks. When humans run into issues in such
scenarios, a likely future involves relying on artificial agents or robots for
aid. This study identifies key aspects for the design of future user-assisting
agents. We analyze quantitative and qualitative data from a user study
examining the impact of on-demand assistance received from a remote human in a
human-robot collaboration (HRC) assembly task. We study scenarios in which
users require help and we assess their experiences in requesting and receiving
assistance. Additionally, we investigate participants' perceptions of future
non-human assisting agents and whether assistance should be on-demand or
unsolicited. Through a user study, we analyze the impact that such design
decisions (human or artificial assistant, on-demand or unsolicited help) can
have on elicited emotional responses, productivity, and preferences of humans
engaged in HRC tasks.

</details>


### [50] [FGO-SLAM: Enhancing Gaussian SLAM with Globally Consistent Opacity Radiance Field](https://arxiv.org/abs/2509.01547)
*Fan Zhu,Yifan Zhao,Ziyu Chen,Biao Yu,Hui Zhu*

Main category: cs.RO

TL;DR: FGO-SLAM是一个基于高斯SLAM的系统，通过不透明度辐射场增强几何映射性能，采用全局调整优化相机位姿和稀疏点云，并引入深度失真和法线一致性约束来提升场景重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法难以满足高质量场景重建需求，而现有高斯SLAM系统缺乏有效的位姿优化方法且在几何重建方面面临挑战。

Method: 使用不透明度辐射场作为场景表示，进行全局位姿和点云优化，维护全局一致的高斯不透明度场，引入深度失真和法线一致性约束，并通过四面体网格提取表面。

Result: 在多个真实世界和大规模合成数据集上实现了最先进的跟踪精度和映射性能。

Conclusion: FGO-SLAM系统有效解决了高斯SLAM的位姿优化和几何重建问题，在跟踪和映射方面表现出色。

Abstract: Visual SLAM has regained attention due to its ability to provide perceptual
capabilities and simulation test data for Embodied AI. However, traditional
SLAM methods struggle to meet the demands of high-quality scene reconstruction,
and Gaussian SLAM systems, despite their rapid rendering and high-quality
mapping capabilities, lack effective pose optimization methods and face
challenges in geometric reconstruction. To address these issues, we introduce
FGO-SLAM, a Gaussian SLAM system that employs an opacity radiance field as the
scene representation to enhance geometric mapping performance. After initial
pose estimation, we apply global adjustment to optimize camera poses and sparse
point cloud, ensuring robust tracking of our approach. Additionally, we
maintain a globally consistent opacity radiance field based on 3D Gaussians and
introduce depth distortion and normal consistency terms to refine the scene
representation. Furthermore, after constructing tetrahedral grids, we identify
level sets to directly extract surfaces from 3D Gaussians. Results across
various real-world and large-scale synthetic datasets demonstrate that our
method achieves state-of-the-art tracking accuracy and mapping performance.

</details>


### [51] [Aleatoric Uncertainty from AI-based 6D Object Pose Predictors for Object-relative State Estimation](https://arxiv.org/abs/2509.01583)
*Thomas Jantos,Stephan Weiss,Jan Steinbrener*

Main category: cs.RO

TL;DR: 提出了一种通过添加两个多层感知器来扩展现有深度学习位姿预测器的方法，用于估计6D位姿的随机不确定性，并将其集成到扩展卡尔曼滤波器中，提高了目标相对状态估计的性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习在机器人感知中广泛应用，但深度神经网络预测的不确定性估计对于概率状态估计器至关重要。现有方法通常使用固定协方差，无法动态适应不同场景的不确定性变化。

Method: 在现有的DL位姿预测器基础上，分离添加两个多层感知器（MLP）分别处理平移和旋转部分的随机不确定性估计，冻结预训练预测器参数进行高效训练。

Result: 方法在合成数据和真实数据上验证有效，相比固定协方差方法显著提高了目标相对状态估计的性能，同时计算开销极小，适合边缘设备部署。

Conclusion: 通过简单的架构扩展即可实现深度学习位姿预测器的随机不确定性估计，为概率状态估计提供了动态适应的测量不确定性，提升了机器人导航任务的性能。

Abstract: Deep Learning (DL) has become essential in various robotics applications due
to excelling at processing raw sensory data to extract task specific
information from semantic objects. For example, vision-based object-relative
navigation relies on a DL-based 6D object pose predictor to provide the
relative pose between the object and the robot as measurements to the robot's
state estimator. Accurately knowing the uncertainty inherent in such Deep
Neural Network (DNN) based measurements is essential for probabilistic state
estimators subsequently guiding the robot's tasks. Thus, in this letter, we
show that we can extend any existing DL-based object-relative pose predictor
for aleatoric uncertainty inference simply by including two multi-layer
perceptrons detached from the translational and rotational part of the DL
predictor. This allows for efficient training while freezing the existing
pre-trained predictor. We then use the inferred 6D pose and its uncertainty as
a measurement and corresponding noise covariance matrix in an extended Kalman
filter (EKF). Our approach induces minimal computational overhead such that the
state estimator can be deployed on edge devices while benefiting from the
dynamically inferred measurement uncertainty. This increases the performance of
the object-relative state estimation task compared to a fix-covariance
approach. We conduct evaluations on synthetic data and real-world data to
underline the benefits of aleatoric uncertainty inference for the
object-relative state estimation task.

</details>


### [52] [A Hybrid Input based Deep Reinforcement Learning for Lane Change Decision-Making of Autonomous Vehicle](https://arxiv.org/abs/2509.01611)
*Ziteng Gao,Jiaqi Qu,Chaoyu Chen*

Main category: cs.RO

TL;DR: 提出基于混合输入的深度强化学习算法，通过轨迹预测和多模态信息融合，实现自动驾驶车辆的安全换道决策与控制


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆的换道决策是一个复杂但高回报的行为，需要综合考虑周围车辆的未来行为风险和环境信息，以提高换道决策的安全性和合理性

Method: 1. 提出周围车辆轨迹预测方法，预测结果作为强化学习的附加输入；2. 同时从高维图像和低维传感器数据中提取特征；3. 融合轨迹预测和多模态信息作为强化学习状态空间；4. 将强化学习宏观决策与端到端车辆控制集成

Result: 在CARLA模拟器中进行的实验表明，混合状态空间的使用显著提高了车辆换道决策的安全性

Conclusion: 所提出的混合输入深度强化学习方法通过整合轨迹预测和多模态信息，有效提升了自动驾驶车辆换道决策的安全性能

Abstract: Lane change decision-making for autonomous vehicles is a complex but
high-reward behavior. In this paper, we propose a hybrid input based deep
reinforcement learning (DRL) algorithm, which realizes abstract lane change
decisions and lane change actions for autonomous vehicles within traffic flow.
Firstly, a surrounding vehicles trajectory prediction method is proposed to
reduce the risk of future behavior of surrounding vehicles to ego vehicle, and
the prediction results are input into the reinforcement learning model as
additional information. Secondly, to comprehensively leverage environmental
information, the model extracts feature from high-dimensional images and
low-dimensional sensor data simultaneously. The fusion of surrounding vehicle
trajectory prediction and multi-modal information are used as state space of
reinforcement learning to improve the rationality of lane change decision.
Finally, we integrate reinforcement learning macro decisions with end-to-end
vehicle control to achieve a holistic lane change process. Experiments were
conducted within the CARLA simulator, and the results demonstrated that the
utilization of a hybrid state space significantly enhances the safety of
vehicle lane change decisions.

</details>


### [53] [Speculative Design of Equitable Robotics: Queer Fictions and Futures](https://arxiv.org/abs/2509.01643)
*Minja Axelsson*

Main category: cs.RO

TL;DR: 本文通过探索性论文形式探讨LGBTQ+群体专属机器人的公平性话题，提出了三种酷儿机器人设计提案，并讨论相关伦理问题。


<details>
  <summary>Details</summary>
Motivation: 旨在激发关于酷儿机器人未来发展的思考与对话，探讨如何通过机器人技术为LGBTQ+群体构建理想化的未来愿景。

Method: 采用探索性论文格式，首先回顾科幻和科学领域的酷儿机器人现状，然后提出三种推测性设计提案：反映用户酷儿身份的机器人、作为酷儿 activism 的机器人、以及酷儿社区资源网络机器人。

Result: 提出了具体的酷儿机器人角色设计方案，并引发了关于机器人是否应该被酷儿化以及相关伦理影响的深入讨论。

Conclusion: 为酷儿机器人未来描绘了理想化的发展蓝图，并指出了实现这一愿景所需的条件和考量。

Abstract: This paper examines the speculative topic of equitable robots through an
exploratory essay format. It focuses specifically on robots by and for LGBTQ+
populations. It aims to provoke thought and conversations in the field about
what aspirational queer robotics futures may look like, both in the arts and
sciences. First, it briefly reviews the state-of-the-art of queer robotics in
fiction and science, drawing together threads from each. Then, it discusses
queering robots through three speculative design proposals for queer robot
roles: 1) reflecting the queerness of their ''in-group'' queer users, building
and celebrating ''in-group'' identity, 2) a new kind of queer activism by
implementing queer robot identity performance to interact with ''out-group''
users, with a goal of reducing bigotry through familiarisation, and 3) a
network of queer-owned robots, through which the community could reach each
other, and distribute and access important resources. The paper then questions
whether robots should be queered, and what ethical implications this raises.
Finally, the paper makes suggestions for what aspirational queer robotics
futures may look like, and what would be required to get there.

</details>


### [54] [Data Retrieval with Importance Weights for Few-Shot Imitation Learning](https://arxiv.org/abs/2509.01657)
*Amber Xie,Rahul Chand,Dorsa Sadigh,Joey Hejna*

Main category: cs.RO

TL;DR: 本文提出了重要性加权检索(IWR)方法，通过高斯核密度估计计算目标数据与先验数据分布的概率比，改进了基于检索的模仿学习中数据选择策略，解决了传统最近邻方法的高方差和忽略先验数据分布的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于检索的模仿学习方法使用最近邻距离作为数据选择标准，这种方法存在两个问题：1) 对噪声敏感的高方差估计；2) 未考虑先验数据分布。需要一种更稳健的数据检索方法。

Method: 提出重要性加权检索(IWR)方法，使用高斯核密度估计计算目标数据分布与先验数据分布的概率比作为重要性权重，通过平滑估计来改进数据选择过程。

Result: 在仿真环境和真实世界Bridge数据集上的评估表明，IWR方法能够持续提升现有基于检索方法的性能，且只需进行微小修改。

Conclusion: IWR通过考虑数据分布的概率比，提供了一种更稳健和有效的数据检索方法，解决了传统最近邻检索的局限性，在少样本模仿学习中表现出优越性能。

Abstract: While large-scale robot datasets have propelled recent progress in imitation
learning, learning from smaller task specific datasets remains critical for
deployment in new environments and unseen tasks. One such approach to few-shot
imitation learning is retrieval-based imitation learning, which extracts
relevant samples from large, widely available prior datasets to augment a
limited demonstration dataset. To determine the relevant data from prior
datasets, retrieval-based approaches most commonly calculate a prior data
point's minimum distance to a point in the target dataset in latent space.
While retrieval-based methods have shown success using this metric for data
selection, we demonstrate its equivalence to the limit of a Gaussian kernel
density (KDE) estimate of the target data distribution. This reveals two
shortcomings of the retrieval rule used in prior work. First, it relies on
high-variance nearest neighbor estimates that are susceptible to noise. Second,
it does not account for the distribution of prior data when retrieving data. To
address these issues, we introduce Importance Weighted Retrieval (IWR), which
estimates importance weights, or the ratio between the target and prior data
distributions for retrieval, using Gaussian KDEs. By considering the
probability ratio, IWR seeks to mitigate the bias of previous selection rules,
and by using reasonable modeling parameters, IWR effectively smooths estimates
using all data points. Across both simulation environments and real-world
evaluations on the Bridge dataset we find that our method, IWR, consistently
improves performance of existing retrieval-based methods, despite only
requiring minor modifications.

</details>


### [55] [MoTo: A Zero-shot Plug-in Interaction-aware Navigation for General Mobile Manipulation](https://arxiv.org/abs/2509.01658)
*Zhenyu Wu,Angyuan Ma,Xiuwei Xu,Hang Yin,Yinan Liang,Ziwei Wang,Jiwen Lu,Haibin Yan*

Main category: cs.RO

TL;DR: MoTo是一个即插即用的模块，可与任何现成的操作基础模型结合，赋予其移动操作能力，通过视觉语言模型和交互感知导航实现零样本移动操作


<details>
  <summary>Details</summary>
Motivation: 传统移动操作方法由于缺乏大规模训练而难以在不同任务和环境间泛化，现有的操作基础模型虽然泛化能力强但仅限于固定基座设置

Method: 提出交互感知导航策略生成机器人对接点，通过多视图一致的视觉语言模型框架生成交互关键点，结合运动规划目标最小化关键点距离并保持轨迹可行性

Result: 在OVMM和真实世界实验中，MoTo比最先进的移动操作方法分别提高了2.68%和16.67%的成功率，且无需额外训练数据

Conclusion: MoTo成功实现了零样本移动操作，无需移动操作专家数据，为移动操作领域提供了有效的即插即用解决方案

Abstract: Mobile manipulation stands as a core challenge in robotics, enabling robots
to assist humans across varied tasks and dynamic daily environments.
Conventional mobile manipulation approaches often struggle to generalize across
different tasks and environments due to the lack of large-scale training.
However, recent advances in manipulation foundation models demonstrate
impressive generalization capability on a wide range of fixed-base manipulation
tasks, which are still limited to a fixed setting. Therefore, we devise a
plug-in module named MoTo, which can be combined with any off-the-shelf
manipulation foundation model to empower them with mobile manipulation ability.
Specifically, we propose an interaction-aware navigation policy to generate
robot docking points for generalized mobile manipulation. To enable zero-shot
ability, we propose an interaction keypoints framework via vision-language
models (VLM) under multi-view consistency for both target object and robotic
arm following instructions, where fixed-base manipulation foundation models can
be employed. We further propose motion planning objectives for the mobile base
and robot arm, which minimize the distance between the two keypoints and
maintain the physical feasibility of trajectories. In this way, MoTo guides the
robot to move to the docking points where fixed-base manipulation can be
successfully performed, and leverages VLM generation and trajectory
optimization to achieve mobile manipulation in a zero-shot manner, without any
requirement on mobile manipulation expert data. Extensive experimental results
on OVMM and real-world demonstrate that MoTo achieves success rates of 2.68%
and 16.67% higher than the state-of-the-art mobile manipulation methods,
respectively, without requiring additional training data.

</details>


### [56] [Articulated Object Estimation in the Wild](https://arxiv.org/abs/2509.01708)
*Abdelrhman Werby,Martin Büchner,Adrian Röfer,Chenguang Huang,Wolfram Burgard,Abhinav Valada*

Main category: cs.RO

TL;DR: ArtiPoint是一个新颖的框架，通过结合深度点跟踪和因子图优化，从原始RGB-D视频中估计铰接物体的运动模型，在动态相机运动和部分观测条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有铰接物体估计方法主要依赖固定相机视角或直接观测物体状态，在无约束环境中容易失败。受人类通过观察他人操作物体来推断铰接关系的启发，需要开发能在动态相机和部分观测条件下工作的新方法。

Method: 结合深度点跟踪和因子图优化框架，直接从原始RGB-D视频中估计铰接部件轨迹和铰接轴。同时创建了首个自我中心视角的野外数据集Arti4D，包含铰接标签和真实相机位姿。

Result: 在Arti4D数据集上对多种经典和学习基线方法进行基准测试，证明ArtiPoint具有优越性能。

Conclusion: ArtiPoint能够有效处理动态相机运动和部分观测条件下的铰接物体估计问题，为未来研究提供了新的数据集和方法框架。

Abstract: Understanding the 3D motion of articulated objects is essential in robotic
scene understanding, mobile manipulation, and motion planning. Prior methods
for articulation estimation have primarily focused on controlled settings,
assuming either fixed camera viewpoints or direct observations of various
object states, which tend to fail in more realistic unconstrained environments.
In contrast, humans effortlessly infer articulation by watching others
manipulate objects. Inspired by this, we introduce ArtiPoint, a novel
estimation framework that can infer articulated object models under dynamic
camera motion and partial observability. By combining deep point tracking with
a factor graph optimization framework, ArtiPoint robustly estimates articulated
part trajectories and articulation axes directly from raw RGB-D videos. To
foster future research in this domain, we introduce Arti4D, the first
ego-centric in-the-wild dataset that captures articulated object interactions
at a scene level, accompanied by articulation labels and ground-truth camera
poses. We benchmark ArtiPoint against a range of classical and learning-based
baselines, demonstrating its superior performance on Arti4D. We make code and
Arti4D publicly available at https://artipoint.cs.uni-freiburg.de.

</details>


### [57] [Constrained Decoding for Robotics Foundation Models](https://arxiv.org/abs/2509.01728)
*Parv Kapoor,Akila Ganlath,Changliu Liu,Sebastian Scherer,Eunsuk Kang*

Main category: cs.RO

TL;DR: 提出了一种用于机器人基础模型的约束解码框架，通过在运行时强制执行信号时序逻辑规范来确保行为正确性和安全性，无需重新训练模型。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人基础模型虽然具有端到端和通用能力，但缺乏明确的行为正确性和安全约束概念，因为它们是纯数据驱动的。

Method: 开发了约束解码框架，在动作轨迹生成时强制执行信号时序逻辑（STL）规范，该方法与底层基础模型无关，在解码时进行干预。

Result: 在多个先进导航基础模型上进行了全面评估，证明该方法不仅能过滤不安全动作，还能用于条件动作生成。

Conclusion: 该方法为机器人基础模型提供了可证明的安全保证，同时保持了模型的泛化能力，无需重新训练即可实现运行时安全约束。

Abstract: Recent advances in the development of robotic foundation models have led to
promising end-to-end and general-purpose capabilities in robotic systems. These
models are pretrained on vast datasets of robot trajectories to process multi-
modal inputs and directly output a sequence of action that the system then
executes in the real world. Although this approach is attractive from the
perspective of im- proved generalization across diverse tasks, these models are
still data-driven and, therefore, lack explicit notions of behavioral
correctness and safety constraints. We address these limitations by introducing
a constrained decoding framework for robotics foundation models that enforces
logical constraints on action trajec- tories in dynamical systems. Our method
ensures that generated actions provably satisfy signal temporal logic (STL)
specifications at runtime without retraining, while remaining agnostic of the
underlying foundation model. We perform com- prehensive evaluation of our
approach across state-of-the-art navigation founda- tion models and we show
that our decoding-time interventions are useful not only for filtering unsafe
actions but also for conditional action-generation. Videos available on our
website: https://constrained-robot-fms.github.io

</details>


### [58] [Fail2Progress: Learning from Real-World Robot Failures with Stein Variational Inference](https://arxiv.org/abs/2509.01746)
*Yixuan Huang,Novella Alvina,Mohanraj Devendran Shanthi,Tucker Hermans*

Main category: cs.RO

TL;DR: Fail2Progress利用Stein变分推理并行生成多个模拟环境，针对观察到的失败情况高效生成训练数据，从而提升技能效果模型在长时程操作任务中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 长时程操作任务的技能效果模型在训练数据分布未覆盖的条件下容易失败，需要让机器人能够从失败中推理和学习。

Method: 提出Fail2Progress方法，利用Stein变分推理并行生成多个模拟环境，针对观察到的失败高效生成数据集，然后对技能效果模型进行微调。

Result: 方法能够处理多个具有挑战性的移动操作任务，包括运输多个物体、整理受限货架和桌面整理。在大规模模拟和真实世界实验中表现出色，能够从不同数量物体的失败中学习。

Conclusion: Fail2Progress在从失败中学习方面优于多个基线方法，能够有效恢复模型性能并最小化未来失败。

Abstract: Skill effect models for long-horizon manipulation tasks are prone to failures
in conditions not covered by training data distributions. Therefore, enabling
robots to reason about and learn from failures is necessary. We investigate the
problem of efficiently generating a dataset targeted to observed failures.
After fine-tuning a skill effect model on this dataset, we evaluate the extent
to which the model can recover from failures and minimize future failures. We
propose Fail2Progress, an approach that leverages Stein variational inference
to generate multiple simulation environments in parallel, enabling efficient
data sample generation similar to observed failures. Our method is capable of
handling several challenging mobile manipulation tasks, including transporting
multiple objects, organizing a constrained shelf, and tabletop organization.
Through large-scale simulation and real-world experiments, we demonstrate that
our approach excels at learning from failures across different numbers of
objects. Furthermore, we show that Fail2Progress outperforms several baselines.

</details>


### [59] [Non-conflicting Energy Minimization in Reinforcement Learning based Robot Control](https://arxiv.org/abs/2509.01765)
*Skand Peri,Akhil Perincherry,Bikram Pandit,Stefan Lee*

Main category: cs.RO

TL;DR: 提出一种无超参数的梯度优化方法，通过策略梯度投影在任务和能量目标之间进行优化，在不影响任务性能的前提下减少64%的能耗


<details>
  <summary>Details</summary>
Motivation: 传统RL方法通过奖励函数惩罚能量使用需要仔细调整权重，容易导致能量最小化与任务成功之间的不良权衡

Method: 基于多任务学习的策略梯度投影方法，在任务和能量目标之间推导策略更新，以不影响任务性能的方式最小化能量消耗

Result: 在DM-Control和HumanoidBench标准运动基准测试中实现64%的能量使用减少，同时保持可比较的任务性能，并在Unitree GO2四足机器人上展示了Sim2Real迁移

Conclusion: 该方法易于在标准RL流程中实现，适用于任何策略梯度方法，为节能控制策略提供了基于原则的替代方案

Abstract: Efficient robot control often requires balancing task performance with energy
expenditure. A common approach in reinforcement learning (RL) is to penalize
energy use directly as part of the reward function. This requires carefully
tuning weight terms to avoid undesirable trade-offs where energy minimization
harms task success. In this work, we propose a hyperparameter-free gradient
optimization method to minimize energy expenditure without conflicting with
task performance. Inspired by recent works in multitask learning, our method
applies policy gradient projection between task and energy objectives to derive
policy updates that minimize energy expenditure in ways that do not impact task
performance. We evaluate this technique on standard locomotion benchmarks of
DM-Control and HumanoidBench and demonstrate a reduction of 64% energy usage
while maintaining comparable task performance. Further, we conduct experiments
on a Unitree GO2 quadruped showcasing Sim2Real transfer of energy efficient
policies. Our method is easy to implement in standard RL pipelines with minimal
code changes, is applicable to any policy gradient method, and offers a
principled alternative to reward shaping for energy efficient control policies.

</details>


### [60] [ManiFlow: A General Robot Manipulation Policy via Consistency Flow Training](https://arxiv.org/abs/2509.01819)
*Ge Yan,Jiyue Zhu,Yuquan Deng,Shiqi Yang,Ri-Zhao Qiu,Xuxin Cheng,Marius Memmel,Ranjay Krishna,Ankit Goyal,Xiaolong Wang,Dieter Fox*

Main category: cs.RO

TL;DR: ManiFlow是一个基于流匹配和一致性训练的视觉运动模仿学习策略，能够通过1-2次推理步骤生成精确的高维动作，支持多模态输入并显著提升机器人操作任务的成功率。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人操作中需要处理多样化视觉、语言和本体感觉输入，并生成精确高维动作的挑战，同时提高推理效率和处理多模态信息的能力。

Method: 采用流匹配与一致性训练相结合的方法，提出DiT-X扩散变换器架构，具有自适应交叉注意力和AdaLN-Zero条件机制，实现动作标记与多模态观测之间的细粒度特征交互。

Result: 在多样化仿真基准测试中表现一致提升，在真实世界任务中成功率几乎翻倍，涵盖单臂、双手和人形机器人设置，对新颖物体和背景变化展现出强鲁棒性和泛化能力。

Conclusion: ManiFlow通过高效的流匹配方法和创新的多模态处理架构，显著提升了机器人操作任务的性能，展示了强大的扩展能力和泛化性能。

Abstract: This paper introduces ManiFlow, a visuomotor imitation learning policy for
general robot manipulation that generates precise, high-dimensional actions
conditioned on diverse visual, language and proprioceptive inputs. We leverage
flow matching with consistency training to enable high-quality dexterous action
generation in just 1-2 inference steps. To handle diverse input modalities
efficiently, we propose DiT-X, a diffusion transformer architecture with
adaptive cross-attention and AdaLN-Zero conditioning that enables fine-grained
feature interactions between action tokens and multi-modal observations.
ManiFlow demonstrates consistent improvements across diverse simulation
benchmarks and nearly doubles success rates on real-world tasks across
single-arm, bimanual, and humanoid robot setups with increasing dexterity. The
extensive evaluation further demonstrates the strong robustness and
generalizability of ManiFlow to novel objects and background changes, and
highlights its strong scaling capability with larger-scale datasets. Our
website: maniflow-policy.github.io.

</details>


### [61] [Multi-vessel Interaction-Aware Trajectory Prediction and Collision Risk Assessment](https://arxiv.org/abs/2509.01836)
*Md Mahbub Alam,Jose F. Rodrigues-Jr,Gabriel Spadon*

Main category: cs.RO

TL;DR: 提出基于Transformer的多船舶轨迹预测框架，集成碰撞风险分析，通过并行编码运动特征、因果卷积和空间变换，在真实AIS数据上展现优越性能


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动模型主要局限于单船舶预测，忽略了船舶交互、航行规则和显式碰撞风险评估，需要更全面的多船舶轨迹预测方案

Method: 基于Transformer的框架，通过并行流编码运动学和物理特征，使用因果卷积处理时间局部性，空间变换进行位置编码，混合位置嵌入捕获局部运动模式和长程依赖

Result: 在大规模真实AIS数据上评估，使用联合多船舶指标，模型展现出超越传统单船舶位移误差的优越预测能力

Conclusion: 通过预测轨迹间的交互模拟，框架能量化潜在碰撞风险，为增强海上安全和决策支持提供可操作的见解

Abstract: Accurate vessel trajectory prediction is essential for enhancing situational
awareness and preventing collisions. Still, existing data-driven models are
constrained mainly to single-vessel forecasting, overlooking vessel
interactions, navigation rules, and explicit collision risk assessment. We
present a transformer-based framework for multi-vessel trajectory prediction
with integrated collision risk analysis. For a given target vessel, the
framework identifies nearby vessels. It jointly predicts their future
trajectories through parallel streams encoding kinematic and derived physical
features, causal convolutions for temporal locality, spatial transformations
for positional encoding, and hybrid positional embeddings that capture both
local motion patterns and long-range dependencies. Evaluated on large-scale
real-world AIS data using joint multi-vessel metrics, the model demonstrates
superior forecasting capabilities beyond traditional single-vessel displacement
errors. By simulating interactions among predicted trajectories, the framework
further quantifies potential collision risks, offering actionable insights to
strengthen maritime safety and decision support.

</details>


### [62] [AI-Driven Marine Robotics: Emerging Trends in Underwater Perception and Ecosystem Monitoring](https://arxiv.org/abs/2509.01878)
*Scarlett Raine,Tobias Fischer*

Main category: cs.RO

TL;DR: 海洋人工智能快速发展，通过弱监督学习、开放集识别等技术解决水下直观挑战，为计算机视觉和环境监测带来重大创新。


<details>
  <summary>Details</summary>
Motivation: 海洋生态系统面临气候变化压力，需要可扩展的AI监测方案。水下AI从小众应用转化为AI创新的点燃前沿。

Method: 识别三大驱动因素：环境监测需求、水下数据集民主化、研究人员从陆地视觉领域转移。分析水下特有挑战如浮江物、隐藏物种检测等对AI技术的驱动作用。

Result: 水下特有限制来动基础模型、自监督学习和视觉技术的边界推进。方法论创新不仅有益海洋应用，还惠及普通计算机视觉、机器人学和环境监测领域。

Conclusion: 水下AI已成为重要研究前沿，其特有挑战正驱动AI核心技术的基础性进步，从被动观测向主动干预能力转变，具有跨领域的重大影响。

Abstract: Marine ecosystems face increasing pressure due to climate change, driving the
need for scalable, AI-powered monitoring solutions. This paper examines the
rapid emergence of underwater AI as a major research frontier and analyzes the
factors that have transformed marine perception from a niche application into a
catalyst for AI innovation. We identify three convergent drivers: environmental
necessity for ecosystem-scale monitoring, democratization of underwater
datasets through citizen science platforms, and researcher migration from
saturated terrestrial computer vision domains. Our analysis reveals how unique
underwater challenges - turbidity, cryptic species detection, expert annotation
bottlenecks, and cross-ecosystem generalization - are driving fundamental
advances in weakly supervised learning, open-set recognition, and robust
perception under degraded conditions. We survey emerging trends in datasets,
scene understanding and 3D reconstruction, highlighting the paradigm shift from
passive observation toward AI-driven, targeted intervention capabilities. The
paper demonstrates how underwater constraints are pushing the boundaries of
foundation models, self-supervised learning, and perception, with
methodological innovations that extend far beyond marine applications to
benefit general computer vision, robotics, and environmental monitoring.

</details>


### [63] [AutoDrive-R$^2$: Incentivizing Reasoning and Self-Reflection Capacity for VLA Model in Autonomous Driving](https://arxiv.org/abs/2509.01944)
*Zhenlong Yuan,Jing Tang,Jinguo Luo,Rui Chen,Chengxuan Qian,Lei Sun,Xiangxiang Chu,Yujun Cai,Dapeng Zhang,Shuo Li*

Main category: cs.RO

TL;DR: AutoDrive-R²是一个新颖的视觉-语言-动作框架，通过思维链处理和强化学习提升自动驾驶系统的推理和自反思能力，在nuScenes和Waymo数据集上表现出最先进的性能和强大泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统中的VLA模型在决策过程的可解释性、连贯性以及动作序列的合理性方面研究不足，需要解决这些问题。

Method: 提出四步逻辑链的自反思验证方法构建认知桥梁，使用GRPO算法在包含空间对齐、车辆动力学和时间平滑度标准的物理基础奖励框架中进行强化学习。

Result: 在nuScenes和Waymo数据集上的广泛评估表明，该方法具有最先进的性能和强大的泛化能力。

Conclusion: AutoDrive-R²框架通过结合思维链处理和强化学习，有效提升了自动驾驶系统的推理和自反思能力，为VLA模型在自动驾驶领域的应用提供了新的解决方案。

Abstract: Vision-Language-Action (VLA) models in autonomous driving systems have
recently demonstrated transformative potential by integrating multimodal
perception with decision-making capabilities. However, the interpretability and
coherence of the decision process and the plausibility of action sequences
remain largely underexplored. To address these issues, we propose
AutoDrive-R$^2$, a novel VLA framework that enhances both reasoning and
self-reflection capabilities of autonomous driving systems through
chain-of-thought (CoT) processing and reinforcement learning (RL).
Specifically, we first propose an innovative CoT dataset named nuScenesR$^2$-6K
for supervised fine-tuning, which effectively builds cognitive bridges between
input information and output trajectories through a four-step logical chain
with self-reflection for validation. Moreover, to maximize both reasoning and
self-reflection during the RL stage, we further employ the Group Relative
Policy Optimization (GRPO) algorithm within a physics-grounded reward framework
that incorporates spatial alignment, vehicle dynamic, and temporal smoothness
criteria to ensure reliable and realistic trajectory planning. Extensive
evaluation results across both nuScenes and Waymo datasets demonstrates the
state-of-the-art performance and robust generalization capacity of our proposed
method.

</details>


### [64] [Hybrid Autonomy Framework for a Future Mars Science Helicopter](https://arxiv.org/abs/2509.01980)
*Luca Di Pierno,Robert Hewitt,Stephan Weiss,Roland Brockers*

Main category: cs.RO

TL;DR: 本文提出了一种用于火星科学直升机自主探索的确定性高层控制框架，结合有限状态机和行为树，实现了可扩展、鲁棒且计算高效的自主解决方案。


<details>
  <summary>Details</summary>
Motivation: 由于地球-火星通信延迟显著且任务复杂，需要先进的自主框架来确保火星科学直升机在无人干预的情况下，根据任务目标和实时条件持续调整行为，实现安全高效操作。

Method: 采用有限状态机（FSM）与行为树（BTs）混合的自主框架，通过蒙特卡洛模拟和实际场地测试进行验证，支持中间件无关的集成。

Result: 框架验证显示其具有鲁棒性和适应性，能够对离散事件和实时系统反馈做出反应，触发状态转换或动态调整行为执行。

Conclusion: 该FSM-BT混合自主框架为深空探索等关键场景提供了有效的自主解决方案，具有可扩展性和通用性，可扩展到航空机器人之外的领域。

Abstract: Autonomous aerial vehicles, such as NASA's Ingenuity, enable rapid planetary
surface exploration beyond the reach of ground-based robots. Thus, NASA is
studying a Mars Science Helicopter (MSH), an advanced concept capable of
performing long-range science missions and autonomously navigating challenging
Martian terrain. Given significant Earth-Mars communication delays and mission
complexity, an advanced autonomy framework is required to ensure safe and
efficient operation by continuously adapting behavior based on mission
objectives and real-time conditions, without human intervention. This study
presents a deterministic high-level control framework for aerial exploration,
integrating a Finite State Machine (FSM) with Behavior Trees (BTs) to achieve a
scalable, robust, and computationally efficient autonomy solution for critical
scenarios like deep space exploration. In this paper we outline key
capabilities of a possible MSH and detail the FSM-BT hybrid autonomy framework
which orchestrates them to achieve the desired objectives. Monte Carlo
simulations and real field tests validate the framework, demonstrating its
robustness and adaptability to both discrete events and real-time system
feedback. These inputs trigger state transitions or dynamically adjust behavior
execution, enabling reactive and context-aware responses. The framework is
middleware-agnostic, supporting integration with systems like F-Prime and
extending beyond aerial robotics.

</details>


### [65] [Geometric Control of Mechanical Systems with Symmetries Based on Sliding Modes](https://arxiv.org/abs/2509.01985)
*Eduardo Espindola,Yu Tang*

Main category: cs.RO

TL;DR: 提出了一个基于主纤维丛的机械系统滑模控制框架，利用对称性简化设计，在基空间执行趋近阶段，在结构群执行滑动阶段。


<details>
  <summary>Details</summary>
Motivation: 针对具有对称性的机械系统，传统滑模控制设计复杂且需要处理特定李群的坐标表示问题，需要一种更简洁有效的控制方法。

Method: 基于降阶运动方程，在结构群上构建滑动子群，在基空间设计基于滑动向量场的趋近律，利用机械连接的局部形式驱动滑动变量。

Result: 证明了几乎全局渐近稳定性和局部指数稳定性，并成功应用于全驱动系统（刚性航天器）和欠驱动非完整系统（独轮车移动机器人）。

Conclusion: 该框架有效降低了设计复杂度，避免了坐标表示的困难选择，为对称机械系统的滑模控制提供了系统化的解决方案。

Abstract: In this paper, we propose a framework for designing sliding mode controllers
for a class of mechanical systems with symmetry, both unconstrained and
constrained, that evolve on principal fiber bundles. Control laws are developed
based on the reduced motion equations by exploring symmetries, leading to a
sliding mode control strategy where the reaching stage is executed on the base
space, and the sliding stage is performed on the structure group. Thus, design
complexity is reduced, and difficult choices for coordinate representations
when working with a particular Lie group are avoided. For this purpose, a
sliding subgroup is constructed on the structure group based on a kinematic
controller, and the sliding variable will converge to the identity of the state
manifold upon reaching the sliding subgroup. A reaching law based on a general
sliding vector field is then designed on the base space using the local form of
the mechanical connection to drive the sliding variable to the sliding
subgroup, and its time evolution is given according to the appropriate
covariant derivative. Almost global asymptotic stability and local exponential
stability are demonstrated using a Lyapunov analysis. We apply the results to a
fully actuated system (a rigid spacecraft actuated by reaction wheels) and a
subactuated nonholonomic system (unicycle mobile robot actuated by wheels),
which is also simulated for illustration.

</details>


### [66] [MIRAGE: Multimodal Intention Recognition and Admittance-Guided Enhancement in VR-based Multi-object Teleoperation](https://arxiv.org/abs/2509.01996)
*Chi Sun,Xian Wang,Abhishek Kumar,Chengbin Cui,Lik-Hang Lee*

Main category: cs.RO

TL;DR: 提出结合虚拟导纳模型和多模态CNN意图感知网络的共享控制框架，通过多模态输入和人工势场引导，显著提升VR遥操作中的抓取成功率和运动效率


<details>
  <summary>Details</summary>
Motivation: 解决VR环境中多目标遥操作任务的感知模糊性和单模态意图识别局限性问题

Method: 虚拟导纳模型使用人工势场引导操作者，优化运动轨迹；多模态CNN网络处理注视、机器人运动和环境上下文等多模态输入来估计抓取意图

Result: MMIPN显著提高抓取成功率，VA模型通过减少路径长度提升运动效率，注视数据是最重要的输入模态

Conclusion: 多模态线索与隐式引导相结合在VR遥操作中有效，为多目标抓取任务提供鲁棒解决方案，实现更自然的交互

Abstract: Effective human-robot interaction (HRI) in multi-object teleoperation tasks
faces significant challenges due to perceptual ambiguities in virtual reality
(VR) environments and the limitations of single-modality intention recognition.
This paper proposes a shared control framework that combines a virtual
admittance (VA) model with a Multimodal-CNN-based Human Intention Perception
Network (MMIPN) to enhance teleoperation performance and user experience. The
VA model employs artificial potential fields to guide operators toward target
objects by adjusting admittance force and optimizing motion trajectories. MMIPN
processes multimodal inputs, including gaze movement, robot motions, and
environmental context, to estimate human grasping intentions, helping to
overcome depth perception challenges in VR. Our user study evaluated four
conditions across two factors, and the results showed that MMIPN significantly
improved grasp success rates, while the VA model enhanced movement efficiency
by reducing path lengths. Gaze data emerged as the most crucial input modality.
These findings demonstrate the effectiveness of combining multimodal cues with
implicit guidance in VR-based teleoperation, providing a robust solution for
multi-object grasping tasks and enabling more natural interactions across
various applications in the future.

</details>


### [67] [Generalizing Unsupervised Lidar Odometry Model from Normal to Snowy Weather Conditions](https://arxiv.org/abs/2509.02011)
*Beibei Zhou,Zhiyuan Zhang,Zhenbo Song,Jianhui Guo,Hui Kong*

Main category: cs.RO

TL;DR: 提出了一种无监督激光雷达里程计模型，通过有效的去噪和自适应权重分配，在雪天等恶劣天气条件下实现稳健的位姿估计，解决了现有模型对雪噪声敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的激光雷达里程计在雪天等恶劣天气条件下性能下降严重，对雪噪声敏感导致泛化能力不足，限制了实际应用。需要开发能够在各种天气条件下稳定工作的解决方案。

Method: 提出Patch Spatial Measure模块评估点云分散度检测稀疏噪声，Patch Point Weight Predictor分配自适应点级权重增强判别能力。采用强度阈值掩码快速抑制密集雪簇，多模态特征融合优化权重预测。

Result: 模型在晴朗天气训练，在雪天和动态场景等多种条件下测试，实验结果表明该方法在晴朗和雪天天气下均表现出稳健性能，提高了模型的泛化能力。

Conclusion: 该方法通过有效的去噪和自适应权重分配机制，显著提升了激光雷达里程计在恶劣天气条件下的性能，为更可靠的自主系统在更广泛环境条件下的运行奠定了基础。

Abstract: Deep learning-based LiDAR odometry is crucial for autonomous driving and
robotic navigation, yet its performance under adverse weather, especially
snowfall, remains challenging. Existing models struggle to generalize across
conditions due to sensitivity to snow-induced noise, limiting real-world use.
In this work, we present an unsupervised LiDAR odometry model to close the gap
between clear and snowy weather conditions. Our approach focuses on effective
denoising to mitigate the impact of snowflake noise and outlier points on pose
estimation, while also maintaining computational efficiency for real-time
applications.
  To achieve this, we introduce a Patch Spatial Measure (PSM) module that
evaluates the dispersion of points within each patch, enabling effective
detection of sparse and discrete noise.
  We further propose a Patch Point Weight Predictor (PPWP) to assign adaptive
point-wise weights, enhancing their discriminative capacity within local
regions. To support real-time performance, we first apply an intensity
threshold mask to quickly suppress dense snowflake clusters near the LiDAR, and
then perform multi-modal feature fusion to refine the point-wise weight
prediction, improving overall robustness under adverse weather. Our model is
trained in clear weather conditions and rigorously tested across various
scenarios, including snowy and dynamic. Extensive experimental results confirm
the effectiveness of our method, demonstrating robust performance in both clear
and snowy weather. This advancement enhances the model's generalizability and
paves the way for more reliable autonomous systems capable of operating across
a wider range of environmental conditions.

</details>


### [68] [Align-Then-stEer: Adapting the Vision-Language Action Models through Unified Latent Guidance](https://arxiv.org/abs/2509.02055)
*Yang Zhang,Chenwei Wang,Ouyang Lu,Yuan Zhao,Yunfei Ge,Zhenglong Sun,Xiu Li,Chi Zhang,Chenjia Bai,Xuelong Li*

Main category: cs.RO

TL;DR: ATE是一个数据高效的即插即用适配框架，通过构建统一潜在空间和对齐动作分布来解决VLA模型在下游任务中的适配问题，显著提升跨机器人和跨任务的操作性能


<details>
  <summary>Details</summary>
Motivation: VLA模型在预训练后适配下游任务时存在动作分布不匹配问题，需要大量数据和计算资源进行微调，限制了实际部署的实用性

Method: ATE框架首先通过变分自编码器和反向KL散度构建统一潜在空间来对齐不同动作空间，然后通过引导机制在微调过程中将模型输出分布推向目标域

Result: 在仿真环境中平均多任务成功率提升9.8%，在真实世界跨机器人设置中获得32%的成功率增益

Conclusion: ATE提供了一个通用且轻量级的解决方案，大大增强了VLA模型在新机器人平台和任务中部署的实用性

Abstract: Vision-Language-Action (VLA) models pre-trained on large, diverse datasets
show remarkable potential for general-purpose robotic manipulation. However, a
primary bottleneck remains in adapting these models to downstream tasks,
especially when the robot's embodiment or the task itself differs from the
pre-training data. This discrepancy leads to a significant mismatch in action
distributions, demanding extensive data and compute for effective fine-tuning.
To address this challenge, we introduce \textbf{Align-Then-stEer
(\texttt{ATE})}, a novel, data-efficient, and plug-and-play adaptation
framework. \texttt{ATE} first aligns disparate action spaces by constructing a
unified latent space, where a variational autoencoder constrained by reverse KL
divergence embeds adaptation actions into modes of the pre-training action
latent distribution. Subsequently, it steers the diffusion- or flow-based VLA's
generation process during fine-tuning via a guidance mechanism that pushes the
model's output distribution towards the target domain. We conduct extensive
experiments on cross-embodiment and cross-task manipulation in both simulation
and real world. Compared to direct fine-tuning of representative VLAs, our
method improves the average multi-task success rate by up to \textbf{9.8\%} in
simulation and achieves a striking \textbf{32\% success rate gain} in a
real-world cross-embodiment setting. Our work presents a general and
lightweight solution that greatly enhances the practicality of deploying VLA
models to new robotic platforms and tasks.

</details>


### [69] [A Geometric Method for Base Parameter Analysis in Robot Inertia Identification Based on Projective Geometric Algebra](https://arxiv.org/abs/2509.02071)
*Guangzhen Sun,Ye Ding,Xiangyang Zhu*

Main category: cs.RO

TL;DR: 提出了一种基于投影几何代数的新型几何方法，用于分析确定机器人系统的基础惯性参数，开发了具有几何解释的闭合形式识别模型和高效算法。


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统基础惯性参数识别方法缺乏几何直观性且计算效率有限，特别是在复杂并联机构中。需要一种具有清晰几何解释且计算高效的分析方法。

Method: 使用投影几何代数重构刚体动力学，提出四面体点(TP)模型，基于三个基本原理（共享点、固定点、平面旋转）开发DRNG算法，实现O(1)复杂度分析。

Result: 在Puma560、Unitree Go2和两种并联机构上成功验证，算法能完整识别所有基础参数，表现出高鲁棒性和计算效率，特别适用于并联机构。

Conclusion: 该方法具有通用性、鲁棒性和高效性，为机器人系统基础参数识别提供了几何直观且计算高效的解决方案，特别在复杂机构中优势明显。

Abstract: This paper proposes a novel geometric method for analytically determining the
base inertial parameters of robotic systems. The rigid body dynamics is
reformulated using projective geometric algebra, leading to a new
identification model named ``tetrahedral-point (TP)" model. Based on the rigid
body TP model, coefficients in the regresoor matrix of the identification model
are derived in closed-form, exhibiting clear geometric interpretations.
Building directly from the dynamic model, three foundational principles for
base parameter analysis are proposed: the shared points principle, fixed points
principle, and planar rotations principle. With these principles, algorithms
are developed to automatically determine all the base parameters. The core
algorithm, referred to as Dynamics Regressor Nullspace Generator (DRNG),
achieves $O(1)$-complexity theoretically following an $O(N)$-complexity
preprocessing stage, where $N$ is the number of rigid bodies. The proposed
method and algorithms are validated across four robots: Puma560, Unitree Go2, a
2RRU-1RRS parallel kinematics mechanism (PKM), and a 2PRS-1PSR PKM. In all
cases, the algorithms successfully identify the complete set of base
parameters. Notably, the approach demonstrates high robustness and
computational efficiency, particularly in the cases of PKMs. Through the
comprehensive demonstrations, the method is shown to be general, robust, and
efficient.

</details>


### [70] [Learning Social Heuristics for Human-Aware Path Planning](https://arxiv.org/abs/2509.02134)
*Andrea Eirale,Matteo Leonetti,Marcello Chiaberge*

Main category: cs.RO

TL;DR: 学习社交导航价值函数作为启发式搜索的额外启发函数，用于排队等社交场景的路径规划


<details>
  <summary>Details</summary>
Motivation: 传统导航方法无法满足真正的社交接受度，机器人需要学习特定的社交规范

Method: 提出HPLSV方法，学习社交导航的价值函数，并将其作为启发式搜索路径规划的额外启发函数

Result: 初步应用于排队场景，计划推广到更多人类活动

Conclusion: 该方法能够使机器人学习并遵守社交规范，提高社交接受度

Abstract: Social robotic navigation has been at the center of numerous studies in
recent years. Most of the research has focused on driving the robotic agent
along obstacle-free trajectories, respecting social distances from humans, and
predicting their movements to optimize navigation. However, in order to really
be socially accepted, the robots must be able to attain certain social norms
that cannot arise from conventional navigation, but require a dedicated
learning process. We propose Heuristic Planning with Learned Social Value
(HPLSV), a method to learn a value function encapsulating the cost of social
navigation, and use it as an additional heuristic in heuristic-search path
planning. In this preliminary work, we apply the methodology to the common
social scenario of joining a queue of people, with the intention of
generalizing to further human activities.

</details>


### [71] [Systematic Evaluation of Trade-Offs in Motion Planning Algorithms for Optimal Industrial Robotic Work Cell Design](https://arxiv.org/abs/2509.02146)
*G. de Mathelin,C. Hartl-Nesic,A. Kugi*

Main category: cs.RO

TL;DR: 本文提出评估工业机器人工作单元双层优化中运动规划权衡的指标，通过仿真研究分析运动级简化对高层优化的影响，并在码垛场景中应用算法寻找模块化机器人的时间最优运动学设计


<details>
  <summary>Details</summary>
Motivation: 工业机器人工作单元性能优化需要双层优化方法，但计算最优机器人运动不可行，需要在运动规划中做出权衡，这些权衡对整体性能影响重大但缺乏系统评估

Method: 引入评估运动规划权衡的指标（最优性、时间增益、鲁棒性、一致性），通过大量仿真研究分析运动级优化简化对高层优化结果的影响

Result: 在两种码垛场景中应用所提算法，成功找到模块化机器人的时间最优运动学设计

Conclusion: 系统评估运动规划权衡对工业机器人工作单元双层优化性能至关重要，提出的指标和方法能够有效平衡计算复杂度和解的质量

Abstract: The performance of industrial robotic work cells depends on optimizing
various hyperparameters referring to the cell layout, such as robot base
placement, tool placement, and kinematic design. Achieving this requires a
bilevel optimization approach, where the high-level optimization adjusts these
hyperparameters, and the low-level optimization computes robot motions.
However, computing the optimal robot motion is computationally infeasible,
introducing trade-offs in motion planning to make the problem tractable. These
trade-offs significantly impact the overall performance of the bilevel
optimization, but their effects still need to be systematically evaluated. In
this paper, we introduce metrics to assess these trade-offs regarding
optimality, time gain, robustness, and consistency. Through extensive
simulation studies, we investigate how simplifications in motion-level
optimization affect the high-level optimization outcomes, balancing
computational complexity with solution quality. The proposed algorithms are
applied to find the time-optimal kinematic design for a modular robot in two
palletization scenarios.

</details>


### [72] [Enhancing Reliability in LLM-Integrated Robotic Systems: A Unified Approach to Security and Safety](https://arxiv.org/abs/2509.02163)
*Wenxiao Zhang,Xiangrui Kong,Conan Dewitt,Thomas Bräunl,Jin B. Hong*

Main category: cs.RO

TL;DR: 通过统一框架缩减LLM机器人系统的提示注入攻击并提高操作安全性，在对抗性条件下表现显著提升


<details>
  <summary>Details</summary>
Motivation: 解决LLM机器人系统在安全性和安全性方面的可靠性挑战，应对恶意攻击和复杂环境中的风险

Method: 提出统一框架，结合提示组装、状态管理和安全验证机制，通过性能和安全指标进行评估

Result: 实验显示在注入攻击下性能提升30.8%，在复杂环境下对抗性条件中提升达325%，较基准情景显著改善

Conclusion: 该工作填补了LLM机器人系统安全性与安全性之间的空白，为实际部署可靠的LLM集成移动机器人提供了可行见解

Abstract: Integrating large language models (LLMs) into robotic systems has
revolutionised embodied artificial intelligence, enabling advanced
decision-making and adaptability. However, ensuring reliability, encompassing
both security against adversarial attacks and safety in complex environments,
remains a critical challenge. To address this, we propose a unified framework
that mitigates prompt injection attacks while enforcing operational safety
through robust validation mechanisms. Our approach combines prompt assembling,
state management, and safety validation, evaluated using both performance and
security metrics. Experiments show a 30.8% improvement under injection attacks
and up to a 325% improvement in complex environment settings under adversarial
conditions compared to baseline scenarios. This work bridges the gap between
safety and security in LLM-based robotic systems, offering actionable insights
for deploying reliable LLM-integrated mobile robots in real-world settings. The
framework is open-sourced with simulation and physical deployment demos at
https://llmeyesim.vercel.app/

</details>


### [73] [Adaptive Navigation Strategy for Low-Thrust Proximity Operations in Circular Relative Orbit](https://arxiv.org/abs/2509.02204)
*Dario Ruggiero,Mauro Mancini,Elisa Capello*

Main category: cs.RO

TL;DR: 提出一种基于自适应观测器的航天器圆形相对轨道导航策略，通过动态调整观测器增益实现快速收敛和低噪声敏感度的状态估计


<details>
  <summary>Details</summary>
Motivation: 解决航天器近距离操作（如编队飞行和非合作目标检测）中的导航挑战，传统固定增益观测器在轨迹跟踪精度和控制输入切换方面存在不足

Method: 采用自适应观测器方法，基于估计状态动态调整观测器增益，结合Lyapunov稳定性分析确保系统稳定性和估计精度

Result: 仿真验证表明，相比传统固定增益观测器，该方法显著提高了轨迹跟踪精度，减少了控制输入切换频率

Conclusion: 该自适应观测器导航策略为自主航天器定位和控制提供了有效的解决方案，在现实视觉传感器条件下表现出良好性能

Abstract: This paper presents an adaptive observer-based navigation strategy for
spacecraft in Circular Relative Orbit (CRO) scenarios, addressing challenges in
proximity operations like formation flight and uncooperative target inspection.
The proposed method adjusts observer gains based on the estimated state to
achieve fast convergence and low noise sensitivity in state estimation. A
Lyapunov-based analysis ensures stability and accuracy, while simulations using
vision-based sensor data validate the approach under realistic conditions.
Compared to classical observers with time-invariant gains, the proposed method
enhances trajectory tracking precision and reduces control input switching,
making it a promising solution for autonomous spacecraft localization and
control.

</details>


### [74] [Human-Inspired Soft Anthropomorphic Hand System for Neuromorphic Object and Pose Recognition Using Multimodal Signals](https://arxiv.org/abs/2509.02275)
*Fengyi Wang,Xiangyu Fu,Nitish Thakor,Gordon Cheng*

Main category: cs.RO

TL;DR: 提出了一种配备多模态传感器的仿生软体人手，采用神经形态编码和脉冲神经网络处理多感官数据，在物体识别和材料分类方面取得优异性能


<details>
  <summary>Details</summary>
Motivation: 受人类体感系统整合触觉、本体感觉和温度信号的多模态感知机制启发，旨在为机器人系统实现高效、鲁棒且类人的感知能力

Method: 开发了传感器化的软体仿人手，配备多种传感器模拟人类手部感官模式；采用生物启发的编码方案将多模态感官数据转换为脉冲序列；使用脉冲神经网络进行高效处理；引入新型微分神经元模型捕捉动态热响应

Result: 在不同姿态下实现了97.14%的物体识别准确率，显著优于以往软体手研究；新型微分神经元模型提升了材料分类性能

Conclusion: 多模态感官融合和神经形态方法为机器人系统实现高效、鲁棒且类人的感知提供了巨大潜力

Abstract: The human somatosensory system integrates multimodal sensory feedback,
including tactile, proprioceptive, and thermal signals, to enable comprehensive
perception and effective interaction with the environment. Inspired by the
biological mechanism, we present a sensorized soft anthropomorphic hand
equipped with diverse sensors designed to emulate the sensory modalities of the
human hand. This system incorporates biologically inspired encoding schemes
that convert multimodal sensory data into spike trains, enabling
highly-efficient processing through Spiking Neural Networks (SNNs). By
utilizing these neuromorphic signals, the proposed framework achieves 97.14%
accuracy in object recognition across varying poses, significantly
outperforming previous studies on soft hands. Additionally, we introduce a
novel differentiator neuron model to enhance material classification by
capturing dynamic thermal responses. Our results demonstrate the benefits of
multimodal sensory fusion and highlight the potential of neuromorphic
approaches for achieving efficient, robust, and human-like perception in
robotic systems.

</details>


### [75] [Sem-RaDiff: Diffusion-Based 3D Radar Semantic Perception in Cluttered Agricultural Environments](https://arxiv.org/abs/2509.02283)
*Ruibin Zhang,Fei Gao*

Main category: cs.RO

TL;DR: 提出基于雷达的3D环境感知框架，用于农业场景中机器人导航，通过并行帧积累、扩散模型和稀疏3D网络实现高精度语义感知，在性能和效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于光学传感器（相机、LiDAR）的感知方法在视觉遮挡情况下性能下降或完全失效，特别是在农业场景中传感器易受污染。雷达具有强穿透能力，可作为可靠替代方案。

Method: 1) 并行帧积累增强雷达原始数据信噪比；2) 基于扩散模型的分层学习框架，先过滤雷达旁瓣伪影，再生成细粒度3D语义点云；3) 专门设计的稀疏3D网络处理大规模雷达原始数据。

Result: 在真实农业场景数据集上的实验表明，该方法在结构和语义预测性能上优于现有方法，同时计算和内存成本分别降低51.3%和27.5%，能够完整重建和准确分类细薄结构。

Conclusion: 该方法展示了密集准确3D雷达感知的潜力，特别适用于存在视觉遮挡和传感器污染的农业环境，为机器人自主导航提供了可靠的感知解决方案。

Abstract: Accurate and robust environmental perception is crucial for robot autonomous
navigation. While current methods typically adopt optical sensors (e.g.,
camera, LiDAR) as primary sensing modalities, their susceptibility to visual
occlusion often leads to degraded performance or complete system failure. In
this paper, we focus on agricultural scenarios where robots are exposed to the
risk of onboard sensor contamination. Leveraging radar's strong penetration
capability, we introduce a radar-based 3D environmental perception framework as
a viable alternative. It comprises three core modules designed for dense and
accurate semantic perception: 1) Parallel frame accumulation to enhance
signal-to-noise ratio of radar raw data. 2) A diffusion model-based
hierarchical learning framework that first filters radar sidelobe artifacts
then generates fine-grained 3D semantic point clouds. 3) A specifically
designed sparse 3D network optimized for processing large-scale radar raw data.
We conducted extensive benchmark comparisons and experimental evaluations on a
self-built dataset collected in real-world agricultural field scenes. Results
demonstrate that our method achieves superior structural and semantic
prediction performance compared to existing methods, while simultaneously
reducing computational and memory costs by 51.3% and 27.5%, respectively.
Furthermore, our approach achieves complete reconstruction and accurate
classification of thin structures such as poles and wires-which existing
methods struggle to perceive-highlighting its potential for dense and accurate
3D radar perception.

</details>


### [76] [Language-Guided Long Horizon Manipulation with LLM-based Planning and Visual Perception](https://arxiv.org/abs/2509.02324)
*Changshi Zhou,Haichuan Xu,Ningquan Gu,Zhipeng Wang,Bin Cheng,Pengpeng Zhang,Yanchao Dong,Mitsuhiro Hayashibe,Yanmin Zhou,Bin He*

Main category: cs.RO

TL;DR: 提出了一种语言引导的长时程布料折叠统一框架，结合LLM规划器和VLM感知系统，在仿真和真实环境中都取得了优异性能


<details>
  <summary>Details</summary>
Motivation: 解决语言引导的柔性物体长时程操作挑战，包括高自由度、复杂动力学和精确的视觉-语言对齐需求

Method: 集成LLM规划器（分解高级指令为低级动作）、VLM感知系统（使用SigLIP2架构和双向交叉注意力融合机制）以及任务执行模块

Result: 在仿真中，在已知指令、未知指令和未知任务上分别优于最先进基线2.23、1.87和33.3分；在真实机器人上能鲁棒执行多步折叠序列

Conclusion: 该方法有效解决了语言引导的柔性物体操作问题，展示了强大的泛化能力和实际应用价值

Abstract: Language-guided long-horizon manipulation of deformable objects presents
significant challenges due to high degrees of freedom, complex dynamics, and
the need for accurate vision-language grounding. In this work, we focus on
multi-step cloth folding, a representative deformable-object manipulation task
that requires both structured long-horizon planning and fine-grained visual
perception. To this end, we propose a unified framework that integrates a Large
Language Model (LLM)-based planner, a Vision-Language Model (VLM)-based
perception system, and a task execution module. Specifically, the LLM-based
planner decomposes high-level language instructions into low-level action
primitives, bridging the semantic-execution gap, aligning perception with
action, and enhancing generalization. The VLM-based perception module employs a
SigLIP2-driven architecture with a bidirectional cross-attention fusion
mechanism and weight-decomposed low-rank adaptation (DoRA) fine-tuning to
achieve language-conditioned fine-grained visual grounding. Experiments in both
simulation and real-world settings demonstrate the method's effectiveness. In
simulation, it outperforms state-of-the-art baselines by 2.23, 1.87, and 33.3
on seen instructions, unseen instructions, and unseen tasks, respectively. On a
real robot, it robustly executes multi-step folding sequences from language
instructions across diverse cloth materials and configurations, demonstrating
strong generalization in practical scenarios. Project page:
https://language-guided.netlify.app/

</details>


### [77] [Physics-Informed Machine Learning with Adaptive Grids for Optical Microrobot Depth Estimation](https://arxiv.org/abs/2509.02343)
*Lan Wei,Lou Genoud,Dandan Zhang*

Main category: cs.RO

TL;DR: 基于物理信息的数据高效框架，通过物理基准焦指标与卷积神经网络相结合，实现了光学微米机器人的准确深度估计，在数据有限条件下仍能获得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 光学微米机器人在生物医学应用中需要准确的三维感知，但微米机器人的透明性质和低对比度显微镜成像给传统深度学习方法带来挑战，同时大规模标注数据获取成本高。

Method: 提出物理信息驱动的数据高效框架，将卷积特征提取与物理基准焦指标（如熵、拉普拉斯函数、梯度锐利度）相结合，采用适应性网格策略在微米机器人区域分配细网格、背景区域分配粗网格，提高深度敏感性并降低计算复杂度。

Result: 在多种微米机器人类型上评估，平均方差错误(MSE)降低60%以上，决定系数(R^2)在所有测试情况下都有提升。尤其显著的是，仅使用20%数据训练的模型性能仍超过使用全部数据训练的ResNet50模型。

Conclusion: 该方法有效解决了光学微米机器人深度估计中的透明性质和数据稀缺挑战，通过物理信息与深度学习的融合，在数据高效和计算效率方面都显示出显著优势，为生物医学领域的精确控制提供了可靠技术支撑。

Abstract: Optical microrobots actuated by optical tweezers (OT) offer great potential
for biomedical applications such as cell manipulation and microscale assembly.
These tasks demand accurate three-dimensional perception to ensure precise
control in complex and dynamic biological environments. However, the
transparent nature of microrobots and low-contrast microscopic imaging
challenge conventional deep learning methods, which also require large
annotated datasets that are costly to obtain. To address these challenges, we
propose a physics-informed, data-efficient framework for depth estimation of
optical microrobots. Our method augments convolutional feature extraction with
physics-based focus metrics, such as entropy, Laplacian of Gaussian, and
gradient sharpness, calculated using an adaptive grid strategy. This approach
allocates finer grids over microrobot regions and coarser grids over background
areas, enhancing depth sensitivity while reducing computational complexity. We
evaluate our framework on multiple microrobot types and demonstrate significant
improvements over baseline models. Specifically, our approach reduces mean
squared error (MSE) by over 60% and improves the coefficient of determination
(R^2) across all test cases. Notably, even when trained on only 20% of the
available data, our model outperforms ResNet50 trained on the full dataset,
highlighting its robustness under limited data conditions. Our code is
available at: https://github.com/LannWei/CBS2025.

</details>


### [78] [OpenGuide: Assistive Object Retrieval in Indoor Spaces for Individuals with Visual Impairments](https://arxiv.org/abs/2509.02425)
*Yifan Xu,Qianwei Wang,Vineet Kamat,Carol Menassa*

Main category: cs.RO

TL;DR: OpenGuide是一个面向视障人士的辅助移动机器人系统，结合自然语言理解、视觉语言基础模型、前沿探索和POMDP规划器，在复杂室内环境中实现多目标物体的高效搜索和定位。


<details>
  <summary>Details</summary>
Motivation: 解决视障人士在复杂杂乱室内环境中定位和收集多个物体时的困难，现有辅助技术主要关注基本导航和避障，缺乏在部分可观测环境中可扩展的多目标搜索能力。

Method: 结合自然语言理解、视觉语言基础模型(VLM)、前沿探索方法和部分可观测马尔可夫决策过程(POMDP)规划器，通过价值衰减和信念空间推理实现鲁棒的检测恢复。

Result: 在模拟和真实世界实验中验证了系统性能，相比现有方法在任务成功率和搜索效率方面都有显著提升。

Conclusion: 为辅助生活环境中的可扩展、以人为中心的机器人辅助建立了基础，展示了在复杂室内环境中多目标搜索的有效解决方案。

Abstract: Indoor built environments like homes and offices often present complex and
cluttered layouts that pose significant challenges for individuals who are
blind or visually impaired, especially when performing tasks that involve
locating and gathering multiple objects. While many existing assistive
technologies focus on basic navigation or obstacle avoidance, few systems
provide scalable and efficient multi-object search capabilities in real-world,
partially observable settings. To address this gap, we introduce OpenGuide, an
assistive mobile robot system that combines natural language understanding with
vision-language foundation models (VLM), frontier-based exploration, and a
Partially Observable Markov Decision Process (POMDP) planner. OpenGuide
interprets open-vocabulary requests, reasons about object-scene relationships,
and adaptively navigates and localizes multiple target items in novel
environments. Our approach enables robust recovery from missed detections
through value decay and belief-space reasoning, resulting in more effective
exploration and object localization. We validate OpenGuide in simulated and
real-world experiments, demonstrating substantial improvements in task success
rate and search efficiency over prior methods. This work establishes a
foundation for scalable, human-centered robotic assistance in assisted living
environments.

</details>


### [79] [U-ARM : Ultra low-cost general teleoperation interface for robot manipulation](https://arxiv.org/abs/2509.02437)
*Yanwen Zou,Zhaoye Zhou,Chenyang Shi,Zewei Ye,Junda Huang,Yan Ding,Bo Zhao*

Main category: cs.RO

TL;DR: U-Arm是一个低成本、快速适配的领导者-跟随者遥操作框架，可与大多数商用机械臂兼容，通过3D打印的领导者臂实现控制，成本仅50-57美元，相比其他低成本接口效率提升39%


<details>
  <summary>Details</summary>
Motivation: 为了解决商用机械臂遥操作接口成本高、适配性差的问题，开发一个低成本、快速适配的开源遥操作框架

Method: 设计三种结构不同的3D打印领导者臂，共享一致的控制逻辑；优化机械设计和伺服选择；通过机械和控制优化解决冗余自由度控制难题

Result: 6自由度版本成本50.5美元，7自由度版本56.8美元；数据收集效率比Joycon高39%；在多种操作场景中任务成功率相当；提供仿真支持和真实世界操作数据

Conclusion: U-Arm提供了一个低成本、高效率的开源遥操作解决方案，具有良好的兼容性和实用性，为机器人遥操作研究提供了有价值的工具和数据资源

Abstract: We propose U-Arm, a low-cost and rapidly adaptable leader-follower
teleoperation framework designed to interface with most of commercially
available robotic arms. Our system supports teleoperation through three
structurally distinct 3D-printed leader arms that share consistent control
logic, enabling seamless compatibility with diverse commercial robot
configurations. Compared with previous open-source leader-follower interfaces,
we further optimized both the mechanical design and servo selection, achieving
a bill of materials (BOM) cost of only \$50.5 for the 6-DoF leader arm and
\$56.8 for the 7-DoF version. To enhance usability, we mitigate the common
challenge in controlling redundant degrees of freedom by %engineering methods
mechanical and control optimizations. Experimental results demonstrate that
U-Arm achieves 39\% higher data collection efficiency and comparable task
success rates across multiple manipulation scenarios compared with Joycon,
another low-cost teleoperation interface. We have open-sourced all CAD models
of three configs and also provided simulation support for validating
teleoperation workflows. We also open-sourced real-world manipulation data
collected with U-Arm. The project website is
https://github.com/MINT-SJTU/LeRobot-Anything-U-Arm.

</details>


### [80] [Coral: A Unifying Abstraction Layer for Composable Robotics Software](https://arxiv.org/abs/2509.02453)
*Steven Swanbeck,Mitch Pryor*

Main category: cs.RO

TL;DR: Coral是一个机器人软件抽象层，通过最大化组件可组合性来解决系统集成难题，支持快速集成而不修改底层代码


<details>
  <summary>Details</summary>
Motivation: 机器人软件集成耗时且困难，现有系统通常紧密耦合，即使是小的改动也需要大量工程投入

Method: 开发Coral抽象层，用于构建、部署和协调独立软件组件，通过语义约束减少配置负担但不限制适应性

Result: 在LiDAR SLAM和多机器人腐蚀缓解等复杂场景中验证了实用性，提高了组件可重用性和系统可重构性

Conclusion: Coral为广泛的机器人系统集成挑战提供了可扩展解决方案，提高了专家和非专家用户的可访问性，已开源发布

Abstract: Despite the multitude of excellent software components and tools available in
the robotics and broader software engineering communities, successful
integration of software for robotic systems remains a time-consuming and
challenging task for users of all knowledge and skill levels. And with robotics
software often being built into tightly coupled, monolithic systems, even minor
alterations to improve performance, adjust to changing task requirements, or
deploy to new hardware can require significant engineering investment. To help
solve this problem, this paper presents Coral, an abstraction layer for
building, deploying, and coordinating independent software components that
maximizes composability to allow for rapid system integration without modifying
low-level code. Rather than replacing existing tools, Coral complements them by
introducing a higher-level abstraction that constrains the integration process
to semantically meaningful choices, reducing the configuration burden without
limiting adaptability to diverse domains, systems, and tasks. We describe Coral
in detail and demonstrate its utility in integrating software for scenarios of
increasing complexity, including LiDAR-based SLAM and multi-robot corrosion
mitigation tasks. By enabling practical composability in robotics software,
Coral offers a scalable solution to a broad range of robotics system
integration challenges, improving component reusability, system
reconfigurability, and accessibility to both expert and non-expert users. We
release Coral open source.

</details>


### [81] [Classification of Vision-Based Tactile Sensors: A Review](https://arxiv.org/abs/2509.02478)
*Haoran Li,Yijiong Lin,Chenghua Lu,Max Yang,Efi Psomopoulou,Nathan F Lepora*

Main category: cs.RO

TL;DR: 该论文提出了一种新的视觉触觉传感器分类方法，将其分为标记基转换原理和强度基转换原理两大类，并进一步细分为四种子类型，提供了硬件特性的比较研究和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 视觉触觉传感器在机器人领域应用广泛，但缺乏统一的分类标准。不同传感器在传感原理、材料组成和多模态方法上存在差异，需要系统性的分类和比较研究。

Method: 提出基于接触转导原理的新分类方法：标记基转换（检测标记位移和密度变化）和强度基转换（像素值变化映射外部扰动）。标记基分为简单标记基和形态标记基，强度基分为反射层基和透明层基。

Result: 建立了系统的视觉触觉传感器分类框架，对四类传感器的硬件特性进行了比较分析，总结了常用的触觉信息解释方法。

Conclusion: 该分类方法为视觉触觉传感器研究提供了统一框架，揭示了当前技术面临的挑战，并指明了未来研究方向，有助于推动该领域的发展。

Abstract: Vision-based tactile sensors (VBTS) have gained widespread application in
robotic hands, grippers and prosthetics due to their high spatial resolution,
low manufacturing costs, and ease of customization. While VBTSs have common
design features, such as a camera module, they can differ in a rich diversity
of sensing principles, material compositions, multimodal approaches, and data
interpretation methods. Here, we propose a novel classification of VBTS that
categorizes the technology into two primary sensing principles based on the
underlying transduction of contact into a tactile image: the Marker-Based
Transduction Principle and the Intensity-Based Transduction Principle.
Marker-Based Transduction interprets tactile information by detecting marker
displacement and changes in marker density. In contrast, Intensity-Based
Transduction maps external disturbances with variations in pixel values.
Depending on the design of the contact module, Marker-Based Transduction can be
further divided into two subtypes: Simple Marker-Based (SMB) and Morphological
Marker-Based (MMB) mechanisms. Similarly, the Intensity-Based Transduction
Principle encompasses the Reflective Layer-based (RLB) and Transparent
Layer-Based (TLB) mechanisms. This paper provides a comparative study of the
hardware characteristics of these four types of sensors including various
combination types, and discusses the commonly used methods for interpreting
tactile information. This~comparison reveals some current challenges faced by
VBTS technology and directions for future research.

</details>


### [82] [Fault-tolerant Model Predictive Control for Spacecraft](https://arxiv.org/abs/2509.02527)
*Raphael Stöckner,Pedro Roque,Maria Charitidou,Dimos V. Dimarogonas*

Main category: cs.RO

TL;DR: 提出基于模型预测控制的航天器轨迹稳定方法，用于处理多执行器故障情况下的安全导航和稳定控制


<details>
  <summary>Details</summary>
Motivation: 卫星星座成本高昂且功能关键，需要确保任务寿命和安全退役，这对空间可持续性至关重要

Method: 采用模型预测控制方法，处理航天器在多执行器故障情况下的轨迹和设定点稳定问题

Result: 该方法能够高效控制故障航天器，实现安全导航和服务或避碰轨迹，确保闭环渐近稳定性和递归可行性

Conclusion: 通过开源数值结果和ATMOS平台的实际实验验证了该方案的有效性，为航天器故障情况下的安全控制提供了可靠解决方案

Abstract: Given the cost and critical functions of satellite constellations, ensuring
mission longevity and safe decommissioning is essential for space
sustainability. This article presents a Model Predictive Control for spacecraft
trajectory and setpoint stabilization under multiple actuation failures. The
proposed solution allows us to efficiently control the faulty spacecraft
enabling safe navigation towards servicing or collision-free trajectories. The
proposed scheme ensures closed-loop asymptotic stability and is shown to be
recursively feasible. We demonstrate its efficacy through open-source numerical
results and realistic experiments using the ATMOS platform.

</details>


### [83] [Manipulation as in Simulation: Enabling Accurate Geometry Perception in Robots](https://arxiv.org/abs/2509.02530)
*Minghuan Liu,Zhengbang Zhu,Xiaoshen Han,Peng Hu,Haotong Lin,Xinyao Li,Jingxiao Chen,Jiafeng Xu,Yichu Yang,Yunfeng Lin,Xinghang Li,Yong Yu,Weinan Zhang,Tao Kong,Bingyi Kang*

Main category: cs.RO

TL;DR: 本文提出相机深度模型(CDMs)，通过模拟深度摄像头噪声模式生成高质量训练数据，实现了在真实深度摄像头上的准确深度预测，最终使得基于模拟深度训练的策略能够无需调整直接演示到真实机器人操作任务中。


<details>
  <summary>Details</summary>
Motivation: 现代机器人操作主要依赖2D视觉观测，但绝纯的颜色信息导致稀缩性差。而人类依赖于3D几何信息（如距离、大小、形状）进行物体交互。深度摄像头能提供这3D信息，但存在准确性不足和噪声问题。

Method: 提出相机深度模型(CDMs)，作为深度摄像头的插件，输入RGB图像和原始深度信号，输出去噪后的准确深度。开发神经数据引擎，通过模拟深度摄像头的噪声模式生成高质量的匹配数据。

Result: CDMs实现了接近模拟级别的深度预测准确性，有效缩小了模拟与真实之间的间隔。在包含关节、反射和细长物体的两个具有挑战性的长期限任务中，基于原始模拟深度训练的策略能够无需噪声添加或真实世界微调，就能够无缝演示到真实机器人，且性能减退很小或无减退。

Conclusion: 该研究为利用模拟数据和3D信息来开发通用的机器人策略提供了新的思路，通过深度信息的准确处理有效解决了模拟到真实的迁移问题，为机器人操作的通用化研究开启了新方向。

Abstract: Modern robotic manipulation primarily relies on visual observations in a 2D
color space for skill learning but suffers from poor generalization. In
contrast, humans, living in a 3D world, depend more on physical properties-such
as distance, size, and shape-than on texture when interacting with objects.
Since such 3D geometric information can be acquired from widely available depth
cameras, it appears feasible to endow robots with similar perceptual
capabilities. Our pilot study found that using depth cameras for manipulation
is challenging, primarily due to their limited accuracy and susceptibility to
various types of noise. In this work, we propose Camera Depth Models (CDMs) as
a simple plugin on daily-use depth cameras, which take RGB images and raw depth
signals as input and output denoised, accurate metric depth. To achieve this,
we develop a neural data engine that generates high-quality paired data from
simulation by modeling a depth camera's noise pattern. Our results show that
CDMs achieve nearly simulation-level accuracy in depth prediction, effectively
bridging the sim-to-real gap for manipulation tasks. Notably, our experiments
demonstrate, for the first time, that a policy trained on raw simulated depth,
without the need for adding noise or real-world fine-tuning, generalizes
seamlessly to real-world robots on two challenging long-horizon tasks involving
articulated, reflective, and slender objects, with little to no performance
degradation. We hope our findings will inspire future research in utilizing
simulation data and 3D information in general robot policies.

</details>
