<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 43]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Real-Time Communication-Aware Ride-Sharing Route Planning for Urban Air Mobility: A Multi-Source Hybrid Attention Reinforcement Learning Approach](https://arxiv.org/abs/2507.14249)
*Yuejiao Xie,Maonan Wang,Di Zhou,Man-On Pun,Zhu Han*

Main category: cs.RO

TL;DR: 论文提出了一种基于无线电地图和混合注意力强化学习的UAM路径规划方法，以应对动态乘客需求和通信质量挑战。


<details>
  <summary>Details</summary>
Motivation: 解决城市空中交通（UAM）中动态乘客需求和通信质量对路径规划的挑战。

Method: 构建无线电地图评估通信质量，提出多源混合注意力强化学习（MSHA-RL）框架，平衡全局与局部信息。

Result: 实验表明该方法能实现通信合规的路径规划，减少旅行时间并提升效率。

Conclusion: MSHA-RL框架为UAM提供了实时、安全的路径规划解决方案。

Abstract: Urban Air Mobility (UAM) systems are rapidly emerging as promising solutions
to alleviate urban congestion, with path planning becoming a key focus area.
Unlike ground transportation, UAM trajectory planning has to prioritize
communication quality for accurate location tracking in constantly changing
environments to ensure safety. Meanwhile, a UAM system, serving as an air taxi,
requires adaptive planning to respond to real-time passenger requests,
especially in ride-sharing scenarios where passenger demands are unpredictable
and dynamic. However, conventional trajectory planning strategies based on
predefined routes lack the flexibility to meet varied passenger ride demands.
To address these challenges, this work first proposes constructing a radio map
to evaluate the communication quality of urban airspace. Building on this, we
introduce a novel Multi-Source Hybrid Attention Reinforcement Learning
(MSHA-RL) framework for the challenge of effectively focusing on passengers and
UAM locations, which arises from the significant dimensional disparity between
the representations. This model first generates the alignment among diverse
data sources with large gap dimensions before employing hybrid attention to
balance global and local insights, thereby facilitating responsive, real-time
path planning. Extensive experimental results demonstrate that the approach
enables communication-compliant trajectory planning, reducing travel time and
enhancing operational efficiency while prioritizing passenger safety.

</details>


### [2] [A Recursive Lie-Group Formulation for the Second-Order Time Derivatives of the Inverse Dynamics of parallel Kinematic Manipulators](https://arxiv.org/abs/2507.14274)
*Andreas Mueller,Shivesh Kumar,Thomas Kordik*

Main category: cs.RO

TL;DR: 本文首次提出了一种计算并联运动学机械臂（PKM）配备串联弹性执行器（SEA）时逆动力学解二阶时间导数的高效方法，填补了文献空白。


<details>
  <summary>Details</summary>
Motivation: 并联运动学机械臂（PKM）配备串联弹性执行器（SEA）的轨迹控制尚未实现，关键在于高效计算逆动力学解的二阶时间导数。

Method: 利用PKM的特殊拓扑结构，复用串联机器人逆动力学的递归算法，并采用李群框架推导所有关系。

Result: 数值结果显示，该方法适用于6自由度Gough-Stewart平台和平面PKM，结合平坦性控制方案。

Conclusion: 本文首次解决了PKM配备SEA时的逆动力学解二阶时间导数计算问题，为轨迹控制提供了有效工具。

Abstract: Series elastic actuators (SEA) were introduced for serial robotic arms. Their
model-based trajectory tracking control requires the second time derivatives of
the inverse dynamics solution, for which algorithms were proposed. Trajectory
control of parallel kinematics manipulators (PKM) equipped with SEAs has not
yet been pursued. Key element for this is the computationally efficient
evaluation of the second time derivative of the inverse dynamics solution. This
has not been presented in the literature, and is addressed in the present paper
for the first time. The special topology of PKM is exploited reusing the
recursive algorithms for evaluating the inverse dynamics of serial robots. A
Lie group formulation is used and all relations are derived within this
framework. Numerical results are presented for a 6-DOF Gough-Stewart platform
(as part of an exoskeleton), and for a planar PKM when a flatness-based control
scheme is applied.

</details>


### [3] [Personalized Socially Assistive Robots With End-to-End Speech-Language Models For Well-Being Support](https://arxiv.org/abs/2507.14412)
*Mengxue Fu,Zhonghao Shi,Minyu Huang,Siqi Liu,Mina Kian,Yirui Song,Maja J. Matarić*

Main category: cs.RO

TL;DR: 论文提出了一种基于端到端语音语言模型（SLM）的社交辅助机器人（SAR）对话系统，并通过用户研究评估其可用性，发现其在共情反馈和自然对话方面表现良好，但在非语言行为和个性化反馈方面仍有不足。


<details>
  <summary>Details</summary>
Motivation: 现有SAR对话系统在实时延迟、反馈机制和个性化对话方面存在局限，需要改进。

Method: 采用端到端语音语言模型（SLM）与SAR结合，并通过小规模用户研究（N=11）评估系统可用性。

Result: 用户认为SLM-enabled SAR系统在共情反馈和自然对话方面表现良好，但非语言行为和个性化反馈仍需改进。

Conclusion: 未来需优化机器人动作同步、提示或微调模型以更符合心理健康实践，并改进语音生成的表现力和适应性。

Abstract: Socially assistive robots (SARs) have shown great potential for supplementing
well-being support. However, prior studies have found that existing dialogue
pipelines for SARs remain limited in real-time latency, back-channeling, and
personalized speech dialogue. Toward addressing these limitations, we propose
using integrated end-to-end speech-language models (SLMs) with SARs. This work
1) evaluated the usability of an SLM-enabled SAR dialogue system through a
small user study, and 2) identified remaining limitations through study user
feedback to inform future improvements. We conducted a small within-participant
user study with university students (N = 11) whose results showed that
participants perceived an SLM-enabled SAR system as capable of providing
empathetic feedback, natural turn-taking, back-channeling, and adaptive
responses. We also found that participants reported the robot's nonverbal
behaviors as lacking variability and synchronization with conversation, and the
SLM's verbal feedback as generic and repetitive. These findings highlighted the
need for real-time robot movement synchronized with conversation, improved
prompting or fine-tuning to generate outputs better aligned with mental health
practices, and more expressive, adaptive vocal generation.

</details>


### [4] [Koopman Operator Based Time-Delay Embeddings and State History Augmented LQR for Periodic Hybrid Systems: Bouncing Pendulum and Bipedal Walking](https://arxiv.org/abs/2507.14455)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 时间延迟嵌入技术用于构建非线性光滑系统的线性状态空间模型，本文将其扩展到周期性非光滑或混合系统，并提出了基于状态历史的线性二次调节器（LQR）。


<details>
  <summary>Details</summary>
Motivation: 探索时间延迟嵌入技术是否适用于周期性非光滑或混合系统，以构建线性状态空间模型。

Method: 扩展时间延迟嵌入技术，应用于两个周期性混合系统（弹跳摆和简单步行器），并设计状态历史增强的LQR控制器。

Result: 成功构建了周期性混合系统的线性模型，并验证了状态历史增强LQR的有效性。

Conclusion: 时间延迟嵌入技术可推广到周期性非光滑或混合系统，状态历史增强LQR为这类系统提供了新的控制方法。

Abstract: Time-delay embedding is a technique that uses snapshots of state history over
time to build a linear state space model of a nonlinear smooth system. We
demonstrate that periodic non-smooth or hybrid system can also be modeled as a
linear state space system using this approach as long as its behavior is
consistent in modes and timings. We extended time-delay embeddings to generate
a linear model of two periodic hybrid systems: the bouncing pendulum and the
simplest walker with control inputs. This leads to a novel state history
augmented linear quadratic regulator (LQR) which uses current and past state
history for feedback control.

</details>


### [5] [A 21-DOF Humanoid Dexterous Hand with Hybrid SMA-Motor Actuation: CYJ Hand-0](https://arxiv.org/abs/2507.14538)
*Jin Chai,Xiang Yao,Mengfan Hou,Yanghong Li,Erbao Dong*

Main category: cs.RO

TL;DR: CYJ Hand-0是一种21自由度的仿人灵巧手，采用混合肌腱驱动系统（结合形状记忆合金和直流电机），通过3D打印金属框架和高强度钓鱼线模拟人手结构。


<details>
  <summary>Details</summary>
Motivation: 设计一种仿人灵巧手，结合多种驱动技术以实现高仿生性和灵活性。

Method: 使用混合驱动系统（SMA和DC电机），3D打印金属框架，并通过线性电机和SMA模块分别控制手指的屈曲和伸展/外展。

Result: 机械和运动学实验验证了设计的有效性，展示了其仿生灵活性。

Conclusion: CYJ Hand-0的设计成功实现了仿人灵巧手的生物力学特性，具有潜在的应用价值。

Abstract: CYJ Hand-0 is a 21-DOF humanoid dexterous hand featuring a hybrid
tendon-driven actuation system that combines shape memory alloys (SMAs) and DC
motors. The hand employs high-strength fishing line as artificial tendons and
uses a fully 3D-printed AlSi10Mg metal frame designed to replicate the skeletal
and tendon-muscle structure of the human hand. A linear motor-driven module
controls finger flexion, while an SMA-based module enables finger extension and
lateral abduction. These modules are integrated into a compact hybrid actuation
unit mounted on a custom rear support structure. Mechanical and kinematic
experiments, conducted under an Arduino Mega 2560-based control system,
validate the effectiveness of the design and demonstrate its biomimetic
dexterity.

</details>


### [6] [BT-TL-DMPs: A Novel Robot TAMP Framework Combining Behavior Tree, Temporal Logic and Dynamical Movement Primitives](https://arxiv.org/abs/2507.14582)
*Zezhi Liu,Shizhen Wu,Hanqian Luo,Deyun Qin,Yongchun Fang*

Main category: cs.RO

TL;DR: 论文提出了一种名为BT-TL-DMPs的分层框架，结合行为树、时序逻辑和动态运动基元，以解决机器人从演示中学习技能并泛化到新场景的挑战。


<details>
  <summary>Details</summary>
Motivation: 在机器人从演示学习（LfD）中，如何将学到的技能泛化到新环境和长时程任务中仍具挑战性。

Method: 框架整合了行为树（BT）、时序逻辑（TL）和动态运动基元（DMPs），利用信号时序逻辑（STL）规范任务需求，并通过优化DMP实现灵活适应。

Result: 仿真和实验验证了框架在复杂任务中的泛化能力和可靠性。

Conclusion: 该框架有效弥合了符号与运动之间的鸿沟，提升了机器人自主操作的泛化性和可靠性。

Abstract: In the field of Learning from Demonstration (LfD), enabling robots to
generalize learned manipulation skills to novel scenarios for long-horizon
tasks remains challenging. Specifically, it is still difficult for robots to
adapt the learned skills to new environments with different task and motion
requirements, especially in long-horizon, multi-stage scenarios with intricate
constraints. This paper proposes a novel hierarchical framework, called
BT-TL-DMPs, that integrates Behavior Tree (BT), Temporal Logic (TL), and
Dynamical Movement Primitives (DMPs) to address this problem. Within this
framework, Signal Temporal Logic (STL) is employed to formally specify complex,
long-horizon task requirements and constraints. These STL specifications are
systematically transformed to generate reactive and modular BTs for high-level
decision-making task structure. An STL-constrained DMP optimization method is
proposed to optimize the DMP forcing term, allowing the learned motion
primitives to adapt flexibly while satisfying intricate spatiotemporal
requirements and, crucially, preserving the essential dynamics learned from
demonstrations. The framework is validated through simulations demonstrating
generalization capabilities under various STL constraints and real-world
experiments on several long-horizon robotic manipulation tasks. The results
demonstrate that the proposed framework effectively bridges the symbolic-motion
gap, enabling more reliable and generalizable autonomous manipulation for
complex robotic tasks.

</details>


### [7] [Koopman Operator Based Linear Model Predictive Control for 2D Quadruped Trotting, Bounding, and Gait Transition](https://arxiv.org/abs/2507.14605)
*Chun-Ming Yang,Pranav A. Bhounsule*

Main category: cs.RO

TL;DR: 利用Koopman算子理论和EDMD方法，构建高维线性模型以保留非线性动力学特性，结合LMPC实现四足机器人多种步态及转换的在线控制。


<details>
  <summary>Details</summary>
Motivation: 解决LMPC因线性化动力学方程导致的解质量下降问题，提升四足机器人在复杂环境中的运动规划能力。

Method: 采用Koopman算子理论和EDMD构建高维线性模型，分阶段建模空中和地面接触动力学，结合LMPC实现实时控制。

Result: 成功演示了在平坦和崎岖地形上的跳跃、小跑及步态转换。

Conclusion: Koopman算子理论为四足机器人提供了高效的混合模型，支持在线生成多种步态及转换，扩展了LMPC的应用范围。

Abstract: Online optimal control of quadrupedal robots would enable them to plan their
movement in novel scenarios. Linear Model Predictive Control (LMPC) has emerged
as a practical approach for real-time control. In LMPC, an optimization problem
with a quadratic cost and linear constraints is formulated over a finite
horizon and solved on the fly. However, LMPC relies on linearizing the
equations of motion (EOM), which may lead to poor solution quality. In this
paper, we use Koopman operator theory and the Extended Dynamic Mode
Decomposition (EDMD) to create a linear model of the system in high dimensional
space, thus retaining the nonlinearity of the EOM. We model the aerial phase
and ground contact phases using different linear models. Then, using LMPC, we
demonstrate bounding, trotting, and bound-to-trot and trot-to-bound gait
transitions in level and rough terrains. The main novelty is the use of Koopman
operator theory to create hybrid models of a quadrupedal system and demonstrate
the online generation of multiple gaits and gaits transitions.

</details>


### [8] [Uncertainty-aware Probabilistic 3D Human Motion Forecasting via Invertible Networks](https://arxiv.org/abs/2507.14694)
*Yue Ma,Kanglei Zhou,Fuyang Yu,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.RO

TL;DR: ProbHMI 提出了一种基于可逆网络的方法，用于3D人体运动预测中的不确定性量化，适用于安全关键场景。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景（如人机协作）中，量化预测的不确定性至关重要，但现有方法因隐式概率表示而难以实现。

Method: 引入可逆网络将姿态参数化到解耦的潜在空间，并显式预测未来潜在分布以实现不确定性量化。

Result: 在基准测试中，ProbHMI 在确定性和多样性预测方面表现优异，同时验证了不确定性校准的有效性。

Conclusion: ProbHMI 为风险感知决策提供了有效的工具，适用于需要高安全性的应用场景。

Abstract: 3D human motion forecasting aims to enable autonomous applications.
Estimating uncertainty for each prediction (i.e., confidence based on
probability density or quantile) is essential for safety-critical contexts like
human-robot collaboration to minimize risks. However, existing diverse motion
forecasting approaches struggle with uncertainty quantification due to implicit
probabilistic representations hindering uncertainty modeling. We propose
ProbHMI, which introduces invertible networks to parameterize poses in a
disentangled latent space, enabling probabilistic dynamics modeling. A
forecasting module then explicitly predicts future latent distributions,
allowing effective uncertainty quantification. Evaluated on benchmarks, ProbHMI
achieves strong performance for both deterministic and diverse prediction while
validating uncertainty calibration, critical for risk-aware decision making.

</details>


### [9] [Corridor-based Adaptive Control Barrier and Lyapunov Functions for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.14700)
*Nicholas Mohammad,Nicola Bezzo*

Main category: cs.RO

TL;DR: 提出了一种结合CLF和CBF的MPCC框架，通过动态调整CBF参数确保安全导航，并在未知杂乱环境中验证。


<details>
  <summary>Details</summary>
Motivation: 现有MPCC方法缺乏正式的安全保证，需解决未知杂乱环境中的安全导航问题。

Method: 结合CLF和CBF的MPCC框架，动态调整CBF参数（使用SAC策略），确保轨迹安全。

Result: 通过仿真和移动机器人实验验证了方法的有效性。

Conclusion: 提出的框架在未知杂乱环境中实现了安全导航，具有实际应用潜力。

Abstract: Safe navigation in unknown and cluttered environments remains a challenging
problem in robotics. Model Predictive Contour Control (MPCC) has shown promise
for performant obstacle avoidance by enabling precise and agile trajectory
tracking, however, existing methods lack formal safety assurances. To address
this issue, we propose a general Control Lyapunov Function (CLF) and Control
Barrier Function (CBF) enabled MPCC framework that enforces safety constraints
derived from a free-space corridor around the planned trajectory. To enhance
feasibility, we dynamically adapt the CBF parameters at runtime using a Soft
Actor-Critic (SAC) policy. The approach is validated with extensive simulations
and an experiment on mobile robot navigation in unknown cluttered environments.

</details>


### [10] [Leveraging Extrinsic Dexterity for Occluded Grasping on Grasp Constraining Walls](https://arxiv.org/abs/2507.14721)
*Keita Kobashi,Masayoshi Tomizuka*

Main category: cs.RO

TL;DR: 提出了一种分层强化学习框架，结合Q学习和CVAE，解决机器人抓取被遮挡物体的问题，并在实验中验证了方法的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决因环境遮挡导致物体主要抓取配置不可用的问题，尤其是在平行夹爪灵活性有限的情况下。

Method: 采用分层强化学习框架，高层策略通过Q学习选择动作类型，低层技能通过CVAE在连续空间中采样具体动作，并结合域随机化训练。

Result: 在仿真和真实环境中测试了六种物体，展示了方法的泛化性和稳健的仿真到现实迁移性能，成功率较高。

Conclusion: 提出的方法有效解决了复杂环境中的抓取问题，具有实际应用潜力。

Abstract: This study addresses the problem of occluded grasping, where primary grasp
configurations of an object are not available due to occlusion with
environment. Simple parallel grippers often struggle with such tasks due to
limited dexterity and actuation constraints. Prior works have explored object
pose reorientation such as pivoting by utilizing extrinsic contacts between an
object and an environment feature like a wall, to make the object graspable.
However, such works often assume the presence of a short wall, and this
assumption may not always hold in real-world scenarios. If the wall available
for interaction is too large or too tall, the robot may still fail to grasp the
object even after pivoting, and the robot must combine different types of
actions to grasp. To address this, we propose a hierarchical reinforcement
learning (RL) framework. We use Q-learning to train a high-level policy that
selects the type of action expected to yield the highest reward. The selected
low-level skill then samples a specific robot action in continuous space. To
guide the robot to an appropriate location for executing the selected action,
we adopt a Conditional Variational Autoencoder (CVAE). We condition the CVAE on
the object point cloud and the skill ID, enabling it to infer a suitable
location based on the object geometry and the selected skill. To promote
generalization, we apply domain randomization during the training of low-level
skills. The RL policy is trained entirely in simulation with a box-like object
and deployed to six objects in real world. We conduct experiments to evaluate
our method and demonstrate both its generalizability and robust sim-to-real
transfer performance with promising success rates.

</details>


### [11] [X-Nav: Learning End-to-End Cross-Embodiment Navigation for Mobile Robots](https://arxiv.org/abs/2507.14731)
*Haitong Wang,Aaron Hao Tan,Angus Fung,Goldie Nejat*

Main category: cs.RO

TL;DR: X-Nav是一个跨机器人平台导航的统一框架，通过两阶段学习实现通用性，并在仿真和真实环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有导航方法通常针对特定机器人设计，缺乏跨平台的通用性，X-Nav旨在解决这一问题。

Method: X-Nav分两阶段：1）训练多个专家策略；2）通过Nav-ACT蒸馏为单一通用策略。

Result: X-Nav在仿真中实现零样本迁移，并在真实环境中验证了其通用性。

Conclusion: X-Nav展示了跨机器人平台导航的潜力，性能随训练数据增加而提升。

Abstract: Existing navigation methods are primarily designed for specific robot
embodiments, limiting their generalizability across diverse robot platforms. In
this paper, we introduce X-Nav, a novel framework for end-to-end
cross-embodiment navigation where a single unified policy can be deployed
across various embodiments for both wheeled and quadrupedal robots. X-Nav
consists of two learning stages: 1) multiple expert policies are trained using
deep reinforcement learning with privileged observations on a wide range of
randomly generated robot embodiments; and 2) a single general policy is
distilled from the expert policies via navigation action chunking with
transformer (Nav-ACT). The general policy directly maps visual and
proprioceptive observations to low-level control commands, enabling
generalization to novel robot embodiments. Simulated experiments demonstrated
that X-Nav achieved zero-shot transfer to both unseen embodiments and
photorealistic environments. A scalability study showed that the performance of
X-Nav improves when trained with an increasing number of randomly generated
embodiments. An ablation study confirmed the design choices of X-Nav.
Furthermore, real-world experiments were conducted to validate the
generalizability of X-Nav in real-world environments.

</details>


### [12] [KGN-Pro: Keypoint-Based Grasp Prediction through Probabilistic 2D-3D Correspondence Learning](https://arxiv.org/abs/2507.14820)
*Bingran Chen,Baorun Li,Jian Yang,Yong Liu,Guangyao Zhai*

Main category: cs.RO

TL;DR: KGN-Pro是一种新型抓取网络，通过概率PnP层直接优化3D信息，提升6-DoF抓取性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在抓取小物体和处理传感器噪声时表现不佳，或依赖昂贵的标注和离散化问题。KGN-Pro旨在结合2D效率和3D信息。

Method: KGN-Pro通过RGB-D图像生成关键点图和置信图，利用概率PnP层进行3D优化，实现端到端学习。

Result: 实验表明，KGN-Pro在抓取覆盖率和成功率上优于现有方法。

Conclusion: KGN-Pro通过结合2D和3D信息，显著提升了抓取性能。

Abstract: High-level robotic manipulation tasks demand flexible 6-DoF grasp estimation
to serve as a basic function. Previous approaches either directly generate
grasps from point-cloud data, suffering from challenges with small objects and
sensor noise, or infer 3D information from RGB images, which introduces
expensive annotation requirements and discretization issues. Recent methods
mitigate some challenges by retaining a 2D representation to estimate grasp
keypoints and applying Perspective-n-Point (PnP) algorithms to compute 6-DoF
poses. However, these methods are limited by their non-differentiable nature
and reliance solely on 2D supervision, which hinders the full exploitation of
rich 3D information. In this work, we present KGN-Pro, a novel grasping network
that preserves the efficiency and fine-grained object grasping of previous KGNs
while integrating direct 3D optimization through probabilistic PnP layers.
KGN-Pro encodes paired RGB-D images to generate Keypoint Map, and further
outputs a 2D confidence map to weight keypoint contributions during
re-projection error minimization. By modeling the weighted sum of squared
re-projection errors probabilistically, the network effectively transmits 3D
supervision to its 2D keypoint predictions, enabling end-to-end learning.
Experiments on both simulated and real-world platforms demonstrate that KGN-Pro
outperforms existing methods in terms of grasp cover rate and success rate.

</details>


### [13] [CoMoCAVs: Cohesive Decision-Guided Motion Planning for Connected and Autonomous Vehicles with Multi-Policy Reinforcement Learning](https://arxiv.org/abs/2507.14903)
*Pan Hu*

Main category: cs.RO

TL;DR: 论文提出了一种名为CDGMP的框架，通过混合专家（MoE）架构和多策略强化学习，紧密集成决策制定和运动规划，以提高自动驾驶的灵活性和安全性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要可靠且高效的解决方案来处理决策制定（如车道选择）和运动规划（如速度和转向控制）等紧密相关的问题。当前在联网自动驾驶车辆（CAVs）中，实现灵活安全的车道选择和精确的轨迹执行仍具挑战性。

Method: CDGMP采用混合专家（MoE）架构和多策略强化学习，通过门控机制协调多个专用子网络，将复杂驾驶任务分解为模块化组件。每个子网络专注于驾驶的特定方面，仅在推理时激活最相关的模块以提高效率。

Result: 仿真结果表明，CDGMP在车道选择和运动规划方面表现可靠。该方法提高了CAV在不同交通场景中的适应性和鲁棒性。

Conclusion: CDGMP为自动驾驶提供了一种可扩展的解决方案，其架构（尤其是MoE的应用）也为其他高维决策和控制任务奠定了基础。

Abstract: Autonomous driving demands reliable and efficient solutions to closely
related problems such as decision-making and motion planning. In this work,
decision-making refers specifically to highway lane selection, while motion
planning involves generating control commands (such as speed and steering) to
reach the chosen lane. In the context of Connected Autonomous Vehicles (CAVs),
achieving both flexible and safe lane selection alongside precise trajectory
execution remains a significant challenge. This paper proposes a framework
called Cohesive Decision-Guided Motion Planning (CDGMP), which tightly
integrates decision-making and motion planning using a Mixture of Experts (MoE)
inspired architecture combined with multi-policy reinforcement learning. By
coordinating multiple specialized sub-networks through a gating mechanism, the
method decomposes the complex driving task into modular components. Each
sub-network focuses on a specific aspect of driving, improving efficiency by
activating only the most relevant modules during inference. This design also
enhances safety through modular specialization. CDGMP improves the adaptability
and robustness of CAVs across diverse traffic scenarios, offering a scalable
solution to real-world autonomy challenges. The architectural principles behind
CDGMP, especially the use of MoE, also provide a strong foundation for other
high-dimensional decision and control tasks. Simulation results (available at
https://youtu.be/_-4OXNHV0UY) demonstrate reliable performance in both lane
selection and motion planning.

</details>


### [14] [One Step Beyond: Feedthrough & Placement-Aware Rectilinear Floorplanner](https://arxiv.org/abs/2507.14914)
*Zhexuan Xu,Jie Wang,Siyuan Xu,Zijie Geng,Mingxuan Yuan,Feng Wu*

Main category: cs.RO

TL;DR: Flora是一个三阶段、考虑馈通和布局的矩形平面规划器，通过分阶段优化HPWL、馈通和组件布局，显著提升了芯片设计的PPA指标。


<details>
  <summary>Details</summary>
Motivation: 现有平面规划方法难以与后续物理设计阶段集成，导致模块内组件布局不优和模块间馈通过多。

Method: Flora分三阶段：1) 使用线掩码和位置掩码粗优化HPWL和馈通；2) 在固定轮廓下通过局部调整模块形状实现零空白布局；3) 基于树搜索快速放置组件并调整模块边界。

Result: 实验显示，Flora平均减少6% HPWL、5.16% FTpin、29.15% FTmod，组件布局性能提升14%。

Conclusion: Flora通过跨阶段优化，显著提升了平面规划的效果，优于现有方法。

Abstract: Floorplanning determines the shapes and locations of modules on a chip canvas
and plays a critical role in optimizing the chip's Power, Performance, and Area
(PPA) metrics. However, existing floorplanning approaches often fail to
integrate with subsequent physical design stages, leading to suboptimal
in-module component placement and excessive inter-module feedthrough. To tackle
this challenge, we propose Flora, a three-stage feedthrough and placement aware
rectilinear floorplanner. In the first stage, Flora employs wiremask and
position mask techniques to achieve coarse-grained optimization of HPWL and
feedthrough. In the second stage, under the constraint of a fixed outline,
Flora achieves a zero-whitespace layout by locally resizing module shapes,
thereby performing fine-grained optimization of feedthrough and improving
component placement. In the third stage, Flora utilizes a fast tree
search-based method to efficiently place components-including macros and
standard cells-within each module, subsequently adjusting module boundaries
based on the placement results to enable cross-stage optimization. Experimental
results show that Flora outperforms recent state-of-the-art floorplanning
approaches, achieving an average reduction of 6% in HPWL, 5.16% in FTpin,
29.15% in FTmod, and a 14% improvement in component placement performance.

</details>


### [15] [Digital twin and extended reality for teleoperation of the electric vehicle battery disassembly](https://arxiv.org/abs/2507.14929)
*Tero Kaarlela,Sami Salo,Jose Outeiro*

Main category: cs.RO

TL;DR: 提出了一种结合远程操作与自动化的系统，用于安全拆卸和分类电动汽车电池（EVB），以提高安全性、适应性和效率。


<details>
  <summary>Details</summary>
Motivation: 手动拆卸EVB存在安全隐患（如触电和有毒化学物质），且效率低下。通过远程操作和自动化技术，可以解决这些问题并推动可持续的电动汽车供应链。

Method: 采用远程操作系统，结合人类操作员和自动化技术。RGB摄像头用于对齐物理和数字孪生，机器人数字孪生基于ROS中间件。

Result: 在线试点研究表明，该系统具有用户友好性，并能减少对劳动力的依赖，提高电池回收效率。

Conclusion: 该系统为EVB拆卸和分类提供了一种安全、高效且可扩展的解决方案，支持可持续的电动汽车供应链。

Abstract: Disassembling and sorting Electric Vehicle Batteries (EVBs) supports a
sustainable transition to electric vehicles by enabling a closed-loop supply
chain. Currently, the manual disassembly process exposes workers to hazards,
including electrocution and toxic chemicals. We propose a teleoperated system
for the safe disassembly and sorting of EVBs. A human-in-the-loop can create
and save disassembly sequences for unknown EVB types, enabling future
automation. An RGB camera aligns the physical and digital twins of the EVB, and
the digital twin of the robot is based on the Robot Operating System (ROS)
middleware. This hybrid approach combines teleoperation and automation to
improve safety, adaptability, and efficiency in EVB disassembly and sorting.
The economic contribution is realized by reducing labor dependency and
increasing throughput in battery recycling. An online pilot study was set up to
evaluate the usability of the presented approach, and the results demonstrate
the potential as a user-friendly solution.

</details>


### [16] [Designing Robots with, not for: A Co-Design Framework for Empowering Interactions in Forensic Psychiatry](https://arxiv.org/abs/2507.14931)
*Qiaoqiao Ren,Remko Proesmans,Arend Pissens,Lara Dehandschutter,William Denecker,Lotte Rouckhout,Joke Carrette,Peter Vanhopplinus,Tony Belpaeme,Francis wyffels*

Main category: cs.RO

TL;DR: 研究探讨了在法医心理健康护理中，通过共同设计开发陪伴机器人，帮助监测和调节患者压力，同时跟踪互动行为以进行长期干预。


<details>
  <summary>Details</summary>
Motivation: 法医心理健康护理环境通常官僚主义严重、风险规避性强且患者自主权受限，导致患者心理压力大。研究旨在通过共同设计改善患者体验。

Method: 在法医精神病诊所进行了四次共同设计工作坊，参与者包括患者、护理人员和治疗师，从原型展示到功能定义逐步推进。

Result: 研究发现，让患者参与设计过程并基于其情绪状态调整方案至关重要，目标是确保每位患者的声音被听到。

Conclusion: 共同设计方法能有效提升患者自主权，为法医心理健康护理提供创新解决方案。

Abstract: Forensic mental health care involves the treatment of individuals with severe
mental disorders who have committed violent offences. These settings are often
characterized by high levels of bureaucracy, risk avoidance, and restricted
autonomy. Patients frequently experience a profound loss of control over their
lives, leading to heightened psychological stress-sometimes resulting in
isolation as a safety measure. In this study, we explore how co-design can be
used to collaboratively develop a companion robot that helps monitor and
regulate stress while maintaining tracking of the patients' interaction
behaviours for long-term intervention. We conducted four co-design workshops in
a forensic psychiatric clinic with patients, caregivers, and therapists. Our
process began with the presentation of an initial speculative prototype to
therapists, enabling reflection on shared concerns, ethical risks, and
desirable features. This was followed by a creative ideation session with
patients, a third workshop focused on defining desired functions and emotional
responses, and we are planning a final prototype demo to gather direct patient
feedback. Our findings emphasize the importance of empowering patients in the
design process and adapting proposals based on their current emotional state.
The goal was to empower the patient in the design process and ensure each
patient's voice was heard.

</details>


### [17] [Heterogeneous object manipulation on nonlinear soft surface through linear controller](https://arxiv.org/abs/2507.14967)
*Pratik Ingle,Kasper Støy,Andres Faiña*

Main category: cs.RO

TL;DR: 提出了一种基于PID的线性闭环反馈控制策略，用于减少高密度执行器阵列的复杂性，实现异构物体的精确操控。


<details>
  <summary>Details</summary>
Motivation: 高密度执行器阵列的复杂性和控制难度限制了其在现实应用中的实用性，传统学习方法需要大量训练样本且难以泛化。

Method: 采用几何变换驱动的PID控制器，直接将倾斜角度控制输出映射到执行器命令，避免黑盒训练。

Result: 通过仿真和物理系统实验，成功操控了多种几何、重量和纹理的物体，包括易碎物品。

Conclusion: 该方法具有高度泛化性，为软体机器人操控提供了实用可靠的解决方案，无需大量训练。

Abstract: Manipulation surfaces indirectly control and reposition objects by actively
modifying their shape or properties rather than directly gripping objects.
These surfaces, equipped with dense actuator arrays, generate dynamic
deformations. However, a high-density actuator array introduces considerable
complexity due to increased degrees of freedom (DOF), complicating control
tasks. High DOF restrict the implementation and utilization of manipulation
surfaces in real-world applications as the maintenance and control of such
systems exponentially increase with array/surface size. Learning-based control
approaches may ease the control complexity, but they require extensive training
samples and struggle to generalize for heterogeneous objects. In this study, we
introduce a simple, precise and robust PID-based linear close-loop feedback
control strategy for heterogeneous object manipulation on MANTA-RAY
(Manipulation with Adaptive Non-rigid Textile Actuation with Reduced Actuation
density). Our approach employs a geometric transformation-driven PID
controller, directly mapping tilt angle control outputs(1D/2D) to actuator
commands to eliminate the need for extensive black-box training. We validate
the proposed method through simulations and experiments on a physical system,
successfully manipulating objects with diverse geometries, weights and
textures, including fragile objects like eggs and apples. The outcomes
demonstrate that our approach is highly generalized and offers a practical and
reliable solution for object manipulation on soft robotic manipulation,
facilitating real-world implementation without prohibitive training demands.

</details>


### [18] [FCRF: Flexible Constructivism Reflection for Long-Horizon Robotic Task Planning with Large Language Models](https://arxiv.org/abs/2507.14975)
*Yufan Song,Jiatao Zhang,Zeng Gu,Qingmiao Liang,Tuocheng Hu,Wei Song,Shiqiang Zhu*

Main category: cs.RO

TL;DR: 提出了一种名为FCRF的灵活自我反思框架，用于提升家用机器人在复杂任务中的错误纠正能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM的自我反思机制不够灵活，限制了其在任务规划错误纠正中的效果。

Method: 采用Mentor-Actor架构，结合任务难度和历史经验进行灵活反思。

Result: 在AlfWorld仿真和真实环境中测试，FCRF显著提升了性能和反思灵活性。

Conclusion: FCRF为复杂任务中的自主错误纠正提供了有效解决方案。

Abstract: Autonomous error correction is critical for domestic robots to achieve
reliable execution of complex long-horizon tasks. Prior work has explored
self-reflection in Large Language Models (LLMs) for task planning error
correction; however, existing methods are constrained by inflexible
self-reflection mechanisms that limit their effectiveness. Motivated by these
limitations and inspired by human cognitive adaptation, we propose the Flexible
Constructivism Reflection Framework (FCRF), a novel Mentor-Actor architecture
that enables LLMs to perform flexible self-reflection based on task difficulty,
while constructively integrating historical valuable experience with failure
lessons. We evaluated FCRF on diverse domestic tasks through simulation in
AlfWorld and physical deployment in the real-world environment. Experimental
results demonstrate that FCRF significantly improves overall performance and
self-reflection flexibility in complex long-horizon robotic tasks.

</details>


### [19] [CPED-NCBFs: A Conformal Prediction for Expert Demonstration-based Neural Control Barrier Functions](https://arxiv.org/abs/2507.15022)
*Sumeadh MS,Kevin Dsouza,Ravi Prakash*

Main category: cs.RO

TL;DR: 该论文提出了一种基于分形共形预测的验证策略（CPED-NCBFs），用于验证从专家演示中学习的神经控制屏障函数（NCBFs）的安全性。


<details>
  <summary>Details</summary>
Motivation: 现有验证方法（如SMT求解器、混合整数规划等）在验证NCBFs时存在保守性高、边界松散的问题，需要更有效的验证策略。

Method: 采用分形共形预测方法（CPED-NCBFs）验证NCBFs，并在点质量系统和非完整模型上进行实验验证。

Result: 实验表明，CPED-NCBFs方法能有效验证NCBFs的安全性。

Conclusion: 提出的CPED-NCBFs方法解决了现有验证技术的局限性，为NCBFs的安全性验证提供了更优方案。

Abstract: Among the promising approaches to enforce safety in control systems, learning
Control Barrier Functions (CBFs) from expert demonstrations has emerged as an
effective strategy. However, a critical challenge remains: verifying that the
learned CBFs truly enforce safety across the entire state space. This is
especially difficult when CBF is represented using neural networks (NCBFs).
Several existing verification techniques attempt to address this problem
including SMT-based solvers, mixed-integer programming (MIP), and interval or
bound-propagation methods but these approaches often introduce loose,
conservative bounds. To overcome these limitations, in this work we use
CPED-NCBFs a split-conformal prediction based verification strategy to verify
the learned NCBF from the expert demonstrations. We further validate our method
on point mass systems and unicycle models to demonstrate the effectiveness of
the proposed theory.

</details>


### [20] [Touch in the Wild: Learning Fine-Grained Manipulation with a Portable Visuo-Tactile Gripper](https://arxiv.org/abs/2507.15062)
*Xinyue Zhu,Binghao Huang,Yunzhu Li*

Main category: cs.RO

TL;DR: 提出了一种便携式、轻量级夹持器，集成了触觉传感器，用于同步收集视觉和触觉数据，并通过跨模态表示学习框架提升机器人操作的精确性。


<details>
  <summary>Details</summary>
Motivation: 现有手持夹持器缺乏触觉反馈，而触觉反馈在精确操作中至关重要。

Method: 开发了集成触觉传感器的夹持器，并提出跨模态表示学习框架，整合视觉和触觉信号。

Result: 在试管插入和移液管流体转移等任务中，表现出更高的准确性和鲁棒性。

Conclusion: 该框架支持基于多模态反馈的高效机器人操作，提升了精确性和适应性。

Abstract: Handheld grippers are increasingly used to collect human demonstrations due
to their ease of deployment and versatility. However, most existing designs
lack tactile sensing, despite the critical role of tactile feedback in precise
manipulation. We present a portable, lightweight gripper with integrated
tactile sensors that enables synchronized collection of visual and tactile data
in diverse, real-world, and in-the-wild settings. Building on this hardware, we
propose a cross-modal representation learning framework that integrates visual
and tactile signals while preserving their distinct characteristics. The
learning procedure allows the emergence of interpretable representations that
consistently focus on contacting regions relevant for physical interactions.
When used for downstream manipulation tasks, these representations enable more
efficient and effective policy learning, supporting precise robotic
manipulation based on multimodal feedback. We validate our approach on
fine-grained tasks such as test tube insertion and pipette-based fluid
transfer, demonstrating improved accuracy and robustness under external
disturbances. Our project page is available at
https://binghao-huang.github.io/touch_in_the_wild/ .

</details>


### [21] [Search-Based Autonomous Vehicle Motion Planning Using Game Theory](https://arxiv.org/abs/2507.15088)
*Pouya Panahandeh,Mohammad Pirani,Baris Fidan,Amir Khajepour*

Main category: cs.RO

TL;DR: 提出了一种基于搜索的交互式运动规划方案，用于自动驾驶车辆，采用博弈论方法，将其他道路使用者视为智能体而非静态障碍物，生成更真实的路径，并实现实时应用。


<details>
  <summary>Details</summary>
Motivation: 传统搜索方法将其他道路用户视为静态障碍物，缺乏对智能行为的考虑，因此需要一种更真实的规划方案。

Method: 采用博弈论方法，将其他道路用户建模为智能体，结合搜索技术生成运动路径。

Result: 提出的方案计算时间短，适用于实时应用，实验验证表明其性能优于现有技术。

Conclusion: 该方案通过博弈论和搜索技术的结合，为自动驾驶车辆提供了更真实的运动规划能力。

Abstract: In this paper, we propose a search-based interactive motion planning scheme
for autonomous vehicles (AVs), using a game-theoretic approach. In contrast to
traditional search-based approaches, the newly developed approach considers
other road users (e.g. drivers and pedestrians) as intelligent agents rather
than static obstacles. This leads to the generation of a more realistic path
for the AV. Due to the low computational time, the proposed motion planning
scheme is implementable in real-time applications. The performance of the
developed motion planning scheme is compared with existing motion planning
techniques and validated through experiments using WATonoBus, an electrical
all-weather autonomous shuttle bus.

</details>


### [22] [Learning-Based Modeling of a Magnetically Steerable Soft Suction Device for Endoscopic Endonasal Interventions](https://arxiv.org/abs/2507.15155)
*Majid Roshanfar,Alex Zhang,Changyan He,Amir Hooshiar,Dale J. Podolsky,Thomas Looi,Eric Diller*

Main category: cs.RO

TL;DR: 提出了一种基于学习的磁控软吸引装置建模框架，用于内窥镜鼻内脑肿瘤切除，实现了亚毫米级的形状预测精度。


<details>
  <summary>Details</summary>
Motivation: 开发一种小型化、生物兼容的磁控软吸引装置，用于微创神经外科手术，解决传统物理假设模型的局限性。

Method: 使用3D打印技术制造装置，集成FBG传感器实时反馈形状，采用Bezier控制点表示形状重建，并通过NN和RF模型训练实验数据。

Result: RF模型表现优于NN，控制点预测均方根误差为0.087 mm，形状重建误差为0.064 mm。

Conclusion: 该学习框架有效建模了磁控软机器人的非线性行为，为微创神经外科手术中的智能控制提供了新方法。

Abstract: This letter introduces a novel learning-based modeling framework for a
magnetically steerable soft suction device designed for endoscopic endonasal
brain tumor resection. The device is miniaturized (4 mm outer diameter, 2 mm
inner diameter, 40 mm length), 3D printed using biocompatible SIL 30 material,
and integrates embedded Fiber Bragg Grating (FBG) sensors for real-time shape
feedback. Shape reconstruction is represented using four Bezier control points,
enabling a compact and smooth model of the device's deformation. A data-driven
model was trained on 5,097 experimental samples covering a range of magnetic
field magnitudes (0-14 mT), actuation frequencies (0.2-1.0 Hz), and vertical
tip distances (90-100 mm), using both Neural Network (NN) and Random Forest
(RF) architectures. The RF model outperformed the NN across all metrics,
achieving a mean root mean square error of 0.087 mm in control point prediction
and a mean shape reconstruction error of 0.064 mm. Feature importance analysis
further revealed that magnetic field components predominantly influence distal
control points, while frequency and distance affect the base configuration.
This learning-based approach effectively models the complex nonlinear behavior
of hyperelastic soft robots under magnetic actuation without relying on
simplified physical assumptions. By enabling sub-millimeter shape prediction
accuracy and real-time inference, this work represents an advancement toward
the intelligent control of magnetically actuated soft robotic tools in
minimally invasive neurosurgery.

</details>


### [23] [CHADET: Cross-Hierarchical-Attention for Depth-Completion Using Unsupervised Lightweight Transformer](https://arxiv.org/abs/2507.15189)
*Kevin Christiansen Marsim,Jinwoo Jeon,Yeeun Kim,Myeongwoo Jeong,Hyun Myung*

Main category: cs.RO

TL;DR: 提出了一种轻量级深度补全网络CHADET，通过RGB图像和稀疏深度点生成精确的密集深度图，解决了现有方法在计算效率和准确性之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 深度信息对机器人任务至关重要，但现有深度补全方法在计算效率和准确性之间存在显著权衡，无法满足实时应用需求。

Method: 提出CHADET网络，结合深度块特征提取和轻量级基于Transformer的解码器，利用跨层次注意力模块优化图像特征。

Result: 在KITTI、NYUv2和VOID数据集上验证了方法的有效性，提高了深度图预测质量并减少了内存使用。

Conclusion: CHADET在保持轻量级的同时提升了深度补全的准确性和效率，适用于实时机器人任务。

Abstract: Depth information which specifies the distance between objects and current
position of the robot is essential for many robot tasks such as navigation.
Recently, researchers have proposed depth completion frameworks to provide
dense depth maps that offer comprehensive information about the surrounding
environment. However, existing methods show significant trade-offs between
computational efficiency and accuracy during inference. The substantial memory
and computational requirements make them unsuitable for real-time applications,
highlighting the need to improve the completeness and accuracy of depth
information while improving processing speed to enhance robot performance in
various tasks. To address these challenges, in this paper, we propose
CHADET(cross-hierarchical-attention depth-completion transformer), a
lightweight depth-completion network that can generate accurate dense depth
maps from RGB images and sparse depth points. For each pair, its feature is
extracted from the depthwise blocks and passed to the equally lightweight
transformer-based decoder. In the decoder, we utilize the novel
cross-hierarchical-attention module that refines the image features from the
depth information. Our approach improves the quality and reduces memory usage
of the depth map prediction, as validated in both KITTI, NYUv2, and VOID
datasets.

</details>


### [24] [VLM-UDMC: VLM-Enhanced Unified Decision-Making and Motion Control for Urban Autonomous Driving](https://arxiv.org/abs/2507.15266)
*Haichao Liu,Haoren Guo,Pei Liu,Benshan Ma,Yuxiang Zhang,Jun Ma,Tong Heng Lee*

Main category: cs.RO

TL;DR: 论文提出了一种基于视觉语言模型（VLM）的统一决策与运动控制框架VLM-UDMC，通过场景推理和风险感知提升自动驾驶的透明度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 模仿人类驾驶员的场景理解和风险感知能力，提升自动驾驶的安全性和效率。

Method: 采用VLM增强的框架，结合检索增强生成（RAG）和多核分解LSTM，实现动态运动规划和实时轨迹预测。

Result: 通过仿真和真实实验验证，VLM-UDMC显著提升了城市驾驶性能。

Conclusion: VLM-UDMC框架有效结合场景理解和注意力分解，为自动驾驶提供了更合理的决策支持。

Abstract: Scene understanding and risk-aware attentions are crucial for human drivers
to make safe and effective driving decisions. To imitate this cognitive ability
in urban autonomous driving while ensuring the transparency and
interpretability, we propose a vision-language model (VLM)-enhanced unified
decision-making and motion control framework, named VLM-UDMC. This framework
incorporates scene reasoning and risk-aware insights into an upper-level slow
system, which dynamically reconfigures the optimal motion planning for the
downstream fast system. The reconfiguration is based on real-time environmental
changes, which are encoded through context-aware potential functions. More
specifically, the upper-level slow system employs a two-step reasoning policy
with Retrieval-Augmented Generation (RAG), leveraging foundation models to
process multimodal inputs and retrieve contextual knowledge, thereby generating
risk-aware insights. Meanwhile, a lightweight multi-kernel decomposed LSTM
provides real-time trajectory predictions for heterogeneous traffic
participants by extracting smoother trend representations for short-horizon
trajectory prediction. The effectiveness of the proposed VLM-UDMC framework is
verified via both simulations and real-world experiments with a full-size
autonomous vehicle. It is demonstrated that the presented VLM-UDMC effectively
leverages scene understanding and attention decomposition for rational driving
decisions, thus improving the overall urban driving performance. Our
open-source project is available at https://github.com/henryhcliu/vlmudmc.git.

</details>


### [25] [RepILN: Reparameterized Inertial Localization Network](https://arxiv.org/abs/2507.15293)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一种重参数化的惯性定位网络，通过多分支结构增强特征提取，并在推理时转换为单路径架构以提高参数效率。引入时间尺度稀疏注意力机制和门控卷积单元，以捕捉长期依赖关系并整合局部特征。实验表明，该方法在精度和模型紧凑性之间取得了良好平衡。


<details>
  <summary>Details</summary>
Motivation: 惯性定位因其成本效益和独立性成为物联网设备的潜在解决方案，但现有方法依赖复杂网络架构，且忽视长期依赖建模，限制了性能。

Method: 采用多分支训练结构，推理时转换为单路径架构；引入时间尺度稀疏注意力机制和门控卷积单元。

Result: 在RoNIN数据集上，绝对轨迹误差降低2.59%，参数数量减少3.86%。

Conclusion: 该方法在精度和模型效率之间取得了显著改进，适用于资源受限的物联网设备。

Abstract: Inertial localization is regarded as a promising positioning solution for
consumer-grade IoT devices due to its cost-effectiveness and independence from
external infrastructure. However, data-driven inertial localization methods
often rely on increasingly complex network architectures to improve accuracy,
which challenges the limited computational resources of IoT devices. Moreover,
these methods frequently overlook the importance of modeling long-term
dependencies in inertial measurements - a critical factor for accurate
trajectory reconstruction - thereby limiting localization performance. To
address these challenges, we propose a reparameterized inertial localization
network that uses a multi-branch structure during training to enhance feature
extraction. At inference time, this structure is transformed into an equivalent
single-path architecture to improve parameter efficiency. To further capture
long-term dependencies in motion trajectories, we introduce a temporal-scale
sparse attention mechanism that selectively emphasizes key trajectory segments
while suppressing noise. Additionally, a gated convolutional unit is
incorporated to effectively integrate long-range dependencies with local
fine-grained features. Extensive experiments on public benchmarks demonstrate
that our method achieves a favorable trade-off between accuracy and model
compactness. For example, on the RoNIN dataset, our approach reduces the
Absolute Trajectory Error (ATE) by 2.59% compared to RoNIN-ResNet while
reducing the number of parameters by 3.86%.

</details>


### [26] [Low-Latency Event-Based Velocimetry for Quadrotor Control in a Narrow Pipe](https://arxiv.org/abs/2507.15444)
*Leonard Bauersfeld,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 提出了一种基于实时流场测量的四旋翼无人机闭环控制系统，用于在狭窄管道中悬停，解决了气流扰动问题。


<details>
  <summary>Details</summary>
Motivation: 在狭窄管道中飞行的四旋翼无人机面临气流扰动挑战，现有方法依赖持续运动或稳定性不足。

Method: 开发了低延迟事件式烟雾测速法，结合循环卷积神经网络估计扰动，并通过强化学习训练控制器。

Result: 系统在管道横向移动中有效抵消气流扰动，避免碰撞，首次实现基于实时流场测量的闭环控制。

Conclusion: 该研究为复杂气流环境中的飞行提供了新方法，并揭示了管道飞行中的流体动力学特性。

Abstract: Autonomous quadrotor flight in confined spaces such as pipes and tunnels
presents significant challenges due to unsteady, self-induced aerodynamic
disturbances. Very recent advances have enabled flight in such conditions, but
they either rely on constant motion through the pipe to mitigate airflow
recirculation effects or suffer from limited stability during hovering. In this
work, we present the first closed-loop control system for quadrotors for
hovering in narrow pipes that leverages real-time flow field measurements. We
develop a low-latency, event-based smoke velocimetry method that estimates
local airflow at high temporal resolution. This flow information is used by a
disturbance estimator based on a recurrent convolutional neural network, which
infers force and torque disturbances in real time. The estimated disturbances
are integrated into a learning-based controller trained via reinforcement
learning. The flow-feedback control proves particularly effective during
lateral translation maneuvers in the pipe cross-section. There, the real-time
disturbance information enables the controller to effectively counteract
transient aerodynamic effects, thereby preventing collisions with the pipe
wall. To the best of our knowledge, this work represents the first
demonstration of an aerial robot with closed-loop control informed by real-time
flow field measurements. This opens new directions for research on flight in
aerodynamically complex environments. In addition, our work also sheds light on
the characteristic flow structures that emerge during flight in narrow,
circular pipes, providing new insights at the intersection of robotics and
fluid dynamics.

</details>


### [27] [The Emergence of Deep Reinforcement Learning for Path Planning](https://arxiv.org/abs/2507.15469)
*Thanh Thi Nguyen,Saeid Nahavandi,Imran Razzak,Dung Nguyen,Nhat Truong Pham,Quoc Viet Hung Nguyen*

Main category: cs.RO

TL;DR: 本文综述了智能路径规划方法，包括传统图搜索、线性规划和进化计算，以及新兴的深度强化学习（DRL），并探讨了它们在自动驾驶、无人机和机器人中的应用。


<details>
  <summary>Details</summary>
Motivation: 复杂动态环境中对自主系统的需求增加，推动了智能路径规划方法的研究。

Method: 分类比较了传统方法和DRL算法，并讨论了它们的计算效率、可扩展性和适应性。

Result: 总结了各类方法的优缺点，并提出了结合DRL与传统技术的混合方法。

Conclusion: 指出了未来研究的开放挑战，尤其是混合方法在提升自主导航鲁棒性和适应性方面的潜力。

Abstract: The increasing demand for autonomous systems in complex and dynamic
environments has driven significant research into intelligent path planning
methodologies. For decades, graph-based search algorithms, linear programming
techniques, and evolutionary computation methods have served as foundational
approaches in this domain. Recently, deep reinforcement learning (DRL) has
emerged as a powerful method for enabling autonomous agents to learn optimal
navigation strategies through interaction with their environments. This survey
provides a comprehensive overview of traditional approaches as well as the
recent advancements in DRL applied to path planning tasks, focusing on
autonomous vehicles, drones, and robotic platforms. Key algorithms across both
conventional and learning-based paradigms are categorized, with their
innovations and practical implementations highlighted. This is followed by a
thorough discussion of their respective strengths and limitations in terms of
computational efficiency, scalability, adaptability, and robustness. The survey
concludes by identifying key open challenges and outlining promising avenues
for future research. Special attention is given to hybrid approaches that
integrate DRL with classical planning techniques to leverage the benefits of
both learning-based adaptability and deterministic reliability, offering
promising directions for robust and resilient autonomous navigation.

</details>


### [28] [All-UWB SLAM Using UWB Radar and UWB AOA](https://arxiv.org/abs/2507.15474)
*Charith Premachandra,Achala Athukorala,U-Xuan Tan*

Main category: cs.RO

TL;DR: 提出了一种结合UWB雷达和AOA测量的新方法，用于在视觉受限且特征缺乏的环境中提升SLAM的准确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 在恶劣环境（如烟雾、灰尘）中，光学传感器易失效，UWB雷达因其穿透能力成为SLAM的潜在解决方案，但现有方法受限于环境特征数量。

Method: 通过动态部署UWB锚点-标签单元获取AOA测量，将其整合到UWB雷达SLAM系统中，以解决特征缺乏问题。

Result: 实验表明，结合UWB AOA单元的SLAM系统能在视觉受限且特征缺乏的环境中有效工作。

Conclusion: 该方法显著提升了SLAM在恶劣环境中的性能，为未来研究提供了新方向。

Abstract: There has been a growing interest in autonomous systems designed to operate
in adverse conditions (e.g. smoke, dust), where the visible light spectrum
fails. In this context, Ultra-wideband (UWB) radar is capable of penetrating
through such challenging environmental conditions due to the lower frequency
components within its broad bandwidth. Therefore, UWB radar has emerged as a
potential sensing technology for Simultaneous Localization and Mapping (SLAM)
in vision-denied environments where optical sensors (e.g. LiDAR, Camera) are
prone to failure. Existing approaches involving UWB radar as the primary
exteroceptive sensor generally extract features in the environment, which are
later initialized as landmarks in a map. However, these methods are constrained
by the number of distinguishable features in the environment. Hence, this paper
proposes a novel method incorporating UWB Angle of Arrival (AOA) measurements
into UWB radar-based SLAM systems to improve the accuracy and scalability of
SLAM in feature-deficient environments. The AOA measurements are obtained using
UWB anchor-tag units which are dynamically deployed by the robot in featureless
areas during mapping of the environment. This paper thoroughly discusses
prevailing constraints associated with UWB AOA measurement units and presents
solutions to overcome them. Our experimental results show that integrating UWB
AOA units with UWB radar enables SLAM in vision-denied feature-deficient
environments.

</details>


### [29] [The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents](https://arxiv.org/abs/2507.15478)
*Simon Kohaut,Felix Divo,Navid Hamid,Benedict Flade,Julian Eggert,Devendra Singh Dhami,Kristian Kersting*

Main category: cs.RO

TL;DR: 论文提出了一种神经符号系统框架CoCo，结合概率符号推理与深度学习，提升自主代理在不确定环境中的安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决自主代理在不确定环境中可靠且合规行为的挑战。

Method: 引入Constitutional Controller (CoCo)框架，结合深度概率逻辑程序和自怀疑机制。

Result: 在真实世界空中交通研究中，CoCo成功提升了系统的安全性和合规性。

Conclusion: CoCo框架为复杂不确定环境中的自主代理提供了一种有效的解决方案。

Abstract: Ensuring reliable and rule-compliant behavior of autonomous agents in
uncertain environments remains a fundamental challenge in modern robotics. Our
work shows how neuro-symbolic systems, which integrate probabilistic, symbolic
white-box reasoning models with deep learning methods, offer a powerful
solution to this challenge. This enables the simultaneous consideration of
explicit rules and neural models trained on noisy data, combining the strength
of structured reasoning with flexible representations. To this end, we
introduce the Constitutional Controller (CoCo), a novel framework designed to
enhance the safety and reliability of agents by reasoning over deep
probabilistic logic programs representing constraints such as those found in
shared traffic spaces. Furthermore, we propose the concept of self-doubt,
implemented as a probability density conditioned on doubt features such as
travel velocity, employed sensors, or health factors. In a real-world aerial
mobility study, we demonstrate CoCo's advantages for intelligent autonomous
systems to learn appropriate doubts and navigate complex and uncertain
environments safely and compliantly.

</details>


### [30] [Robots for Kiwifruit Harvesting and Pollination](https://arxiv.org/abs/2507.15484)
*Jamie Bell*

Main category: cs.RO

TL;DR: 研究开发了用于猕猴桃果园的移动机器人，实现了定向花粉喷洒和自动化采摘，改进了采摘机制和导航系统。


<details>
  <summary>Details</summary>
Motivation: 解决猕猴桃果园中自动化采摘和花粉喷洒的挑战，提高效率和覆盖范围。

Method: 设计了多种猕猴桃采摘机制，测试了其中一种；使用2D和3D激光雷达进行导航；开发了计算机视觉算法。

Result: 采摘机制覆盖了80%以上的果实，优于之前的70%；花粉喷洒和导航系统在测试中表现良好。

Conclusion: 移动机器人和新技术显著提升了猕猴桃果园的自动化作业效率。

Abstract: This research was a part of a project that developed mobile robots that
performed targeted pollen spraying and automated harvesting in pergola
structured kiwifruit orchards. Multiple kiwifruit detachment mechanisms were
designed and field testing of one of the concepts showed that the mechanism
could reliably pick kiwifruit. Furthermore, this kiwifruit detachment mechanism
was able to reach over 80 percent of fruit in the cluttered kiwifruit canopy,
whereas the previous state of the art mechanism was only able to reach less
than 70 percent of the fruit. Artificial pollination was performed by detecting
flowers and then spraying pollen in solution onto the detected flowers from a
line of sprayers on a boom, while driving at up to 1.4 ms-1. In addition, the
height of the canopy was measured and the spray boom was moved up and down to
keep the boom close enough to the flowers for the spray to reach the flowers,
while minimising collisions with the canopy. Mobile robot navigation was
performed using a 2D lidar in apple orchards and vineyards. Lidar navigation in
kiwifruit orchards was more challenging because the pergola structure only
provides a small amount of data for the direction of rows, compared to the
amount of data from the overhead canopy, the undulating ground and other
objects in the orchards. Multiple methods are presented here for extracting
structure defining features from 3D lidar data in kiwifruit orchards. In
addition, a 3D lidar navigation system -- which performed row following, row
end detection and row end turns -- was tested for over 30 km of autonomous
driving in kiwifruit orchards. Computer vision algorithms for row detection and
row following were also tested. The computer vision algorithm worked as well as
the 3D lidar row following method in testing.

</details>


### [31] [GR-3 Technical Report](https://arxiv.org/abs/2507.15493)
*Chilam Cheang,Sijin Chen,Zhongren Cui,Yingdong Hu,Liqun Huang,Tao Kong,Hang Li,Yifeng Li,Yuxiao Liu,Xiao Ma,Hao Niu,Wenxuan Ou,Wanli Peng,Zeyu Ren,Haixin Shi,Jiawen Tian,Hongtao Wu,Xin Xiao,Yuyang Xiao,Jiafeng Xu,Yichu Yang*

Main category: cs.RO

TL;DR: GR-3是一个大规模视觉-语言-动作模型，展示了在新对象、环境和抽象指令上的泛化能力，并能高效微调。


<details>
  <summary>Details</summary>
Motivation: 目标是构建通用机器人策略，以辅助人类日常生活。

Method: 通过多方面的训练方法，包括网络规模视觉-语言数据协同训练、VR设备收集的人类轨迹数据微调，以及机器人轨迹数据的模仿学习。

Result: GR-3在多种挑战性任务中超越了现有基准方法π₀，尤其在长时程和灵巧任务中表现优异。

Conclusion: GR-3是迈向通用机器人技术的重要一步，展示了其在现实世界中的潜力。

Abstract: We report our recent progress towards building generalist robot policies, the
development of GR-3. GR-3 is a large-scale vision-language-action (VLA) model.
It showcases exceptional capabilities in generalizing to novel objects,
environments, and instructions involving abstract concepts. Furthermore, it can
be efficiently fine-tuned with minimal human trajectory data, enabling rapid
and cost-effective adaptation to new settings. GR-3 also excels in handling
long-horizon and dexterous tasks, including those requiring bi-manual
manipulation and mobile movement, showcasing robust and reliable performance.
These capabilities are achieved through a multi-faceted training recipe that
includes co-training with web-scale vision-language data, efficient fine-tuning
from human trajectory data collected via VR devices, and effective imitation
learning with robot trajectory data. In addition, we introduce ByteMini, a
versatile bi-manual mobile robot designed with exceptional flexibility and
reliability, capable of accomplishing a wide range of tasks when integrated
with GR-3. Through extensive real-world experiments, we show GR-3 surpasses the
state-of-the-art baseline method, $\pi_0$, on a wide variety of challenging
tasks. We hope GR-3 can serve as a step towards building generalist robots
capable of assisting humans in daily life.

</details>


### [32] [CLEVER: Stream-based Active Learning for Robust Semantic Perception from Human Instructions](https://arxiv.org/abs/2507.15499)
*Jongseok Lee,Timo Birr,Rudolph Triebel,Tamim Asfour*

Main category: cs.RO

TL;DR: CLEVER是一个基于深度神经网络的主动学习系统，通过在线获取人类支持并适应指令，提升语义感知的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络在流数据语义感知任务中的失败问题，通过人类干预和在线适应提升性能。

Method: 采用贝叶斯框架编码领域知识，设计了一个满足多需求的系统，并通过用户验证和实验验证其能力。

Result: 在真实机器人上实现了流式主动学习，提升了语义感知的鲁棒性。

Conclusion: CLEVER系统首次在真实机器人上实现了流式主动学习，证明了其在实际中提升语义感知鲁棒性的潜力。

Abstract: We propose CLEVER, an active learning system for robust semantic perception
with Deep Neural Networks (DNNs). For data arriving in streams, our system
seeks human support when encountering failures and adapts DNNs online based on
human instructions. In this way, CLEVER can eventually accomplish the given
semantic perception tasks. Our main contribution is the design of a system that
meets several desiderata of realizing the aforementioned capabilities. The key
enabler herein is our Bayesian formulation that encodes domain knowledge
through priors. Empirically, we not only motivate CLEVER's design but further
demonstrate its capabilities with a user validation study as well as
experiments on humanoid and deformable objects. To our knowledge, we are the
first to realize stream-based active learning on a real robot, providing
evidence that the robustness of the DNN-based semantic perception can be
improved in practice. The project website can be accessed at
https://sites.google.com/view/thecleversystem.

</details>


### [33] [Estimation of Payload Inertial Parameters from Human Demonstrations by Hand Guiding](https://arxiv.org/abs/2507.15604)
*Johannes Hartwig,Philipp Lienhardt,Dominik Henrich*

Main category: cs.RO

TL;DR: 论文提出了一种方法，通过利用非接触运动部分估计机器人工具的负载惯性参数（PIP），从而无需专门的PIP校准，使非专家用户能更高效地编程接触运动。


<details>
  <summary>Details</summary>
Motivation: 随着协作机器人（cobot）的普及，需要让缺乏编程知识的用户也能高效操作系统。现有的编程方法依赖手引导等直观交互，但接触运动编程需要知道工具负载惯性参数（PIP），限制了灵活性。

Method: 利用任务中的非接触运动部分，通过已有估计技术估算PIP，避免专门的校准步骤。

Result: 实验显示，负载质量的估计准确，但质心和惯性张量受噪声和激励不足的影响。

Conclusion: 该方法证明了在手引导中估计PIP的可行性，但需要足够的负载加速度以提高估计精度。

Abstract: As the availability of cobots increases, it is essential to address the needs
of users with little to no programming knowledge to operate such systems
efficiently. Programming concepts often use intuitive interaction modalities,
such as hand guiding, to address this. When programming in-contact motions,
such frameworks require knowledge of the robot tool's payload inertial
parameters (PIP) in addition to the demonstrated velocities and forces to
ensure effective hybrid motion-force control. This paper aims to enable
non-expert users to program in-contact motions more efficiently by eliminating
the need for a dedicated PIP calibration, thereby enabling flexible robot tool
changes. Since demonstrated tasks generally also contain motions with
non-contact, our approach uses these parts to estimate the robot's PIP using
established estimation techniques. The results show that the estimation of the
payload's mass is accurate, whereas the center of mass and the inertia tensor
are affected by noise and a lack of excitation. Overall, these findings show
the feasibility of PIP estimation during hand guiding but also highlight the
need for sufficient payload accelerations for an accurate estimation.

</details>


### [34] [A Universal Vehicle-Trailer Navigation System with Neural Kinematics and Online Residual Learning](https://arxiv.org/abs/2507.15607)
*Yanbo Chen,Yunzhe Tan,Yaojia Wang,Zhengzhe Xu,Junbo Tan,Xueqian Wang*

Main category: cs.RO

TL;DR: 提出一种新型通用车辆-拖车导航系统，结合混合运动学模型和在线残差学习模块，通过模型预测控制框架实现鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 解决车辆-拖车系统（尤其是带脚轮的拖车）在复杂环境中的精确建模和导航问题。

Method: 结合经典非完整约束和神经网络拖车运动学的混合模型，辅以在线残差学习模块；采用加权模型组合策略的模型预测控制框架。

Result: 在多种拖车类型和负载条件下验证，无需手动调整或拖车特定校准，表现鲁棒。

Conclusion: 该系统在复杂环境中实现了高效、安全的车辆-拖车导航。

Abstract: Autonomous navigation of vehicle-trailer systems is crucial in environments
like airports, supermarkets, and concert venues, where various types of
trailers are needed to navigate with different payloads and conditions.
However, accurately modeling such systems remains challenging, especially for
trailers with castor wheels. In this work, we propose a novel universal
vehicle-trailer navigation system that integrates a hybrid nominal kinematic
model--combining classical nonholonomic constraints for vehicles and neural
network-based trailer kinematics--with a lightweight online residual learning
module to correct real-time modeling discrepancies and disturbances.
Additionally, we develop a model predictive control framework with a weighted
model combination strategy that improves long-horizon prediction accuracy and
ensures safer motion planning. Our approach is validated through extensive
real-world experiments involving multiple trailer types and varying payload
conditions, demonstrating robust performance without manual tuning or
trailer-specific calibration.

</details>


### [35] [Optimizing Force Signals from Human Demonstrations of In-Contact Motions](https://arxiv.org/abs/2507.15608)
*Johannes Hartwig,Fabian Viessmann,Dominik Henrich*

Main category: cs.RO

TL;DR: 论文探讨了通过优化力信号以更好地反映人类意图，比较了不同信号滤波方法，并提出了一种峰值检测方法以减少首次接触偏差。


<details>
  <summary>Details</summary>
Motivation: 为非机器人编程专家提供更直观的输入方法，解决人类演示中不精确和噪声信号的问题。

Method: 比较不同信号滤波方法，提出峰值检测方法，并分析关键参数对滤波方法的影响。

Result: 单个运动的误差标准可提高达20%。

Conclusion: 提出的方法能提升机器人编程的可用性和人机交互体验。

Abstract: For non-robot-programming experts, kinesthetic guiding can be an intuitive
input method, as robot programming of in-contact tasks is becoming more
prominent. However, imprecise and noisy input signals from human demonstrations
pose problems when reproducing motions directly or using the signal as input
for machine learning methods. This paper explores optimizing force signals to
correspond better to the human intention of the demonstrated signal. We compare
different signal filtering methods and propose a peak detection method for
dealing with first-contact deviations in the signal. The evaluation of these
methods considers a specialized error criterion between the input and the
human-intended signal. In addition, we analyze the critical parameters'
influence on the filtering methods. The quality for an individual motion could
be increased by up to \SI{20}{\percent} concerning the error criterion. The
proposed contribution can improve the usability of robot programming and the
interaction between humans and robots.

</details>


### [36] [EMP: Executable Motion Prior for Humanoid Robot Standing Upper-body Motion Imitation](https://arxiv.org/abs/2507.15649)
*Haocheng Xu,Haodong Zhang,Zhenghan Chen,Rong Xiong*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的框架，使人形机器人模仿人类上半身动作并保持整体稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究人形机器人在站立时如何稳定执行上半身动作，解决其可控范围有限的问题。

Method: 设计了重定向网络生成大规模动作数据集，结合强化学习策略和领域随机化，并引入可执行运动先验（EMP）模块调整目标动作。

Result: 通过仿真和实际测试验证了框架的实用性，提高了机器人的稳定性和动作执行能力。

Conclusion: 该框架有效解决了人形机器人在模仿人类动作时的稳定性问题，具有实际应用价值。

Abstract: To support humanoid robots in performing manipulation tasks, it is essential
to study stable standing while accommodating upper-body motions. However, the
limited controllable range of humanoid robots in a standing position affects
the stability of the entire body. Thus we introduce a reinforcement learning
based framework for humanoid robots to imitate human upper-body motions while
maintaining overall stability. Our approach begins with designing a retargeting
network that generates a large-scale upper-body motion dataset for training the
reinforcement learning (RL) policy, which enables the humanoid robot to track
upper-body motion targets, employing domain randomization for enhanced
robustness. To avoid exceeding the robot's execution capability and ensure
safety and stability, we propose an Executable Motion Prior (EMP) module, which
adjusts the input target movements based on the robot's current state. This
adjustment improves standing stability while minimizing changes to motion
amplitude. We evaluate our framework through simulation and real-world tests,
demonstrating its practical applicability.

</details>


### [37] [Data-Driven MPC with Data Selection for Flexible Cable-Driven Robotic Arms](https://arxiv.org/abs/2507.15677)
*Huayue Liang,Yanbo Chen,Hongyang Cheng,Yanzhao Yu,Shoujie Li,Junbo Tan,Xueqian Wang,Long Zeng*

Main category: cs.RO

TL;DR: 本文提出了一种基于输入输出数据的模型预测控制（MPC）方法，用于提高柔性电缆驱动机械臂（FCRA）的控制精度，无需物理模型。通过数据选择算法（DSA）优化计算效率，并在实验中验证了其性能优于传统PID方法。


<details>
  <summary>Details</summary>
Motivation: 柔性电缆驱动机械臂（FCRAs）的电缆特性（如弹性、迟滞和摩擦）导致建模和控制困难，传统方法难以精确控制。

Method: 1. 基于输入输出数据构建隐式模型，并集成到MPC框架中；2. 引入数据选择算法（DSA）优化计算效率；3. 通过仿真研究超参数对跟踪误差的影响。

Result: 实验表明，平均定位精度约为2.070毫米，跟踪误差为0.541度，优于PID方法的1.418度。计算效率提升80%，每步求解时间降至约4毫秒。

Conclusion: 提出的MPC方法显著提高了FCRA的控制精度和计算效率，适用于实际应用。

Abstract: Flexible cable-driven robotic arms (FCRAs) offer dexterous and compliant
motion. Still, the inherent properties of cables, such as resilience,
hysteresis, and friction, often lead to particular difficulties in modeling and
control. This paper proposes a model predictive control (MPC) method that
relies exclusively on input-output data, without a physical model, to improve
the control accuracy of FCRAs. First, we develop an implicit model based on
input-output data and integrate it into an MPC optimization framework. Second,
a data selection algorithm (DSA) is introduced to filter the data that best
characterize the system, thereby reducing the solution time per step to
approximately 4 ms, which is an improvement of nearly 80%. Lastly, the
influence of hyperparameters on tracking error is investigated through
simulation. The proposed method has been validated on a real FCRA platform,
including five-point positioning accuracy tests, a five-point response tracking
test, and trajectory tracking for letter drawing. The results demonstrate that
the average positioning accuracy is approximately 2.070 mm. Moreover, compared
to the PID method with an average tracking error of 1.418{\deg}, the proposed
method achieves an average tracking error of 0.541{\deg}.

</details>


### [38] [Strong, Accurate, and Low-Cost Robot Manipulator](https://arxiv.org/abs/2507.15693)
*Georges Chebly,Spencer Little,Nisal Perera,Aliya Abedeen,Ken Suzuki,Donghyun Kim*

Main category: cs.RO

TL;DR: Forte是一款全3D打印的6自由度机械臂，具有接近工业级的性能（0.63 kg负载、0.467 m工作范围和亚毫米级重复精度），成本低于215美元。


<details>
  <summary>Details</summary>
Motivation: 推动低成本教育机械臂的性能极限，适用于课堂教育和AI实验。

Method: 采用成本效益高的机械设计，包括基于绞盘的电缆驱动、同步带、简单张紧机构和轻量化3D打印结构，结合拓扑优化提升结构刚度。

Result: 实验验证显示Forte具有高重复性和负载能力。

Conclusion: Forte为课堂教学和高级机器人研究提供了一个有吸引力的平台。

Abstract: This paper presents Forte, a fully 3D-printable, 6-DoF robotic arm designed
to achieve near industrial-grade performance - 0.63 kg payload, 0.467 m reach,
and sub-millimeter repeatability - at a material cost under $215. As an
accessible robot for broad applications across classroom education to AI
experiments, Forte pushes forward the performance limitations of existing
low-cost educational arms. We introduce a cost-effective mechanical design that
combines capstan-based cable drives, timing belts, simple tensioning
mechanisms, and lightweight 3D-printed structures, along with topology
optimization for structural stiffness. Through careful drivetrain engineering,
we minimize backlash and maintain control fidelity without relying on
high-power electronics or expensive manufacturing processes. Experimental
validation demonstrates that Forte achieves high repeatability and load
capacity, offering a compelling robotic platform for both classroom instruction
and advanced robotics research.

</details>


### [39] [Selective Densification for Rapid Motion Planning in High Dimensions with Narrow Passages](https://arxiv.org/abs/2507.15710)
*Lu Huang,Lingxiao Meng,Jiankun Wang,Xingjian Jing*

Main category: cs.RO

TL;DR: 提出了一种高效的多分辨率采样规划框架，通过动态调整采样密度，在复杂配置空间中保持规划速度和完整性。


<details>
  <summary>Details</summary>
Motivation: 解决现有采样规划算法在复杂配置空间中效率低、通用性差或需大量训练的问题。

Method: 结合不同粒度的规划，动态调整稀疏与密集采样，在线探索多分辨率样本。

Result: 在多种配置空间和机器人实验中，表现优于现有方法。

Conclusion: 该方法在复杂环境中高效且通用，无需大量先验训练。

Abstract: Sampling-based algorithms are widely used for motion planning in
high-dimensional configuration spaces. However, due to low sampling efficiency,
their performance often diminishes in complex configuration spaces with narrow
corridors. Existing approaches address this issue using handcrafted or learned
heuristics to guide sampling toward useful regions. Unfortunately, these
strategies often lack generalizability to various problems or require extensive
prior training. In this paper, we propose a simple yet efficient sampling-based
planning framework along with its bidirectional version that overcomes these
issues by integrating different levels of planning granularity. Our approach
probes configuration spaces with uniform random samples at varying resolutions
and explores these multi-resolution samples online with a bias towards sparse
samples when traveling large free configuration spaces. By seamlessly
transitioning between sparse and dense samples, our approach can navigate
complex configuration spaces while maintaining planning speed and completeness.
The simulation results demonstrate that our approach outperforms several
state-of-the-art sampling-based planners in $\mathbb{SE}(2)$, $\mathbb{SE}(3)$,
and $\mathbb{R}^{14}$ with challenging terrains. Furthermore, experiments
conducted with the Franka Emika Panda robot operating in a constrained
workspace provide additional evidence of the superiority of the proposed
method.

</details>


### [40] [DiffPF: Differentiable Particle Filtering with Generative Sampling via Conditional Diffusion Models](https://arxiv.org/abs/2507.15716)
*Ziyu Wan,Lin Zhao*

Main category: cs.RO

TL;DR: DiffPF是一种可微分粒子滤波器，利用扩散模型进行动态系统的状态估计，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统可微分粒子滤波器依赖预定义或低容量提议分布，限制了性能。DiffPF旨在通过扩散模型学习灵活的后验采样器，提升状态估计精度。

Method: DiffPF通过将扩散模型条件化于预测粒子和当前观测，实现复杂、高维、多模态分布的高质量采样。

Result: 在模拟和真实任务中，DiffPF表现优异，如在多模态全局定位任务中精度提升82.8%，在KITTI视觉测距任务中提升26%。

Conclusion: DiffPF首次将条件扩散模型引入粒子滤波，显著提升了后验采样质量和状态估计性能。

Abstract: This paper proposes DiffPF, a differentiable particle filter that leverages
diffusion models for state estimation in dynamic systems. Unlike conventional
differentiable particle filters, which require importance weighting and
typically rely on predefined or low-capacity proposal distributions. DiffPF
learns a flexible posterior sampler by conditioning a diffusion model on
predicted particles and the current observation. This enables accurate,
equally-weighted sampling from complex, high-dimensional, and multimodal
filtering distributions. We evaluate DiffPF across a range of scenarios,
including both unimodal and highly multimodal distributions, and test it on
simulated as well as real-world tasks, where it consistently outperforms
existing filtering baselines. In particular, DiffPF achieves an 82.8%
improvement in estimation accuracy on a highly multimodal global localization
benchmark, and a 26% improvement on the real-world KITTI visual odometry
benchmark, compared to state-of-the-art differentiable filters. To the best of
our knowledge, DiffPF is the first method to integrate conditional diffusion
models into particle filtering, enabling high-quality posterior sampling that
produces more informative particles and significantly improves state
estimation.

</details>


### [41] [Gaze-supported Large Language Model Framework for Bi-directional Human-Robot Interaction](https://arxiv.org/abs/2507.15729)
*Jens V. Rüppel,Andrey Rudenko,Tim Schreiter,Martin Magnusson,Achim J. Lilienthal*

Main category: cs.RO

TL;DR: 论文提出了一种基于大语言模型（LLM）的辅助机器人交互系统，通过多模态输入（如视线和语音）实现动态任务支持，并在实验中与传统脚本化系统进行了比较。


<details>
  <summary>Details</summary>
Motivation: 现有的人机交互系统在单向指令执行和任务解决方面已有显著进展，但在双向、多模态和上下文感知的协作任务支持方面仍存在挑战。

Method: 设计了一个模块化、可迁移的系统，结合多视觉输入和实时语言交互状态表示，支持动态用户任务。

Result: 实验表明，基于LLM的系统在适应性和用户参与度上略有提升，但可能产生冗余输出；脚本化系统更适合简单任务。

Conclusion: LLM方法在复杂任务中表现更优，但需优化以减少冗余；脚本化系统在简单任务中仍具优势。

Abstract: The rapid development of Large Language Models (LLMs) creates an exciting
potential for flexible, general knowledge-driven Human-Robot Interaction (HRI)
systems for assistive robots. Existing HRI systems demonstrate great progress
in interpreting and following user instructions, action generation, and robot
task solving. On the other hand, bi-directional, multi-modal, and context-aware
support of the user in collaborative tasks still remains an open challenge. In
this paper, we present a gaze- and speech-informed interface to the assistive
robot, which is able to perceive the working environment from multiple vision
inputs and support the dynamic user in their tasks. Our system is designed to
be modular and transferable to adapt to diverse tasks and robots, and it is
capable of real-time use of language-based interaction state representation and
fast on board perception modules. Its development was supported by multiple
public dissemination events, contributing important considerations for improved
robustness and user experience. Furthermore, in two lab studies, we compare the
performance and user ratings of our system with those of a traditional scripted
HRI pipeline. Our findings indicate that an LLM-based approach enhances
adaptability and marginally improves user engagement and task execution metrics
but may produce redundant output, while a scripted pipeline is well suited for
more straightforward tasks.

</details>


### [42] [Interleaved LLM and Motion Planning for Generalized Multi-Object Collection in Large Scene Graphs](https://arxiv.org/abs/2507.15782)
*Ruochu Yang,Yu Zhou,Fumin Zhang,Mengxue Hou*

Main category: cs.RO

TL;DR: 提出了一种新型的Inter-LLM算法，用于解决家庭机器人在多目标收集任务中的长期规划问题，显著提升了任务完成率和效率。


<details>
  <summary>Details</summary>
Motivation: 家庭机器人在处理开放集对象和大型环境导航时缺乏人类智能，需要解决多目标收集任务中的长期规划挑战。

Method: 设计了一种多模态动作成本相似性函数，结合LLM和运动规划，优化长期任务规划。

Result: 仿真实验显示，Inter-LLM算法在任务完成率、成功率和成本方面比现有方法提升了30%。

Conclusion: Inter-LLM算法在多目标收集任务中表现出色，平衡了规划质量和效率。

Abstract: Household robots have been a longstanding research topic, but they still lack
human-like intelligence, particularly in manipulating open-set objects and
navigating large environments efficiently and accurately. To push this
boundary, we consider a generalized multi-object collection problem in large
scene graphs, where the robot needs to pick up and place multiple objects
across multiple locations in a long mission of multiple human commands. This
problem is extremely challenging since it requires long-horizon planning in a
vast action-state space under high uncertainties. To this end, we propose a
novel interleaved LLM and motion planning algorithm Inter-LLM. By designing a
multimodal action cost similarity function, our algorithm can both reflect the
history and look into the future to optimize plans, striking a good balance of
quality and efficiency. Simulation experiments demonstrate that compared with
latest works, our algorithm improves the overall mission performance by 30% in
terms of fulfilling human commands, maximizing mission success rates, and
minimizing mission costs.

</details>


### [43] [Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers](https://arxiv.org/abs/2507.15833)
*Ian Chuang,Andrew Lee,Dechen Gao,Jinyu Zou,Iman Soltani*

Main category: cs.RO

TL;DR: 论文探讨了将人类主动注视机制引入机器人视觉系统，以提高效率和性能。通过结合眼动数据和机器人演示，提出了一种基于ViTs的注视引导方法，显著减少了计算量并提升了任务表现。


<details>
  <summary>Details</summary>
Motivation: 人类视觉通过注视主动处理任务相关区域，而机器人通常被动处理图像。研究旨在通过模仿人类注视机制提升机器人视觉系统的效率和性能。

Method: 提出了一种结合眼动数据和机器人演示的框架，使用ViTs的注视引导patch tokenization方案，并探索了两种注视预测方法。

Result: 方法显著减少了计算量，提升了高精度任务的性能，并增强了对未知干扰的鲁棒性。

Conclusion: 人类视觉处理机制为机器人视觉系统提供了有效的归纳偏置，显著提升了效率和性能。

Abstract: Human vision is a highly active process driven by gaze, which directs
attention and fixation to task-relevant regions and dramatically reduces visual
processing. In contrast, robot learning systems typically rely on passive,
uniform processing of raw camera images. In this work, we explore how
incorporating human-like active gaze into robotic policies can enhance both
efficiency and performance. We build on recent advances in foveated image
processing and apply them to an Active Vision robot system that emulates both
human head movement and eye tracking. Extending prior work on the AV-ALOHA
robot simulation platform, we introduce a framework for simultaneously
collecting eye-tracking data and robot demonstrations from a human operator as
well as a simulation benchmark and dataset for training robot policies that
incorporate human gaze. Given the widespread use of Vision Transformers (ViTs)
in robot learning, we integrate gaze information into ViTs using a foveated
patch tokenization scheme inspired by recent work in image segmentation.
Compared to uniform patch tokenization, this significantly reduces the number
of tokens-and thus computation-without sacrificing visual fidelity near regions
of interest. We also explore two approaches to gaze imitation and prediction
from human data. The first is a two-stage model that predicts gaze to guide
foveation and action; the second integrates gaze into the action space,
allowing the policy to jointly predict gaze and actions end-to-end. Our results
show that our method for foveated robot vision not only drastically reduces
computational overhead, but also improves performance for high precision tasks
and robustness to unseen distractors. Together, these findings suggest that
human-inspired visual processing offers a useful inductive bias for robotic
vision systems. https://ian-chuang.github.io/gaze-av-aloha/

</details>
