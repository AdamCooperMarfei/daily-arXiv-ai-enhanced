<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 108]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Mobile Robot Localization via Indoor Positioning System and Odometry Fusion](https://arxiv.org/abs/2509.22693)
*Muhammad Hafil Nugraha,Fauzi Abdul,Lastiko Bramantyo,Estiko Rijanto,Roni Permana Saputra,Oka Mahendra*

Main category: cs.RO

TL;DR: 提出了一种通过融合超声波室内定位系统和轮式里程计数据的移动机器人定位方法，使用扩展卡尔曼滤波器(EKF)进行传感器融合，显著提高了室内定位精度。


<details>
  <summary>Details</summary>
Motivation: 准确的定位对于移动机器人在室内环境中的有效运行至关重要，需要克服单一定位方法的局限性。

Method: 采用扩展卡尔曼滤波器(EKF)融合超声波室内定位系统(IPS)和轮式里程计数据，结合两种方法的优势。

Result: 在受控室内环境中的广泛实验表明，融合定位系统相比独立系统显著提高了精度和准确性，有效减少了轮子打滑和传感器噪声带来的误差。

Conclusion: 传感器融合方法为移动机器人提供了更鲁棒可靠的室内定位解决方案，特别是在轨迹跟踪方面表现出显著改进。

Abstract: Accurate localization is crucial for effectively operating mobile robots in
indoor environments. This paper presents a comprehensive approach to mobile
robot localization by integrating an ultrasound-based indoor positioning system
(IPS) with wheel odometry data via sensor fusion techniques. The fusion
methodology leverages the strengths of both IPS and wheel odometry,
compensating for the individual limitations of each method. The Extended Kalman
Filter (EKF) fusion method combines the data from the IPS sensors and the
robot's wheel odometry, providing a robust and reliable localization solution.
Extensive experiments in a controlled indoor environment reveal that the
fusion-based localization system significantly enhances accuracy and precision
compared to standalone systems. The results demonstrate significant
improvements in trajectory tracking, with the EKF-based approach reducing
errors associated with wheel slippage and sensor noise.

</details>


### [2] [Nonlinear Model Predictive Control with Single-Shooting Method for Autonomous Personal Mobility Vehicle](https://arxiv.org/abs/2509.22694)
*Rakha Rahmadani Pratama,Catur Hilman A. H. B. Baskoro,Joga Dharma Setiawan,Dyah Kusuma Dewi,P Paryanto,Mochammad Ariyanto,Roni Permana Saputra*

Main category: cs.RO

TL;DR: 提出了一种基于非线性模型预测控制(NMPC)的单人电动自主运输车(SEATER)控制方法，使用单射击方法通过非线性规划解决最优控制问题，在Gazebo仿真中验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 为自主个人移动车辆开发有效的控制方法，使其能够在满足约束条件(如避障)的同时到达目标位置。

Method: 采用非线性模型预测控制(NMPC)和单射击方法，通过非线性规划解决最优控制问题，使用里程计数据进行定位反馈，在ROS框架下实现。

Result: 仿真结果表明，该方法能够成功控制车辆到达目标位置，同时满足约束条件，在无障碍和静态障碍环境中都表现出良好的性能。

Conclusion: NMPC结合单射击方法在自主车辆控制中展现出鲁棒性和实时有效性，适用于所评估的场景。

Abstract: This paper introduces a proposed control method for autonomous personal
mobility vehicles, specifically the Single-passenger Electric Autonomous
Transporter (SEATER), using Nonlinear Model Predictive Control (NMPC). The
proposed method leverages a single-shooting approach to solve the optimal
control problem (OCP) via non-linear programming (NLP). The proposed NMPC is
implemented to a non-holonomic vehicle with a differential drive system, using
odometry data as localization feedback to guide the vehicle towards its target
pose while achieving objectives and adhering to constraints, such as obstacle
avoidance. To evaluate the performance of the proposed method, a number of
simulations have been conducted in both obstacle-free and static obstacle
environments. The SEATER model and testing environment have been developed in
the Gazebo Simulation and the NMPC are implemented within the Robot Operating
System (ROS) framework. The simulation results demonstrate that the NMPC-based
approach successfully controls the vehicle to reach the desired target location
while satisfying the imposed constraints. Furthermore, this study highlights
the robustness and real-time effectiveness of NMPC with a single-shooting
approach for autonomous vehicle control in the evaluated scenarios.

</details>


### [3] [ReSeFlow: Rectifying SE(3)-Equivariant Policy Learning Flows](https://arxiv.org/abs/2509.22695)
*Zhitao Wang,Yanke Wang,Jiangtao Wen,Roberto Horowitz,Yuxing Han*

Main category: cs.RO

TL;DR: 提出了ReSeFlow方法，将整流流引入SE(3)-等变扩散模型，实现快速、测地线一致且计算量最少的策略生成，在机器人操作任务中显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中的机器人操作需要生成鲁棒的长时程轨迹级策略，SE(3)-等变扩散模型虽然数据高效但推理时间成本高，需要提高推理效率。

Method: 将整流流引入SE(3)-等变扩散模型，提出ReSeFlow方法，使用SE(3)-等变网络保持旋转和平移对称性，实现测地线一致的快速策略生成。

Result: 在模拟基准测试中，ReSeFlow仅需一步推理就能达到比基线方法更好的性能，在绘画任务中误差减少48.5%，在旋转三角形任务中减少21.9%。

Conclusion: 该方法结合了SE(3)等变性和整流流的优势，为生成式策略学习模型在真实世界应用中提供了数据和推理效率。

Abstract: Robotic manipulation in unstructured environments requires the generation of
robust and long-horizon trajectory-level policy with conditions of perceptual
observations and benefits from the advantages of SE(3)-equivariant diffusion
models that are data-efficient. However, these models suffer from the inference
time costs. Inspired by the inference efficiency of rectified flows, we
introduce the rectification to the SE(3)-diffusion models and propose the
ReSeFlow, i.e., Rectifying SE(3)-Equivariant Policy Learning Flows, providing
fast, geodesic-consistent, least-computational policy generation. Crucially,
both components employ SE(3)-equivariant networks to preserve rotational and
translational symmetry, enabling robust generalization under rigid-body
motions. With the verification on the simulated benchmarks, we find that the
proposed ReSeFlow with only one inference step can achieve better performance
with lower geodesic distance than the baseline methods, achieving up to a 48.5%
error reduction on the painting task and a 21.9% reduction on the rotating
triangle task compared to the baseline's 100-step inference. This method takes
advantages of both SE(3) equivariance and rectified flow and puts it forward
for the real-world application of generative policy learning models with the
data and inference efficiency.

</details>


### [4] [Advancing Audio-Visual Navigation Through Multi-Agent Collaboration in 3D Environments](https://arxiv.org/abs/2509.22698)
*Hailong Zhang,Yinfeng Yu,Liejun Wang,Fuchun Sun,Wendong Zheng*

Main category: cs.RO

TL;DR: MASTAVN是一个多智能体音频视觉导航框架，通过两个智能体的协作在3D环境中定位和导航到音频目标，显著提升了任务完成效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有音频视觉导航研究主要关注单智能体系统，但在动态3D环境中，特别是在紧急响应等时间敏感应用中，需要快速的多智能体协调能力。

Method: MASTAVN整合了跨智能体通信协议和联合音频视觉融合机制，增强了空间推理和时间同步能力。

Result: 在Replica和Matterport3D等真实感3D模拟器中的评估显示，相比单智能体和非协作基线，MASTAVN显著减少了任务完成时间并提高了导航成功率。

Conclusion: 研究验证了MASTAVN在时间敏感紧急场景中的有效性，并为推进复杂3D环境中可扩展多智能体具身智能建立了范式。

Abstract: Intelligent agents often require collaborative strategies to achieve complex
tasks beyond individual capabilities in real-world scenarios. While existing
audio-visual navigation (AVN) research mainly focuses on single-agent systems,
their limitations emerge in dynamic 3D environments where rapid multi-agent
coordination is critical, especially for time-sensitive applications like
emergency response. This paper introduces MASTAVN (Multi-Agent Scalable
Transformer Audio-Visual Navigation), a scalable framework enabling two agents
to collaboratively localize and navigate toward an audio target in shared 3D
environments. By integrating cross-agent communication protocols and joint
audio-visual fusion mechanisms, MASTAVN enhances spatial reasoning and temporal
synchronization. Through rigorous evaluation in photorealistic 3D simulators
(Replica and Matterport3D), MASTAVN achieves significant reductions in task
completion time and notable improvements in navigation success rates compared
to single-agent and non-collaborative baselines. This highlights the essential
role of spatiotemporal coordination in multi-agent systems. Our findings
validate MASTAVN's effectiveness in time-sensitive emergency scenarios and
establish a paradigm for advancing scalable multi-agent embodied intelligence
in complex 3D environments.

</details>


### [5] [Large Language Models for 3D IC Space Planning](https://arxiv.org/abs/2509.22716)
*Hung-Ying Chu,Guan-Wei Chen,Shao-Yu Wei,Yu-Cheng Lin*

Main category: cs.RO

TL;DR: 该研究探索使用大语言模型进行3D集成电路空间规划，通过后序切片树表示法保证合法布局并最小化死区空间，在合成数据集和MCNC基准测试中取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 随着3D集成电路设计复杂度增加，需要有效的空间规划方法来减少死区空间并确保布局质量，传统EDA方法面临挑战。

Method: 使用后序切片树表示法，对开源大语言模型在大规模合成数据集上进行微调，并在MCNC衍生的3D基准上进行评估。

Result: 提出的框架在运行效率、合法性和死区空间减少之间取得良好平衡，在实用运行预算下，相当部分测试案例实现了零死区空间布局。

Conclusion: 基于大语言模型的空间规划可以作为传统EDA方法的数据驱动补充，为可扩展3D布局生成提供新思路，并具有跨领域应用潜力。

Abstract: Three-dimensional integrated circuits (3D ICs) have emerged as a promising
solution to the scaling limits of two-dimensional designs, offering higher
integration density, shorter interconnects, and improved performance. As design
complexity increases, effective space planning becomes essential to reduce dead
space and ensure layout quality. This study investigates the use of large
language models (LLMs) for 3D IC space planning through a post-order slicing
tree representation, which guarantees legal space plans while aiming to
minimize dead space. Open-source LLMs were fine-tuned on large-scale synthetic
datasets and further evaluated on MCNC-derived 3D benchmarks. Experimental
results indicate that the proposed framework achieves a favorable balance
between runtime efficiency, legality, and dead-space reduction, with
zero-dead-space layouts obtained in a significant portion of test cases under
practical runtime budgets. Beyond synthetic benchmarks, the method generalizes
to MCNC cases such as ami33 and ami49, though larger and irregular instances
remain challenging. The approach also shows potential for cross-domain
applications, including logistics and 3D object placement, where spatial
efficiency is critical. Overall, the results suggest that LLM-based space
planning can serve as a data-driven complement to traditional electronic design
automation (EDA) methods, providing new insights for scalable 3D layout
generation.

</details>


### [6] [Self-driving cars: Are we there yet?](https://arxiv.org/abs/2509.22754)
*Merve Atasever,Zhuochen Liu,Qingpei Li,Akshay Hitendra Shah,Hans Walker,Jyotirmoy V. Deshmukh,Rahul Jain*

Main category: cs.RO

TL;DR: 对CARLA、nuPlan和Waymo三大自动驾驶规划算法基准平台上的运动规划方法进行综合比较分析，识别当前方法的优缺点和发展趋势


<details>
  <summary>Details</summary>
Motivation: 自动驾驶领域需要标准化评估平台来比较不同运动规划算法的性能，但目前缺乏对这些主流基准平台的统一比较研究

Method: 采用CARLA leaderboard v2.0作为统一评估平台，对三个基准平台上的运动规划方法进行适配和比较分析

Result: 识别了当前运动规划方法的优势、局限性和共同挑战

Conclusion: 通过对比分析揭示了运动规划研究的发展趋势，并为未来研究方向提供了建议

Abstract: Autonomous driving remains a highly active research domain that seeks to
enable vehicles to perceive dynamic environments, predict the future
trajectories of traffic agents such as vehicles, pedestrians, and cyclists and
plan safe and efficient future motions. To advance the field, several
competitive platforms and benchmarks have been established to provide
standardized datasets and evaluation protocols. Among these, leaderboards by
the CARLA organization and nuPlan and the Waymo Open Dataset have become
leading benchmarks for assessing motion planning algorithms. Each offers a
unique dataset and challenging planning problems spanning a wide range of
driving scenarios and conditions. In this study, we present a comprehensive
comparative analysis of the motion planning methods featured on these three
leaderboards. To ensure a fair and unified evaluation, we adopt CARLA
leaderboard v2.0 as our common evaluation platform and modify the selected
models for compatibility. By highlighting the strengths and weaknesses of
current approaches, we identify prevailing trends, common challenges, and
suggest potential directions for advancing motion planning research.

</details>


### [7] [Persistent Autoregressive Mapping with Traffic Rules for Autonomous Driving](https://arxiv.org/abs/2509.22756)
*Shiyi Liang,Xinyuan Chang,Changjie Wu,Huiyuan Yan,Yifan Bai,Xinran Liu,Hang Zhang,Yujian Yuan,Shuang Zeng,Mu Xu,Xing Wei*

Main category: cs.RO

TL;DR: PAMR框架通过自回归方式同时构建车道向量和交通规则，解决了现有方法无法在长驾驶序列中保持交通规则持续有效性的问题。


<details>
  <summary>Details</summary>
Motivation: 安全自动驾驶需要准确的高清地图构建和对交通规则的持续感知，即使相关标志不再可见。现有方法要么只关注几何元素，要么将规则视为临时分类，无法在长驾驶序列中保持规则的持续有效性。

Method: 提出PAMR框架，包含两个关键机制：地图-规则协同构建用于处理时间片段中的驾驶场景，以及地图-规则缓存用于保持跨片段的规则一致性。

Result: 在联合向量-规则映射任务中表现出优越性能，能够在长驾驶序列中保持规则的持续有效性。

Conclusion: PAMR通过自回归协同构建车道向量和交通规则，有效解决了自动驾驶中地图构建和规则持续感知的关键问题。

Abstract: Safe autonomous driving requires both accurate HD map construction and
persistent awareness of traffic rules, even when their associated signs are no
longer visible. However, existing methods either focus solely on geometric
elements or treat rules as temporary classifications, failing to capture their
persistent effectiveness across extended driving sequences. In this paper, we
present PAMR (Persistent Autoregressive Mapping with Traffic Rules), a novel
framework that performs autoregressive co-construction of lane vectors and
traffic rules from visual observations. Our approach introduces two key
mechanisms: Map-Rule Co-Construction for processing driving scenes in temporal
segments, and Map-Rule Cache for maintaining rule consistency across these
segments. To properly evaluate continuous and consistent map generation, we
develop MapDRv2, featuring improved lane geometry annotations. Extensive
experiments demonstrate that PAMR achieves superior performance in joint
vector-rule mapping tasks, while maintaining persistent rule effectiveness
throughout extended driving sequences.

</details>


### [8] [Towards Developing Standards and Guidelines for Robot Grasping and Manipulation Pipelines in the COMPARE Ecosystem](https://arxiv.org/abs/2509.22801)
*Huajing Zhao,Brian Flynn,Adam Norton,Holly Yanco*

Main category: cs.RO

TL;DR: COMPARE生态系统通过制定组件级和流水线级标准与指南，旨在提高机器人操作开源产品的兼容性和基准测试能力。


<details>
  <summary>Details</summary>
Motivation: 改善机器人操作开源产品的兼容性和基准测试，促进模块化实践。

Method: 构建开源产品仓库识别组件特性，研究现有模块化流水线获取最佳实践，开发符合标准的新模块化流水线。

Result: 正在进行的工作包括识别组件共同特征、总结最佳实践以及开发符合标准的新流水线。

Conclusion: COMPARE生态系统通过标准化和模块化实践，有望提升机器人操作系统的互操作性和性能评估。

Abstract: The COMPARE Ecosystem aims to improve the compatibility and benchmarking of
open-source products for robot manipulation through a series of activities. One
such activity is the development of standards and guidelines to specify
modularization practices at the component-level for individual modules (e.g.,
perception, grasp planning, motion planning) and integrations of components
that form robot manipulation capabilities at the pipeline-level. This paper
briefly reviews our work-in-progress to date to (1) build repositories of
open-source products to identify common characteristics of each component in
the pipeline, (2) investigate existing modular pipelines to glean best
practices, and (3) develop new modular pipelines that advance prior work while
abiding by the proposed standards and guidelines.

</details>


### [9] [Teleoperator-Aware and Safety-Critical Adaptive Nonlinear MPC for Shared Autonomy in Obstacle Avoidance of Legged Robots](https://arxiv.org/abs/2509.22815)
*Ruturaj Sambhus,Muneeb Ahmad,Basit Muhammad Imran,Sujith Vijayan,Dylan P. Losey,Kaveh Akbari Hamed*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人共享自主权的自适应非线性模型预测控制框架，通过在线学习人类意图参数和集成控制屏障函数约束，确保在避障任务中的安全人机协作。


<details>
  <summary>Details</summary>
Motivation: 传统共享控制方法依赖固定混合策略，无法捕捉腿式机器人的动态特性，可能危及安全。需要开发能够适应人类行为不确定性并确保安全性的共享自主控制框架。

Method: 采用分层控制架构：高层CBF-ANMPC（10Hz）生成混合速度参考，中层动态感知NMPC（60Hz）跟踪参考并执行简化动力学，底层非线性全身控制器（500Hz）通过二次规划跟踪中层轨迹。使用Boltzmann模型在线学习人类意图参数。

Result: 在Unitree Go2四足机器人上进行的数值、硬件实验和用户研究表明，该框架能够实现实时避障、在线学习人类意图参数，并确保安全的远程操作协作。

Conclusion: 该自适应非线性模型预测控制框架有效解决了四足机器人在共享自主权中的安全协作问题，通过分层控制和在线学习机制实现了安全的人机交互。

Abstract: Ensuring safe and effective collaboration between humans and autonomous
legged robots is a fundamental challenge in shared autonomy, particularly for
teleoperated systems navigating cluttered environments. Conventional
shared-control approaches often rely on fixed blending strategies that fail to
capture the dynamics of legged locomotion and may compromise safety. This paper
presents a teleoperator-aware, safety-critical, adaptive nonlinear model
predictive control (ANMPC) framework for shared autonomy of quadrupedal robots
in obstacle-avoidance tasks. The framework employs a fixed arbitration weight
between human and robot actions but enhances this scheme by modeling the human
input with a noisily rational Boltzmann model, whose parameters are adapted
online using a projected gradient descent (PGD) law from observed joystick
commands. Safety is enforced through control barrier function (CBF) constraints
integrated into a computationally efficient NMPC, ensuring forward invariance
of safe sets despite uncertainty in human behavior. The control architecture is
hierarchical: a high-level CBF-based ANMPC (10 Hz) generates blended
human-robot velocity references, a mid-level dynamics-aware NMPC (60 Hz)
enforces reduced-order single rigid body (SRB) dynamics to track these
references, and a low-level nonlinear whole-body controller (500 Hz) imposes
the full-order dynamics via quadratic programming to track the mid-level
trajectories. Extensive numerical and hardware experiments, together with a
user study, on a Unitree Go2 quadrupedal robot validate the framework,
demonstrating real-time obstacle avoidance, online learning of human intent
parameters, and safe teleoperator collaboration.

</details>


### [10] [Parameter Identification of a Differentiable Human Arm Musculoskeletal Model without Deep Muscle EMG Reconstruction](https://arxiv.org/abs/2509.22825)
*Philip Sanderink,Yingfan Zhou,Shuzhen Luo,Cheng Fang*

Main category: cs.RO

TL;DR: 提出了一种无需重建深层肌肉EMG信号即可同时识别人体手臂骨骼和表层肌肉参数的方法，通过可微分优化框架实现参数识别。


<details>
  <summary>Details</summary>
Motivation: 现有的基于EMG的个性化肌肉骨骼模型参数识别方法受限于深层肌肉EMG信号难以无创测量，且现有重建深层肌肉信号的方法可靠性有限。

Method: 使用深层肌肉力的最小二乘解来计算相对于模型参数的损失梯度，在可微分优化框架中识别参数，无需重建深层肌肉EMG信号。

Result: 广泛的对比仿真结果表明，该方法在估计精度上与所有肌肉EMG信号可用的类似方法相当。

Conclusion: 该方法能够在无需测量深层肌肉EMG信号的情况下，有效识别人体手臂肌肉骨骼模型参数，为安全可靠的协作机器人系统开发提供了新途径。

Abstract: Accurate parameter identification of a subject-specific human musculoskeletal
model is crucial to the development of safe and reliable physically
collaborative robotic systems, for instance, assistive exoskeletons.
Electromyography (EMG)-based parameter identification methods have demonstrated
promising performance for personalized musculoskeletal modeling, whereas their
applicability is limited by the difficulty of measuring deep muscle EMGs
invasively. Although several strategies have been proposed to reconstruct deep
muscle EMGs or activations for parameter identification, their reliability and
robustness are limited by assumptions about the deep muscle behavior. In this
work, we proposed an approach to simultaneously identify the bone and
superficial muscle parameters of a human arm musculoskeletal model without
reconstructing the deep muscle EMGs. This is achieved by only using the
least-squares solution of the deep muscle forces to calculate a loss gradient
with respect to the model parameters for identifying them in a framework of
differentiable optimization. The results of extensive comparative simulations
manifested that our proposed method can achieve comparable estimation accuracy
compared to a similar method, but with all the muscle EMGs available.

</details>


### [11] [Dynamic Buffers: Cost-Efficient Planning for Tabletop Rearrangement with Stacking](https://arxiv.org/abs/2509.22828)
*Arman Barghi,Hamed Hosseini,Seraj Ghasemi,Mehdi Tale Masouleh,Ahmad Kalhor*

Main category: cs.RO

TL;DR: 提出动态缓冲区规划原语，通过形成可移动的临时堆栈来改善密集桌面环境中的物体重排效率，相比现有方法减少机械臂移动成本5.69%-11.89%。


<details>
  <summary>Details</summary>
Motivation: 解决传统规划器在密集桌面环境中效率低下的问题，传统方法使用固定缓冲区导致高成本规划，静态堆栈限制基座物体移动，影响整体效率。

Method: 引入动态缓冲区规划原语，允许机器人形成临时可移动的堆栈，这些堆栈可以作为整体运输，提高缓冲容量和移动灵活性。

Result: 在密集场景中减少机械臂移动成本11.89%，在大型低密度环境中减少5.69%，并在Delta并联机器人和二指夹爪上验证了实用性。

Conclusion: 动态缓冲是成本高效和鲁棒重排规划的关键原语，显著改善密集布局的可行性和效率，同时减少大尺度环境中的移动成本。

Abstract: Rearranging objects in cluttered tabletop environments remains a
long-standing challenge in robotics. Classical planners often generate
inefficient, high-cost plans by shuffling objects individually and using fixed
buffers--temporary spaces such as empty table regions or static stacks--to
resolve conflicts. When only free table locations are used as buffers, dense
scenes become inefficient, since placing an object can restrict others from
reaching their goals and complicate planning. Allowing stacking provides extra
buffer capacity, but conventional stacking is static: once an object supports
another, the base cannot be moved, which limits efficiency. To overcome these
issues, a novel planning primitive called the Dynamic Buffer is introduced.
Inspired by human grouping strategies, it enables robots to form temporary,
movable stacks that can be transported as a unit. This improves both
feasibility and efficiency in dense layouts, and it also reduces travel in
large-scale settings where space is abundant. Compared with a state-of-the-art
rearrangement planner, the approach reduces manipulator travel cost by 11.89%
in dense scenarios with a stationary robot and by 5.69% in large, low-density
settings with a mobile manipulator. Practicality is validated through
experiments on a Delta parallel robot with a two-finger gripper. These findings
establish dynamic buffering as a key primitive for cost-efficient and robust
rearrangement planning.

</details>


### [12] [Empart: Interactive Convex Decomposition for Converting Meshes to Parts](https://arxiv.org/abs/2509.22847)
*Brandon Vu,Shameek Ganguly,Pushkar Joshi*

Main category: cs.RO

TL;DR: Empart是一个交互式工具，允许用户为3D网格的不同区域指定不同的简化容差，通过区域特定的约束优化凸分解，显著减少凸部件数量并提升仿真性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在整个网格上应用统一的误差容差，导致在非关键区域过度细化或在关键区域细节不足，无法在机器人应用中实现精度与性能的最佳平衡。

Method: 利用现有凸分解算法作为子程序，采用新颖的并行化框架处理区域特定约束，提供带视觉反馈的用户友好界面进行迭代优化。

Result: 在固定误差阈值下，相比最先进方法(V-HACD)显著减少凸部件数量，机器人拾放任务中仿真时间减少69%。

Conclusion: 交互式、区域特定的简化方法对于高性能机器人应用具有重要价值，能够实现精度与仿真效率的更好平衡。

Abstract: Simplifying complex 3D meshes is a crucial step in robotics applications to
enable efficient motion planning and physics simulation. Common methods, such
as approximate convex decomposition, represent a mesh as a collection of simple
parts, which are computationally inexpensive to simulate. However, existing
approaches apply a uniform error tolerance across the entire mesh, which can
result in a sub-optimal trade-off between accuracy and performance. For
instance, a robot grasping an object needs high-fidelity geometry in the
vicinity of the contact surfaces but can tolerate a coarser simplification
elsewhere. A uniform tolerance can lead to excessive detail in non-critical
areas or insufficient detail where it's needed most.
  To address this limitation, we introduce Empart, an interactive tool that
allows users to specify different simplification tolerances for selected
regions of a mesh. Our method leverages existing convex decomposition
algorithms as a sub-routine but uses a novel, parallelized framework to handle
region-specific constraints efficiently. Empart provides a user-friendly
interface with visual feedback on approximation error and simulation
performance, enabling designers to iteratively refine their decomposition. We
demonstrate that our approach significantly reduces the number of convex parts
compared to a state-of-the-art method (V-HACD) at a fixed error threshold,
leading to substantial speedups in simulation performance. For a robotic
pick-and-place task, Empart-generated collision meshes reduced the overall
simulation time by 69% compared to a uniform decomposition, highlighting the
value of interactive, region-specific simplification for performant robotics
applications.

</details>


### [13] [Multi-Robot Allocation for Information Gathering in Non-Uniform Spatiotemporal Environments](https://arxiv.org/abs/2509.22883)
*Kaleb Ben Naveed,Haejoon Lee,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出一个两阶段多机器人框架，用于在非均匀时空环境中估计时空场，通过变差图驱动规划器学习区域特定空间长度尺度，并基于不确定性重新分配机器人以更新时间长度尺度。


<details>
  <summary>Details</summary>
Motivation: 现有高斯过程方法通常假设全局长度尺度或仅周期性更新，有些允许空间变化但忽略时间变化，导致不确定性估计不准确。

Method: 两阶段框架：第一阶段使用变差图驱动规划器学习区域特定空间长度尺度；第二阶段基于当前不确定性重新分配机器人，并在细化时间长度尺度时更新采样。

Result: 在多样化环境中评估了所提方法，提供了空间长度尺度估计的收敛性分析，以及量化与oracle分配序列差距的动态遗憾边界。

Conclusion: 该方法能够有效处理非均匀时空环境中的场估计问题，提高不确定性估计的准确性。

Abstract: Autonomous robots are increasingly deployed to estimate spatiotemporal fields
(e.g., wind, temperature, gas concentration) that vary across space and time.
We consider environments divided into non-overlapping regions with distinct
spatial and temporal dynamics, termed non-uniform spatiotemporal environments.
Gaussian Processes (GPs) can be used to estimate these fields. The GP model
depends on a kernel that encodes how the field co-varies in space and time,
with its spatial and temporal lengthscales defining the correlation. Hence,
when these lengthscales are incorrect or do not correspond to the actual field,
the estimates of uncertainty can be highly inaccurate. Existing GP methods
often assume one global lengthscale or update only periodically; some allow
spatial variation but ignore temporal changes. To address these limitations, we
propose a two-phase framework for multi-robot field estimation. Phase 1 uses a
variogram-driven planner to learn region-specific spatial lengthscales. Phase 2
employs an allocation strategy that reassigns robots based on the current
uncertainty, and updates sampling as temporal lengthscales are refined. For
encoding uncertainty, we utilize clarity, an information metric from our
earlier work. We evaluate the proposed method across diverse environments and
provide convergence analysis for spatial lengthscale estimation, along with
dynamic regret bounds quantifying the gap to the oracle's allocation sequence.

</details>


### [14] [Good Weights: Proactive, Adaptive Dead Reckoning Fusion for Continuous and Robust Visual SLAM](https://arxiv.org/abs/2509.22910)
*Yanwei Du,Jing-Chen Peng,Patricio A. Vela*

Main category: cs.RO

TL;DR: Good Weights算法通过自适应融合航位推算和视觉SLAM，在视觉退化环境中提供连续准确的位姿估计。


<details>
  <summary>Details</summary>
Motivation: 视觉SLAM在纹理缺失或视觉退化环境中表现不佳，而机器人通常配备的航位推算传感器短期性能良好但长期不可靠。

Method: 提出自适应加权框架，根据视觉跟踪可靠性动态调整航位推算的权重，并在完整SLAM系统中集成航位推算模块。

Result: 在收集的数据集和实际部署中验证了Good Weights算法的有效性，提高了视觉SLAM的性能和鲁棒性。

Conclusion: Good Weights为移动导航提供了实用解决方案，通过自适应融合航位推算增强了视觉SLAM在挑战性环境中的表现。

Abstract: Given that Visual SLAM relies on appearance cues for localization and scene
understanding, texture-less or visually degraded environments (e.g., plain
walls or low lighting) lead to poor pose estimation and track loss. However,
robots are typically equipped with sensors that provide some form of dead
reckoning odometry with reasonable short-time performance but unreliable
long-time performance. The Good Weights (GW) algorithm described here provides
a framework to adaptively integrate dead reckoning (DR) with passive visual
SLAM for continuous and accurate frame-level pose estimation. Importantly, it
describes how all modules in a comprehensive SLAM system must be modified to
incorporate DR into its design. Adaptive weighting increases DR influence when
visual tracking is unreliable and reduces when visual feature information is
strong, maintaining pose track without overreliance on DR. Good Weights yields
a practical solution for mobile navigation that improves visual SLAM
performance and robustness. Experiments on collected datasets and in real-world
deployment demonstrate the benefits of Good Weights.

</details>


### [15] [ARMimic: Learning Robotic Manipulation from Passive Human Demonstrations in Augmented Reality](https://arxiv.org/abs/2509.22914)
*Rohan Walia,Yusheng Wang,Ralf Römer,Masahiro Nishio,Angela P. Schoellig,Jun Ota*

Main category: cs.RO

TL;DR: ARMimic是一个轻量级框架，仅使用消费级XR头显和固定工作场所摄像头，通过集成手部追踪、AR机器人叠加和实时深度感知，实现无机器人、可扩展的演示数据收集，在模仿学习中显著减少演示时间并提高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 传统机器人技能获取方法（如动觉教学和遥操作）笨重、硬件需求高且干扰工作流程。现有XR被动观察方法需要额外硬件、复杂校准或受限记录条件，限制了可扩展性和可用性。

Method: 集成第一人称手部追踪、AR机器人叠加和实时深度感知，确保碰撞感知和运动学可行的演示。统一模仿学习管道将人类和虚拟机器人轨迹视为可互换，实现跨不同实体和环境的策略泛化。

Result: 在两个操作任务（包括具有挑战性的长时域碗堆叠）上验证，ARMimic相比遥操作减少50%演示时间，比在遥操作数据上训练的最先进基线ACT提高11%任务成功率。

Conclusion: ARMimic能够实现安全、无缝的野外数据收集，为多样化真实世界环境中的可扩展机器人学习提供了巨大潜力。

Abstract: Imitation learning is a powerful paradigm for robot skill acquisition, yet
conventional demonstration methods--such as kinesthetic teaching and
teleoperation--are cumbersome, hardware-heavy, and disruptive to workflows.
Recently, passive observation using extended reality (XR) headsets has shown
promise for egocentric demonstration collection, yet current approaches require
additional hardware, complex calibration, or constrained recording conditions
that limit scalability and usability. We present ARMimic, a novel framework
that overcomes these limitations with a lightweight and hardware-minimal setup
for scalable, robot-free data collection using only a consumer XR headset and a
stationary workplace camera. ARMimic integrates egocentric hand tracking,
augmented reality (AR) robot overlays, and real-time depth sensing to ensure
collision-aware, kinematically feasible demonstrations. A unified imitation
learning pipeline is at the core of our method, treating both human and virtual
robot trajectories as interchangeable, which enables policies that generalize
across different embodiments and environments. We validate ARMimic on two
manipulation tasks, including challenging long-horizon bowl stacking. In our
experiments, ARMimic reduces demonstration time by 50% compared to
teleoperation and improves task success by 11% over ACT, a state-of-the-art
baseline trained on teleoperated data. Our results demonstrate that ARMimic
enables safe, seamless, and in-the-wild data collection, offering great
potential for scalable robot learning in diverse real-world settings.

</details>


### [16] [DBF-MA: A Differential Bayesian Filtering Planner for Multi-Agent Autonomous Racing Overtakes](https://arxiv.org/abs/2509.22937)
*Trent Weiss,Amar Kulkarni,Madhur Behl*

Main category: cs.RO

TL;DR: 提出了一种基于扩展差分贝叶斯滤波框架的轨迹合成方法，用于自动驾驶赛车中的超车机动，无需依赖球形车辆近似或约束线性化。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶赛车中的超车机动生成是一个重大挑战，现有方法往往依赖过度简化的碰撞避免假设和动态约束。

Method: 将无碰撞轨迹合成问题构建为在复合贝塞尔曲线空间上的贝叶斯推断问题，采用无导数方法，避免球形车辆近似和约束线性化。

Result: 在闭环分析中，DBF-MA方法在87%的测试场景中成功完成超车，在自动驾驶超车方面优于现有方法。

Conclusion: 基于差分贝叶斯滤波的轨迹合成方法能够有效处理复杂赛道上的超车机动，无需传统简化假设。

Abstract: A significant challenge in autonomous racing is to generate overtaking
maneuvers. Racing agents must execute these maneuvers on complex racetracks
with little room for error. Optimization techniques and graph-based methods
have been proposed, but these methods often rely on oversimplified assumptions
for collision-avoidance and dynamic constraints. In this work, we present an
approach to trajectory synthesis based on an extension of the Differential
Bayesian Filtering framework. Our approach for collision-free trajectory
synthesis frames the problem as one of Bayesian Inference over the space of
Composite Bezier Curves. Our method is derivative-free, does not require a
spherical approximation of the vehicle footprint, linearization of constraints,
or simplifying upper bounds on collision avoidance. We conduct a closed-loop
analysis of DBF-MA and find it successfully overtakes an opponent in 87% of
tested scenarios, outperforming existing methods in autonomous overtaking.

</details>


### [17] [Hierarchical Control Design for Space Robots with Application to In-Orbit Servicing Missions](https://arxiv.org/abs/2509.22955)
*Pietro Bruschi*

Main category: cs.RO

TL;DR: 提出了一种用于自主捕获空间翻滚物体的分层控制框架，结合了内部鲁棒控制环和外部扩展逆运动学问题求解，并考虑了追赶器液体晃动动力学。


<details>
  <summary>Details</summary>
Motivation: 在轨服务和主动碎片清除需要先进的机器人能力来捕获和稳定非合作目标，现有方法很少考虑追赶器的液体晃动动力学。

Method: 开发了包含追赶器液体晃动动力学的仿真环境，提出了分层控制器，内环基于Lyapunov的鲁棒控制处理多体动力学，外环解决扩展逆运动学问题。

Result: 仿真结果表明，与现有控制方案相比，该方法具有更好的鲁棒性和适应性。

Conclusion: 所提出的分层控制框架在自主捕获空间翻滚物体方面表现出优越性能，特别是在考虑液体晃动动力学的情况下。

Abstract: In-Orbit Servicing and Active Debris Removal require advanced robotic
capabilities for capturing and detumbling uncooperative targets. This work
presents a hierarchical control framework for autonomous robotic capture of
tumbling objects in space. A simulation environment is developed, incorporating
sloshing dynamics of the chaser, a rarely studied effect in space robotics. The
proposed controller combines an inner Lyapunov-based robust control loop for
multi-body dynamics with an outer loop addressing an extended inverse
kinematics problem. Simulation results show improved robustness and
adaptability compared to existing control schemes.

</details>


### [18] [Robot Learning from Any Images](https://arxiv.org/abs/2509.22970)
*Siheng Zhao,Jiageng Mao,Wei Chow,Zeyu Shangguan,Tianheng Shi,Rong Xue,Yuxi Zheng,Yijia Weng,Yang You,Daniel Seita,Leonidas Guibas,Sergey Zakharov,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: RoLA是一个框架，能够将任意真实世界图像转换为交互式、支持物理的机器人环境，无需额外硬件或数字资产，可快速生成大量视觉运动机器人演示数据。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要额外硬件或数字资产来创建机器人环境，限制了机器人数据生成的规模和可访问性。RoLA旨在通过单张图像直接创建物理启用的机器人环境，实现机器人数据生成的民主化。

Method: 结合单视图物理场景恢复新方法和高效视觉融合策略，从单张图像中恢复物理场景并进行逼真的数据收集。

Result: RoLA展示了在可扩展机器人数据生成与增强、从互联网图像学习机器人技能、以及单图像真实-仿真-真实系统等多个应用中的多功能性，适用于机械臂和人形机器人。

Conclusion: RoLA框架能够仅凭单张图像快速创建物理启用的机器人环境，为机器人学习提供了高效、可扩展的数据生成解决方案。

Abstract: We introduce RoLA, a framework that transforms any in-the-wild image into an
interactive, physics-enabled robotic environment. Unlike previous methods, RoLA
operates directly on a single image without requiring additional hardware or
digital assets. Our framework democratizes robotic data generation by producing
massive visuomotor robotic demonstrations within minutes from a wide range of
image sources, including camera captures, robotic datasets, and Internet
images. At its core, our approach combines a novel method for single-view
physical scene recovery with an efficient visual blending strategy for
photorealistic data collection. We demonstrate RoLA's versatility across
applications like scalable robotic data generation and augmentation, robot
learning from Internet images, and single-image real-to-sim-to-real systems for
manipulators and humanoids. Video results are available at
https://sihengz02.github.io/RoLA .

</details>


### [19] [Safe Task Space Synchronization with Time-Delayed Information](https://arxiv.org/abs/2509.22976)
*Rounak Bhattacharya,Vrithik R. Guthikonda,Ashwin P. Dani*

Main category: cs.RO

TL;DR: 设计了一种自适应控制器，用于在存在通信时延的情况下实现机器人轨迹与人类轨迹的同步，同时确保安全性约束。


<details>
  <summary>Details</summary>
Motivation: 在人类-机器人协作任务中，通信时延（如传感器处理、网络延迟等）会影响轨迹同步，且机器人的运动学和动力学参数通常未知，需要设计能够处理这些不确定性的控制器。

Method: 使用障碍李雅普诺夫函数(BLF)约束笛卡尔坐标确保安全，采用ICL自适应律处理未知运动学，梯度自适应律估计未知动力学，使用障碍李雅普诺夫-克拉索夫斯基函数进行稳定性分析。

Result: 稳定性分析表明同步误差和参数估计误差保持半全局一致最终有界(SGUUB)，仿真结果验证了带安全约束的同步控制器的有效性。

Conclusion: 所设计的自适应控制器能够有效处理通信时延、未知运动学和动力学参数，在保证安全约束的前提下实现人类-机器人轨迹同步。

Abstract: In this paper, an adaptive controller is designed for the synchronization of
the trajectory of a robot with unknown kinematics and dynamics to that of the
current human trajectory in the task space using the delayed human trajectory
information. The communication time delay may be a result of various factors
that arise in human-robot collaboration tasks, such as sensor processing or
fusion to estimate trajectory/intent, network delays, or computational
limitations. The developed adaptive controller uses Barrier Lyapunov Function
(BLF) to constrain the Cartesian coordinates of the robot to ensure safety, an
ICL-based adaptive law to account for the unknown kinematics, and a
gradient-based adaptive law to estimate unknown dynamics. Barrier
Lyapunov-Krasovskii (LK) functionals are used for the stability analysis to
show that the synchronization and parameter estimation errors remain
semi-globally uniformly ultimately bounded (SGUUB). The simulation results
based on a human-robot synchronization scenario with time delay are provided to
demonstrate the effectiveness of the designed synchronization controller with
safety constraints.

</details>


### [20] [UniPrototype: Humn-Robot Skill Learning with Uniform Prototypes](https://arxiv.org/abs/2509.23021)
*Xiao Hu,Qi Yin,Yangming Shi,Yang Ye*

Main category: cs.RO

TL;DR: UniPrototype框架通过共享运动基元实现从人类到机器人领域的知识迁移，解决了机器人学习中的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 机器人学习面临数据稀缺的挑战，而人类演示可以从丰富的运动捕捉数据和互联网资源中受益。为了弥合人类和机器人操作能力之间的差距，需要有效的知识迁移方法。

Method: 提出了UniPrototype框架，包含三个关键贡献：(1) 具有软分配的组成性原型发现机制，允许多个基元共同激活以捕捉混合和分层技能；(2) 自适应原型选择策略，自动调整原型数量以匹配任务复杂度；(3) 在仿真环境和真实机器人系统中进行广泛实验验证。

Result: 实验结果表明，UniPrototype成功将人类操作知识迁移到机器人，与现有方法相比显著提高了学习效率和任务性能。

Conclusion: UniPrototype框架有效解决了机器人学习中的数据稀缺问题，通过从人类领域到机器人领域的知识迁移，提升了机器人的操作能力。

Abstract: Data scarcity remains a fundamental challenge in robot learning. While human
demonstrations benefit from abundant motion capture data and vast internet
resources, robotic manipulation suffers from limited training examples. To
bridge this gap between human and robot manipulation capabilities, we propose
UniPrototype, a novel framework that enables effective knowledge transfer from
human to robot domains via shared motion primitives. ur approach makes three
key contributions: (1) We introduce a compositional prototype discovery
mechanism with soft assignments, enabling multiple primitives to co-activate
and thus capture blended and hierarchical skills; (2) We propose an adaptive
prototype selection strategy that automatically adjusts the number of
prototypes to match task complexity, ensuring scalable and efficient
representation; (3) We demonstrate the effectiveness of our method through
extensive experiments in both simulation environments and real-world robotic
systems. Our results show that UniPrototype successfully transfers human
manipulation knowledge to robots, significantly improving learning efficiency
and task performance compared to existing approaches.The code and dataset will
be released upon acceptance at an anonymous repository.

</details>


### [21] [RAISE: A Robot-Assisted Selective Disassembly and Sorting System for End-of-Life Phones](https://arxiv.org/abs/2509.23048)
*Chang Liu,Badrinath Balasubramaniam,Neal Yancey,Michael Severson,Adam Shine,Philip Bove,Beiwen Li,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 提出了一种低成本、易部署的自动化选择性拆解和分拣系统，用于处理报废手机，每小时可处理120多部手机，拆解成功率达98.9%。


<details>
  <summary>Details</summary>
Motivation: 报废手机因其高产量和短生命周期而加剧全球电子垃圾问题，手动拆解过程劳动密集且耗时。

Method: 系统包含三个子系统：自适应切割系统、基于视觉的机器人分拣系统和电池移除系统。

Result: 系统每小时处理超过120部手机，平均拆解成功率为98.9%，有效将高价值组件输送到下游处理。

Conclusion: 该系统为报废手机拆解提供了可靠且可扩展的自动化解决方案，能将原本无利可图的过程转变为产生净收益的过程。

Abstract: End-of-Life (EoL) phones significantly exacerbate global e-waste challenges
due to their high production volumes and short lifecycles. Disassembly is among
the most critical processes in EoL phone recycling. However, it relies heavily
on human labor due to product variability. Consequently, the manual process is
both labor-intensive and time-consuming. In this paper, we propose a low-cost,
easily deployable automated and selective disassembly and sorting system for
EoL phones, consisting of three subsystems: an adaptive cutting system, a
vision-based robotic sorting system, and a battery removal system. The system
can process over 120 phones per hour with an average disassembly success rate
of 98.9%, efficiently delivering selected high-value components to downstream
processing. It provides a reliable and scalable automated solution to the
pressing challenge of EoL phone disassembly. Additionally, the automated system
can enhance disassembly economics, converting a previously unprofitable process
into one that yields a net profit per unit weight of EoL phones.

</details>


### [22] [In-Hand Manipulation of Articulated Tools with Dexterous Robot Hands with Sim-to-Real Transfer](https://arxiv.org/abs/2509.23075)
*Soofiyan Atar,Daniel Huang,Florian Richter,Michael Yip*

Main category: cs.RO

TL;DR: 该论文提出了一种结合仿真训练和硬件演示学习的控制器，用于机器人手对铰接工具进行灵巧操作，通过触觉和力反馈实现从仿真到实物的鲁棒迁移。


<details>
  <summary>Details</summary>
Motivation: 解决铰接机构操作中的挑战，如接触动力学复杂、关节摩擦、间隙等未建模现象，使策略在真实环境中更加鲁棒。

Method: 在仿真训练的基础策略上，增加基于硬件演示的传感器驱动精炼模块，融合本体感知、目标关节状态以及全手触觉和力反馈，通过交叉注意力机制整合策略内部动作意图。

Result: 在剪刀、钳子、微创手术工具和订书机等多种真实铰接工具上验证了方法，实现了从仿真到硬件的鲁棒迁移、改进的抗干扰能力和对未见铰接工具的泛化能力。

Conclusion: 该方法减少了在接触丰富场景中对精确物理建模的依赖，能够在线适应特定实例的铰接特性，稳定接触交互，调节内力，并在扰动下协调耦合连杆运动。

Abstract: Reinforcement learning (RL) and sim-to-real transfer have advanced robotic
manipulation of rigid objects. Yet, policies remain brittle when applied to
articulated mechanisms due to contact-rich dynamics and under-modeled joint
phenomena such as friction, stiction, backlash, and clearances. We address this
challenge through dexterous in-hand manipulation of articulated tools using a
robotic hand with reduced articulation and kinematic redundancy relative to the
human hand. Our controller augments a simulation-trained base policy with a
sensor-driven refinement learned from hardware demonstrations, conditioning on
proprioception and target articulation states while fusing whole-hand tactile
and force feedback with the policy's internal action intent via
cross-attention-based integration. This design enables online adaptation to
instance-specific articulation properties, stabilizes contact interactions,
regulates internal forces, and coordinates coupled-link motion under
perturbations. We validate our approach across a diversity of real-world
examples, including scissors, pliers, minimally invasive surgical tools, and
staplers. We achieve robust transfer from simulation to hardware, improved
disturbance resilience, and generalization to previously unseen articulated
tools, thereby reducing reliance on precise physical modeling in contact-rich
settings.

</details>


### [23] [Open-Vocabulary Spatio-Temporal Scene Graph for Robot Perception and Teleoperation Planning](https://arxiv.org/abs/2509.23107)
*Yi Wang,Zeyu Xue,Mujie Liu,Tongqin Zhang,Yan Hu,Zhou Zhao,Chenguang Yang,Zhenyu Lu*

Main category: cs.RO

TL;DR: 提出ST-OVSG时空开放词汇场景图，通过增强开放词汇感知与时间动态和延迟标注，解决远程操作中传输延迟导致的命令误解问题，提高规划鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在动态远程场景中，双向通信的传输延迟会造成远程感知状态与操作者意图之间的差距，导致命令误解和执行错误，需要一种能够缓解延迟影响的表示方法。

Method: 利用LVLMs构建开放词汇3D对象表示，通过匈牙利分配和时序匹配成本扩展到时间域，形成统一时空场景图，嵌入延迟标签使规划器能回溯查询过去场景状态，并采用任务导向子图过滤策略减少冗余。

Result: 在Replica基准测试中达到74%节点准确率，优于ConceptGraph；在延迟鲁棒性实验中，ST-OVSG辅助的LVLM规划器实现了70.5%的规划成功率。

Conclusion: ST-OVSG能够泛化到新类别，无需微调即可增强规划对传输延迟的鲁棒性，有效解决本地-远程状态不匹配问题。

Abstract: Teleoperation via natural-language reduces operator workload and enhances
safety in high-risk or remote settings. However, in dynamic remote scenes,
transmission latency during bidirectional communication creates gaps between
remote perceived states and operator intent, leading to command
misunderstanding and incorrect execution. To mitigate this, we introduce the
Spatio-Temporal Open-Vocabulary Scene Graph (ST-OVSG), a representation that
enriches open-vocabulary perception with temporal dynamics and lightweight
latency annotations. ST-OVSG leverages LVLMs to construct open-vocabulary 3D
object representations, and extends them into the temporal domain via Hungarian
assignment with our temporal matching cost, yielding a unified spatio-temporal
scene graph. A latency tag is embedded to enable LVLM planners to
retrospectively query past scene states, thereby resolving local-remote state
mismatches caused by transmission delays. To further reduce redundancy and
highlight task-relevant cues, we propose a task-oriented subgraph filtering
strategy that produces compact inputs for the planner. ST-OVSG generalizes to
novel categories and enhances planning robustness against transmission latency
without requiring fine-tuning. Experiments show that our method achieves 74
percent node accuracy on the Replica benchmark, outperforming ConceptGraph.
Notably, in the latency-robustness experiment, the LVLM planner assisted by
ST-OVSG achieved a planning success rate of 70.5 percent.

</details>


### [24] [Liaohe-CobotMagic-PnP: an Imitation Learning Dataset of Intelligent Robot for Industrial Applications](https://arxiv.org/abs/2509.23111)
*Chen Yizhe,Wang Qi,Hu Dongxiao,Jingzhe Fang,Liu Sichao,Zixin An,Hongliang Niu,Haoran Liu,Li Dong,Chuanfen Feng,Lan Dapeng,Liu Yu,Zhibo Pang*

Main category: cs.RO

TL;DR: 提出了一个工业级多模态干扰数据集，用于机器人在复杂环境下的感知与控制，包含视觉、扭矩和关节状态等多维同步数据。


<details>
  <summary>Details</summary>
Motivation: 工业4.0应用中，动态环境干扰导致环境状态与机器人行为之间存在高度非线性和强耦合相互作用，当前机器人数据集难以有效表示动态环境状态。

Method: 集成多维干扰特征（尺寸、颜色、光照变化），使用高精度传感器同步采集视觉、扭矩和关节状态测量数据，采用微秒级时间同步和抗振动数据采集协议。

Result: 实验结果表明，该数据集增强了模型验证的鲁棒性，并提高了机器人在动态干扰环境中的操作稳定性。

Conclusion: 该数据集为机器人在复杂干扰环境下的感知与控制研究提供了重要支持，并已公开发布。

Abstract: In Industry 4.0 applications, dynamic environmental interference induces
highly nonlinear and strongly coupled interactions between the environmental
state and robotic behavior. Effectively representing dynamic environmental
states through multimodal sensor data fusion remains a critical challenge in
current robotic datasets. To address this, an industrial-grade multimodal
interference dataset is presented, designed for robotic perception and control
under complex conditions. The dataset integrates multi-dimensional interference
features including size, color, and lighting variations, and employs
high-precision sensors to synchronously collect visual, torque, and joint-state
measurements. Scenarios with geometric similarity exceeding 85\% and
standardized lighting gradients are included to ensure real-world
representativeness. Microsecond-level time-synchronization and
vibration-resistant data acquisition protocols, implemented via the Robot
Operating System (ROS), guarantee temporal and operational fidelity.
Experimental results demonstrate that the dataset enhances model validation
robustness and improves robotic operational stability in dynamic,
interference-rich environments. The dataset is publicly available
at:https://modelscope.cn/datasets/Liaoh_LAB/Liaohe-CobotMagic-PnP.

</details>


### [25] [FTACT: Force Torque aware Action Chunking Transformer for Pick-and-Reorient Bottle Task](https://arxiv.org/abs/2509.23112)
*Ryo Watanabe,Maxime Alvarez,Pablo Ferreiro,Pavel Savkin,Genki Sano*

Main category: cs.RO

TL;DR: 提出了一种多模态模仿学习策略，将动作分块变换器与力和扭矩传感相结合，用于解决零售环境中机械臂操作直立饮料瓶等接触密集型任务。


<details>
  <summary>Details</summary>
Motivation: 零售环境中的机械臂操作在接触密集型边缘情况下仍需要昂贵的人工远程操作，特别是直立饮料瓶操作中纯视觉线索往往不足以解析精确操作所需的细微接触事件。

Method: 开发了多模态模仿学习策略，将动作分块变换器与力和扭矩传感增强，支持端到端学习图像、关节状态、力和扭矩信息。在Telexistence公司的Ghost单臂平台上部署，通过检测和利用按压和放置过程中的接触转换来改进拾取和重定向瓶子任务。

Result: 硬件实验显示，与仅匹配ACT观测空间的基线相比，该方法显著提高了任务成功率。实验表明在视觉可观测性受限的按压和放置阶段，力和扭矩信号特别有益。

Conclusion: 研究结果支持将交互力作为接触密集型技能的补充模态，为通过结合现代模仿学习架构与轻量级力和扭矩传感来扩展零售操作提供了实用路径。

Abstract: Manipulator robots are increasingly being deployed in retail environments,
yet contact rich edge cases still trigger costly human teleoperation. A
prominent example is upright lying beverage bottles, where purely visual cues
are often insufficient to resolve subtle contact events required for precise
manipulation. We present a multimodal Imitation Learning policy that augments
the Action Chunking Transformer with force and torque sensing, enabling
end-to-end learning over images, joint states, and forces and torques. Deployed
on Ghost, single-arm platform by Telexistence Inc, our approach improves
Pick-and-Reorient bottle task by detecting and exploiting contact transitions
during pressing and placement. Hardware experiments demonstrate greater task
success compared to baseline matching the observation space of ACT as an
ablation and experiments indicate that force and torque signals are beneficial
in the press and place phases where visual observability is limited, supporting
the use of interaction forces as a complementary modality for contact rich
skills. The results suggest a practical path to scaling retail manipulation by
combining modern imitation learning architectures with lightweight force and
torque sensing.

</details>


### [26] [EKF-Based Fusion of Wi-Fi/LiDAR/IMU for Indoor Localization and Navigation](https://arxiv.org/abs/2509.23118)
*Zeyi Li,Zhe Tang,Kyeong Soo Kim,Sihao Li,Jeremy S. Smith*

Main category: cs.RO

TL;DR: 提出了一种融合Wi-Fi RSSI指纹识别、LiDAR SLAM和IMU的多传感器室内定位导航框架，通过EKF集成传感器信息，显著提高了定位精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统Wi-Fi RSSI指纹定位精度不足，而LiDAR方案成本高且复杂，需要一种平衡精度与成本的解决方案。

Method: 使用DNN进行Wi-Fi RSSI粗定位，结合IMU动态定位和Gmapping SLAM生成地图，通过EKF预测-更新集成传感器信息并抑制噪声和漂移误差。

Result: 在真实环境实验中，该框架的平均2D误差为0.2449-0.3781米，远优于Wi-Fi RSSI（最高1.3404米）和LiDAR/IMU定位（0.6233-2.8803米）。

Conclusion: 多传感器融合框架有效抑制了单一方法的不足，在所有路径配置下都能提供稳定的高精度定位性能。

Abstract: Conventional Wi-Fi received signal strength indicator (RSSI) fingerprinting
cannot meet the growing demand for accurate indoor localization and navigation
due to its lower accuracy, while solutions based on light detection and ranging
(LiDAR) can provide better localization performance but is limited by their
higher deployment cost and complexity. To address these issues, we propose a
novel indoor localization and navigation framework integrating Wi-Fi RSSI
fingerprinting, LiDAR-based simultaneous localization and mapping (SLAM), and
inertial measurement unit (IMU) navigation based on an extended Kalman filter
(EKF). Specifically, coarse localization by deep neural network (DNN)-based
Wi-Fi RSSI fingerprinting is refined by IMU-based dynamic positioning using a
Gmapping-based SLAM to generate an occupancy grid map and output high-frequency
attitude estimates, which is followed by EKF prediction-update integrating
sensor information while effectively suppressing Wi-Fi-induced noise and IMU
drift errors. Multi-group real-world experiments conducted on the IR building
at Xi'an Jiaotong-Liverpool University demonstrates that the proposed
multi-sensor fusion framework suppresses the instability caused by individual
approaches and thereby provides stable accuracy across all path configurations
with mean two-dimensional (2D) errors ranging from 0.2449 m to 0.3781 m. In
contrast, the mean 2D errors of Wi-Fi RSSI fingerprinting reach up to 1.3404 m
in areas with severe signal interference, and those of LiDAR/IMU localization
are between 0.6233 m and 2.8803 m due to cumulative drift.

</details>


### [27] [LAGEA: Language Guided Embodied Agents for Robotic Manipulation](https://arxiv.org/abs/2509.23155)
*Abdul Monaf Chowdhury,Akm Moshiur Rahman Mazumder,Rabeya Akter,Safaeid Hossain Arib*

Main category: cs.RO

TL;DR: LAGEA框架利用视觉语言模型将语言反馈转化为强化学习的时序指导，通过总结尝试、定位关键时刻、对齐视觉状态，并将目标进展和反馈一致性转化为有界的逐步塑形奖励，从而帮助机器人从错误中学习。


<details>
  <summary>Details</summary>
Motivation: 当前机器人代理缺乏从自身错误中学习的系统方法，研究探索自然语言是否能作为反馈信号，帮助具身智能体诊断错误并纠正行为。

Method: 提出LAGEA框架：1）用VLM总结每次尝试；2）定位轨迹中的决定性时刻；3）在共享表示中对齐反馈与视觉状态；4）将目标进展和反馈一致性转化为有界的逐步塑形奖励；5）使用自适应、失败感知系数调节奖励影响。

Result: 在Meta-World MT10具身操作基准测试中，LAGEA相比最先进方法在随机目标上平均成功率提升9.0%，在固定目标上提升5.3%，且收敛更快。

Conclusion: 当语言被结构化并在时间上接地时，是教导机器人自我反思错误并做出更好选择的有效机制。

Abstract: Robotic manipulation benefits from foundation models that describe goals, but
today's agents still lack a principled way to learn from their own mistakes. We
ask whether natural language can serve as feedback, an error reasoning signal
that helps embodied agents diagnose what went wrong and correct course. We
introduce LAGEA (Language Guided Embodied Agents), a framework that turns
episodic, schema-constrained reflections from a vision language model (VLM)
into temporally grounded guidance for reinforcement learning. LAGEA summarizes
each attempt in concise language, localizes the decisive moments in the
trajectory, aligns feedback with visual state in a shared representation, and
converts goal progress and feedback agreement into bounded, step-wise shaping
rewardswhose influence is modulated by an adaptive, failure-aware coefficient.
This design yields dense signals early when exploration needs direction and
gracefully recedes as competence grows. On the Meta-World MT10 embodied
manipulation benchmark, LAGEA improves average success over the
state-of-the-art (SOTA) methods by 9.0% on random goals and 5.3% on fixed
goals, while converging faster. These results support our hypothesis: language,
when structured and grounded in time, is an effective mechanism for teaching
robots to self-reflect on mistakes and make better choices. Code will be
released soon.

</details>


### [28] [Physically-Feasible Reactive Synthesis for Terrain-Adaptive Locomotion](https://arxiv.org/abs/2509.23185)
*Ziyi Zhou,Qian Meng,Hadas Kress-Gazit,Ye Zhao*

Main category: cs.RO

TL;DR: 提出了一种四足机器人在动态变化、未知地形上的集成规划框架，结合反应式合成和混合整数凸规划，实现符号级控制器生成和物理可行的步态规划。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖实时落脚点选择的启发式方法（限制鲁棒性和适应性）或计算密集的轨迹优化，需要更高效可靠的规划框架。

Method: 结合反应式合成生成构造正确的符号级控制器，使用混合整数凸规划进行动态物理可行的步态规划，采用符号修复机制减少MICP求解依赖，实时MICP重规划结合运行时符号修复和延迟感知协调。

Result: 通过广泛仿真和硬件实验验证，框架能够识别缺失的移动技能，在安全关键环境中有效响应，包括分散踏脚石和钢筋场景。

Conclusion: 该集成规划框架成功实现了离线合成与在线操作的无缝衔接，提高了四足机器人在动态未知地形上的适应性和鲁棒性。

Abstract: We present an integrated planning framework for quadrupedal locomotion over
dynamically changing, unforeseen terrains. Existing methods often depend on
heuristics for real-time foothold selection-limiting robustness and
adaptability-or rely on computationally intensive trajectory optimization
across complex terrains and long horizons. In contrast, our approach combines
reactive synthesis for generating correct-by-construction symbolic-level
controllers with mixed-integer convex programming (MICP) for dynamic and
physically feasible footstep planning during each symbolic transition. To
reduce the reliance on costly MICP solves and accommodate specifications that
may be violated due to physical infeasibility, we adopt a symbolic repair
mechanism that selectively generates only the required symbolic transitions.
During execution, real-time MICP replanning based on actual terrain data,
combined with runtime symbolic repair and delay-aware coordination, enables
seamless bridging between offline synthesis and online operation. Through
extensive simulation and hardware experiments, we validate the framework's
ability to identify missing locomotion skills and respond effectively in
safety-critical environments, including scattered stepping stones and rebar
scenarios.

</details>


### [29] [CE-Nav: Flow-Guided Reinforcement Refinement for Cross-Embodiment Local Navigation](https://arxiv.org/abs/2509.23203)
*Kai Yang,Tianlin Zhang,Zhengbo Wang,Zedong Chu,Xiaolong Wu,Yang Cai,Mu Xu*

Main category: cs.RO

TL;DR: CE-Nav是一个两阶段框架，通过解耦通用几何推理和特定形态动态适应，实现跨机器人形态的导航策略泛化。第一阶段训练通用专家模型学习运动学可行动作分布，第二阶段为特定机器人训练轻量级动态精炼器。


<details>
  <summary>Details</summary>
Motivation: 解决跨机器人形态导航策略泛化的挑战，包括需要昂贵特定形态数据、规划与控制紧密耦合、以及确定性模型无法捕捉多模态决策等问题。

Method: 两阶段框架：1) 离线训练通用专家模型（VelFlow），使用条件归一化流学习运动学可行动作分布；2) 在线训练轻量级动态精炼器，通过强化学习补偿特定机器人动态特性。

Result: 在四足、双足和四旋翼机器人上的广泛实验表明，CE-Nav实现了最先进的性能，同时大幅降低了适应成本。真实世界部署验证了该方法的有效性。

Conclusion: CE-Nav提供了一个高效、可扩展的解决方案，用于构建可泛化的导航系统，成功解决了跨机器人形态的导航策略泛化问题。

Abstract: Generalizing local navigation policies across diverse robot morphologies is a
critical challenge. Progress is often hindered by the need for costly and
embodiment-specific data, the tight coupling of planning and control, and the
"disastrous averaging" problem where deterministic models fail to capture
multi-modal decisions (e.g., turning left or right). We introduce CE-Nav, a
novel two-stage (IL-then-RL) framework that systematically decouples universal
geometric reasoning from embodiment-specific dynamic adaptation. First, we
train an embodiment-agnostic General Expert offline using imitation learning.
This expert, a conditional normalizing flow model named VelFlow, learns the
full distribution of kinematically-sound actions from a large-scale dataset
generated by a classical planner, completely avoiding real robot data and
resolving the multi-modality issue. Second, for a new robot, we freeze the
expert and use it as a guiding prior to train a lightweight, Dynamics-Aware
Refiner via online reinforcement learning. This refiner rapidly learns to
compensate for the target robot's specific dynamics and controller
imperfections with minimal environmental interaction. Extensive experiments on
quadrupeds, bipeds, and quadrotors show that CE-Nav achieves state-of-the-art
performance while drastically reducing adaptation cost. Successful real-world
deployments further validate our approach as an efficient and scalable solution
for building generalizable navigation systems.

</details>


### [30] [Simulated Annealing for Multi-Robot Ergodic Information Acquisition Using Graph-Based Discretization](https://arxiv.org/abs/2509.23214)
*Benjamin Wong,Aaron Weber,Mohamed M. Safwat,Santosh Devasia,Ashis G. Banerjee*

Main category: cs.RO

TL;DR: 本文提出使用模拟退火方法为多机器人团队生成目标采样分布，从均匀分布开始，逐渐转向估计的最优分布，通过调节玻尔兹曼分布的冷度参数来实现。


<details>
  <summary>Details</summary>
Motivation: 多机器人主动信息采集中，需要保持各区域相对不确定性在相同水平以确保一致的采集质量。虽然可以使用遍历覆盖根据观测质量分配采样数量，但噪声水平未知且初始估计不可靠，会产生波动值。

Method: 使用模拟退火生成目标采样分布，从均匀分布开始，通过调节玻尔兹曼分布的冷度参数，以估计的采样熵作为能量，逐渐转向估计的最优分布。

Result: 仿真结果显示，与均匀搜索和直接遍历搜索相比，该方法在瞬态熵和渐近熵方面都有显著改善。通过TurtleBot群系统演示验证了算法的物理适用性。

Conclusion: 提出的模拟退火方法能有效解决多机器人信息采集中噪声水平未知的问题，实现更好的不确定性平衡和采集质量一致性。

Abstract: One of the goals of active information acquisition using multi-robot teams is
to keep the relative uncertainty in each region at the same level to maintain
identical acquisition quality (e.g., consistent target detection) in all the
regions. To achieve this goal, ergodic coverage can be used to assign the
number of samples according to the quality of observation, i.e., sampling noise
levels. However, the noise levels are unknown to the robots. Although this
noise can be estimated from samples, the estimates are unreliable at first and
can generate fluctuating values. The main contribution of this paper is to use
simulated annealing to generate the target sampling distribution, starting from
uniform and gradually shifting to an estimated optimal distribution, by varying
the coldness parameter of a Boltzmann distribution with the estimated sampling
entropy as energy. Simulation results show a substantial improvement of both
transient and asymptotic entropy compared to both uniform and direct-ergodic
searches. Finally, a demonstration is performed with a TurtleBot swarm system
to validate the physical applicability of the algorithm.

</details>


### [31] [GLUE: Global-Local Unified Encoding for Imitation Learning via Key-Patch Tracking](https://arxiv.org/abs/2509.23220)
*Ye Chen,Zichen Zhou,Jianyu Dou,Te Cui,Yi Yang,Yufeng Yue*

Main category: cs.RO

TL;DR: GLUE是一个基于关键补丁跟踪的全局-局部统一编码框架，通过文本引导机制选择和跟踪关键补丁作为局部表示，通过全局补丁特征查询局部补丁来融合信息，从而在复杂OOD场景下提升模仿学习策略的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在复杂OOD场景中，全局视觉表示的注意力会被稀释或干扰，导致策略性能下降。局部表示对任务相关对象具有不变性，可以缓解协变量偏移问题。

Method: 提出GLUE框架：1）使用文本引导机制选择和跟踪关键补丁；2）全局补丁特征查询局部补丁以提取关键信息；3）生成细粒度局部特征并与全局上下文融合。

Result: 在仿真环境中比最强基线提升17.6%，在真实环境中提升36.3%，在真实世界泛化设置中提升58.3%。

Conclusion: GLUE通过全局-局部融合表示引导机器人视觉注意力到任务相关对象，同时保留精确全局上下文，有效提升模仿学习策略在复杂OOD场景下的鲁棒性。

Abstract: In recent years, visual representation learning has gained widespread
attention in robotic imitation learning. However, in complex
Out-of-Distribution(OOD) settings characterized by clutter and occlusion, the
attention of global visual representations can be diluted or interfered,
leading to degraded policy performance. The invariance of local representations
for task-relevant objects offers a solution. By efficiently utilizing these
local representations, training and testing data can be mapped to a more
similar feature space, thereby mitigating the covariate shift problem.
Accordingly, we propose GLUE, a global-local unified encoding framework for
imitation learning based on key-patch tracking. GLUE selects and tracks
key-patches as critical local representations by employing a text-guided
mechanism. It features a novel fusion framework where global patch features
query local patches to distill essential information, yielding fine-grained
local features with low heterogeneity relative to the global context. This
fused representation steers the robot's visual attention toward task-relevant
objects and preserves precise global context, which together align the training
and testing distributions into a similar and task-informative feature space,
ultimately enhancing the robustness of the imitation learning policy.
Experiments demonstrate that GLUE achieves strong performance across diverse
tasks in both simulation and real-world settings, outperforming the strongest
baseline by 17.6% in simulation, 36.3% in real-world environments, and 58.3% on
real-world generalization settings. The project website of GLUE is available at
https://GLUE666.github.io/.

</details>


### [32] [SAC-Loco: Safe and Adjustable Compliant Quadrupedal Locomotion](https://arxiv.org/abs/2509.23223)
*Aoqian Zhang,Zixuan Zhuang,Chunzheng Wang,Shuzhi Sam Ge,Fan Shi,Cheng Xiang*

Main category: cs.RO

TL;DR: 提出了一种切换策略框架，用于实现四足机器人的柔顺和安全运动控制，结合了可调节柔顺性策略和安全策略，通过可恢复性网络进行策略切换。


<details>
  <summary>Details</summary>
Motivation: 现有四足机器人控制方法缺乏动物所具备的自适应和可调节柔顺性能力，在受到大扰动时容易失效，需要开发能够同时实现柔顺性和安全性的控制框架。

Method: 使用师生强化学习框架训练具有可调节柔顺性水平的力柔顺策略，无需显式力传感；基于捕获点概念开发安全策略；引入可恢复性网络预测失败可能性并在两种策略间切换。

Result: 该框架使四足机器人在受到严重外部扰动时能够同时实现力柔顺性和鲁棒安全性。

Conclusion: 所提出的切换策略框架成功解决了四足机器人在扰动环境下的柔顺控制和安全性问题，实现了类似动物的自适应柔顺能力。

Abstract: Quadruped robots are designed to achieve agile locomotion by mimicking legged
animals. However, existing control methods for quadrupeds often lack one of the
key capabilities observed in animals: adaptive and adjustable compliance in
response to external disturbances. Most locomotion controllers do not provide
tunable compliance and tend to fail under large perturbations. In this work, we
propose a switched policy framework for compliant and safe quadruped
locomotion. First, we train a force compliant policy with adjustable compliance
levels using a teacher student reinforcement learning framework, eliminating
the need for explicit force sensing. Next, we develop a safe policy based on
the capture point concept to stabilize the robot when the compliant policy
fails. Finally, we introduce a recoverability network that predicts the
likelihood of failure and switches between the compliant and safe policies.
Together, this framework enables quadruped robots to achieve both force
compliance and robust safety when subjected to severe external disturbances.

</details>


### [33] [Leave No Observation Behind: Real-time Correction for VLA Action Chunks](https://arxiv.org/abs/2509.23224)
*Kohei Sendai,Maxime Alvarez,Tatsuya Matsushima,Yutaka Matsuo,Yusuke Iwasawa*

Main category: cs.RO

TL;DR: 提出A2C2方法，通过轻量级实时动作块校正头来解决VLA模型动作分块导致的反应性下降问题，无需重新训练基础策略即可恢复闭环响应能力。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言-动作模型使用动作分块提高效率和时序一致性，但会损害在推理延迟和长时域下的反应性。

Method: A2C2是一个轻量级实时校正头，在每个控制步骤运行，结合最新观测、VLA预测动作、位置特征和基础策略特征，输出逐步骤校正。

Result: 在动态Kinetix任务套件和LIBERO Spatial上，相比RTC方法，在增加延迟和执行时域下分别获得23%和7%的成功率提升，即使在零延迟下也改善了长时域的鲁棒性。

Conclusion: A2C2是一种有效、即插即用的机制，可在实时控制中部署高容量分块策略，校正头轻量快速，计算开销极小。

Abstract: To improve efficiency and temporal coherence, Vision-Language-Action (VLA)
models often predict action chunks; however, this action chunking harms
reactivity under inference delay and long horizons. We introduce Asynchronous
Action Chunk Correction (A2C2), which is a lightweight real-time chunk
correction head that runs every control step and adds a time-aware correction
to any off-the-shelf VLA's action chunk. The module combines the latest
observation, the predicted action from VLA (base action), a positional feature
that encodes the index of the base action within the chunk, and some features
from the base policy, then outputs a per-step correction. This preserves the
base model's competence while restoring closed-loop responsiveness. The
approach requires no retraining of the base policy and is orthogonal to
asynchronous execution schemes such as Real Time Chunking (RTC). On the dynamic
Kinetix task suite (12 tasks) and LIBERO Spatial, our method yields consistent
success rate improvements across increasing delays and execution horizons (+23%
point and +7% point respectively, compared to RTC), and also improves
robustness for long horizons even with zero injected delay. Since the
correction head is small and fast, there is minimal overhead compared to the
inference of large VLA models. These results indicate that A2C2 is an
effective, plug-in mechanism for deploying high-capacity chunking policies in
real-time control.

</details>


### [34] [Online Dynamic Goal Recognition in Gym Environments](https://arxiv.org/abs/2509.23244)
*Shamir Matan,Elhadad Osher,Nageris Ben,Mirsky Reuth*

Main category: cs.RO

TL;DR: 提出了两个开源框架gr-libs和gr-envs，用于标准化目标识别（GR）算法的开发、评估和比较，解决了该领域在基准测试、领域和评估协议方面的不一致问题。


<details>
  <summary>Details</summary>
Motivation: 目标识别领域由于基准测试、领域和评估协议的不一致而呈现碎片化状态，需要统一的框架来支持算法开发和比较。

Method: 开发了两个互补的开源框架：gr-libs包含模块化的MDP-based GR基线实现、诊断工具和评估工具；gr-envs提供了一套适用于动态和目标导向行为的环境，并确保与标准强化学习工具包的兼容性。

Result: 创建了一个标准化、可扩展和可复现的平台，支持GR研究的推进，两个包已在GitHub和PyPI上开源提供。

Conclusion: 这些框架为GR研究提供了一个统一的平台，有助于解决该领域的碎片化问题，促进算法的标准化开发和比较。

Abstract: Goal Recognition (GR) is the task of inferring an agent's intended goal from
partial observations of its behavior, typically in an online and one-shot
setting. Despite recent advances in model-free GR, particularly in applications
such as human-robot interaction, surveillance, and assistive systems, the field
remains fragmented due to inconsistencies in benchmarks, domains, and
evaluation protocols.
  To address this, we introduce gr-libs
(https://github.com/MatanShamir1/gr_libs) and gr-envs
(https://github.com/MatanShamir1/gr_envs), two complementary open-source
frameworks that support the development, evaluation, and comparison of GR
algorithms in Gym-compatible environments. gr-libs includes modular
implementations of MDP-based GR baselines, diagnostic tools, and evaluation
utilities. gr-envs provides a curated suite of environments adapted for dynamic
and goal-directed behavior, along with wrappers that ensure compatibility with
standard reinforcement learning toolkits. Together, these libraries offer a
standardized, extensible, and reproducible platform for advancing GR research.
Both packages are open-source and available on GitHub and PyPI.

</details>


### [35] [Preventing Robotic Jailbreaking via Multimodal Domain Adaptation](https://arxiv.org/abs/2509.23281)
*Francesco Marchiori,Rohan Sinha,Christopher Agia,Alexander Robey,George J. Pappas,Mauro Conti,Marco Pavone*

Main category: cs.RO

TL;DR: J-DAPT是一个轻量级多模态越狱检测框架，通过注意力融合和领域适应技术，在机器人环境中实现接近100%的检测准确率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和视觉语言模型在机器人环境中部署时容易受到越狱攻击，绕过安全机制导致现实世界中的不安全行为。现有基于数据驱动的防御方法在专业数据集稀缺的领域泛化能力有限。

Method: J-DAPT整合文本和视觉嵌入来捕捉语义意图和环境基础，同时通过注意力融合和领域适应技术将通用越狱数据集与领域特定参考数据对齐。

Result: 在自动驾驶、海洋机器人和四足导航等领域的评估显示，J-DAPT将检测准确率提升至接近100%，且开销极小。

Conclusion: J-DAPT为机器人应用中的视觉语言模型提供了一个实用的安全防御解决方案。

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) are
increasingly deployed in robotic environments but remain vulnerable to
jailbreaking attacks that bypass safety mechanisms and drive unsafe or
physically harmful behaviors in the real world. Data-driven defenses such as
jailbreak classifiers show promise, yet they struggle to generalize in domains
where specialized datasets are scarce, limiting their effectiveness in robotics
and other safety-critical contexts. To address this gap, we introduce J-DAPT, a
lightweight framework for multimodal jailbreak detection through
attention-based fusion and domain adaptation. J-DAPT integrates textual and
visual embeddings to capture both semantic intent and environmental grounding,
while aligning general-purpose jailbreak datasets with domain-specific
reference data. Evaluations across autonomous driving, maritime robotics, and
quadruped navigation show that J-DAPT boosts detection accuracy to nearly 100%
with minimal overhead. These results demonstrate that J-DAPT provides a
practical defense for securing VLMs in robotic applications. Additional
materials are made available at: https://j-dapt.github.io.

</details>


### [36] [A Novel Narrow Region Detector for Sampling-Based Planners' Efficiency: Match Based Passage Identifier](https://arxiv.org/abs/2509.23288)
*Yafes Enes Şahiner,Esat Yusuf Gündoğdu,Volkan Sezer*

Main category: cs.RO

TL;DR: 提出一种新型采样器，使用占据栅格地图确定性识别狭窄通道环境，并在这些区域增加采样量，在狭窄通道环境中显著提升路径规划性能。


<details>
  <summary>Details</summary>
Motivation: 概率路径规划方法在狭窄通道环境中普遍存在性能问题，需要专门解决这类环境的采样策略。

Method: 基于占据栅格地图确定性识别狭窄通道，并在这些区域增加采样密度，算法代码开源。

Result: 在特定模拟环境、随机模拟环境和真实世界环境的基准测试中，相比基线采样器，该算法在规划时间和里程碑数量方面表现更优。

Conclusion: 提出的采样器能有效解决狭窄通道环境中的路径规划问题，显著提升规划性能。

Abstract: Autonomous technology, which has become widespread today, appears in many
different configurations such as mobile robots, manipulators, and drones. One
of the most important tasks of these vehicles during autonomous operations is
path planning. In the literature, path planners are generally divided into two
categories: probabilistic and deterministic methods. In the analysis of
probabilistic methods, the common problem of almost all methods is observed in
narrow passage environments. In this paper, a novel sampler is proposed that
deterministically identifies narrow passage environments using occupancy grid
maps and accordingly increases the amount of sampling in these regions. The
codes of the algorithm is provided as open source. To evaluate the performance
of the algorithm, benchmark studies are conducted in three distinct categories:
specific and random simulation environments, and a real-world environment. As a
result, it is observed that our algorithm provides higher performance in
planning time and number of milestones compared to the baseline samplers.

</details>


### [37] [Distributed Multi-Robot Multi-Target Simultaneous Search and Tracking in an Unknown Non-convex Environment](https://arxiv.org/abs/2509.23308)
*Jun Chen,Jiaqing Ma,Philip Dames*

Main category: cs.RO

TL;DR: 提出了一种集成前沿探索、保证覆盖和多目标跟踪三种策略的运动规划算法框架，用于在未知非凸环境中平衡覆盖搜索和高精度主动跟踪。


<details>
  <summary>Details</summary>
Motivation: 在室内和地下等未知非凸环境中，部署机器人舰队同时进行环境探索、目标搜索和跟踪以维持高精度数据收集是一个亟待解决的基础挑战。现有研究尚未建立同时优化这些任务的框架。

Method: 提出集成三种控制策略的运动规划算法框架：基于前沿的探索策略、基于Lloyd算法的保证覆盖策略、基于传感器的多目标跟踪策略。

Result: 通过MATLAB仿真验证了算法的有效性和优越性，证明能够平衡覆盖搜索和高精度主动跟踪。

Conclusion: 该算法框架成功解决了在复杂环境中同时优化探索、搜索和跟踪任务的挑战，为环境监测和救援等应用提供了有效解决方案。

Abstract: In unknown non-convex environments, such as indoor and underground spaces,
deploying a fleet of robots to explore the surroundings while simultaneously
searching for and tracking targets of interest to maintain high-precision data
collection represents a fundamental challenge that urgently requires resolution
in applications such as environmental monitoring and rescue operations. Current
research has made significant progress in addressing environmental exploration,
information search, and target tracking problems, but has yet to establish a
framework for simultaneously optimizing these tasks in complex environments. In
this paper, we propose a novel motion planning algorithm framework that
integrates three control strategies: a frontier-based exploration strategy, a
guaranteed coverage strategy based on Lloyd's algorithm, and a sensor-based
multi-target tracking strategy. By incorporating these three strategies, the
proposed algorithm balances coverage search and high-precision active tracking
during exploration. Our approach is validated through a series of MATLAB
simulations, demonstrating validity and superiority over standard approaches.

</details>


### [38] [GUARD: Toward a Compromise between Traditional Control and Learning for Safe Robot Systems](https://arxiv.org/abs/2509.23312)
*Johannes A. Gaus,Junheon Yoon,Woo-Jeong Baek,Seungwon Choi,Suhan Park,Jaeheung Park*

Main category: cs.RO

TL;DR: GUARD是一个结合传统控制与不确定性感知感知技术的机器人安全避障框架，通过主动学习和实时能力实现风险感知决策。


<details>
  <summary>Details</summary>
Motivation: 解决机器人学中传统方法与学习算法之间的平衡问题，开发安全、高效且灵活的应用。

Method: 将反应式模型预测轮廓控制（RMPCC）与迭代最近点（ICP）算法结合，通过概率核优化技术在线归因不确定性源，具备实时主动学习能力。

Result: 实验研究表明GUARD具有高性能，能够有效处理机器人文献中安全概念的模糊性。

Conclusion: GUARD框架展示了将传统控制与学习算法结合的潜力，未来需要扩大其适用性。

Abstract: This paper presents the framework \textbf{GUARD} (\textbf{G}uided robot
control via \textbf{U}ncertainty attribution and prob\textbf{A}bilistic kernel
optimization for \textbf{R}isk-aware \textbf{D}ecision making) that combines
traditional control with an uncertainty-aware perception technique using active
learning with real-time capability for safe robot collision avoidance. By doing
so, this manuscript addresses the central challenge in robotics of finding a
reasonable compromise between traditional methods and learning algorithms to
foster the development of safe, yet efficient and flexible applications. By
unifying a reactive model predictive countouring control (RMPCC) with an
Iterative Closest Point (ICP) algorithm that enables the attribution of
uncertainty sources online using active learning with real-time capability via
a probabilistic kernel optimization technique, \emph{GUARD} inherently handles
the existing ambiguity of the term \textit{safety} that exists in robotics
literature. Experimental studies indicate the high performance of \emph{GUARD},
thereby highlighting the relevance and need to broaden its applicability in
future.

</details>


### [39] [Space Robotics Bench: Robot Learning Beyond Earth](https://arxiv.org/abs/2509.23328)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 提出了Space Robotics Bench开源仿真框架，用于空间机器人学习，包含模块化架构、程序化生成和大规模并行仿真，支持创建多样化训练分布和基准任务。


<details>
  <summary>Details</summary>
Motivation: 空间探索需要能在极端外星环境下运行的自主系统，但机器人学习在该领域应用受限，主要因为技术演示成本高昂和数据稀缺。

Method: 开发开源仿真框架，采用模块化架构整合按需程序化生成和大规模并行仿真环境，提供基准任务套件，使用标准强化学习算法建立性能基线。

Result: 通过实验案例研究揭示了当前方法在泛化、端到端学习、自适应控制和仿真到现实迁移方面的局限性，证明了框架能生成具有实际应用能力的策略。

Conclusion: Space Robotics Bench为开发、基准测试和部署空间探索所需的稳健自主系统提供了宝贵资源。

Abstract: The growing ambition for space exploration demands robust autonomous systems
that can operate in unstructured environments under extreme extraterrestrial
conditions. The adoption of robot learning in this domain is severely hindered
by the prohibitive cost of technology demonstrations and the limited
availability of data. To bridge this gap, we introduce the Space Robotics
Bench, an open-source simulation framework for robot learning in space. It
offers a modular architecture that integrates on-demand procedural generation
with massively parallel simulation environments to support the creation of vast
and diverse training distributions for learning-based agents. To ground
research and enable direct comparison, the framework includes a comprehensive
suite of benchmark tasks that span a wide range of mission-relevant scenarios.
We establish performance baselines using standard reinforcement learning
algorithms and present a series of experimental case studies that investigate
key challenges in generalization, end-to-end learning, adaptive control, and
sim-to-real transfer. Our results reveal insights into the limitations of
current methods and demonstrate the utility of the framework in producing
policies capable of real-world operation. These contributions establish the
Space Robotics Bench as a valuable resource for developing, benchmarking, and
deploying the robust autonomous systems required for the final frontier.

</details>


### [40] [Robust Orientation Estimation with TRIAD-aided Manifold EKF](https://arxiv.org/abs/2509.23456)
*Arjun Sadananda,Ravi Banavar,Kavi Arya*

Main category: cs.RO

TL;DR: 将TRIAD算法的次优特性整合到流形扩展卡尔曼滤波中，以减轻磁力计读数对俯仰和滚转轴确定的影响


<details>
  <summary>Details</summary>
Motivation: 磁力计作为姿态确定传感器容易受到校准和外部磁场干扰，影响姿态估计精度

Method: 在流形扩展卡尔曼滤波算法中融入TRIAD算法的次优特性来减轻磁力计读数的影响

Result: 通过实验验证了所提方法的有效性

Conclusion: 提出的方法能够有效减轻磁力计读数对姿态确定的影响

Abstract: The manifold extended Kalman filter (Manifold EKF) has found extensive
application for attitude determination. Magnetometers employed as sensors for
such attitude determination are easily prone to disturbances by their
sensitivity to calibration and external magnetic fields. The TRIAD (Tri-Axial
Attitude Determination) algorithm is well known as a sub-optimal attitude
estimator. In this article, we incorporate this sub-optimal feature of the
TRIAD in mitigating the influence of the magnetometer reading in the pitch and
roll axis determination in the Manifold EKF algorithm. We substantiate our
results with experiments.

</details>


### [41] [Multi-Modal Manipulation via Multi-Modal Policy Consensus](https://arxiv.org/abs/2509.23468)
*Haonan Chen,Jiaming Xu,Hongyu Chen,Kaiwen Hong,Binghao Huang,Chaoqi Liu,Jiayuan Mao,Yunzhu Li,Yilun Du,Katherine Driggs-Campbell*

Main category: cs.RO

TL;DR: 提出了一种多模态机器人操作策略，通过扩散模型分解和路由器网络自适应融合不同模态，解决了传统特征拼接方法中主导模态压制稀疏关键信号的问题。


<details>
  <summary>Details</summary>
Motivation: 传统特征拼接方法在多模态机器人操作中存在缺陷：视觉等主导模态会压制触觉等稀疏但关键的信号，且单一架构无法灵活处理新模态或缺失模态。

Method: 将策略分解为一组专门处理单个表征（如视觉或触觉）的扩散模型，使用路由器网络学习共识权重来自适应组合各模型的贡献，支持新表征的增量集成。

Result: 在RLBench模拟操作任务和真实世界任务（如遮挡物体抓取、手内勺子重定向、拼图插入）中显著优于特征拼接基线，对物理扰动和传感器损坏具有鲁棒性。

Conclusion: 该方法在多模态推理场景中表现优异，扰动重要性分析揭示了模态间的自适应切换，为多模态机器人操作提供了更灵活和鲁棒的解决方案。

Abstract: Effectively integrating diverse sensory modalities is crucial for robotic
manipulation. However, the typical approach of feature concatenation is often
suboptimal: dominant modalities such as vision can overwhelm sparse but
critical signals like touch in contact-rich tasks, and monolithic architectures
cannot flexibly incorporate new or missing modalities without retraining. Our
method factorizes the policy into a set of diffusion models, each specialized
for a single representation (e.g., vision or touch), and employs a router
network that learns consensus weights to adaptively combine their
contributions, enabling incremental of new representations. We evaluate our
approach on simulated manipulation tasks in {RLBench}, as well as real-world
tasks such as occluded object picking, in-hand spoon reorientation, and puzzle
insertion, where it significantly outperforms feature-concatenation baselines
on scenarios requiring multimodal reasoning. Our policy further demonstrates
robustness to physical perturbations and sensor corruption. We further conduct
perturbation-based importance analysis, which reveals adaptive shifts between
modalities.

</details>


### [42] [Ask, Reason, Assist: Decentralized Robot Collaboration via Language and Logic](https://arxiv.org/abs/2509.23506)
*Dan BW Choe,Sundhar Vinodh Sangeetha,Steven Emanuel,Chih-Yuan Chiu,Samuel Coogan,Shreyas Kousik*

Main category: cs.RO

TL;DR: 提出了一种去中心化框架，让机器人能够通过自然语言请求和提供帮助，使用LLM进行决策和STL翻译，通过MILP求解，显著优于启发式方法。


<details>
  <summary>Details</summary>
Motivation: 解决异构机器人团队在仓储等场景中应对意外冲突的需求，实现无缝协作。

Method: 机器人检测冲突后使用LLM决定是否需要外部帮助，广播自然语言请求；帮助机器人通过LLM和STL语法进行推理，使用MILP求解；请求者基于系统级任务完成时间选择帮助者。

Result: 实验表明考虑多个帮助提议能最小化增加的总完成时间，显著优于选择最近可用机器人的启发式方法，性能接近集中式基准但信息需求更少。

Conclusion: 该去中心化框架有效实现了异构机器人团队的合作，在减少信息需求的同时达到接近最优性能。

Abstract: Increased robot deployment, such as in warehousing, has revealed a need for
seamless collaboration among heterogeneous robot teams to resolve unforeseen
conflicts. To address this challenge, we propose a novel decentralized
framework that enables robots to request and provide help. The process begins
when a robot detects a conflict and uses a Large Language Model (LLM) to decide
whether external assistance is required. If so, it crafts and broadcasts a
natural language (NL) help request. Potential helper robots reason over the
request and respond with offers of assistance, including information about the
effect on their ongoing tasks. Helper reasoning is implemented via an LLM
grounded in Signal Temporal Logic (STL) using a Backus-Naur Form (BNF) grammar,
ensuring syntactically valid NL-to-STL translations, which are then solved as a
Mixed Integer Linear Program (MILP). Finally, the requester robot selects a
helper by reasoning over the expected increase in system-level total task
completion time. We evaluated our framework through experiments comparing
different helper-selection strategies and found that considering multiple
offers allows the requester to minimize added makespan. Our approach
significantly outperforms heuristics such as selecting the nearest available
candidate helper robot, and achieves performance comparable to a centralized
"Oracle" baseline but without heavy information demands.

</details>


### [43] [Zero-shot Whole-Body Manipulation with a Large-Scale Soft Robotic Torso via Guided Reinforcement Learning](https://arxiv.org/abs/2509.23556)
*Curtis C. Johnson,Carlo Alessi,Egidio Falotico,Marc D. Killpack*

Main category: cs.RO

TL;DR: 开发了高速软体机器人仿真框架（350倍实时速度），实现了零样本仿真到实体的全身操作策略迁移，在Baloo硬件平台上达到88%成功率，展示了双连续软臂的强力六自由度全身操作能力。


<details>
  <summary>Details</summary>
Motivation: 软体机器人因其被动柔顺性适合接触丰富的全身操作任务，但其运动学和动力学不确定性给仿真和控制带来挑战，需要开发高效的仿真和控制方法。

Method: 使用MuJoCo开发高速仿真框架（350倍实时速度），结合简单运动基元引导强化学习，实现零样本仿真到实体的策略迁移。

Result: 在Baloo硬件平台上实现88%成功率的全身操作，能够处理10kg载荷，策略表现出有益的响应行为如重新抓取和扰动恢复。

Conclusion: 这是首次使用双连续软臂实现强力六自由度全身操作的零样本策略迁移，证明了运动基元引导的强化学习在复杂软体机器人控制中的有效性。

Abstract: Whole-body manipulation is a powerful yet underexplored approach that enables
robots to interact with large, heavy, or awkward objects using more than just
their end-effectors. Soft robots, with their inherent passive compliance, are
particularly well-suited for such contact-rich manipulation tasks, but their
uncertainties in kinematics and dynamics pose significant challenges for
simulation and control. In this work, we address this challenge with a
simulation that can run up to 350x real time on a single thread in MuJoCo and
provide a detailed analysis of the critical tradeoffs between speed and
accuracy for this simulation. Using this framework, we demonstrate a successful
zero-shot sim-to-real transfer of a learned whole-body manipulation policy,
achieving an 88% success rate on the Baloo hardware platform. We show that
guiding RL with a simple motion primitive is critical to this success where
standard reward shaping methods struggled to produce a stable and successful
policy for whole-body manipulation. Furthermore, our analysis reveals that the
learned policy does not simply mimic the motion primitive. It exhibits
beneficial reactive behavior, such as re-grasping and perturbation recovery. We
analyze and contrast this learned policy against an open-loop baseline to show
that the policy can also exhibit aggressive over-corrections under
perturbation. To our knowledge, this is the first demonstration of forceful,
six-DoF whole-body manipulation using two continuum soft arms on a large-scale
platform (10 kg payloads), with zero-shot policy transfer.

</details>


### [44] [High Torque Density PCB Axial Flux Permanent Magnet Motor for Micro Robots](https://arxiv.org/abs/2509.23561)
*Jianren Wang,Jie Han,Abhinav Gupta,Deepak Pathak,Yang Zhang*

Main category: cs.RO

TL;DR: 本文介绍了一种采用PCB绕组和HDI技术的微型轴向磁通永磁电机，解决了传统绕线定子在20mm以下直径电机中铜填充率低的问题，实现了45%的高铜填充率。


<details>
  <summary>Details</summary>
Motivation: 准直驱驱动需要在小尺寸关节包络内提供高扭矩，但传统AFPM电机在20mm以下直径时铜填充率低，导致电阻增加和连续扭矩受限。

Method: 采用印刷电路板绕组和先进IC基板高密度互连技术，通过堆叠四个12层HDI模块形成48层定子结构。

Result: 在仅5mm厚、19mm直径的封装中实现了45%的创纪录铜填充率，并通过电磁和热分析指导设计，实验验证了原型性能。

Conclusion: PCB绕组和HDI技术成功解决了微型AFPM电机的铜填充率限制，为小型化高扭矩电机提供了可行方案。

Abstract: Quasi-direct-drive (QDD) actuation is transforming legged and manipulator
robots by eliminating high-ratio gearboxes, yet it demands motors that deliver
very high torque at low speed within a thin, disc-shaped joint envelope.
Axial-flux permanent-magnet (AFPM) machines meet these geometric and torque
requirements, but scaling them below a 20mm outer diameter is hampered by poor
copper fill in conventional wound stators, inflating resistance and throttling
continuous torque. This paper introduces a micro-scale AFPM motor that
overcomes these limitations through printed-circuit-board (PCB) windings
fabricated with advanced IC-substrate high-density interconnect (HDI)
technology. The resulting 48-layer stator-formed by stacking four 12-layer HDI
modules-achieves a record 45\% copper fill in a package only 5mm thick and 19mm
in diameter. We perform comprehensive electromagnetic and thermal analyses to
inform the motor design, then fabricate a prototype whose performance
characteristics are experimentally verified.

</details>


### [45] [RAVEN: Resilient Aerial Navigation via Open-Set Semantic Memory and Behavior Adaptation](https://arxiv.org/abs/2509.23563)
*Seungchan Kim,Omar Alama,Dmytro Kurdydyk,John Keller,Nikhil Keetha,Wenshan Wang,Yonatan Bisk,Sebastian Scherer*

Main category: cs.RO

TL;DR: RAVEN是一个基于3D记忆和行为树框架的空中语义导航系统，专门用于非结构化户外环境中的目标搜索。


<details>
  <summary>Details</summary>
Motivation: 解决户外语义导航中现有方法的局限性：室内方法受限于空间范围和结构化布局，户外方法要么依赖反应式策略导致短视行为，要么需要离线预计算场景图限制在线部署适应性。

Method: 使用空间一致的语义体素射线图作为持久记忆，结合短程体素搜索和远程射线搜索，利用大型视觉语言模型提供辅助线索，通过行为树协调自适应切换行为。

Result: 在10个逼真户外仿真环境中测试100个语义任务，RAVEN比基线方法性能提升85.25%，并在真实户外环境中成功部署验证。

Conclusion: RAVEN框架通过3D记忆和自适应行为树实现了户外环境中稳健的长距离语义导航，克服了现有方法的局限性。

Abstract: Aerial outdoor semantic navigation requires robots to explore large,
unstructured environments to locate target objects. Recent advances in semantic
navigation have demonstrated open-set object-goal navigation in indoor
settings, but these methods remain limited by constrained spatial ranges and
structured layouts, making them unsuitable for long-range outdoor search. While
outdoor semantic navigation approaches exist, they either rely on reactive
policies based on current observations, which tend to produce short-sighted
behaviors, or precompute scene graphs offline for navigation, limiting
adaptability to online deployment. We present RAVEN, a 3D memory-based,
behavior tree framework for aerial semantic navigation in unstructured outdoor
environments. It (1) uses a spatially consistent semantic voxel-ray map as
persistent memory, enabling long-horizon planning and avoiding purely reactive
behaviors, (2) combines short-range voxel search and long-range ray search to
scale to large environments, (3) leverages a large vision-language model to
suggest auxiliary cues, mitigating sparsity of outdoor targets. These
components are coordinated by a behavior tree, which adaptively switches
behaviors for robust operation. We evaluate RAVEN in 10 photorealistic outdoor
simulation environments over 100 semantic tasks, encompassing single-object
search, multi-class, multi-instance navigation and sequential task changes.
Results show RAVEN outperforms baselines by 85.25% in simulation and
demonstrate its real-world applicability through deployment on an aerial robot
in outdoor field tests.

</details>


### [46] [GES-UniGrasp: A Two-Stage Dexterous Grasping Strategy With Geometry-Based Expert Selection](https://arxiv.org/abs/2509.23567)
*Fangting Xu,Jilin Zhu,Xiaoming Gu,Jianzhong Tang*

Main category: cs.RO

TL;DR: 提出了ContactGrasp数据集和Geometry-based Expert Selection框架，用于实现类人灵巧抓取，在训练集和测试集上分别达到99.4%和96.3%的高成功率。


<details>
  <summary>Details</summary>
Motivation: 现有基于抓取先验的强化学习方法往往产生不自然的行为，需要开发能够实现类人灵巧抓取的方法来推进真实场景中的智能机器人操作。

Method: 构建包含773个物体、82个类别的ContactGrasp数据集，通过基于几何形状的聚类将物体分组，采用两阶段的Geometry-based Expert Selection框架选择专门专家来抓取不同几何形状的物体。

Result: 方法展示了自然的抓取姿势，在训练集和测试集上分别达到99.4%和96.3%的高成功率，表现出强大的泛化能力和高质量的抓取执行。

Conclusion: ContactGrasp数据集和GES框架能够有效实现类人灵巧抓取，具有强大的泛化能力，为智能机器人操作提供了重要基础。

Abstract: Robust and human-like dexterous grasping of general objects is a critical
capability for advancing intelligent robotic manipulation in real-world
scenarios. However, existing reinforcement learning methods guided by grasp
priors often result in unnatural behaviors. In this work, we present
\textit{ContactGrasp}, a robotic dexterous pre-grasp and grasp dataset that
explicitly accounts for task-relevant wrist orientation and thumb-index
pinching coordination. The dataset covers 773 objects in 82 categories,
providing a rich foundation for training human-like grasp strategies. Building
upon this dataset, we perform geometry-based clustering to group objects by
shape, enabling a two-stage Geometry-based Expert Selection (GES) framework
that selects among specialized experts for grasping diverse object geometries,
thereby enhancing adaptability to diverse shapes and generalization across
categories. Our approach demonstrates natural grasp postures and achieves high
success rates of 99.4\% and 96.3\% on the train and test sets, respectively,
showcasing strong generalization and high-quality grasp execution.

</details>


### [47] [Generalizable Coarse-to-Fine Robot Manipulation via Language-Aligned 3D Keypoints](https://arxiv.org/abs/2509.23575)
*Jianshu Hu,Lidi Wang,Shujia Li,Yunpeng Jiang,Xiao Li,Paul Weng,Yutong Ban*

Main category: cs.RO

TL;DR: 提出了CLAP框架，通过任务分解、VLM微调进行3D关键点预测和3D感知表示，显著提升了分层策略在机器人3D操作任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的分层粗到细策略虽然在机器人3D操作任务中表现出潜力，但即使使用预训练模型，仍然存在泛化问题，难以适应新的指令和环境变化。

Method: CLAP框架包含三个关键组件：1）任务分解；2）基于VLM微调的3D关键点预测；3）3D感知表示。

Result: 在GemBench基准测试中，比SOTA方法平均成功率提高12%，且仅使用1/5的训练轨迹。在真实机器人实验中，仅用10个演示就能成功泛化到新指令和环境。

Conclusion: CLAP框架通过语言对齐的分层策略，有效解决了机器人3D操作中的泛化问题，在样本效率和泛化能力方面都取得了显著提升。

Abstract: Hierarchical coarse-to-fine policy, where a coarse branch predicts a region
of interest to guide a fine-grained action predictor, has demonstrated
significant potential in robotic 3D manipulation tasks by especially enhancing
sample efficiency and enabling more precise manipulation. However, even
augmented with pre-trained models, these hierarchical policies still suffer
from generalization issues. To enhance generalization to novel instructions and
environment variations, we propose Coarse-to-fine Language-Aligned manipulation
Policy (CLAP), a framework that integrates three key components: 1) task
decomposition, 2) VLM fine-tuning for 3D keypoint prediction, and 3) 3D-aware
representation. Through comprehensive experiments in simulation and on a real
robot, we demonstrate its superior generalization capability. Specifically, on
GemBench, a benchmark designed for evaluating generalization, our approach
achieves a 12\% higher average success rate than the SOTA method while using
only 1/5 of the training trajectories. In real-world experiments, our policy,
trained on only 10 demonstrations, successfully generalizes to novel
instructions and environments.

</details>


### [48] [Encoding Material Safety using Control Barrier Functions for Soft Actuator Control](https://arxiv.org/abs/2509.23623)
*Nicholas Pagliocca,Behrad Koohbor,Mitja Trkov*

Main category: cs.RO

TL;DR: 本文提出了软体机器人材料安全的正式定义，基于应变能函数设计控制器来强制执行安全规范，使用高阶控制屏障函数确保材料不超出安全应变范围。


<details>
  <summary>Details</summary>
Motivation: 随着软体机器人向反馈控制发展，需要明确定义安全概念。软体机器人的统一特性是通过变形实现功能，但本构模型精度限制和材料失效风险是所有软体机器人的固有挑战。

Method: 基于应变能函数定义材料安全，使用高阶控制屏障函数和基于二次规划的反馈控制来强制执行安全规范，以不可压缩超弹性管为案例进行研究。

Result: 仿真结果表明，所提出的方法能够有效强制执行材料安全规范，确保材料在安全应变范围内工作。

Conclusion: 该工作为软体机器人提供了形式化的安全定义和控制方法，解决了软体机器人因材料失效而变得不安全的关键问题。

Abstract: Until recently, the concept of soft robot safety was an informal notion,
often attributed solely to the fact that soft robots are less likely to damage
their operating environment than rigid robots. As the field moves toward
feedback control for practical applications, it becomes increasingly important
to define what safety means and to characterize how soft robots can become
unsafe. The unifying theme of soft robotics is to achieve useful functionality
through deformation. Consequently, limitations in constitutive model accuracy
and risks of material failure are inherent to all soft robots and pose a key
challenge in designing provably safe controllers. This work introduces a formal
definition of material safety based on strain energy functions and provides a
controller that enforces it. We characterize safe and unsafe sets of an
incompressible hyperelastic material and demonstrate that safety can be
enforced using a high-order control barrier function (HOCBF) with quadratic
program-based feedback control. As a case study, we consider a pressurized
hyperelastic tube with inertial effects, first-order viscous effects, and
full-state feedback. Simulation results verify that the proposed methodology
can enforce the material safety specification.

</details>


### [49] [KiVi: Kinesthetic-Visuospatial Integration for Dynamic and Safe Egocentric Legged Locomotion](https://arxiv.org/abs/2509.23650)
*Peizhuo Li,Hongyi Li,Yuxuan Ma,Linnan Chang,Xinrong Yang,Ruiqi Yu,Yifeng Zhang,Yuhong Cao,Qiuguo Zhu,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: KiVi框架通过分离动觉和视觉空间通路，利用本体感觉作为稳定骨干，选择性结合视觉进行地形感知和避障，使四足机器人能在复杂环境中稳定运动。


<details>
  <summary>Details</summary>
Motivation: 视觉信息易受遮挡、反射和光照变化影响，导致运动不稳定。受动物感觉运动整合启发，需要平衡视觉和本体感觉的融合。

Method: 提出KiVi框架，分离动觉编码和视觉空间推理通路，结合记忆增强注意力机制，让机器人稳定解释视觉线索同时通过本体感觉保持后备稳定性。

Result: 实验表明该方法使四足机器人能稳定穿越多样化地形，在非结构化户外环境中可靠运行，对训练中未见过的视觉噪声和遮挡保持鲁棒性。

Conclusion: KiVi框架有效提升了腿式机器人在真实世界环境中的运动能力和适用性，展示了模态平衡设计的重要性。

Abstract: Vision-based locomotion has shown great promise in enabling legged robots to
perceive and adapt to complex environments. However, visual information is
inherently fragile, being vulnerable to occlusions, reflections, and lighting
changes, which often cause instability in locomotion. Inspired by animal
sensorimotor integration, we propose KiVi, a Kinesthetic-Visuospatial
integration framework, where kinesthetics encodes proprioceptive sensing of
body motion and visuospatial reasoning captures visual perception of
surrounding terrain. Specifically, KiVi separates these pathways, leveraging
proprioception as a stable backbone while selectively incorporating vision for
terrain awareness and obstacle avoidance. This modality-balanced, yet
integrative design, combined with memory-enhanced attention, allows the robot
to robustly interpret visual cues while maintaining fallback stability through
proprioception. Extensive experiments show that our method enables quadruped
robots to stably traverse diverse terrains and operate reliably in unstructured
outdoor environments, remaining robust to out-of-distribution (OOD) visual
noise and occlusion unseen during training, thereby highlighting its
effectiveness and applicability to real-world legged locomotion.

</details>


### [50] [HeLoM: Hierarchical Learning for Whole-Body Loco-Manipulation in Hexapod Robot](https://arxiv.org/abs/2509.23651)
*Xinrong Yang,Peizhuo Li,Hongyi Li,Junkai Lu,Linnan Chang,Yuhong Cao,Yifeng Zhang,Ge Sun,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: 提出HeLoM框架，一种基于学习的层次化全身操纵方法，使六足机器人能够通过协调多肢控制稳定推动重物。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在真实环境中推动与自身重量相当的重物时的挑战，需要足够的操纵力同时保持稳定性，特别是对于重或不规则物体。

Method: 采用分层设计：高层规划器规划推动行为和目标物体姿态，低层控制器维持运动稳定性并生成动态一致的关节动作。利用冗余接触点和高自由度实现接触力的动态重新分配。

Result: 在仿真和真实世界实验中验证有效性，能够稳定推动不同尺寸和未知物理属性的箱子到指定目标姿态，且无需额外微调。

Conclusion: HeLoM框架通过协调多肢控制实现了稳定的重物推动，展示了在真实环境中直接部署仿真训练策略的可行性。

Abstract: Robots in real-world environments are often required to move/manipulate
objects comparable in weight to their own bodies. Compared to grasping and
carrying, pushing provides a more straightforward and efficient non-prehensile
manipulation strategy, avoiding complex grasp design while leveraging direct
contact to regulate an object's pose. Achieving effective pushing, however,
demands both sufficient manipulation forces and the ability to maintain
stability, which is particularly challenging when dealing with heavy or
irregular objects. To address these challenges, we propose HeLoM, a
learning-based hierarchical whole-body manipulation framework for a hexapod
robot that exploits coordinated multi-limb control. Inspired by the cooperative
strategies of multi-legged insects, our framework leverages redundant contact
points and high degrees of freedom to enable dynamic redistribution of contact
forces. HeLoM's high-level planner plans pushing behaviors and target object
poses, while its low-level controller maintains locomotion stability and
generates dynamically consistent joint actions. Our policies trained in
simulation are directly deployed on real robots without additional fine-tuning.
This design allows the robot to maintain balance while exerting continuous and
controllable pushing forces through coordinated foreleg interaction and
supportive hind-leg propulsion. We validate the effectiveness of HeLoM through
both simulation and real-world experiments. Results show that our framework can
stably push boxes of varying sizes and unknown physical properties to
designated goal poses in the real world.

</details>


### [51] [Focusing on What Matters: Object-Agent-centric Tokenization for Vision Language Action models](https://arxiv.org/abs/2509.23655)
*Rokas Bendikas,Daniel Dijkman,Markus Peschl,Sanjay Haresh,Pietro Mazzaglia*

Main category: cs.RO

TL;DR: Oat-VLA提出了一种面向对象和智能体的视觉标记化方法，通过减少视觉标记数量来显著降低VLA模型的计算成本，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在适应机器人领域时计算成本过高，主要问题在于视觉输入的标记化方案效率低下。

Method: 基于对象中心表示学习的见解，引入了对场景对象和智能体自身视觉信息的归纳偏置，将视觉标记大幅减少到仅几个标记。

Result: 在LIBERO套件上收敛速度至少是OpenVLA的两倍，在多样化的真实世界拾取放置任务中表现优于OpenVLA。

Conclusion: Oat-VLA通过高效的视觉标记化方案，实现了VLA模型训练的计算效率大幅提升，同时保持甚至提升了性能。

Abstract: Vision-Language-Action (VLA) models offer a pivotal approach to learning
robotic manipulation at scale by repurposing large pre-trained
Vision-Language-Models (VLM) to output robotic actions. However, adapting VLMs
for robotic domains comes with an unnecessarily high computational cost, which
we attribute to the tokenization scheme of visual inputs. In this work, we aim
to enable efficient VLA training by proposing Oat-VLA, an Object-Agent-centric
Tokenization for VLAs. Building on the insights of object-centric
representation learning, our method introduces an inductive bias towards scene
objects and the agent's own visual information. As a result, we find that
Oat-VLA can drastically reduce the number of visual tokens to just a few tokens
without sacrificing performance. We reveal that Oat-VLA converges at least
twice as fast as OpenVLA on the LIBERO suite, as well as outperform OpenVLA in
diverse real-world pick and place tasks.

</details>


### [52] [Certifiably Optimal State Estimation and Robot Calibration Using Trace-Constrained SDP](https://arxiv.org/abs/2509.23656)
*Liangting Wu,Roberto Tron*

Main category: cs.RO

TL;DR: 该论文提出了一种针对机器人学中非凸问题的半定规划方法，通过引入固定迹约束来促进秩1解，并开发了梯度优化程序来改进解的质量。


<details>
  <summary>Details</summary>
Motivation: 机器人学中的许多非凸问题可以通过半定规划转化为凸问题，但实际解的质量依赖于获得秩1矩阵，这通常需要额外的约束条件。

Method: 引入定制化的固定迹变量和约束来表示机器人学中的常见量（如旋转和平移），并开发梯度优化程序将松弛解投影到秩1候选解。

Result: 该方法在透视n点估计、手眼标定和双机器人系统标定等任务中表现出有效性，并通过对偶问题验证全局最优性。

Conclusion: 固定迹约束的半定规划框架能够有效处理多种机器人学任务，并通过模块化的"虚拟机器人"抽象简化建模过程。

Abstract: Many nonconvex problems in robotics can be relaxed into convex formulations
via semidefinite programming (SDP), which offers the advantage of global
optimality. The practical quality of these solutions, however, critically
depends on achieving rank-1 matrices, a condition that typically requires
additional tightening. In this work, we focus on trace-constrained SDPs, where
the decision variables are positive semidefinite (PSD) matrices with fixed
trace values. These additional constraints not only capture important
structural properties but also facilitate first-order methods for recovering
rank-1 solutions. We introduce customized fixed-trace variables and constraints
to represent common robotic quantities such as rotations and translations,
which can be exactly recovered when the corresponding variables are rank-1. To
further improve practical performance, we develop a gradient-based refinement
procedure that projects relaxed SDP solutions toward rank-1, low-cost
candidates, which can then be certified for global optimality via the dual
problem. We demonstrate that many robotics tasks can be expressed within this
trace-constrained SDP framework, and showcase its effectiveness through
simulations in perspective-n-point (PnP) estimation, hand-eye calibration, and
dual-robot system calibration. To support broader use, we also introduce a
modular ``virtual robot'' abstraction that simplifies modeling across different
problem settings.

</details>


### [53] [MDCPP: Multi-robot Dynamic Coverage Path Planning for Workload Adaptation](https://arxiv.org/abs/2509.23705)
*Jun Chen,Mingjia Chen,Shinkyu Park*

Main category: cs.RO

TL;DR: 提出了一种多机器人动态覆盖路径规划算法MDCPP，通过动态估计机器人工作负载和使用容量约束Voronoi图来分配覆盖区域，解决了传统方法中机器人速度固定导致的负载不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统的多机器人覆盖路径规划方法假设机器人以固定速度移动，这在现实应用中不切实际。机器人需要根据具体覆盖任务调整速度，传统方法导致工作负载分布不均和覆盖任务完成时间增加。

Method: 使用高斯混合模型近似目标分布来动态估计每个机器人的剩余工作负载，采用容量约束Voronoi图分配覆盖区域，并开发了分布式实现用于范围受限的机器人网络。

Result: 仿真结果验证了MDCPP的有效性，相比现有的扫描算法，在定性改进和性能表现上更优越，并量化了通信范围对覆盖效率的影响。

Conclusion: MDCPP算法能够有效解决多机器人动态覆盖路径规划问题，通过动态工作负载估计和智能区域分配，显著提高了覆盖效率和负载均衡性。

Abstract: Multi-robot Coverage Path Planning (MCPP) addresses the problem of computing
paths for multiple robots to effectively cover a large area of interest.
Conventional approaches to MCPP typically assume that robots move at fixed
velocities, which is often unrealistic in real-world applications where robots
must adapt their speeds based on the specific coverage tasks assigned to
them.Consequently, conventional approaches often lead to imbalanced workload
distribution among robots and increased completion time for coverage tasks. To
address this, we introduce a novel Multi-robot Dynamic Coverage Path Planning
(MDCPP) algorithm for complete coverage in two-dimensional environments. MDCPP
dynamically estimates each robot's remaining workload by approximating the
target distribution with Gaussian mixture models, and assigns coverage regions
using a capacity-constrained Voronoi diagram. We further develop a distributed
implementation of MDCPP for range-constrained robotic networks. Simulation
results validate the efficacy of MDCPP, showing qualitative improvements and
superior performance compared to an existing sweeping algorithm, and a
quantifiable impact of communication range on coverage efficiency.

</details>


### [54] [DA-MMP: Learning Coordinated and Accurate Throwing with Dynamics-Aware Motion Manifold Primitives](https://arxiv.org/abs/2509.23721)
*Chi Chu,Huazhe Xu*

Main category: cs.RO

TL;DR: 提出DA-MMP框架，通过运动流形原语和条件流匹配模型，解决动态操作任务中的动力学差距问题，在环抛任务中实现高成功率并超越人类专家表现。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法依赖手动设计的动作参数化，难以产生复杂任务所需的协调运动；运动规划存在动力学差距，导致计划轨迹与实际执行轨迹偏差较大。

Method: 扩展运动流形原语支持变长轨迹，从大规模规划运动数据学习高质量流形，在潜在空间训练条件流匹配模型，结合少量真实世界试验数据生成考虑执行动力学的投掷轨迹。

Result: 在环抛任务中生成协调平滑的运动轨迹，真实世界评估达到高成功率并超越训练有素的人类专家，能泛化到训练范围之外的新目标。

Conclusion: DA-MMP成功学习了轨迹-动力学映射，为动态操作任务提供了有效的运动生成框架，具有实际应用价值和泛化能力。

Abstract: Dynamic manipulation is a key capability for advancing robot performance,
enabling skills such as tossing. While recent learning-based approaches have
pushed the field forward, most methods still rely on manually designed action
parameterizations, limiting their ability to produce the highly coordinated
motions required in complex tasks. Motion planning can generate feasible
trajectories, but the dynamics gap-stemming from control inaccuracies, contact
uncertainties, and aerodynamic effects-often causes large deviations between
planned and executed trajectories. In this work, we propose Dynamics-Aware
Motion Manifold Primitives (DA-MMP), a motion generation framework for
goal-conditioned dynamic manipulation, and instantiate it on a challenging
real-world ring-tossing task. Our approach extends motion manifold primitives
to variable-length trajectories through a compact parametrization and learns a
high-quality manifold from a large-scale dataset of planned motions. Building
on this manifold, a conditional flow matching model is trained in the latent
space with a small set of real-world trials, enabling the generation of
throwing trajectories that account for execution dynamics. Experiments show
that our method can generate coordinated and smooth motion trajectories for the
ring-tossing task. In real-world evaluations, it achieves high success rates
and even surpasses the performance of trained human experts. Moreover, it
generalizes to novel targets beyond the training range, indicating that it
successfully learns the underlying trajectory-dynamics mapping.

</details>


### [55] [LocoFormer: Generalist Locomotion via Long-context Adaptation](https://arxiv.org/abs/2509.23745)
*Min Liu,Deepak Pathak,Ananye Agarwal*

Main category: cs.RO

TL;DR: LocoFormer是一个通用的全身运动控制模型，能够控制未见过的腿式和轮式机器人，无需精确的运动学知识，并能适应形态和动力学的变化。


<details>
  <summary>Details</summary>
Motivation: 现有的运动控制器通常针对特定机器人手动调优，缺乏通用性。本文旨在开发一个能够适应不同机器人形态和动力学的通用运动控制模型。

Method: 采用大规模强化学习训练，在程序生成的机器人上进行训练，并应用激进的领域随机化。同时，将上下文长度扩展到跨越整个episode边界，以解决传统策略的短视问题。

Result: LocoFormer能够部署到各种机器人上，即使在面对重量变化和电机故障等大扰动时也能保持鲁棒控制。在极端场景下，模型表现出跨episode的适应性，能够从早期跌倒中学习并改进后续控制策略。

Conclusion: 这种简单而通用的方法可以用于训练其他机器人技能的基础模型，为通用机器人控制提供了有前景的解决方案。

Abstract: Modern locomotion controllers are manually tuned for specific embodiments. We
present LocoFormer, a generalist omni-bodied locomotion model that can control
previously unseen legged and wheeled robots, even without precise knowledge of
their kinematics. LocoFormer is able to adapt to changes in morphology and
dynamics at test time. We find that two key choices enable adaptation. First,
we train massive scale RL on procedurally generated robots with aggressive
domain randomization. Second, in contrast to previous policies that are myopic
with short context lengths, we extend context by orders of magnitude to span
episode boundaries. We deploy the same LocoFormer to varied robots and show
robust control even with large disturbances such as weight change and motor
failures. In extreme scenarios, we see emergent adaptation across episodes,
LocoFormer learns from falls in early episodes to improve control strategies in
later ones. We believe that this simple, yet general recipe can be used to
train foundation models for other robotic skills in the future. Videos at
generalist-locomotion.github.io.

</details>


### [56] [Sequence Pathfinder for Multi-Agent Pickup and Delivery in the Warehouse](https://arxiv.org/abs/2509.23778)
*Zeyuan Zhang,Chaoran Li,Shao Zhang,Ying Wen*

Main category: cs.RO

TL;DR: 本文提出Sequential Pathfinder (SePar)方法，将多智能体路径规划问题建模为序列建模问题，利用Transformer范式实现隐式信息交换，在保持全局感知的同时将决策复杂度从指数级降低到线性级。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在多智能体拾取和配送任务中，在狭窄通道和长走廊的仓库环境中表现不佳，主要依赖局部观测进行分布式决策。通信学习虽然能缓解全局信息缺乏问题，但点对点通信带来了高计算复杂度。

Method: 将MAPF问题建模为序列建模问题，证明路径规划策略在序列建模下具有顺序不变的最优性。提出SePar方法，利用Transformer范式实现隐式信息交换，结合模仿学习处理复杂地图。

Result: 实验表明SePar在各种MAPF任务及其变体上持续优于现有基于学习的方法，在未见过的环境中泛化能力良好。在复杂仓库地图中集成模仿学习是必要的。

Conclusion: SePar通过序列建模和Transformer范式有效解决了MAPD问题中的信息交换和决策复杂度问题，在保持效率的同时实现了全局感知，在复杂环境中表现出色。

Abstract: Multi-Agent Pickup and Delivery (MAPD) is a challenging extension of
Multi-Agent Path Finding (MAPF), where agents are required to sequentially
complete tasks with fixed-location pickup and delivery demands. Although
learning-based methods have made progress in MAPD, they often perform poorly in
warehouse-like environments with narrow pathways and long corridors when
relying only on local observations for distributed decision-making.
Communication learning can alleviate the lack of global information but
introduce high computational complexity due to point-to-point communication. To
address this challenge, we formulate MAPF as a sequence modeling problem and
prove that path-finding policies under sequence modeling possess
order-invariant optimality, ensuring its effectiveness in MAPD. Building on
this, we propose the Sequential Pathfinder (SePar), which leverages the
Transformer paradigm to achieve implicit information exchange, reducing
decision-making complexity from exponential to linear while maintaining
efficiency and global awareness. Experiments demonstrate that SePar
consistently outperforms existing learning-based methods across various MAPF
tasks and their variants, and generalizes well to unseen environments.
Furthermore, we highlight the necessity of integrating imitation learning in
complex maps like warehouses.

</details>


### [57] [High-Precision Climbing Robot Localization Using Planar Array UWB/GPS/IMU/Barometer Integration](https://arxiv.org/abs/2509.23801)
*Shuning Zhang,Renjing Xu,Zhanchen Zhu,Xiangyu Chen,Yunheng Wang,Xu Jiang,Peibo Duan*

Main category: cs.RO

TL;DR: 提出一种基于注意力机制的多传感器融合系统，用于复杂高空环境中攀爬机器人的高精度定位，融合UWB、GPS、IMU和气压计数据，通过端到端神经网络和UKF实现0.48米定位精度。


<details>
  <summary>Details</summary>
Motivation: 解决复杂高空环境中单传感器定位方法的局限性，应对GPS遮挡和UWB非视距问题，提高攀爬机器人的定位精度和鲁棒性。

Method: 设计注意力机制融合算法(AMFA)，集成平面阵列UWB、GPS、IMU和气压计；开发UWB和气压计的端到端神经网络推理模型；采用多模态注意力机制进行自适应数据融合；应用无迹卡尔曼滤波(UKF)优化轨迹。

Result: 实际实验显示该方法达到0.48米定位精度，最大误差1.50米，优于GPS/INS-EKF等基线算法，具有更强的鲁棒性。

Conclusion: 多传感器融合系统结合注意力机制和UKF能够有效提升复杂高空环境中攀爬机器人的定位性能，为类似应用提供了可行解决方案。

Abstract: To address the need for high-precision localization of climbing robots in
complex high-altitude environments, this paper proposes a multi-sensor fusion
system that overcomes the limitations of single-sensor approaches. Firstly, the
localization scenarios and the problem model are analyzed. An integrated
architecture of Attention Mechanism-based Fusion Algorithm (AMFA) incorporating
planar array Ultra-Wideband (UWB), GPS, Inertial Measurement Unit (IMU), and
barometer is designed to handle challenges such as GPS occlusion and UWB
Non-Line-of-Sight (NLOS) problem. Then, End-to-end neural network inference
models for UWB and barometer are developed, along with a multimodal attention
mechanism for adaptive data fusion. An Unscented Kalman Filter (UKF) is applied
to refine the trajectory, improving accuracy and robustness. Finally,
real-world experiments show that the method achieves 0.48 m localization
accuracy and lower MAX error of 1.50 m, outperforming baseline algorithms such
as GPS/INS-EKF and demonstrating stronger robustness.

</details>


### [58] [Fostering Robots: A Governance-First Conceptual Framework for Domestic, Curriculum-Based Trajectory Collection](https://arxiv.org/abs/2509.23821)
*Federico Pablo-Marti,Carlos Mir Fernandez*

Main category: cs.RO

TL;DR: 提出了Robot Fostering概念框架，这是以课程驱动、治理优先的家庭机器人部署方法，强调长期、精心策划的交互轨迹。


<details>
  <summary>Details</summary>
Motivation: 需要建立概念性和经验可测试的框架来指导家庭机器人的长期部署，确保交互质量符合治理标准。

Method: 形式化轨迹质量，使用可量化的指标和评估协议，与欧盟级治理标准对齐，制定低资源经验路线图。

Result: 提出了一个概念框架和评估协议，为未来试点研究提供严格验证的基础。

Conclusion: Robot Fostering框架为家庭机器人部署提供了治理优先、课程驱动的方法，支持长期交互轨迹的量化评估和验证。

Abstract: We propose a conceptual, empirically testable framework for Robot Fostering,
-a curriculum-driven, governance-first approach to domestic robot deployments,
emphasizing long-term, curated interaction trajectories. We formalize
trajectory quality with quantifiable metrics and evaluation protocols aligned
with EU-grade governance standards, delineating a low-resource empirical
roadmap to enable rigorous validation through future pilot studies.

</details>


### [59] [Control Your Robot: A Unified System for Robot Control and Policy Deployment](https://arxiv.org/abs/2509.23823)
*Tian Nian,Weijie Ke,Yao Mu,Tianxing Chen,Shaolong Zhu,Bingshan Hu*

Main category: cs.RO

TL;DR: Control Your Robot是一个模块化通用框架，通过标准化工作流程、统一API和闭环架构，解决了跨平台机器人控制中的数据格式和控制范式碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 跨平台机器人控制面临硬件接口、数据格式和控制范式差异大的挑战，导致工具链碎片化和部署缓慢。

Method: 采用模块化设计、统一API和闭环架构，支持灵活的机器人注册、遥操作和轨迹回放双模式控制，以及从多模态数据采集到推理的无缝集成。

Result: 在单臂和双臂系统上的实验显示，能够实现高效、低延迟的数据收集，并有效支持模仿学习和视觉-语言-动作模型的策略学习。

Conclusion: 基于该框架收集数据训练的策略与专家演示高度匹配，表明该框架能够实现跨平台的可扩展和可复现的机器人学习。

Abstract: Cross-platform robot control remains difficult because hardware interfaces,
data formats, and control paradigms vary widely, which fragments toolchains and
slows deployment. To address this, we present Control Your Robot, a modular,
general-purpose framework that unifies data collection and policy deployment
across diverse platforms. The system reduces fragmentation through a
standardized workflow with modular design, unified APIs, and a closed-loop
architecture. It supports flexible robot registration, dual-mode control with
teleoperation and trajectory playback, and seamless integration from multimodal
data acquisition to inference. Experiments on single-arm and dual-arm systems
show efficient, low-latency data collection and effective support for policy
learning with imitation learning and vision-language-action models. Policies
trained on data gathered by Control Your Robot match expert demonstrations
closely, indicating that the framework enables scalable and reproducible robot
learning across platforms.

</details>


### [60] [DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation](https://arxiv.org/abs/2509.23829)
*Kefei Zhu,Fengshuo Bai,YuanHao Xiang,Yishuai Cai,Xinglin Chen,Ruochong Li,Xingtao Wang,Hao Dong,Yaodong Yang,Xiaopeng Fan,Yuanpei Chen*

Main category: cs.RO

TL;DR: DexFlyWheel是一个可扩展的数据生成框架，通过自改进循环持续丰富数据多样性，解决了灵巧操作中高质量数据集稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 灵巧操作对提升机器人真实世界能力至关重要，但现有数据收集方法依赖人工遥控、需要大量人工工程或生成数据多样性有限，限制了可扩展性和泛化能力。

Method: 采用自改进循环框架：从种子演示开始，通过模仿学习提取人类行为，残差强化学习增强策略泛化，在仿真中生成轨迹，并进行跨环境和空间配置的数据增强，形成数据飞轮效应。

Result: 在四个挑战性任务中生成了2000多个多样化演示，训练的策略在挑战测试集上平均成功率达81.9%，通过数字孪生成功迁移到现实世界，在双臂举升任务中达到78.3%成功率。

Conclusion: DexFlyWheel框架能够有效生成多样化数据集，显著提升策略性能并成功实现从仿真到现实的迁移，为解决灵巧操作数据稀缺问题提供了可行方案。

Abstract: Dexterous manipulation is critical for advancing robot capabilities in
real-world applications, yet diverse and high-quality datasets remain scarce.
Existing data collection methods either rely on human teleoperation or require
significant human engineering, or generate data with limited diversity, which
restricts their scalability and generalization. In this paper, we introduce
DexFlyWheel, a scalable data generation framework that employs a self-improving
cycle to continuously enrich data diversity. Starting from efficient seed
demonstrations warmup, DexFlyWheel expands the dataset through iterative
cycles. Each cycle follows a closed-loop pipeline that integrates Imitation
Learning (IL), residual Reinforcement Learning (RL), rollout trajectory
collection, and data augmentation. Specifically, IL extracts human-like
behaviors from demonstrations, and residual RL enhances policy generalization.
The learned policy is then used to generate trajectories in simulation, which
are further augmented across diverse environments and spatial configurations
before being fed back into the next cycle. Over successive iterations, a
self-improving data flywheel effect emerges, producing datasets that cover
diverse scenarios and thereby scaling policy performance. Experimental results
demonstrate that DexFlyWheel generates over 2,000 diverse demonstrations across
four challenging tasks. Policies trained on our dataset achieve an average
success rate of 81.9\% on the challenge test sets and successfully transfer to
the real world through digital twin, achieving a 78.3\% success rate on
dual-arm lift tasks.

</details>


### [61] [MAD-PINN: A Decentralized Physics-Informed Machine Learning Framework for Safe and Optimal Multi-Agent Control](https://arxiv.org/abs/2509.23960)
*Manan Tayal,Aditya Singh,Shishir Kolathaya,Somil Bansal*

Main category: cs.RO

TL;DR: MAD-PINN是一个去中心化的物理信息机器学习框架，用于解决多智能体状态约束最优控制问题，在保证安全性的同时实现高性能。


<details>
  <summary>Details</summary>
Motivation: 大规模多智能体系统中同时优化安全性和性能是一个基本挑战。现有的MARL、安全过滤或MPC方法要么缺乏严格的安全保证，要么过于保守，要么无法有效扩展。

Method: 采用基于外延的SC-OCP重构来同时捕获性能和安全，通过物理信息神经网络近似解。通过训练简化智能体系统的SC-OCP值函数实现可扩展性，并以去中心化方式部署，每个智能体仅依赖邻居的局部观测进行决策。

Result: 在多智能体导航任务上的实验表明，MAD-PINN实现了优越的安全-性能权衡，随着智能体数量增加保持可扩展性，并持续优于最先进的基线方法。

Conclusion: MAD-PINN框架成功解决了大规模多智能体系统的安全性和性能协同优化问题，通过去中心化架构和物理信息学习实现了有效的安全保证和可扩展性。

Abstract: Co-optimizing safety and performance in large-scale multi-agent systems
remains a fundamental challenge. Existing approaches based on multi-agent
reinforcement learning (MARL), safety filtering, or Model Predictive Control
(MPC) either lack strict safety guarantees, suffer from conservatism, or fail
to scale effectively. We propose MAD-PINN, a decentralized physics-informed
machine learning framework for solving the multi-agent state-constrained
optimal control problem (MASC-OCP). Our method leverages an epigraph-based
reformulation of SC-OCP to simultaneously capture performance and safety, and
approximates its solution via a physics-informed neural network. Scalability is
achieved by training the SC-OCP value function on reduced-agent systems and
deploying them in a decentralized fashion, where each agent relies only on
local observations of its neighbours for decision-making. To further enhance
safety and efficiency, we introduce an Hamilton-Jacobi (HJ) reachability-based
neighbour selection strategy to prioritize safety-critical interactions, and a
receding-horizon policy execution scheme that adapts to dynamic interactions
while reducing computational burden. Experiments on multi-agent navigation
tasks demonstrate that MAD-PINN achieves superior safety-performance
trade-offs, maintains scalability as the number of agents grows, and
consistently outperforms state-of-the-art baselines.

</details>


### [62] [Prepare for Warp Speed: Sub-millisecond Visual Place Recognition Using Event Cameras](https://arxiv.org/abs/2509.24094)
*Vignesh Ramanathan,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: Flash是一个轻量级视觉位置识别系统，使用亚毫秒级事件数据片段进行位置预测，通过二进制帧编码活跃像素位置，显著提升了识别速度和准确率。


<details>
  <summary>Details</summary>
Motivation: 现有基于事件相机的VPR方法依赖密集表示且需要数十到数百毫秒的事件数据，Flash旨在突破这一范式，实现亚毫秒级的快速位置识别。

Method: 利用活跃像素位置作为强判别特征，通过高效的二进制帧进行编码，并使用快速位运算计算相似度，根据查询帧和参考帧的相对事件活动进行归一化。

Result: 在室内QCR-Event-Dataset上Recall@1提升了11.33倍，在8公里Brisbane-Event-VPR数据集上提升了5.92倍，显著减少了机器人无位置感知的运行时间。

Conclusion: 这是首个展示使用事件相机实现亚毫秒级VPR的工作，通过轻量级方法大幅提升了位置识别的速度和效率。

Abstract: Visual Place Recognition (VPR) enables systems to identify previously visited
locations within a map, a fundamental task for autonomous navigation. Prior
works have developed VPR solutions using event cameras, which asynchronously
measure per-pixel brightness changes with microsecond temporal resolution.
However, these approaches rely on dense representations of the inherently
sparse camera output and require tens to hundreds of milliseconds of event data
to predict a place. Here, we break this paradigm with Flash, a lightweight VPR
system that predicts places using sub-millisecond slices of event data. Our
method is based on the observation that active pixel locations provide strong
discriminative features for VPR. Flash encodes these active pixel locations
using efficient binary frames and computes similarities via fast bitwise
operations, which are then normalized based on the relative event activity in
the query and reference frames. Flash improves Recall@1 for sub-millisecond VPR
over existing baselines by 11.33x on the indoor QCR-Event-Dataset and 5.92x on
the 8 km Brisbane-Event-VPR dataset. Moreover, our approach reduces the
duration for which the robot must operate without awareness of its position, as
evidenced by a localization latency metric we term Time to Correct Match (TCM).
To the best of our knowledge, this is the first work to demonstrate
sub-millisecond VPR using event cameras.

</details>


### [63] [Ancestry Tree Clustering for Particle Filter Diversity Maintenance](https://arxiv.org/abs/2509.24124)
*Ilari Vallivaara,Bingnan Duan,Yinhuan Dong,Tughrul Arslan*

Main category: cs.RO

TL;DR: 提出了一种基于粒子祖先树拓扑结构的线性时间多样性维护方法，通过聚类相关粒子来防止多模态环境中的过早收敛。


<details>
  <summary>Details</summary>
Motivation: 在多模态环境中，粒子滤波器容易过早收敛到单一模式，需要有效的多样性维护机制来保持对多个可能状态的跟踪。

Method: 基于粒子祖先树的拓扑结构进行聚类，将密切相关的粒子分组，结合簇内适应度共享和未聚类粒子的保护机制。

Result: 在多模态机器人仿真和真实室内环境中验证，相比确定性重采样和粒子高斯混合等方法，实现了高成功率且对紧凑性影响很小。

Conclusion: 该方法在不同领域和挑战性初始条件下表现出强鲁棒性，能有效维持粒子多样性而不牺牲估计紧凑性。

Abstract: We propose a method for linear-time diversity maintenance in particle
filtering. It clusters particles based on ancestry tree topology: closely
related particles in sufficiently large subtrees are grouped together. The main
idea is that the tree structure implicitly encodes similarity without the need
for spatial or other domain-specific metrics. This approach, when combined with
intra-cluster fitness sharing and the protection of particles not included in a
cluster, effectively prevents premature convergence in multimodal environments
while maintaining estimate compactness. We validate our approach in a
multimodal robotics simulation and a real-world multimodal indoor environment.
We compare the performance to several diversity maintenance algorithms from the
literature, including Deterministic Resampling and Particle Gaussian Mixtures.
Our algorithm achieves high success rates with little to no negative effect on
compactness, showing particular robustness to different domains and challenging
initial conditions.

</details>


### [64] [BOSfM: A View Planning Framework for Optimal 3D Reconstruction of Agricultural Scenes](https://arxiv.org/abs/2509.24126)
*Athanasios Bacharis,Konstantinos D. Polyzos,Georgios B. Giannakis,Nikolaos Papanikolopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种基于贝叶斯优化的视图规划框架，用于在农业环境中优化相机放置位置，以使用更少的图像实现有效的3D重建，并具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 主动视觉在农业应用中很重要，但传统方法需要大量图像且处理困难。视图规划通过优化相机位置来捕获更少但信息量更大的图像，但面临相机位置噪声和泛化到未知环境的挑战。

Method: 采用基于重建质量的优化方法，利用运动恢复结构技术从选定图像重建3D环境。由于优化函数无解析表达式且评估成本高，使用贝叶斯优化方法高效执行视图规划过程。

Result: 在模拟和真实农业环境中的数值测试表明，该方法能有效估计最优相机放置位置，准确重建3D环境，并在类似未知环境中具有良好的泛化性能。

Conclusion: 提出的视图规划框架能够高效优化相机布局，使用少量图像实现准确的3D重建，并能很好地泛化到其他类似农业环境，无需重新优化或训练。

Abstract: Active vision (AV) has been in the spotlight of robotics research due to its
emergence in numerous applications including agricultural tasks such as
precision crop monitoring and autonomous harvesting to list a few. A major AV
problem that gained popularity is the 3D reconstruction of targeted
environments using 2D images from diverse viewpoints. While collecting and
processing a large number of arbitrarily captured 2D images can be arduous in
many practical scenarios, a more efficient solution involves optimizing the
placement of available cameras in 3D space to capture fewer, yet more
informative, images that provide sufficient visual information for effective
reconstruction of the environment of interest. This process termed as view
planning (VP), can be markedly challenged (i) by noise emerging in the location
of the cameras and/or in the extracted images, and (ii) by the need to
generalize well in other unknown similar agricultural environments without need
for re-optimizing or re-training. To cope with these challenges, the present
work presents a novel VP framework that considers a reconstruction
quality-based optimization formulation that relies on the notion of
`structure-from-motion' to reconstruct the 3D structure of the sought
environment from the selected 2D images. With no analytic expression of the
optimization function and with costly function evaluations, a Bayesian
optimization approach is proposed to efficiently carry out the VP process using
only a few function evaluations, while accounting for different noise cases.
Numerical tests on both simulated and real agricultural settings signify the
benefits of the advocated VP approach in efficiently estimating the optimal
camera placement to accurately reconstruct 3D environments of interest, and
generalize well on similar unknown environments.

</details>


### [65] [Mash, Spread, Slice! Learning to Manipulate Object States via Visual Spatial Progress](https://arxiv.org/abs/2509.24129)
*Priyanka Mandikal,Jiaheng Hu,Shivin Dass,Sagnik Majumder,Roberto Martín-Martín,Kristen Grauman*

Main category: cs.RO

TL;DR: SPARTA是一个统一的机器人操作框架，专门处理物体状态变化任务（如捣碎、涂抹、切片等），通过空间渐进式物体变化分割图来生成结构化策略观察和密集奖励。


<details>
  <summary>Details</summary>
Motivation: 大多数机器人操作关注物体运动状态变化，但现实世界中许多任务涉及物体物理和视觉状态的渐进变化，需要专门的处理方法。

Method: SPARTA整合空间渐进式物体变化分割图，将物体区域分为可操作和已转换状态，生成结构化策略观察和密集奖励，支持强化学习和贪心控制两种策略变体。

Result: 在真实机器人上验证了3个挑战性任务和10种不同物体，相比稀疏奖励和视觉目标条件基线，显著提升了训练时间和准确性。

Conclusion: 基于进度感知的视觉表示是物体状态操作任务家族的通用基础，SPARTA框架为这类任务提供了有效解决方案。

Abstract: Most robot manipulation focuses on changing the kinematic state of objects:
picking, placing, opening, or rotating them. However, a wide range of
real-world manipulation tasks involve a different class of object state
change--such as mashing, spreading, or slicing--where the object's physical and
visual state evolve progressively without necessarily changing its position. We
present SPARTA, the first unified framework for the family of object state
change manipulation tasks. Our key insight is that these tasks share a common
structural pattern: they involve spatially-progressing, object-centric changes
that can be represented as regions transitioning from an actionable to a
transformed state. Building on this insight, SPARTA integrates spatially
progressing object change segmentation maps, a visual skill to perceive
actionable vs. transformed regions for specific object state change tasks, to
generate a) structured policy observations that strip away appearance
variability, and b) dense rewards that capture incremental progress over time.
These are leveraged in two SPARTA policy variants: reinforcement learning for
fine-grained control without demonstrations or simulation; and greedy control
for fast, lightweight deployment. We validate SPARTA on a real robot for three
challenging tasks across 10 diverse real-world objects, achieving significant
improvements in training time and accuracy over sparse rewards and visual
goal-conditioned baselines. Our results highlight progress-aware visual
representations as a versatile foundation for the broader family of object
state manipulation tasks. Project website:
https://vision.cs.utexas.edu/projects/sparta-robot

</details>


### [66] [A Novel Model for 3D Motion Planning for a Generalized Dubins Vehicle with Pitch and Yaw Rate Constraints](https://arxiv.org/abs/2509.24143)
*Deepak Prakash Kumar,Swaroop Darbha,Satyanarayana Gupta Manyam,David Casbeer*

Main category: cs.RO

TL;DR: 提出了一种新的3D运动规划建模方法和快速算法，适用于固定翼无人机，考虑完整车辆方向（滚转、俯仰、偏航角）和双控制输入（俯仰率和偏航率），通过连接球面、柱面或平面上的最优Dubins路径来构建最短路径。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅考虑俯仰和/或航向角，不足以唯一确定方向，且大多依赖单一输入（如路径曲率），无法准确模拟3D中的车辆运动学。需要更完整的车辆方向描述和更准确的控制输入模型。

Method: 使用旋转最小化框架描述车辆配置及其演变，通过连接球面、柱面或平面上的最优Dubins路径来构建路径，考虑完整的车辆方向（滚转、俯仰、偏航角）和双控制输入（俯仰率和偏航率）。

Result: 数值模拟显示该方法平均在10秒内生成可行路径，在大多数情况下比现有方法产生更短的路径。

Conclusion: 所提出的方法能够有效处理固定翼无人机的3D运动规划问题，考虑完整的车辆方向和控制输入，生成更短且可行的路径。

Abstract: In this paper, we propose a new modeling approach and a fast algorithm for 3D
motion planning, applicable for fixed-wing unmanned aerial vehicles. The goal
is to construct the shortest path connecting given initial and final
configurations subject to motion constraints. Our work differs from existing
literature in two ways. First, we consider full vehicle orientation using a
body-attached frame, which includes roll, pitch, and yaw angles. However,
existing work uses only pitch and/or heading angle, which is insufficient to
uniquely determine orientation. Second, we use two control inputs to represent
bounded pitch and yaw rates, reflecting control by two separate actuators. In
contrast, most previous methods rely on a single input, such as path curvature,
which is insufficient for accurately modeling the vehicle's kinematics in 3D.
We use a rotation minimizing frame to describe the vehicle's configuration and
its evolution, and construct paths by concatenating optimal Dubins paths on
spherical, cylindrical, or planar surfaces. Numerical simulations show our
approach generates feasible paths within 10 seconds on average and yields
shorter paths than existing methods in most cases.

</details>


### [67] [Memory Transfer Planning: LLM-driven Context-Aware Code Adaptation for Robot Manipulation](https://arxiv.org/abs/2509.24160)
*Tomoyuki Kagaya,Subramanian Lakshmi,Yuxuan Lou,Thong Jing Yuan,Jayashree Karlekar,Sugiri Pranata,Natsuki Murakami,Akira Kinose,Yang You*

Main category: cs.RO

TL;DR: 提出了Memory Transfer Planning (MTP)框架，利用不同环境中的成功控制代码作为程序知识，通过检索和上下文适应实现跨环境的机器人操作规划。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在机器人操作中的方法难以适应新环境，需要环境特定的策略训练或依赖固定提示，导致可迁移性有限且需要手动调整。

Method: MTP框架：(i)使用LLM生成初始计划和代码；(ii)从代码记忆中检索相关成功示例；(iii)在目标设置中上下文适应检索的代码进行重新规划，无需更新模型参数。

Result: 在RLBench、CALVIN和物理机器人上的评估显示，MTP相比固定提示代码生成、简单检索和无记忆重新规划，持续提高了成功率和适应性。仿真构建的记忆在硬件实验中也被证明有效。

Conclusion: MTP提供了一种实用方法，利用程序知识实现跨多样化机器人操作场景的鲁棒LLM规划，增强了对新环境的适应性，并弥合了仿真和实际部署之间的差距。

Abstract: Large language models (LLMs) are increasingly explored in robot manipulation,
but many existing methods struggle to adapt to new environments. Many systems
require either environment-specific policy training or depend on fixed prompts
and single-shot code generation, leading to limited transferability and manual
re-tuning. We introduce Memory Transfer Planning (MTP), a framework that
leverages successful control-code examples from different environments as
procedural knowledge, using them as in-context guidance for LLM-driven
planning. Specifically, MTP (i) generates an initial plan and code using LLMs,
(ii) retrieves relevant successful examples from a code memory, and (iii)
contextually adapts the retrieved code to the target setting for re-planning
without updating model parameters. We evaluate MTP on RLBench, CALVIN, and a
physical robot, demonstrating effectiveness beyond simulation. Across these
settings, MTP consistently improved success rate and adaptability compared with
fixed-prompt code generation, naive retrieval, and memory-free re-planning.
Furthermore, in hardware experiments, leveraging a memory constructed in
simulation proved effective. MTP provides a practical approach that exploits
procedural knowledge to realize robust LLM-based planning across diverse
robotic manipulation scenarios, enhancing adaptability to novel environments
and bridging simulation and real-world deployment.

</details>


### [68] [Preference-Based Long-Horizon Robotic Stacking with Multimodal Large Language Models](https://arxiv.org/abs/2509.24163)
*Wanming Yu,Adrian Röfer,Abhinav Valada,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 该论文提出使用多模态大语言模型作为高级规划器来解决机器人长时程堆叠任务，通过创建考虑重量、稳定性等物理属性的定制数据集来微调模型，在仿真和真实人形机器人上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 预训练大语言模型在需要物理属性推理的长时程机器人操作任务中表现不足，特别是在涉及隐藏物体和物理特性（如重量、稳定性）的容器堆叠任务中。

Method: 使用多模态LLM作为高级规划器，为每个堆叠对象输入多模态信息，通过推理堆叠偏好来推断最佳堆叠序列。创建考虑重量、稳定性、尺寸和足迹的定制数据集来微调模型。

Result: 与仅使用提示调优的预训练LLM相比，使用定制数据集微调的LLM在堆叠完成度上有显著提升，在大规模仿真评估中表现更好，并在真实人形机器人上成功展示了长时程堆叠任务的有效性。

Conclusion: 多模态LLM通过定制数据集微调能够有效解决需要物理属性推理的长时程机器人堆叠任务，在仿真和真实机器人环境中都表现出色。

Abstract: Pretrained large language models (LLMs) can work as high-level robotic
planners by reasoning over abstract task descriptions and natural language
instructions, etc. However, they have shown a lack of knowledge and
effectiveness in planning long-horizon robotic manipulation tasks where the
physical properties of the objects are essential. An example is the stacking of
containers with hidden objects inside, which involves reasoning over hidden
physics properties such as weight and stability. To this end, this paper
proposes to use multimodal LLMs as high-level planners for such long-horizon
robotic stacking tasks. The LLM takes multimodal inputs for each object to
stack and infers the current best stacking sequence by reasoning over stacking
preferences. Furthermore, in order to enable the LLM to reason over multiple
preferences at the same time without giving explicit instructions, we propose
to create a custom dataset considering stacking preferences including weight,
stability, size, and footprint, to fine-tune the LLM. Compared to the
pretrained LLM with prompt tuning, we demonstrate the improved stacking
completion of the LLM fine-tuned with our custom dataset via large-scale
simulation evaluation. Furthermore, we showcase the effectiveness of the
proposed framework for the long-horizon stacking task on a real humanoid robot
in an online manner.

</details>


### [69] [Very High Frequency Interpolation for Direct Torque Control](https://arxiv.org/abs/2509.24175)
*Rafael Kourdis,Maciej Stępień,Jérôme Manhes,Nicolas Mansard,Steve Tonneau,Philippe Souères,Thomas Flayols*

Main category: cs.RO

TL;DR: 提出了一种在开源硬件上实现高达40kHz全身线性反馈的新方法，通过稳定扭矩控制器来解锁扭矩控制机器人的潜力


<details>
  <summary>Details</summary>
Motivation: 扭矩控制能够实现敏捷和鲁棒的机器人运动，但实际部署常因不稳定性和硬件限制而受阻

Method: 在开源硬件上执行高达40kHz的全身线性反馈，并在实际执行过程中插值非线性方案，如逆动力学和学习扭矩策略

Result: 通过稳定扭矩控制器，高频线性反馈成为解锁扭矩控制机器人潜力的有效途径

Conclusion: 高频线性反馈是解锁扭矩控制机器人潜力的有效方法

Abstract: Torque control enables agile and robust robot motion, but deployment is often
hindered by instability and hardware limits. Here, we present a novel solution
to execute whole-body linear feedback at up to 40 kHz on open-source hardware.
We use this to interpolate non-linear schemes during real-world execution, such
as inverse dynamics and learned torque policies. Our results show that by
stabilizing torque controllers, high-frequency linear feedback could be an
effective route towards unlocking the potential of torque-controlled robotics.

</details>


### [70] [ViReSkill: Vision-Grounded Replanning with Skill Memory for LLM-Based Planning in Lifelong Robot Learning](https://arxiv.org/abs/2509.24219)
*Tomoyuki Kagaya,Subramanian Lakshmi,Anbang Ye,Thong Jing Yuan,Jayashree Karlekar,Sugiri Pranata,Natsuki Murakami,Akira Kinose,Yang You*

Main category: cs.RO

TL;DR: ViReSkill框架结合视觉重规划和技能记忆，通过失败时重规划、成功时存储技能的方式实现自主持续学习，在仿真和真实机器人任务中优于传统基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs/VLMs在运动规划中的两个关键障碍：符号规划缺乏场景几何和物体物理的接地性，以及模型输出不一致影响执行可靠性。

Method: 提出ViReSkill框架，包含视觉接地重规划和技能记忆。失败时基于当前场景重规划动作序列，成功时将执行计划存储为可重用技能，后续遇到相同情况时直接回放而不调用LLMs/VLMs。

Result: 在LIBERO、RLBench等仿真器和真实机器人上评估，ViReSkill在任务成功率上持续优于传统基线方法，展示了鲁棒的仿真到真实泛化能力。

Conclusion: ViReSkill通过反馈循环实现自主持续学习，每次尝试都能扩展技能集并稳定后续执行，为机器人任务规划提供了有效的解决方案。

Abstract: Robots trained via Reinforcement Learning (RL) or Imitation Learning (IL)
often adapt slowly to new tasks, whereas recent Large Language Models (LLMs)
and Vision-Language Models (VLMs) promise knowledge-rich planning from minimal
data. Deploying LLMs/VLMs for motion planning, however, faces two key
obstacles: (i) symbolic plans are rarely grounded in scene geometry and object
physics, and (ii) model outputs can vary for identical prompts, undermining
execution reliability. We propose ViReSkill, a framework that pairs
vision-grounded replanning with a skill memory for accumulation and reuse. When
a failure occurs, the replanner generates a new action sequence conditioned on
the current scene, tailored to the observed state. On success, the executed
plan is stored as a reusable skill and replayed in future encounters without
additional calls to LLMs/VLMs. This feedback loop enables autonomous continual
learning: each attempt immediately expands the skill set and stabilizes
subsequent executions. We evaluate ViReSkill on simulators such as LIBERO and
RLBench as well as on a physical robot. Across all settings, it consistently
outperforms conventional baselines in task success rate, demonstrating robust
sim-to-real generalization.

</details>


### [71] [Towards Tighter Convex Relaxation of Mixed-integer Programs: Leveraging Logic Network Flow for Task and Motion Planning](https://arxiv.org/abs/2509.24235)
*Xuan Lin,Jiming Ren,Yandong Luo,Weijun Xie,Ye Zhao*

Main category: cs.RO

TL;DR: 提出基于优化的任务与运动规划框架"逻辑网络流"，将时序逻辑规范集成到混合整数规划中，通过网络流模型实现高效机器人规划


<details>
  <summary>Details</summary>
Motivation: 传统逻辑树方法在处理时序逻辑规范时存在约束复杂、松弛度不够紧的问题，需要更高效的规划方法

Method: 受凸集图启发，将时序谓词编码为网络流模型边上的多面体约束，提出基于网络流的傅里叶-莫茨金消元法，消除连续流变量同时保持凸松弛紧度

Result: 在车辆路径规划、多机器人协调、时序逻辑控制等实验中，计算速度提升数个数量级，四足机器人硬件验证了动态环境下的实时重规划能力

Conclusion: 逻辑网络流框架在时序逻辑运动规划中实现了显著的计算加速和更紧的凸松弛，为机器人实时规划提供了有效解决方案

Abstract: This paper proposes an optimization-based task and motion planning framework,
named "Logic Network Flow", that integrates temporal logic specifications into
mixed-integer programs for efficient robot planning. Inspired by the
Graph-of-Convex-Sets formulation, temporal predicates are encoded as polyhedron
constraints on each edge of a network flow model, instead of as constraints
between nodes in traditional Logic Tree formulations. We further propose a
network-flow-based Fourier-Motzkin elimination procedure that removes
continuous flow variables while preserving convex relaxation tightness, leading
to provably tighter convex relaxations and fewer constraints than Logic Tree
formulations. For temporal logic motion planning with piecewise-affine dynamic
systems, comprehensive experiments across vehicle routing, multi-robot
coordination, and temporal logic control on dynamical systems using point mass
and linear inverted pendulum models demonstrate computational speedups of up to
several orders of magnitude. Hardware demonstrations with quadrupedal robots
validate real-time replanning capabilities under dynamically changing
environmental conditions. The project website is at
https://logicnetworkflow.github.io/.

</details>


### [72] [PROFusion: Robust and Accurate Dense Reconstruction via Camera Pose Regression and Optimization](https://arxiv.org/abs/2509.24236)
*Siyan Dong,Zijun Wang,Lulu Cai,Yi Ma,Yanchao Yang*

Main category: cs.RO

TL;DR: 提出了一种结合学习式初始化和优化式精化的RGB-D SLAM方法，通过相机位姿回归网络预测相对位姿作为优化起点，在剧烈相机运动下实现实时密集场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D SLAM系统在相机经历大视角变化、快速运动或突然抖动时会失败。基于优化的方法精度高但对初始化敏感，基于学习的方法鲁棒性强但精度不足。

Method: 使用相机位姿回归网络从连续RGB-D帧预测度量感知的相对位姿，作为随机优化算法的可靠起点，进一步将深度图像与场景几何对齐。

Result: 在挑战性基准测试中优于最佳竞争对手，在稳定运动序列上保持相当精度，系统可实时运行。

Conclusion: 结合简单而原则性的技术可以在不稳定运动下实现鲁棒性，同时保持密集重建的精度。

Abstract: Real-time dense scene reconstruction during unstable camera motions is
crucial for robotics, yet current RGB-D SLAM systems fail when cameras
experience large viewpoint changes, fast motions, or sudden shaking. Classical
optimization-based methods deliver high accuracy but fail with poor
initialization during large motions, while learning-based approaches provide
robustness but lack sufficient accuracy for dense reconstruction. We address
this challenge through a combination of learning-based initialization with
optimization-based refinement. Our method employs a camera pose regression
network to predict metric-aware relative poses from consecutive RGB-D frames,
which serve as reliable starting points for a randomized optimization algorithm
that further aligns depth images with the scene geometry. Extensive experiments
demonstrate promising results: our approach outperforms the best competitor on
challenging benchmarks, while maintaining comparable accuracy on stable motion
sequences. The system operates in real-time, showcasing that combining simple
and principled techniques can achieve both robustness for unstable motions and
accuracy for dense reconstruction. Project page:
https://github.com/siyandong/PROFusion.

</details>


### [73] [SafeFlowMatcher: Safe and Fast Planning using Flow Matching with Control Barrier Functions](https://arxiv.org/abs/2509.24243)
*Jeongyong Yang,Seunghwan Jang,Soojean Han*

Main category: cs.RO

TL;DR: SafeFlowMatcher结合流匹配与控制屏障函数，通过预测-校正积分器实现实时高效且具备安全保证的路径规划。


<details>
  <summary>Details</summary>
Motivation: 基于流匹配的生成规划器虽然能快速生成高质量路径，但缺乏正式的安全保证，且在约束附近可能产生不完整路径。

Method: 采用两阶段预测-校正积分器：预测阶段通过流匹配生成候选路径，校正阶段使用时间缩放向量场和基于CBF的二次规划进行最小扰动修正。

Result: 在迷宫导航和运动基准测试中，SafeFlowMatcher比基于扩散和流匹配的基线方法获得更快、更平滑、更安全的路径。

Conclusion: SafeFlowMatcher通过仅在执行路径上强制安全约束，避免了分布漂移和局部陷阱问题，实现了高效且安全认证的路径规划。

Abstract: Generative planners based on flow matching (FM) can produce high-quality
paths in one or a few ODE steps, but their sampling dynamics offer no formal
safety guarantees and can yield incomplete paths near constraints. We present
SafeFlowMatcher, a planning framework that couples FM with control barrier
functions (CBFs) to achieve both real-time efficiency and certified safety.
SafeFlowMatcher uses a two-phase prediction-correction (PC) integrator: (i) a
prediction phase integrates the learned FM once (or a few steps) to obtain a
candidate path without intervention; (ii) a correction phase refines this path
with a vanishing time-scaled vector field and a CBF-based quadratic program
that minimally perturbs the vector field. We prove a barrier certificate for
the resulting flow system, establishing forward invariance of a robust safe set
and finite-time convergence to the safe set. By enforcing safety only on the
executed path (rather than on all intermediate latent paths), SafeFlowMatcher
avoids distributional drift and mitigates local trap problems. Across maze
navigation and locomotion benchmarks, SafeFlowMatcher attains faster, smoother,
and safer paths than diffusion- and FM-based baselines. Extensive ablations
corroborate the contributions of the PC integrator and the barrier certificate.

</details>


### [74] [Contextual Neural Moving Horizon Estimation for Robust Quadrotor Control in Varying Conditions](https://arxiv.org/abs/2509.24281)
*Kasra Torshizi,Chak Lam Shek,Khuzema Habib,Guangyao Shi,Pratap Tokekar,Troi Williams*

Main category: cs.RO

TL;DR: 提出Contextual NeuroMHE方法，使用贝叶斯优化和GP来选择数据收集的环境上下文，避免在所有环境中进行详尽训练，同时保持鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 四旋翼自适应控制器需要估计扰动以确保鲁棒轨迹跟踪，但现实世界环境多变且不确定，传统估计器需要针对特定场景进行大量调优，缺乏灵活性。

Method: 采用顺序决策策略，使用贝叶斯优化和高斯过程来选择数据收集的环境上下文，让神经网络动态调整参数。

Result: 在各种真实世界设置中的实验结果表明，该方法在最大绝对位置误差方面优于先前工作20.3%，仅需少量精心选择的上下文即可捕捉环境变化。

Conclusion: Contextual NeuroMHE方法消除了在所有环境中进行详尽训练的需求，同时在不同条件下保持鲁棒性能，提高了效率和泛化能力。

Abstract: Adaptive controllers on quadrotors typically rely on estimation of
disturbances to ensure robust trajectory tracking. Estimating disturbances
across diverse environmental contexts is challenging due to the inherent
variability and uncertainty in the real world. Such estimators require
extensive fine-tuning for a specific scenario, which makes them inflexible and
brittle to changing conditions. Machine-learning approaches, such as training a
neural network to tune the estimator's parameters, are promising. However,
collecting data across all possible environmental contexts is impossible. It is
also inefficient as the same estimator parameters could work for "nearby"
contexts. In this paper, we present a sequential decision making strategy that
decides which environmental contexts, using Bayesian Optimization with a
Gaussian Process, to collect data from in order to ensure robust performance
across a wide range of contexts. Our method, Contextual NeuroMHE, eliminates
the need for exhaustive training across all environments while maintaining
robust performance under different conditions. By enabling the neural network
to adapt its parameters dynamically, our method improves both efficiency and
generalization. Experimental results in various real-world settings demonstrate
that our approach outperforms the prior work by 20.3\% in terms of maximum
absolute position error and can capture the variations in the environment with
a few carefully chosen contexts.

</details>


### [75] [Learning to Sample: Reinforcement Learning-Guided Sampling for Autonomous Vehicle Motion Planning](https://arxiv.org/abs/2509.24313)
*Korbinian Moller,Roland Stroop,Mattia Piccinini,Alexander Langmann,Johannes Betz*

Main category: cs.RO

TL;DR: 提出了一种混合运动规划框架，结合强化学习指导采样过程，显著减少采样数量（99%）和运行时间（84%），同时保持规划质量。


<details>
  <summary>Details</summary>
Motivation: 解决基于采样的运动规划在复杂城市场景中，均匀或启发式采样产生大量不可行或不相关轨迹的问题。

Method: 使用强化学习代理指导采样过程，结合基于可解码深度集编码器的世界模型，保持轨迹生成和评估的分析性和可验证性。

Result: 在CommonRoad仿真环境中评估，采样数量减少99%，运行时间减少84%，同时保持规划成功率和无碰撞率。

Conclusion: 该方法实现了更快、更可靠的自动驾驶决策，在现实约束下实现更安全、响应更快的导航。

Abstract: Sampling-based motion planning is a well-established approach in autonomous
driving, valued for its modularity and analytical tractability. In complex
urban scenarios, however, uniform or heuristic sampling often produces many
infeasible or irrelevant trajectories. We address this limitation with a hybrid
framework that learns where to sample while keeping trajectory generation and
evaluation fully analytical and verifiable. A reinforcement learning (RL) agent
guides the sampling process toward regions of the action space likely to yield
feasible trajectories, while evaluation and final selection remains governed by
deterministic feasibility checks and cost functions. We couple the RL sampler
with a world model (WM) based on a decodable deep set encoder, enabling both
variable numbers of traffic participants and reconstructable latent
representations. The approach is evaluated in the CommonRoad simulation
environment, showing up to 99% fewer required samples and a runtime reduction
of up to 84% while maintaining planning quality in terms of success and
collision-free rates. These improvements lead to faster, more reliable
decision-making for autonomous vehicles in urban environments, achieving safer
and more responsive navigation under real-world constraints. Code and trained
artifacts are publicly available at:
https://github.com/TUM-AVS/Learning-to-Sample

</details>


### [76] [SONAR: Semantic-Object Navigation with Aggregated Reasoning through a Cross-Modal Inference Paradigm](https://arxiv.org/abs/2509.24321)
*Yao Wang,Zhirui Sun,Wenzheng Chi,Baozhi Jia,Wenjun Xu,Jiankun Wang*

Main category: cs.RO

TL;DR: 提出SONAR方法，通过跨模态范式集成语义地图目标预测和视觉语言模型价值地图，在未知环境中实现更鲁棒的视觉语言导航，平衡泛化能力和场景适应性。


<details>
  <summary>Details</summary>
Motivation: 现有模块化方法依赖训练数据质量且泛化能力差，而视觉语言模型方法在语义线索弱时表现不佳，需要解决这些限制。

Method: 集成语义地图目标预测模块和视觉语言模型价值地图模块，提出多尺度语义地图与置信度地图融合的目标定位策略。

Result: 在Gazebo模拟器中使用MP3D数据集测试，达到38.4%的成功率和17.7%的SPL。

Conclusion: SONAR方法能有效处理不同语义线索水平的未知环境导航，平衡了泛化能力和场景适应性。

Abstract: Understanding human instructions and accomplishing Vision-Language Navigation
tasks in unknown environments is essential for robots. However, existing
modular approaches heavily rely on the quality of training data and often
exhibit poor generalization. Vision-Language Model based methods, while
demonstrating strong generalization capabilities, tend to perform
unsatisfactorily when semantic cues are weak. To address these issues, this
paper proposes SONAR, an aggregated reasoning approach through a cross modal
paradigm. The proposed method integrates a semantic map based target prediction
module with a Vision-Language Model based value map module, enabling more
robust navigation in unknown environments with varying levels of semantic cues,
and effectively balancing generalization ability with scene adaptability. In
terms of target localization, we propose a strategy that integrates multi-scale
semantic maps with confidence maps, aiming to mitigate false detections of
target objects. We conducted an evaluation of the SONAR within the Gazebo
simulator, leveraging the most challenging Matterport 3D (MP3D) dataset as the
experimental benchmark. Experimental results demonstrate that SONAR achieves a
success rate of 38.4% and an SPL of 17.7%.

</details>


### [77] [AdaNav: Adaptive Reasoning with Uncertainty for Vision-Language Navigation](https://arxiv.org/abs/2509.24387)
*Xin Ding,Jianyu Wei,Yifan Yang,Shiqi Jiang,Qianxi Zhang,Hao Wu,Fucheng Jia,Liang Mi,Yuxuan Yan,Weijun Wang,Yunxin Liu,Zhibo Chen,Ting Cao*

Main category: cs.RO

TL;DR: AdaNav是一个基于不确定性的自适应推理框架，通过动态触发推理来提升视觉语言导航性能，仅用6K训练样本就显著超越了基于百万级数据训练的模型。


<details>
  <summary>Details</summary>
Motivation: 视觉语言导航需要代理根据自然语言指令在长序列视觉观察中进行导航。固定步长的推理往往导致次优性能和冗余计算，因此需要自适应推理机制来提升时间一致性和感知-动作对齐。

Method: 提出AdaNav框架，核心是不确定性自适应推理块(UAR)，这是一个轻量级插件，通过动作熵作为策略先验来动态触发推理。采用启发式到强化学习的训练方法逐步优化推理策略，使代理能在严格数据限制下学习难度感知的推理策略。

Result: 仅使用6K训练样本，AdaNav在R2R val-unseen上成功率提升20%，在RxR-CE上提升11.7%，在真实世界场景中提升11.4%，显著超越了基于百万级数据训练的闭源模型。

Conclusion: AdaNav通过不确定性驱动的自适应推理机制，在有限数据下实现了卓越的视觉语言导航性能，证明了自适应推理在具身任务中的有效性。

Abstract: Vision Language Navigation (VLN) requires agents to follow natural language
instructions by grounding them in sequential visual observations over long
horizons. Explicit reasoning could enhance temporal consistency and perception
action alignment, but reasoning at fixed steps often leads to suboptimal
performance and unnecessary computation. To address this, we propose AdaNav, an
uncertainty-based adaptive reasoning framework for VLN. At its core is the
Uncertainty Adaptive Reasoning Block (UAR), a lightweight plugin that
dynamically triggers reasoning. We introduce Action Entropy as a policy prior
for UAR and progressively refine it through a Heuristics to RL training method,
enabling agents to learn difficulty aware reasoning policies under the strict
data limitations of embodied tasks. Results show that with only 6K training
samples, AdaNav achieves substantial gains over closed source models trained on
million scale data, improving success rate by 20% on R2R val-unseen, 11.7% on
RxR-CE, and 11.4% in real world scenes. The code is available at
https://github.com/xinding-sys/AdaNav.

</details>


### [78] [DynaMIC: Dynamic Multimodal In-Context Learning Enabled Embodied Robot Counterfactual Resistance Ability](https://arxiv.org/abs/2509.24413)
*Tianqiang Yan,Ziqiao Lin,Sicheng Wang,Tianwei Zhang,Zhenglong Sun*

Main category: cs.RO

TL;DR: 该论文提出了DynaMIC框架，用于识别机器人任务中的误导性指令（DCFs）并主动向人类反馈，以提高机器人执行任务的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有研究将大型语言模型与机器人集成，通过自然语言指令控制机器人。但发现机器人严格遵循包含误导信息的指令时，可能导致执行错误和安全风险，这在机器人研究中尚未引起足够重视。

Method: 提出DynaMIC框架，生成机器人任务流程来识别指令反事实（DCFs），并主动向人类提供反馈。

Result: 进行了语义级实验和消融研究，证明了该框架的有效性。

Conclusion: 该框架能够帮助机器人对任务中潜在的误导性指令保持敏感，从而增强执行过程的可靠性。

Abstract: The emergence of large pre-trained models based on natural language has
breathed new life into robotics development. Extensive research has integrated
large models with robots, utilizing the powerful semantic understanding and
generation capabilities of large models to facilitate robot control through
natural language instructions gradually. However, we found that robots that
strictly adhere to human instructions, especially those containing misleading
information, may encounter errors during task execution, potentially leading to
safety hazards. This resembles the concept of counterfactuals in natural
language processing (NLP), which has not yet attracted much attention in
robotic research. In an effort to highlight this issue for future studies, this
paper introduced directive counterfactuals (DCFs) arising from misleading human
directives. We present DynaMIC, a framework for generating robot task flows to
identify DCFs and relay feedback to humans proactively. This capability can
help robots be sensitive to potential DCFs within a task, thus enhancing the
reliability of the execution process. We conducted semantic-level experiments
and ablation studies, showcasing the effectiveness of this framework.

</details>


### [79] [PhysiAgent: An Embodied Agent Framework in Physical World](https://arxiv.org/abs/2509.24524)
*Zhihao Wang,Jianxiong Li,Jinliang Zheng,Wencong Zhang,Dongxiu Liu,Yinan Zheng,Haoyi Niu,Junzhi Yu,Xianyuan Zhan*

Main category: cs.RO

TL;DR: 提出PhysiAgent框架，通过监控、记忆、自反思机制和轻量级工具箱，实现VLM和VLA的有效协作，在物理环境中显著提升任务解决性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型泛化能力有限，而将VLM作为助手集成到VLA中的方法通常采用僵化的顺序结构，导致协作效率低下和接地问题。

Method: PhysiAgent框架包含监控、记忆、自反思机制和轻量级工具箱，通过实时能力反馈让VLM组织不同组件，最大化利用VLA的能力。

Result: 实验结果显示在复杂真实世界机器人任务中任务解决性能显著提升，展示了VLM的有效自我调节、工具协作连贯性和框架在执行中的自适应演化。

Conclusion: PhysiAgent为集成VLM和VLA做出了实用且开创性的努力，有效将具身智能体框架接地到真实世界环境中。

Abstract: Vision-Language-Action (VLA) models have achieved notable success but often
struggle with limited generalizations. To address this, integrating generalized
Vision-Language Models (VLMs) as assistants to VLAs has emerged as a popular
solution. However, current approaches often combine these models in rigid,
sequential structures: using VLMs primarily for high-level scene understanding
and task planning, and VLAs merely as executors of lower-level actions, leading
to ineffective collaboration and poor grounding challenges. In this paper, we
propose an embodied agent framework, PhysiAgent, tailored to operate
effectively in physical environments. By incorporating monitor, memory,
self-reflection mechanisms, and lightweight off-the-shelf toolboxes, PhysiAgent
offers an autonomous scaffolding framework to prompt VLMs to organize different
components based on real-time proficiency feedback from VLAs to maximally
exploit VLAs' capabilities. Experimental results demonstrate significant
improvements in task-solving performance on complex real-world robotic tasks,
showcasing effective self-regulation of VLMs, coherent tool collaboration, and
adaptive evolution of the framework during execution. PhysiAgent makes
practical and pioneering efforts to integrate VLMs and VLAs, effectively
grounding embodied agent frameworks in real-world settings.

</details>


### [80] [Game Theory to Study Cooperation in Human-Robot Mixed Groups: Exploring the Potential of the Public Good Game](https://arxiv.org/abs/2509.24530)
*Giulia Pusceddu,Sara Mongile,Francesco Rea,Alessandra Sciutti*

Main category: cs.RO

TL;DR: 本研究使用公共物品游戏探索人类与机器人混合群体中的合作与信任，测试不同机器人策略对人类合作倾向的影响。


<details>
  <summary>Details</summary>
Motivation: 研究机器人如何在人机混合群体中促进信任和凝聚力，为开发能够培养信任与合作的社会机器人提供理论基础。

Method: 采用改良版公共物品游戏，让三名人类参与者与人形机器人iCub进行游戏，测试不同机器人策略（始终合作、始终搭便车、以牙还牙）对人类合作行为的影响。

Result: 初步分析显示，尽管参与者认为机器人慷慨，但多数人仍不愿向公共池投资。

Conclusion: 这项研究为理解机器人在人机混合群体中促进信任与合作的作用提供了有价值见解，具有开发社交机器人的潜力。

Abstract: In this study, we explore the potential of Game Theory as a means to
investigate cooperation and trust in human-robot mixed groups. Particularly, we
introduce the Public Good Game (PGG), a model highlighting the tension between
individual self-interest and collective well-being. In this work, we present a
modified version of the PGG, where three human participants engage in the game
with the humanoid robot iCub to assess whether various robot game strategies
(e.g., always cooperate, always free ride, and tit-for-tat) can influence the
participants' inclination to cooperate. We test our setup during a pilot study
with nineteen participants. A preliminary analysis indicates that participants
prefer not to invest their money in the common pool, despite they perceive the
robot as generous. By conducting this research, we seek to gain valuable
insights into the role that robots can play in promoting trust and cohesion
during human-robot interactions within group contexts. The results of this
study may hold considerable potential for developing social robots capable of
fostering trust and cooperation within mixed human-robot groups.

</details>


### [81] [Unlocking the Potential of Soft Actor-Critic for Imitation Learning](https://arxiv.org/abs/2509.24539)
*Nayari Marie Lessa,Melya Boukheddimi,Frank Kirchner*

Main category: cs.RO

TL;DR: 提出结合对抗运动先验(AMP)和离策略软演员-评论者(SAC)的新模仿学习框架，用于四足机器人步态学习，相比广泛使用的AMP+PPO方法在样本效率和策略泛化方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 当前基于PPO的模仿学习方法虽然稳定但样本效率低且策略泛化能力有限，需要开发更高效的框架来提升机器人运动生成的自然性和适应性。

Method: 将对抗运动先验(AMP)与离策略软演员-评论者(SAC)算法结合，利用回放驱动学习和熵正则化探索，实现自然行为学习和任务执行。

Result: 在涉及多种参考运动和不同地形的四足步态实验中，AMP+SAC方法不仅保持稳定任务执行，还获得了比AMP+PPO更高的模仿奖励。

Conclusion: 离策略模仿学习框架在机器人运动生成方面具有显著潜力，能够提高数据效率和鲁棒性。

Abstract: Learning-based methods have enabled robots to acquire bio-inspired movements
with increasing levels of naturalness and adaptability. Among these, Imitation
Learning (IL) has proven effective in transferring complex motion patterns from
animals to robotic systems. However, current state-of-the-art frameworks
predominantly rely on Proximal Policy Optimization (PPO), an on-policy
algorithm that prioritizes stability over sample efficiency and policy
generalization. This paper proposes a novel IL framework that combines
Adversarial Motion Priors (AMP) with the off-policy Soft Actor-Critic (SAC)
algorithm to overcome these limitations. This integration leverages
replay-driven learning and entropy-regularized exploration, enabling
naturalistic behavior and task execution, improving data efficiency and
robustness. We evaluate the proposed approach (AMP+SAC) on quadruped gaits
involving multiple reference motions and diverse terrains. Experimental results
demonstrate that the proposed framework not only maintains stable task
execution but also achieves higher imitation rewards compared to the widely
used AMP+PPO method. These findings highlight the potential of an off-policy IL
formulation for advancing motion generation in robotics.

</details>


### [82] [Prompting Robot Teams with Natural Language](https://arxiv.org/abs/2509.24575)
*Nicolas Pfitzer,Eduardo Sebastián,Ajay Shankar,Amanda Prorok*

Main category: cs.RO

TL;DR: 提出一个使用自然语言表达来提示多机器人团队执行高级任务的框架，将语言模型的推理能力用于多机器人协作和决策制定。


<details>
  <summary>Details</summary>
Motivation: 利用最近语言模型在理解和分解人类意图表达方面展示的推理能力，将其重新用于多机器人协作和决策制定。关键挑战在于集体中个体行为难以指定和解释，必须持续适应其他机器人的行动。

Method: 将任务表示为确定性有限自动机(DFA)，使用循环神经网络(RNN)编码多个自动机，将语言模型获得的逻辑和子任务顺序分解提炼到RNN中，并训练基于RNN隐藏状态和语言嵌入的图神经网络(GNN)控制策略。

Result: 在需要团队顺序和协作行为的各种模拟和真实世界多机器人任务中评估了这个轻量级可解释模型。

Conclusion: 该方法使机器人能够以分散方式执行与任务相关的行动，解决了多机器人系统中个体行为规范与实时分散操作之间的平衡问题。

Abstract: This paper presents a framework towards prompting multi-robot teams with
high-level tasks using natural language expressions. Our objective is to use
the reasoning capabilities demonstrated by recent language models in
understanding and decomposing human expressions of intent, and repurpose these
for multi-robot collaboration and decision-making. The key challenge is that an
individual's behavior in a collective can be hard to specify and interpret, and
must continuously adapt to actions from others. This necessitates a framework
that possesses the representational capacity required by the logic and
semantics of a task, and yet supports decentralized and interactive real-time
operation. We solve this dilemma by recognizing that a task can be represented
as a deterministic finite automaton (DFA), and that recurrent neural networks
(RNNs) can encode numerous automata. This allows us to distill the logic and
sequential decompositions of sub-tasks obtained from a language model into an
RNN, and align its internal states with the semantics of a given task. By
training a graph neural network (GNN) control policy that is conditioned on the
hidden states of the RNN and the language embeddings, our method enables robots
to execute task-relevant actions in a decentralized manner. We present
evaluations of this single light-weight interpretable model on various
simulated and real-world multi-robot tasks that require sequential and
collaborative behavior by the team -- sites.google.com/view/prompting-teams.

</details>


### [83] [U-DiT Policy: U-shaped Diffusion Transformers for Robotic Manipulation](https://arxiv.org/abs/2509.24579)
*Linzhi Wu,Aoran Mei,Xiyue Wang,Guo-Niu Zhu,Zhongxue Gan*

Main category: cs.RO

TL;DR: 提出U-DiT Policy，一种U形扩散Transformer框架，结合U-Net的多尺度特征融合优势和Transformer的全局上下文建模能力，在机器人操作任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的机器人控制方法主要采用U-Net架构（DP-U），存在全局上下文建模能力有限和过度平滑伪影的问题，需要改进。

Method: 设计U形扩散Transformer框架，保留U-Net的多尺度特征融合优势，同时集成Transformer的全局上下文建模能力，增强表示能力和策略表达能力。

Result: 在仿真中平均性能提升10%，比使用AdaLN块的Transformer扩散策略（DP-T）高6%；在真实机器人任务中平均提升22.5%，在干扰和光照变化下表现出更好的鲁棒性和泛化能力。

Conclusion: U-DiT Policy作为基于扩散的机器人操作的新基础，展现了有效性和实际潜力。

Abstract: Diffusion-based methods have been acknowledged as a powerful paradigm for
end-to-end visuomotor control in robotics. Most existing approaches adopt a
Diffusion Policy in U-Net architecture (DP-U), which, while effective, suffers
from limited global context modeling and over-smoothing artifacts. To address
these issues, we propose U-DiT Policy, a novel U-shaped Diffusion Transformer
framework. U-DiT preserves the multi-scale feature fusion advantages of U-Net
while integrating the global context modeling capability of Transformers,
thereby enhancing representational power and policy expressiveness. We evaluate
U-DiT extensively across both simulation and real-world robotic manipulation
tasks. In simulation, U-DiT achieves an average performance gain of 10\% over
baseline methods and surpasses Transformer-based diffusion policies (DP-T) that
use AdaLN blocks by 6\% under comparable parameter budgets. On real-world
robotic tasks, U-DiT demonstrates superior generalization and robustness,
achieving an average improvement of 22.5\% over DP-U. In addition, robustness
and generalization experiments under distractor and lighting variations further
highlight the advantages of U-DiT. These results highlight the effectiveness
and practical potential of U-DiT Policy as a new foundation for diffusion-based
robotic manipulation.

</details>


### [84] [PoseDiff: A Unified Diffusion Model Bridging Robot Pose Estimation and Video-to-Action Control](https://arxiv.org/abs/2509.24591)
*Haozhuo Zhang,Michele Caprio,Jing Shao,Qiang Zhang,Jian Tang,Shanghang Zhang,Wei Pan*

Main category: cs.RO

TL;DR: PoseDiff是一个统一的扩散模型框架，将机器人状态估计和控制整合在一起，通过单张RGB图像估计机器人状态，并扩展到视频到动作的逆动力学任务。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人系统通常采用多阶段流水线，需要辅助模态，缺乏感知与控制的统一高效整合。

Method: 使用条件扩散模型，从单张RGB图像映射到结构化机器人状态（3D关键点或关节角度），并基于世界模型生成的关键帧通过重叠平均策略产生平滑的长时程动作序列。

Result: 在DREAM数据集上达到最先进的姿态估计精度和实时性能；在Libero-Object操作任务中显著提升成功率，即使在严格离线设置下。

Conclusion: PoseDiff为具身AI中的感知、规划和控制提供了一个可扩展、准确且高效的桥梁。

Abstract: We present PoseDiff, a conditional diffusion model that unifies robot state
estimation and control within a single framework. At its core, PoseDiff maps
raw visual observations into structured robot states-such as 3D keypoints or
joint angles-from a single RGB image, eliminating the need for multi-stage
pipelines or auxiliary modalities. Building upon this foundation, PoseDiff
extends naturally to video-to-action inverse dynamics: by conditioning on
sparse video keyframes generated by world models, it produces smooth and
continuous long-horizon action sequences through an overlap-averaging strategy.
This unified design enables scalable and efficient integration of perception
and control. On the DREAM dataset, PoseDiff achieves state-of-the-art accuracy
and real-time performance for pose estimation. On Libero-Object manipulation
tasks, it substantially improves success rates over existing inverse dynamics
modules, even under strict offline settings. Together, these results show that
PoseDiff provides a scalable, accurate, and efficient bridge between
perception, planning, and control in embodied AI. The video visualization
results can be found on the project page:
https://haozhuo-zhang.github.io/PoseDiff-project-page/.

</details>


### [85] [CEDex: Cross-Embodiment Dexterous Grasp Generation at Scale from Human-like Contact Representations](https://arxiv.org/abs/2509.24661)
*Zhiyuan Wu,Rolandos Alexandros Potamias,Xuyang Zhang,Zhongqun Zhang,Jiankang Deng,Shan Luo*

Main category: cs.RO

TL;DR: 提出CEDex方法，通过将机器人运动学模型与生成的人类接触表示对齐，实现跨形态灵巧抓取合成，构建了包含500K物体和2000万抓取的最大跨形态抓取数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖缺乏人类运动学理解的物理优化，要么需要局限于拟人结构的手动数据收集过程，难以实现跨形态的灵巧抓取合成。

Method: 使用在人类接触数据上预训练的条件变分自编码器生成人类接触表示，通过拓扑合并进行运动学对齐，然后进行基于符号距离场的物理感知抓取优化。

Result: 构建了包含500K物体、四种夹爪类型、总计2000万抓取的最大跨形态抓取数据集，实验表明CEDex优于现有方法且数据集能促进跨形态抓取学习。

Conclusion: CEDex通过桥接人类抓取运动学和机器人运动学，实现了高质量的跨形态灵巧抓取合成，为多样化机器人操作提供了有效解决方案。

Abstract: Cross-embodiment dexterous grasp synthesis refers to adaptively generating
and optimizing grasps for various robotic hands with different morphologies.
This capability is crucial for achieving versatile robotic manipulation in
diverse environments and requires substantial amounts of reliable and diverse
grasp data for effective model training and robust generalization. However,
existing approaches either rely on physics-based optimization that lacks
human-like kinematic understanding or require extensive manual data collection
processes that are limited to anthropomorphic structures. In this paper, we
propose CEDex, a novel cross-embodiment dexterous grasp synthesis method at
scale that bridges human grasping kinematics and robot kinematics by aligning
robot kinematic models with generated human-like contact representations. Given
an object's point cloud and an arbitrary robotic hand model, CEDex first
generates human-like contact representations using a Conditional Variational
Auto-encoder pretrained on human contact data. It then performs kinematic human
contact alignment through topological merging to consolidate multiple human
hand parts into unified robot components, followed by a signed distance
field-based grasp optimization with physics-aware constraints. Using CEDex, we
construct the largest cross-embodiment grasp dataset to date, comprising 500K
objects across four gripper types with 20M total grasps. Extensive experiments
show that CEDex outperforms state-of-the-art approaches and our dataset
benefits cross-embodiment grasp learning with high-quality diverse grasps.

</details>


### [86] [Stabilizing Humanoid Robot Trajectory Generation via Physics-Informed Learning and Control-Informed Steering](https://arxiv.org/abs/2509.24697)
*Evelyn D'Elia,Paolo Maria Viceconte,Lorenzo Rapetti,Diego Ferigo,Giulio Romualdi,Giuseppe L'Erario,Raffaello Camoriano,Daniele Pucci*

Main category: cs.RO

TL;DR: 提出一种结合物理先验和比例积分控制的双重学习策略，用于改进人形机器人的运动生成，提高轨迹的物理可行性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的模仿学习方法虽然能生成平滑的人体运动轨迹，但受限于数据量且缺乏物理规律知识，可能导致轨迹发散和滑动接触问题，影响实际稳定性。

Method: 1. 在监督模仿学习中编码物理先验以促进轨迹可行性；2. 在推理时对生成的状态输出应用比例积分控制器以最小化漂移；3. 在ergoCub人形机器人上验证，使用物理信息损失鼓励零接触脚速度。

Result: 实验证明该方法与多种控制器兼容，显著提高了生成轨迹的准确性和物理约束符合度。

Conclusion: 提出的双重学习策略有效解决了人形机器人运动生成中的物理约束问题，提高了实际应用的稳定性。

Abstract: Recent trends in humanoid robot control have successfully employed imitation
learning to enable the learned generation of smooth, human-like trajectories
from human data. While these approaches make more realistic motions possible,
they are limited by the amount of available motion data, and do not incorporate
prior knowledge about the physical laws governing the system and its
interactions with the environment. Thus they may violate such laws, leading to
divergent trajectories and sliding contacts which limit real-world stability.
We address such limitations via a two-pronged learning strategy which leverages
the known physics of the system and fundamental control principles. First, we
encode physics priors during supervised imitation learning to promote
trajectory feasibility. Second, we minimize drift at inference time by applying
a proportional-integral controller directly to the generated output state. We
validate our method on various locomotion behaviors for the ergoCub humanoid
robot, where a physics-informed loss encourages zero contact foot velocity. Our
experiments demonstrate that the proposed approach is compatible with multiple
controllers on a real robot and significantly improves the accuracy and
physical constraint conformity of generated trajectories.

</details>


### [87] [LLM-Handover:Exploiting LLMs for Task-Oriented Robot-Human Handovers](https://arxiv.org/abs/2509.24706)
*Andreea Tulbure,Rene Zurbruegg,Timm Grigat,Marco Hutter*

Main category: cs.RO

TL;DR: LLM-Handover是一个集成大型语言模型推理和部件分割的框架，用于实现上下文感知的机器人抓取选择和执行，优化人机协作中的物体传递效果。


<details>
  <summary>Details</summary>
Motivation: 现有的人机协作物体传递方法往往忽视人类接收后的动作，依赖限制泛化能力的假设，需要更智能的上下文感知解决方案。

Method: 结合LLM推理和部件分割，通过RGB-D图像和任务描述推断相关物体部件，选择优化接收后可用性的抓取方式。

Result: 在零样本设置下实现83%的成功率，用户研究中86%的参与者偏好该方法，证明其能实现更直观、上下文感知的物体传递。

Conclusion: LLM-Handover框架显著提升了人机协作中物体传递的性能和用户体验，为上下文感知的机器人操作提供了有效解决方案。

Abstract: Effective human-robot collaboration depends on task-oriented handovers, where
robots present objects in ways that support the partners intended use. However,
many existing approaches neglect the humans post-handover action, relying on
assumptions that limit generalizability. To address this gap, we propose
LLM-Handover, a novel framework that integrates large language model
(LLM)-based reasoning with part segmentation to enable context-aware grasp
selection and execution. Given an RGB-D image and a task description, our
system infers relevant object parts and selects grasps that optimize
post-handover usability. To support evaluation, we introduce a new dataset of
60 household objects spanning 12 categories, each annotated with detailed part
labels. We first demonstrate that our approach improves the performance of the
used state-of-the-art part segmentation method, in the context of robot-human
handovers. Next, we show that LLM-Handover achieves higher grasp success rates
and adapts better to post-handover task constraints. During hardware
experiments, we achieve a success rate of 83% in a zero-shot setting over
conventional and unconventional post-handover tasks. Finally, our user study
underlines that our method enables more intuitive, context-aware handovers,
with participants preferring it in 86% of cases.

</details>


### [88] [APREBot: Active Perception System for Reflexive Evasion Robot](https://arxiv.org/abs/2509.24733)
*Zihao Xu,Kuankuan Sima,Junhao Deng,Zixuan Zhuang,Chunzheng Wang,Ce Hao,Jin Song Dong*

Main category: cs.RO

TL;DR: APREBot是一个用于四足机器人的主动感知系统，结合了LiDAR的全向扫描和相机的主动聚焦，实现了动态环境中的敏捷避障。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在动态环境中需要可靠的感知能力，单传感器系统存在局限性：LiDAR缺乏纹理信息，相机视野受限。

Method: 集成反射式规避与主动分层感知，战略性地结合LiDAR全向扫描和相机主动聚焦。

Result: 通过广泛的仿真到真实实验验证，在安全指标和操作效率上相比现有基准方法有显著提升。

Conclusion: APREBot在安全关键场景中具有可靠的自主性潜力。

Abstract: Reliable onboard perception is critical for quadruped robots navigating
dynamic environments, where obstacles can emerge from any direction under
strict reaction-time constraints. Single-sensor systems face inherent
limitations: LiDAR provides omnidirectional coverage but lacks rich texture
information, while cameras capture high-resolution detail but suffer from
restricted field of view. We introduce APREBot (Active Perception System for
Reflexive Evasion Robot), a novel framework that integrates reflexive evasion
with active hierarchical perception. APREBot strategically combines LiDAR-based
omnidirectional scanning with camera-based active focusing, achieving
comprehensive environmental awareness essential for agile obstacle avoidance in
quadruped robots. We validate APREBot through extensive sim-to-real experiments
on a quadruped platform, evaluating diverse obstacle types, trajectories, and
approach directions. Our results demonstrate substantial improvements over
state-of-the-art baselines in both safety metrics and operational efficiency,
highlighting APREBot's potential for dependable autonomy in safety-critical
scenarios. Videos are available at https://sites.google.com/view/aprebot/

</details>


### [89] [SSR-ZSON: Zero-Shot Object Navigation via Spatial-Semantic Relations within a Hierarchical Exploration Framework](https://arxiv.org/abs/2509.24763)
*Xiangyi Meng,Delun Li,Zihao Mao,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: SSR-ZSON是一种基于TARE分层探索框架的空间语义相对零样本目标导航方法，通过平衡空间覆盖和语义密度的视点生成策略与基于LLM的全局引导机制，解决了零样本目标导航中的语义引导不足和空间记忆限制问题。


<details>
  <summary>Details</summary>
Motivation: 零样本目标导航面临两个主要挑战：语义引导不足导致探索效率低下，以及环境结构造成的空间记忆限制导致局部区域被困。

Method: 提出SSR-ZSON方法，包含两个关键创新：1）视点生成策略优先考虑可遍历子区域内的高语义密度区域；2）基于LLM的全局引导机制评估语义关联以引导导航。

Result: 在Matterport3D和Habitat-Matterport3D数据集上，相比最先进方法，成功率分别提高18.5%和11.2%，路径长度加权成功率分别提高0.181和0.140。

Conclusion: SSR-ZSON实现了实时操作和优越性能，通过平衡空间覆盖和语义密度的策略有效解决了零样本目标导航的关键挑战。

Abstract: Zero-shot object navigation in unknown environments presents significant
challenges, mainly due to two key limitations: insufficient semantic guidance
leads to inefficient exploration, while limited spatial memory resulting from
environmental structure causes entrapment in local regions. To address these
issues, we propose SSR-ZSON, a spatial-semantic relative zero-shot object
navigation method based on the TARE hierarchical exploration framework,
integrating a viewpoint generation strategy balancing spatial coverage and
semantic density with an LLM-based global guidance mechanism. The performance
improvement of the proposed method is due to two key innovations. First, the
viewpoint generation strategy prioritizes areas of high semantic density within
traversable sub-regions to maximize spatial coverage and minimize invalid
exploration. Second, coupled with an LLM-based global guidance mechanism, it
assesses semantic associations to direct navigation toward high-value spaces,
preventing local entrapment and ensuring efficient exploration. Deployed on
hybrid Habitat-Gazebo simulations and physical platforms, SSR-ZSON achieves
real-time operation and superior performance. On Matterport3D and
Habitat-Matterport3D datasets, it improves the Success Rate(SR) by 18.5\% and
11.2\%, and the Success weighted by Path Length(SPL) by 0.181 and 0.140,
respectively, over state-of-the-art methods.

</details>


### [90] [IA-VLA: Input Augmentation for Vision-Language-Action models in settings with semantically complex tasks](https://arxiv.org/abs/2509.24768)
*Eric Hannus,Miika Malin,Tran Nguyen Le,Ville Kyrki*

Main category: cs.RO

TL;DR: IA-VLA框架利用大型视觉语言模型的强大语言理解能力作为预处理阶段，为视觉语言动作模型(VLA)生成改进的上下文输入，以处理涉及视觉重复对象的复杂语言指令任务。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言动作模型(VLA)由于需要输出适合机器人控制频率的动作，限制了其语言模型的规模，从而影响了处理复杂语言指令的能力，特别是需要根据相对位置识别目标对象的任务。

Method: 提出IA-VLA框架，使用大型视觉语言模型作为预处理阶段，生成增强的上下文信息来补充VLA的输入，专门针对涉及视觉重复对象的复杂语义任务。

Result: 在包含重复对象的三种场景数据集上的实验表明，增强后的VLA性能显著提升，特别是在需要从演示中概念外推的语言指令任务上表现更好。

Conclusion: IA-VLA框架通过利用大型视觉语言模型的强大语言理解能力，有效提升了VLA处理复杂语义任务的能力，特别是在面对视觉重复对象和需要概念外推的指令时。

Abstract: Vision-language-action models (VLAs) have become an increasingly popular
approach for addressing robot manipulation problems in recent years. However,
such models need to output actions at a rate suitable for robot control, which
limits the size of the language model they can be based on, and consequently,
their language understanding capabilities. Manipulation tasks may require
complex language instructions, such as identifying target objects by their
relative positions, to specify human intention. Therefore, we introduce IA-VLA,
a framework that utilizes the extensive language understanding of a large
vision language model as a pre-processing stage to generate improved context to
augment the input of a VLA. We evaluate the framework on a set of semantically
complex tasks which have been underexplored in VLA literature, namely tasks
involving visual duplicates, i.e., visually indistinguishable objects. A
dataset of three types of scenes with duplicate objects is used to compare a
baseline VLA against two augmented variants. The experiments show that the VLA
benefits from the augmentation scheme, especially when faced with language
instructions that require the VLA to extrapolate from concepts it has seen in
the demonstrations. For the code, dataset, and videos, see
https://sites.google.com/view/ia-vla.

</details>


### [91] [Fidelity-Aware Data Composition for Robust Robot Generalization](https://arxiv.org/abs/2509.24797)
*Zizhao Tong,Di Chen,Sicheng Hu,Hongwei Fan,Liliang Chen,Guanghui Ren,Hao Tang,Hao Dong,Ling Shao*

Main category: cs.RO

TL;DR: 提出CIFT框架，通过保真度感知的数据组合优化来解决机器人策略在分布外泛化中的挑战，显著提升OOD成功率


<details>
  <summary>Details</summary>
Motivation: 大规模训练的通才机器人策略容易受到捷径学习影响，导致分布外泛化能力下降。传统生成数据增强方法虽然引入多样性，但可能损害信息保真度。

Method: 提出CIFT框架，将数据组合视为优化问题，使用特征空间几何作为信息保真度代理，识别训练稳定性恶化的退相干点，并开发MVAug生成因果解缠的数据谱。

Result: 在π₀和Diffusion Policy等策略架构上应用CIFT，OOD成功率提升超过54%

Conclusion: 保真度感知的数据组合（而不仅仅是数据合成）是开发鲁棒通用机器人的重要组成部分

Abstract: Generalist robot policies trained on large-scale, visually homogeneous
datasets can be susceptible to shortcut learning, which impairs their
out-of-distribution (OOD) generalization. While generative data augmentation is
a common approach to introduce diversity, it presents a subtle challenge: data
composition. Naively mixing real and synthetic data can corrupt the learning
signal, as this process often prioritizes visual diversity at the expense of
information fidelity. This paper suggests that robust generalization depends on
principled, fidelity-aware data composition. We introduce Coherent Information
Fidelity Tuning (CIFT), a framework that treats data composition as an
optimization problem. CIFT uses a practical proxy for Information Fidelity
based on the feature-space geometry of a dataset. This enables the
identification of a phase transition, termed the Decoherence Point, where
training stability degrades. The framework includes a generative engine,
Multi-View Video Augmentation (MVAug), to synthesize a causally disentangled
data spectrum for this tuning process. Applying CIFT to policy architectures
such as $\pi_0$ and Diffusion Policy improves OOD success rates by over 54\%.
These results indicate that fidelity-aware composition, beyond data synthesis
alone, is an important component for developing robust, general-purpose robots.

</details>


### [92] [Towards Modular and Accessible AUV Systems](https://arxiv.org/abs/2509.24864)
*Mingxi Zhou,Farhang Naderi,Yuewei Fu,Tony Jacob,Lin Zhao,Manavi Panjnani,Chengzhi Yuan,William McConnell,Emir Cem Gezer*

Main category: cs.RO

TL;DR: 开发了名为Marine Vehicle Packages (MVP)的新型开源模块化框架，用于自主水下航行器，包含软硬件设计，支持快速构建可定制的研究用AUV。


<details>
  <summary>Details</summary>
Motivation: 为研究目的提供易于构建、高度可定制且具有足够有效载荷能力的自主水下航行器框架。

Method: 采用可扩展的硬件系统设计和模块化软件架构，集成铰接推进器和高层图形用户界面等新特性。

Result: 通过仿真和现场实验验证了MVP的性能和兼容性。

Conclusion: MVP框架成功实现了自主水下航行器的模块化、可定制化设计，为研究应用提供了有效的解决方案。

Abstract: This paper reports the development of a new open-access modular framework,
called Marine Vehicle Packages (MVP), for Autonomous Underwater Vehicles. The
framework consists of both software and hardware designs allowing easy
construction of AUV for research with increased customizability and sufficient
payload capacity. This paper will present the scalable hardware system design
and the modular software design architecture. New features, such as articulated
thruster integration and high-level Graphic User Interface will be discussed.
Both simulation and field experiments results are shown to highlight the
performance and compatibility of the MVP.

</details>


### [93] [Finding an Initial Probe Pose in Teleoperated Robotic Echocardiography via 2D LiDAR-Based 3D Reconstruction](https://arxiv.org/abs/2509.24867)
*Mariadas Capsran Roshan,Edgar M Hidalgo,Mats Isaksson,Michelle Dunn,Jagannatha Charjee Pyaraka*

Main category: cs.RO

TL;DR: 提出了一种基于机器人安装2D LiDAR的方法，用于自动重建胸部表面3D并估计超声探头初始位置，以解决远程机器人超声检查时间过长的问题。


<details>
  <summary>Details</summary>
Motivation: 远程机器人超声检查虽然能解决偏远地区医疗资源不足的问题，但临床研究表明其检查时间比手动操作更长，增加了诊断延迟和操作员负担。自动执行非专家任务（如自动将探头移动到理想起始位置）可以减轻这一负担。

Method: 使用机器人安装的2D LiDAR重建胸部表面3D，通过基于平面的外部校准估计LiDAR与机器人基座坐标系之间的变换，然后使用非刚性模板对齐识别初始探头位置。

Result: 外部校准的RMS残差为1.8mm，旋转不确定性低于0.2度；人体模型研究显示平均表面误差为2.78±0.21mm；人体试验中初始点距离临床定义点20-30mm，同一受试者重复试验的变异小于4mm。

Conclusion: 该方法首次展示了机器人安装2D LiDAR用于人体表面3D重建，能够可靠地自动估计超声探头初始位置，有望减少远程机器人超声检查的时间和操作员负担。

Abstract: Echocardiography is a key imaging modality for cardiac assessment but remains
highly operator-dependent, and access to trained sonographers is limited in
underserved settings. Teleoperated robotic echocardiography has been proposed
as a solution; however, clinical studies report longer examination times than
manual procedures, increasing diagnostic delays and operator workload.
Automating non-expert tasks, such as automatically moving the probe to an ideal
starting pose, offers a pathway to reduce this burden. Prior vision- and
depth-based approaches to estimate an initial probe pose are sensitive to
lighting, texture, and anatomical variability. We propose a robot-mounted 2D
LiDAR-based approach that reconstructs the chest surface in 3D and estimates
the initial probe pose automatically. To the best of our knowledge, this is the
first demonstration of robot-mounted 2D LiDAR used for 3D reconstruction of a
human body surface. Through plane-based extrinsic calibration, the
transformation between the LiDAR and robot base frames was estimated with an
overall root mean square (RMS) residual of 1.8 mm and rotational uncertainty
below 0.2{\deg}. The chest front surface, reconstructed from two linear LiDAR
sweeps, was aligned with non-rigid templates to identify an initial probe pose.
A mannequin-based study assessing reconstruction accuracy showed mean surface
errors of 2.78 +/- 0.21 mm. Human trials (N=5) evaluating the proposed approach
found probe initial points typically 20-30 mm from the clinically defined
initial point, while the variation across repeated trials on the same subject
was less than 4 mm.

</details>


### [94] [JuggleRL: Mastering Ball Juggling with a Quadrotor via Deep Reinforcement Learning](https://arxiv.org/abs/2509.24892)
*Shilong Ji,Yinuo Chen,Chuqi Wang,Jiayu Chen,Ruize Zhang,Feng Gao,Wenhao Tang,Shu'ang Yu,Sirui Xiang,Xinlei Chen,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: JuggleRL是首个基于强化学习的空中杂耍系统，通过模拟训练和系统校准来减小仿真与现实差距，在真实硬件上实现了零样本部署，平均能连续击球311次。


<details>
  <summary>Details</summary>
Motivation: 空中机器人需要在不确定性下执行精确的接触式操作，而空中球类杂耍任务对时机准确性、稳定控制和持续适应能力提出了很高要求。

Method: 使用强化学习在大规模仿真中学习闭环策略，通过系统校准四旋翼和球体动力学减小仿真与现实差距，结合奖励塑造鼓励球拍中心击球和持续杂耍，并采用领域随机化增强鲁棒性。

Result: 在真实世界中平均连续击球311次（最高462次），远超基于模型的基线方法（最多14次，平均3.1次），并能泛化到未见过的条件，对5克轻球平均击球145.9次。

Conclusion: 这项工作证明强化学习能够赋予空中机器人在动态交互任务中实现鲁棒和稳定的控制。

Abstract: Aerial robots interacting with objects must perform precise, contact-rich
maneuvers under uncertainty. In this paper, we study the problem of aerial ball
juggling using a quadrotor equipped with a racket, a task that demands accurate
timing, stable control, and continuous adaptation. We propose JuggleRL, the
first reinforcement learning-based system for aerial juggling. It learns
closed-loop policies in large-scale simulation using systematic calibration of
quadrotor and ball dynamics to reduce the sim-to-real gap. The training
incorporates reward shaping to encourage racket-centered hits and sustained
juggling, as well as domain randomization over ball position and coefficient of
restitution to enhance robustness and transferability. The learned policy
outputs mid-level commands executed by a low-level controller and is deployed
zero-shot on real hardware, where an enhanced perception module with a
lightweight communication protocol reduces delays in high-frequency state
estimation and ensures real-time control. Experiments show that JuggleRL
achieves an average of $311$ hits over $10$ consecutive trials in the real
world, with a maximum of $462$ hits observed, far exceeding a model-based
baseline that reaches at most $14$ hits with an average of $3.1$. Moreover, the
policy generalizes to unseen conditions, successfully juggling a lighter $5$ g
ball with an average of $145.9$ hits. This work demonstrates that reinforcement
learning can empower aerial robots with robust and stable control in dynamic
interaction tasks.

</details>


### [95] [DRCP: Diffusion on Reinforced Cooperative Perception for Perceiving Beyond Limits](https://arxiv.org/abs/2509.24903)
*Lantao Li,Kang Yang,Rui Song,Chen Sun*

Main category: cs.RO

TL;DR: DRCP是一个实时可部署的协同感知框架，通过跨模态融合和轻量级扩散精炼模块，提升自动驾驶在动态驾驶环境中的检测鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的协同感知部署面临部分检测和噪声累积等挑战，这些限制了下游检测的准确性。

Method: 集成两个关键组件：Precise-Pyramid-Cross-Modality-Cross-Agent跨模态协同感知模块和Mask-Diffusion-Mask-Aggregation轻量级扩散精炼模块。

Result: 该系统在移动平台上实现实时性能，并在挑战性条件下显著提高鲁棒性。

Conclusion: DRCP框架有效解决了动态驾驶环境中的协同感知问题，具有实际部署价值。

Abstract: Cooperative perception enabled by Vehicle-to-Everything communication has
shown great promise in enhancing situational awareness for autonomous vehicles
and other mobile robotic platforms. Despite recent advances in perception
backbones and multi-agent fusion, real-world deployments remain challenged by
hard detection cases, exemplified by partial detections and noise accumulation
which limit downstream detection accuracy. This work presents Diffusion on
Reinforced Cooperative Perception (DRCP), a real-time deployable framework
designed to address aforementioned issues in dynamic driving environments. DRCP
integrates two key components: (1) Precise-Pyramid-Cross-Modality-Cross-Agent,
a cross-modal cooperative perception module that leverages
camera-intrinsic-aware angular partitioning for attention-based fusion and
adaptive convolution to better exploit external features; and (2)
Mask-Diffusion-Mask-Aggregation, a novel lightweight diffusion-based refinement
module that encourages robustness against feature perturbations and aligns
bird's-eye-view features closer to the task-optimal manifold. The proposed
system achieves real-time performance on mobile platforms while significantly
improving robustness under challenging conditions. Code will be released in
late 2025.

</details>


### [96] [Real-time Recognition of Human Interactions from a Single RGB-D Camera for Socially-Aware Robot Navigation](https://arxiv.org/abs/2509.24907)
*Thanh Long Nguyen,Duc Phu Nguyen,Thanh Thao Ton Nu,Quan Le,Thuan Hoang Tran,Manh Duong Phung*

Main category: cs.RO

TL;DR: 提出一种基于RGB-D相机识别人类群体互动的框架，用于社交感知导航，通过3D关键点检测、PCA分析互动方向和鞋带公式计算兴趣区域


<details>
  <summary>Details</summary>
Motivation: 传统机器人系统主要关注障碍物避让，忽略了社交线索，无法实现自然的人机交互，需要识别人类群体互动来实现社交感知导航

Method: 使用单目RGB-D相机获取彩色和深度帧，估计3D人体关键点和位置，通过PCA确定主导互动方向，应用鞋带公式计算兴趣点和参与区域

Result: 方法能够识别不同场景下不同人数的群体互动，在单板计算机上每帧处理时间约4毫秒，实现了高速性能

Conclusion: 该方法作为ROS 2包实现，易于集成到现有导航系统中，为社交机器人提供了有效的群体互动识别能力

Abstract: {Recognizing human interactions is essential for social robots as it enables
them to navigate safely and naturally in shared environments. Conventional
robotic systems however often focus on obstacle avoidance, neglecting social
cues necessary for seamless human-robot interaction. To address this gap, we
propose a framework to recognize human group interactions for socially aware
navigation. Our method utilizes color and depth frames from a monocular RGB-D
camera to estimate 3D human keypoints and positions. Principal component
analysis (PCA) is then used to determine dominant interaction directions. The
shoelace formula is finally applied to compute interest points and engagement
areas. Extensive experiments have been conducted to evaluate the validity of
the proposed method. The results show that our method is capable of recognizing
group interactions across different scenarios with varying numbers of
individuals. It also achieves high-speed performance, processing each frame in
approximately 4 ms on a single-board computer used in robotic systems. The
method is implemented as a ROS 2 package making it simple to integrate into
existing navigation systems. Source code is available at
https://github.com/thanhlong103/social-interaction-detector

</details>


### [97] [From Code to Action: Hierarchical Learning of Diffusion-VLM Policies](https://arxiv.org/abs/2509.24917)
*Markus Peschl,Pietro Mazzaglia,Daniel Dijkman*

Main category: cs.RO

TL;DR: 提出了一种分层框架，结合代码生成视觉语言模型和低层扩散策略，通过将机器人API作为结构化监督源来改进模仿学习在复杂长时程任务中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决机器人模仿学习在复杂长时程任务中泛化能力有限和数据稀缺的问题。

Method: 使用视觉语言模型将任务描述分解为可执行子程序，通过扩散策略模仿对应机器人行为，并引入记忆机制处理非马尔可夫任务。

Result: 该设计实现了可解释的策略分解，相比平面策略提高了泛化能力，并能分别评估高层规划和低层控制。

Conclusion: 将开源机器人API作为结构化监督源的分层框架有效提升了模仿学习的性能和可解释性。

Abstract: Imitation learning for robotic manipulation often suffers from limited
generalization and data scarcity, especially in complex, long-horizon tasks. In
this work, we introduce a hierarchical framework that leverages code-generating
vision-language models (VLMs) in combination with low-level diffusion policies
to effectively imitate and generalize robotic behavior. Our key insight is to
treat open-source robotic APIs not only as execution interfaces but also as
sources of structured supervision: the associated subtask functions - when
exposed - can serve as modular, semantically meaningful labels. We train a VLM
to decompose task descriptions into executable subroutines, which are then
grounded through a diffusion policy trained to imitate the corresponding robot
behavior. To handle the non-Markovian nature of both code execution and certain
real-world tasks, such as object swapping, our architecture incorporates a
memory mechanism that maintains subtask context across time. We find that this
design enables interpretable policy decomposition, improves generalization when
compared to flat policies and enables separate evaluation of high-level
planning and low-level control.

</details>


### [98] [CineWild: Balancing Art and Robotics for Ethical Wildlife Documentary Filmmaking](https://arxiv.org/abs/2509.24921)
*Pablo Pueyo,Fernando Caballero,Ana Cristina Murillo,Eduardo Montijano*

Main category: cs.RO

TL;DR: CineWild是一个自主无人机框架，结合机器人技术、电影摄影和伦理考量，通过模型预测控制动态调整飞行路径和相机设置，在野生动物纪录片拍摄中平衡电影质量与动物福利。


<details>
  <summary>Details</summary>
Motivation: 无人机在野生动物纪录片拍摄中提供了独特的视角，但也存在干扰动物的伦理风险，需要开发能平衡电影质量与动物福利的自主系统。

Method: 基于模型预测控制，系统动态调整飞行路径和相机设置，包括自适应变焦以保持声学和视觉安全距离、避开动物视野的路径规划、平滑低噪音机动。

Result: 通过仿真研究验证了系统有效性，代码将在接受后发布。

Conclusion: CineWild展示了跨学科创新，连接了工程、视觉叙事和环境伦理，为无人机野生动物拍摄提供了伦理解决方案。

Abstract: Drones, or unmanned aerial vehicles (UAVs), have become powerful tools across
domains-from industry to the arts. In documentary filmmaking, they offer
dynamic, otherwise unreachable perspectives, transforming how stories are told.
Wildlife documentaries especially benefit, yet drones also raise ethical
concerns: the risk of disturbing the animals they aim to capture. This paper
introduces CineWild, an autonomous UAV framework that combines robotics,
cinematography, and ethics. Built on model predictive control, CineWild
dynamically adjusts flight paths and camera settings to balance cinematic
quality with animal welfare. Key features include adaptive zoom for filming
from acoustic and visual safe distances, path-planning that avoids an animal's
field of view, and smooth, low-noise maneuvers. CineWild exemplifies
interdisciplinary innovation-bridging engineering, visual storytelling, and
environmental ethics. We validate the system through simulation studies and
will release the code upon acceptance.

</details>


### [99] [Trajectory Prediction via Bayesian Intention Inference under Unknown Goals and Kinematics](https://arxiv.org/abs/2509.24928)
*Shunan Yin,Zehui Lu,Shaoshuai Mou*

Main category: cs.RO

TL;DR: 提出了一种自适应贝叶斯算法，用于实时轨迹预测和意图推断，能够处理目标意图和运动特性的未知变化。


<details>
  <summary>Details</summary>
Motivation: 目标对象的意图和运动特性通常是未知且可能随时变化的，需要一种能够实时适应这些变化的轨迹预测方法。

Method: 通过联合估计目标的当前意图（马尔可夫潜在状态）和意图参数（描述目标遵循最短路径策略的程度），结合采样轨迹预测机制生成概率预测。

Result: 实验验证表明该方法显著优于非自适应和部分自适应方法，在四旋翼和四足机器人平台上实时运行（约270Hz）。

Conclusion: 该方法无需训练或对目标行为的先验知识，在各种机器人系统中具有广泛适用性。

Abstract: This work introduces an adaptive Bayesian algorithm for real-time trajectory
prediction via intention inference, where a target's intentions and motion
characteristics are unknown and subject to change. The method concurrently
estimates two critical variables: the target's current intention, modeled as a
Markovian latent state, and an intention parameter that describes the target's
adherence to a shortest-path policy. By integrating this joint update
technique, the algorithm maintains robustness against abrupt intention shifts
and unknown motion dynamics. A sampling-based trajectory prediction mechanism
then exploits these adaptive estimates to generate probabilistic forecasts with
quantified uncertainty. We validate the framework through numerical
experiments: Ablation studies of two cases, and a 500-trial Monte Carlo
analysis; Hardware demonstrations on quadrotor and quadrupedal platforms.
Experimental results demonstrate that the proposed approach significantly
outperforms non-adaptive and partially adaptive methods. The method operates in
real time around 270 Hz without requiring training or detailed prior knowledge
of target behavior, showcasing its applicability in various robotic systems.

</details>


### [100] [World-Env: Leveraging World Model as a Virtual Environment for VLA Post-Training](https://arxiv.org/abs/2509.24948)
*Junjin Xiao,Yandan Yang,Xinyuan Chang,Ronghan Chen,Feng Xiong,Mu Xu,Wei-Shi Zheng,Qing Zhang*

Main category: cs.RO

TL;DR: 提出World-Env框架，使用世界模型模拟器替代真实环境交互，解决VLA模型在数据稀缺场景下的性能下降问题，通过强化学习后训练提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统VLA模型依赖大规模演示数据，在数据稀缺时性能显著下降；真实环境不可重置的特性限制了强化学习的应用，特别是在高风险工业自动化领域；现有方法缺乏可靠的任务完成检测机制。

Method: World-Env框架包含两个核心组件：基于视频的世界模拟器生成时序一致的未来视觉观察，以及VLM引导的即时反射器提供连续奖励信号并预测动作终止。通过虚拟模拟器替代物理交互实现安全探索。

Result: 在复杂机器人操作任务上的实验表明，该方法仅需每个任务5个专家演示就能获得显著性能提升，有效克服了传统VLA模型的数据效率低、安全约束和执行效率问题。

Conclusion: World-Env为资源受限环境下的VLA模型后训练提供了实用且可扩展的解决方案，能够安全地探索和泛化，超越初始模仿学习分布。

Abstract: Vision-Language-Action (VLA) models trained via imitation learning suffer
from significant performance degradation in data-scarce scenarios due to their
reliance on large-scale demonstration datasets. Although reinforcement learning
(RL)-based post-training has proven effective in addressing data scarcity, its
application to VLA models is hindered by the non-resettable nature of
real-world environments. This limitation is particularly critical in high-risk
domains such as industrial automation, where interactions often induce state
changes that are costly or infeasible to revert. Furthermore, existing VLA
approaches lack a reliable mechanism for detecting task completion, leading to
redundant actions that reduce overall task success rates. To address these
challenges, we propose World-Env, an RL-based post-training framework that
replaces physical interaction with a low-cost, world model-based virtual
simulator. World-Env consists of two key components: (1) a video-based world
simulator that generates temporally consistent future visual observations, and
(2) a vision-language model (VLM)-guided instant reflector that provides
continuous reward signals and predicts action termination. This simulated
environment enables VLA models to safely explore and generalize beyond their
initial imitation learning distribution. Our method achieves notable
performance gains with as few as five expert demonstrations per task.
Experiments on complex robotic manipulation tasks demonstrate that World-Env
effectively overcomes the data inefficiency, safety constraints, and
inefficient execution of conventional VLA models that rely on real-world
interaction, offering a practical and scalable solution for post-training in
resource-constrained settings.

</details>


### [101] [MSG: Multi-Stream Generative Policies for Sample-Efficient Robotic Manipulation](https://arxiv.org/abs/2509.24956)
*Jan Ole von Hartz,Lukas Schweizer,Joschka Boedecker,Abhinav Valada*

Main category: cs.RO

TL;DR: 提出MSG框架，通过推理时组合多个物体中心策略来提升生成式机器人策略的泛化能力和样本效率，仅需5个演示就能学习高质量策略，比单流方法性能提升89%


<details>
  <summary>Details</summary>
Motivation: 生成式机器人策略（如Flow Matching）虽然灵活多模态但样本效率低，物体中心策略虽改善效率但仍有局限，需要更高效的策略学习方法

Method: MSG框架在推理时组合多个预训练的物体中心策略，模型无关且仅需推理阶段，适用于各种生成式策略和训练范式

Result: 仅需5个演示就能学习高质量策略，演示数量减少95%，性能比单流方法提升89%，支持零样本物体实例迁移

Conclusion: MSG框架显著提升生成式策略的样本效率和性能，具有广泛适用性，为实际部署提供了实用建议

Abstract: Generative robot policies such as Flow Matching offer flexible, multi-modal
policy learning but are sample-inefficient. Although object-centric policies
improve sample efficiency, it does not resolve this limitation. In this work,
we propose Multi-Stream Generative Policy (MSG), an inference-time composition
framework that trains multiple object-centric policies and combines them at
inference to improve generalization and sample efficiency. MSG is
model-agnostic and inference-only, hence widely applicable to various
generative policies and training paradigms. We perform extensive experiments
both in simulation and on a real robot, demonstrating that our approach learns
high-quality generative policies from as few as five demonstrations, resulting
in a 95% reduction in demonstrations, and improves policy performance by 89
percent compared to single-stream approaches. Furthermore, we present
comprehensive ablation studies on various composition strategies and provide
practical recommendations for deployment. Finally, MSG enables zero-shot object
instance transfer. We make our code publicly available at
https://msg.cs.uni-freiburg.de.

</details>


### [102] [Annotation-Free One-Shot Imitation Learning for Multi-Step Manipulation Tasks](https://arxiv.org/abs/2509.24972)
*Vijja Wichitwechkarn,Emlyn Williams,Charles Fox,Ruchi Choudhary*

Main category: cs.RO

TL;DR: 提出了一种无需额外模型训练或人工标注的单次演示模仿学习方法，能够处理长时域多步任务，在单步和多步操作任务中分别达到90%和82.5%的平均成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的单次模仿学习方法在单步任务上表现良好，但在处理长时域多步任务时需要额外模型训练或人工标注，限制了其实际应用。

Method: 基于单次演示的模仿学习方法，无需额外模型训练或手动标注，能够直接应用于多步任务设置。

Result: 在多步操作任务中平均成功率为82.5%，在单步操作任务中为90%，性能均优于基线方法。

Conclusion: 该方法在无需额外训练或标注的情况下，有效解决了长时域多步任务的单次模仿学习问题，并验证了不同预训练特征提取器的性能和计算效率。

Abstract: Recent advances in one-shot imitation learning have enabled robots to acquire
new manipulation skills from a single human demonstration. While existing
methods achieve strong performance on single-step tasks, they remain limited in
their ability to handle long-horizon, multi-step tasks without additional model
training or manual annotation. We propose a method that can be applied to this
setting provided a single demonstration without additional model training or
manual annotation. We evaluated our method on multi-step and single-step
manipulation tasks where our method achieves an average success rate of 82.5%
and 90%, respectively. Our method matches and exceeds the performance of the
baselines in both these cases. We also compare the performance and
computational efficiency of alternative pre-trained feature extractors within
our framework.

</details>


### [103] [Path Diffuser: Diffusion Model for Data-Driven Traffic Simulator](https://arxiv.org/abs/2509.24995)
*Da Saem Lee,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: 提出了Path Diffuser（PD），一种基于扩散模型的两阶段方法，用于生成无需历史轨迹信息的智能体姿态初始化和轨迹，通过运动原语先验和Frenet框架确保道路合规性。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的规划器缺乏多样性和真实性，而基于学习的模拟器依赖历史轨迹数据，难以生成新场景且在分布外地图场景下产生不现实轨迹。

Method: 两阶段扩散模型，第一阶段生成智能体姿态初始化，第二阶段生成对应轨迹；结合运动原语先验和Frenet框架候选轨迹；探索多智能体交互建模设计选择。

Result: 在Argoverse2数据集上表现优异，在分布外地图变体上具有良好泛化能力；在分布指标上比基线方法提升1.92倍，常识指标提升1.14倍，道路合规性提升1.62倍。

Conclusion: Path Diffuser能够有效生成多样且符合道路规则的轨迹，无需依赖智能体历史轨迹信息，在分布外场景下表现出色。

Abstract: Simulating diverse and realistic traffic scenarios is critical for developing
and testing autonomous planning. Traditional rule-based planners lack diversity
and realism, while learning-based simulators often replay, forecast, or edit
scenarios using historical agent trajectories. However, they struggle to
generate new scenarios, limiting scalability and diversity due to their
reliance on fully annotated logs and historical data. Thus, a key challenge for
a learning-based simulator's performance is that it requires agents' past
trajectories and pose information in addition to map data, which might not be
available for all agents on the road.Without which, generated scenarios often
produce unrealistic trajectories that deviate from drivable areas, particularly
under out-of-distribution (OOD) map scenes (e.g., curved roads). To address
this, we propose Path Diffuser (PD): a two-stage, diffusion model for
generating agent pose initializations and their corresponding trajectories
conditioned on the map, free of any historical context of agents' trajectories.
Furthermore, PD incorporates a motion primitive-based prior, leveraging Frenet
frame candidate trajectories to enhance diversity while ensuring road-compliant
trajectory generation. We also explore various design choices for modeling
complex multi-agent interactions. We demonstrate the effectiveness of our
method through extensive experiments on the Argoverse2 Dataset and additionally
evaluate the generalizability of the approach on OOD map variants. Notably,
Path Diffuser outperforms the baseline methods by 1.92x on distribution
metrics, 1.14x on common-sense metrics, and 1.62x on road compliance from
adversarial benchmarks.

</details>


### [104] [AIRoA MoMa Dataset: A Large-Scale Hierarchical Dataset for Mobile Manipulation](https://arxiv.org/abs/2509.25032)
*Ryosuke Takanami,Petr Khrapchenkov,Shu Morikuni,Jumpei Arima,Yuta Takaba,Shunsuke Maeda,Takuya Okubo,Genki Sano,Satoshi Sekioka,Aoi Kadoya,Motonari Kambara,Naoya Nishiura,Haruto Suzuki,Takanori Yoshimoto,Koya Sakamoto,Shinnosuke Ono,Hu Yang,Daichi Yashima,Aoi Horo,Tomohiro Motoda,Kensuke Chiyoma,Hiroshi Ito,Koki Fukuda,Akihito Goto,Kazumi Morinaga,Yuya Ikeda,Riko Kawada,Masaki Yoshikawa,Norio Kosuge,Yuki Noguchi,Kei Ota,Tatsuya Matsushima,Yusuke Iwasawa,Yutaka Matsuo,Tetsuya Ogata*

Main category: cs.RO

TL;DR: 提出了AIRoA MoMa数据集，这是一个用于移动操作的大规模多模态数据集，包含同步的RGB图像、关节状态、六轴腕力扭矩信号和机器人内部状态，以及用于分层学习和错误分析的两层注释方案。


<details>
  <summary>Details</summary>
Motivation: 随着机器人从受控环境转向非结构化的人类环境，构建能够可靠遵循自然语言指令的通用智能体仍然是一个核心挑战。需要大规模多模态数据集来捕捉接触丰富和长时程任务，但现有资源缺乏同步的力扭矩传感、分层注释和明确的失败案例。

Method: 创建了AIRoA MoMa数据集，包含25,469个片段（约94小时），使用人支持机器人（HSR）收集，并采用LeRobot v2.1格式标准化。数据集包括同步的RGB图像、关节状态、六轴腕力扭矩信号和机器人内部状态，以及包含子目标和原始动作的两层注释方案。

Result: 数据集已在HuggingFace上发布，为推进下一代视觉-语言-动作模型提供了关键基准。通过独特地整合移动操作、接触丰富的交互和长时程结构，填补了现有资源的空白。

Conclusion: AIRoA MoMa数据集通过提供大规模、多模态、具有分层注释和力扭矩传感的数据，为移动操作研究提供了重要资源，有助于推进通用机器人智能体的发展。

Abstract: As robots transition from controlled settings to unstructured human
environments, building generalist agents that can reliably follow natural
language instructions remains a central challenge. Progress in robust mobile
manipulation requires large-scale multimodal datasets that capture contact-rich
and long-horizon tasks, yet existing resources lack synchronized force-torque
sensing, hierarchical annotations, and explicit failure cases. We address this
gap with the AIRoA MoMa Dataset, a large-scale real-world multimodal dataset
for mobile manipulation. It includes synchronized RGB images, joint states,
six-axis wrist force-torque signals, and internal robot states, together with a
novel two-layer annotation schema of sub-goals and primitive actions for
hierarchical learning and error analysis. The initial dataset comprises 25,469
episodes (approx. 94 hours) collected with the Human Support Robot (HSR) and is
fully standardized in the LeRobot v2.1 format. By uniquely integrating mobile
manipulation, contact-rich interaction, and long-horizon structure, AIRoA MoMa
provides a critical benchmark for advancing the next generation of
Vision-Language-Action models. The first version of our dataset is now
available at https://huggingface.co/datasets/airoa-org/airoa-moma .

</details>


### [105] [AgriCruiser: An Open Source Agriculture Robot for Over-the-row Navigation](https://arxiv.org/abs/2509.25056)
*Kenny Truong,Yongkyu Lee,Jason Irie,Shivam Kumar Panda,Shahab Ahmad,Md. Mukhlesur Rahman,M. Khalid Jawed*

Main category: cs.RO

TL;DR: AgriCruiser是一款开源的跨行农业机器人，具有可调节轨道宽度和紧凑转弯半径，实现了低成本部署和快速适应不同作物。配备精准喷洒系统，在杂草管理中效果显著，比人工除草减少24-42倍杂草，同时减少作物损伤。


<details>
  <summary>Details</summary>
Motivation: 开发低成本、可重构的跨行农业机器人，以解决传统农业中杂草管理效率低、作物损伤大和劳动力需求高的问题，并为表型分析、传感等农业应用提供多功能平台。

Method: 使用商用T型槽铝型材构建可调节底盘（轨道宽度1.42-1.57米，离地间隙0.94米），实现紧凑转弯（半径0.71-0.79米）。集成精准喷洒系统，在亚麻田进行杂草管理测试。

Result: 在12个亚麻地块中，单次机器人喷洒使杂草总数减少24-42倍，作物损伤更小。在混凝土、沥青、砾石、草地和干湿土壤上的移动性测试表现可靠。制造成本约5000-6000美元。

Conclusion: 低成本可重构跨行机器人能有效管理杂草，减少作物损伤和劳动力需求，为农业应用提供多功能基础。发布设计文件以加速模块化农业机器人研究与应用。

Abstract: We present the AgriCruiser, an open-source over-the-row agricultural robot
developed for low-cost deployment and rapid adaptation across diverse crops and
row layouts. The chassis provides an adjustable track width of 1.42 m to 1.57
m, along with a ground clearance of 0.94 m. The AgriCruiser achieves compact
pivot turns with radii of 0.71 m to 0.79 m, enabling efficient headland
maneuvers. The platform is designed for the integration of the other
subsystems, and in this study, a precision spraying system was implemented to
assess its effectiveness in weed management. In twelve flax plots, a single
robotic spray pass reduced total weed populations (pigweed and Venice mallow)
by 24- to 42-fold compared to manual weeding in four flax plots, while also
causing less crop damage. Mobility experiments conducted on concrete, asphalt,
gravel, grass, and both wet and dry soil confirmed reliable traversal
consistent with torque sizing. The complete chassis can be constructed from
commodity T-slot extrusion with minimal machining, resulting in a bill of
materials costing approximately $5,000 - $6,000, which enables replication and
customization. The mentioned results demonstrate that low-cost, reconfigurable
over-the-row robots can achieve effective weed management with reduced crop
damage and labor requirements, while providing a versatile foundation for
phenotyping, sensing, and other agriculture applications. Design files and
implementation details are released to accelerate research and adoption of
modular agricultural robotics.

</details>


### [106] [Crop Spirals: Re-thinking the field layout for future robotic agriculture](https://arxiv.org/abs/2509.25091)
*Lakshan Lavan,Lanojithan Thiyagarasa,Udara Muthugala,Rajitha de Silva*

Main category: cs.RO

TL;DR: 提出了机器人中心的方形螺旋布局，替代传统的线性作物布局，使机器人导航更简单高效。开发了结合DH-ResNet18路径点回归、像素到里程计映射、A*规划和模型预测控制的导航系统，在模拟中显示路径缩短28%，执行速度提升25%。


<details>
  <summary>Details</summary>
Motivation: 传统线性作物布局为拖拉机优化，但阻碍机器人导航，导致转弯困难、行程长和感知混淆。需要重新设计更适合自主农业的田地几何形状。

Method: 开发机器人中心的方形螺旋布局，配有中央轨道线。导航系统结合DH-ResNet18路径点回归、像素到里程计映射、A*路径规划和模型预测控制。

Result: 模拟显示螺旋布局比线性布局路径缩短28%，执行速度提升约25%。全场覆盖性能与优化的线性U形转弯策略相当。多机器人研究中，贪婪分配器比匈牙利分配降低33-37%的批次完成时间。

Conclusion: 重新设计田地几何形状能显著改善自主农业机器人的导航效率和协调性能，螺旋布局展现出巨大潜力。

Abstract: Conventional linear crop layouts, optimised for tractors, hinder robotic
navigation with tight turns, long travel distances, and perceptual aliasing. We
propose a robot-centric square spiral layout with a central tramline, enabling
simpler motion and more efficient coverage. To exploit this geometry, we
develop a navigation stack combining DH-ResNet18 waypoint regression,
pixel-to-odometry mapping, A* planning, and model predictive control (MPC). In
simulations, the spiral layout yields up to 28% shorter paths and about 25%
faster execution for waypoint-based tasks across 500 waypoints than linear
layouts, while full-field coverage performance is comparable to an optimised
linear U-turn strategy. Multi-robot studies demonstrate efficient coordination
on the spirals rule-constrained graph, with a greedy allocator achieving 33-37%
lower batch completion times than a Hungarian assignment under our setup. These
results highlight the potential of redesigning field geometry to better suit
autonomous agriculture.

</details>


### [107] [Curriculum Imitation Learning of Distributed Multi-Robot Policies](https://arxiv.org/abs/2509.25097)
*Jesús Roche,Eduardo Sebastián,Eduardo Montijano*

Main category: cs.RO

TL;DR: 提出了一种从全局演示中学习多机器人系统分布式控制策略的方法，通过课程学习改善长期协调性，并通过感知估计方法将全局状态转换为局部观测。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统中长期协调的挑战以及获取真实训练数据的困难，旨在从全局演示中学习分布式控制策略。

Method: 采用课程学习策略逐步增加专家轨迹长度，并使用感知估计方法将全局状态转换为局部可用的观测信息，包括邻居过滤、参考系转换和传感器噪声模拟。

Result: 实验表明课程学习提高了长期行为的准确性，感知估计方法使策略对现实不确定性具有鲁棒性，能够学习到有效的分布式控制器。

Conclusion: 结合课程学习和感知估计方法，能够从全局演示中学习到鲁棒的分布式控制策略，无需专家动作或机载测量数据。

Abstract: Learning control policies for multi-robot systems (MRS) remains a major
challenge due to long-term coordination and the difficulty of obtaining
realistic training data. In this work, we address both limitations within an
imitation learning framework. First, we shift the typical role of Curriculum
Learning in MRS, from scalability with the number of robots, to focus on
improving long-term coordination. We propose a curriculum strategy that
gradually increases the length of expert trajectories during training,
stabilizing learning and enhancing the accuracy of long-term behaviors. Second,
we introduce a method to approximate the egocentric perception of each robot
using only third-person global state demonstrations. Our approach transforms
idealized trajectories into locally available observations by filtering
neighbors, converting reference frames, and simulating onboard sensor
variability. Both contributions are integrated into a physics-informed
technique to produce scalable, distributed policies from observations. We
conduct experiments across two tasks with varying team sizes and noise levels.
Results show that our curriculum improves long-term accuracy, while our
perceptual estimation method yields policies that are robust to realistic
uncertainty. Together, these strategies enable the learning of robust,
distributed controllers from global demonstrations, even in the absence of
expert actions or onboard measurements.

</details>


### [108] [Safe Planning in Unknown Environments using Conformalized Semantic Maps](https://arxiv.org/abs/2509.25124)
*David Smith Sundarsingh,Yifei Li,Tianji Tang,George J. Pappas,Nikolay Atanasov,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 提出了一种在未知环境下处理语义规划问题的新方法，能够在感知不确定性的情况下完成语义到达-规避任务，且无需传感器模型或噪声知识。


<details>
  <summary>Details</summary>
Motivation: 解决在未知环境中语义规划时面临的感知不确定性挑战，现有方法要么忽略感知不确定性导致缺乏正确性保证，要么需要已知的传感器模型和噪声特性。

Method: 使用保形预测方法以模型无关和分布无关的方式量化语义地图中的不确定性，这些地图是从感知测量中实时构建的。

Result: 通过大量实验验证了该方法，显示其始终优于基线方法在任务成功率方面的表现，并实现了理论上的任务完成率。

Conclusion: 该方法是在语义到达-规避任务中首个无需传感器模型知识就能实现用户指定任务完成率的规划器，为未知环境下的语义规划提供了可靠解决方案。

Abstract: This paper addresses semantic planning problems in unknown environments under
perceptual uncertainty. The environment contains multiple unknown semantically
labeled regions or objects, and the robot must reach desired locations while
maintaining class-dependent distances from them. We aim to compute robot paths
that complete such semantic reach-avoid tasks with user-defined probability
despite uncertain perception. Existing planning algorithms either ignore
perceptual uncertainty - thus lacking correctness guarantees - or assume known
sensor models and noise characteristics. In contrast, we present the first
planner for semantic reach-avoid tasks that achieves user-specified mission
completion rates without requiring any knowledge of sensor models or noise.
This is enabled by quantifying uncertainty in semantic maps - constructed
on-the-fly from perceptual measurements - using conformal prediction in a
model- and distribution-free manner. We validate our approach and the
theoretical mission completion rates through extensive experiments, showing
that it consistently outperforms baselines in mission success rates.

</details>
