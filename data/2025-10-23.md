<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 25]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Towards Proprioceptive Terrain Mapping with Quadruped Robots for Exploration in Planetary Permanently Shadowed Regions](https://arxiv.org/abs/2510.18986)
*Alberto Sanchez-Delgado,João Carlos Virgolino Soares,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 提出了一种用于四足机器人的地形映射框架，通过内部感知估计高程、足部滑移、能量消耗和稳定性边界，并在模拟月球环境中验证了性能。


<details>
  <summary>Details</summary>
Motivation: 月球极区永久阴影区地形复杂，适合腿式机器人探索，但现有外部传感器无法量化地形与机器人的物理交互，需要基于本体感知的地形映射方法。

Method: 开发了基于四足机器人内部感知的地形映射框架，增量式将高程、足部滑移、能量消耗和稳定性边界整合到多层2.5D网格地图中。

Result: 在模拟月球环境中使用21公斤四足机器人Aliengo进行测试，在月球重力和地形条件下展现出稳定的映射性能。

Conclusion: 该框架能够有效量化地形与机器人的物理交互特性，为月球极区复杂地形探索提供了实用的地形感知解决方案。

Abstract: Permanently Shadowed Regions (PSRs) near the lunar poles are of interest for
future exploration due to their potential to contain water ice and preserve
geological records. Their complex, uneven terrain favors the use of legged
robots, which can traverse challenging surfaces while collecting in-situ data,
and have proven effective in Earth analogs, including dark caves, when equipped
with onboard lighting. While exteroceptive sensors like cameras and lidars can
capture terrain geometry and even semantic information, they cannot quantify
its physical interaction with the robot, a capability provided by
proprioceptive sensing. We propose a terrain mapping framework for quadruped
robots, which estimates elevation, foot slippage, energy cost, and stability
margins from internal sensing during locomotion. These metrics are
incrementally integrated into a multi-layer 2.5D gridmap that reflects terrain
interaction from the robot's perspective. The system is evaluated in a
simulator that mimics a lunar environment, using the 21 kg quadruped robot
Aliengo, showing consistent mapping performance under lunar gravity and terrain
conditions.

</details>


### [2] [Underwater Dense Mapping with the First Compact 3D Sonar](https://arxiv.org/abs/2510.18991)
*Chinmay Burgul,Yewei Huang,Michalis Chatzispyrou,Ioannis Rekleitis,Alberto Quattrini Li,Marios Xanthidis*

Main category: cs.RO

TL;DR: 本文首次研究紧凑型3D声纳的性能、能力和应用机会，提出了3D声纳与相机的标定方法，开发了新型水下建图和SLAM系统，并在洞穴等挑战性环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 水下环境中电磁波传播受限，传统2D声纳只能提供空间模糊信息，而紧凑型3D声纳的出现为水下状态估计提供了新的感知选择。

Method: 开发了3D声纳与相机的外参标定程序，研究了不同表面和材料的声学响应特性，构建了新型水下建图和SLAM流水线。

Result: 3D声纳能够捕获一致的空间信息，实现数百米范围内的详细重建和定位，在几何和声学挑战性水下环境中表现良好。

Conclusion: 3D声纳在水下环境中具有独特优势，能够提供详细的空间信息，但仍面临声波传播相关的挑战，相关数据集将公开发布以促进进一步研究。

Abstract: In the past decade, the adoption of compact 3D range sensors, such as LiDARs,
has driven the developments of robust state-estimation pipelines, making them a
standard sensor for aerial, ground, and space autonomy. Unfortunately, poor
propagation of electromagnetic waves underwater, has limited the
visibility-independent sensing options of underwater state-estimation to
acoustic range sensors, which provide 2D information including, at-best,
spatially ambiguous information. This paper, to the best of our knowledge, is
the first study examining the performance, capacity, and opportunities arising
from the recent introduction of the first compact 3D sonar. Towards that
purpose, we introduce calibration procedures for extracting the extrinsics
between the 3D sonar and a camera and we provide a study on acoustic response
in different surfaces and materials. Moreover, we provide novel mapping and
SLAM pipelines tested in deployments in underwater cave systems and other
geometrically and acoustically challenging underwater environments. Our
assessment showcases the unique capacity of 3D sonars to capture consistent
spatial information allowing for detailed reconstructions and localization in
datasets expanding to hundreds of meters. At the same time it highlights
remaining challenges related to acoustic propagation, as found also in other
acoustic sensors. Datasets collected for our evaluations would be released and
shared with the community to enable further research advancements.

</details>


### [3] [SHRUMS: Sensor Hallucination for Real-time Underwater Motion Planning with a Compact 3D Sonar](https://arxiv.org/abs/2510.18996)
*Susheel Vadakkekuruppath,Herman B. Amundsen,Jason M. O'Kane,Marios Xanthidis*

Main category: cs.RO

TL;DR: SHRUMS是首个集成3D声纳的水下自主导航系统，通过传感器幻觉技术实现复杂3D环境中的鲁棒导航。


<details>
  <summary>Details</summary>
Motivation: 水下机器人缺乏类似LiDAR的紧凑3D传感器，最近出现的3D声纳为解决水下3D自主导航问题提供了新机会。

Method: 提出传感器幻觉概念，从不存在但参数可定制的虚拟传感器生成测量数据，以适应新型3D声纳数据流并实现实时局部最优性能。

Result: 在能见度极差的复杂3D环境中展现出强鲁棒性，使用真实3D声纳数据在挑战性场景中验证了概念。

Conclusion: SHRUMS是首个集成3D声纳的水下导航系统，通过创新方法解决了水下3D导航的关键挑战，实地部署验证即将进行。

Abstract: Autonomous navigation in 3D is a fundamental problem for autonomy. Despite
major advancements in terrestrial and aerial settings due to improved range
sensors including LiDAR, compact sensors with similar capabilities for
underwater robots have only recently become available, in the form of 3D
sonars. This paper introduces a novel underwater 3D navigation pipeline, called
SHRUMS (Sensor Hallucination for Robust Underwater Motion planning with 3D
Sonar). To the best of the authors' knowledge, SHRUMS is the first underwater
autonomous navigation stack to integrate a 3D sonar. The proposed pipeline
exhibits strong robustness while operating in complex 3D environments in spite
of extremely poor visibility conditions. To accommodate the intricacies of the
novel sensor data stream while achieving real-time locally optimal performance,
SHRUMS introduces the concept of hallucinating sensor measurements from
non-existent sensors with convenient arbitrary parameters, tailored to
application specific requirements. The proposed concepts are validated with
real 3D sonar sensor data, utilizing real inputs in challenging settings and
local maps constructed in real-time. Field deployments validating the proposed
approach in full are planned in the very near future.

</details>


### [4] [$\nabla$-SDF: Learning Euclidean Signed Distance Functions Online with Gradient-Augmented Octree Interpolation and Neural Residual](https://arxiv.org/abs/2510.18999)
*Zhirui Dai,Qihao Qian,Tianxing Fan,Nikolay Atanasov*

Main category: cs.RO

TL;DR: 提出了一种结合显式梯度增强八叉树插值和隐式神经残差的混合方法∇-SDF，用于从点云数据重建非截断的有符号距离函数，在计算效率和精度方面均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在在线大规模SDF重建中存在局限性：基于离散体素的方法影响SDF的连续性和可微性，而神经网络方法虽然精度高但效率低、存在灾难性遗忘问题，且通常仅限于截断SDF。

Method: 提出∇-SDF混合方法，结合梯度增强八叉树插值提供的显式先验和隐式神经残差，实现非截断欧几里得SDF重建。

Result: 该方法在计算效率和内存使用方面与体素方法相当，在可微性和精度方面与神经网络方法相当，在准确性和效率方面均优于现有技术。

Conclusion: ∇-SDF为机器人和计算机视觉中的下游任务提供了可扩展的解决方案，实现了效率和精度的良好平衡。

Abstract: Estimation of signed distance functions (SDFs) from point cloud data has been
shown to benefit many robot autonomy capabilities, including localization,
mapping, motion planning, and control. Methods that support online and
large-scale SDF reconstruction tend to rely on discrete volumetric data
structures, which affect the continuity and differentiability of the SDF
estimates. Recently, using implicit features, neural network methods have
demonstrated high-fidelity and differentiable SDF reconstruction but they tend
to be less efficient, can experience catastrophic forgetting and memory
limitations in large environments, and are often restricted to truncated SDFs.
This work proposes $\nabla$-SDF, a hybrid method that combines an explicit
prior obtained from gradient-augmented octree interpolation with an implicit
neural residual. Our method achieves non-truncated (Euclidean) SDF
reconstruction with computational and memory efficiency comparable to
volumetric methods and differentiability and accuracy comparable to neural
network methods. Extensive experiments demonstrate that \methodname{}
outperforms the state of the art in terms of accuracy and efficiency, providing
a scalable solution for downstream tasks in robotics and computer vision.

</details>


### [5] [Motion Planning and Control of an Overactuated 4-Wheel Drive with Constrained Independent Steering](https://arxiv.org/abs/2510.19054)
*Shiyu Liu,Ilija Hadzic,Akshay Gupta,Aliasghar Arab*

Main category: cs.RO

TL;DR: 该论文研究了具有独立转向的四轮驱动系统（4WIS）的运动规划与控制，处理了机械约束导致的转向不连续性问题，提出了考虑转向约束和速度平滑过渡的运动规划器。


<details>
  <summary>Details</summary>
Motivation: 解决四轮独立转向机器人在机械约束下无法实现360度全向旋转时出现的配置空间不连续问题，确保机器人运动的平滑性和效率。

Method: 引入转向约束的数学公式，推导速度空间中的不连续平面，设计考虑转向约束和速度平滑过渡的运动规划器，以及处理不连续穿越的局部反馈控制器。

Result: 实现了作为ROS导航包扩展的运动规划器，在仿真和物理机器人上进行了系统评估，验证了方法的有效性。

Conclusion: 提出的方法能够有效处理四轮独立转向机器人的转向约束和不连续性问题，实现平滑高效的运动规划与控制。

Abstract: This paper addresses motion planning and con- trol of an overactuated 4-wheel
drive train with independent steering (4WIS) where mechanical constraints
prevent the wheels from executing full 360-degree rotations (swerve). The
configuration space of such a robot is constrained and contains discontinuities
that affect the smoothness of the robot motion. We introduce a mathematical
formulation of the steering constraints and derive discontinuity planes that
partition the velocity space into regions of smooth and efficient motion. We
further design the motion planner for path tracking and ob- stacle avoidance
that explicitly accounts for swerve constraints and the velocity transition
smoothness. The motion controller uses local feedback to generate actuation
from the desired velocity, while properly handling the discontinuity crossing
by temporarily stopping the motion and repositioning the wheels. We implement
the proposed motion planner as an extension to ROS Navigation package and
evaluate the system in simulation and on a physical robot.

</details>


### [6] [Convex Maneuver Planning for Spacecraft Collision Avoidance](https://arxiv.org/abs/2510.19058)
*Fausto Vega,Jon Arrizabalaga,Ryan Watson,Zachary Manchester*

Main category: cs.RO

TL;DR: 提出一种用于短期交会事件的低推力碰撞规避机动规划算法，将非凸QCQP问题通过Shor松弛转化为凸SDP问题，可恢复全局最优解。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星密度增加，传统手动碰撞规避规划效率低下，需要自主化解决方案。

Method: 将碰撞规避问题建模为非凸二次约束二次规划，通过Shor松弛转化为凸半定规划，确保在最近接近时刻达到期望碰撞概率。

Result: 经验证松弛是紧的，能够恢复原始非凸问题的全局最优解，在高保真模拟中有效降低碰撞风险。

Conclusion: 该算法能够生成最小能量或最小风险的碰撞规避机动，为自主卫星碰撞规避提供了有效解决方案。

Abstract: Conjunction analysis and maneuver planning for spacecraft collision avoidance
remains a manual and time-consuming process, typically involving repeated
forward simulations of hand-designed maneuvers. With the growing density of
satellites in low-Earth orbit (LEO), autonomy is becoming essential for
efficiently evaluating and mitigating collisions. In this work, we present an
algorithm to design low-thrust collision-avoidance maneuvers for short-term
conjunction events. We first formulate the problem as a nonconvex
quadratically-constrained quadratic program (QCQP), which we then relax into a
convex semidefinite program (SDP) using Shor's relaxation. We demonstrate
empirically that the relaxation is tight, which enables the recovery of
globally optimal solutions to the original nonconvex problem. Our formulation
produces a minimum-energy solution while ensuring a desired probability of
collision at the time of closest approach. Finally, if the desired probability
of collision cannot be satisfied, we relax this constraint into a penalty,
yielding a minimum-risk solution. We validate our algorithm with a
high-fidelity simulation of a satellite conjunction in low-Earth orbit with a
simulated conjunction data message (CDM), demonstrating its effectiveness in
reducing collision risk.

</details>


### [7] [A Learning-based Model Reference Adaptive Controller Implemented on a Prosthetic Hand Wrist](https://arxiv.org/abs/2510.19068)
*Shifa Sulaiman,Mohammad Gohari,Francesco Schetter,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 提出了一种基于神经网络的模型参考自适应控制器，用于肌腱驱动的软连续体手腕假肢，实现了高精度和快速响应的实时控制。


<details>
  <summary>Details</summary>
Motivation: 当前假肢手的柔顺手腕控制策略缺乏适应性且计算成本高，阻碍了辅助机器人的实时部署。

Method: 使用Timoshenko梁理论进行手腕动力学建模，提出NN-MRAC控制器通过在线自适应估计所需肌腱力并最小化与参考模型的偏差。

Result: 仿真结果显示RMSE为6.14×10⁻⁴ m，稳定时间3.2s；实验验证平均RMSE为5.66×10⁻³ m，稳态误差8.05×10⁻³ m，稳定时间1.58s。

Conclusion: 该控制器能够提高软假肢系统的运动精度和响应性，推进自适应智能控制在可穿戴辅助设备中的集成。

Abstract: The functionality and natural motion of prosthetic hands remain limited by
the challenges in controlling compliant wrist mechanisms. Current control
strategies often lack adaptability and incur high computational costs, which
impedes real-time deployment in assistive robotics. To address this gap, this
study presents a computationally efficient Neural Network (NN)-based Model
Reference Adaptive Controller (MRAC) for a tendon-driven soft continuum wrist
integrated with a prosthetic hand. The dynamic modeling of the wrist is
formulated using Timoshenko beam theory, capturing both shear and bending
deformations. The proposed NN-MRAC estimates the required tendon forces from
deflection errors and minimizes deviation from a reference model through online
adaptation. Simulation results demonstrate improved precision with a root mean
square error (RMSE) of $6.14 \times 10^{-4}$ m and a settling time of $3.2$s.
Experimental validations confirm real-time applicability, with an average RMSE
of $5.66 \times 10^{-3}$ m, steady-state error of $8.05 \times 10^{-3}$ m, and
settling time of $1.58$ s. These results highlight the potential of the
controller to enhance motion accuracy and responsiveness in soft prosthetic
systems, thereby advancing the integration of adaptive intelligent control in
wearable assistive devices.

</details>


### [8] [Sample-Based Hybrid Mode Control: Asymptotically Optimal Switching of Algorithmic and Non-Differentiable Control Modes](https://arxiv.org/abs/2510.19074)
*Yilang Liu,Haoxiang You,Ian Abraham*

Main category: cs.RO

TL;DR: 提出了一种基于采样的混合模式控制解决方案，通过整数优化选择控制模式、切换时机和持续时间，在机器人任务中实现复杂算法合成和反应式切换。


<details>
  <summary>Details</summary>
Motivation: 解决非可微和算法混合模式中的混合控制问题，需要在长期规划和高频控制之间进行反应式切换。

Method: 将混合控制模式建模为整数优化问题，通过基于采样的变体在整数域中高效搜索最优解。

Result: 该方法在多种机器人相关任务中表现出强大的性能保证，能够合成复杂算法和政策以实现具有挑战性的任务。

Conclusion: 所提出的方法在需要长期规划和高频控制之间反应式切换的实际机器人应用中表现出有效性。

Abstract: This paper investigates a sample-based solution to the hybrid mode control
problem across non-differentiable and algorithmic hybrid modes. Our approach
reasons about a set of hybrid control modes as an integer-based optimization
problem where we select what mode to apply, when to switch to another mode, and
the duration for which we are in a given control mode. A sample-based variation
is derived to efficiently search the integer domain for optimal solutions. We
find our formulation yields strong performance guarantees that can be applied
to a number of robotics-related tasks. In addition, our approach is able to
synthesize complex algorithms and policies to compound behaviors and achieve
challenging tasks. Last, we demonstrate the effectiveness of our approach in
real-world robotic examples that require reactive switching between long-term
planning and high-frequency control.

</details>


### [9] [Kinematic Analysis and Integration of Vision Algorithms for a Mobile Manipulator Employed Inside a Self-Driving Laboratory](https://arxiv.org/abs/2510.19081)
*Shifa Sulaiman,Tobias Busk Jensen,Stefan Hein Bengtson,Simon Bøgh*

Main category: cs.RO

TL;DR: 开发用于自主实验室环境的移动机械臂系统，具备精确操控和可靠抓取纹理物体的能力，通过视觉算法实现实时物体检测和姿态估计。


<details>
  <summary>Details</summary>
Motivation: 随着机器人和自主系统的发展，实验室环境中机器人应用日益广泛，需要开发能够协助人类操作员的移动机械臂系统，以提升自主实验室的可扩展性和可重复性。

Method: 基于DH约定进行机械臂运动学建模并求解逆运动学，结合基于特征的检测和单应性驱动的姿态估计的视觉方法，利用深度信息将物体姿态表示为3D空间中的2D平面投影。

Result: 实现了精确的自适应操控能力，能够可靠抓取纹理物体，并在动态抓取和跟踪任务中表现出色，系统能够适应物体方向变化并在多样化环境中实现稳健的自主操控。

Conclusion: 该移动机械臂系统通过实现自主实验和人机协作，为下一代化学实验室的可扩展性和可重复性做出了贡献。

Abstract: Recent advances in robotics and autonomous systems have broadened the use of
robots in laboratory settings, including automated synthesis, scalable reaction
workflows, and collaborative tasks in self-driving laboratories (SDLs). This
paper presents a comprehensive development of a mobile manipulator designed to
assist human operators in such autonomous lab environments. Kinematic modeling
of the manipulator is carried out based on the Denavit Hartenberg (DH)
convention and inverse kinematics solution is determined to enable precise and
adaptive manipulation capabilities. A key focus of this research is enhancing
the manipulator ability to reliably grasp textured objects as a critical
component of autonomous handling tasks. Advanced vision-based algorithms are
implemented to perform real-time object detection and pose estimation, guiding
the manipulator in dynamic grasping and following tasks. In this work, we
integrate a vision method that combines feature-based detection with
homography-driven pose estimation, leveraging depth information to represent an
object pose as a $2$D planar projection within $3$D space. This adaptive
capability enables the system to accommodate variations in object orientation
and supports robust autonomous manipulation across diverse environments. By
enabling autonomous experimentation and human-robot collaboration, this work
contributes to the scalability and reproducibility of next-generation chemical
laboratories

</details>


### [10] [Safe Active Navigation and Exploration for Planetary Environments Using Proprioceptive Measurements](https://arxiv.org/abs/2510.19101)
*Matthew Jiang,Shipeng Liu,Feifei Qian*

Main category: cs.RO

TL;DR: SAEGT是一个用于腿式机器人在未知颗粒地形中安全探索的导航框架，通过本体感知估计地形可通行性，使用高斯过程回归和反应式控制器实现实时安全探索。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人虽然能通过力交互感知地形，但在高度可变形或不稳定地形中仍面临挑战，特别是在视觉输入无法捕捉地形变形性的情况下。

Method: 使用高斯过程回归从腿-地形交互中在线估计安全区域和边界区域，结合反应式控制器进行实时安全探索和导航。

Result: 在仿真中，SAEGT仅使用本体感知估计的可通行性就能安全探索并导航到指定目标。

Conclusion: SAEGT框架能够有效解决腿式机器人在未知颗粒地形中的安全探索问题，特别适用于视觉感知失效的场景。

Abstract: Legged robots can sense terrain through force interactions during locomotion,
offering more reliable traversability estimates than remote sensing and serving
as scouts for guiding wheeled rovers in challenging environments. However, even
legged scouts face challenges when traversing highly deformable or unstable
terrain. We present Safe Active Exploration for Granular Terrain (SAEGT), a
navigation framework that enables legged robots to safely explore unknown
granular environments using proprioceptive sensing, particularly where visual
input fails to capture terrain deformability. SAEGT estimates the safe region
and frontier region online from leg-terrain interactions using Gaussian Process
regression for traversability assessment, with a reactive controller for
real-time safe exploration and navigation. SAEGT demonstrated its ability to
safely explore and navigate toward a specified goal using only proprioceptively
estimated traversability in simulation.

</details>


### [11] [A Cross-Environment and Cross-Embodiment Path Planning Framework via a Conditional Diffusion Model](https://arxiv.org/abs/2510.19128)
*Mehran Ghafarian Tamizi,Homayoun Honari,Amir Mehdi Soufi Enayati,Aleksey Nozdryn-Plotnicki,Homayoun Najjaran*

Main category: cs.RO

TL;DR: GADGET是一个基于扩散模型的路径规划框架，能够在新环境和不同机器人上实现零样本迁移，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 解决高维杂乱环境中机器人路径规划的计算效率、安全性和适应性不足的问题。传统方法计算时间长且需要大量参数调优，而现有学习方法泛化能力有限。

Method: 提出GADGET模型，使用扩散模型生成关节空间轨迹，结合体素化场景表示和起点-目标配置。采用混合双条件机制，将无分类器引导与基于控制屏障函数的安全整形相结合。

Result: 在球形障碍物、箱内拾取和货架环境中实现高成功率且碰撞强度低，CBF引导进一步提高了安全性。在Franka Panda、Kinova Gen3和UR5机器人上展示了良好的可迁移性。

Conclusion: GADGET框架能够有效生成安全、无碰撞的轨迹，支持零样本迁移到新环境和不同机器人硬件，在真实环境中表现出色。

Abstract: Path planning for a robotic system in high-dimensional cluttered environments
needs to be efficient, safe, and adaptable for different environments and
hardware. Conventional methods face high computation time and require extensive
parameter tuning, while prior learning-based methods still fail to generalize
effectively. The primary goal of this research is to develop a path planning
framework capable of generalizing to unseen environments and new robotic
manipulators without the need for retraining. We present GADGET (Generalizable
and Adaptive Diffusion-Guided Environment-aware Trajectory generation), a
diffusion-based planning model that generates joint-space trajectories
conditioned on voxelized scene representations as well as start and goal
configurations. A key innovation is GADGET's hybrid dual-conditioning mechanism
that combines classifier-free guidance via learned scene encoding with
classifier-guided Control Barrier Function (CBF) safety shaping, integrating
environment awareness with real-time collision avoidance directly in the
denoising process. This design supports zero-shot transfer to new environments
and robotic embodiments without retraining. Experimental results show that
GADGET achieves high success rates with low collision intensity in
spherical-obstacle, bin-picking, and shelf environments, with CBF guidance
further improving safety. Moreover, comparative evaluations indicate strong
performance relative to both sampling-based and learning-based baselines.
Furthermore, GADGET provides transferability across Franka Panda, Kinova Gen3
(6/7-DoF), and UR5 robots, and physical execution on a Kinova Gen3 demonstrates
its ability to generate safe, collision-free trajectories in real-world
settings.

</details>


### [12] [GRASPLAT: Enabling dexterous grasping through novel view synthesis](https://arxiv.org/abs/2510.19200)
*Matteo Bortolon,Nuno Ferreira Duarte,Plinio Moreno,Fabio Poiesi,José Santos-Victor,Alessio Del Bue*

Main category: cs.RO

TL;DR: GRASPLAT是一种新颖的抓取框架，仅使用RGB图像训练，通过3D高斯泼溅生成手-物体交互的高保真新视图，实现端到端训练，显著提升抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖完整3D扫描来预测抓取姿势，但在真实场景中获取高质量3D数据困难，因此需要仅使用RGB图像就能实现灵巧抓取的方法。

Method: 利用3D高斯泼溅合成手抓取物体的物理合理图像，回归对应的手关节位置；引入光度损失来最小化渲染图像与真实图像之间的差异，优化抓取预测。

Result: 在合成和真实世界抓取数据集上的广泛实验表明，GRASPLAT相比现有基于图像的方法，抓取成功率提升高达36.9%。

Conclusion: GRASPLAT证明了仅使用RGB图像就能有效学习灵巧抓取，无需依赖难以获取的3D扫描数据，为实际应用提供了可行解决方案。

Abstract: Achieving dexterous robotic grasping with multi-fingered hands remains a
significant challenge. While existing methods rely on complete 3D scans to
predict grasp poses, these approaches face limitations due to the difficulty of
acquiring high-quality 3D data in real-world scenarios. In this paper, we
introduce GRASPLAT, a novel grasping framework that leverages consistent 3D
information while being trained solely on RGB images. Our key insight is that
by synthesizing physically plausible images of a hand grasping an object, we
can regress the corresponding hand joints for a successful grasp. To achieve
this, we utilize 3D Gaussian Splatting to generate high-fidelity novel views of
real hand-object interactions, enabling end-to-end training with RGB data.
Unlike prior methods, our approach incorporates a photometric loss that refines
grasp predictions by minimizing discrepancies between rendered and real images.
We conduct extensive experiments on both synthetic and real-world grasping
datasets, demonstrating that GRASPLAT improves grasp success rates up to 36.9%
over existing image-based methods. Project page:
https://mbortolon97.github.io/grasplat/

</details>


### [13] [Hierarchical DLO Routing with Reinforcement Learning and In-Context Vision-language Models](https://arxiv.org/abs/2510.19268)
*Mingen Li,Houjian Yu,Yixuan Huang,Youngjin Hong,Changhyun Choi*

Main category: cs.RO

TL;DR: 提出了一种用于可变形线性物体长时程路由任务的自主分层框架，结合视觉语言模型进行高层推理和强化学习技能执行，在复杂场景中达到92.5%的成功率。


<details>
  <summary>Details</summary>
Motivation: 解决可变形线性物体（如电缆、绳索）在工业装配线和日常生活中的长时程路由任务挑战，这些任务需要适应非线性动力学、分解抽象路由目标并生成多步骤计划。

Method: 使用分层框架：利用视觉语言模型进行上下文高层推理合成可行计划，通过强化学习训练的低层技能执行计划，并引入故障恢复机制重新定向物体状态。

Result: 在长时程路由场景中总体成功率92.5%，比次优基线方法提升近50%，能够泛化到涉及物体属性、空间描述和隐式语言命令的多样化场景。

Conclusion: 提出的分层框架成功解决了可变形线性物体的复杂路由任务，结合高层推理和低层技能执行，实现了高成功率和强泛化能力。

Abstract: Long-horizon routing tasks of deformable linear objects (DLOs), such as
cables and ropes, are common in industrial assembly lines and everyday life.
These tasks are particularly challenging because they require robots to
manipulate DLO with long-horizon planning and reliable skill execution.
Successfully completing such tasks demands adapting to their nonlinear
dynamics, decomposing abstract routing goals, and generating multi-step plans
composed of multiple skills, all of which require accurate high-level reasoning
during execution. In this paper, we propose a fully autonomous hierarchical
framework for solving challenging DLO routing tasks. Given an implicit or
explicit routing goal expressed in language, our framework leverages
vision-language models~(VLMs) for in-context high-level reasoning to synthesize
feasible plans, which are then executed by low-level skills trained via
reinforcement learning. To improve robustness in long horizons, we further
introduce a failure recovery mechanism that reorients the DLO into
insertion-feasible states. Our approach generalizes to diverse scenes involving
object attributes, spatial descriptions, as well as implicit language commands.
It outperforms the next best baseline method by nearly 50% and achieves an
overall success rate of 92.5% across long-horizon routing scenarios.

</details>


### [14] [TARMAC: A Taxonomy for Robot Manipulation in Chemistry](https://arxiv.org/abs/2510.19289)
*Kefeng Huang,Jonathon Pipe,Alice E. Martin,Tianyuan Wang,Barnabas A. Franklin,Andy M. Tyrrell,Ian J. S. Fairlamb,Jihong Zhu*

Main category: cs.RO

TL;DR: 提出了TARMAC框架，一个用于化学实验室机器人操作的分类法，旨在解决现有系统缺乏结构化操作技能表示的问题，支持技能复用和可扩展的自动化工作流。


<details>
  <summary>Details</summary>
Motivation: 现有化学实验室自动化系统仍依赖频繁人工干预，缺乏对机器人操作技能的系统化描述，限制了自主性和技能迁移能力。

Method: 基于标注的教学实验室演示，开发了TARMAC分类法，按功能角色和物理执行要求对操作进行分类，可实例化为机器人可执行原语并组合成高级宏。

Result: TARMAC提供了一个结构化的操作技能基础框架，支持技能复用和可扩展集成到长期工作流中。

Conclusion: TARMAC为更灵活和自主的实验室自动化提供了结构化基础，有助于减少人工依赖并提高系统自主性。

Abstract: Chemistry laboratory automation aims to increase throughput, reproducibility,
and safety, yet many existing systems still depend on frequent human
intervention. Advances in robotics have reduced this dependency, but without a
structured representation of the required skills, autonomy remains limited to
bespoke, task-specific solutions with little capacity to transfer beyond their
initial design. Current experiment abstractions typically describe
protocol-level steps without specifying the robotic actions needed to execute
them. This highlights the lack of a systematic account of the manipulation
skills required for robots in chemistry laboratories. To address this gap, we
introduce TARMAC - a Taxonomy for Robot Manipulation in Chemistry - a
domain-specific framework that defines and organizes the core manipulations
needed in laboratory practice. Based on annotated teaching-lab demonstrations
and supported by experimental validation, TARMAC categorizes actions according
to their functional role and physical execution requirements. Beyond serving as
a descriptive vocabulary, TARMAC can be instantiated as robot-executable
primitives and composed into higher-level macros, enabling skill reuse and
supporting scalable integration into long-horizon workflows. These
contributions provide a structured foundation for more flexible and autonomous
laboratory automation. More information is available at
https://tarmac-paper.github.io/

</details>


### [15] [Imitation Learning Policy based on Multi-Step Consistent Integration Shortcut Model](https://arxiv.org/abs/2510.19356)
*Yu Fang,Xinyu Wang,Xuehe Zhang,Wanli Xue,Mingwei Zhang,Shengyong Chen,Jie Zhao*

Main category: cs.RO

TL;DR: 提出一种用于机器人模仿学习的一步捷径方法，通过多步集成平衡推理速度与性能，解决了流匹配方法推理时间高的问题。


<details>
  <summary>Details</summary>
Motivation: 流匹配方法在机器人模仿学习中应用广泛，但面临推理时间高的问题。现有的蒸馏方法和一致性方法在性能上难以与原始扩散模型和流匹配模型竞争。

Method: 在捷径模型基础上扩展多步一致性损失，将一步损失拆分为多步损失；提出自适应梯度分配方法解决多步损失和原始流匹配损失的不稳定优化问题。

Result: 在两个仿真基准和五个真实环境任务中评估，实验结果验证了所提算法的有效性。

Conclusion: 该方法在保持快速推理的同时提升了性能，解决了流匹配方法在机器人模仿学习中的推理效率问题。

Abstract: The wide application of flow-matching methods has greatly promoted the
development of robot imitation learning. However, these methods all face the
problem of high inference time. To address this issue, researchers have
proposed distillation methods and consistency methods, but the performance of
these methods still struggles to compete with that of the original diffusion
models and flow-matching models. In this article, we propose a one-step
shortcut method with multi-step integration for robot imitation learning. To
balance the inference speed and performance, we extend the multi-step
consistency loss on the basis of the shortcut model, split the one-step loss
into multi-step losses, and improve the performance of one-step inference.
Secondly, to solve the problem of unstable optimization of the multi-step loss
and the original flow-matching loss, we propose an adaptive gradient allocation
method to enhance the stability of the learning process. Finally, we evaluate
the proposed method in two simulation benchmarks and five real-world
environment tasks. The experimental results verify the effectiveness of the
proposed algorithm.

</details>


### [16] [ProTerrain: Probabilistic Physics-Informed Rough Terrain World Modeling](https://arxiv.org/abs/2510.19364)
*Golnaz Raja,Ruslan Agishev,Miloš Prágr,Joni Pajarinen,Karel Zimmermann,Arun Kumar Singh,Reza Ghabcheloo*

Main category: cs.RO

TL;DR: 提出了一种高效的概率框架，用于在非结构化越野环境中进行不确定性感知的机器人运动预测，通过建模空间相关的偶然不确定性并通过可微分物理引擎传播，显著提高了不确定性估计和轨迹预测精度。


<details>
  <summary>Details</summary>
Motivation: 在非结构化越野环境中，地形异质性强且感知不确定性高，现有方法通常假设确定性或空间独立的terrain不确定性，忽略了3D空间数据固有的局部相关性，导致预测不可靠。

Method: 引入概率框架，将空间相关的偶然不确定性建模为概率世界模型，并通过可微分物理引擎传播这种不确定性进行概率轨迹预测，利用结构化卷积算子以可管理计算成本提供高分辨率多变量预测。

Result: 在公开数据集上的实验评估显示，与偶然不确定性估计基线相比，该方法在不确定性估计和轨迹预测精度方面有显著提升。

Conclusion: 该概率框架能够有效建模和传播空间相关的terrain不确定性，为下游的可穿越性估计和自主导航安全提供了更可靠的预测。

Abstract: Uncertainty-aware robot motion prediction is crucial for downstream
traversability estimation and safe autonomous navigation in unstructured,
off-road environments, where terrain is heterogeneous and perceptual
uncertainty is high. Most existing methods assume deterministic or spatially
independent terrain uncertainties, ignoring the inherent local correlations of
3D spatial data and often producing unreliable predictions. In this work, we
introduce an efficient probabilistic framework that explicitly models spatially
correlated aleatoric uncertainty over terrain parameters as a probabilistic
world model and propagates this uncertainty through a differentiable physics
engine for probabilistic trajectory forecasting. By leveraging structured
convolutional operators, our approach provides high-resolution multivariate
predictions at manageable computational cost. Experimental evaluation on a
publicly available dataset shows significantly improved uncertainty estimation
and trajectory prediction accuracy over aleatoric uncertainty estimation
baselines.

</details>


### [17] [Using Temperature Sampling to Effectively Train Robot Learning Policies on Imbalanced Datasets](https://arxiv.org/abs/2510.19373)
*Basavasagar Patil,Sydney Belt,Jayjun Lee,Nima Fazeli,Bernadette Bucher*

Main category: cs.RO

TL;DR: 提出一种简单的采样策略来解决机器人任务数据集中物理动作不平衡的问题，只需几行代码即可集成到现有代码库中，提高模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人任务数据集虽然任务描述不同，但许多涉及相似的物理动作序列，导致数据集在物理机器人动作表示上严重不平衡。

Method: 提出一种简单的采样策略，在策略训练时缓解这种不平衡，可以轻松集成到现有代码库中。

Result: 在预训练小模型和微调大型基础模型中都取得显著改进，在低资源任务上相比现有最先进方法有大幅提升，且不影响高资源任务性能。

Conclusion: 该方法能更有效地利用多任务策略的模型容量，并在真实机器人设置中得到验证。

Abstract: Increasingly large datasets of robot actions and sensory observations are
being collected to train ever-larger neural networks. These datasets are
collected based on tasks and while these tasks may be distinct in their
descriptions, many involve very similar physical action sequences (e.g., 'pick
up an apple' versus 'pick up an orange'). As a result, many datasets of robotic
tasks are substantially imbalanced in terms of the physical robotic actions
they represent. In this work, we propose a simple sampling strategy for policy
training that mitigates this imbalance. Our method requires only a few lines of
code to integrate into existing codebases and improves generalization. We
evaluate our method in both pre-training small models and fine-tuning large
foundational models. Our results show substantial improvements on low-resource
tasks compared to prior state-of-the-art methods, without degrading performance
on high-resource tasks. This enables more effective use of model capacity for
multi-task policies. We also further validate our approach in a real-world
setup on a Franka Panda robot arm across a diverse set of tasks.

</details>


### [18] [Risk Assessment of an Autonomous Underwater Snake Robot in Confined Operations](https://arxiv.org/abs/2510.19415)
*Abdelrahman Sayed Sayed*

Main category: cs.RO

TL;DR: 提出一种贝叶斯方法来评估鳗鱼形水下机器人在两种任务场景中的丢失风险，旨在提高任务成功率


<details>
  <summary>Details</summary>
Motivation: 海洋探测需求增长，需要在受限环境中进行检测和干预。鳗鱼形机器人的细长形状和可变形能力适合此类环境，但面临不确定环境、极端条件和导航能力受限等挑战

Method: 采用贝叶斯方法来评估机器人丢失风险，并进行敏感性分析

Result: 通过敏感性分析识别出对机器人丢失影响最大的因素

Conclusion: 该贝叶斯风险评估方法有助于提高鳗鱼形水下机器人的性能和任务成功率

Abstract: The growing interest in ocean discovery imposes a need for inspection and
intervention in confined and demanding environments. Eely's slender shape, in
addition to its ability to change its body configurations, makes articulated
underwater robots an adequate option for such environments. However, operation
of Eely in such environments imposes demanding requirements on the system, as
it must deal with uncertain and unstructured environments, extreme
environmental conditions, and reduced navigational capabilities. This paper
proposes a Bayesian approach to assess the risks of losing Eely during two
mission scenarios. The goal of this work is to improve Eely's performance and
the likelihood of mission success. Sensitivity analysis results are presented
in order to demonstrate the causes having the highest impact on losing Eely.

</details>


### [19] [GigaBrain-0: A World Model-Powered Vision-Language-Action Model](https://arxiv.org/abs/2510.19430)
*GigaBrain Team,Angen Ye,Boyuan Wang,Chaojun Ni,Guan Huang,Guosheng Zhao,Haoyun Li,Jie Li,Jiagang Zhu,Lv Feng,Peng Li,Qiuping Deng,Runqi Ouyang,Wenkang Qin,Xinze Chen,Xiaofeng Wang,Yang Wang,Yifan Li,Yilong Li,Yiran Ding,Yuan Xu,Yun Ye,Yukun Zhou,Zhehao Dong,Zhenan Wang,Zhichao Liu,Zheng Zhu*

Main category: cs.RO

TL;DR: GigaBrain-0是一个创新的视觉-语言-动作基础模型，通过世界模型生成数据来减少对真实机器人数据的依赖，同时提升跨任务泛化能力和策略鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决视觉-语言-动作模型训练需要大规模真实机器人数据的问题，这些数据收集成本高且耗时，限制了VLA系统的可扩展性和泛化能力。

Method: 利用世界模型生成多样化数据（视频生成、真实到真实转换、人类转换、视角转换、仿真到真实转换），采用RGBD输入建模和具身思维链监督来增强策略鲁棒性。

Result: 在灵巧操作、长视野任务和移动操作任务上实现显著性能提升，在外观、物体放置和相机视角变化方面表现出优异的泛化能力。

Conclusion: GigaBrain-0通过世界模型生成数据有效解决了真实数据收集瓶颈，同时开发了轻量级变体GigaBrain-0-Small以适应边缘设备部署。

Abstract: Training Vision-Language-Action (VLA) models for generalist robots typically
requires large-scale real-world robot data, which is expensive and
time-consuming to collect. The inefficiency of physical data collection
severely limits the scalability, and generalization capacity of current VLA
systems. To address this challenge, we introduce GigaBrain-0, a novel VLA
foundation model empowered by world model-generated data (e.g., video
generation, real2real transfer, human transfer, view transfer, sim2real
transfer data). By leveraging world models to generate diverse data at scale,
GigaBrain-0 significantly reduces reliance on real robot data while improving
cross-task generalization. Our approach further improves policy robustness
through RGBD input modeling and embodied Chain-of-Thought (CoT) supervision,
enabling the model to reason about spatial geometry, object states, and
long-horizon dependencies during task execution. This leads to substantial
gains in real-world performance on dexterous, long-horizon, and mobile
manipulation tasks. Extensive experiments demonstrate that GigaBrain-0 achieves
superior generalization across variations in appearances (e.g., textures,
colors), object placements, and camera viewpoints. Additionally, we present
GigaBrain-0-Small, an optimized lightweight variant designed to run efficiently
on devices such as the NVIDIA Jetson AGX Orin.

</details>


### [20] [Using Non-Expert Data to Robustify Imitation Learning via Offline Reinforcement Learning](https://arxiv.org/abs/2510.19495)
*Kevin Huang,Rosario Scalise,Cleah Winston,Ayush Agrawal,Yunchu Zhang,Rohan Baijal,Markus Grotz,Byron Boots,Benjamin Burchfiel,Hongkai Dai,Masha Itkina,Paarth Shah,Abhishek Gupta*

Main category: cs.RO

TL;DR: 提出使用离线强化学习来利用非专家数据增强模仿学习策略性能的方法，通过简单的算法修改在稀疏数据覆盖下有效利用非专家数据，显著提升了策略的恢复能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 模仿学习依赖高质量、任务特定的专家数据，限制了在多样化现实世界场景中的适应性。非专家数据（如游戏数据、次优演示等）具有更广覆盖范围和更低收集成本，但传统模仿学习方法无法有效利用这些数据。

Method: 采用离线强化学习作为工具来利用非专家数据，通过简单的算法修改（如扩大策略分布的支持范围），在稀疏数据覆盖条件下有效利用非专家数据，无需额外假设。

Result: 在操作任务中，该方法显著扩大了学习策略成功的初始条件范围，能够利用包括部分或次优演示在内的所有收集数据来提升任务导向策略性能，表现出显著增强的恢复和泛化行为。

Conclusion: 这些方法强调了利用非专家数据的算法技术对于机器人稳健策略学习的重要性，展示了离线强化学习在增强模仿学习性能方面的潜力。

Abstract: Imitation learning has proven effective for training robots to perform
complex tasks from expert human demonstrations. However, it remains limited by
its reliance on high-quality, task-specific data, restricting adaptability to
the diverse range of real-world object configurations and scenarios. In
contrast, non-expert data -- such as play data, suboptimal demonstrations,
partial task completions, or rollouts from suboptimal policies -- can offer
broader coverage and lower collection costs. However, conventional imitation
learning approaches fail to utilize this data effectively. To address these
challenges, we posit that with right design decisions, offline reinforcement
learning can be used as a tool to harness non-expert data to enhance the
performance of imitation learning policies. We show that while standard offline
RL approaches can be ineffective at actually leveraging non-expert data under
the sparse data coverage settings typically encountered in the real world,
simple algorithmic modifications can allow for the utilization of this data,
without significant additional assumptions. Our approach shows that broadening
the support of the policy distribution can allow imitation algorithms augmented
by offline RL to solve tasks robustly, showing considerably enhanced recovery
and generalization behavior. In manipulation tasks, these innovations
significantly increase the range of initial conditions where learned policies
are successful when non-expert data is incorporated. Moreover, we show that
these methods are able to leverage all collected data, including partial or
suboptimal demonstrations, to bolster task-directed policy performance. This
underscores the importance of algorithmic techniques for using non-expert data
for robust policy learning in robotics.

</details>


### [21] [Optimizing Prosthetic Wrist Movement: A Model Predictive Control Approach](https://arxiv.org/abs/2510.19541)
*Francesco Schetter,Shifa Sulaiman,Shoby George,Paolino De Risi,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 本研究在肌腱驱动假手上实现模型预测控制(MPC)策略，用于调节软连续腕部运动，以较低计算成本提升假手适应性和性能。


<details>
  <summary>Details</summary>
Motivation: 将先进控制策略集成到假手中对于提高其适应性和性能至关重要，MPC在增强假手功能和响应性方面发挥关键作用。

Method: 使用欧拉-伯努利梁方法进行运动学建模，拉格朗日方法进行动力学建模，实施模型预测控制策略来调节软连续腕部运动。

Result: 通过仿真和实验验证，证明MPC在优化腕部关节运动和用户控制方面的有效性，显著提高假手灵活性，使运动更自然直观。

Conclusion: 这项研究为智能假肢系统提供了一个有前景的方向，对机器人学和生物医学工程领域做出贡献。

Abstract: The integration of advanced control strategies into prosthetic hands is
essential to improve their adaptability and performance. In this study, we
present an implementation of a Model Predictive Control (MPC) strategy to
regulate the motions of a soft continuum wrist section attached to a
tendon-driven prosthetic hand with less computational effort. MPC plays a
crucial role in enhancing the functionality and responsiveness of prosthetic
hands. By leveraging predictive modeling, this approach enables precise
movement adjustments while accounting for dynamic user interactions. This
advanced control strategy allows for the anticipation of future movements and
adjustments based on the current state of the prosthetic device and the
intentions of the user. Kinematic and dynamic modelings are performed using
Euler-Bernoulli beam and Lagrange methods respectively. Through simulation and
experimental validations, we demonstrate the effectiveness of MPC in optimizing
wrist articulation and user control. Our findings suggest that this technique
significantly improves the prosthetic hand dexterity, making movements more
natural and intuitive. This research contributes to the field of robotics and
biomedical engineering by offering a promising direction for intelligent
prosthetic systems.

</details>


### [22] [LaViRA: Language-Vision-Robot Actions Translation for Zero-Shot Vision Language Navigation in Continuous Environments](https://arxiv.org/abs/2510.19655)
*Hongyu Ding,Ziming Xu,Yudong Fang,You Wu,Zixuan Chen,Jieqi Shi,Jing Huo,Yifan Zhang,Yang Gao*

Main category: cs.RO

TL;DR: LaViRA是一个零样本视觉语言导航框架，通过语言-视觉-机器人三层动作分解，利用不同规模多模态大语言模型的优势，在未见环境中实现高效导航。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在环境特定路径点预测器与大型模型推理能力利用之间的权衡问题，提升在连续环境中的零样本导航性能。

Method: 提出粗到细的动作层次分解：语言动作用于高层规划，视觉动作用于感知接地，机器人动作用于鲁棒导航，利用不同规模MLLMs的优势。

Result: 在VLN-CE基准测试中显著优于现有最先进方法，在未见环境中展现出优越的泛化能力。

Conclusion: LaViRA框架通过模块化分解有效解决了零样本视觉语言导航中的关键权衡问题，兼具推理能力、接地能力和实际控制能力。

Abstract: Zero-shot Vision-and-Language Navigation in Continuous Environments (VLN-CE)
requires an agent to navigate unseen environments based on natural language
instructions without any prior training. Current methods face a critical
trade-off: either rely on environment-specific waypoint predictors that limit
scene generalization, or underutilize the reasoning capabilities of large
models during navigation. We introduce LaViRA, a simple yet effective zero-shot
framework that addresses this dilemma by decomposing action into a
coarse-to-fine hierarchy: Language Action for high-level planning, Vision
Action for perceptual grounding, and Robot Action for robust navigation. This
modular decomposition allows us to leverage the distinct strengths of different
scales of Multimodal Large Language Models (MLLMs) at each stage, creating a
system that is powerful in its reasoning, grounding and practical control.
LaViRA significantly outperforms existing state-of-the-art methods on the
VLN-CE benchmark, demonstrating superior generalization capabilities in unseen
environments, while maintaining transparency and efficiency for real-world
deployment.

</details>


### [23] [Fast Marker Detection for UV-Based Visual Relative Localisation in Agile UAV Swarms](https://arxiv.org/abs/2510.19663)
*Vojtěch Vrba,Viktor Walter,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种用于无人机群视觉相对定位的快速机载孤立标记检测方法，包含CPU优化、GPU着色器程序和FPGA流架构三种创新方案，处理速度比现有技术快2-3个数量级。


<details>
  <summary>Details</summary>
Motivation: 为敏捷无人机群的实时定位系统提供快速机载检测解决方案，满足低端无人机和微型飞行器的应用需求。

Method: 开发了三种功能等效的架构：CPU优化程序、GPU着色器程序和FPGA流架构，用于快速检测视觉相对定位中的孤立标记。

Result: CPU和GPU解决方案的处理速度比现有技术快2-3个数量级，FPGA架构在从相机曝光到检测结果的总延迟方面提供了最显著的加速效果。

Conclusion: 该方法已成为敏捷无人机群的关键使能技术，在各种32位和64位嵌入式平台上验证了其效率和可行性。

Abstract: A novel approach for the fast onboard detection of isolated markers for
visual relative localisation of multiple teammates in agile UAV swarms is
introduced in this paper. As the detection forms a key component of real-time
localisation systems, a three-fold innovation is presented, consisting of an
optimised procedure for CPUs, a GPU shader program, and a functionally
equivalent FPGA streaming architecture. For the proposed CPU and GPU solutions,
the mean processing time per pixel of input camera frames was accelerated by
two to three orders of magnitude compared to the state of the art. For the
localisation task, the proposed FPGA architecture offered the most significant
overall acceleration by minimising the total delay from camera exposure to
detection results. Additionally, the proposed solutions were evaluated on
various 32-bit and 64-bit embedded platforms to demonstrate their efficiency,
as well as their feasibility for applications using low-end UAVs and MAVs.
Thus, it has become a crucial enabling technology for agile UAV swarming.

</details>


### [24] [Learning Affordances at Inference-Time for Vision-Language-Action Models](https://arxiv.org/abs/2510.19752)
*Ameesh Shah,William Chen,Adwait Godbole,Federico Mora,Sanjit A. Seshia,Sergey Levine*

Main category: cs.RO

TL;DR: LITEN方法通过连接低层VLA策略与高层VLM，在推理时从执行经验中学习，通过迭代规划和评估阶段来改进机器人任务执行能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型缺乏在任务失败时动态调整行为的能力，无法像人类一样从错误中学习并改进策略。

Method: LITEN连接低层VLA策略与高层VLM，通过迭代的推理阶段（生成和执行计划）和评估阶段（反思执行结果并提取有用结论）来学习。

Result: 实验结果表明LITEN能够有效从过去经验中学习，生成使用高可用性指令来完成长视野任务的计划。

Conclusion: LITEN提供了一种在非结构化真实世界机器人轨迹中进行自我优化的有效方法，通过上下文学习改进了机器人任务执行能力。

Abstract: Solving complex real-world control tasks often takes multiple tries: if we
fail at first, we reflect on what went wrong, and change our strategy
accordingly to avoid making the same mistake. In robotics,
Vision-Language-Action models (VLAs) offer a promising path towards solving
complex control tasks, but lack the ability to contextually and dynamically
readjust behavior when they fail to accomplish a task. In this work, we
introduce Learning from Inference-Time Execution (LITEN), which connects a VLA
low-level policy to a high-level VLM that conditions on past experiences by
including them in-context, allowing it to learn the affordances and
capabilities of the low-level VLA. Our approach iterates between a reasoning
phase that generates and executes plans for the low-level VLA, and an
assessment phase that reflects on the resulting execution and draws useful
conclusions to be included in future reasoning contexts. Unlike similar
approaches to self-refinement in non-robotics domains, LITEN must reflect on
unstructured real-world robot trajectories (e.g., raw videos), which requires
structured guiderails during assessment. Our experimental results demonstrate
LITEN is able to effectively learn from past experience to generate plans that
use high-affordance instructions to accomplish long-horizon tasks.

</details>


### [25] [SEA: Semantic Map Prediction for Active Exploration of Uncertain Areas](https://arxiv.org/abs/2510.19766)
*Hongyu Ding,Xinyue Liang,Yudong Fang,You Wu,Jieqi Shi,Jing Huo,Wenbin Li,Jing Wu,Yu-Kun Lai,Yang Gao*

Main category: cs.RO

TL;DR: SEA是一种通过语义地图预测和强化学习分层探索策略的主动机器人探索方法，通过迭代预测-探索框架和新型奖励机制，在有限步数内构建准确语义地图。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法依赖单步路径点预测，缺乏对环境长期理解，导致探索效率不高。

Method: 提出迭代预测-探索框架，基于当前观测预测地图缺失区域，使用实际累积地图与预测全局地图的差异指导探索，并设计基于强化学习的奖励机制更新长期探索策略。

Result: 实验结果表明，该方法在相同时间限制下显著优于现有最先进的探索策略，获得更优的全局地图覆盖范围。

Conclusion: SEA方法通过增强智能体对环境长期理解，实现了更高效的探索，在语义地图构建方面表现出色。

Abstract: In this paper, we propose SEA, a novel approach for active robot exploration
through semantic map prediction and a reinforcement learning-based hierarchical
exploration policy. Unlike existing learning-based methods that rely on
one-step waypoint prediction, our approach enhances the agent's long-term
environmental understanding to facilitate more efficient exploration. We
propose an iterative prediction-exploration framework that explicitly predicts
the missing areas of the map based on current observations. The difference
between the actual accumulated map and the predicted global map is then used to
guide exploration. Additionally, we design a novel reward mechanism that
leverages reinforcement learning to update the long-term exploration
strategies, enabling us to construct an accurate semantic map within limited
steps. Experimental results demonstrate that our method significantly
outperforms state-of-the-art exploration strategies, achieving superior
coverage ares of the global map within the same time constraints.

</details>
