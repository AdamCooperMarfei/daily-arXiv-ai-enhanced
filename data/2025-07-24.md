<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 38]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Summarizing Normative Driving Behavior From Large-Scale NDS Datasets for Vehicle System Development](https://arxiv.org/abs/2507.16839)
*Gregory Beale,Gibran Ali*

Main category: cs.RO

TL;DR: 本研究开发了一套方法论来处理大规模自然驾驶研究数据，分析五个关键驾驶指标（速度、超速、车道保持、跟车距离和车头时距），并考虑道路特征、车辆类型和驾驶员人口统计学特征的影响，为车辆安全和智能交通系统开发提供支持。


<details>
  <summary>Details</summary>
Motivation: 现有的车辆安全系统和智能交通系统开发需要对正常驾驶行为有准确的量化描述，但缺乏处理大规模自然驾驶研究数据的系统性方法论来分析不同群体间的驾驶行为差异。

Method: 使用SHRP 2自然驾驶研究数据（包含3400多名驾驶员的3400万英里驾驶数据），结合车辆、GPS和前向雷达数据，开发数据处理方法论来生成五个驾驶指标的汇总统计。同时开发交互式在线分析工具，通过动态数据选择和分组来可视化和比较不同群体的驾驶行为。

Result: 研究发现在65英里/小时道路上，16-19岁女性驾驶员超速7.5-15英里/小时的频率略高于同龄男性；年轻驾驶员保持1.5秒以下车头时距的频率高于年长驾驶员。成功开发了可进行跨群体比较的NDS数据集分析方法论。

Conclusion: 该研究通过量化正常驾驶行为，为开发更好的车辆系统和更安全的基础设施提供了支持，并为分析自然驾驶研究数据集进行跨群体比较提供了有效的方法论。

Abstract: This paper presents a methodology to process large-scale naturalistic driving
studies (NDS) to describe the driving behavior for five vehicle metrics,
including speed, speeding, lane keeping, following distance, and headway,
contextualized by roadway characteristics, vehicle classes, and driver
demographics. Such descriptions of normative driving behaviors can aid in the
development of vehicle safety and intelligent transportation systems. The
methodology is demonstrated using data from the Second Strategic Highway
Research Program (SHRP 2) NDS, which includes over 34 million miles of driving
across more than 3,400 drivers. Summaries of each driving metric were generated
using vehicle, GPS, and forward radar data. Additionally, interactive online
analytics tools were developed to visualize and compare driving behavior across
groups through dynamic data selection and grouping. For example, among drivers
on 65-mph roads for the SHRP 2 NDS, females aged 16-19 exceeded the speed limit
by 7.5 to 15 mph slightly more often than their male counterparts, and younger
drivers maintained headways under 1.5 seconds more frequently than older
drivers. This work supports better vehicle systems and safer infrastructure by
quantifying normative driving behaviors and offers a methodology for analyzing
NDS datasets for cross group comparisons.

</details>


### [2] [AquaChat: An LLM-Guided ROV Framework for Adaptive Inspection of Aquaculture Net Pens](https://arxiv.org/abs/2507.16841)
*Waseem Akram,Muhayy Ud Din,Abdelhaleem Saad,Irfan Hussain*

Main category: cs.RO

TL;DR: 本研究提出了AquaChat，一个集成大语言模型的智能水下机器人框架，用于水产养殖网箱检查，通过自然语言交互实现自适应任务规划和执行。


<details>
  <summary>Details</summary>
Motivation: 传统的水产养殖网箱检查方法依赖预编程任务或人工控制，对动态水下环境和用户特定需求的适应性有限，需要更智能和灵活的检查系统来维护结构完整性、生物安全性和运营效率。

Method: 设计了多层架构的AquaChat框架：(1)高层规划层使用大语言模型解释自然语言用户命令并生成符号任务计划；(2)中层任务管理器将计划转换为ROV控制序列；(3)低层运动控制层精确执行导航和检查任务。系统具备实时反馈和事件触发重规划功能。

Result: 在模拟和受控水环境中进行验证实验，结果显示系统在任务灵活性、检查准确性和运营效率方面都有显著改善，证明了框架在具有挑战性的水产养殖环境中的鲁棒性。

Conclusion: AquaChat展示了将基于语言的人工智能与海洋机器人技术集成的潜力，能够为可持续水产养殖运营提供智能的、用户交互式的检查系统，为水产养殖行业的自动化和智能化发展提供了新的解决方案。

Abstract: Inspection of aquaculture net pens is essential for maintaining the
structural integrity, biosecurity, and operational efficiency of fish farming
systems. Traditional inspection approaches rely on pre-programmed missions or
manual control, offering limited adaptability to dynamic underwater conditions
and user-specific demands. In this study, we propose AquaChat, a novel Remotely
Operated Vehicle (ROV) framework that integrates Large Language Models (LLMs)
for intelligent and adaptive net pen inspection. The system features a
multi-layered architecture: (1) a high-level planning layer that interprets
natural language user commands using an LLM to generate symbolic task plans;
(2) a mid-level task manager that translates plans into ROV control sequences;
and (3) a low-level motion control layer that executes navigation and
inspection tasks with precision. Real-time feedback and event-triggered
replanning enhance robustness in challenging aquaculture environments. The
framework is validated through experiments in both simulated and controlled
aquatic environments representative of aquaculture net pens. Results
demonstrate improved task flexibility, inspection accuracy, and operational
efficiency. AquaChat illustrates the potential of integrating language-based AI
with marine robotics to enable intelligent, user-interactive inspection systems
for sustainable aquaculture operations.

</details>


### [3] [Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning](https://arxiv.org/abs/2507.16842)
*Yinan Meng,Kun Qian,Jiong Yang,Renbo Su,Zhenhong Li,Charlie C. L. Wang*

Main category: cs.RO

TL;DR: 本文提出了一种传感器空间模仿学习运动学控制（SS-ILKC）框架，用于解决冗余软体机械臂在执行器饱和和受限环境约束下的鲁棒运动学控制问题。


<details>
  <summary>Details</summary>
Motivation: 冗余软体机械臂虽然具有内在柔顺性和高自由度优势，但在未知外载荷变形和受限环境中容易出现执行器饱和问题，导致有效的运动学控制极具挑战性。

Method: 采用双学习策略：基于强化学习原理的多目标传感器空间控制框架（用于开放空间），以及基于生成对抗模仿学习的方法（用于受限空间的稀疏专家演示学习）。同时提出预处理的仿真到现实转移机制来缓解仿真现实差距。

Result: 实验结果表明该方法能够有效控制气动软体机械臂，在未知载荷条件下的受限环境中实现精确的路径跟踪和物体操作。

Conclusion: SS-ILKC框架成功解决了软体机械臂在执行器饱和和环境约束下的运动学控制问题，实现了零样本现实世界部署，为软体机器人的实际应用提供了有效解决方案。

Abstract: The intrinsic compliance and high degree of freedom (DoF) of redundant soft
manipulators facilitate safe interaction and flexible task execution. However,
effective kinematic control remains highly challenging, as it must handle
deformations caused by unknown external loads and avoid actuator saturation due
to improper null-space regulation - particularly in confined environments. In
this paper, we propose a Sensor-Space Imitation Learning Kinematic Control
(SS-ILKC) framework to enable robust kinematic control under actuator
saturation and restrictive environmental constraints. We employ a dual-learning
strategy: a multi-goal sensor-space control framework based on reinforcement
learning principle is trained in simulation to develop robust control policies
for open spaces, while a generative adversarial imitation learning approach
enables effective policy learning from sparse expert demonstrations for
confined spaces. To enable zero-shot real-world deployment, a pre-processed
sim-to-real transfer mechanism is proposed to mitigate the
simulation-to-reality gap and accurately characterize actuator saturation
limits. Experimental results demonstrate that our method can effectively
control a pneumatically actuated soft manipulator, achieving precise
path-following and object manipulation in confined environments under unknown
loading conditions.

</details>


### [4] [Analytical Formulation of Autonomous Vehicle Freeway Merging Control with State-Dependent Discharge Rates](https://arxiv.org/abs/2507.16846)
*Qing Tang,Xianbiao Hu*

Main category: cs.RO

TL;DR: 本文提出了一种自动驾驶车辆高速公路汇合控制的动态规划方法，通过解析推导有效排放率并建立碰撞风险函数，实现延误和安全风险的联合优化


<details>
  <summary>Details</summary>
Motivation: 传统排队模型忽略了交叉交通对汇合点流量的影响，现有基础图未能准确反映拥堵期间流量下降的现象，需要开发更准确的自动驾驶车辆汇合控制方法来提高交通效率和安全性

Method: 首次解析推导多阶段动态汇合过程中的有效排放率闭式表达式；建立碰撞风险函数量化汇合过程中的潜在碰撞；将问题表述为动态规划模型，以汇合位置和速度为决策变量，采用后向归纳法求解最小成本方案

Result: 使用NGSIM数据集验证了推导的有效排放率；提出的模型在性能上优于两种基准算法；实现了更高效、更安全的汇合过程

Conclusion: 本文成功建立了考虑多阶段动态汇合过程的解析模型，通过动态规划方法实现了交通延误和碰撞风险的联合优化，为自动驾驶车辆高速公路汇合控制提供了新的理论框架和实用解决方案

Abstract: The core of the freeway merging control problem lies in dynamic queue
propagation and dissipation linked to merging vehicle behavior. Traditionally,
queuing is modeled through demand-supply interactions with time varying demand
and fixed capacity. However, field observations show flow rates decrease during
congestion at freeway merges due to the impact of intersecting traffic, a
factor overlooked in fundamental diagrams. This manuscript introduces an
analytical approach to characterize and control the dynamic multi-stage merging
of autonomous vehicles, prioritizing traffic efficiency and safety. For the
first time, the effective discharge rate at the merging point, reduced by the
multi-stage dynamic merging process, is analytically derived using a closed
form formulation. Leveraging this expression, performance metrics such as queue
length and traffic delay are derived as the first objective. Additionally, a
crash risk function is established to quantitatively assess potential
collisions during the merging process, serving as the second objective.
Finally, the problem is formulated as a dynamic programming model to jointly
minimize delay and crash risk, with the merging location and speed as decision
variables. Given the terminal state, the ramp vehicle merging task is
formulated as a recursive optimization problem, employing backward induction to
find the minimum cost solution. Numerical experiments using the NGSIM dataset
validate the derived effective discharge rate. The results indicate that the
proposed model outperforms two benchmark algorithms, leading to a more
efficient and safer merging process.

</details>


### [5] [MobileUse: A GUI Agent with Hierarchical Reflection for Autonomous Mobile Operation](https://arxiv.org/abs/2507.16853)
*Ning Li,Xiangmou Qu,Jiamu Zhou,Jun Wang,Muning Wen,Kounianhua Du,Xingyu Lou,Qiuying Peng,Jun Wang,Weinan Zhang*

Main category: cs.RO

TL;DR: 本文提出了MobileUse，一个用于移动设备任务自动化的GUI智能体，通过分层反思架构和主动探索模块解决了长期任务执行、错误恢复和冷启动问题，在AndroidWorld和AndroidLab基准测试中取得了最先进的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型虽然能够理解视觉输入并遵循用户指令，但在实际移动场景中应用时面临长期任务执行、错误恢复困难以及在陌生环境中的冷启动问题等重大挑战。

Method: 提出MobileUse GUI智能体，包含两个核心模块：1）分层反思架构 - 使智能体能够在多个时间尺度上进行自我监控、错误检测和恢复，并通过按需反思策略保持效率；2）主动探索模块 - 通过自主规划的探索来丰富智能体对环境的理解，解决冷启动问题。

Result: 在AndroidWorld和AndroidLab基准测试中建立了新的最先进性能，成功率分别达到62.9%和44.2%。同时发布了用于物理移动设备自动化任务执行的开箱即用工具包。

Conclusion: MobileUse通过分层反思架构和主动探索模块有效解决了移动智能体在实际应用中的关键挑战，在基准测试中取得显著性能提升，为移动设备任务自动化提供了实用的解决方案。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled the
development of mobile agents that can understand visual inputs and follow user
instructions, unlocking new possibilities for automating complex tasks on
mobile devices. However, applying these models to real-world mobile scenarios
remains a significant challenge due to the long-horizon task execution,
difficulty in error recovery, and the cold-start problem in unfamiliar
environments. To address these challenges, we propose MobileUse, a GUI agent
designed for robust and adaptive mobile task execution. To improve resilience
in long-horizon tasks and dynamic environments, we introduce a hierarchical
reflection architecture that enables the agent to self-monitor, detect, and
recover from errors across multiple temporal scales-ranging from individual
actions to overall task completion-while maintaining efficiency through a
reflection-on-demand strategy. To tackle cold-start issues, we further
introduce a proactive exploration module, which enriches the agent's
understanding of the environment through self-planned exploration. Evaluations
on AndroidWorld and AndroidLab benchmarks demonstrate that MobileUse
establishes new state-of-the-art performance, achieving success rates of 62.9%
and 44.2%, respectively. To facilitate real-world applications, we release an
out-of-the-box toolkit for automated task execution on physical mobile devices,
which is available at https://github.com/MadeAgents/mobile-use.

</details>


### [6] [Leveraging multi-source and heterogeneous signals for fatigue detection](https://arxiv.org/abs/2507.16859)
*Luobin Cui,Yanlai Wu,Tang Ying,Weikai Li*

Main category: cs.RO

TL;DR: 本文提出了一个异构多源疲劳检测框架，能够在传感器受限的真实场景中有效监测疲劳状态，通过利用不同源域的知识来提升目标域的检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有疲劳检测方法主要依赖高端传感器和受控环境，在真实世界应用中存在局限性。需要开发能够在传感器受限的实际场景中进行有效疲劳监测的方法，同时能够利用来自不同传感器配置的源域知识。

Method: 提出了一个异构多源疲劳检测框架，该框架能够自适应地利用目标域中的可用模态，同时从具有不同配置的源域中获益。框架可以处理不同传感器设置之间的差异，实现知识迁移。

Result: 在使用实际部署的传感器设置和两个公开数据集进行的实验中，该方法展现了实用性、鲁棒性和改进的泛化能力，证明了在传感器受限场景下进行有效疲劳监测的可行性。

Conclusion: 该研究为在传感器受限的真实场景中进行有效疲劳监测铺平了实用道路，通过异构多源学习框架成功解决了实际应用中的传感器配置差异问题。

Abstract: Fatigue detection plays a critical role in safety-critical applications such
as aviation, mining, and long-haul transport. However, most existing methods
rely on high-end sensors and controlled environments, limiting their
applicability in real world settings. This paper formally defines a practical
yet underexplored problem setting for real world fatigue detection, where
systems operating with context-appropriate sensors aim to leverage knowledge
from differently instrumented sources including those using impractical sensors
deployed in controlled environments. To tackle this challenge, we propose a
heterogeneous and multi-source fatigue detection framework that adaptively
utilizes the available modalities in the target domain while benefiting from
the diverse configurations present in source domains. Our experiments,
conducted using a realistic field-deployed sensor setup and two publicly
available datasets, demonstrate the practicality, robustness, and improved
generalization of our approach, paving the practical way for effective fatigue
monitoring in sensor-constrained scenarios.

</details>


### [7] [ResKACNNet: A Residual ChebyKAN Network for Inertial Odometry](https://arxiv.org/abs/2507.16865)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Huiru Zheng,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出了一种基于ResChebyKAN骨干网络和高效核自注意力模块的惯性定位方法，通过切比雪夫多项式建模复杂运动模式，在多个公开数据集上显著降低了轨迹误差


<details>
  <summary>Details</summary>
Motivation: 传统基于CNN的惯性定位方法难以捕获IMU数据中的非线性运动特征和长期依赖关系，需要开发能够更好处理复杂运动模式的新方法

Method: 提出ResChebyKAN通用骨干网络，利用切比雪夫多项式的非线性逼近能力建模复杂运动模式；引入高效核自注意力(EKSA)模块捕获上下文信息并增强长期依赖建模

Result: 在RIDI、RoNIN、RNIN-VIO、OxIOD、IMUNet和TLIO等公开数据集上，相比现有基准方法，绝对轨迹误差降低了3.79%到42.32%；从加速度数据中去除重力分量可显著提升惯性定位性能

Conclusion: 所提出的基于ResChebyKAN和EKSA的惯性定位网络能够有效建模IMU数据的非线性特征和长期依赖，在多个数据集上实现了显著的性能提升，为低成本精确定位提供了新的解决方案

Abstract: Inertial Measurement Unit (IMU) has become a key technology for achieving
low-cost and precise positioning. However, traditional CNN-based inertial
positioning methods struggle to capture the nonlinear motion characteristics
and long-term dependencies in IMU data. To address this limitation, we propose
a novel inertial positioning network with a generic backbone called
ResChebyKAN, which leverages the nonlinear approximation capabilities of
Chebyshev polynomials to model complex motion patterns. Additionally, we
introduce an Efficient Kernel-based Self-Attention (EKSA) module to effectively
capture contextual information and enhance long-term dependency modeling.
Experimental results on public datasets (e.g., RIDI, RoNIN, RNIN-VIO, OxIOD,
IMUNet, and TLIO) demonstrate that our method reduces the absolute trajectory
error by 3.79% to 42.32% compared to existing benchmark methods. Furthermore,
we release a preprocessed dataset and empirically show that removing the
gravity component from acceleration data significantly improves inertial
positioning performance.

</details>


### [8] [Multi-agent Reinforcement Learning for Robotized Coral Reef Sample Collection](https://arxiv.org/abs/2507.16941)
*Daniel Correa,Tero Kaarlela,Jose Fuentes,Paulo Padrao,Alain Duran,Leonardo Bobadilla*

Main category: cs.RO

TL;DR: 本文提出了一个强化学习环境来开发自主水下机器人珊瑚采样智能体，通过软件在环和硬件在环方法，使用数字孪生在仿真中训练RL控制器并在物理实验中验证，结合通用游戏引擎、深度强化学习和实时水下动作捕捉系统实现了有效的零样本仿真到现实转移。


<details>
  <summary>Details</summary>
Motivation: 珊瑚礁保护和研究中需要自主水下机器人进行珊瑚采样，这是一个关键任务。传统方法难以在复杂水下环境中实现精确的自主采样操作，需要开发能够从仿真环境无缝转移到真实环境的智能控制系统。

Method: 采用强化学习方法训练水下机器人控制器，使用软件在环(SIL)和硬件在环(HIL)技术，构建数字孪生模型进行仿真训练，结合通用游戏引擎进行环境建模，利用水下动作捕捉(MOCAP)系统提供实时3D位置和姿态反馈，实现数字域和物理域之间的精确同步。

Result: 成功开发了能够进行珊瑚采样的自主水下机器人AI控制器，通过数字孪生仿真训练后在物理实验中得到验证，实现了从仿真到现实的零样本转移，水下动作捕捉系统提供了精确的实时反馈用于验证测试。

Conclusion: 该研究证明了结合通用游戏引擎仿真、深度强化学习和实时水下动作捕捉技术能够有效实现零样本仿真到现实转移策略，为水下机器人自主珊瑚采样任务提供了新颖且有效的解决方案，对珊瑚礁保护和研究具有重要意义。

Abstract: This paper presents a reinforcement learning (RL) environment for developing
an autonomous underwater robotic coral sampling agent, a crucial coral reef
conservation and research task. Using software-in-the-loop (SIL) and
hardware-in-the-loop (HIL), an RL-trained artificial intelligence (AI)
controller is developed using a digital twin (DT) in simulation and
subsequently verified in physical experiments. An underwater motion capture
(MOCAP) system provides real-time 3D position and orientation feedback during
verification testing for precise synchronization between the digital and
physical domains. A key novelty of this approach is the combined use of a
general-purpose game engine for simulation, deep RL, and real-time underwater
motion capture for an effective zero-shot sim-to-real strategy.

</details>


### [9] [RAPTAR: Radar Radiation Pattern Acquisition through Automated Collaborative Robotics](https://arxiv.org/abs/2507.16988)
*Maaz Qureshi,Mohammad Omid Bagheri,Abdelrahman Elbadrawy,William Melek,George Shaker*

Main category: cs.RO

TL;DR: 研究提出了RAPTAR系统，这是一个基于协作机器人的便携式自动化系统，用于测量集成雷达模块的3D辐射方向图，无需专用消声室设施


<details>
  <summary>Details</summary>
Motivation: 现有的片上天线表征技术存在局限性：角度覆盖有限、依赖定制硬件、需要频繁手动对准。传统测量设置在车辆、无人机、AR/VR头显和生物医学设备等真实世界配置中不实用

Method: 开发了RAPTAR（通过机器人自动化获取辐射方向图）系统，使用7自由度Franka协作机器人持有接收探头，在半球形空间域内进行无碰撞操作，配备实时运动规划和校准功能，RMS误差低于0.9毫米

Result: 系统实现了高达2.5度的角度分辨率，与RF仪器无缝集成进行近场和远场功率测量。对60 GHz雷达模块的实验扫描显示，与全波电磁仿真真值相比，平均绝对误差小于2 dB。与基准方法相比，平均绝对误差降低了36.5%

Conclusion: RAPTAR系统成功解决了现代片上天线表征的挑战，提供了便携式、高精度、可重复的3D辐射方向图测量解决方案，特别适用于各种实际应用场景中的集成雷达模块测试

Abstract: Accurate characterization of modern on-chip antennas remains challenging, as
current probe-station techniques offer limited angular coverage, rely on
bespoke hardware, and require frequent manual alignment. This research
introduces RAPTAR (Radiation Pattern Acquisition through Robotic Automation), a
portable, state-of-the-art, and autonomous system based on collaborative
robotics. RAPTAR enables 3D radiation-pattern measurement of integrated radar
modules without dedicated anechoic facilities. The system is designed to
address the challenges of testing radar modules mounted in diverse real-world
configurations, including vehicles, UAVs, AR/VR headsets, and biomedical
devices, where traditional measurement setups are impractical. A
7-degree-of-freedom Franka cobot holds the receiver probe and performs
collision-free manipulation across a hemispherical spatial domain, guided by
real-time motion planning and calibration accuracy with RMS error below 0.9 mm.
The system achieves an angular resolution upto 2.5 degree and integrates
seamlessly with RF instrumentation for near- and far-field power measurements.
Experimental scans of a 60 GHz radar module show a mean absolute error of less
than 2 dB compared to full-wave electromagnetic simulations ground truth.
Benchmarking against baseline method demonstrates 36.5% lower mean absolute
error, highlighting RAPTAR accuracy and repeatability.

</details>


### [10] [Shared Control of Holonomic Wheelchairs through Reinforcement Learning](https://arxiv.org/abs/2507.17055)
*Jannis Bähler,Diego Paez-Granados,Jorge Peña-Queralta*

Main category: cs.RO

TL;DR: 本文提出了一种基于强化学习的智能电动轮椅共享控制方法，通过2D用户输入生成3D运动控制，在确保安全导航的同时提升用户舒适度并降低认知负荷，并实现了首个全向移动平台的RL共享控制真实世界应用。


<details>
  <summary>Details</summary>
Motivation: 现有的全向系统共享控制方法往往导致用户体验不直观，且未能充分利用全向驾驶的潜力。针对非完整约束机器人的共享控制虽然在提升导航安全性方面显示出潜力，但对于全向系统仍存在局限性，需要开发更适合全向移动平台的智能控制方法。

Method: 采用强化学习方法，接收2D用户输入并输出3D运动控制。在Isaac Gym中训练RL智能体，在Gazebo中进行仿真测试。比较不同的RL智能体架构和奖励函数，基于认知负荷和用户舒适度指标进行评估。最后进行仿真到现实的迁移实验。

Result: 实验结果表明该方法能够确保无碰撞导航，同时智能地调整轮椅方向，相比之前的非学习方法显示出更好或具有竞争力的平滑性表现。成功实现了仿真到现实的迁移，并完成了全向移动平台RL共享控制的首次真实世界实现。

Conclusion: 本研究成功开发了基于强化学习的全向电动轮椅共享控制系统，有效提升了用户体验，降低了认知负荷，并实现了安全高效的导航。这是首个在真实世界中实现的全向移动平台RL共享控制系统，为智能轮椅技术发展提供了重要贡献。

Abstract: Smart electric wheelchairs can improve user experience by supporting the
driver with shared control. State-of-the-art work showed the potential of
shared control in improving safety in navigation for non-holonomic robots.
However, for holonomic systems, current approaches often lead to unintuitive
behavior for the user and fail to utilize the full potential of omnidirectional
driving. Therefore, we propose a reinforcement learning-based method, which
takes a 2D user input and outputs a 3D motion while ensuring user comfort and
reducing cognitive load on the driver. Our approach is trained in Isaac Gym and
tested in simulation in Gazebo. We compare different RL agent architectures and
reward functions based on metrics considering cognitive load and user comfort.
We show that our method ensures collision-free navigation while smartly
orienting the wheelchair and showing better or competitive smoothness compared
to a previous non-learning-based method. We further perform a sim-to-real
transfer and demonstrate, to the best of our knowledge, the first real-world
implementation of RL-based shared control for an omnidirectional mobility
platform.

</details>


### [11] [Deformable Cluster Manipulation via Whole-Arm Policy Learning](https://arxiv.org/abs/2507.17085)
*Jayadeep Jacob,Wenzheng Zhang,Houston Warren,Paulo Borges,Tirthankar Bandyopadhyay,Fabio Ramos*

Main category: cs.RO

TL;DR: 提出了一个结合3D点云和本体感觉触觉指示器的无模型强化学习框架，用于操控可变形物体集群，特别是电力线路清障任务，实现了从仿真到现实的零样本策略迁移。


<details>
  <summary>Details</summary>
Motivation: 可变形物体集群操控面临诸多挑战：现实模型合成能力有限、感知不确定性高、缺乏高效的空间抽象等。传统的末端执行器操控模式无法满足需要全臂接触交互的复杂任务需求。

Method: 开发了一个无模型强化学习框架，集成3D点云和本体感觉触觉指示器两种模态；采用分布式状态表示和核均值嵌入技术提高训练效率；提出了上下文无关的遮挡启发式算法用于清除目标区域的可变形物体；强调全身接触感知的操控策略。

Result: 在电力线路清障场景中，智能体能够创造性地利用多个手臂链节进行去遮挡操作；实现了零样本仿真到现实的策略迁移，成功清除具有未知遮挡模式、未见拓扑结构和不确定动力学的真实树枝。

Conclusion: 该框架成功解决了可变形物体集群操控的关键挑战，通过多模态感知和分布式状态表示实现了高效学习，并在实际应用中展现了良好的泛化能力和鲁棒性。

Abstract: Manipulating clusters of deformable objects presents a substantial challenge
with widespread applicability, but requires contact-rich whole-arm
interactions. A potential solution must address the limited capacity for
realistic model synthesis, high uncertainty in perception, and the lack of
efficient spatial abstractions, among others. We propose a novel framework for
learning model-free policies integrating two modalities: 3D point clouds and
proprioceptive touch indicators, emphasising manipulation with full body
contact awareness, going beyond traditional end-effector modes. Our
reinforcement learning framework leverages a distributional state
representation, aided by kernel mean embeddings, to achieve improved training
efficiency and real-time inference. Furthermore, we propose a novel
context-agnostic occlusion heuristic to clear deformables from a target region
for exposure tasks. We deploy the framework in a power line clearance scenario
and observe that the agent generates creative strategies leveraging multiple
arm links for de-occlusion. Finally, we perform zero-shot sim-to-real policy
transfer, allowing the arm to clear real branches with unknown occlusion
patterns, unseen topology, and uncertain dynamics.

</details>


### [12] [MARSCalib: Multi-robot, Automatic, Robust, Spherical Target-based Extrinsic Calibration in Field and Extraterrestrial Environments](https://arxiv.org/abs/2507.17130)
*Seokhwan Jeong,Hogyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 本文提出了一种基于球形目标的LiDAR-相机外参标定方法，适用于多机器人系统的户外环境，能够处理目标和传感器损坏情况。


<details>
  <summary>Details</summary>
Motivation: 现有的LiDAR-相机标定方法在户外多机器人系统中面临目标和传感器损坏的挑战，需要一种鲁棒的标定方法来处理这些实际应用中的问题。

Method: 从图像中提取2D椭圆中心，从点云中提取3D球体中心，然后配对计算变换矩阵。使用SAM模型分解图像，提出新算法从损坏球体中提取椭圆并纠正透视投影误差。对于LiDAR点云，应用分层加权求和处理噪声点云以准确提取球体。

Result: 实验证明该方法在两种损坏情况下都能鲁棒检测球体，性能优于其他目标。在三种不同类型的LiDAR（旋转式、固态和非重复式）和三个不同位置的相机上进行了评估，并在行星测试和野外环境中验证了对目标损坏的鲁棒性。

Conclusion: 提出的球形目标标定方法在处理目标和传感器损坏方面表现出色，为户外多机器人系统的LiDAR-相机标定提供了可靠的解决方案，具有良好的实用性和鲁棒性。

Abstract: This paper presents a novel spherical target-based LiDAR-camera extrinsic
calibration method designed for outdoor environments with multi-robot systems,
considering both target and sensor corruption. The method extracts the 2D
ellipse center from the image and the 3D sphere center from the pointcloud,
which are then paired to compute the transformation matrix. Specifically, the
image is first decomposed using the Segment Anything Model (SAM). Then, a novel
algorithm extracts an ellipse from a potentially corrupted sphere, and the
extracted center of ellipse is corrected for errors caused by the perspective
projection model. For the LiDAR pointcloud, points on the sphere tend to be
highly noisy due to the absence of flat regions. To accurately extract the
sphere from these noisy measurements, we apply a hierarchical weighted sum to
the accumulated pointcloud. Through experiments, we demonstrated that the
sphere can be robustly detected even under both types of corruption,
outperforming other targets. We evaluated our method using three different
types of LiDARs (spinning, solid-state, and non-repetitive) with cameras
positioned in three different locations. Furthermore, we validated the
robustness of our method to target corruption by experimenting with spheres
subjected to various types of degradation. These experiments were conducted in
both a planetary test and a field environment. Our code is available at
https://github.com/sparolab/MARSCalib.

</details>


### [13] [Dynamic Modeling and Dimensional Optimization of Legged Mechanisms for Construction Robot](https://arxiv.org/abs/2507.17132)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文基于蚂蚁腿部结构设计建筑机器人腿部，提出新的结构优化方法，通过拉格朗日动力学建模和几何参数优化，实现了关节扭矩和能耗降低超过20%的显著效果。


<details>
  <summary>Details</summary>
Motivation: 随着建筑行业快速发展，恶劣工作环境、高强度高风险任务和劳动力短缺问题日益突出，迫切需要开发低能耗、高机动性和高负载能力的建筑机器人来解决这些挑战。

Method: 首先基于自然界蚂蚁的腿部构型设计机器人腿部结构；然后提出新颖的结构优化方法，使用拉格朗日方法建立腿部动力学模型；结合动力学模型和腿部运动轨迹，制定多个动态评估指标，对各腿段几何参数进行综合优化研究。

Result: 优化后的腿部结构使峰值关节扭矩和能耗降低超过20%；ADAMS动力学仿真实验显示优化后各关节驱动功率显著降低，验证了所提策略的有效性和合理性。

Conclusion: 本研究为重载、高性能建筑机器人的设计提供了理论基础和技术支撑，所提出的仿生腿部结构设计和优化方法能够有效提升建筑机器人的动态性能、降低能耗并增强承载能力。

Abstract: With the rapid development of the construction industry, issues such as harsh
working environments, high-intensity and high-risk tasks, and labor shortages
have become increasingly prominent. This drives higher demands for construction
robots in terms of low energy consumption, high mobility, and high load
capacity. This paper focuses on the design and optimization of leg structures
for construction robots, aiming to improve their dynamic performance, reduce
energy consumption, and enhance load-bearing capabilities. Firstly, based on
the leg configuration of ants in nature, we design a structure for the robot's
leg. Secondly, we propose a novel structural optimization method. Using the
Lagrangian approach, a dynamic model of the leg was established. Combining the
dynamic model with the leg's motion trajectory, we formulated multiple dynamic
evaluation metrics and conducted a comprehensive optimization study on the
geometric parameters of each leg segment. The results show that the optimized
leg structure reduces peak joint torques and energy consumption by over 20%.
Finally, dynamic simulation experiments were conducted using ADAMS. The results
demonstrate a significant reduction in the driving power of each joint after
optimization, validating the effectiveness and rationality of the proposed
strategy. This study provides a theoretical foundation and technical support
for the design of heavy-load, high-performance construction robots.

</details>


### [14] [Dynamic Parameter Identification of a Curtain Wall Installation Robotic Arm](https://arxiv.org/abs/2507.17136)
*Xiao Liu,Yunxiao Cheng,Weijun Wang,Tianlun Huang,Wei Feng*

Main category: cs.RO

TL;DR: 本文针对幕墙安装设计了液压驱动机械臂，并提出了动态参数识别方法，通过D-H模型和Stribeck摩擦模型构建复合参数系统，采用分层递进参数识别策略实现高精度动态参数识别，提升幕墙安装智能化水平。


<details>
  <summary>Details</summary>
Motivation: 传统建筑施工方法无法满足现代对效率和质量的需求，幕墙安装作为建筑项目的关键组成部分，需要提升其智能化水平。因此需要设计专用的液压驱动机械臂并开发相应的动态参数识别方法。

Method: 建立基于测量机械臂结构参数的D-H模型，集成液压缸动力学构建由Stribeck摩擦模型驱动的复合参数系统；设计高信噪比位移激励信号，结合傅里叶级数构建满足关节约束的最优激励轨迹；提出分层递进参数识别策略，采用最小二乘估计分别识别和联合标定液压缸和机械臂的动态参数。

Result: 实验验证显示理论与测量关节扭矩之间的残差标准偏差低于0.4 Nm，确认了液压驱动幕墙安装机械臂的高精度动态参数识别效果，获得了各关节的Stribeck模型曲线。

Conclusion: 研究成功实现了液压驱动幕墙安装机械臂的高精度动态参数识别，为提升幕墙安装作业的智能化水平做出了重要贡献，为建筑行业自动化发展提供了技术支撑。

Abstract: In the construction industry, traditional methods fail to meet the modern
demands for efficiency and quality. The curtain wall installation is a critical
component of construction projects. We design a hydraulically driven robotic
arm for curtain wall installation and a dynamic parameter identification
method. We establish a Denavit-Hartenberg (D-H) model based on measured robotic
arm structural parameters and integrate hydraulic cylinder dynamics to
construct a composite parametric system driven by a Stribeck friction model. By
designing high-signal-to-noise ratio displacement excitation signals for
hydraulic cylinders and combining Fourier series to construct optimal
excitation trajectories that satisfy joint constraints, this method effectively
excites the characteristics of each parameter in the minimal parameter set of
the dynamic model of the robotic arm. On this basis, a hierarchical progressive
parameter identification strategy is proposed: least squares estimation is
employed to separately identify and jointly calibrate the dynamic parameters of
both the hydraulic cylinder and the robotic arm, yielding Stribeck model curves
for each joint. Experimental validation on a robotic arm platform demonstrates
residual standard deviations below 0.4 Nm between theoretical and measured
joint torques, confirming high-precision dynamic parameter identification for
the hydraulic-driven curtain wall installation robotic arm. This significantly
contributes to enhancing the intelligence level of curtain wall installation
operations.

</details>


### [15] [Multi-Objective Trajectory Planning for a Robotic Arm in Curtain Wall Installation](https://arxiv.org/abs/2507.17140)
*Xiao Liu,Yunxiao Cheng,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 针对幕墙安装机器人在复杂施工环境中的多目标轨迹优化问题，提出了NSGA-III-FO算法，通过集成串联、并联和折叠臂元素设计机械臂，并引入焦点算子筛选机制加速算法收敛，实验验证了该方法在幕墙安装任务中的高效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 在劳动力短缺和成本上升的背景下，建筑机器人被视为革新传统建筑方法、提高建筑行业效率和质量的关键。然而，传统的单目标轨迹优化方法难以满足复杂多变的施工环境要求，需要开发能够在复杂施工环境中高效准确执行任务的多目标轨迹优化方法。

Method: 设计了一种集成串联、并联和折叠臂元素的幕墙安装机械臂，并提出了NSGA-III-FO算法（带焦点算子的NSGA-III）。该算法通过引入焦点算子筛选机制来加速算法向帕累托前沿的收敛，从而有效平衡建筑机器人的多目标约束。

Result: 在DTLZ3和WFG3测试函数上进行十次连续试验，NSGA-III-FO算法与NSGA-III、MOEA/D和MSOPS-II相比显示出明显更好的收敛效率。在设计的机械臂平台上进行的两组实验证实了NSGA-III-FO算法在解决幕墙安装任务多目标轨迹规划问题方面的效率和实用性。

Conclusion: NSGA-III-FO算法能够有效解决幕墙安装机器人的多目标轨迹优化问题，在复杂施工环境中表现出良好的收敛效率和实用性，为建筑机器人在幕墙安装等复杂任务中的应用提供了有效的技术解决方案。

Abstract: In the context of labor shortages and rising costs, construction robots are
regarded as the key to revolutionizing traditional construction methods and
improving efficiency and quality in the construction industry. In order to
ensure that construction robots can perform tasks efficiently and accurately in
complex construction environments, traditional single-objective trajectory
optimization methods are difficult to meet the complex requirements of the
changing construction environment. Therefore, we propose a multi-objective
trajectory optimization for the robotic arm used in the curtain wall
installation. First, we design a robotic arm for curtain wall installation,
integrating serial, parallel, and folding arm elements, while considering its
physical properties and motion characteristics. In addition, this paper
proposes an NSGA-III-FO algorithm (NSGA-III with Focused Operator, NSGA-III-FO)
that incorporates a focus operator screening mechanism to accelerate the
convergence of the algorithm towards the Pareto front, thereby effectively
balancing the multi-objective constraints of construction robots. The proposed
algorithm is tested against NSGA-III, MOEA/D, and MSOPS-II in ten consecutive
trials on the DTLZ3 and WFG3 test functions, showing significantly better
convergence efficiency than the other algorithms. Finally, we conduct two sets
of experiments on the designed robotic arm platform, which confirm the
efficiency and practicality of the NSGA-III-FO algorithm in solving
multi-objective trajectory planning problems for curtain wall installation
tasks.

</details>


### [16] [Towards Human-level Intelligence via Human-like Whole-Body Manipulation](https://arxiv.org/abs/2507.17141)
*Guang Gao,Jianan Wang,Jinbo Zuo,Junnan Jiang,Jingfan Zhang,Xianwen Zeng,Yuejiang Zhu,Lianyang Ma,Ke Chen,Minhua Sheng,Ruirui Zhang,Zhaohui An*

Main category: cs.RO

TL;DR: Astribot Suite是一个全身机器人操作学习套件，通过模仿人类行为和持续环境交互来构建通用智能机器人，集成了安全硬件设计、直观遥操作界面和全身视觉运动策略学习算法。


<details>
  <summary>Details</summary>
Motivation: 构建通用智能机器人是机器人学的基本目标，需要通过模仿人类进化轨迹来实现——通过持续的环境交互学习，早期进展由模仿人类行为驱动。这需要解决三个核心挑战：设计具有人类级别物理能力的安全机器人硬件、开发直观可扩展的全身遥操作数据收集界面、创建能够从人类演示中学习全身视觉运动策略的算法。

Method: 提出Astribot Suite统一框架，这是一个面向多样化环境中通用日常任务的全身操作机器人学习套件。该系统整合了三个关键组件：(1)具有人类级别物理能力的安全机器人硬件设计；(2)直观且可扩展的全身遥操作界面用于数据收集；(3)能够从人类演示中学习全身视觉运动策略的算法。

Result: 在需要全身协调、广泛可达性、人类级别灵巧性和敏捷性的广泛活动上验证了系统的有效性。Astribot通过具身设计、遥操作界面和学习管道的协同集成，在现实世界通用全身机器人操作方面取得了显著进展。

Conclusion: Astribot Suite的协同集成标志着在现实世界通用全身机器人操作方面迈出了重要一步，为下一代智能机器人奠定了基础。该系统成功解决了构建通用智能机器人的三个核心挑战，展现了从硬件到算法的完整解决方案的潜力。

Abstract: Building general-purpose intelligent robots has long been a fundamental goal
of robotics. A promising approach is to mirror the evolutionary trajectory of
humans: learning through continuous interaction with the environment, with
early progress driven by the imitation of human behaviors. Achieving this goal
presents three core challenges: (1) designing safe robotic hardware with
human-level physical capabilities; (2) developing an intuitive and scalable
whole-body teleoperation interface for data collection; and (3) creating
algorithms capable of learning whole-body visuomotor policies from human
demonstrations. To address these challenges in a unified framework, we propose
Astribot Suite, a robot learning suite for whole-body manipulation aimed at
general daily tasks across diverse environments. We demonstrate the
effectiveness of our system on a wide range of activities that require
whole-body coordination, extensive reachability, human-level dexterity, and
agility. Our results show that Astribot's cohesive integration of embodiment,
teleoperation interface, and learning pipeline marks a significant step towards
real-world, general-purpose whole-body robotic manipulation, laying the
groundwork for the next generation of intelligent robots.

</details>


### [17] [Falconry-like palm landing by a flapping-wing drone based on the human gesture interaction and distance-aware flight planning](https://arxiv.org/abs/2507.17144)
*Kazuki Numazato,Keiichiro Kan,Masaki Kitagawa,Yunong Li,Johannes Kubel,Moju Zhao*

Main category: cs.RO

TL;DR: 本研究首次实现了扑翼无人机与人类的接触式交互，开发了一个类似鹰猎的交互系统，让扑翼无人机能够安全地降落在人类手掌上。


<details>
  <summary>Details</summary>
Motivation: 扑翼无人机具有低噪音和柔性翼等特点，适合人机交互，但很少有研究探索人类与扑翼无人机的实际交互。受鹰猎者引导猛禽降落在手臂上的启发，将人体解释为动态着陆平台，可应用于拥挤或空间受限的环境。

Method: 设计了一个类似鹰猎的交互系统，其中扑翼无人机在人类手掌上执行掌上着陆动作。开发了考虑人类安全物理和心理因素（如无人机速度和与用户距离）的轨迹规划方法。使用商业扑翼平台实施运动规划并进行实验评估。

Result: 实验结果表明，该方法能够实现安全、平稳的手部着陆交互。成功验证了掌上着陆性能和安全性。

Conclusion: 这是首次实现扑翼无人机与人类之间基于接触的交互，为人机交互领域开辟了新的可能性，特别是在需要安全、灵活交互的应用场景中。

Abstract: Flapping-wing drones have attracted significant attention due to their
biomimetic flight. They are considered more human-friendly due to their
characteristics such as low noise and flexible wings, making them suitable for
human-drone interactions. However, few studies have explored the practical
interaction between humans and flapping-wing drones. On establishing a physical
interaction system with flapping-wing drones, we can acquire inspirations from
falconers who guide birds of prey to land on their arms. This interaction
interprets the human body as a dynamic landing platform, which can be utilized
in various scenarios such as crowded or spatially constrained environments.
Thus, in this study, we propose a falconry-like interaction system in which a
flapping-wing drone performs a palm landing motion on a human hand. To achieve
a safe approach toward humans, we design a trajectory planning method that
considers both physical and psychological factors of the human safety such as
the drone's velocity and distance from the user. We use a commercial flapping
platform with our implemented motion planning and conduct experiments to
evaluate the palm landing performance and safety. The results demonstrate that
our approach enables safe and smooth hand landing interactions. To the best of
our knowledge, it is the first time to achieve a contact-based interaction
between flapping-wing drones and humans.

</details>


### [18] [JAM: Keypoint-Guided Joint Prediction after Classification-Aware Marginal Proposal for Multi-Agent Interaction](https://arxiv.org/abs/2507.17152)
*Fangze Lin,Ying He,Fei Yu,Hong Zhang*

Main category: cs.RO

TL;DR: 本文提出了一个两阶段多智能体交互预测框架JAM，通过分类感知的边际提议和关键点引导的联合预测来解决自动驾驶中低概率模式生成质量差的问题，在Waymo数据集上取得了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中预测道路参与者未来运动是关键任务，但现有方法在多智能体联合预测中存在低概率模式生成质量差的挑战，需要提出更好的解决方案来改善这一问题。

Method: 提出了两阶段多智能体交互预测框架JAM：第一阶段为边际预测过程，按轨迹类型对查询进行分类以学习所有类别轨迹；第二阶段为联合预测过程，以场景上下文和第一阶段的边际提议为输入学习最终联合分布，并引入关键路径点来指导联合预测模块更好地捕获和利用初始预测轨迹的关键信息。

Result: 在真实世界Waymo开放运动数据集交互预测基准上进行了广泛实验，方法取得了具有竞争力的性能。在框架比较实验中，JAM超越了其他预测框架，在交互轨迹预测方面达到了最先进的性能。

Conclusion: 所提出的JAM框架有效解决了多智能体联合预测中低概率模式生成质量差的问题，通过两阶段设计和关键点引导机制实现了交互轨迹预测的最先进性能，为自动驾驶中的运动预测任务提供了有效解决方案。

Abstract: Predicting the future motion of road participants is a critical task in
autonomous driving. In this work, we address the challenge of low-quality
generation of low-probability modes in multi-agent joint prediction. To tackle
this issue, we propose a two-stage multi-agent interactive prediction framework
named \textit{keypoint-guided joint prediction after classification-aware
marginal proposal} (JAM). The first stage is modeled as a marginal prediction
process, which classifies queries by trajectory type to encourage the model to
learn all categories of trajectories, providing comprehensive mode information
for the joint prediction module. The second stage is modeled as a joint
prediction process, which takes the scene context and the marginal proposals
from the first stage as inputs to learn the final joint distribution. We
explicitly introduce key waypoints to guide the joint prediction module in
better capturing and leveraging the critical information from the initial
predicted trajectories. We conduct extensive experiments on the real-world
Waymo Open Motion Dataset interactive prediction benchmark. The results show
that our approach achieves competitive performance. In particular, in the
framework comparison experiments, the proposed JAM outperforms other prediction
frameworks and achieves state-of-the-art performance in interactive trajectory
prediction. The code is available at https://github.com/LinFunster/JAM to
facilitate future research.

</details>


### [19] [Reconfigurable Tendon-Driven Robots: Eliminating Inter-segmental Coupling via Independently Lockable Joints](https://arxiv.org/abs/2507.17163)
*Botao Lin,Shuang Song,Jiaole Wang*

Main category: cs.RO

TL;DR: 本文提出了一种配备创新可锁定关节的可重构腱驱动机器人(RTR)，通过选择性激活目标机器人段来消除段间耦合，简化控制复杂性，并在复杂环境中展现出优越的机动性和工作空间。


<details>
  <summary>Details</summary>
Motivation: 传统腱驱动机器人虽然具有大工作空间和高机动性，但增加机器人段数量会导致段间耦合加剧，需要更复杂的模型和额外的电机来实现精确控制，这成为了一个亟待解决的技术挑战。

Method: 设计了配备创新可锁定关节的可重构腱驱动机器人(RTR)，每个关节的状态(锁定/自由)可通过一对拮抗腱单独控制，结构设计无需持续供电来维持状态。操作员可以选择性地激活目标机器人段，从根本上消除段间耦合。

Result: 通过仿真比较了RTR与传统TDR的工作空间，验证了RTR的优势。建立了RTR的运动学和静力学模型，并进行了验证实验。使用七关节RTR原型进行了演示，仅用六个电机的执行器包就展现了其可重构性和在复杂环境中的运动能力。

Conclusion: 提出的可重构腱驱动机器人通过可锁定关节设计成功解决了传统腱驱动机器人的段间耦合问题，简化了控制复杂性，在保持大工作空间和高机动性的同时，实现了更高效的控制和更好的适应性。

Abstract: With a slender redundant body, the tendon-driven robot (TDR) has a large
workspace and great maneuverability while working in complex environments. TDR
comprises multiple independently controlled robot segments, each with a set of
driving tendons. While increasing the number of robot segments enhances
dexterity and expands the workspace, this structural expansion also introduces
intensified inter-segmental coupling. Therefore, achieving precise TDR control
requires more complex models and additional motors. This paper presents a
reconfigurable tendon-driven robot (RTR) equipped with innovative lockable
joints. Each joint's state (locked/free) can be individually controlled through
a pair of antagonistic tendons, and its structure eliminates the need for a
continuous power supply to maintain the state. Operators can selectively
actuate the targeted robot segments, and this scheme fundamentally eliminates
the inter-segmental coupling, thereby avoiding the requirement for complex
coordinated control between segments. The workspace of RTR has been simulated
and compared with traditional TDRs' workspace, and RTR's advantages are further
revealed. The kinematics and statics models of the RTR have been derived and
validation experiments have been conducted. Demonstrations have been performed
using a seven-joint RTR prototype to show its reconfigurability and moving
ability in complex environments with an actuator pack comprising only six
motors.

</details>


### [20] [FAST-Calib: LiDAR-Camera Extrinsic Calibration in One Second](https://arxiv.org/abs/2507.17210)
*Chunran Zheng,Fu Zhang*

Main category: cs.RO

TL;DR: 本文提出FAST-Calib，一种基于定制3D标靶的快速用户友好的LiDAR-相机外参标定工具，支持机械式和固态LiDAR，具有高精度和鲁棒性


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR-相机外参标定方法存在精度不足、处理速度慢、对不同LiDAR扫描模式适应性差等问题，需要开发一种快速、准确、用户友好的标定工具

Method: 基于定制3D标靶设计FAST-Calib工具，采用与LiDAR扫描模式无关的高效可靠边缘提取算法，通过椭圆拟合补偿LiDAR光斑扩散引起的边缘扩张伪影，支持多场景联合优化

Result: 在三种LiDAR模型(Ouster、Avia、Mid360)与广角相机的配对测试中，点对点配准误差始终低于6.5mm，总处理时间少于0.7秒，相比现有方法表现出更优的精度和鲁棒性

Conclusion: FAST-Calib提供了一个高效、准确、基于标靶的自动标定管道，代码和数据集已开源到GitHub，为机器人学社区提供了实用的标定工具

Abstract: This paper proposes FAST-Calib, a fast and user-friendly LiDAR-camera
extrinsic calibration tool based on a custom-made 3D target. FAST-Calib
supports both mechanical and solid-state LiDARs by leveraging an efficient and
reliable edge extraction algorithm that is agnostic to LiDAR scan patterns. It
also compensates for edge dilation artifacts caused by LiDAR spot spread
through ellipse fitting, and supports joint optimization across multiple
scenes. We validate FAST-Calib on three LiDAR models (Ouster, Avia, and
Mid360), each paired with a wide-angle camera. Experimental results demonstrate
superior accuracy and robustness compared to existing methods. With
point-to-point registration errors consistently below 6.5mm and total
processing time under 0.7s, FAST-Calib provides an efficient, accurate, and
target-based automatic calibration pipeline. We have open-sourced our code and
dataset on GitHub to benefit the robotics community.

</details>


### [21] [Optimizing Delivery Logistics: Enhancing Speed and Safety with Drone Technology](https://arxiv.org/abs/2507.17253)
*Maharshi Shastri,Ujjval Shrivastav*

Main category: cs.RO

TL;DR: 本研究开发了一个AI集成的无人机配送系统，结合YOLOv4 Tiny目标检测、GPS导航和实时通信技术，通过机器学习和IoT设备优化路线、提高安全性，并解决电池效率和监管合规等关键挑战，初步研究显示相比传统地面物流在配送时间上有显著改善。


<details>
  <summary>Details</summary>
Motivation: 随着最后一公里配送解决方案对快速性和成本效益需求的不断增长，推动了基于无人机物流的重大进展。研究旨在开发一个能够解决配送效率、安全性和监管合规等挑战的智能无人机配送系统。

Method: 采用YOLOv4 Tiny进行目标检测，NEO 6M GPS模块进行导航，A7670 SIM模块进行实时通信。通过对轻量级AI模型和硬件组件进行对比分析，确定实时无人机配送的最优配置。整合机器学习技术、IoT设备和加密协议来解决电池效率、监管合规和安全考虑等关键挑战。

Result: 初步研究表明，相比传统地面物流，该系统在配送时间上有显著改善，通过面部识别实现了高精度的收件人身份验证。系统架构和设计已完成，初步仿真结果已获得，但实验结果、仿真基准测试和部署统计数据仍在收集中。

Conclusion: 该研究成功设计了一个AI集成的无人机配送系统架构，解决了路线优化、目标检测、安全包裹处理和实时跟踪等关键问题。系统符合FAA、EASA和DGCA等监管标准，并考虑了伦理影响和社会接受度。完整的分析将在扩展版本中提供。

Abstract: The increasing demand for fast and cost effective last mile delivery
solutions has catalyzed significant advancements in drone based logistics. This
research describes the development of an AI integrated drone delivery system,
focusing on route optimization, object detection, secure package handling, and
real time tracking. The proposed system leverages YOLOv4 Tiny for object
detection, the NEO 6M GPS module for navigation, and the A7670 SIM module for
real time communication. A comparative analysis of lightweight AI models and
hardware components is conducted to determine the optimal configuration for
real time UAV based delivery. Key challenges including battery efficiency,
regulatory compliance, and security considerations are addressed through the
integration of machine learning techniques, IoT devices, and encryption
protocols. Preliminary studies demonstrate improvement in delivery time
compared to conventional ground based logistics, along with high accuracy
recipient authentication through facial recognition. The study also discusses
ethical implications and societal acceptance of drone deliveries, ensuring
compliance with FAA, EASA and DGCA regulatory standards. Note: This paper
presents the architecture, design, and preliminary simulation results of the
proposed system. Experimental results, simulation benchmarks, and deployment
statistics are currently being acquired. A comprehensive analysis will be
included in the extended version of this work.

</details>


### [22] [Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning](https://arxiv.org/abs/2507.17275)
*Po-Yen Wu,Cheng-Yu Kuo,Yuki Kadokawa,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 本文提出了一个强化学习框架，通过将工具寿命作为策略优化因素，使机器人学会既能完成任务又能延长工具使用寿命的策略，在仿真和真实环境中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 在不可达环境中，机器人常依赖通用工具来完成不确定的任务需求。这些工具没有预定义的使用策略，其寿命对使用方式高度敏感。如何让机器人学会既能完成任务又能延长工具寿命的使用策略是一个根本性挑战。

Method: 提出了一个强化学习框架，将工具寿命纳入策略优化过程。利用有限元分析(FEA)和Miner规则基于累积应力估算剩余有用寿命(RUL)，并将RUL整合到强化学习奖励中指导策略学习。引入自适应奖励归一化(ARN)机制，根据估算的RUL动态调整奖励缩放，确保稳定的学习信号。

Result: 在仿真和真实世界的工具使用任务中验证了方法的有效性，包括物体移动和开门任务。学习到的策略能够持续延长工具寿命(仿真中最高达8.01倍)，并能有效迁移到真实世界环境中。

Conclusion: 该研究成功解决了机器人在使用通用工具时如何平衡任务完成和工具寿命延长的问题。通过将工具寿命估算整合到强化学习框架中，实现了寿命导向的工具使用策略学习，展现了在实际应用中的价值。

Abstract: In inaccessible environments with uncertain task demands, robots often rely
on general-purpose tools that lack predefined usage strategies. These tools are
not tailored for particular operations, making their longevity highly sensitive
to how they are used. This creates a fundamental challenge: how can a robot
learn a tool-use policy that both completes the task and prolongs the tool's
lifespan? In this work, we address this challenge by introducing a
reinforcement learning (RL) framework that incorporates tool lifespan as a
factor during policy optimization. Our framework leverages Finite Element
Analysis (FEA) and Miner's Rule to estimate Remaining Useful Life (RUL) based
on accumulated stress, and integrates the RUL into the RL reward to guide
policy learning toward lifespan-guided behavior. To handle the fact that RUL
can only be estimated after task execution, we introduce an Adaptive Reward
Normalization (ARN) mechanism that dynamically adjusts reward scaling based on
estimated RULs, ensuring stable learning signals. We validate our method across
simulated and real-world tool use tasks, including Object-Moving and
Door-Opening with multiple general-purpose tools. The learned policies
consistently prolong tool lifespan (up to 8.01x in simulation) and transfer
effectively to real-world settings, demonstrating the practical value of
learning lifespan-guided tool use strategies.

</details>


### [23] [VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback](https://arxiv.org/abs/2507.17294)
*Jianxin Bi,Kevin Yuchen Ma,Ce Hao,Mike Zheng Shou,Harold Soh*

Main category: cs.RO

TL;DR: VLA-Touch是一种在不微调基础VLA模型的情况下，通过触觉感知增强通用机器人策略的方法，提出了双层触觉反馈集成机制来改善任务规划效率和执行精度。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作(VLA)模型缺乏解释和使用触觉信号的能力，这限制了它们在接触丰富任务中的有效性。由于缺乏大型多模态数据集，将触觉反馈整合到这些系统中具有挑战性。

Method: 提出VLA-Touch方法，包含两个关键创新：(1)利用预训练的触觉-语言模型为高级任务规划提供语义触觉反馈的管道；(2)基于扩散的控制器，使用触觉信号优化VLA生成的动作以实现接触丰富的操作。

Result: 通过真实世界实验验证，双层触觉反馈集成提高了任务规划效率，同时增强了执行精度。代码已开源。

Conclusion: VLA-Touch成功实现了在不微调基础VLA模型的情况下集成触觉感知，通过双层架构有效改善了机器人在接触丰富任务中的表现。

Abstract: Tactile feedback is generally recognized to be crucial for effective
interaction with the physical world. However, state-of-the-art
Vision-Language-Action (VLA) models lack the ability to interpret and use
tactile signals, limiting their effectiveness in contact-rich tasks.
Incorporating tactile feedback into these systems is challenging due to the
absence of large multi-modal datasets. We present VLA-Touch, an approach that
enhances generalist robot policies with tactile sensing \emph{without
fine-tuning} the base VLA. Our method introduces two key innovations: (1) a
pipeline that leverages a pretrained tactile-language model that provides
semantic tactile feedback for high-level task planning, and (2) a
diffusion-based controller that refines VLA-generated actions with tactile
signals for contact-rich manipulation. Through real-world experiments, we
demonstrate that our dual-level integration of tactile feedback improves task
planning efficiency while enhancing execution precision. Code is open-sourced
at \href{https://github.com/jxbi1010/VLA-Touch}{this URL}.

</details>


### [24] [HuNavSim 2.0](https://arxiv.org/abs/2507.17317)
*Miguel Escudero-Jiménez,Noé Pérez-Higueras,Andrés Martínez-Silva,Fernando Caballero,Luis Merino*

Main category: cs.RO

TL;DR: 本文介绍了Human Navigation Simulator (HuNavSim)的新版本，这是一个开源的人机导航行为仿真工具，基于ROS 2框架开发，可与Gazebo或NVidia Isaac Sim等机器人仿真器配合使用，用于促进人机感知机器人导航系统的开发和评估。


<details>
  <summary>Details</summary>
Motivation: 为了促进人机感知机器人导航系统在仿真环境中的开发和评估，需要一个能够模拟不同人机导航行为场景的仿真工具，以便研究人员能够更好地测试和改进机器人在与人类共存环境中的导航能力。

Method: 开发了基于ROS 2框架的Human Navigation Simulator (HuNavSim)开源仿真工具，该工具可以与现有的知名机器人仿真器（如Gazebo或NVidia Isaac Sim）集成使用。新版本扩展了行为树中可组合的动作和条件集合，以构建复杂且逼真的人类行为模式。

Result: 成功开发了HuNavSim的新迭代版本，该版本在原有功能基础上进行了多项改进，并新增了功能特性，特别是扩展了行为树的动作和条件集合，使得能够模拟更加复杂和逼真的人类导航行为。

Conclusion: HuNavSim的新版本为人机感知机器人导航系统的仿真开发提供了一个强大的开源工具，通过扩展的行为树功能和与主流仿真器的兼容性，能够更好地支持复杂人机交互场景的建模和评估。

Abstract: This work presents a new iteration of the Human Navigation Simulator
(HuNavSim), a novel open-source tool for the simulation of different
human-agent navigation behaviors in scenarios with mobile robots. The tool,
programmed under the ROS 2 framework, can be used together with different
well-known robotics simulators such as Gazebo or NVidia Isaac Sim. The main
goal is to facilitate the development and evaluation of human-aware robot
navigation systems in simulation. In this new version, several features have
been improved and new ones added, such as the extended set of actions and
conditions that can be combined in Behavior Trees to compound complex and
realistic human behaviors.

</details>


### [25] [Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks](https://arxiv.org/abs/2507.17338)
*Corrado Pezzato,Ozan Çatal,Toon Van de Maele,Riddhi J. Pitliya,Tim Verbelen*

Main category: cs.RO

TL;DR: 本文提出了一种分层主动推理架构，首次在复杂长期机器人任务中成功应用主动推理，在Habitat移动操作基准测试中超越了现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 主动推理在机器人控制中虽然受到关注，但在复杂长期任务中的应用仍未得到验证。现有方法在处理现实机器人环境中的目标导向行为时存在局限性。

Method: 设计了一个完全分层的主动推理架构，结合高层主动推理模型来选择离散技能，并通过全身主动推理控制器实现这些技能。该统一方法支持灵活的技能组合、在线适应性和任务失败恢复，无需离线训练。

Result: 在Habitat移动操作基准测试的三个长期任务中，该方法在所有任务上都超越了最先进的基线方法，首次证明了主动推理可以扩展到现代机器人基准测试的复杂度。

Conclusion: 首次成功将主动推理扩展到复杂的现代机器人基准测试，证明了分层主动推理架构在长期机器人任务中的有效性和优越性能。

Abstract: Despite growing interest in active inference for robotic control, its
application to complex, long-horizon tasks remains untested. We address this
gap by introducing a fully hierarchical active inference architecture for
goal-directed behavior in realistic robotic settings. Our model combines a
high-level active inference model that selects among discrete skills realized
via a whole-body active inference controller. This unified approach enables
flexible skill composition, online adaptability, and recovery from task
failures without requiring offline training. Evaluated on the Habitat Benchmark
for mobile manipulation, our method outperforms state-of-the-art baselines
across the three long-horizon tasks, demonstrating for the first time that
active inference can scale to the complexity of modern robotics benchmarks.

</details>


### [26] [An Exploratory Study on Human-Robot Interaction using Semantics-based Situational Awareness](https://arxiv.org/abs/2507.17376)
*Tianshu Ruan,Aniketh Ramesh,Rustam Stolkin,Manolis Chiou*

Main category: cs.RO

TL;DR: 本文研究了高级语义信息对人机团队协作和人机交互的影响，特别是在移动机器人部署的灾难响应任务中。研究发现语义信息能够减轻操作员工作负荷、提高态势感知信任度并缩短自主级别切换反应时间。


<details>
  <summary>Details</summary>
Motivation: 虽然语义学在人工智能领域被广泛研究，但高级语义如何使人机团队范式受益仍然未被充分探索、模糊且难以处理。在灾难响应等复杂任务中，人类操作员面临高工作负荷和压力，需要在机器人和其他任务间快速切换注意力，难以快速建立态势感知。

Method: 应用基于语义的框架，该框架能够揭示环境的不同指标（即存在多少语义信息），在模拟灾难响应任务中进行实验验证。

Result: 实验结果表明，所提出的语义信息：1）减轻了人类操作员的感知工作负荷；2）提高了操作员对态势感知的信任；3）有助于在需要时减少切换自主级别的反应时间。此外，发现对系统信任度较高的参与者在高级语义的鼓励下更多地使用遥操作模式。

Conclusion: 高级语义信息在人机团队协作中具有显著的积极作用，能够有效改善人机交互质量，特别是在复杂的灾难响应场景中。语义信息不仅能减轻操作员负担，还能提升系统信任度和响应效率。

Abstract: In this paper, we investigate the impact of high-level semantics (evaluation
of the environment) on Human-Robot Teams (HRT) and Human-Robot Interaction
(HRI) in the context of mobile robot deployments. Although semantics has been
widely researched in AI, how high-level semantics can benefit the HRT paradigm
is underexplored, often fuzzy, and intractable. We applied a semantics-based
framework that could reveal different indicators of the environment (i.e. how
much semantic information exists) in a mock-up disaster response mission. In
such missions, semantics are crucial as the HRT should handle complex
situations and respond quickly with correct decisions, where humans might have
a high workload and stress. Especially when human operators need to shift their
attention between robots and other tasks, they will struggle to build
Situational Awareness (SA) quickly. The experiment suggests that the presented
semantics: 1) alleviate the perceived workload of human operators; 2) increase
the operator's trust in the SA; and 3) help to reduce the reaction time in
switching the level of autonomy when needed. Additionally, we find that
participants with higher trust in the system are encouraged by high-level
semantics to use teleoperation mode more.

</details>


### [27] [Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models](https://arxiv.org/abs/2507.17379)
*Shen Tan,Dong Zhou,Xiangyu Shao,Junqiao Wang,Guanghui Sun*

Main category: cs.RO

TL;DR: 本文提出了LOVMM框架，结合大语言模型和视觉语言模型，用于解决开放词汇移动操作任务，能够在家庭环境中根据自然语言指令处理新颖和未见过的物体。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的开放词汇移动操作（OVMM）面临重大挑战，需要在不同工作空间中处理新颖和未见过的物体，现有方法在这方面能力有限。

Method: 提出LOVMM（Language-conditioned Open-Vocabulary Mobile Manipulation）框架，结合大语言模型（LLM）和视觉语言模型（VLM），能够处理自由形式的自然语言指令进行移动操作任务。

Result: 在复杂家庭环境的仿真实验中展现出强大的零样本泛化能力和多任务学习能力，在多个桌面操作任务上也能泛化并获得比其他最先进方法更好的成功率。

Conclusion: LOVMM框架成功解决了开放词汇移动操作的挑战，通过结合LLM和VLM实现了对自然语言指令的理解和执行，在家庭环境和桌面操作任务中都表现出优异的性能。

Abstract: Open-vocabulary mobile manipulation (OVMM) that involves the handling of
novel and unseen objects across different workspaces remains a significant
challenge for real-world robotic applications. In this paper, we propose a
novel Language-conditioned Open-Vocabulary Mobile Manipulation framework, named
LOVMM, incorporating the large language model (LLM) and vision-language model
(VLM) to tackle various mobile manipulation tasks in household environments.
Our approach is capable of solving various OVMM tasks with free-form natural
language instructions (e.g. "toss the food boxes on the office room desk to the
trash bin in the corner", and "pack the bottles from the bed to the box in the
guestroom"). Extensive experiments simulated in complex household environments
show strong zero-shot generalization and multi-task learning abilities of
LOVMM. Moreover, our approach can also generalize to multiple tabletop
manipulation tasks and achieve better success rates compared to other
state-of-the-art methods.

</details>


### [28] [Confidence Calibration in Vision-Language-Action Models](https://arxiv.org/abs/2507.17383)
*Thomas P Zollo,Richard Zemel*

Main category: cs.RO

TL;DR: 这是首个针对视觉-语言-动作(VLA)基础模型置信度校准的系统性研究，旨在让机器人能够可靠地量化其成功概率，提升机器人行为的可信度


<details>
  <summary>Details</summary>
Motivation: 可信的机器人行为不仅需要高任务成功率，还需要机器人能够可靠地量化自己成功的可能性。现有的VLA模型缺乏对置信度校准的系统性研究，这限制了机器人在实际应用中的可信度

Method: 1) 对多个数据集和VLA变体进行广泛基准测试，分析任务成功率与校准误差的关系；2) 引入提示集成方法，通过平均不同释义指令的置信度来改善校准；3) 分析任务时间范围内的校准表现；4) 提出动作维度独立的Platt缩放方法来重新校准每个动作维度

Result: 发现任务性能和校准并不冲突；提示集成方法能持续改善校准效果；置信度在取得一定进展后往往更可靠，为风险感知干预提供了自然的时机；揭示了不同动作维度间的差异性误校准现象

Conclusion: 通过系统性的置信度校准研究，为开发高性能且高可信度的VLA模型提供了必要的工具和概念理解，使机器人能够通过可靠的不确定性量化实现更好的表现和可信度

Abstract: Trustworthy robot behavior requires not only high levels of task success but
also that the robot can reliably quantify how likely it is to succeed. To this
end, we present the first systematic study of confidence calibration in
vision-language-action (VLA) foundation models, which map visual observations
and natural-language instructions to low-level robot motor commands. We begin
with extensive benchmarking to understand the critical relationship between
task success and calibration error across multiple datasets and VLA variants,
finding that task performance and calibration are not in tension. Next, we
introduce prompt ensembles for VLAs, a lightweight, Bayesian-inspired algorithm
that averages confidence across paraphrased instructions and consistently
improves calibration. We further analyze calibration over the task time
horizon, showing that confidence is often most reliable after making some
progress, suggesting natural points for risk-aware intervention. Finally, we
reveal differential miscalibration across action dimensions and propose
action-wise Platt scaling, a method to recalibrate each action dimension
independently to produce better confidence estimates. Our aim in this study is
to begin to develop the tools and conceptual understanding necessary to render
VLAs both highly performant and highly trustworthy via reliable uncertainty
quantification.

</details>


### [29] [The Wilhelm Tell Dataset of Affordance Demonstrations](https://arxiv.org/abs/2507.17401)
*Rachel Ringe,Mihai Pomarlan,Nikolaos Tsiogkas,Stefano De Giorgis,Maria Hedblom,Rainer Malaka*

Main category: cs.RO

TL;DR: 该论文提出了一个新的视频数据集，用于学习日常家务任务中的可供性(affordances)，包含第一人称和第三人称视角的演示，旨在训练机器人感知系统识别可供性表现。


<details>
  <summary>Details</summary>
Motivation: 现有的可供性学习方法主要基于静态图像或形状的标注数据进行训练，缺乏动态的、真实的任务演示数据。机器人在人类环境中操作需要更好地感知环境和物体提供的行动可能性，特别是在日常家务任务中的可供性表现。

Method: 构建了一个包含常见家务任务的新型可供性学习数据集。数据集包含视频序列，从第一人称和第三人称视角展示任务执行过程，并提供关于任务中体现的可供性的元数据。数据收集自多个参与者，总计约七小时的人类活动记录。

Result: 成功构建了一个综合性的可供性学习数据集，包含多样化的任务执行表现，能够研究人们为完成任务而进行的准备性操作，如任务空间的安排等。该数据集为训练感知系统识别可供性表现提供了基础。

Conclusion: 该数据集为可供性学习提供了新的视频基础资源，不仅可以训练机器人感知系统识别可供性表现，还可以研究人类的准备性行为，这对于协作服务机器人的发展具有重要意义。数据集的多样性和真实性为该领域的研究提供了有价值的工具。

Abstract: Affordances - i.e. possibilities for action that an environment or objects in
it provide - are important for robots operating in human environments to
perceive. Existing approaches train such capabilities on annotated static
images or shapes. This work presents a novel dataset for affordance learning of
common household tasks. Unlike previous approaches, our dataset consists of
video sequences demonstrating the tasks from first- and third-person
perspectives, along with metadata about the affordances that are manifested in
the task, and is aimed towards training perception systems to recognize
affordance manifestations. The demonstrations were collected from several
participants and in total record about seven hours of human activity. The
variety of task performances also allows studying preparatory maneuvers that
people may perform for a task, such as how they arrange their task space, which
is also relevant for collaborative service robots.

</details>


### [30] [IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception](https://arxiv.org/abs/2507.17445)
*Haichuan Li,Changda Tian,Panos Trahanias,Tomi Westerlund*

Main category: cs.RO

TL;DR: 提出了IndoorBEV方法，一种基于掩码的鸟瞰图(BEV)方法，用于室内移动机器人的3D点云目标检测，通过将3D场景投影到2D BEV网格来处理遮挡问题并区分静态障碍物和动态物体


<details>
  <summary>Details</summary>
Motivation: 传统边界框方法在复杂室内3D点云环境中检测多样化目标时存在局限性，特别是在处理不同形状物体、杂乱环境以及静态和动态元素共存的场景时表现不佳

Method: 采用基于掩码的鸟瞰图(BEV)方法：(1)将3D场景投影到2D BEV网格；(2)使用轴紧凑编码器和基于窗口的骨干网络从BEV地图提取丰富的空间特征；(3)采用基于查询的解码器头，使用学习的目标查询同时预测BEV空间中的目标类别和实例掩码

Result: 在包含多样化目标类别(包括静态物体和机器人等动态元素)的自定义室内数据集上验证了IndoorBEV的有效性，展示了其在鲁棒室内场景理解方面的潜力

Conclusion: IndoorBEV通过掩码中心的表述方式有效捕获了静态和动态物体的足迹特征，为边界框回归提供了鲁棒的替代方案，生成的2D BEV结果可直接用于导航、运动预测和规划等下游机器人任务

Abstract: Detecting diverse objects within complex indoor 3D point clouds presents
significant challenges for robotic perception, particularly with varied object
shapes, clutter, and the co-existence of static and dynamic elements where
traditional bounding box methods falter. To address these limitations, we
propose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor
mobile robots.
  In a BEV method, a 3D scene is projected into a 2D BEV grid which handles
naturally occlusions and provides a consistent top-down view aiding to
distinguish static obstacles from dynamic agents. The obtained 2D BEV results
is directly usable to downstream robotic tasks like navigation, motion
prediction, and planning. Our architecture utilizes an axis compact encoder and
a window-based backbone to extract rich spatial features from this BEV map. A
query-based decoder head then employs learned object queries to concurrently
predict object classes and instance masks in the BEV space. This mask-centric
formulation effectively captures the footprint of both static and dynamic
objects regardless of their shape, offering a robust alternative to bounding
box regression. We demonstrate the effectiveness of IndoorBEV on a custom
indoor dataset featuring diverse object classes including static objects
  and dynamic elements like robots and miscellaneous items, showcasing its
potential for robust indoor scene understanding.

</details>


### [31] [Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners](https://arxiv.org/abs/2507.17519)
*Kostas Karakontis,Thanos Petsanis,Athanasios Ch. Kapoutsis,Pavlos Ch. Kapoutsis,Elias B. Kosmatopoulos*

Main category: cs.RO

TL;DR: 本文提出了一种模块化算法，将商业二维路径规划器扩展为地形感知的三维覆盖路径规划，通过调整高度和相机方向改善3D重建效果，特别是在垂直表面和遮挡区域


<details>
  <summary>Details</summary>
Motivation: 现有商业软件中的多无人机覆盖路径规划算法通常只将感兴趣区域视为2D平面，忽略了重要的3D结构特征，导致3D重建不完整，特别是在遮挡或垂直表面周围

Method: 提出了一种模块化算法，可以扩展商业二维路径规划器以实现地形感知规划，通过调整高度和相机方向来优化路径。具体将知名的DARP算法扩展为DARP-3D算法

Result: 在多个3D环境中进行仿真测试和使用DJI硬件的真实飞行测试。与基线方法相比，该方法在具有显著垂直特征的区域中始终能够获得改进的3D重建效果

Conclusion: 提出的地形感知路径规划算法能够有效改善3D重建质量，特别是在处理垂直表面和复杂地形结构方面表现出色，并提供了开源实现

Abstract: Multi-UAV Coverage Path Planning (mCPP) algorithms in popular commercial
software typically treat a Region of Interest (RoI) only as a 2D plane,
ignoring important3D structure characteristics. This leads to incomplete
3Dreconstructions, especially around occluded or vertical surfaces. In this
paper, we propose a modular algorithm that can extend commercial
two-dimensional path planners to facilitate terrain-aware planning by adjusting
altitude and camera orientations. To demonstrate it, we extend the well-known
DARP (Divide Areas for Optimal Multi-Robot Coverage Path Planning) algorithm
and produce DARP-3D. We present simulation results in multiple 3D environments
and a real-world flight test using DJI hardware. Compared to baseline, our
approach consistently captures improved 3D reconstructions, particularly in
areas with significant vertical features. An open-source implementation of the
algorithm is available here:https://github.com/konskara/TerraPlan

</details>


### [32] [InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation](https://arxiv.org/abs/2507.17520)
*Shuai Yang,Hao Li,Yilun Chen,Bin Wang,Yang Tian,Tai Wang,Hanqing Wang,Feng Zhao,Yiyi Liao,Jiangmiao Pang*

Main category: cs.RO

TL;DR: InstructVLA是一个端到端的视觉-语言-动作模型，通过新颖的VLA-IT训练范式，在保持大型视觉语言模型灵活推理能力的同时，实现了领先的机器人操控性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型往往在多模态推理和精确动作生成之间做出牺牲，能力局限于特定任务的操控数据，并且会遭受预训练视觉语言能力的灾难性遗忘问题。需要一个能够平衡推理能力和操控性能的统一模型。

Method: 提出了视觉-语言-动作指令调优(VLA-IT)的新训练范式，采用混合专家适应的多模态训练方法，在标准VLM语料库和精心策划的65万样本VLA-IT数据集上联合优化文本推理和动作生成。

Result: 在SimplerEnv任务上比SpatialVLA提升30.5%；在新提出的SimplerEnv-Instruct 80任务基准测试中，比微调的OpenVLA提升92%，比GPT-4o辅助的动作专家提升29%；在多模态任务上超越基线VLM模型，并展现出推理时间缩放特性。

Conclusion: InstructVLA成功桥接了直观可控的人机交互与高效的策略学习，证明了其在真实世界机器人应用中的潜力，为实现既能灵活推理又能精确操控的机器人系统提供了新的解决方案。

Abstract: To operate effectively in the real world, robots must integrate multimodal
reasoning with precise action generation. However, existing
vision-language-action (VLA) models often sacrifice one for the other, narrow
their abilities to task-specific manipulation data, and suffer catastrophic
forgetting of pre-trained vision-language capabilities. To bridge this gap, we
introduce InstructVLA, an end-to-end VLA model that preserves the flexible
reasoning of large vision-language models (VLMs) while delivering leading
manipulation performance. InstructVLA introduces a novel training paradigm,
Vision-Language-Action Instruction Tuning (VLA-IT), which employs multimodal
training with mixture-of-experts adaptation to jointly optimize textual
reasoning and action generation on both standard VLM corpora and a curated
650K-sample VLA-IT dataset. On in-domain SimplerEnv tasks, InstructVLA achieves
30.5% improvement over SpatialVLA. To evaluate generalization, we introduce
SimplerEnv-Instruct, an 80-task benchmark requiring closed-loop control and
high-level instruction understanding, where it outperforms a fine-tuned OpenVLA
by 92% and an action expert aided by GPT-4o by 29%. Additionally, InstructVLA
surpasses baseline VLMs on multimodal tasks and exhibits inference-time scaling
by leveraging textual reasoning to boost manipulation performance in both
simulated and real-world settings. These results demonstrate InstructVLA's
potential for bridging intuitive and steerable human-robot interaction with
efficient policy learning.

</details>


### [33] [When and Where Localization Fails: An Analysis of the Iterative Closest Point in Evolving Environment](https://arxiv.org/abs/2507.17531)
*Abdel-Raouf Dannaoui,Johann Laconte,Christophe Debain,Francois Pomerleau,Paul Checchin*

Main category: cs.RO

TL;DR: 本研究针对动态户外环境中的短期重定位问题，提出了一个高分辨率多时间数据集，并比较了两种ICP算法在点云配准中的性能，发现Point-to-Plane ICP在稀疏特征和植被密集区域表现更稳定准确。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注长期定位问题，而对于几天到几周内发生的短期环境变化研究不足，这种短期变化在实际应用中具有重要意义，需要专门的数据集和方法来解决动态户外环境中基于3D激光雷达的鲁棒重定位挑战。

Method: 构建了2025年2月至4月期间每周采集的高分辨率短期多时间数据集，涵盖自然和半城市环境，包含高密度点云地图、360度全景图像和轨迹数据。使用从点云地图投影的激光雷达扫描数据，建模传感器精确遮挡，采用两种迭代最近点(ICP)算法变体（Point-to-Point和Point-to-Plane）评估与真值的对齐精度。

Result: Point-to-Plane ICP相比Point-to-Point ICP提供了显著更稳定和准确的配准结果，特别是在稀疏特征区域或植被密集的环境中表现更优。研究还揭示了局部几何结构和环境变异性如何影响定位成功率。

Conclusion: 该研究为评估短期定位鲁棒性提供了结构化数据集，建立了在噪声条件下分析扫描到地图对齐的可重现框架，并对不断变化的户外环境中的ICP性能进行了比较评估，为设计更具弹性的机器人系统提供了重要见解。

Abstract: Robust relocalization in dynamic outdoor environments remains a key challenge
for autonomous systems relying on 3D lidar. While long-term localization has
been widely studied, short-term environmental changes, occurring over days or
weeks, remain underexplored despite their practical significance. To address
this gap, we present a highresolution, short-term multi-temporal dataset
collected weekly from February to April 2025 across natural and semi-urban
settings. Each session includes high-density point cloud maps, 360 deg
panoramic images, and trajectory data. Projected lidar scans, derived from the
point cloud maps and modeled with sensor-accurate occlusions, are used to
evaluate alignment accuracy against the ground truth using two Iterative
Closest Point (ICP) variants: Point-to-Point and Point-to-Plane. Results show
that Point-to-Plane offers significantly more stable and accurate registration,
particularly in areas with sparse features or dense vegetation. This study
provides a structured dataset for evaluating short-term localization
robustness, a reproducible framework for analyzing scan-to-map alignment under
noise, and a comparative evaluation of ICP performance in evolving outdoor
environments. Our analysis underscores how local geometry and environmental
variability affect localization success, offering insights for designing more
resilient robotic systems.

</details>


### [34] [Robot-mediated physical Human-Human Interaction in Neurorehabilitation: a position paper](https://arxiv.org/abs/2507.17561)
*Lorenzo Vianello,Matthew Short,Julia Manczurowsky,Emek Barış Küçüktabak,Francesco Di Tommaso,Alessia Noccaro,Laura Bandini,Shoshana Clark,Alaina Fiorenza,Francesca Lunardini,Alberto Canton,Marta Gandolla,Alessandra L. G. Pedrocchi,Emilia Ambrosini,Manuel Murie-Fernandez,Carmen B. Roman,Jesus Tornero,Natacha Leon,Andrew Sawers,Jim Patton,Domenico Formica,Nevio Luigi Tagliamonte,Georg Rauter,Kilian Baur,Fabian Just,Christopher J. Hasson,Vesna D. Novak,Jose L. Pons*

Main category: cs.RO

TL;DR: 本文提出了一种机器人介导的人-人物理交互框架，将治疗师的临床专业知识与机器人的精确性和重复性相结合，用于神经康复治疗


<details>
  <summary>Details</summary>
Motivation: 传统神经康复依赖患者与物理治疗师的交互，而机器人系统虽能改善物理反馈但未充分利用治疗师的适应性和临床专业知识，需要一种结合两者优势的新方法

Method: 提出机器人介导的人-人物理交互框架，使两个人通过机器人设备进行物理交互；采用多学科团队方法，包括统一的机器人介导康复分类法、基于社会心理学的交互框架，以及使机器人系统成为自然人-人交互无缝促进者的技术方法

Result: 该框架已在不同研究小组中得到研究，最近作为连接传统手工治疗和康复机器人的有前景的桥梁而出现，协调了两种方法的优势

Conclusion: 机器人介导的人-人物理交互框架能够整合治疗师的临床专业知识和细致决策能力与机器人的力量、精确性和重复性，为神经康复提供了一种创新的治疗方法

Abstract: Neurorehabilitation conventionally relies on the interaction between a
patient and a physical therapist. Robotic systems can improve and enrich the
physical feedback provided to patients after neurological injury, but they
under-utilize the adaptability and clinical expertise of trained therapists. In
this position paper, we advocate for a novel approach that integrates the
therapist's clinical expertise and nuanced decision-making with the strength,
accuracy, and repeatability of robotics: Robot-mediated physical Human-Human
Interaction. This framework, which enables two individuals to physically
interact through robotic devices, has been studied across diverse research
groups and has recently emerged as a promising link between conventional manual
therapy and rehabilitation robotics, harmonizing the strengths of both
approaches. This paper presents the rationale of a multidisciplinary
team-including engineers, doctors, and physical therapists-for conducting
research that utilizes: a unified taxonomy to describe robot-mediated
rehabilitation, a framework of interaction based on social psychology, and a
technological approach that makes robotic systems seamless facilitators of
natural human-human interaction.

</details>


### [35] [KernelSOS for Global Sampling-Based Optimal Control and Estimation via Semidefinite Programming](https://arxiv.org/abs/2507.17572)
*Antoine Groudiev,Fabian Schramm,Éloïse Berthier,Justin Carpentier,Frederike Dümbgen*

Main category: cs.RO

TL;DR: 本文将核平方和(KernelSOS)框架应用于控制和估计问题的全局优化，该方法结合了多项式优化中的平方和方法和机器学习中的核方法，能够处理具有不良局部最小值的优化问题。


<details>
  <summary>Details</summary>
Motivation: 全局优化问题中存在不良局部最小值的挑战，特别是在控制和估计领域。传统的平方和方法受限于多项式和参数化形式，而KernelSOS框架能够克服这些限制，提供更强的表达能力和适用性。

Method: 采用核平方和(KernelSOS)框架，该方法结合了多项式优化社区的平方和方法的潜力和机器学习中广泛使用的核方法的表达能力。KernelSOS具有基于样本的特性，可以将集成仿真器作为黑盒处理，既可以作为独立方法，也可以作为局部求解器的强大初始化方法。

Result: KernelSOS在控制和估计领域的多个问题上表现良好。在估计问题上，KernelSOS与其他平方和方法具有竞争力，同时适用于非多项式和非参数化形式。在轨迹优化问题中，该方法能够促进发现更好的解决方案。

Conclusion: KernelSOS框架为解决具有不良局部最小值的控制和估计问题提供了一个强大的全局优化工具。其基于样本的特性和对非多项式、非参数化问题的适用性使其在实际应用中具有重要价值，特别是在轨迹优化等复杂问题中表现出色。

Abstract: Global optimization has gained attraction over the past decades, thanks to
the development of both theoretical foundations and efficient numerical
routines to cope with optimization problems of various complexities. Among
recent methods, Kernel Sum of Squares (KernelSOS) appears as a powerful
framework, leveraging the potential of sum of squares methods from the
polynomial optimization community with the expressivity of kernel methods
widely used in machine learning. This paper applies the kernel sum of squares
framework for solving control and estimation problems, which exhibit poor local
minima. We demonstrate that KernelSOS performs well on a selection of problems
from both domains. In particular, we show that KernelSOS is competitive with
other sum of squares approaches on estimation problems, while being applicable
to non-polynomial and non-parametric formulations. The sample-based nature of
KernelSOS allows us to apply it to trajectory optimization problems with an
integrated simulator treated as a black box, both as a standalone method and as
a powerful initialization method for local solvers, facilitating the discovery
of better solutions.

</details>


### [36] [Event Detection for Active Lower Limb Prosthesis](https://arxiv.org/abs/2507.17649)
*J. D. Clark,P. Ellison*

Main category: cs.RO

TL;DR: 研究了双髁膝关节设计中十字韧带拉伸在步态事件检测中的作用，发现韧带拉伸模式可以用作预测步态事件的指标，从而改善动力假肢的控制精度。


<details>
  <summary>Details</summary>
Motivation: 准确的事件检测是半被动和动力假肢成功设计的关键。自然膝关节运动学复杂，包含平移和旋转成分，对步态特征有重要影响。当简化为铰接关节时，会丢失部分行为特征。因此需要研究十字韧带拉伸在事件检测中的作用。

Method: 使用双髁膝关节设计，由前后十字韧带类似物约束。通过平行于Russell膝关节韧带的LVDTs记录韧带拉伸情况。在弯膝拐杖上进行实验，在跑步机上以3种速度采集数据，通过韧带拉伸来表征膝关节运动学。

Result: 发现十字韧带拉伸存在速度依赖性，主要在步态周期的5%和80%处（后十字韧带和前十字韧带）。循环轮廓随速度保持一致。在90%和95%处发现转折点特征，可作为初始接触的预测前兆。同样在90%和95%处的另一对转折点可用于预测足平期。

Conclusion: 双髁膝关节设计的使用可以改善步态周期中事件的检测，因此可以提高动力假肢后续控制器的精度。十字韧带拉伸模式可作为步态事件预测的有效指标。

Abstract: Accurate event detection is key to the successful design of semi-passive and
powered prosthetics. Kinematically, the natural knee is complex, with
translation and rotation components that have a substantial impact on gait
characteristics. When simplified to a pin joint, some of this behaviour is
lost. This study investigates the role of cruciate ligament stretch in event
detection. A bicondylar knee design was used, constrained by analogues of the
anterior and posterior cruciate ligaments. This offers the ability to
characterize knee kinematics by the stretch of the ligaments. The ligament
stretch was recorded using LVDTs parallel to the ligaments of the Russell knee
on a bent knee crutch. Which was used to capture data on a treadmill at 3
speeds. This study finds speed dependence within the stretch of the cruciate
ligaments, prominently around 5\% and 80\% of the gait cycle for the posterior
and anterior. The cycle profile remains consistent with speed; therefore, other
static events such as the turning point feature at around 90\% and 95\% of the
cycle, for the posterior and anterior, respectively, could be used as a
predictive precursor for initial contact. Likewise at 90\% and 95\%, another
pair of turning points that in this case could be used to predict foot flat.
This concludes that the use of a bicondylar knee design could improve the
detection of events during the gait cycle, and therefore could increase the
accuracy of subsequent controllers for powered prosthetics.

</details>


### [37] [Safety Assurance for Quadrotor Kinodynamic Motion Planning](https://arxiv.org/abs/2507.17679)
*Theodoros Tavoulareas,Marzia Cescon*

Main category: cs.RO

TL;DR: 本文提出了一种结合运行时安全保障的无人机运动规划方法，通过采样几何规划器生成无碰撞路径，并设计低级安全保障滤波器为LQR控制器提供安全保证，在Crazyflie 2.0无人机仿真中验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有运动规划技术虽能生成无碰撞轨迹，但在创建运动计划时未考虑系统的安全操作区域，导致部署时可能违反安全约束。随着无人机在民用应用中日益普及，确保安全操作失败可能导致系统物理损坏、环境污染甚至人员伤亡。

Method: 提出了一种在运动学动力学运动规划方案中利用运行时安全保障的方法：首先使用基于采样的几何规划器在用户定义空间内确定高级无碰撞路径；其次设计低级安全保障滤波器，为专门用于轨迹跟踪的线性二次调节器(LQR)的控制输入提供安全保证。

Result: 在受限3D仿真环境中使用Crazyflie 2.0无人机模型验证了所提出方法的有效性，证明了该方法能够在运动规划过程中满足系统的操作约束。

Conclusion: 通过将运行时安全保障集成到运动学动力学运动规划中，该方法成功解决了传统运动规划技术忽略安全操作区域的问题，为自主无人机的安全部署提供了有效解决方案。

Abstract: Autonomous drones have gained considerable attention for applications in
real-world scenarios, such as search and rescue, inspection, and delivery. As
their use becomes ever more pervasive in civilian applications, failure to
ensure safe operation can lead to physical damage to the system, environmental
pollution, and even loss of human life. Recent work has demonstrated that
motion planning techniques effectively generate a collision-free trajectory
during navigation. However, these methods, while creating the motion plans, do
not inherently consider the safe operational region of the system, leading to
potential safety constraints violation during deployment. In this paper, we
propose a method that leverages run time safety assurance in a kinodynamic
motion planning scheme to satisfy the system's operational constraints. First,
we use a sampling-based geometric planner to determine a high-level
collision-free path within a user-defined space. Second, we design a low-level
safety assurance filter to provide safety guarantees to the control input of a
Linear Quadratic Regulator (LQR) designed with the purpose of trajectory
tracking. We demonstrate our proposed approach in a restricted 3D simulation
environment using a model of the Crazyflie 2.0 drone.

</details>


### [38] [CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation](https://arxiv.org/abs/2507.17727)
*Robel Mamo,Taeyeong Choi*

Main category: cs.RO

TL;DR: 本文提出了一种新的数据增强方法Crop-Aligned Cutout (CA-Cut)，通过在作物行周围空间分布的区域进行掩码，提高农业机器人在复杂冠层下环境中的视觉导航性能，相比传统增强方法可减少36.9%的预测误差。


<details>
  <summary>Details</summary>
Motivation: 现有的冠层下视觉导航方法依赖深度学习感知模型，但需要大量训练数据以确保实际部署的可靠性。数据收集成本高昂，传统的数据增强技术（如颜色抖动、高斯模糊等）在复杂的冠层下环境中可能导致次优性能，特别是在频繁遮挡、碎片和作物间距不均匀的情况下。

Method: 提出了Crop-Aligned Cutout (CA-Cut)数据增强方法，该方法在输入图像中随机掩码作物行两侧空间分布的区域，鼓励训练模型即使在细粒度信息被遮挡时也能捕获高级上下文特征。方法将掩码分布偏向于作物行区域，以模拟遮挡情况。

Result: 在公共玉米田数据集上的大量实验表明，基于掩码的增强方法能有效模拟遮挡并显著提高视觉导航中语义关键点预测的鲁棒性。CA-Cut方法在预测准确性和跨不同环境的泛化能力方面都有提升，预测误差最多可减少36.9%。

Conclusion: CA-Cut数据增强方法通过将掩码分布偏向作物行区域，能够有效提高农业机器人在复杂冠层下环境中的视觉导航性能。消融研究确定了掩码数量、大小和空间分布的最优参数，证明了该方法在提高模型鲁棒性和泛化能力方面的有效性。

Abstract: State-of-the-art visual under-canopy navigation methods are designed with
deep learning-based perception models to distinguish traversable space from
crop rows. While these models have demonstrated successful performance, they
require large amounts of training data to ensure reliability in real-world
field deployment. However, data collection is costly, demanding significant
human resources for in-field sampling and annotation. To address this
challenge, various data augmentation techniques are commonly employed during
model training, such as color jittering, Gaussian blur, and horizontal flip, to
diversify training data and enhance model robustness. In this paper, we
hypothesize that utilizing only these augmentation techniques may lead to
suboptimal performance, particularly in complex under-canopy environments with
frequent occlusions, debris, and non-uniform spacing of crops. Instead, we
propose a novel augmentation method, so-called Crop-Aligned Cutout (CA-Cut)
which masks random regions out in input images that are spatially distributed
around crop rows on the sides to encourage trained models to capture high-level
contextual features even when fine-grained information is obstructed. Our
extensive experiments with a public cornfield dataset demonstrate that
masking-based augmentations are effective for simulating occlusions and
significantly improving robustness in semantic keypoint predictions for visual
navigation. In particular, we show that biasing the mask distribution toward
crop rows in CA-Cut is critical for enhancing both prediction accuracy and
generalizability across diverse environments achieving up to a 36.9% reduction
in prediction error. In addition, we conduct ablation studies to determine the
number of masks, the size of each mask, and the spatial distribution of masks
to maximize overall performance.

</details>
