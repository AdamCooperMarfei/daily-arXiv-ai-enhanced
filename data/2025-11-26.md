<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 28]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Discover, Learn, and Reinforce: Scaling Vision-Language-Action Pretraining with Diverse RL-Generated Trajectories](https://arxiv.org/abs/2511.19528)
*Rushuai Yang,Zhiyuan Feng,Tianxiang Zhang,Kaixin Wang,Chuheng Zhang,Li Zhao,Xiu Su,Yi Chen,Jiang Bian*

Main category: cs.RO

TL;DR: 提出DLR框架，通过信息论模式发现生成多种不同的高成功率行为模式，为视觉语言动作模型预训练提供更多样化的轨迹数据。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言动作模型预训练需要大量多样化、高质量的操控轨迹数据，但人类远程操作获取成本高且难以扩展。强化学习方法虽然能通过自主探索学习有用技能，但标准RL训练会收敛到单一执行模式，限制了其在大规模预训练中的实用性。

Method: 提出Discover、Learn和Reinforce（DLR）框架，这是一个基于信息论的模式发现框架，能够为VLA预训练生成多种不同的高成功率行为模式。

Result: 在LIBERO基准测试中，DLR生成了明显更多样化的轨迹语料库，学会了同一任务的多种不同高成功率策略，而标准RL只发现一种策略。当适应未见过的下游任务套件时，在多样化RL数据上预训练的VLA模型优于在同等规模标准RL数据集上训练的对应模型。

Conclusion: DLR展示了标准单模式RL所缺乏的积极数据扩展行为，将多模式RL定位为具身基础模型的实用、可扩展数据引擎。

Abstract: Scaling vision-language-action (VLA) model pre-training requires large volumes of diverse, high-quality manipulation trajectories. Most current data is obtained via human teleoperation, which is expensive and difficult to scale. Reinforcement learning (RL) methods learn useful skills through autonomous exploration, making them a viable approach for generating data. However, standard RL training collapses to a narrow execution pattern, limiting its utility for large-scale pre-training. We propose Discover, Lea rn and Reinforce (DLR), an information-theoretic pattern discovery framework that generates multiple distinct, high-success behavioral patterns for VLA pretraining. Empirically, DLR generates a markedly more diverse trajectory corpus on LIBERO. Specifically, it learns multiple distinct, high-success strategies for the same task where standard RL discovers only one, and hence it covers substantially broader regions of the state-action space. When adapted to unseen downstream task suites, VLA models pretrained on our diverse RL data surpass counterparts trained on equal-sized standard RL datasets. Moreover, DLR exhibits positive data-scaling behavior that single-pattern RL lacks. These results position multi-pattern RL as a practical, scalable data engine for embodied foundation models.

</details>


### [2] [A Virtual Mechanical Interaction Layer Enables Resilient Human-to-Robot Object Handovers](https://arxiv.org/abs/2511.19543)
*Omar Faris,Sławomir Tadeja,Fulvio Forni*

Main category: cs.RO

TL;DR: 提出了一种基于虚拟模型控制和增强现实的人机物体交接方法，能够适应交接过程中的动态变化和不确定性。


<details>
  <summary>Details</summary>
Motivation: 物体交接是协作任务中的常见交互形式，但实现高效交接仍具挑战性，需要机器人能够适应交接过程中物体姿态的复杂变化。

Method: 使用虚拟模型控制创建交互层来控制机器人并适应交接过程的动态变化，同时利用增强现实促进人机双向通信。

Result: 控制器在各种不确定性条件下表现出良好的韧性，用户研究显示参与者普遍偏好该方法，并揭示了指导进一步发展的见解。

Conclusion: 所提出的方法在人机物体交接中表现良好，为适应用户交互的进一步发展提供了指导。

Abstract: Object handover is a common form of interaction that is widely present in collaborative tasks. However, achieving it efficiently remains a challenge. We address the problem of ensuring resilient robotic actions that can adapt to complex changes in object pose during human-to-robot object handovers. We propose the use of Virtual Model Control to create an interaction layer that controls the robot and adapts to the dynamic changes in the handover process. Additionally, we propose the use of augmented reality to facilitate bidirectional communication between humans and robots during handovers. We assess the performance of our controller in a set of experiments that demonstrate its resilience to various sources of uncertainties, including complex changes to the object's pose during the handover. Finally, we performed a user study with 16 participants to understand human preferences for different robot control profiles and augmented reality visuals in object handovers. Our results showed a general preference for the proposed approach and revealed insights that can guide further development in adapting the interaction with the user.

</details>


### [3] [Robot-Powered Data Flywheels: Deploying Robots in the Wild for Continual Data Collection and Foundation Model Adaptation](https://arxiv.org/abs/2511.19647)
*Jennifer Grannen,Michelle Pan,Kenneth Llontop,Cherie Ho,Mark Zolotas,Jeannette Bohg,Dorsa Sadigh*

Main category: cs.RO

TL;DR: 提出了机器人驱动的数据飞轮框架，将机器人从基础模型消费者转变为数据生成器。通过在真实环境中部署配备基础模型的机器人，实现良性循环：机器人执行有用任务的同时收集真实世界数据，用于改进领域特定适应和领域相邻泛化能力。


<details>
  <summary>Details</summary>
Motivation: 基础模型在视觉和语言任务中展现出强大的零样本能力，但依赖互联网预训练数据使其在非结构化真实环境中表现脆弱。真实世界中的杂乱数据（如遮挡或多语言文本）在现有语料库中严重不足。机器人作为具身代理，能够通过物理环境交互收集大规模真实世界数据来弥补这一差距。

Method: 开发了Scanford移动机械臂系统，在东亚图书馆部署2周。系统自主扫描书架，使用视觉语言模型识别书籍，并利用图书馆目录进行无人工标注的图像标记。通过2103个书架的数据收集，实现数据飞轮循环。

Result: Scanford将书籍识别准确率从32.0%提升至71.8%，领域相邻的多语言OCR性能从24.8%提升至46.6%（英文）和30.8%提升至38.0%（中文），同时节省约18.7小时人工时间。

Conclusion: 机器人驱动的数据飞轮既能减少真实部署中的人工努力，又能为基础模型持续适应现实世界的复杂性开辟新途径。

Abstract: Foundation models (FM) have unlocked powerful zero-shot capabilities in vision and language, yet their reliance on internet pretraining data leaves them brittle in unstructured, real-world settings. The messy, real-world data encountered during deployment (e.g. occluded or multilingual text) remains massively underrepresented in existing corpora. Robots, as embodied agents, are uniquely positioned to close this gap: they can act in physical environments to collect large-scale, real-world data that enriches FM training with precisely the examples current models lack. We introduce the Robot-Powered Data Flywheel, a framework that transforms robots from FM consumers into data generators. By deploying robots equipped with FMs in the wild, we enable a virtuous cycle: robots perform useful tasks while collecting real-world data that improves both domain-specific adaptation and domain-adjacent generalization. We instantiate this framework with Scanford, a mobile manipulator deployed in the East Asia Library for 2 weeks. Scanford autonomously scans shelves, identifies books using a vision-language model (VLM), and leverages the library catalog to label images without human annotation. This deployment both aids librarians and produces a dataset to finetune the underlying VLM, improving performance on the domain-specific in-the-wild library setting and on domain-adjacent multilingual OCR benchmarks. Using data collected from 2103 shelves, Scanford improves VLM performance on book identification from 32.0% to 71.8% and boosts domain-adjacent multilingual OCR from 24.8% to 46.6% (English) and 30.8% to 38.0% (Chinese), while saving an ~18.7 hrs of human time. These results highlight how robot-powered data flywheels can both reduce human effort in real deployments and unlock new pathways for continually adapting FMs to the messiness of reality. More details are at: https://scanford-robot.github.io

</details>


### [4] [Online Learning-Enhanced High Order Adaptive Safety Control](https://arxiv.org/abs/2511.19651)
*Lishuo Pan,Mattia Catellani,Thales C. Silva,Lorenzo Sabattini,Nora Ayanian*

Main category: cs.RO

TL;DR: 提出了一种基于神经ODE的在线学习增强高阶自适应控制屏障函数方法，能够在复杂时变模型扰动下实时提高CBF认证系统的安全性，并在38g纳米四旋翼上成功验证，在18km/h风速下保持与障碍物的安全距离。


<details>
  <summary>Details</summary>
Motivation: 控制屏障函数(CBFs)是保证系统安全性的有效工具，但其安全保证的成功转移到现实系统严重依赖于模型准确性。有效载荷或风扰动等会显著影响飞行器动力学并破坏安全保证。

Method: 使用神经ODE开发高效灵活的高阶自适应控制屏障函数，结合在线学习增强，在复杂时变模型扰动下实时改进CBF认证系统的安全性。

Result: 在38g纳米四旋翼上成功部署混合自适应CBF控制器，在18km/h风速下能够保持与障碍物的安全距离。

Conclusion: 该方法能够在复杂时变模型扰动下有效提高CBF认证系统的安全性，为现实世界系统的安全控制提供了可行解决方案。

Abstract: Control barrier functions (CBFs) are an effective model-based tool to formally certify the safety of a system. With the growing complexity of modern control problems, CBFs have received increasing attention in both optimization-based and learning-based control communities as a safety filter, owing to their provable guarantees. However, success in transferring these guarantees to real-world systems is critically tied to model accuracy. For example, payloads or wind disturbances can significantly influence the dynamics of an aerial vehicle and invalidate the safety guarantee. In this work, we propose an efficient yet flexible online learning-enhanced high-order adaptive control barrier function using Neural ODEs. Our approach improves the safety of a CBF-certified system on the fly, even under complex time-varying model perturbations. In particular, we deploy our hybrid adaptive CBF controller on a 38g nano quadrotor, keeping a safe distance from the obstacle, against 18km/h wind.

</details>


### [5] [Flow-Based Path Planning for Multiple Homogenous UAVs for Outdoor Formation-Flying](https://arxiv.org/abs/2511.19653)
*Mahmud Suhaimi Ibrahim,Shantanu Rahman,Muhammad Samin Hasan,Minhaj Uddin Ahmad,Abdullah Abrar*

Main category: cs.RO

TL;DR: 提出了一种基于流网络的多无人机编队飞行无碰撞路径规划方法，通过流网络图、最小成本路径算法和Ford-Fulkerson最大流方法实现安全路径规划。


<details>
  <summary>Details</summary>
Motivation: 多无人机编队飞行中的无碰撞路径规划是关键挑战，需要解决无人机间的碰撞问题。

Method: 1) 从GPS坐标构建流网络图；2) 使用图路径算法寻找最小成本路径；3) 应用Ford-Fulkerson方法寻找最大流无碰撞路径。

Result: 进行了最多64架无人机的仿真和3架四旋翼无人机的实际实验，验证了方法的有效性和可行性。

Conclusion: 该方法能够生成安全的无碰撞路径，在多无人机编队飞行中具有实用价值。

Abstract: Collision-free path planning is the most crucial component in multi-UAV formation-flying (MFF). We use unlabeled homogenous quadcopters (UAVs) to demonstrate the use of a flow network to create complete (inter-UAV) collision-free paths. This procedure has three main parts: 1) Creating a flow network graph from physical GPS coordinates, 2) Finding a path of minimum cost (least distance) using any graph-based path-finding algorithm, and 3) Implementing the Ford-Fulkerson Method to find the paths with the maximum flow (no collision). Simulations of up to 64 UAVs were conducted for various formations, followed by a practical experiment with 3 quadcopters for testing physical plausibility and feasibility. The results of these tests show the efficacy of this method's ability to produce safe, collision-free paths.

</details>


### [6] [Development of a Testbed for Autonomous Vehicles: Integrating MPC Control with Monocular Camera Lane Detection](https://arxiv.org/abs/2511.19655)
*Shantanu Rahman,Nayeb Hasin,Mainul Islam*

Main category: cs.RO

TL;DR: 提出了一种结合车道识别与模型预测控制(MPC)的新方法，用于提高自动驾驶汽车轨迹跟踪的精度和稳定性，在仿真中轨迹跟踪误差降低了27.65%。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆在道路应用中需要提高轨迹跟踪的精度和稳定性，特别是对于采用阿克曼转向机制的标准车辆。

Method: 使用边缘识别、滑动窗口直线识别进行车道线提取，结合基于自行车车辆动力学模型的MPC控制器，并在ROS Gazebo中构建单车道道路仿真模型进行验证。

Result: 仿真结果显示，最优跟踪轨迹与目标轨迹之间的均方根误差降低了27.65%，证明了所开发控制器的高鲁棒性和灵活性。

Conclusion: 结合车道识别与MPC的方法能有效提高自动驾驶车辆的轨迹跟踪性能，在仿真环境中表现出良好的控制效果。

Abstract: Autonomous vehicles are becoming popular day by day not only for autonomous road traversal but also for industrial automation, farming and military. Most of the standard vehicles follow the Ackermann style steering mechanism. This has become to de facto standard for large and long faring vehicles. The local planner of an autonomous vehicle controls the low-level vehicle movement upon which the vehicle will perform its motor actuation. In our work, we focus on autonomous vehicles in road and perform experiments to analyze the effect of low-level controllers in the simulation and a real environment. To increase the precision and stability of trajectory tracking in autonomous cars, a novel method that combines lane identification with Model Predictive Control (MPC) is presented. The research focuses on camera-equipped autonomous vehicles and uses methods like edge recognition, sliding window-based straight-line identification for lane line extraction, and dynamic region of interest (ROI) extraction. Next, to follow the identified lane line, an MPC built on a bicycle vehicle dynamics model is created. A single-lane road simulation model is built using ROS Gazebo and tested in order to verify the controller's performance. The root mean square error between the optimal tracking trajectory and the target trajectory was reduced by 27.65% in the simulation results, demonstrating the high robustness and flexibility of the developed controller.

</details>


### [7] [Multi-Agent gatekeeper: Safe Flight Planning and Formation Control for Urban Air Mobility](https://arxiv.org/abs/2511.19691)
*Thomas Marshall Vielmetti,Devansh R Agrawal,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出了Multi-Agent gatekeeper框架，为3D杂乱环境中的领导者-跟随者编队控制提供可证明的安全保证，通过领导者安全轨迹作为共享备份集，确保跟随者始终有安全备份机动。


<details>
  <summary>Details</summary>
Motivation: 现有方法面临权衡：在线规划器和控制器缺乏形式化安全保证，而离线规划器缺乏对代理数量或期望编队变化的适应性。

Method: 采用混合架构，单个领导者跟踪预计算的安全轨迹作为共享轨迹备份集，跟随者执行名义编队保持跟踪控制器，并始终拥有沿领导者路径的已知安全备份机动。

Result: 在模拟3D城市环境中，100次随机试验中实现了100%的碰撞避免成功率，显著优于基线CBF和NMPC方法，并在四旋翼无人机团队上验证了轨迹的物理可行性。

Conclusion: 该方法为多智能体系统提供了可证明的安全保证，是门卫框架在3D环境中的首次应用，实现了安全的多智能体协调。

Abstract: We present Multi-Agent gatekeeper, a framework that provides provable safety guarantees for leader-follower formation control in cluttered 3D environments. Existing methods face a trad-off: online planners and controllers lack formal safety guarantees, while offline planners lack adaptability to changes in the number of agents or desired formation. To address this gap, we propose a hybrid architecture where a single leader tracks a pre-computed, safe trajectory, which serves as a shared trajectory backup set for all follower agents. Followers execute a nominal formation-keeping tracking controller, and are guaranteed to remain safe by always possessing a known-safe backup maneuver along the leader's path. We formally prove this method ensures collision avoidance with both static obstacles and other agents. The primary contributions are: (1) the multi-agent gatekeeper algorithm, which extends our single-agent gatekeeper framework to multi-agent systems; (2) the trajectory backup set for provably safe inter-agent coordination for leader-follower formation control; and (3) the first application of the gatekeeper framework in a 3D environment. We demonstrate our approach in a simulated 3D urban environment, where it achieved a 100% collision-avoidance success rate across 100 randomized trials, significantly outperforming baseline CBF and NMPC methods. Finally, we demonstrate the physical feasibility of the resulting trajectories on a team of quadcopters.

</details>


### [8] [Whole-Body Inverse Dynamics MPC for Legged Loco-Manipulation](https://arxiv.org/abs/2511.19709)
*Lukas Molnar,Jin Cheng,Gabriele Fadini,Dongho Kang,Fatemeh Zargarbashi,Stelian Coros*

Main category: cs.RO

TL;DR: 提出了一个全身模型预测控制框架，通过全阶逆动力学直接优化关节扭矩，在单个预测层内实现统一的运动和力规划与执行，在四足机器人上实现了80Hz的实时性能。


<details>
  <summary>Details</summary>
Motivation: 全身运动操作需要协调的全身运动来有效操纵物体，同时保持运动稳定性，这对规划和控制都提出了重大挑战。

Method: 使用全身模型预测控制框架，通过全阶逆动力学直接优化关节扭矩，采用Pinocchio、CasADi软件框架和Fatrop求解器实现。

Result: 在配备机械臂的Unitree B2四足机器人上实现了80Hz的实时性能，成功完成了拉动重物、推箱子和擦拭白板等现实世界交互任务。

Conclusion: 该MPC框架能够实现物理一致的全身行为，有效处理系统动力学和物理约束，在实时机器人操作任务中表现出色。

Abstract: Loco-manipulation demands coordinated whole-body motion to manipulate objects effectively while maintaining locomotion stability, presenting significant challenges for both planning and control. In this work, we propose a whole-body model predictive control (MPC) framework that directly optimizes joint torques through full-order inverse dynamics, enabling unified motion and force planning and execution within a single predictive layer. This approach allows emergent, physically consistent whole-body behaviors that account for the system's dynamics and physical constraints. We implement our MPC formulation using open software frameworks (Pinocchio and CasADi), along with the state-of-the-art interior-point solver Fatrop. In real-world experiments on a Unitree B2 quadruped equipped with a Unitree Z1 manipulator arm, our MPC formulation achieves real-time performance at 80 Hz. We demonstrate loco-manipulation tasks that demand fine control over the end-effector's position and force to perform real-world interactions like pulling heavy loads, pushing boxes, and wiping whiteboards.

</details>


### [9] [Unifying Perception and Action: A Hybrid-Modality Pipeline with Implicit Visual Chain-of-Thought for Robotic Action Generation](https://arxiv.org/abs/2511.19859)
*Xiangkai Ma,Lekai Xing,Han Zhang,Wenzhong Li,Sanglu Lu*

Main category: cs.RO

TL;DR: 提出VITA框架，通过共享离散潜空间联合建模视觉和动作，解决视觉观察与低级动作之间的模态差距以及视觉预测与动作生成的竞争目标问题。


<details>
  <summary>Details</summary>
Motivation: 文本CoT难以在复杂空间环境中充分捕捉场景细节，而现有利用视觉先验的方法面临视觉观察与低级动作的模态差距，以及视觉预测与动作生成的训练不稳定问题。

Method: VITA框架学习视觉和动作的共享离散潜空间，通过自回归生成的token同时解码为未来帧预测和机器人动作，将视觉动态内化为运动规划的归纳偏置。

Result: 在CALVIN、LIBERO和SimplerEnv上分别比现有基线提升14.5%、9.6%和12.1%，在六个真实世界任务中平均成功率达到80.5%。

Conclusion: VITA展示了作为通用机器人操作模型的潜力，通过联合建模感知和运动控制实现了最先进的性能。

Abstract: Vision-Language-Action (VLA) models built upon Chain-of-Thought (CoT) have achieved remarkable success in advancing general-purpose robotic agents, owing to its significant perceptual comprehension. Recently, since text-only CoT struggles to adequately capture scene details in complex spatial environments, a highly promising strategy involves leveraging visual priors to guide robotic action generation. Nevertheless, these strategies face two inherent challenges: (i) a modality gap between visual observations and low-level actions, and (ii) unstable training due to competing objectives between visual prediction and action generation. To address these challenges, we propose a Vision-Integrated Trajectory Alignment (VITA) framework that learns a shared discrete latent space for vision and action, enabling joint modeling of perception and motor control. VITA introduces a implicit visual CoT: autoregressively generated tokens is simultaneously decoded into future frames predictions and robot actions, thereby internalizing visual dynamics as an inductive bias for motion planning. Extensive experiments on simulated and real-world environments demonstrate state-of-the-art performance. VITA improves 14.5\%, 9.6\% and 12.1\% over existing baselines on CALVIN, LIBERO and SimplerEnv. Furthermore, VITA attains an average success rate of 80.5\% across six real-world tasks, demonstrating its potential as a generalist robotic manipulation model.

</details>


### [10] [Human-Centered Cooperative Control Coupling Autonomous and Haptic Shared Control via Control Barrier Function](https://arxiv.org/abs/2511.19869)
*Eito Sato,Takahiro Wada*

Main category: cs.RO

TL;DR: 提出了一种结合独立操纵杆自主控制器与触觉共享控制的协作框架，通过控制屏障函数在安全区域内忽略操纵杆输入，在虚拟环境实验中相比传统触觉共享控制提高了精度并减少了所需时间。


<details>
  <summary>Details</summary>
Motivation: 当完全自主性受到不确定性或感知约束限制时，触觉共享控制(HSC)在遥操作中很有效。但由于操纵杆和人类手臂的动力学会影响机器人行为，仅通过最大化HSC强度获得的自主控制性能有限。

Method: 提出了一个协作框架，将独立于操纵杆的自主控制器与HSC耦合。控制屏障函数在由人类操作员实时确定的安全区域内忽略操纵杆输入，而在其他情况下启用HSC。

Result: 在虚拟环境中对遥操作水下机器人进行的模拟任务试点实验表明，相比传统HSC，该方法提高了精度并减少了所需时间。

Conclusion: 所提出的协作框架通过结合自主控制器和触觉共享控制，有效解决了传统HSC的性能限制问题，在遥操作任务中取得了更好的性能表现。

Abstract: Haptic shared control (HSC) is effective in teleoperation when full autonomy is limited by uncertainty or sensing constraints. However, autonomous control performance achieved by maximizing HSC strength is limited because the dynamics of the joystick and human arm affect the robot's behavior. We propose a cooperative framework coupling a joystick-independent autonomous controller with HSC. A control barrier function ignores joystick inputs within a safe region determined by the human operator in real-time, while HSC is engaged otherwise. A pilot experiment on simulated tasks with tele-operated underwater robot in virtual environment demonstrated improved accuracy and reduced required time over conventional HSC.

</details>


### [11] [CoC-VLA: Delving into Adversarial Domain Transfer for Explainable Autonomous Driving via Chain-of-Causality Visual-Language-Action Model](https://arxiv.org/abs/2511.19914)
*Dapeng Zhang,Fei Shen,Rui Zhao,Yinda Chen,Peng Zhi,Chenyang Li,Rui Zhou,Qingguo Zhou*

Main category: cs.RO

TL;DR: 提出了CoC-VLA框架，通过对抗迁移学习将仿真环境中的长尾场景处理能力迁移到真实世界自动驾驶系统中，结合教师-学生VLM模型和判别器实现端到端的知识转移。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么依赖真实世界数据（适合工业部署），要么使用针对罕见场景的仿真数据，但很少能有效整合两者的互补优势。需要解决仿真到真实世界的长尾场景处理能力迁移问题。

Method: 提出CoC-VLA框架，包含教师VLM、学生VLM和判别器。采用共享的因果链视觉语言模型(CoC VLM)架构，集成时间信息并通过端到端文本适配器支持链式推理。教师和学生VLM分别在仿真和真实数据集上预训练，判别器通过对抗训练和新型反向传播策略促进能力迁移。

Result: 框架能够有效将仿真环境中的长尾场景处理能力迁移到真实世界部署中，提升自动驾驶系统在复杂情况下的推理和性能表现。

Conclusion: CoC-VLA框架成功解决了仿真与真实世界数据源的有效整合问题，通过对抗迁移学习实现了长尾场景处理能力的跨域转移，为自动驾驶系统提供了更全面的场景覆盖能力。

Abstract: Autonomous driving represents a prominent application of artificial intelligence. Recent approaches have shifted from focusing solely on common scenarios to addressing complex, long-tail situations such as subtle human behaviors, traffic accidents, and non-compliant driving patterns. Given the demonstrated capabilities of large language models (LLMs) in understanding visual and natural language inputs and following instructions, recent methods have integrated LLMs into autonomous driving systems to enhance reasoning, interpretability, and performance across diverse scenarios. However, existing methods typically rely either on real-world data, which is suitable for industrial deployment, or on simulation data tailored to rare or hard case scenarios. Few approaches effectively integrate the complementary advantages of both data sources. To address this limitation, we propose a novel VLM-guided, end-to-end adversarial transfer framework for autonomous driving that transfers long-tail handling capabilities from simulation to real-world deployment, named CoC-VLA. The framework comprises a teacher VLM model, a student VLM model, and a discriminator. Both the teacher and student VLM models utilize a shared base architecture, termed the Chain-of-Causality Visual-Language Model (CoC VLM), which integrates temporal information via an end-to-end text adapter. This architecture supports chain-of-thought reasoning to infer complex driving logic. The teacher and student VLM models are pre-trained separately on simulated and real-world datasets. The discriminator is trained adversarially to facilitate the transfer of long-tail handling capabilities from simulated to real-world environments by the student VLM model, using a novel backpropagation strategy.

</details>


### [12] [Collaborate sim and real: Robot Bin Packing Learning in Real-world and Physical Engine](https://arxiv.org/abs/2511.19932)
*Lidi Zhang,Han Wu,Liyu Zhang,Ruofeng Liu,Haotian Wang,Chao Li,Desheng Zhang,Yunhuai Liu,Tian He*

Main category: cs.RO

TL;DR: 提出了一种结合物理仿真和真实世界数据反馈的混合强化学习框架，用于解决3D装箱问题中的仿真到现实差距问题，显著降低了包装坍塌率。


<details>
  <summary>Details</summary>
Motivation: 现有的3D装箱方法通常将其建模为离散和静态过程，而实际应用涉及连续的重力驱动交互，这种理想化简化导致实际部署不可行（如不稳定包装）。物理仿真与真实世界物理属性（如摩擦系数、弹性、重量分布）的动态变化之间存在仿真到现实差距。

Method: 1. 在仿真中应用领域随机化，让智能体接触各种物理参数以增强泛化能力；2. 使用真实世界部署反馈对RL智能体进行微调，进一步降低坍塌率。

Result: 大量实验表明该方法在仿真和真实场景中都实现了更低的坍塌率。在物流系统中的大规模部署验证了实际有效性，与基线方法相比包装坍塌减少了35%。

Conclusion: 提出的混合RL框架通过结合物理仿真和真实世界反馈，有效解决了3D装箱问题中的仿真到现实差距，显著提高了包装稳定性，具有实际应用价值。

Abstract: The 3D bin packing problem, with its diverse industrial applications, has garnered significant research attention in recent years. Existing approaches typically model it as a discrete and static process, while real-world applications involve continuous gravity-driven interactions. This idealized simplification leads to infeasible deployments (e.g., unstable packing) in practice. Simulations with physical engine offer an opportunity to emulate continuous gravity effects, enabling the training of reinforcement learning (RL) agents to address such limitations and improve packing stability. However, a simulation-to-reality gap persists due to dynamic variations in physical properties of real-world objects, such as various friction coefficients, elasticity, and non-uniform weight distributions. To bridge this gap, we propose a hybrid RL framework that collaborates with physical simulation with real-world data feedback. Firstly, domain randomization is applied during simulation to expose agents to a spectrum of physical parameters, enhancing their generalization capability. Secondly, the RL agent is fine-tuned with real-world deployment feedback, further reducing collapse rates. Extensive experiments demonstrate that our method achieves lower collapse rates in both simulated and real-world scenarios. Large-scale deployments in logistics systems validate the practical effectiveness, with a 35\% reduction in packing collapse compared to baseline methods.

</details>


### [13] [ShapeForce: Low-Cost Soft Robotic Wrist for Contact-Rich Manipulation](https://arxiv.org/abs/2511.19955)
*Jinxuan Zhu,Zihao Yan,Yangyu Xiao,Jingxiang Guo,Chenrui Tie,Xinyi Cao,Yuhang Zheng,Lin Shao*

Main category: cs.RO

TL;DR: ShapeForce是一个低成本、即插即用的软手腕，通过将外力扭矩转换为可测量的形变来提供类似力的信号，用于接触丰富的机器人操作任务。


<details>
  <summary>Details</summary>
Motivation: 六维力扭矩传感器成本高且易碎，限制了在接触丰富任务中的应用。需要提供更经济易用的接触反馈方案。

Method: 通过柔性核心将外力扭矩转换为形变，使用基于标记的姿态跟踪估计形变，然后转换为类似力的信号。无需校准或专用电子设备。

Result: 在多种接触丰富任务和操作策略的广泛实验中，ShapeForce以极低成本实现了与六维力扭矩传感器相当的性能。

Conclusion: ShapeForce为接触丰富的机器人操作提供了经济高效的接触反馈解决方案，性能可与昂贵传感器相媲美。

Abstract: Contact feedback is essential for contact-rich robotic manipulation, as it allows the robot to detect subtle interaction changes and adjust its actions accordingly. Six-axis force-torque sensors are commonly used to obtain contact feedback, but their high cost and fragility have discouraged many researchers from adopting them in contact-rich tasks. To offer a more cost-efficient and easy-accessible source of contact feedback, we present ShapeForce, a low-cost, plug-and-play soft wrist that provides force-like signals for contact-rich robotic manipulation. Inspired by how humans rely on relative force changes in contact rather than precise force magnitudes, ShapeForce converts external force and torque into measurable deformations of its compliant core, which are then estimated via marker-based pose tracking and converted into force-like signals. Our design eliminates the need for calibration or specialized electronics to obtain exact values, and instead focuses on capturing force and torque changes sufficient for enabling contact-rich manipulation. Extensive experiments across diverse contact-rich tasks and manipulation policies demonstrate that ShapeForce delivers performance comparable to six-axis force-torque sensors at an extremely low cost.

</details>


### [14] [Active3D: Active High-Fidelity 3D Reconstruction via Hierarchical Uncertainty Quantification](https://arxiv.org/abs/2511.20050)
*Yan Li,Yingzhao Li,Gim Hee Lee*

Main category: cs.RO

TL;DR: 提出了一种用于高保真3D重建的主动探索框架，通过构建多级不确定性空间和不确定性驱动的运动规划来选择最佳视角。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D重建方法在复杂场景中难以平衡全局结构先验和局部细节捕捉的问题，以及缺乏有效的主动探索策略来优化重建质量。

Method: 采用混合隐式-显式表示融合神经场和高斯基元；构建分层不确定性体积量化全局结构质量和局部表面置信度；提出不确定性驱动的关键帧选择策略和视角空间滑动窗口；将最佳视角选择建模为期望混合信息增益问题。

Result: 在具有挑战性的基准测试中，该方法在精度、完整性和渲染质量方面均达到最先进水平。

Conclusion: 该方法在真实世界主动重建和机器人感知任务中表现出色，证明了其有效性。

Abstract: In this paper, we present an active exploration framework for high-fidelity 3D reconstruction that incrementally builds a multi-level uncertainty space and selects next-best-views through an uncertainty-driven motion planner. We introduce a hybrid implicit-explicit representation that fuses neural fields with Gaussian primitives to jointly capture global structural priors and locally observed details. Based on this hybrid state, we derive a hierarchical uncertainty volume that quantifies both implicit global structure quality and explicit local surface confidence. To focus optimization on the most informative regions, we propose an uncertainty-driven keyframe selection strategy that anchors high-entropy viewpoints as sparse attention nodes, coupled with a viewpoint-space sliding window for uncertainty-aware local refinement. The planning module formulates next-best-view selection as an Expected Hybrid Information Gain problem and incorporates a risk-sensitive path planner to ensure efficient and safe exploration. Extensive experiments on challenging benchmarks demonstrate that our approach consistently achieves state-of-the-art accuracy, completeness, and rendering quality, highlighting its effectiveness for real-world active reconstruction and robotic perception tasks.

</details>


### [15] [Hibikino-Musashi@Home 2025 Team Description Paper](https://arxiv.org/abs/2511.20180)
*Ryohei Kobayashi,Kosei Isomoto,Kosei Yamao,Soma Fumoto,Koshun Arimura,Naoki Yamaguchi,Akinobu Mizutani,Tomoya Shiba,Kouki Kimizuka,Yuta Ohno,Ryo Terashima,Hiromasa Yamaguchi,Tomoaki Fujino,Ryoga Maruno,Wataru Yoshimura,Kazuhito Mine,Tang Phu Thien Nhan,Yuga Yano,Yuichiro Tanaka,Takeshi Nishida,Takashi Morie,Hakaru Tamukoh*

Main category: cs.RO

TL;DR: Hibikino-Musashi@Home团队开发了用于家庭服务机器人的数据集生成器、开源开发环境、LLM任务规划器和脑启发记忆模型，旨在提供直观个性化家庭辅助服务。


<details>
  <summary>Details</summary>
Motivation: 设计能够协助人类在家庭环境中完成任务的机器人，并通过持续参与竞赛来评估和改进系统性能。

Method: 开发数据集生成器训练机器人视觉系统，创建开源开发环境，使用大语言模型进行任务规划，研究脑启发记忆模型以适应个体家庭环境。

Result: 团队开发了完整的技术栈，包括视觉系统训练工具、模拟器环境、智能任务规划器和个性化适应机制，并贡献了导航系统的可重用性。

Conclusion: 该团队通过综合技术方法构建了家庭服务机器人系统，并通过竞赛验证系统性能，为个性化家庭辅助服务提供了可行方案。

Abstract: This paper provides an overview of the techniques employed by Hibikino-Musashi@Home, which intends to participate in the domestic standard platform league. The team developed a dataset generator for training a robot vision system and an open-source development environment running on a Human Support Robot simulator. The large-language-model-powered task planner selects appropriate primitive skills to perform the task requested by the user. Moreover, the team has focused on research involving brain-inspired memory models for adaptation to individual home environments. This approach aims to provide intuitive and personalized assistance. Additionally, the team contributed to the reusability of the navigation system developed by Pumas in RoboCup2024. The team aimed to design a home service robot to assist humans in their homes and continuously attend competitions to evaluate and improve the developed system.

</details>


### [16] [Toward generic control for soft robotic systems](https://arxiv.org/abs/2511.20226)
*Yu Sun,Yaosheng Deng,Wenjie Mei,Xiaogang Xiong,Yang Bai,Masaki Ogura,Zeyu Zhou,Mir Feroskhan,Michael Yu Wang,Qiyang Zuo,Yao Li,Yunjiang Lou*

Main category: cs.RO

TL;DR: 提出了一种基于控制柔顺性的通用软体机器人控制框架，通过利用而非抑制近似动作表示来实现鲁棒性和适应性，验证了跨不同形态和驱动机制的稳定、安全、可迁移控制。


<details>
  <summary>Details</summary>
Motivation: 软体机器人控制方法仍处于碎片化状态，不同形态和驱动方案需要特定控制器，阻碍了理论整合和大规模部署。刚性机器人控制逻辑依赖精确模型和严格低级执行，不适用于软体机器人，而控制柔顺性（容忍和利用近似动作表示的能力）是鲁棒性和适应性的基础。

Method: 受人类运动控制启发，提出基于控制柔顺性的通用软体机器人控制框架：通过高层运动趋势表达意图，而反射和生物力学机制自主解决局部细节，不计算精确动力学或发出详细肌肉级命令。

Result: 在具有不同形态和驱动机制的机器人上验证了该框架，展示了稳定、安全且跨平台可迁移的行为表现。

Conclusion: 拥抱而非抵抗控制柔顺性可能为统一的软体机器人控制提供广泛应用基础，实现鲁棒性、灵活性和跨任务泛化能力。

Abstract: Soft robotics has advanced rapidly, yet its control methods remain fragmented: different morphologies and actuation schemes still require task-specific controllers, hindering theoretical integration and large-scale deployment. A generic control framework is therefore essential, and a key obstacle lies in the persistent use of rigid-body control logic, which relies on precise models and strict low-level execution. Such a paradigm is effective for rigid robots but fails for soft robots, where the ability to tolerate and exploit approximate action representations, i.e., control compliance, is the basis of robustness and adaptability rather than a disturbance to be eliminated. Control should thus shift from suppressing compliance to explicitly exploiting it. Human motor control exemplifies this principle: instead of computing exact dynamics or issuing detailed muscle-level commands, it expresses intention through high-level movement tendencies, while reflexes and biomechanical mechanisms autonomously resolve local details. This architecture enables robustness, flexibility, and cross-task generalization. Motivated by this insight, we propose a generic soft-robot control framework grounded in control compliance and validate it across robots with diverse morphologies and actuation mechanisms. The results demonstrate stable, safe, and cross-platform transferable behavior, indicating that embracing control compliance, rather than resisting it, may provide a widely applicable foundation for unified soft-robot control.

</details>


### [17] [HAFO: Humanoid Force-Adaptive Control for Intense External Force Interaction Environments](https://arxiv.org/abs/2511.20275)
*Chenhui Dong,Haozhe Xu,Wenhao Feng,Zhipeng Wang,Yanmin Zhou,Yifei Zhao,Bin He*

Main category: cs.RO

TL;DR: HAFO是一个双智能体强化学习控制框架，通过耦合训练同时优化稳健的步态策略和精确的上半身操作策略，在强外力交互环境下实现人形机器人的稳定控制。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习控制器在人形机器人步态和轻负载操作方面取得进展，但在强外力交互下实现稳健精确运动仍面临挑战。

Method: 提出双智能体强化学习框架，通过弹簧-阻尼系统显式建模外部拉力干扰，利用非对称Actor-Critic框架，Critic网络访问特权弹簧阻尼力信息指导Actor网络学习通用稳健策略。

Result: HAFO在各种强外力交互下实现了人形机器人的稳定控制，在负载任务中表现出色，并在绳索拉力干扰下确保机器人稳定运行。

Conclusion: 该框架成功实现了在强外力交互环境下的人形机器人稳健控制，展示了在复杂动态环境中的优异性能。

Abstract: Reinforcement learning controllers have made impressive progress in humanoid locomotion and light load manipulation. However, achieving robust and precise motion with strong force interaction remains a significant challenge. Based on the above limitations, this paper proposes HAFO, a dual-agent reinforcement learning control framework that simultaneously optimizes both a robust locomotion strategy and a precise upper-body manipulation strategy through coupled training under external force interaction environments. Simultaneously, we explicitly model the external pulling disturbances through a spring-damper system and achieve fine-grained force control by manipulating the virtual spring. During this process, the reinforcement-learning policy spontaneously generates disturbance-rejection response by exploiting environmental feedback. Moreover, HAFO employs an asymmetric Actor-Critic framework in which the Critic-network access to privileged spring-damping forces guides the actor-network to learn a generalizable, robust policy for resisting external disturbances. The experimental results demonstrate that HAFO achieves stable control of humanoid robot under various strong force interactions, showing remarkable performance in load tasks and ensuring stable robot operation under rope tension disturbances. Project website: hafo-robot.github.io.

</details>


### [18] [Dynamic-ICP: Doppler-Aware Iterative Closest Point Registration for Dynamic Scenes](https://arxiv.org/abs/2511.20292)
*Dong Wang,Daniel Casado Herraez,Stefan May,Andreas Nüchter*

Main category: cs.RO

TL;DR: Dynamic-ICP是一种基于多普勒感知的激光雷达里程计方法，通过在动态环境中使用多普勒速度信息来改进点云配准精度。


<details>
  <summary>Details</summary>
Motivation: 在高度动态环境中，传统的ICP配准方法假设场景近似静态，在重复或低纹理几何中性能下降。需要一种能够处理动态物体的可靠里程计方法。

Method: 该方法包括四个步骤：(i)通过稳健回归从点级多普勒速度估计自我运动并构建速度滤波器；(ii)聚类动态物体并从自我补偿的径向测量重建物体平移速度；(iii)使用恒定速度模型预测动态点；(iv)使用结合点面几何残差和旋转不变多普勒残差的紧凑目标函数对齐扫描。

Result: 在三个数据集（HeRCULES、HeLiPR、AevaScenes）上的评估显示，Dynamic-ICP在旋转稳定性和平移精度方面持续优于最先进方法。

Conclusion: Dynamic-ICP提供了一种无需外部传感器或传感器-车辆标定的轻量级解决方案，可在动态环境中实现实时鲁棒配准，易于集成到现有流程中。

Abstract: Reliable odometry in highly dynamic environments remains challenging when it relies on ICP-based registration: ICP assumes near-static scenes and degrades in repetitive or low-texture geometry. We introduce Dynamic-ICP, a Doppler-aware registration framework. The method (i) estimates ego motion from per-point Doppler velocity via robust regression and builds a velocity filter, (ii) clusters dynamic objects and reconstructs object-wise translational velocities from ego-compensated radial measurements, (iii) predicts dynamic points with a constant-velocity model, and (iv) aligns scans using a compact objective that combines point-to-plane geometry residual with a translation-invariant, rotation-only Doppler residual. The approach requires no external sensors or sensor-vehicle calibration and operates directly on FMCW LiDAR range and Doppler velocities. We evaluate Dynamic-ICP on three datasets-HeRCULES, HeLiPR, AevaScenes-focusing on highly dynamic scenes. Dynamic-ICP consistently improves rotational stability and translation accuracy over the state-of-the-art methods. Our approach is also simple to integrate into existing pipelines, runs in real time, and provides a lightweight solution for robust registration in dynamic environments. To encourage further research, the code is available at: https://github.com/JMUWRobotics/Dynamic-ICP.

</details>


### [19] [How Robot Kinematics Influence Human Performance in Virtual Robot-to-Human Handover Tasks](https://arxiv.org/abs/2511.20299)
*Róisín Keenan,Joost C. Dessing*

Main category: cs.RO

TL;DR: 研究使用VR探索人机协作中的物体传递任务，发现人类受益于机器人提供早期视觉信息和平滑轨迹，这能提高预测准确性和同步性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统越来越多地融入人类工作场所，需要优化人机协作协调性，特别是在物体传递任务中。

Method: 通过VR模拟机器人传递任务，分别测试了四个影响因素：任务启动控制和机器人运动同步性、伙伴外观、机器人速度曲线、物体旋转运动时机。

Result: 人类在机器人提供早期视觉信息和平滑轨迹时表现更好，这些因素不同程度地提高了预测准确性和交互同步性。

Conclusion: 人机交互设计应让人类能够利用其检测生物运动的自然能力，从而减少机器人计算成本或人类认知适应需求。

Abstract: Recent advancements in robotics have increased the possibilities for integrating robotic systems into human-involved workplaces, highlighting the need to examine and optimize human-robot coordination in collaborative settings. This study explores human-robot interactions during handover tasks using Virtual Reality (VR) to investigate differences in human motor performance across various task dynamics and robot kinematics. A VR-based robot handover simulation afforded safe and controlled assessments of human-robot interactions. In separate experiments, four potential influences on human performance were examined (1) control over task initiation and robot movement synchrony (temporal and spatiotemporal); (2) partner appearance (human versus robotic); (3) robot velocity profiles (minimum jerk, constant velocity, constant acceleration, and biphasic); and (4) the timing of rotational object motion. Findings across experiments emphasize humans benefit from robots providing early and salient visual information about task-relevant object motion, and advantages of human-like smooth robot trajectories. To varying degrees, these manipulations improved predictive accuracy and synchronization during interaction. This suggests that human-robot interactions should be designed to allow humans to leverage their natural capabilities for detecting biological motion, which conversely may reduce the need for costly robotic computations or added cognitive adaptation on the human side.

</details>


### [20] [ArtiBench and ArtiBrain: Benchmarking Generalizable Vision-Language Articulated Object Manipulation](https://arxiv.org/abs/2511.20330)
*Yuhan Wu,Tiantian Wei,Shuo Wang,ZhiChao Wang,Yanyong Zhang,Daniel Cremers,Yan Xia*

Main category: cs.RO

TL;DR: 提出了ArtiBench基准测试和ArtiBrain框架，用于解决关节物体操作中的泛化挑战，结合高层推理和自适应底层控制，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言和基于扩散的策略在跨部件、实例和类别的关节操作中泛化能力不足，需要解决长时程、多步骤交互的物理一致性挑战。

Method: ArtiBrain采用模块化框架：使用VLM任务推理器分解和验证子目标，混合控制器结合几何感知关键帧执行和可供性引导扩散，通过可供性记忆库积累和传播成功经验。

Result: 在ArtiBench上的广泛实验表明，ArtiBrain在鲁棒性和泛化能力上显著优于最先进的多模态和基于扩散的方法。

Conclusion: ArtiBrain框架通过统一高层推理和自适应控制，有效解决了关节物体操作的泛化挑战，为交互式关节操作提供了可行的解决方案。

Abstract: Interactive articulated manipulation requires long-horizon, multi-step interactions with appliances while maintaining physical consistency. Existing vision-language and diffusion-based policies struggle to generalize across parts, instances, and categories. We first introduce ArtiBench, a five-level benchmark covering kitchen, storage, office, and tool environments. ArtiBench enables structured evaluation from cross-part and cross-instance variation to long-horizon multi-object tasks, revealing the core generalization challenges of articulated object manipulation. Building on this benchmark, we propose ArtiBrain, a modular framework that unifies high-level reasoning with adaptive low-level control. ArtiBrain uses a VLM-based Task Reasoner (GPT-4.1) to decompose and validate subgoals, and employs a Hybrid Controller that combines geometry-aware keyframe execution with affordance-guided diffusion for precise and interpretable manipulation. An Affordance Memory Bank continually accumulates successful execution episodes and propagates part-level actionable affordances to unseen articulated parts and configurations. Extensive experiments on ArtiBench show that our ArtiBrain significantly outperforms state-of-the-art multimodal and diffusion-based methods in robustness and generalization. Code and dataset will be released upon acceptance.

</details>


### [21] [Quality-guided UAV Surface Exploration for 3D Reconstruction](https://arxiv.org/abs/2511.20353)
*Benjamin Sportich,Kenza Boubakri,Olivier Simonin,Alessandro Renzaglia*

Main category: cs.RO

TL;DR: 提出了一种用于空中机器人的模块化Next-Best-View规划框架，通过重建质量目标指导探索规划，在覆盖范围、3D地图质量和路径效率方面优于传统NBV策略。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在未知环境中的建图需求广泛，但现有规划策略往往忽视了不同应用场景（如快速信息收集和建筑结构评估）对方法的不同要求。

Method: 开发了基于截断符号距离场(TSDF)的模块化NBV规划框架，包含自适应于用户定义质量要求的视图生成和视点候选选择方法，充分利用环境不确定性信息。

Result: 在真实环境中的广泛仿真验证表明，该方法能成功根据用户目标调整行为，在覆盖范围、最终3D地图质量和路径效率方面持续优于传统NBV策略。

Conclusion: 所提出的框架能够根据预定目标进行信息化和高效的探索决策，为不同质量要求的建图任务提供了有效的解决方案。

Abstract: Reasons for mapping an unknown environment with autonomous robots are wide-ranging, but in practice, they are often overlooked when developing planning strategies. Rapid information gathering and comprehensive structural assessment of buildings have different requirements and therefore necessitate distinct methodologies. In this paper, we propose a novel modular Next-Best-View (NBV) planning framework for aerial robots that explicitly uses a reconstruction quality objective to guide the exploration planning. In particular, our approach introduces new and efficient methods for view generation and selection of viewpoint candidates that are adaptive to the user-defined quality requirements, fully exploiting the uncertainty encoded in a Truncated Signed Distance field (TSDF) representation of the environment. This results in informed and efficient exploration decisions tailored towards the predetermined objective. Finally, we validate our method via extensive simulations in realistic environments. We demonstrate that it successfully adjusts its behavior to the user goal while consistently outperforming conventional NBV strategies in terms of coverage, quality of the final 3D map and path efficiency.

</details>


### [22] [Improved adaptive wind driven optimization algorithm for real-time path planning](https://arxiv.org/abs/2511.20394)
*Shiqian Liu,Azlan Mohd Zain,Le-le Mao*

Main category: cs.RO

TL;DR: 提出了一种改进的风驱动优化算法MAWDO，通过分层引导机制在动态环境中实现更好的路径规划性能，缩短路径长度并提高平滑度。


<details>
  <summary>Details</summary>
Motivation: 动态环境中的实时适应性是自主导航的关键挑战，需要生成无碰撞、平滑且高效的轨迹。风驱动优化算法因其物理可解释的搜索动态而具有潜力。

Method: 提出了多层级自适应风驱动优化(MAWDO)，采用分层引导机制将种群划分为多个组，由个体、区域和全局领导者引导，平衡探索与利用。

Result: 在16个基准函数上评估显示MAWDO具有优越的优化精度、收敛稳定性和适应性。在动态路径规划中，路径长度缩短至469.28像素，比MEWDO、AWDO和WDO分别提升3.51%、11.63%和14.93%，最优性差距最小(1.01)，平滑度为0.71。

Conclusion: MAWDO能够在复杂环境中生成更平滑、更短且无碰撞的轨迹，证实了其在实时路径规划中的有效性。

Abstract: Recently, path planning has achieved remarkable progress in enhancing global search capability and convergence accuracy through heuristic and learning-inspired optimization frameworks. However, real-time adaptability in dynamic environments remains a critical challenge for autonomous navigation, particularly when robots must generate collision-free, smooth, and efficient trajectories under complex constraints. By analyzing the difficulties in dynamic path planning, the Wind Driven Optimization (WDO) algorithm emerges as a promising framework owing to its physically interpretable search dynamics. Motivated by these observations, this work revisits the WDO principle and proposes a variant formulation, Multi-hierarchical adaptive wind driven optimization(MAWDO), that improves adaptability and robustness in time-varying environments. To mitigate instability and premature convergence, a hierarchical-guidance mechanism divides the population into multiple groups guided by individual, regional, and global leaders to balance exploration and exploitation. Extensive evaluations on sixteen benchmark functions show that MAWDO achieves superior optimization accuracy, convergence stability, and adaptability over state-of-the art metaheuristics. In dynamic path planning, MAWDO shortens the path length to 469.28 pixels, improving over Multi-strategy ensemble wind driven optimization(MEWDO), Adaptive wind driven optimization(AWDO) and WDO by 3.51\%, 11.63\% and 14.93\%, and achieves the smallest optimality gap (1.01) with smoothness 0.71 versus 13.50 and 15.67 for AWDO and WDO, leading to smoother, shorter, and collision-free trajectories that confirm its effectiveness for real-time path planning in complex environments.

</details>


### [23] [Power-Efficient Autonomous Mobile Robots](https://arxiv.org/abs/2511.20467)
*Liangkai Liu,Weisong Shi,Kang G. Shin*

Main category: cs.RO

TL;DR: pNav是一个新型的功率管理系统，通过联合优化物理/机械和网络子系统，显著提高了自主移动机器人(AMR)的功率/能效。


<details>
  <summary>Details</summary>
Motivation: 通过分析AMR的功耗特性，发现实现CPS(网络物理系统)功率效率面临三个挑战：系统功耗分解的可变性、环境感知导航的局部性、以及网络和物理子系统的协调。

Method: 采用多层面方法：集成毫秒级功耗预测、实时建模和监控导航时空局部性、动态协调软件和硬件配置。基于ROS导航栈、2D LiDAR和摄像头构建原型。

Result: 在真实机器人和Gazebo环境中的评估显示，功耗预测准确率>96%，功耗降低38.1%，且不影响导航精度和安全性。

Conclusion: pNav系统有效解决了AMR功率效率问题，实现了显著的功耗降低和准确的功耗预测。

Abstract: This paper presents pNav, a novel power-management system that significantly enhances the power/energy-efficiency of Autonomous Mobile Robots (AMRs) by jointly optimizing their physical/mechanical and cyber subsystems. By profiling AMRs' power consumption, we identify three challenges in achieving CPS (cyber-physical system) power-efficiency that involve both cyber (C) and physical (P) subsystems: (1) variabilities of system power consumption breakdown, (2) environment-aware navigation locality, and (3) coordination of C and P subsystems. pNav takes a multi-faceted approach to achieve power-efficiency of AMRs. First, it integrates millisecond-level power consumption prediction for both C and P subsystems. Second, it includes novel real-time modeling and monitoring of spatial and temporal navigation localities for AMRs. Third, it supports dynamic coordination of AMR software (navigation, detection) and hardware (motors, DVFS driver) configurations. pNav is prototyped using the Robot Operating System (ROS) Navigation Stack, 2D LiDAR, and camera. Our in-depth evaluation with a real robot and Gazebo environments demonstrates a >96% accuracy in predicting power consumption and a 38.1% reduction in power consumption without compromising navigation accuracy and safety.

</details>


### [24] [Kleinkram: Open Robotic Data Management](https://arxiv.org/abs/2511.20492)
*Cyrill Püntener,Johann Schwabe,Dominique Garmier,Jonas Frey,Marco Hutter*

Main category: cs.RO

TL;DR: Kleinkram是一个开源系统，用于管理大规模非结构化机器人数据集，提供可扩展存储、索引和共享功能，支持ROS bags和MCAP等标准格式，并包含基于Docker的工作流执行器。


<details>
  <summary>Details</summary>
Motivation: 解决管理大规模、非结构化机器人数据集的挑战，支持从个体实验到大规模研究集合的数据管理需求。

Method: 采用模块化、本地云解决方案，集成S3兼容存储，原生支持ROS bags和MCAP格式，并包含可定制的Docker工作流执行器（Action Runner）。

Result: 已成功管理超过30TB来自不同机器人系统的数据，通过现代Web界面和强大CLI简化研究生命周期。

Conclusion: Kleinkram提供了一个有效的解决方案，能够满足机器人研究中对大规模数据集管理的需求，具有灵活性和可扩展性。

Abstract: We introduce Kleinkram, a free and open-source system designed to solve the challenge of managing massive, unstructured robotic datasets. Designed as a modular, on-premises cloud solution, Kleinkram enables scalable storage, indexing, and sharing of datasets, ranging from individual experiments to large-scale research collections. Kleinkram natively integrates with standard formats such as ROS bags and MCAP and utilises S3-compatible storage for flexibility. Beyond storage, Kleinkram features an integrated "Action Runner" that executes customizable Docker-based workflows for data validation, curation, and benchmarking. Kleinkram has successfully managed over 30 TB of data from diverse robotic systems, streamlining the research lifecycle through a modern web interface and a robust Command Line Interface (CLI).

</details>


### [25] [Metric, inertially aligned monocular state estimation via kinetodynamic priors](https://arxiv.org/abs/2511.20496)
*Jiaxin Liu,Min Li,Wanting Xu,Liang Li,Jiaqi Yang,Laurent Kneip*

Main category: cs.RO

TL;DR: 提出了一种将现有刚体姿态估计方法扩展到非刚性系统的框架，通过结合学习的变形-力模型和连续时间B样条运动模型，建立视觉轨迹加速度与变形诱导加速度之间的物理联系。


<details>
  <summary>Details</summary>
Motivation: 柔性机器人系统的精确状态估计面临重大挑战，特别是对于具有动态变形结构的平台，这些结构使刚体假设失效。本文旨在解决这个问题，将现有的刚体姿态估计方法扩展到非刚性系统。

Method: 使用多层感知器学习注入式变形-力模型来捕捉弹性特性；采用连续时间B样条运动模型求解平台的平滑运动；通过连续应用牛顿第二定律，建立视觉轨迹加速度与预测变形诱导加速度之间的物理联系。

Result: 该方法不仅能在非刚性平台上实现稳健准确的姿态估计，而且正确建模的平台物理特性激发了惯性传感特性。在简单的弹簧相机系统上验证了可行性，并展示了如何稳健解决单目视觉里程计中度量尺度和重力恢复这一通常不适定问题。

Conclusion: 所提出的方法成功地将刚体姿态估计扩展到非刚性系统，通过物理建模实现了准确的姿态估计，并解决了单目视觉里程计中的尺度和重力恢复问题。

Abstract: Accurate state estimation for flexible robotic systems poses significant challenges, particular for platforms with dynamically deforming structures that invalidate rigid-body assumptions. This paper tackles this problem and allows to extend existing rigid-body pose estimation methods to non-rigid systems. Our approach hinges on two core assumptions: first, the elastic properties are captured by an injective deformation-force model, efficiently learned via a Multi-Layer Perceptron; second, we solve the platform's inherently smooth motion using continuous-time B-spline kinematic models. By continuously applying Newton's Second Law, our method establishes a physical link between visually-derived trajectory acceleration and predicted deformation-induced acceleration. We demonstrate that our approach not only enables robust and accurate pose estimation on non-rigid platforms, but that the properly modeled platform physics instigate inertial sensing properties. We demonstrate this feasibility on a simple spring-camera system, and show how it robustly resolves the typically ill-posed problem of metric scale and gravity recovery in monocular visual odometry.

</details>


### [26] [Gated Uncertainty-Aware Runtime Dual Invariants for Neural Signal-Controlled Robotics](https://arxiv.org/abs/2511.20570)
*Tasha Kim,Oiwi Parker Jones*

Main category: cs.RO

TL;DR: GUARDIAN是一个用于神经信号控制机器人的实时神经符号验证框架，通过结合置信度校准的脑信号解码与符号目标接地和双层级运行时监控，确保逻辑安全和生理信任。


<details>
  <summary>Details</summary>
Motivation: 安全关键的辅助系统需要直接从神经信号解码用户意图，这要求严格的可靠性和信任保证。

Method: 采用置信度校准的脑信号解码、符号目标接地和双层级运行时监控，在BNCI2014运动想象EEG数据集上进行验证。

Result: 系统在轻量级解码器架构下实现了94-97%的高安全率，在模拟噪声测试中比基线提高了1.7倍的正确干预率，监控器以100Hz频率和亚毫秒延迟运行。

Conclusion: GUARDIAN框架能够提供从意图到行动的可审计追踪，在信号退化时表现出渐进响应，适用于闭环神经信号系统。

Abstract: Safety-critical assistive systems that directly decode user intent from neural signals require rigorous guarantees of reliability and trust. We present GUARDIAN (Gated Uncertainty-Aware Runtime Dual Invariants), a framework for real-time neuro-symbolic verification for neural signal-controlled robotics. GUARDIAN enforces both logical safety and physiological trust by coupling confidence-calibrated brain signal decoding with symbolic goal grounding and dual-layer runtime monitoring. On the BNCI2014 motor imagery electroencephalogram (EEG) dataset with 9 subjects and 5,184 trials, the system performs at a high safety rate of 94-97% even with lightweight decoder architectures with low test accuracies (27-46%) and high ECE confidence miscalibration (0.22-0.41). We demonstrate 1.7x correct interventions in simulated noise testing versus at baseline. The monitor operates at 100Hz and sub-millisecond decision latency, making it practically viable for closed-loop neural signal-based systems. Across 21 ablation results, GUARDIAN exhibits a graduated response to signal degradation, and produces auditable traces from intent, plan to action, helping to link neural evidence to verifiable robot action.

</details>


### [27] [Safe and Stable Neural Network Dynamical Systems for Robot Motion Planning](https://arxiv.org/abs/2511.20593)
*Allen Emmanuel Binny,Mahathi Anand,Hugo T. M. Kussaba,Lingyun Chen,Shreenabh Agrawal,Fares J. Abu-Dakka,Abdalla Swikir*

Main category: cs.RO

TL;DR: S²-NNDS是一个从演示中学习机器人运动的框架，同时学习神经动力学系统以及神经Lyapunov稳定性和屏障安全证书，提供概率安全保证。


<details>
  <summary>Details</summary>
Motivation: 在复杂非线性任务中，从演示中学习安全稳定的机器人运动仍然具有挑战性，特别是在动态、障碍物丰富的环境中。

Method: 利用神经网络捕捉复杂机器人运动，通过分割保形预测在学习证书中提供概率保证，不同于传统限制性多项式参数化方法。

Result: 在2D和3D数据集（包括LASA手写和Franka Emika Panda机器人演示）上的实验验证了S²-NNDS从潜在不安全演示中学习鲁棒、安全、稳定运动的有效性。

Conclusion: S²-NNDS能够同时学习表达性神经动力学系统以及稳定性和安全证书，为复杂环境中的机器人运动学习提供可靠解决方案。

Abstract: Learning safe and stable robot motions from demonstrations remains a challenge, especially in complex, nonlinear tasks involving dynamic, obstacle-rich environments. In this paper, we propose Safe and Stable Neural Network Dynamical Systems S$^2$-NNDS, a learning-from-demonstration framework that simultaneously learns expressive neural dynamical systems alongside neural Lyapunov stability and barrier safety certificates. Unlike traditional approaches with restrictive polynomial parameterizations, S$^2$-NNDS leverages neural networks to capture complex robot motions providing probabilistic guarantees through split conformal prediction in learned certificates. Experimental results on various 2D and 3D datasets -- including LASA handwriting and demonstrations recorded kinesthetically from the Franka Emika Panda robot -- validate S$^2$-NNDS effectiveness in learning robust, safe, and stable motions from potentially unsafe demonstrations.

</details>


### [28] [Reinforcing Action Policies by Prophesying](https://arxiv.org/abs/2511.20633)
*Jiahui Zhang,Ze Huang,Chun Gu,Zipei Ma,Li Zhang*

Main category: cs.RO

TL;DR: ProphRL通过先知世界模型和强化学习优化视觉语言动作策略，在公开基准上提升5-17%成功率，在真实机器人上提升24-30%成功率


<details>
  <summary>Details</summary>
Motivation: 解决VLA策略仅通过模仿学习训练导致的过拟合和分布偏移问题，同时避免真实机器人交互的高成本和传统仿真器的工程难度

Method: 提出ProphRL框架：1) Prophet - 跨大规模异构机器人数据预训练的动作到视频世界模型；2) FA-GRPO - 适配VLA动作的强化学习算法；3) FlowScale - 流动作头中的梯度重缩放方法

Result: 在公开基准上获得5-17%成功率提升，在真实机器人上获得24-30%成功率提升，能够少样本适应新机器人、物体和环境

Conclusion: ProphRL为VLA后训练提供了实用、数据和计算高效的路径，显著提升了策略的鲁棒性和性能

Abstract: Vision-Language-Action (VLA) policies excel in aligning language, perception, and robot control. However, most VLAs are trained purely by imitation, which overfits to demonstrations, and is brittle under distribution shift. Reinforcement learning (RL) directly optimizes task reward and thus addresses this misalignment, but real-robot interaction is expensive and conventional simulators are hard to engineer and transfer. We address both data efficiency and optimization stability in VLA post-training via a learned world model and an RL procedure tailored to flow-based action heads. Specifically, we introduce Prophet, a unified action-to-video robot actuation pretrained across large-scale, heterogeneous robot data to learn reusable action-outcome dynamics. It is able to few-shot adapt to new robots, objects, and environments, yielding a rollout-ready simulator. Upon Prophet, we reinforce action policies with Flow-action-GRPO (FA-GRPO), which adapts Flow-GRPO to operate on VLA actions, and with FlowScale, a stepwise reweighting that rescales per-step gradients in the flow head. Together, Prophet, FA-GRPO, and FlowScale constitute ProphRL, a practical, data- and compute-efficient path to VLA post-training. Experiments show 5-17% success gains on public benchmarks and 24-30% gains on real robots across different VLA variants.

</details>
