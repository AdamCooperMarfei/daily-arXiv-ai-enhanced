<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 33]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ERUPT: An Open Toolkit for Interfacing with Robot Motion Planners in Extended Reality](https://arxiv.org/abs/2510.02464)
*Isaac Ngui,Courtney McBeth,André Santos,Grace He,Katherine J. Mimnaugh,James D. Motes,Luciano Soares,Marco Morales,Nancy M. Amato*

Main category: cs.RO

TL;DR: ERUPT是一个扩展现实(XR)系统，用于交互式运动规划，允许用户在规划机器人路径时创建和动态重新配置环境。


<details>
  <summary>Details</summary>
Motivation: 传统机器人运动规划系统使用2D屏幕投影，限制了用户的空间理解和自然交互能力。XR环境可以提供更好的空间感知和更自然的交互方式。

Method: 系统集成MoveIt操纵规划框架，在沉浸式3D XR环境中，用户可以通过自然交互方式抓取和调整环境中的物体，发送运动规划请求并可视化机器人路径。

Result: 用户可以在虚拟空间中可视化机器人运动，确保期望行为并避免碰撞，然后将规划好的路径部署到真实世界的物理机器人上。

Conclusion: ERUPT系统通过XR技术显著提升了机器人运动规划的用户体验，提供了更直观的空间理解和更自然的交互方式。

Abstract: We propose the Extended Reality Universal Planning Toolkit (ERUPT), an
extended reality (XR) system for interactive motion planning. Our system allows
users to create and dynamically reconfigure environments while they plan robot
paths. In immersive three-dimensional XR environments, users gain a greater
spatial understanding. XR also unlocks a broader range of natural interaction
capabilities, allowing users to grab and adjust objects in the environment
similarly to the real world, rather than using a mouse and keyboard with the
scene projected onto a two-dimensional computer screen. Our system integrates
with MoveIt, a manipulation planning framework, allowing users to send motion
planning requests and visualize the resulting robot paths in virtual or
augmented reality. We provide a broad range of interaction modalities, allowing
users to modify objects in the environment and interact with a virtual robot.
Our system allows operators to visualize robot motions, ensuring desired
behavior as it moves throughout the environment, without risk of collisions
within a virtual space, and to then deploy planned paths on physical robots in
the real world.

</details>


### [2] [SIMSplat: Predictive Driving Scene Editing with Language-aligned 4D Gaussian Splatting](https://arxiv.org/abs/2510.02469)
*Sung-Yeon Park,Adam Lee,Juanwu Lu,Can Cui,Luyang Jiang,Rohit Gupta,Kyungtae Han,Ahmadreza Moradipari,Ziran Wang*

Main category: cs.RO

TL;DR: SIMSplat是一个基于语言对齐高斯泼溅的预测性驾驶场景编辑器，支持自然语言提示来直观地操作驾驶场景，提供详细的对象级编辑功能。


<details>
  <summary>Details</summary>
Motivation: 现有的驾驶场景编辑框架由于编辑能力有限，难以高效生成真实场景。需要一种能够直观操作且支持精确编辑的方法。

Method: 通过语言对齐高斯重建场景，支持直接查询道路对象，实现精确灵活编辑。结合多智能体运动预测进行预测性路径优化，生成真实交互。

Result: 在Waymo数据集上的实验证明了SIMSplat广泛的编辑能力和在各种场景下的适应性。

Conclusion: SIMSplat提供了一个高效、直观的驾驶场景编辑框架，能够生成真实的交互场景，解决了现有方法编辑能力有限的问题。

Abstract: Driving scene manipulation with sensor data is emerging as a promising
alternative to traditional virtual driving simulators. However, existing
frameworks struggle to generate realistic scenarios efficiently due to limited
editing capabilities. To address these challenges, we present SIMSplat, a
predictive driving scene editor with language-aligned Gaussian splatting. As a
language-controlled editor, SIMSplat enables intuitive manipulation using
natural language prompts. By aligning language with Gaussian-reconstructed
scenes, it further supports direct querying of road objects, allowing precise
and flexible editing. Our method provides detailed object-level editing,
including adding new objects and modifying the trajectories of both vehicles
and pedestrians, while also incorporating predictive path refinement through
multi-agent motion prediction to generate realistic interactions among all
agents in the scene. Experiments on the Waymo dataset demonstrate SIMSplat's
extensive editing capabilities and adaptability across a wide range of
scenarios. Project page: https://sungyeonparkk.github.io/simsplat/

</details>


### [3] [U-LAG: Uncertainty-Aware, Lag-Adaptive Goal Retargeting for Robotic Manipulation](https://arxiv.org/abs/2510.02526)
*Anamika J H,Anujith Muraleedharan*

Main category: cs.RO

TL;DR: U-LAG是一个中间执行目标重定向层，能够在感知延迟的情况下重新调整任务目标，而无需改变底层控制器。


<details>
  <summary>Details</summary>
Motivation: 机器人在变化环境中操作时，需要处理延迟、噪声或过时的感知信息，这会影响操作的准确性和成功率。

Method: 提出了UAR-PF（不确定性感知重定向器），在感知延迟下维护物体姿态分布，并选择能最大化预期进展的目标。

Result: 在0-10厘米偏移和0-400毫秒延迟的测试中，UAR-PF和ICP相比无重定向基线表现更好，成功率高，末端执行器移动距离小，中止次数少。

Conclusion: U-LAG提供了一个可插拔的重定向接口，能够有效处理感知延迟问题，提高机器人在动态环境中的操作性能。

Abstract: Robots manipulating in changing environments must act on percepts that are
late, noisy, or stale. We present U-LAG, a mid-execution goal-retargeting layer
that leaves the low-level controller unchanged while re-aiming task goals
(pre-contact, contact, post) as new observations arrive. Unlike motion
retargeting or generic visual servoing, U-LAG treats in-flight goal re-aiming
as a first-class, pluggable module between perception and control. Our main
technical contribution is UAR-PF, an uncertainty-aware retargeter that
maintains a distribution over object pose under sensing lag and selects goals
that maximize expected progress. We instantiate a reproducible Shift x Lag
stress test in PyBullet/PandaGym for pick, push, stacking, and peg insertion,
where the object undergoes abrupt in-plane shifts while synthetic perception
lag is injected during approach. Across 0-10 cm shifts and 0-400 ms lags,
UAR-PF and ICP degrade gracefully relative to a no-retarget baseline, achieving
higher success with modest end-effector travel and fewer aborts; simple
operational safeguards further improve stability. Contributions: (1) UAR-PF for
lag-adaptive, uncertainty-aware goal retargeting; (2) a pluggable retargeting
interface; and (3) a reproducible Shift x Lag benchmark with evaluation on
pick, push, stacking, and peg insertion.

</details>


### [4] [A Recipe for Efficient Sim-to-Real Transfer in Manipulation with Online Imitation-Pretrained World Models](https://arxiv.org/abs/2510.02538)
*Yilin Wang,Shangzhe Li,Haoyi Niu,Zhiao Huang,Weitong Zhang,Hao Su*

Main category: cs.RO

TL;DR: 提出基于世界模型的sim-to-real框架，通过在线模仿预训练和离线微调解决有限专家数据下的模仿学习问题，相比离线方法显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 现有离线模仿学习方法面临数据覆盖不足和性能严重下降的问题，需要利用机器人模拟器实现在线模仿学习来克服这些限制。

Method: 基于世界模型的sim-to-real框架，结合在线模仿预训练和离线微调，利用在线交互缓解离线方法的数据覆盖限制。

Result: 在sim-to-sim转移中成功率提高至少31.7%，在sim-to-real转移中提高至少23.3%，优于现有离线模仿学习基线。

Conclusion: 该方法通过在线交互有效解决了离线模仿学习的数据覆盖问题，提高了鲁棒性和泛化能力，在领域转移中表现优异。

Abstract: We are interested in solving the problem of imitation learning with a limited
amount of real-world expert data. Existing offline imitation methods often
struggle with poor data coverage and severe performance degradation. We propose
a solution that leverages robot simulators to achieve online imitation
learning. Our sim-to-real framework is based on world models and combines
online imitation pretraining with offline finetuning. By leveraging online
interactions, our approach alleviates the data coverage limitations of offline
methods, leading to improved robustness and reduced performance degradation
during finetuning. It also enhances generalization during domain transfer. Our
empirical results demonstrate its effectiveness, improving success rates by at
least 31.7% in sim-to-sim transfer and 23.3% in sim-to-real transfer over
existing offline imitation learning baselines.

</details>


### [5] [Efficient Optimal Path Planning in Dynamic Environments Using Koopman MPC](https://arxiv.org/abs/2510.02584)
*Mohammad Abtahi,Navid Mojahed,Shima Nazari*

Main category: cs.RO

TL;DR: 提出基于Koopman算子的数据驱动模型预测控制框架，用于移动机器人在动态环境中的导航，通过双线性Koopman模型实现非线性最优控制问题的线性化，计算效率比非线性MPC提高320倍。


<details>
  <summary>Details</summary>
Motivation: 传统Koopman方法仅关注系统动力学的线性化，而本文旨在为包含非线性机器人动力学和避障约束的最优路径规划问题寻找全局线性表示，以解决计算效率问题。

Method: 使用扩展动态模式分解从输入状态数据中识别线性和双线性Koopman实现，在提升空间中制定机器人路径规划的二次规划问题，并在MPC框架中确定最优机器人动作。

Result: 开环分析表明只有双线性Koopman模型能准确捕捉非线性状态-输入耦合和避障所需的二次项，计算速度比原始状态空间中的非线性MPC快320倍。

Conclusion: 双线性Koopman实现对于高度非线性最优控制问题的线性化具有巨大潜力，能够实现类似线性问题的计算效率，同时处理非线性状态和输入约束。

Abstract: This paper presents a data-driven model predictive control framework for
mobile robots navigating in dynamic environments, leveraging Koopman operator
theory. Unlike the conventional Koopman-based approaches that focus on the
linearization of system dynamics only, our work focuses on finding a global
linear representation for the optimal path planning problem that includes both
the nonlinear robot dynamics and collision-avoidance constraints. We deploy
extended dynamic mode decomposition to identify linear and bilinear Koopman
realizations from input-state data. Our open-loop analysis demonstrates that
only the bilinear Koopman model can accurately capture nonlinear state-input
couplings and quadratic terms essential for collision avoidance, whereas linear
realizations fail to do so. We formulate a quadratic program for the robot path
planning in the presence of moving obstacles in the lifted space and determine
the optimal robot action in an MPC framework. Our approach is capable of
finding the safe optimal action 320 times faster than a nonlinear MPC
counterpart that solves the path planning problem in the original state space.
Our work highlights the potential of bilinear Koopman realizations for
linearization of highly nonlinear optimal control problems subject to nonlinear
state and input constraints to achieve computational efficiency similar to
linear problems.

</details>


### [6] [SubSense: VR-Haptic and Motor Feedback for Immersive Control in Subsea Telerobotics](https://arxiv.org/abs/2510.02594)
*Ruo Chen,David Blow,Adnan Abdullah,Md Jahidul Islam*

Main category: cs.RO

TL;DR: SubSense是一个集成触觉反馈和VR控制界面的框架，用于增强水下ROV的远程操作能力，通过非侵入式反馈接口和VR平台提供沉浸式体验。


<details>
  <summary>Details</summary>
Motivation: 传统ROV远程操作依赖低分辨率2D摄像头，缺乏沉浸感和感官反馈，在复杂海底环境中降低了态势感知能力。

Method: 提出SubSense框架，将非侵入式反馈接口与1-DOF机械手配对，通过操作者手套提供触觉反馈和抓取状态，并集成端到端软件管理控制输入和VR沉浸式摄像头视图。

Result: 通过综合实验和用户研究验证了系统有效性，相比传统远程操作接口，在精细操作任务中表现更佳。

Conclusion: 多感官反馈在沉浸式虚拟环境中能显著提升远程态势感知和任务性能，为现场ROV操作提供更直观和易用的解决方案。

Abstract: This paper investigates the integration of haptic feedback and virtual
reality (VR) control interfaces to enhance teleoperation and telemanipulation
of underwater ROVs (remotely operated vehicles). Traditional ROV teleoperation
relies on low-resolution 2D camera feeds and lacks immersive and sensory
feedback, which diminishes situational awareness in complex subsea
environments. We propose SubSense -- a novel VR-Haptic framework incorporating
a non-invasive feedback interface to an otherwise 1-DOF (degree of freedom)
manipulator, which is paired with the teleoperator's glove to provide haptic
feedback and grasp status. Additionally, our framework integrates end-to-end
software for managing control inputs and displaying immersive camera views
through a VR platform. We validate the system through comprehensive experiments
and user studies, demonstrating its effectiveness over conventional
teleoperation interfaces, particularly for delicate manipulation tasks. Our
results highlight the potential of multisensory feedback in immersive virtual
environments to significantly improve remote situational awareness and mission
performance, offering more intuitive and accessible ROV operations in the
field.

</details>


### [7] [UMI-on-Air: Embodiment-Aware Guidance for Embodiment-Agnostic Visuomotor Policies](https://arxiv.org/abs/2510.02614)
*Harsh Gupta,Xiaofeng Guo,Huy Ha,Chuer Pan,Muqing Cao,Dongjae Lee,Sebastian Sherer,Shuran Song,Guanya Shi*

Main category: cs.RO

TL;DR: UMI-on-Air是一个框架，用于将手持夹爪收集的人类演示策略部署到受约束的机器人平台上，通过结合高层策略和低层控制器实现动态可行的轨迹适配。


<details>
  <summary>Details</summary>
Motivation: 解决从手持夹爪收集的无约束人类演示策略转移到受约束机器人平台（如空中机械臂）时的控制动态不匹配问题，避免超出分布的行为和执行失败。

Method: 提出Embodiment-Aware Diffusion Policy (EADP)，在推理时将高层UMI策略与低层特定控制器耦合，通过控制器跟踪成本的梯度反馈引导扩散采样过程，生成适合部署平台的动态可行轨迹。

Result: 在多个长视野和高精度空中操作任务上验证，相比无引导的扩散基线，显示出更高的成功率、效率和抗干扰鲁棒性，并在未见环境中成功部署。

Conclusion: 该方法为在不同（甚至高度受限的）平台上扩展通用操作技能提供了一条实用途径，实现了即插即用的平台感知轨迹适配。

Abstract: We introduce UMI-on-Air, a framework for embodiment-aware deployment of
embodiment-agnostic manipulation policies. Our approach leverages diverse,
unconstrained human demonstrations collected with a handheld gripper (UMI) to
train generalizable visuomotor policies. A central challenge in transferring
these policies to constrained robotic embodiments-such as aerial
manipulators-is the mismatch in control and robot dynamics, which often leads
to out-of-distribution behaviors and poor execution. To address this, we
propose Embodiment-Aware Diffusion Policy (EADP), which couples a high-level
UMI policy with a low-level embodiment-specific controller at inference time.
By integrating gradient feedback from the controller's tracking cost into the
diffusion sampling process, our method steers trajectory generation towards
dynamically feasible modes tailored to the deployment embodiment. This enables
plug-and-play, embodiment-aware trajectory adaptation at test time. We validate
our approach on multiple long-horizon and high-precision aerial manipulation
tasks, showing improved success rates, efficiency, and robustness under
disturbances compared to unguided diffusion baselines. Finally, we demonstrate
deployment in previously unseen environments, using UMI demonstrations
collected in the wild, highlighting a practical pathway for scaling
generalizable manipulation skills across diverse-and even highly
constrained-embodiments. All code, data, and checkpoints will be publicly
released after acceptance. Result videos can be found at umi-on-air.github.io.

</details>


### [8] [RSV-SLAM: Toward Real-Time Semantic Visual SLAM in Indoor Dynamic Environments](https://arxiv.org/abs/2510.02616)
*Mobin Habibpour,Alireza Nemati,Ali Meghdari,Alireza Taheri,Shima Nazari*

Main category: cs.RO

TL;DR: 提出了一种用于动态环境的实时语义RGBD SLAM方法，通过深度学习语义信息和扩展卡尔曼滤波器检测动态物体，使用生成网络填补动态物体区域，在TUM数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统视觉SLAM方法假设静态世界，在动态环境中表现不佳，需要专门针对动态环境设计的SLAM系统。

Method: 结合深度学习语义信息到SLAM系统，使用扩展卡尔曼滤波器识别暂时静止的动态物体，实现生成网络填补动态物体区域，构建高度模块化框架。

Result: 在GTX1080上达到约22fps，在TUM动态序列基准测试中定位误差与最先进方法相当，接近实时运行。

Conclusion: 该方法能有效检测动态物体并维护静态地图，在动态环境中提供鲁棒的相机跟踪性能，源代码已公开。

Abstract: Simultaneous Localization and Mapping (SLAM) plays an important role in many
robotics fields, including social robots. Many of the available visual SLAM
methods are based on the assumption of a static world and struggle in dynamic
environments. In the current study, we introduce a real-time semantic RGBD SLAM
approach designed specifically for dynamic environments. Our proposed system
can effectively detect moving objects and maintain a static map to ensure
robust camera tracking. The key innovation of our approach is the incorporation
of deep learning-based semantic information into SLAM systems to mitigate the
impact of dynamic objects. Additionally, we enhance the semantic segmentation
process by integrating an Extended Kalman filter to identify dynamic objects
that may be temporarily idle. We have also implemented a generative network to
fill in the missing regions of input images belonging to dynamic objects. This
highly modular framework has been implemented on the ROS platform and can
achieve around 22 fps on a GTX1080. Benchmarking the developed pipeline on
dynamic sequences from the TUM dataset suggests that the proposed approach
delivers competitive localization error in comparison with the state-of-the-art
methods, all while operating in near real-time. The source code is publicly
available.

</details>


### [9] [Reachable Predictive Control: A Novel Control Algorithm for Nonlinear Systems with Unknown Dynamics and its Practical Applications](https://arxiv.org/abs/2510.02623)
*Taha Shafa,Yiming Meng,Melkior Ornik*

Main category: cs.RO

TL;DR: 提出一种无需系统动力学先验知识的算法，能够驱动系统跟随分段线性轨迹，即使在系统动力学发生突变的情况下也能保证跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 针对系统动力学可能发生突变的关键故障场景，需要开发能够在不知道系统动力学的情况下仍能保证轨迹跟踪的算法。

Method: 算法首先施加小扰动来局部学习当前状态附近的系统动力学，然后计算使用局部学习到的动力学及其最大增长率边界可证明可达的状态集合，最后合成控制动作将系统导航到保证可达的状态。

Result: 算法能够跟随由可证明可达状态组成的路径点集合，即使不知道系统动力学也能保证轨迹跟踪性能。

Conclusion: 该算法证明了在不知道系统动力学的情况下，通过局部学习和可达性分析，仍然可以实现对分段线性轨迹的可靠跟踪。

Abstract: This paper proposes an algorithm capable of driving a system to follow a
piecewise linear trajectory without prior knowledge of the system dynamics.
Motivated by a critical failure scenario in which a system can experience an
abrupt change in its dynamics, we demonstrate that it is possible to follow a
set of waypoints comprised of states analytically proven to be reachable
despite not knowing the system dynamics. The proposed algorithm first applies
small perturbations to locally learn the system dynamics around the current
state, then computes the set of states that are provably reachable using the
locally learned dynamics and their corresponding maximum growth-rate bounds,
and finally synthesizes a control action that navigates the system to a
guaranteed reachable state.

</details>


### [10] [Multi-robot Rigid Formation Navigation via Synchronous Motion and Discrete-time Communication-Control Optimization](https://arxiv.org/abs/2510.02624)
*Qun Yang,Soung Chang Liew*

Main category: cs.RO

TL;DR: 提出了一种新颖的"hold-and-hit"通信控制框架，结合周期内优化方法，用于多机器人刚性编队导航，解决了无线网络延迟和数据包丢失问题，使机器人能够在复杂曲线上保持精确编队。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏在微处理器平台上通过无线网络实现多机器人编队导航的全面解决方案，特别是在需要穿越复杂曲线路径的情况下。

Method: 开发了"hold-and-hit"通信控制框架，与ROS平台无缝集成，通过离散时间通信控制周期同步机器人运动；同时提出周期内优化方法，使刚性编队能够紧密跟随期望的曲线路径。

Result: 仿真显示该方法在S形路径上保持四机器人方形编队方面优于现有方法；真实实验验证了框架有效性：机器人保持间距误差在±0.069m内，角度误差在±19.15°内，以0.1m/s速度沿S形路径导航。

Conclusion: hold-and-hit框架与周期内优化的结合确保了在挑战性场景下的精确可靠导航，为多机器人刚性编队导航提供了有效的解决方案。

Abstract: Rigid-formation navigation of multiple robots is essential for applications
such as cooperative transportation. This process involves a team of
collaborative robots maintaining a predefined geometric configuration, such as
a square, while in motion. For untethered collaborative motion, inter-robot
communication must be conducted through a wireless network. Notably, few
existing works offer a comprehensive solution for multi-robot formation
navigation executable on microprocessor platforms via wireless networks,
particularly for formations that must traverse complex curvilinear paths. To
address this gap, we introduce a novel "hold-and-hit" communication-control
framework designed to work seamlessly with the widely-used Robotic Operating
System (ROS) platform. The hold-and-hit framework synchronizes robot movements
in a manner robust against wireless network delays and packet loss. It operates
over discrete-time communication-control cycles, making it suitable for
implementation on contemporary microprocessors. Complementary to hold-and-hit,
we propose an intra-cycle optimization approach that enables rigid formations
to closely follow desired curvilinear paths, even under the nonholonomic
movement constraints inherent to most vehicular robots. The combination of
hold-and-hit and intra-cycle optimization ensures precise and reliable
navigation even in challenging scenarios. Simulations in a virtual environment
demonstrate the superiority of our method in maintaining a four-robot square
formation along an S-shaped path, outperforming two existing approaches.
Furthermore, real-world experiments validate the effectiveness of our
framework: the robots maintained an inter-distance error within $\pm 0.069m$
and an inter-angular orientation error within $\pm19.15^{\circ}$ while
navigating along an S-shaped path at a fixed linear velocity of $0.1 m/s$.

</details>


### [11] [A Trajectory Generator for High-Density Traffic and Diverse Agent-Interaction Scenarios](https://arxiv.org/abs/2510.02627)
*Ruining Yang,Yi Xu,Yixiao Chen,Yun Fu,Lili Su*

Main category: cs.RO

TL;DR: 提出了一种新颖的轨迹生成框架，通过结构化网格表示和行为感知生成机制，合成高密度场景和罕见行为，解决现有数据集中长尾分布问题。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹预测数据集存在明显的长尾分布问题，大多数样本来自低密度场景和简单直线驾驶行为，缺乏高密度场景和安全关键操作（如变道、超车、转弯）的代表性，这阻碍了模型泛化能力并导致评估过于乐观。

Method: 将连续道路环境转换为结构化网格表示，支持细粒度路径规划、显式冲突检测和多智能体协调；引入结合基于规则的决策触发、Frenet轨迹平滑和动态可行性约束的行为感知生成机制。

Result: 在Argoverse 1和Argoverse 2数据集上的广泛实验表明，该方法显著提高了智能体密度和行为多样性，同时保持了运动真实性和场景级安全性；合成数据还惠及下游轨迹预测模型，在挑战性高密度场景中提升了性能。

Conclusion: 所提出的轨迹生成框架有效解决了轨迹预测数据集中的长尾分布问题，能够合成具有复杂交互的现实高密度场景和罕见行为，为自动驾驶系统的安全规划提供更好的数据支持。

Abstract: Accurate trajectory prediction is fundamental to autonomous driving, as it
underpins safe motion planning and collision avoidance in complex environments.
However, existing benchmark datasets suffer from a pronounced long-tail
distribution problem, with most samples drawn from low-density scenarios and
simple straight-driving behaviors. This underrepresentation of high-density
scenarios and safety critical maneuvers such as lane changes, overtaking and
turning is an obstacle to model generalization and leads to overly optimistic
evaluations. To address these challenges, we propose a novel trajectory
generation framework that simultaneously enhances scenarios density and
enriches behavioral diversity. Specifically, our approach converts continuous
road environments into a structured grid representation that supports
fine-grained path planning, explicit conflict detection, and multi-agent
coordination. Built upon this representation, we introduce behavior-aware
generation mechanisms that combine rule-based decision triggers with
Frenet-based trajectory smoothing and dynamic feasibility constraints. This
design allows us to synthesize realistic high-density scenarios and rare
behaviors with complex interactions that are often missing in real data.
Extensive experiments on the large-scale Argoverse 1 and Argoverse 2 datasets
demonstrate that our method significantly improves both agent density and
behavior diversity, while preserving motion realism and scenario-level safety.
Our synthetic data also benefits downstream trajectory prediction models and
enhances performance in challenging high-density scenarios.

</details>


### [12] [A $1000\times$ Faster LLM-enhanced Algorithm For Path Planning in Large-scale Grid Maps](https://arxiv.org/abs/2510.02716)
*Junlin Zeng,Xin Zhang,Xiang Zhao,Yan Pan*

Main category: cs.RO

TL;DR: 本文提出iLLM-A*算法，通过优化A*算法、增量学习方法和路径点选择机制，显著提升了LLM-A*在网格地图路径规划中的性能，实现了超过1000倍的速度提升和58.6%的内存节省。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法（如A*、Dijkstra）在大规模地图上搜索时间和内存消耗过高，而基于大语言模型的方法存在空间错觉和规划性能差的问题。LLM-A*虽然结合了LLM和A*，但在大规模地图上计算时间仍然很高。

Method: 设计iLLM-A*算法，包含三个核心机制：1）优化A*算法；2）为LLM设计增量学习方法以生成高质量路径点；3）选择适合A*路径规划的路径点。

Result: 在各种网格地图上的综合评估显示，相比LLM-A*，iLLM-A*实现了：1）平均超过1000倍的速度提升，极端情况下达2349.5倍；2）最高节省58.6%内存成本；3）路径长度明显更短且标准差更低。

Conclusion: iLLM-A*通过精心设计的机制有效解决了LLM-A*的性能瓶颈，在大规模网格地图路径规划中实现了显著的速度提升和内存优化。

Abstract: Path planning in grid maps, arising from various applications, has garnered
significant attention. Existing methods, such as A*, Dijkstra, and their
variants, work well for small-scale maps but fail to address large-scale ones
due to high search time and memory consumption. Recently, Large Language Models
(LLMs) have shown remarkable performance in path planning but still suffer from
spatial illusion and poor planning performance. Among all the works, LLM-A*
\cite{meng2024llm} leverages LLM to generate a series of waypoints and then
uses A* to plan the paths between the neighboring waypoints. In this way, the
complete path is constructed. However, LLM-A* still suffers from high
computational time for large-scale maps. To fill this gap, we conducted a deep
investigation into LLM-A* and found its bottleneck, resulting in limited
performance. Accordingly, we design an innovative LLM-enhanced algorithm, abbr.
as iLLM-A*. iLLM-A* includes 3 carefully designed mechanisms, including the
optimization of A*, an incremental learning method for LLM to generate
high-quality waypoints, and the selection of the appropriate waypoints for A*
for path planning. Finally, a comprehensive evaluation on various grid maps
shows that, compared with LLM-A*, iLLM-A* \textbf{1) achieves more than
$1000\times$ speedup on average, and up to $2349.5\times$ speedup in the
extreme case, 2) saves up to $58.6\%$ of the memory cost, 3) achieves both
obviously shorter path length and lower path length standard deviation.}

</details>


### [13] [Team Xiaomi EV-AD VLA: Caption-Guided Retrieval System for Cross-Modal Drone Navigation -- Technical Report for IROS 2025 RoboSense Challenge Track 4](https://arxiv.org/abs/2510.02728)
*Lingfeng Zhang,Erjia Xiao,Yuchen Zhang,Haoxiang Fu,Ruibin Hu,Yanbiao Ma,Wenbo Ding,Long Chen,Hangjun Ye,Xiaoshuai Hao*

Main category: cs.RO

TL;DR: 提出了一种两阶段检索优化方法CGRS，通过智能重排序增强基线粗排名，在RoboSense 2025挑战赛中取得TOP-2成绩。


<details>
  <summary>Details</summary>
Motivation: 解决跨模态无人机导航中文本查询与视觉内容之间细粒度语义匹配的挑战，特别是在复杂空中场景下。

Method: 首先使用基线模型获得前20个最相关图像的初始粗排名，然后使用视觉语言模型为候选图像生成详细描述，最后在多模态相似度计算框架中进行细粒度重排序。

Result: 在所有关键指标（Recall@1、Recall@5、Recall@10）上相比基线方法实现了5%的稳定提升。

Conclusion: 该方法在真实机器人导航场景中展示了语义细化策略的实用价值，成功构建了视觉内容与自然语言描述之间的语义桥梁。

Abstract: Cross-modal drone navigation remains a challenging task in robotics,
requiring efficient retrieval of relevant images from large-scale databases
based on natural language descriptions. The RoboSense 2025 Track 4 challenge
addresses this challenge, focusing on robust, natural language-guided
cross-view image retrieval across multiple platforms (drones, satellites, and
ground cameras). Current baseline methods, while effective for initial
retrieval, often struggle to achieve fine-grained semantic matching between
text queries and visual content, especially in complex aerial scenes. To
address this challenge, we propose a two-stage retrieval refinement method:
Caption-Guided Retrieval System (CGRS) that enhances the baseline coarse
ranking through intelligent reranking. Our method first leverages a baseline
model to obtain an initial coarse ranking of the top 20 most relevant images
for each query. We then use Vision-Language-Model (VLM) to generate detailed
captions for these candidate images, capturing rich semantic descriptions of
their visual content. These generated captions are then used in a multimodal
similarity computation framework to perform fine-grained reranking of the
original text query, effectively building a semantic bridge between the visual
content and natural language descriptions. Our approach significantly improves
upon the baseline, achieving a consistent 5\% improvement across all key
metrics (Recall@1, Recall@5, and Recall@10). Our approach win TOP-2 in the
challenge, demonstrating the practical value of our semantic refinement
strategy in real-world robotic navigation scenarios.

</details>


### [14] [Flow with the Force Field: Learning 3D Compliant Flow Matching Policies from Force and Demonstration-Guided Simulation Data](https://arxiv.org/abs/2510.02738)
*Tianyu Li,Yihan Li,Zizhe Zhang,Nadia Figueroa*

Main category: cs.RO

TL;DR: 提出了一种基于单次人类演示生成力信息仿真数据的框架，结合顺应性策略提升视觉运动策略在接触丰富任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉运动策略在处理需要连续接触的任务时忽视顺应性，导致接触力过大或行为脆弱。引入力信息可改善接触感知，但需要大量数据。

Method: 通过单次人类演示生成力信息仿真数据，结合顺应性策略训练视觉运动策略。

Result: 在真实机器人任务（非抓取块翻转和双手物体移动）中验证，学习到的策略表现出可靠的接触维持和对新条件的适应能力。

Conclusion: 该方法通过仿真数据生成和顺应性策略的耦合，有效提升了视觉运动策略在接触丰富任务中的性能。

Abstract: While visuomotor policy has made advancements in recent years, contact-rich
tasks still remain a challenge. Robotic manipulation tasks that require
continuous contact demand explicit handling of compliance and force. However,
most visuomotor policies ignore compliance, overlooking the importance of
physical interaction with the real world, often leading to excessive contact
forces or fragile behavior under uncertainty. Introducing force information
into vision-based imitation learning could help improve awareness of contacts,
but could also require a lot of data to perform well. One remedy for data
scarcity is to generate data in simulation, yet computationally taxing
processes are required to generate data good enough not to suffer from the
Sim2Real gap. In this work, we introduce a framework for generating
force-informed data in simulation, instantiated by a single human
demonstration, and show how coupling with a compliant policy improves the
performance of a visuomotor policy learned from synthetic data. We validate our
approach on real-robot tasks, including non-prehensile block flipping and a
bi-manual object moving, where the learned policy exhibits reliable contact
maintenance and adaptation to novel conditions. Project Website:
https://flow-with-the-force-field.github.io/webpage/

</details>


### [15] [Work Zones challenge VLM Trajectory Planning: Toward Mitigation and Robust Autonomous Driving](https://arxiv.org/abs/2510.02803)
*Yifan Liao,Zhen Sun,Xiaoyun Qiu,Zixiao Zhao,Wenbing Tang,Xinlei He,Xinhu Zheng,Tianwei Zhang,Xinyi Huang,Xingshuo Han*

Main category: cs.RO

TL;DR: 本文首次系统研究视觉语言模型在工作区轨迹规划中的表现，发现主流VLMs在68%情况下无法生成正确轨迹。作者提出REACT-Drive框架，结合检索增强生成技术，显著降低轨迹规划误差并提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 工作区包含不规则布局、临时交通控制和动态变化的几何结构，现有视觉语言模型在这种复杂环境下的轨迹规划能力尚未被探索，存在显著性能差距。

Method: 通过子图挖掘和聚类分析识别失败模式，提出REACT-Drive框架，利用VLMs将失败案例转化为约束规则和可执行代码，同时使用RAG在新场景中检索相似模式来指导轨迹生成。

Result: 在ROADWork数据集上，REACT-Drive相比VLM基线平均位移误差降低约3倍，推理时间仅0.58秒，远低于微调方法的17.90秒。在15个真实工作区场景的实车实验验证了其强实用性。

Conclusion: REACT-Drive框架有效解决了VLMs在工作区轨迹规划中的失败问题，显著提升了规划精度和效率，为自动驾驶系统在复杂工作区环境中的安全导航提供了可行解决方案。

Abstract: Visual Language Models (VLMs), with powerful multimodal reasoning
capabilities, are gradually integrated into autonomous driving by several
automobile manufacturers to enhance planning capability in challenging
environments. However, the trajectory planning capability of VLMs in work
zones, which often include irregular layouts, temporary traffic control, and
dynamically changing geometric structures, is still unexplored. To bridge this
gap, we conduct the \textit{first} systematic study of VLMs for work zone
trajectory planning, revealing that mainstream VLMs fail to generate correct
trajectories in $68.0%$ of cases. To better understand these failures, we first
identify candidate patterns via subgraph mining and clustering analysis, and
then confirm the validity of $8$ common failure patterns through human
verification. Building on these findings, we propose REACT-Drive, a trajectory
planning framework that integrates VLMs with Retrieval-Augmented Generation
(RAG). Specifically, REACT-Drive leverages VLMs to convert prior failure cases
into constraint rules and executable trajectory planning code, while RAG
retrieves similar patterns in new scenarios to guide trajectory generation.
Experimental results on the ROADWork dataset show that REACT-Drive yields a
reduction of around $3\times$ in average displacement error relative to VLM
baselines under evaluation with Qwen2.5-VL. In addition, REACT-Drive yields the
lowest inference time ($0.58$s) compared with other methods such as fine-tuning
($17.90$s). We further conduct experiments using a real vehicle in 15 work zone
scenarios in the physical world, demonstrating the strong practicality of
REACT-Drive.

</details>


### [16] [Assist-as-needed Control for FES in Foot Drop Management](https://arxiv.org/abs/2510.02808)
*Andreas Christou,Elliot Lister,Georgia Andreopoulou,Don Mahad,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 提出了一种基于实时脚趾间隙的闭环FES控制器，相比传统开环控制器，在保证足够脚趾间隙的同时显著降低刺激强度，减少肌肉疲劳。


<details>
  <summary>Details</summary>
Motivation: 传统开环FES控制器使用固定刺激强度，存在过度刺激导致肌肉疲劳或刺激不足增加跌倒风险的问题。

Method: 开发闭环FES控制器，根据实时脚趾间隙动态调整刺激强度，在健康参与者中诱导足下垂，在不同步行条件下与开环控制器进行比较。

Result: 闭环控制器在保持足够脚趾间隙的同时，显著降低刺激强度，且不影响髋、膝、踝关节角度。

Conclusion: 该方法不仅匹配现有系统的有效性，还减少肌肉疲劳，改善长期用户舒适度和依从性。

Abstract: Foot drop is commonly managed using Functional Electrical Stimulation (FES),
typically delivered via open-loop controllers with fixed stimulation
intensities. While users may manually adjust the intensity through external
controls, this approach risks overstimulation, leading to muscle fatigue and
discomfort, or understimulation, which compromises dorsiflexion and increases
fall risk. In this study, we propose a novel closed-loop FES controller that
dynamically adjusts the stimulation intensity based on real-time toe clearance,
providing "assistance as needed". We evaluate this system by inducing foot drop
in healthy participants and comparing the effects of the closed-loop controller
with a traditional open-loop controller across various walking conditions,
including different speeds and surface inclinations. Kinematic data reveal that
our closed-loop controller maintains adequate toe clearance without
significantly affecting the joint angles of the hips, the knees, and the
ankles, and while using significantly lower stimulation intensities compared to
the open-loop controller. These findings suggest that the proposed method not
only matches the effectiveness of existing systems but also offers the
potential for reduced muscle fatigue and improved long-term user comfort and
adherence.

</details>


### [17] [Action Deviation-Aware Inference for Low-Latency Wireless Robots](https://arxiv.org/abs/2510.02851)
*Jeyoung Park,Yeonsub Lim,Seungeun Oh,Jihong Park,Jinho Choi,Seong-Lyun Kim*

Main category: cs.RO

TL;DR: 提出了一种动作偏差感知的混合推理方法，通过选择性跳过服务器验证来降低延迟和传输开销，适用于机器人操作等具身AI应用的分布式推理。


<details>
  <summary>Details</summary>
Motivation: 6G分布式机器学习需要支持延迟敏感的AI应用，但行为克隆策略无法并行验证多个动作草案，因为每个动作都依赖于前一个动作更新的观察结果。

Method: 动作偏差感知混合推理：草案模型估计动作需要目标模型验证的概率，选择性跳过服务器通信和计算操作，基于路径偏差阈值平衡传输率和推理性能。

Result: 减少上行传输和服务器操作40%，端到端延迟降低33.32%，任务成功率可达目标模型单独推理的97.03%。

Conclusion: 动作偏差感知方法能有效降低分布式推理的延迟和通信开销，同时保持接近目标模型的性能，适用于具身AI应用的实时需求。

Abstract: To support latency-sensitive AI applications ranging from autonomous driving
to industrial robot manipulation, 6G envisions distributed ML, connecting
distributed computational resources in edge and cloud over hyper-reliable
low-latency communication (HRLLC). In this setting, speculative decoding can
facilitate collaborative inference of models distributively deployed: an
on-device draft model locally generates drafts and a remote server-based target
model verifies and corrects them, resulting lower latency. However, unlike
autoregressive text generation, behavior cloning policies, typically used for
embodied AI applications like robot manipulation and autonomous driving, cannot
parallelize verification and correction for multiple drafts as each action
depends on observation which needs to be updated by a previous action. To this
end, we propose Action Deviation-Aware Hybrid Inference, wherein the draft
model estimates an action's need for verification and correction by the target
model and selectively skips communication and computation for server
operations. Action deviation shows a strong correlation with action's rejection
probability by the target model, enabling selective skipping. We derive the
path deviation threshold that balances the transmission rate and the inference
performance, and we empirically show that action deviation-aware hybrid
inference reduces uplink transmission and server operation by 40%, while
lowering end-to-end latency by 33.32% relative to hybrid inference without
skipping and achieving task success rate up to 97.03% of that of target model
only inference.

</details>


### [18] [Novel UWB Synthetic Aperture Radar Imaging for Mobile Robot Mapping](https://arxiv.org/abs/2510.02874)
*Charith Premachandra,U-Xuan Tan*

Main category: cs.RO

TL;DR: 本文提出了一种将超宽带雷达合成孔径成像技术集成到移动机器人中的管道，用于在恶劣能见度条件下进行环境建图和闭环检测。


<details>
  <summary>Details</summary>
Motivation: 传统的外部传感器（如激光雷达和相机）在恶劣能见度条件下感知环境存在困难，而超宽带雷达能够穿透恶劣环境条件（如灰尘、烟雾和雨水），因此需要开发基于雷达的建图解决方案。

Method: 通过移动机器人路径合成虚拟大孔径，生成合成孔径雷达图像，然后使用经典特征检测器（SIFT、SURF、BRISK、AKAZE和ORB）进行闭环检测。

Result: 实验在模拟恶劣环境条件下进行，结果表明UWB SAR成像在高分辨率环境建图和闭环检测方面具有可行性和有效性。

Conclusion: UWB SAR成像技术能够为机器人感知系统提供更强大和可靠的建图能力，特别是在恶劣能见度条件下。

Abstract: Traditional exteroceptive sensors in mobile robots, such as LiDARs and
cameras often struggle to perceive the environment in poor visibility
conditions. Recently, radar technologies, such as ultra-wideband (UWB) have
emerged as potential alternatives due to their ability to see through adverse
environmental conditions (e.g. dust, smoke and rain). However, due to the small
apertures with low directivity, the UWB radars cannot reconstruct a detailed
image of its field of view (FOV) using a single scan. Hence, a virtual large
aperture is synthesized by moving the radar along a mobile robot path. The
resulting synthetic aperture radar (SAR) image is a high-definition
representation of the surrounding environment. Hence, this paper proposes a
pipeline for mobile robots to incorporate UWB radar-based SAR imaging to map an
unknown environment. Finally, we evaluated the performance of classical feature
detectors: SIFT, SURF, BRISK, AKAZE and ORB to identify loop closures using UWB
SAR images. The experiments were conducted emulating adverse environmental
conditions. The results demonstrate the viability and effectiveness of UWB SAR
imaging for high-resolution environmental mapping and loop closure detection
toward more robust and reliable robotic perception systems.

</details>


### [19] [Point Cloud-Based Control Barrier Functions for Model Predictive Control in Safety-Critical Navigation of Autonomous Mobile Robots](https://arxiv.org/abs/2510.02885)
*Faduo Liang,Yunfeng Yang,Shi-Lu Dai*

Main category: cs.RO

TL;DR: 提出了一种结合动态障碍物跟踪、预测和FTD地图构建的安全关键运动规划算法，通过CBF与非线性模型预测控制的结合实现静态和动态障碍物的有效避障。


<details>
  <summary>Details</summary>
Motivation: 为自主移动机器人提供安全关键导航能力，特别是在包含动态障碍物的复杂环境中实现可靠的避障。

Method: 集成实时动态障碍物跟踪与映射系统，使用卡尔曼滤波预测动态点云运动状态，构建FTD地图，并结合控制屏障函数与非线性模型预测控制进行规划。

Result: 仿真和真实场景实验证明算法在复杂环境中有效，相比基线方法在安全性和鲁棒性方面表现更优。

Conclusion: 所提算法能够有效处理动态环境中的避障问题，为机器人社区提供了实用的安全导航解决方案。

Abstract: In this work, we propose a novel motion planning algorithm to facilitate
safety-critical navigation for autonomous mobile robots. The proposed algorithm
integrates a real-time dynamic obstacle tracking and mapping system that
categorizes point clouds into dynamic and static components. For dynamic point
clouds, the Kalman filter is employed to estimate and predict their motion
states. Based on these predictions, we extrapolate the future states of dynamic
point clouds, which are subsequently merged with static point clouds to
construct the forward-time-domain (FTD) map. By combining control barrier
functions (CBFs) with nonlinear model predictive control, the proposed
algorithm enables the robot to effectively avoid both static and dynamic
obstacles. The CBF constraints are formulated based on risk points identified
through collision detection between the predicted future states and the FTD
map. Experimental results from both simulated and real-world scenarios
demonstrate the efficacy of the proposed algorithm in complex environments. In
simulation experiments, the proposed algorithm is compared with two baseline
approaches, showing superior performance in terms of safety and robustness in
obstacle avoidance. The source code is released for the reference of the
robotics community.

</details>


### [20] [Metrics vs Surveys: Can Quantitative Measures Replace Human Surveys in Social Robot Navigation? A Correlation Analysis](https://arxiv.org/abs/2510.02941)
*Stefano Trepella,Mauro Martini,Noé Pérez-Higueras,Andrea Ostuni,Fernando Caballero,Luis Merino,Marcello Chiaberge*

Main category: cs.RO

TL;DR: 本文探讨了社交导航中数值指标与人类中心评估之间的关系，旨在找到两者之间的相关性，以便用标准化指标替代昂贵的人类评估。


<details>
  <summary>Details</summary>
Motivation: 社交导航评估复杂且成本高昂，人类中心评估可靠但资源密集，数值指标易于计算但缺乏标准。研究旨在探索两者关联，以降低对调查的依赖。

Method: 通过分析数值指标与人类中心评估之间的关系，识别潜在相关性，并评估现有指标在捕捉主观因素方面的充分性。

Result: 结果显示当前指标能捕捉机器人导航行为的某些方面，但重要主观因素仍未被充分代表，需要开发新指标。

Conclusion: 虽然数值指标与人类感知存在一定关联，但现有指标不足以全面代表主观评估要素，需要开发新的标准化指标。

Abstract: Social, also called human-aware, navigation is a key challenge for the
integration of mobile robots into human environments. The evaluation of such
systems is complex, as factors such as comfort, safety, and legibility must be
considered. Human-centered assessments, typically conducted through surveys,
provide reliable insights but are costly, resource-intensive, and difficult to
reproduce or compare across systems. Alternatively, numerical social navigation
metrics are easy to compute and facilitate comparisons, yet the community lacks
consensus on a standard set of metrics.
  This work explores the relationship between numerical metrics and
human-centered evaluations to identify potential correlations. If specific
quantitative measures align with human perceptions, they could serve as
standardized evaluation tools, reducing the dependency on surveys. Our results
indicate that while current metrics capture some aspects of robot navigation
behavior, important subjective factors remain insufficiently represented and
new metrics are necessary.

</details>


### [21] [Single-Rod Brachiation Robot: Mechatronic Control Design and Validation of Prejump Phases](https://arxiv.org/abs/2510.02946)
*Juraj Lieskovský,Hijiri Akahane,Aoto Osawa,Jaroslav Bušek,Ikuo Mizuuchi,Tomáš Vyhlídal*

Main category: cs.RO

TL;DR: 本文提出了一种最小配置摆荡机器人的完整机电设计，采用单根刚性杆和两端夹持机构，通过曲柄滑块机构移动质心位置实现摆动和旋转运动，开发了bang-bang最优控制和连续控制策略，并在实验中得到验证。


<details>
  <summary>Details</summary>
Motivation: 设计一种简单可靠的摆荡机器人，能够通过质心位置控制实现类似猿猴的摆荡运动，重点关注能量积累以实现后续跳跃阶段。

Method: 使用单刚性杆和两端夹持机构，通过曲柄滑块机构移动质心位置；基于非线性模型提出bang-bang最优控制策略，并利用输入输出线性化设计考虑扭矩限制和几何约束的连续控制策略。

Result: 两种控制策略在仿真中得到验证和比较，连续控制策略在基于STM32的低成本控制系统中实现，摆动和旋转阶段的摆荡运动在实验中成功验证。

Conclusion: 提出的最小配置摆荡机器人设计可行，连续控制策略能够有效处理实际系统的扭矩限制和几何约束，为后续跳跃阶段的能量积累提供了基础。

Abstract: A complete mechatronic design of a minimal configuration brachiation robot is
presented. The robot consists of a single rigid rod with gripper mechanisms
attached to both ends. The grippers are used to hang the robot on a horizontal
bar on which it swings or rotates. The motion is imposed by repositioning the
robot's center of mass, which is performed using a crank-slide mechanism. Based
on a non-linear model, an optimal control strategy is proposed, for
repositioning the center of mass in a bang-bang manner. Consequently, utilizing
the concept of input-output linearization, a continuous control strategy is
proposed that takes into account the limited torque of the crank-slide
mechanism and its geometry. An increased attention is paid to energy
accumulation towards the subsequent jump stage of the brachiation. These two
strategies are validated and compared in simulations. The continuous control
strategy is then also implemented within a low-cost STM32-based control system,
and both the swing and rotation stages of the brachiation motion are
experimentally validated.

</details>


### [22] [YawSitter: Modeling and Controlling a Tail-Sitter UAV with Enhanced Yaw Control](https://arxiv.org/abs/2510.02968)
*Amir Habel,Fawad Mehboob,Jeffrin Sam,Clement Fortin,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 提出了一种基于侧滑力模型的尾坐式无人机横向运动控制策略，通过差动推力产生的螺旋桨滑流效应实现偏航控制和横向位置控制，避免了滚转耦合问题。


<details>
  <summary>Details</summary>
Motivation: 尾坐式无人机在悬停状态下缺乏明确的横向动力学模型，存在复杂的气动耦合问题，导致横向运动建模和去耦控制面临重大挑战。

Method: 引入基于差动推力下螺旋桨滑流效应的侧滑力模型，采用YXZ欧拉旋转公式表示姿态并包含重力分量，直接在y轴控制偏航以改善横向动态行为。

Result: 在Unity环境中进行轨迹跟踪仿真测试，矩形和圆形路径上均表现稳定，平均绝对位置误差低，偏航偏差控制在5.688度以内。

Conclusion: 所提出的侧滑力生成模型有效，为开发敏捷的悬停能力尾坐式无人机奠定了基础。

Abstract: Achieving precise lateral motion modeling and decoupled control in hover
remains a significant challenge for tail-sitter Unmanned Aerial Vehicles
(UAVs), primarily due to complex aerodynamic couplings and the absence of
welldefined lateral dynamics. This paper presents a novel modeling and control
strategy that enhances yaw authority and lateral motion by introducing a
sideslip force model derived from differential propeller slipstream effects
acting on the fuselage under differential thrust. The resulting lateral force
along the body y-axis enables yaw-based lateral position control without
inducing roll coupling. The control framework employs a YXZ Euler rotation
formulation to accurately represent attitude and incorporate gravitational
components while directly controlling yaw in the yaxis, thereby improving
lateral dynamic behavior and avoiding singularities. The proposed approach is
validated through trajectory-tracking simulations conducted in a Unity-based
environment. Tests on both rectangular and circular paths in hover mode
demonstrate stable performance, with low mean absolute position errors and yaw
deviations constrained within 5.688 degrees. These results confirm the
effectiveness of the proposed lateral force generation model and provide a
foundation for the development of agile, hover-capable tail-sitter UAVs.

</details>


### [23] [AI-Enhanced Kinematic Modeling of Flexible Manipulators Using Multi-IMU Sensor Fusion](https://arxiv.org/abs/2510.02975)
*Amir Hossein Barjini,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出了一种使用多个IMU估计柔性机械臂位置和方向的新框架，通过PSO优化互补滤波器参数，并用RBFNN补偿残差误差，实现了高精度的运动估计。


<details>
  <summary>Details</summary>
Motivation: 柔性机械臂在垂直运动中的精确位置和方向估计对控制至关重要，但传统方法存在噪声和延迟问题，需要更准确的估计方案。

Method: 将柔性连杆建模为刚性段，使用低成本IMU的加速度计和陀螺仪测量估计关节角度，采用PSO优化的互补滤波器融合数据，并用RBFNN补偿位置和方向残差。

Result: 实验验证了方法的有效性，在y、z和θ方向上的均方根误差分别为0.00021m、0.00041m和0.00024rad。

Conclusion: 所提出的智能多IMU运动学估计方法能够有效提高柔性机械臂位置和方向估计的精度，具有实际应用价值。

Abstract: This paper presents a novel framework for estimating the position and
orientation of flexible manipulators undergoing vertical motion using multiple
inertial measurement units (IMUs), optimized and calibrated with ground truth
data. The flexible links are modeled as a series of rigid segments, with joint
angles estimated from accelerometer and gyroscope measurements acquired by
cost-effective IMUs. A complementary filter is employed to fuse the
measurements, with its parameters optimized through particle swarm optimization
(PSO) to mitigate noise and delay. To further improve estimation accuracy,
residual errors in position and orientation are compensated using radial basis
function neural networks (RBFNN). Experimental results validate the
effectiveness of the proposed intelligent multi-IMU kinematic estimation
method, achieving root mean square errors (RMSE) of 0.00021~m, 0.00041~m, and
0.00024~rad for $y$, $z$, and $\theta$, respectively.

</details>


### [24] [Real-Time Nonlinear Model Predictive Control of Heavy-Duty Skid-Steered Mobile Platform for Trajectory Tracking Tasks](https://arxiv.org/abs/2510.02976)
*Alvaro Paz,Pauli Mustalahti,Mohammad Dastranj,Jouni Mattila*

Main category: cs.RO

TL;DR: 提出了一种用于重型滑移转向移动平台轨迹跟踪的实时最优控制框架，采用多重打靶非线性模型预测控制，在速度和精度方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 由于动态系统在不确定性和干扰下需要安全稳定的控制性能，因此需要开发能够实时补偿这些现象的控制器。

Method: 采用多重打靶非线性模型预测控制框架，结合合适的算法和多种传感器读数，实现高精度的实时性能。

Result: 控制器在不同轨迹跟踪测试中表现出高度理想的速度和精度性能，相比现有文献中的非线性模型预测控制器有显著改进。

Conclusion: 所提出的控制框架能够为重型滑移转向移动平台提供稳定、准确且实时的轨迹跟踪控制性能。

Abstract: This paper presents a framework for real-time optimal controlling of a
heavy-duty skid-steered mobile platform for trajectory tracking. The importance
of accurate real-time performance of the controller lies in safety
considerations of situations where the dynamic system under control is affected
by uncertainties and disturbances, and the controller should compensate for
such phenomena in order to provide stable performance. A multiple-shooting
nonlinear model-predictive control framework is proposed in this paper. This
framework benefits from suitable algorithm along with readings from various
sensors for genuine real-time performance with extremely high accuracy. The
controller is then tested for tracking different trajectories where it
demonstrates highly desirable performance in terms of both speed and accuracy.
This controller shows remarkable improvement when compared to existing
nonlinear model-predictive controllers in the literature that were implemented
on skid-steered mobile platforms.

</details>


### [25] [3D-CovDiffusion: 3D-Aware Diffusion Policy for Coverage Path Planning](https://arxiv.org/abs/2510.03011)
*Chenyuan Chen,Haoran Ding,Ran Ding,Tianyu Liu,Zewen He,Anqing Duan,Dezhen Song,Xiaodan Liang,Yoshihiko Nakamura*

Main category: cs.RO

TL;DR: 提出基于扩散模型的端到端轨迹生成框架，用于工业表面处理任务，显著提升轨迹连续性、覆盖率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法受限于预定义函数形式，难以处理复杂多样的任务，泛化能力差，需要为每个新场景手动重新设计或调参。

Method: 使用扩散模型，通过精心学习的噪声调度和条件机制迭代去噪轨迹，确保平滑一致的运动并灵活适应任务上下文。

Result: 平均改进点向Chamfer距离98.2%，平滑度97.0%，表面覆盖率提高61%相比现有方法。

Conclusion: 为工业表面处理任务提供统一的端到端轨迹学习方法，无需类别特定模型。

Abstract: Diffusion models, as a class of deep generative models, have recently emerged
as powerful tools for robot skills by enabling stable training with reliable
convergence. In this paper, we present an end-to-end framework for generating
long, smooth trajectories that explicitly target high surface coverage across
various industrial tasks, including polishing, robotic painting, and spray
coating. The conventional methods are always fundamentally constrained by their
predefined functional forms, which limit the shapes of the trajectories they
can represent and make it difficult to handle complex and diverse tasks.
Moreover, their generalization is poor, often requiring manual redesign or
extensive parameter tuning when applied to new scenarios. These limitations
highlight the need for more expressive generative models, making
diffusion-based approaches a compelling choice for trajectory generation. By
iteratively denoising trajectories with carefully learned noise schedules and
conditioning mechanisms, diffusion models not only ensure smooth and consistent
motion but also flexibly adapt to the task context. In experiments, our method
improves trajectory continuity, maintains high coverage, and generalizes to
unseen shapes, paving the way for unified end-to-end trajectory learning across
industrial surface-processing tasks without category-specific models. On
average, our approach improves Point-wise Chamfer Distance by 98.2\% and
smoothness by 97.0\%, while increasing surface coverage by 61\% compared to
prior methods. The link to our code can be found
\href{https://anonymous.4open.science/r/spraydiffusion_ral-2FCE/README.md}{here}.

</details>


### [26] [HumanoidExo: Scalable Whole-Body Humanoid Manipulation via Wearable Exoskeleton](https://arxiv.org/abs/2510.03022)
*Rui Zhong,Yizhe Sun,Junjie Wen,Jinming Li,Chuang Cheng,Wei Dai,Zhiwen Zeng,Huimin Lu,Yichen Zhu,Yi Xu*

Main category: cs.RO

TL;DR: HumanoidExo系统通过将人类运动转换为全身人形机器人数据，解决了人形机器人策略学习中大规模多样化数据集获取困难的问题。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人策略学习中大规模多样化数据集获取困难的问题，因为收集可靠的现实世界数据既困难又成本高昂。

Method: 引入HumanoidExo系统，将人类运动转换为全身人形机器人数据，最小化人类演示者与机器人之间的体现差距。

Result: 在三个具有挑战性的现实世界任务中评估：桌面操作、站立-蹲下运动整合的操作以及全身操作。实证表明HumanoidExo能够使人形策略泛化到新环境，仅用5个真实机器人演示学习复杂全身控制，甚至仅从HumanoidExo数据学习新技能（如行走）。

Conclusion: HumanoidExo是真实机器人数据的重要补充，通过促进收集更大量和多样化的数据集，显著提升了人形机器人在动态现实场景中的性能。

Abstract: A significant bottleneck in humanoid policy learning is the acquisition of
large-scale, diverse datasets, as collecting reliable real-world data remains
both difficult and cost-prohibitive. To address this limitation, we introduce
HumanoidExo, a novel system that transfers human motion to whole-body humanoid
data. HumanoidExo offers a high-efficiency solution that minimizes the
embodiment gap between the human demonstrator and the robot, thereby tackling
the scarcity of whole-body humanoid data. By facilitating the collection of
more voluminous and diverse datasets, our approach significantly enhances the
performance of humanoid robots in dynamic, real-world scenarios. We evaluated
our method across three challenging real-world tasks: table-top manipulation,
manipulation integrated with stand-squat motions, and whole-body manipulation.
Our results empirically demonstrate that HumanoidExo is a crucial addition to
real-robot data, as it enables the humanoid policy to generalize to novel
environments, learn complex whole-body control from only five real-robot
demonstrations, and even acquire new skills (i.e., walking) solely from
HumanoidExo data.

</details>


### [27] [Long-Term Human Motion Prediction Using Spatio-Temporal Maps of Dynamics](https://arxiv.org/abs/2510.03031)
*Yufei Zhu,Andrey Rudenko,Tomasz P. Kucner,Achim J. Lilienthal,Martin Magnusson*

Main category: cs.RO

TL;DR: 提出MoD-LHMP框架，利用动态地图编码运动模式，实现长达60秒的长期人体运动预测，在真实数据集上表现优于学习方法。


<details>
  <summary>Details</summary>
Motivation: 长期人体运动预测对自主机器人和车辆在共享环境中的安全高效运行至关重要，需要准确预测用于运动规划、人机交互等应用。

Method: 提出MoD-informed LHMP框架，支持多种动态地图类型，包含排序方法输出最可能轨迹，并引入时间条件MoD捕捉不同时段运动模式变化。

Result: 在两个真实数据集上，MoD-informed方法优于学习方法，平均位移误差改善达50%，时间条件变体达到最高准确率。

Conclusion: 动态地图能够有效提升长期人体运动预测性能，时间条件MoD进一步改善预测精度，为机器人应用提供实用框架。

Abstract: Long-term human motion prediction (LHMP) is important for the safe and
efficient operation of autonomous robots and vehicles in environments shared
with humans. Accurate predictions are important for applications including
motion planning, tracking, human-robot interaction, and safety monitoring. In
this paper, we exploit Maps of Dynamics (MoDs), which encode spatial or
spatio-temporal motion patterns as environment features, to achieve LHMP for
horizons of up to 60 seconds. We propose an MoD-informed LHMP framework that
supports various types of MoDs and includes a ranking method to output the most
likely predicted trajectory, improving practical utility in robotics. Further,
a time-conditioned MoD is introduced to capture motion patterns that vary
across different times of day. We evaluate MoD-LHMP instantiated with three
types of MoDs. Experiments on two real-world datasets show that MoD-informed
method outperforms learning-based ones, with up to 50\% improvement in average
displacement error, and the time-conditioned variant achieves the highest
accuracy overall. Project code is available at
https://github.com/test-bai-cpu/LHMP-with-MoDs.git

</details>


### [28] [Embracing Evolution: A Call for Body-Control Co-Design in Embodied Humanoid Robot](https://arxiv.org/abs/2510.03081)
*Guiliang Liu,Bo Yue,Yi Jin Kim,Kui Jia*

Main category: cs.RO

TL;DR: 这篇立场论文主张在人形机器人中采用协同设计机制，同时优化控制策略和物理结构，以实现真正的具身智能。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注固定机器人结构的控制策略优化，但人形机器人作为通用物理智能体，需要整合智能控制和自适应形态来在多样化现实环境中有效运作。

Method: 提出基于战略探索、Sim2Real迁移和元策略学习的实用协同设计方法，从方法论、应用驱动和社区导向三个角度分析协同设计的必要性。

Result: 将协同设计定位为开发下一代智能和适应性人形智能体的基石，并提出了从短期创新到长期目标的开放研究问题。

Conclusion: 协同设计机制是实现人形机器人真正具身智能的关键，需要同时进化控制策略和物理结构以适应任务特定和资源受限的环境。

Abstract: Humanoid robots, as general-purpose physical agents, must integrate both
intelligent control and adaptive morphology to operate effectively in diverse
real-world environments. While recent research has focused primarily on
optimizing control policies for fixed robot structures, this position paper
argues for evolving both control strategies and humanoid robots' physical
structure under a co-design mechanism. Inspired by biological evolution, this
approach enables robots to iteratively adapt both their form and behavior to
optimize performance within task-specific and resource-constrained contexts.
Despite its promise, co-design in humanoid robotics remains a relatively
underexplored domain, raising fundamental questions about its feasibility and
necessity in achieving true embodied intelligence. To address these challenges,
we propose practical co-design methodologies grounded in strategic exploration,
Sim2Real transfer, and meta-policy learning. We further argue for the essential
role of co-design by analyzing it from methodological, application-driven, and
community-oriented perspectives. Striving to guide and inspire future studies,
we present open research questions, spanning from short-term innovations to
long-term goals. This work positions co-design as a cornerstone for developing
the next generation of intelligent and adaptable humanoid agents.

</details>


### [29] [Whisker-based Tactile Flight for Tiny Drones](https://arxiv.org/abs/2510.03119)
*Chaoxiang Ye,Guido de Croon,Salua Hamaza*

Main category: cs.RO

TL;DR: 开发了一种仅重3.2克的触须式触觉传感装置，使微型无人机能够在黑暗等恶劣环境中通过物理接触进行导航和探索。


<details>
  <summary>Details</summary>
Motivation: 微型飞行机器人在搜救、安全检查和环境监测方面具有巨大潜力，但其小尺寸限制了传统传感能力，特别是在光线差、烟雾、灰尘或反光障碍物等条件下。

Method: 受自然界启发，采用基于气压计的触须传感器检测障碍物位置，同时开发了触觉深度估计方法以处理传感器噪声和漂移问题。系统运行在192KB RAM的微控制器上。

Result: 实现了亚6毫米精度的触觉深度估计，使无人机能够在完全黑暗中仅通过触觉导航、沿障碍物轮廓飞行和探索受限空间，支持软性和刚性表面。

Conclusion: 这种仿生方法重新定义了无视觉导航，为微型飞行器在极端环境中的应用开辟了新可能性。

Abstract: Tiny flying robots hold great potential for search-and-rescue, safety
inspections, and environmental monitoring, but their small size limits
conventional sensing-especially with poor-lighting, smoke, dust or reflective
obstacles. Inspired by nature, we propose a lightweight, 3.2-gram,
whisker-based tactile sensing apparatus for tiny drones, enabling them to
navigate and explore through gentle physical interaction. Just as rats and
moles use whiskers to perceive surroundings, our system equips drones with
tactile perception in flight, allowing obstacle sensing even in pitch-dark
conditions. The apparatus uses barometer-based whisker sensors to detect
obstacle locations while minimising destabilisation. To address sensor noise
and drift, we develop a tactile depth estimation method achieving sub-6 mm
accuracy. This enables drones to navigate, contour obstacles, and explore
confined spaces solely through touch-even in total darkness along both soft and
rigid surfaces. Running fully onboard a 192-KB RAM microcontroller, the system
supports autonomous tactile flight and is validated in both simulation and
real-world tests. Our bio-inspired approach redefines vision-free navigation,
opening new possibilities for micro aerial vehicles in extreme environments.

</details>


### [30] [Learning Stability Certificate for Robotics in Real-World Environments](https://arxiv.org/abs/2510.03123)
*Zhe Shen*

Main category: cs.RO

TL;DR: 提出了一种从轨迹数据直接学习李雅普诺夫函数的框架，无需系统动力学模型即可验证自主系统的稳定性


<details>
  <summary>Details</summary>
Motivation: 传统稳定性证书需要系统动力学的显式知识，对于复杂未知系统来说难以实现，需要数据驱动的稳定性保证方法

Method: 使用神经网络参数化李雅普诺夫候选函数，通过Cholesky分解确保正定性，允许稳定性条件的受控违反以处理噪声数据

Result: 该框架能够提供数据驱动的稳定性保证，在动态现实环境中为机器人系统提供鲁棒的安全认证

Conclusion: 该方法无需访问内部控制算法，适用于系统行为不透明或专有的情况，为机器人系统安全提供了实用的稳定性认证工具

Abstract: Stability certificates play a critical role in ensuring the safety and
reliability of robotic systems. However, deriving these certificates for
complex, unknown systems has traditionally required explicit knowledge of
system dynamics, often making it a daunting task. This work introduces a novel
framework that learns a Lyapunov function directly from trajectory data,
enabling the certification of stability for autonomous systems without needing
detailed system models. By parameterizing the Lyapunov candidate using a neural
network and ensuring positive definiteness through Cholesky factorization, our
approach automatically identifies whether the system is stable under the given
trajectory. To address the challenges posed by noisy, real-world data, we allow
for controlled violations of the stability condition, focusing on maintaining
high confidence in the stability certification process. Our results demonstrate
that this framework can provide data-driven stability guarantees, offering a
robust method for certifying the safety of robotic systems in dynamic,
real-world environments. This approach works without access to the internal
control algorithms, making it applicable even in situations where system
behavior is opaque or proprietary. The tool for learning the stability proof is
open-sourced by this research: https://github.com/HansOersted/stability.

</details>


### [31] [MM-Nav: Multi-View VLA Model for Robust Visual Navigation via Multi-Expert Learning](https://arxiv.org/abs/2510.03142)
*Tianyu Xu,Jiawei Chen,Jiazhao Zhang,Wenyao Zhang,Zekun Qi,Minghan Li,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: 提出MM-Nav多视角视觉语言动作模型，通过教师-学生方式从合成专家数据中学习多样化导航能力，在真实环境中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 视觉导航策略难以像激光雷达或深度图那样明确建模，需要智能模型和大规模数据，因此利用VLA模型从合成专家数据中学习导航能力。

Method: 基于预训练大语言模型和视觉基础模型构建多视角VLA模型MM-Nav，从三个RL专家收集专家数据，采用动态平衡训练比例的策略进行迭代训练。

Result: 在合成环境中展现出强大的泛化能力，学生VLA模型超越了RL教师，体现了多种能力整合的协同效应，真实世界实验进一步验证了有效性。

Conclusion: VLA模型能够有效学习多样化导航能力，通过教师-学生框架和动态数据平衡策略，实现了超越专家性能的导航能力。

Abstract: Visual navigation policy is widely regarded as a promising direction, as it
mimics humans by using egocentric visual observations for navigation. However,
optical information of visual observations is difficult to be explicitly
modeled like LiDAR point clouds or depth maps, which subsequently requires
intelligent models and large-scale data. To this end, we propose to leverage
the intelligence of the Vision-Language-Action (VLA) model to learn diverse
navigation capabilities from synthetic expert data in a teacher-student manner.
Specifically, we implement the VLA model, MM-Nav, as a multi-view VLA (with 360
observations) based on pretrained large language models and visual foundation
models. For large-scale navigation data, we collect expert data from three
reinforcement learning (RL) experts trained with privileged depth information
in three challenging tailor-made environments for different navigation
capabilities: reaching, squeezing, and avoiding. We iteratively train our VLA
model using data collected online from RL experts, where the training ratio is
dynamically balanced based on performance on individual capabilities. Through
extensive experiments in synthetic environments, we demonstrate that our model
achieves strong generalization capability. Moreover, we find that our student
VLA model outperforms the RL teachers, demonstrating the synergistic effect of
integrating multiple capabilities. Extensive real-world experiments further
confirm the effectiveness of our method.

</details>


### [32] [Optimal Smooth Coverage Trajectory Planning for Quadrotors in Cluttered Environment](https://arxiv.org/abs/2510.03169)
*Duanjiao Li,Yun Chen,Ying Zhang,Junwen Yao,Dongyue Huang,Jianguo Zhang,Ning Ding*

Main category: cs.RO

TL;DR: 提出一种用于无人机在复杂环境中进行覆盖轨迹规划的两阶段优化算法，前端使用遗传算法解决旅行商问题生成初始访问序列，后端通过非线性最小二乘问题优化轨迹平滑度、时间和避障约束。


<details>
  <summary>Details</summary>
Motivation: 针对无人机在电网等复杂环境中的典型应用需求，需要规划能够覆盖所有兴趣点且满足平滑性、时间效率和避障约束的轨迹。

Method: 两阶段算法：前端使用遗传算法解决TSP问题生成POI访问序列；后端将序列优化问题建模为非线性最小二乘问题，综合考虑轨迹平滑度、时间消耗和障碍物避让。

Result: 数值仿真验证了算法的有效性，确保无人机能够在复杂环境中平滑覆盖所有兴趣点。

Conclusion: 该算法能够有效解决无人机在复杂环境中的覆盖轨迹规划问题，生成满足平滑性、时间效率和避障要求的优化轨迹。

Abstract: For typical applications of UAVs in power grid scenarios, we construct the
problem as planning UAV trajectories for coverage in cluttered environments. In
this paper, we propose an optimal smooth coverage trajectory planning
algorithm. The algorithm consists of two stages. In the front-end, a Genetic
Algorithm (GA) is employed to solve the Traveling Salesman Problem (TSP) for
Points of Interest (POIs), generating an initial sequence of optimized visiting
points. In the back-end, the sequence is further optimized by considering
trajectory smoothness, time consumption, and obstacle avoidance. This is
formulated as a nonlinear least squares problem and solved to produce a smooth
coverage trajectory that satisfies these constraints. Numerical simulations
validate the effectiveness of the proposed algorithm, ensuring UAVs can
smoothly cover all POIs in cluttered environments.

</details>


### [33] [Simulation to Rules: A Dual-VLM Framework for Formal Visual Planning](https://arxiv.org/abs/2510.03182)
*Yilun Hao,Yongchao Chen,Chuchu Fan,Yang Zhang*

Main category: cs.RO

TL;DR: VLMFP是一个双VLM引导的框架，能够自主生成PDDL问题文件和领域文件，解决视觉语言模型在空间和长时程推理方面的不足，同时结合PDDL规划器的优势。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在视觉规划方面有潜力，但在精确空间和长时程推理方面存在困难；而PDDL规划器擅长形式化规划，但无法解释视觉输入。现有方法需要人工预定义领域文件或依赖环境访问进行优化。

Method: 提出VLMFP框架，包含两个VLM：SimVLM基于输入规则描述模拟动作后果，GenVLM通过比较PDDL和SimVLM执行结果来生成和迭代优化PDDL文件。

Result: 在6个网格世界领域评估中，SimVLM能够准确描述95.5%（已知外观）和82.6%（未知外观）的场景，模拟85.5%和87.8%的动作序列，判断82.4%和85.6%的目标达成。VLMFP能够为已知和未知外观的未见实例生成有效规划，成功率分别为70.0%和54.1%。

Conclusion: VLMFP能够自主生成PDDL文件，实现多层次的泛化能力：同一生成的PDDL领域文件适用于同一问题下的不同实例，且VLM能够泛化到具有不同外观和规则的问题。

Abstract: Vision Language Models (VLMs) show strong potential for visual planning but
struggle with precise spatial and long-horizon reasoning. In contrast, Planning
Domain Definition Language (PDDL) planners excel at long-horizon formal
planning, but cannot interpret visual inputs. Recent works combine these
complementary advantages by enabling VLMs to turn visual planning problems into
PDDL files for formal planning. However, while VLMs can generate PDDL problem
files satisfactorily, they struggle to accurately generate the PDDL domain
files, which describe all the planning rules. As a result, prior methods rely
on human experts to predefine domain files or on constant environment access
for refinement. We propose VLMFP, a Dual-VLM-guided framework that can
autonomously generate both PDDL problem and domain files for formal visual
planning. VLMFP introduces two VLMs to ensure reliable PDDL file generation: A
SimVLM that simulates action consequences based on input rule descriptions, and
a GenVLM that generates and iteratively refines PDDL files by comparing the
PDDL and SimVLM execution results. VLMFP unleashes multiple levels of
generalizability: The same generated PDDL domain file works for all the
different instances under the same problem, and VLMs generalize to different
problems with varied appearances and rules. We evaluate VLMFP with 6 grid-world
domains and test its generalization to unseen instances, appearance, and game
rules. On average, SimVLM accurately describes 95.5%, 82.6% of scenarios,
simulates 85.5%, 87.8% of action sequence, and judges 82.4%, 85.6% goal
reaching for seen and unseen appearances, respectively. With the guidance of
SimVLM, VLMFP can generate PDDL files to reach 70.0%, 54.1% valid plans for
unseen instances in seen and unseen appearances, respectively. Project page:
https://sites.google.com/view/vlmfp.

</details>
