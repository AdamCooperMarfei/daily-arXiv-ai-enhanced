<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 28]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Configuration-Dependent Robot Kinematics Model and Calibration](https://arxiv.org/abs/2510.19962)
*Chen-Lung Lu,Honglu He,Agung Julius,John T. Wen*

Main category: cs.RO

TL;DR: 提出一种基于局部POE模型和傅里叶基函数插值的构型依赖运动学校准框架，显著提高工业机器人全工作空间定位精度


<details>
  <summary>Details</summary>
Motivation: 解决非几何因素导致的构型依赖模型偏差问题，满足冷喷涂制造等应用对亚毫米级精度的需求

Method: 在多个构型下识别局部POE模型，通过肩肘关节角度参数化的傅里叶基函数插值构建全局模型

Result: 在两种6自由度工业机器人上验证，最大定位误差降低超过50%，达到亚毫米精度要求

Conclusion: 该方法训练效率高，对构型依赖偏差大的机器人效果更显著，在双机器人协作任务中展示了实用性和可重复性

Abstract: Accurate robot kinematics is essential for precise tool placement in
articulated robots, but non-geometric factors can introduce
configuration-dependent model discrepancies. This paper presents a
configuration-dependent kinematic calibration framework for improving accuracy
across the entire workspace. Local Product-of-Exponential (POE) models,
selected for their parameterization continuity, are identified at multiple
configurations and interpolated into a global model. Inspired by joint gravity
load expressions, we employ Fourier basis function interpolation parameterized
by the shoulder and elbow joint angles, achieving accuracy comparable to neural
network and autoencoder methods but with substantially higher training
efficiency. Validation on two 6-DoF industrial robots shows that the proposed
approach reduces the maximum positioning error by over 50%, meeting the
sub-millimeter accuracy required for cold spray manufacturing. Robots with
larger configuration-dependent discrepancies benefit even more. A dual-robot
collaborative task demonstrates the framework's practical applicability and
repeatability.

</details>


### [2] [Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC](https://arxiv.org/abs/2510.19974)
*Hien Bui,Yufeiyang Gao,Haoran Yang,Eric Cui,Siddhant Mody,Brian Acosta,Thomas Stephen Felix,Bibit Bianchini,Michael Posa*

Main category: cs.RO

TL;DR: 本文提出了C3+算法，一种增强的接触隐式模型预测控制方法，能够在多物体平面推动任务中实现实时性能，成功率达到98%。


<details>
  <summary>Details</summary>
Motivation: 解决非抓取操作中物体物理属性未知和接触丰富交互复杂性的核心挑战，扩展CI-MPC方法在多样化物体几何和多物体场景中的应用能力。

Method: 引入Consensus Complementarity Control Plus (C3+)算法，集成物体扫描、网格重建和硬件执行的完整流程，相比前代C3显著提升求解速度。

Result: 在33个物体上达到98%的成功率，平均完成时间分别为：单物体0.5分钟、双物体1.6分钟、三物体3.2分钟、四物体5.3分钟。

Conclusion: C3+算法在多物体推动任务中表现出色，实现了接触隐式控制的实时应用，扩展了非抓取操作的边界。

Abstract: Non-prehensile manipulation of diverse objects remains a core challenge in
robotics, driven by unknown physical properties and the complexity of
contact-rich interactions. Recent advances in contact-implicit model predictive
control (CI-MPC), with contact reasoning embedded directly in the trajectory
optimization, have shown promise in tackling the task efficiently and robustly,
yet demonstrations have been limited to narrowly curated examples. In this
work, we showcase the broader capabilities of CI-MPC through precise planar
pushing tasks over a wide range of object geometries, including multi-object
domains. These scenarios demand reasoning over numerous inter-object and
object-environment contacts to strategically manipulate and de-clutter the
environment, challenges that were intractable for prior CI-MPC methods. To
achieve this, we introduce Consensus Complementarity Control Plus (C3+), an
enhanced CI-MPC algorithm integrated into a complete pipeline spanning object
scanning, mesh reconstruction, and hardware execution. Compared to its
predecessor C3, C3+ achieves substantially faster solve times, enabling
real-time performance even in multi-object pushing tasks. On hardware, our
system achieves overall 98% success rate across 33 objects, reaching pose goals
within tight tolerances. The average time-to-goal is approximately 0.5, 1.6,
3.2, and 5.3 minutes for 1-, 2-, 3-, and 4-object tasks, respectively. Project
page: https://dairlab.github.io/push-anything.

</details>


### [3] [Simultaneous learning of state-to-state minimum-time planning and control](https://arxiv.org/abs/2510.20008)
*Swati Dantu,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 提出基于强化学习的框架，学习无人机任意状态间的最小时间飞行策略，结合敏捷飞行和稳定悬停，并在真实环境中验证其泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统自主无人机竞速方法受限于预设轨道布局，缺乏现实世界的通用性。需要开发能够在任意起点和终点状态间进行最小时间飞行的通用策略。

Method: 使用强化学习框架，以点质量模型轨迹作为代理奖励来近似最优飞行目标，并采用课程学习来高效扩展训练过程和实现泛化。

Result: 仿真实验显示方法优于非线性模型预测控制跟踪点质量模型轨迹，真实世界实验证实策略在户外环境中的鲁棒性和泛化能力，可在小型ARM单板计算机上运行。

Conclusion: 该方法成功实现了无人机任意状态间的最小时间飞行策略学习，具有良好的泛化能力和实际部署可行性。

Abstract: This paper tackles the challenge of learning a generalizable minimum-time
flight policy for UAVs, capable of navigating between arbitrary start and goal
states while balancing agile flight and stable hovering. Traditional
approaches, particularly in autonomous drone racing, achieve impressive speeds
and agility but are constrained to predefined track layouts, limiting
real-world applicability. To address this, we propose a reinforcement
learning-based framework that simultaneously learns state-to-state minimum-time
planning and control and generalizes to arbitrary state-to-state flights. Our
approach leverages Point Mass Model (PMM) trajectories as proxy rewards to
approximate the true optimal flight objective and employs curriculum learning
to scale the training process efficiently and to achieve generalization. We
validate our method through simulation experiments, comparing it against
Nonlinear Model Predictive Control (NMPC) tracking PMM-generated trajectories
and conducting ablation studies to assess the impact of curriculum learning.
Finally, real-world experiments confirm the robustness of our learned policy in
outdoor environments, demonstrating its ability to generalize and operate on a
small ARM-based single-board computer.

</details>


### [4] [Calibration of Parallel Kinematic Machine Based on Stewart Platform-A Literature Review](https://arxiv.org/abs/2510.20070)
*Sourabh Karmakar,Apurva Patel,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本文综述了基于Stewart平台的并联运动学机器人的标定方法，重点分析了逆运动学标定的优势，比较了外部仪器、约束和自标定三种方法，并指出了当前研究主要关注无负载条件下的结构误差补偿。


<details>
  <summary>Details</summary>
Motivation: 并联运动学机器人在精密应用中需要达到微纳级运动控制精度，因此必须进行精确标定。传统正向运动学标定过于复杂，而逆运动学标定能更有效地完成这一任务。

Method: 通过文献综述分析了三种主要标定方法：外部仪器标定、约束标定和自标定，重点关注逆运动学在标定中的应用。

Result: 研究发现研究人员主要关注平台位置和方向精度的提升，考虑单一或多重误差源，主要是结构误差，部分考虑环境因素，但都在无负载条件下进行标定。

Conclusion: 本研究旨在理解该领域当前技术水平，为其他研究人员在特定领域的进一步探索提供方向和扩展空间。

Abstract: Stewart platform-based Parallel Kinematic (PKM) Machines have been
extensively studied by researchers due to their inherent finer control
characteristics. This has opened its potential deployment opportunities in
versatile critical applications like the medical field, engineering machines,
space research, electronic chip manufacturing, automobile manufacturing, etc.
All these precise, complicated, and repeatable motion applications require
micro and nano-scale movement control in 3D space; a 6-DOF PKM can take this
challenge smartly. For this, the PKM must be more accurate than the desired
application accuracy level and thus proper calibration for a PKM robot is
essential. Forward kinematics-based calibration for such hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To analyze different techniques, an external instrument-based,
constraint-based, and auto or self-calibration-based approaches have been used
for calibration. This survey has been done by reviewing these key
methodologies, their outcome, and important points related to inverse
kinematic-based PKM calibrations in general. It is observed in this study that
the researchers focused on improving the accuracy of the platform position and
orientation considering the errors contributed by a single source or multiple
sources. The error sources considered are mainly structural, in some cases,
environmental factors are also considered, however, these calibrations are done
under no-load conditions. This study aims to understand the current state of
the art in this field and to expand the scope for other researchers in further
exploration in a specific area.

</details>


### [5] [Design of a Bed Rotation Mechanism to Facilitate In-Situ Photogrammetric Reconstruction of Printed Parts](https://arxiv.org/abs/2510.20079)
*Travis A. Roberts,Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 设计并制造了一台用于聚合物FDM工艺研究的3D打印机，具有闭环位置反馈、温度控制、环境监测和原位摄影测量功能，特别关注可旋转加热床的创新机制。


<details>
  <summary>Details</summary>
Motivation: 商用和消费级3D打印机通常是封闭平台，缺乏研究所需的灵活性和参数控制精度，需要开发一个能够精确控制和监测FDM工艺参数的研究平台。

Method: 设计和制造了具有闭环位置反馈、温度控制、环境监测的FDM打印机，采用可旋转加热床机制，使用最少数量的摄像头实现原位摄影测量和几何重建。

Result: 成功开发了一个能够精确控制FDM工艺参数的研究平台，通过旋转加热床机制实现了使用最少摄像头进行摄影测量重建的能力。

Conclusion: 该平台为聚合物FDM工艺研究提供了可重复实验的基础，通过创新的旋转床机制实现了高效的原位几何记录和缺陷分析。

Abstract: Additive manufacturing, or 3D printing, is a complex process that creates
free-form geometric objects by sequentially placing material to construct an
object, usually in a layer-by-layer process. One of the most widely used
methods is Fused Deposition Modeling (FDM). FDM is used in many of the
consumer-grade polymer 3D printers available today. While consumer grade
machines are cheap and plentiful, they lack many of the features desired in a
machine used for research purposes and are often closed-source platforms.
Commercial-grade models are more expensive and are also usually closed-source
platforms that do not offer flexibility for modifications often needed for
research. The authors designed and fabricated a machine to be used as a test
bed for research in the field of polymer FDM processes. The goal was to create
a platform that tightly controls and/or monitors the FDM build parameters so
that experiments can be repeated with a known accuracy. The platform offers
closed loop position feedback, control of the hot end and bed temperature, and
monitoring of environment temperature and humidity. Additionally, the platform
is equipped with cameras and a mechanism for in-situ photogrammetry, creating a
geometric record of the printing throughout the printing process. Through
photogrammetry, backtracking and linking process parameters to observable
geometric defects can be achieved. This paper focuses on the design of a novel
mechanism for spinning the heated bed to allow for photogrammetric
reconstruction of the printed part using a minimal number of cameras, as
implemented on this platform.

</details>


### [6] [PathFormer: A Transformer with 3D Grid Constraints for Digital Twin Robot-Arm Trajectory Generation](https://arxiv.org/abs/2510.20161)
*Ahmed Alanazi,Duy Ho,Yugyung Lee*

Main category: cs.RO

TL;DR: 提出基于路径的Transformer模型，通过3网格表示和约束掩码解码生成机器人轨迹，在真实机器人上实现高成功率。


<details>
  <summary>Details</summary>
Motivation: 解决序列模型忽略运动结构导致无效或低效执行的问题，将图规划与序列学习相结合。

Method: 使用3网格（位置/内容/时间）表示编码机器人运动，采用约束掩码解码确保相邻移动和工作空间约束，基于53,755条轨迹训练。

Result: 达到89.44%步骤准确率，99.99%路径合法，在真实机器人上实现97.5%到达成功率和92.5%抓取成功率，在60个语言指定任务中达到86.7%端到端成功率。

Conclusion: 路径结构表示使Transformer能够生成准确、可靠、可解释的机器人轨迹，为通用操作和仿真到现实迁移提供实用基础。

Abstract: Robotic arms require precise, task-aware trajectory planning, yet sequence
models that ignore motion structure often yield invalid or inefficient
executions. We present a Path-based Transformer that encodes robot motion with
a 3-grid (where/what/when) representation and constraint-masked decoding,
enforcing lattice-adjacent moves and workspace bounds while reasoning over task
graphs and action order. Trained on 53,755 trajectories (80% train / 20%
validation), the model aligns closely with ground truth -- 89.44% stepwise
accuracy, 93.32% precision, 89.44% recall, and 90.40% F1 -- with 99.99% of
paths legal by construction. Compiled to motor primitives on an xArm Lite 6
with a depth-camera digital twin, it attains up to 97.5% reach and 92.5% pick
success in controlled tests, and 86.7% end-to-end success across 60
language-specified tasks in cluttered scenes, absorbing slips and occlusions
via local re-grounding without global re-planning. These results show that
path-structured representations enable Transformers to generate accurate,
reliable, and interpretable robot trajectories, bridging graph-based planning
and sequence-based learning and providing a practical foundation for
general-purpose manipulation and sim-to-real transfer.

</details>


### [7] [Reinforcement Learning-based Robust Wall Climbing Locomotion Controller in Ferromagnetic Environment](https://arxiv.org/abs/2510.20174)
*Yong Um,Young-Ha Shin,Joon-Ha Kim,Soonpyo Kwon,Hae-Won Park*

Main category: cs.RO

TL;DR: 提出了一种针对四足磁性爬壁机器人的强化学习框架，通过三阶段课程学习处理磁力附着不确定性，实现稳健的垂直表面爬行。


<details>
  <summary>Details</summary>
Motivation: 解决磁性爬壁机器人中磁力附着的不确定性问题，包括部分接触、气隙敏感性和概率性附着失败，以提高在复杂环境中的鲁棒性。

Method: 采用三阶段课程学习：1) 在平坦地面学习爬行步态；2) 逐渐旋转重力矢量并激活附着模型；3) 注入随机附着失败以训练滑移恢复能力。

Result: 学习到的策略在模拟中实现了高成功率、强附着保持和快速脱落恢复。硬件实验证实了在钢表面上稳健的垂直爬行能力。

Conclusion: 结合课程学习和真实附着建模为磁性爬壁机器人提供了弹性的仿真到现实框架，能够在复杂环境中保持运动稳定性。

Abstract: We present a reinforcement learning framework for quadrupedal wall-climbing
locomotion that explicitly addresses uncertainty in magnetic foot adhesion. A
physics-based adhesion model of a quadrupedal magnetic climbing robot is
incorporated into simulation to capture partial contact, air-gap sensitivity,
and probabilistic attachment failures. To stabilize learning and enable
reliable transfer, we design a three-phase curriculum: (1) acquire a crawl gait
on flat ground without adhesion, (2) gradually rotate the gravity vector to
vertical while activating the adhesion model, and (3) inject stochastic
adhesion failures to encourage slip recovery. The learned policy achieves a
high success rate, strong adhesion retention, and rapid recovery from
detachment in simulation under degraded adhesion. Compared with a model
predictive control (MPC) baseline that assumes perfect adhesion, our controller
maintains locomotion when attachment is intermittently lost. Hardware
experiments with the untethered robot further confirm robust vertical crawling
on steel surfaces, maintaining stability despite transient misalignment and
incomplete attachment. These results show that combining curriculum learning
with realistic adhesion modeling provides a resilient sim-to-real framework for
magnetic climbing robots in complex environments.

</details>


### [8] [A Contact-Driven Framework for Manipulating in the Blind](https://arxiv.org/abs/2510.20177)
*Muhammad Suhail Saleem,Lai Yuan,Maxim Likhachev*

Main category: cs.RO

TL;DR: 提出了一种在视觉受限环境中结合触觉反馈和结构先验的机器人操作框架，包含接触检测定位、占据估计和规划三个模块，在模拟和真实环境中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 机器人在视觉受限环境（如遮挡、光线差）中操作时，需要依赖触觉反馈来感知环境。许多环境具有结构先验（如管道布局），可以利用这些先验来预测未观察到的结构并避免碰撞。

Method: 框架包含三个紧密耦合的组件：(1) 基于关节力矩传感和接触粒子滤波器的接触检测定位模块；(2) 使用接触观测历史构建部分占据图并通过学习预测器外推的占据估计模块；(3) 考虑噪声的接触定位和占据预测的规划模块。

Result: 在模拟和真实UR10e机械臂上测试了两个家庭任务：操作厨房水槽下的阀门和在杂乱货架上取物。结果显示框架可靠完成任务，相比基线方法任务完成时间最多减少2倍，消融实验确认了各模块的贡献。

Conclusion: 该框架通过整合触觉反馈和结构先验，实现了在视觉受限环境中的鲁棒操作，显著提高了任务效率。

Abstract: Robots often face manipulation tasks in environments where vision is
inadequate due to clutter, occlusions, or poor lighting--for example, reaching
a shutoff valve at the back of a sink cabinet or locating a light switch above
a crowded shelf. In such settings, robots, much like humans, must rely on
contact feedback to distinguish free from occupied space and navigate around
obstacles. Many of these environments often exhibit strong structural
priors--for instance, pipes often span across sink cabinets--that can be
exploited to anticipate unseen structure and avoid unnecessary collisions. We
present a theoretically complete and empirically efficient framework for
manipulation in the blind that integrates contact feedback with structural
priors to enable robust operation in unknown environments. The framework
comprises three tightly coupled components: (i) a contact detection and
localization module that utilizes joint torque sensing with a contact particle
filter to detect and localize contacts, (ii) an occupancy estimation module
that uses the history of contact observations to build a partial occupancy map
of the workspace and extrapolate it into unexplored regions with learned
predictors, and (iii) a planning module that accounts for the fact that contact
localization estimates and occupancy predictions can be noisy, computing paths
that avoid collisions and complete tasks efficiently without eliminating
feasible solutions. We evaluate the system in simulation and in the real world
on a UR10e manipulator across two domestic tasks--(i) manipulating a valve
under a kitchen sink surrounded by pipes and (ii) retrieving a target object
from a cluttered shelf. Results show that the framework reliably solves these
tasks, achieving up to a 2x reduction in task completion time compared to
baselines, with ablations confirming the contribution of each module.

</details>


### [9] [NODA-MMH: Certified Learning-Aided Nonlinear Control for Magnetically-Actuated Swarm Experiment Toward On-Orbit Proof](https://arxiv.org/abs/2510.20231)
*Yuta Takahashi,Atsuki Ochi,Yoichi Tomioka,Shin-Ichiro Sakai*

Main category: cs.RO

TL;DR: 该研究通过实验验证了基于学习辅助磁场相互作用的大规模卫星群控制原理，使用卫星安装的磁力矩器进行驱动，解决了多卫星长期编队维持中的非线性挑战。


<details>
  <summary>Details</summary>
Motivation: 解决多卫星编队维持中的基本挑战：非完整约束、欠驱动、可扩展性和计算成本，特别是在卫星数量超过三个时这些挑战与高度非线性问题同时出现。

Method: 采用学习辅助的时间积分电流控制方法，设计两轴线圈和基于气浮平台的地面实验装置，开发NODA-MMH算法进行基于模型的功率最优群控制。

Result: 实验验证了学习辅助时间积分电流控制的两个关键方面：增强平均系统动力学的可控性（具有理论保证的误差界限）和分散式电流管理。

Conclusion: 该研究为磁驱动卫星群的长期编队维持问题提供了实验验证，证明了学习辅助磁场相互作用控制原理的有效性。

Abstract: This study experimentally validates the principle of large-scale satellite
swarm control through learning-aided magnetic field interactions generated by
satellite-mounted magnetorquers. This actuation presents a promising solution
for the long-term formation maintenance of multiple satellites and has
primarily been demonstrated in ground-based testbeds for two-satellite position
control. However, as the number of satellites increases beyond three,
fundamental challenges coupled with the high nonlinearity arise: 1)
nonholonomic constraints, 2) underactuation, 3) scalability, and 4)
computational cost. Previous studies have shown that time-integrated current
control theoretically solves these problems, where the average actuator outputs
align with the desired command, and a learning-based technique further enhances
their performance. Through multiple experiments, we validate critical aspects
of learning-aided time-integrated current control: (1) enhanced controllability
of the averaged system dynamics, with a theoretically guaranteed error bound,
and (2) decentralized current management. We design two-axis coils and a
ground-based experimental setup utilizing an air-bearing platform, enabling a
mathematical replication of orbital dynamics. Based on the effectiveness of the
learned interaction model, we introduce NODA-MMH (Neural power-Optimal Dipole
Allocation for certified learned Model-based Magnetically swarm control
Harness) for model-based power-optimal swarm control. This study complements
our tutorial paper on magnetically actuated swarms for the long-term formation
maintenance problem.

</details>


### [10] [Kinaema: a recurrent sequence model for memory and pose in motion](https://arxiv.org/abs/2510.20261)
*Mert Bulent Sariyildiz,Philippe Weinzaepfel,Guillaume Bono,Gianluca Monaci,Christian Wolf*

Main category: cs.RO

TL;DR: Kinaema模型通过隐式潜在记忆和循环变换器处理视觉观察流，实现在大场景中定位和导航，无需显式存储观察历史。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在连续操作中利用先前观察信息进行高效定位和导航的问题，克服传统方法在上下文长度上的限制。

Method: 使用循环变换器更新隐式潜在记忆，压缩传感器读数历史为紧凑表示，支持处理查询图像并预测相对位置。

Result: 模型能有效维护场景表示，导航到先前观察的目标位置，计算效率优于基于观察历史注意力的传统变换器。

Conclusion: Kinaema通过隐式记忆机制实现了高效的场景理解和导航，为连续机器人操作提供了可行的解决方案。

Abstract: One key aspect of spatially aware robots is the ability to "find their
bearings", ie. to correctly situate themselves in previously seen spaces. In
this work, we focus on this particular scenario of continuous robotics
operations, where information observed before an actual episode start is
exploited to optimize efficiency. We introduce a new model, Kinaema, and agent,
capable of integrating a stream of visual observations while moving in a
potentially large scene, and upon request, processing a query image and
predicting the relative position of the shown space with respect to its current
position. Our model does not explicitly store an observation history, therefore
does not have hard constraints on context length. It maintains an implicit
latent memory, which is updated by a transformer in a recurrent way,
compressing the history of sensor readings into a compact representation. We
evaluate the impact of this model in a new downstream task we call "Mem-Nav".
We show that our large-capacity recurrent model maintains a useful
representation of the scene, navigates to goals observed before the actual
episode start, and is computationally efficient, in particular compared to
classical transformers with attention over an observation history.

</details>


### [11] [MemER: Scaling Up Memory for Robot Control via Experience Retrieval](https://arxiv.org/abs/2510.20328)
*Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn*

Main category: cs.RO

TL;DR: 提出MemER分层策略框架，让机器人策略具备记忆能力。高层策略选择跟踪历史关键帧，结合最新帧生成文本指令给底层策略执行，兼容现有VLA模型，在需要分钟级记忆的长时程操作任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 人类依赖记忆执行任务，但大多数机器人策略缺乏这种能力。直接使用长观测历史计算成本高且对分布偏移敏感，而无差别采样历史会导致信息冗余或无关。

Method: 分层策略框架：高层策略训练选择跟踪历史相关关键帧，使用选定关键帧和最新帧为底层策略生成文本指令。基于Qwen2.5-VL-7B-Instruct和π0.5分别作为高低层策略进行微调，使用带最小语言标注的演示数据。

Result: MemER在三个需要分钟级记忆的真实世界长时程机器人操作任务中优于先前方法。

Conclusion: 提出的分层记忆框架有效解决了机器人策略的记忆问题，能够高效处理长时程依赖关系，在复杂操作任务中表现出色。

Abstract: Humans routinely rely on memory to perform tasks, yet most robot policies
lack this capability; our goal is to endow robot policies with the same
ability. Naively conditioning on long observation histories is computationally
expensive and brittle under covariate shift, while indiscriminate subsampling
of history leads to irrelevant or redundant information. We propose a
hierarchical policy framework, where the high-level policy is trained to select
and track previous relevant keyframes from its experience. The high-level
policy uses selected keyframes and the most recent frames when generating text
instructions for a low-level policy to execute. This design is compatible with
existing vision-language-action (VLA) models and enables the system to
efficiently reason over long-horizon dependencies. In our experiments, we
finetune Qwen2.5-VL-7B-Instruct and $\pi_{0.5}$ as the high-level and low-level
policies respectively, using demonstrations supplemented with minimal language
annotations. Our approach, MemER, outperforms prior methods on three real-world
long-horizon robotic manipulation tasks that require minutes of memory. Videos
and code can be found at https://jen-pan.github.io/memer/.

</details>


### [12] [Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking](https://arxiv.org/abs/2510.20335)
*Zixuan Wu,Hengyuan Zhang,Ting-Hsuan Chen,Yuliang Guo,David Paz,Xinyu Huang,Liu Ren*

Main category: cs.RO

TL;DR: DDP是一个领域无关的自主停车系统，结合视觉基础模型和扩散规划，在分布偏移下实现泛化感知和鲁棒运动规划。


<details>
  <summary>Details</summary>
Motivation: 解决端到端方法在领域转移（如天气和光照变化）下鲁棒性不足的问题，不依赖额外数据。

Method: 集成视觉基础模型与基于扩散的规划，在CARLA中训练并在对抗性设置中进行零样本迁移。

Result: 在所有测试的分布外场景中停车成功率超过90%，消融研究证实网络架构和算法设计显著提升跨域性能。

Conclusion: 在3D高斯溅射环境中测试显示出有前景的模拟到真实世界迁移能力。

Abstract: Parking is a critical pillar of driving safety. While recent end-to-end (E2E)
approaches have achieved promising in-domain results, robustness under domain
shifts (e.g., weather and lighting changes) remains a key challenge. Rather
than relying on additional data, in this paper, we propose Dino-Diffusion
Parking (DDP), a domain-agnostic autonomous parking pipeline that integrates
visual foundation models with diffusion-based planning to enable generalized
perception and robust motion planning under distribution shifts. We train our
pipeline in CARLA at regular setting and transfer it to more adversarial
settings in a zero-shot fashion. Our model consistently achieves a parking
success rate above 90% across all tested out-of-distribution (OOD) scenarios,
with ablation studies confirming that both the network architecture and
algorithmic design significantly enhance cross-domain performance over existing
baselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment
reconstructed from a real-world parking lot demonstrates promising sim-to-real
transfer.

</details>


### [13] [Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots](https://arxiv.org/abs/2510.20347)
*Ashutosh Mishra,Shreya Santra,Elian Neppel,Edoardo M. Rossi Lombardi,Shamistan Karimov,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出了一种去中心化强化学习方案，使模块化可重构机器人能够零样本泛化到未见过的配置，在月球模拟现场测试中验证了自主运动、转向和重构的集成能力。


<details>
  <summary>Details</summary>
Motivation: 模块化可重构机器人适合特定任务的空间操作，但形态组合的指数增长阻碍了统一控制，需要解决模块化系统的控制泛化问题。

Method: 采用去中心化强化学习方案，轮式模块使用SAC算法进行运动控制，7自由度肢体模块使用PPO算法进行转向和操作控制。

Result: 转向策略实现了3.63度的平均绝对误差，操作策略在目标偏移标准下达到84.6%成功率，轮式策略相比基线将平均电机扭矩降低了95.4%同时保持99.6%成功率。

Conclusion: 系统在策略执行期间能够平滑过渡同步、并行和顺序模式，没有空闲状态或控制冲突，表明这是一种可扩展、可重用且鲁棒的模块化月球机器人方法。

Abstract: Modular reconfigurable robots suit task-specific space operations, but the
combinatorial growth of morphologies hinders unified control. We propose a
decentralized reinforcement learning (Dec-RL) scheme where each module learns
its own policy: wheel modules use Soft Actor-Critic (SAC) for locomotion and
7-DoF limbs use Proximal Policy Optimization (PPO) for steering and
manipulation, enabling zero-shot generalization to unseen configurations. In
simulation, the steering policy achieved a mean absolute error of 3.63{\deg}
between desired and induced angles; the manipulation policy plateaued at 84.6 %
success on a target-offset criterion; and the wheel policy cut average motor
torque by 95.4 % relative to baseline while maintaining 99.6 % success.
Lunar-analogue field tests validated zero-shot integration for autonomous
locomotion, steering, and preliminary alignment for reconfiguration. The system
transitioned smoothly among synchronous, parallel, and sequential modes for
Policy Execution, without idle states or control conflicts, indicating a
scalable, reusable, and robust approach for modular lunar robots.

</details>


### [14] [NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control](https://arxiv.org/abs/2510.20390)
*Yijiong Lin,Bowen Deng,Chenghua Lu,Max Yang,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: NeuralTouch是一个多模态框架，结合神经描述场(NDF)和触觉传感，通过轻柔物理交互实现准确、可泛化的抓取。


<details>
  <summary>Details</summary>
Motivation: NDF单独使用时由于相机标定不完美、点云不完整和物体变化性会产生不准确的抓取姿态，而现有触觉方法通常局限于简单的预定义接触几何形状。

Method: 利用NDF隐式表示目标接触几何，训练深度强化学习策略使用触觉反馈来优化抓取，该策略以神经描述符为条件，无需显式指定接触类型。

Result: 在模拟和真实世界操作任务(如孔中插销和瓶盖开启)中的零样本迁移验证显示，NeuralTouch显著提高了抓取准确性和鲁棒性。

Conclusion: NeuralTouch为精确、接触丰富的机器人操作提供了一个通用框架。

Abstract: Grasping accuracy is a critical prerequisite for precise object manipulation,
often requiring careful alignment between the robot hand and object. Neural
Descriptor Fields (NDF) offer a promising vision-based method to generate
grasping poses that generalize across object categories. However, NDF alone can
produce inaccurate poses due to imperfect camera calibration, incomplete point
clouds, and object variability. Meanwhile, tactile sensing enables more precise
contact, but existing approaches typically learn policies limited to simple,
predefined contact geometries. In this work, we introduce NeuralTouch, a
multimodal framework that integrates NDF and tactile sensing to enable
accurate, generalizable grasping through gentle physical interaction. Our
approach leverages NDF to implicitly represent the target contact geometry,
from which a deep reinforcement learning (RL) policy is trained to refine the
grasp using tactile feedback. This policy is conditioned on the neural
descriptors and does not require explicit specification of contact types. We
validate NeuralTouch through ablation studies in simulation and zero-shot
transfer to real-world manipulation tasks--such as peg-out-in-hole and bottle
lid opening--without additional fine-tuning. Results show that NeuralTouch
significantly improves grasping accuracy and robustness over baseline methods,
offering a general framework for precise, contact-rich robotic manipulation.

</details>


### [15] [PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning](https://arxiv.org/abs/2510.20406)
*Xiaogang Jia,Qian Wang,Anrui Wang,Han A. Wang,Balázs Gyenes,Emiliyan Gospodinov,Xinkai Jiang,Ge Li,Hongyi Zhou,Weiran Liao,Xi Huang,Maximilian Beck,Moritz Reuss,Rudolf Lioutikov,Gerhard Neumann*

Main category: cs.RO

TL;DR: PointMapPolicy是一种新颖的扩散策略方法，通过在不进行下采样的结构化点网格上操作，结合RGB图像数据，实现增强的多模态感知，在机器人操作任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前点云方法难以捕捉细粒度细节，而RGB方法缺乏几何感知能力，限制了机器人操作系统的精度和泛化能力。需要结合两种感知模态的优势。

Method: 提出PointMapPolicy，在结构化点网格上条件化扩散策略，使用xLSTM作为骨干网络有效融合点图和RGB数据，可直接将计算机视觉技术应用于3D数据。

Result: 在RoboCasa和CALVIN基准测试以及真实机器人评估中，该方法在多样化操作任务上实现了最先进的性能。

Conclusion: PointMapPolicy通过结构化点网格和RGB数据的有效融合，显著提升了机器人操作系统的感知能力和任务执行性能。

Abstract: Robotic manipulation systems benefit from complementary sensing modalities,
where each provides unique environmental information. Point clouds capture
detailed geometric structure, while RGB images provide rich semantic context.
Current point cloud methods struggle to capture fine-grained detail, especially
for complex tasks, which RGB methods lack geometric awareness, which hinders
their precision and generalization. We introduce PointMapPolicy, a novel
approach that conditions diffusion policies on structured grids of points
without downsampling. The resulting data type makes it easier to extract shape
and spatial relationships from observations, and can be transformed between
reference frames. Yet due to their structure in a regular grid, we enable the
use of established computer vision techniques directly to 3D data. Using xLSTM
as a backbone, our model efficiently fuses the point maps with RGB data for
enhanced multi-modal perception. Through extensive experiments on the RoboCasa
and CALVIN benchmarks and real robot evaluations, we demonstrate that our
method achieves state-of-the-art performance across diverse manipulation tasks.
The overview and demos are available on our project page:
https://point-map.github.io/Point-Map/

</details>


### [16] [MR-UBi: Mixed Reality-Based Underwater Robot Arm Teleoperation System with Reaction Torque Indicator via Bilateral Control](https://arxiv.org/abs/2510.20407)
*Kohei Nishi,Masato Kobayashi,Yuki Uranishi*

Main category: cs.RO

TL;DR: 开发了基于混合现实的水下机器人手臂遥操作系统MR-UBi，通过双边控制和反应扭矩指示器整合视觉与触觉反馈，显著提高了抓取扭矩控制精度和用户体验。


<details>
  <summary>Details</summary>
Motivation: 解决水下机器人手臂遥操作中视觉与触觉反馈整合不足的问题，提高操作的稳定性和准确性。

Method: 使用混合现实头戴显示器(MR-HMD)叠加颜色和长度编码的扭矩条作为反应扭矩指示器，结合双边控制实现视觉与触觉反馈的整合。

Result: MR-UBi显著提高了抓取扭矩控制精度，增加了在最佳扭矩范围内的时间，减少了低和高抓取扭矩范围，主观评估显示更高的可用性和更低的工作负荷。

Conclusion: MR-UBi通过整合视觉和触觉反馈，实现了更稳定、准确和用户友好的水下机器人手臂遥操作。

Abstract: We present a mixed reality-based underwater robot arm teleoperation system
with a reaction torque indicator via bilateral control (MR-UBi). The reaction
torque indicator (RTI) overlays a color and length-coded torque bar in the
MR-HMD, enabling seamless integration of visual and haptic feedback during
underwater robot arm teleoperation. User studies with sixteen participants
compared MR-UBi against a bilateral-control baseline. MR-UBi significantly
improved grasping-torque control accuracy, increasing the time within the
optimal torque range and reducing both low and high grasping torque range
during lift and pick-and-place tasks with objects of different stiffness.
Subjective evaluations further showed higher usability (SUS) and lower workload
(NASA--TLX). Overall, the results confirm that \textit{MR-UBi} enables more
stable, accurate, and user-friendly underwater robot-arm teleoperation through
the integration of visual and haptic feedback. For additional material, please
check: https://mertcookimg.github.io/mr-ubi

</details>


### [17] [Robot Path and Trajectory Planning Considering a Spatially Fixed TCP](https://arxiv.org/abs/2510.20473)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller,Ronald Naderer*

Main category: cs.RO

TL;DR: 提出了一种在工作空间坐标系中规划轨迹的方法，使用空间固定的工具中心点，同时考虑零件上的加工路径，特别适用于移动零件比移动工具更容易的场景。


<details>
  <summary>Details</summary>
Motivation: 当移动零件比移动工具更容易时，需要一种能够规划固定工具中心点轨迹的方法，同时考虑零件上的加工路径。

Method: 使用B样条表示机器人路径，无论使用数学形状描述还是设计程序中的单点，都能生成连续平滑的轨迹。在计算机器人轨迹时考虑规定的方向和TCP的给定速度。

Result: 该方法在真实系统上进行了验证，使用工业机器人移动任意定义的零件。

Conclusion: 该方法能够有效规划固定工具中心点的轨迹，生成连续平滑的机器人运动路径，适用于零件移动更便利的加工场景。

Abstract: This paper presents a method for planning a trajectory in workspace
coordinates using a spatially fixed tool center point (TCP), while taking into
account the processing path on a part. This approach is beneficial if it is
easier to move the part rather than moving the tool. Whether a mathematical
description that defines the shape to be processed or single points from a
design program are used, the robot path is finally represented using B-splines.
The use of splines enables the path to be continuous with a desired degree,
which finally leads to a smooth robot trajectory. While calculating the robot
trajectory through prescribed orientation, additionally a given velocity at the
TCP has to be considered. The procedure was validated on a real system using an
industrial robot moving an arbitrary defined part.

</details>


### [18] [Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization Leveraging LiDAR-Based Robot Detections](https://arxiv.org/abs/2510.20480)
*Václav Pritzl,Xianjia Yu,Tomi Westerlund,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种自适应多模态多机器人协同定位方法，使用因子图融合异步的视觉惯性里程计、激光雷达惯性里程计和3D机器人间检测，在传感器受限环境中显著提升定位精度。


<details>
  <summary>Details</summary>
Motivation: 解决在GNSS受限环境中，单个机器人携带所有传感器会增加尺寸、重量和功耗的问题。通过将传感器分布在多个机器人上增强部署性，但需要处理来自独立移动平台的异步多模态数据融合挑战。

Method: 使用因子图公式松散耦合地融合异步VIO、LIO和3D机器人间检测。提出基于插值的因子融合未同步测量，通过近似扫描匹配Hessian评估LIO退化，并基于连续VIO输出之间的Wasserstein距离对里程计数据进行加权。

Result: 在真实世界数据上广泛评估，使用异构UGV和UAV团队，显示该方法在各种传感器退化情况下显著提高了定位精度。

Conclusion: 该方法能够适应变化条件，利用可靠数据辅助受传感器退化影响的机器人，在多机器人系统中有效提升了长期定位性能。

Abstract: Accurate long-term localization using onboard sensors is crucial for robots
operating in Global Navigation Satellite System (GNSS)-denied environments.
While complementary sensors mitigate individual degradations, carrying all the
available sensor types on a single robot significantly increases the size,
weight, and power demands. Distributing sensors across multiple robots enhances
the deployability but introduces challenges in fusing asynchronous, multi-modal
data from independently moving platforms. We propose a novel adaptive
multi-modal multi-robot cooperative localization approach using a factor-graph
formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial
Odometry (LIO), and 3D inter-robot detections from distinct robots in a
loosely-coupled fashion. The approach adapts to changing conditions, leveraging
reliable data to assist robots affected by sensory degradations. A novel
interpolation-based factor enables fusion of the unsynchronized measurements.
LIO degradations are evaluated based on the approximate scan-matching Hessian.
A novel approach of weighting odometry data proportionally to the Wasserstein
distance between the consecutive VIO outputs is proposed. A theoretical
analysis is provided, investigating the cooperative localization problem under
various conditions, mainly in the presence of sensory degradations. The
proposed method has been extensively evaluated on real-world data gathered with
heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial
Vehicles (UAVs), showing that the approach provides significant improvements in
localization accuracy in the presence of various sensory degradations.

</details>


### [19] [Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty](https://arxiv.org/abs/2510.20483)
*Victor Vantilborgh,Hrishikesh Sathyanarayan,Guillaume Crevecoeur,Ian Abraham,Tom Lefebvre*

Main category: cs.RO

TL;DR: 提出两种方法解决机器人操作任务中的未知动力学问题，通过主动探索和在线参数适应来提高基于模型的控制精度。


<details>
  <summary>Details</summary>
Motivation: 解决在未知动力学（如负载不确定性）下机器人操作任务的问题，需要主动探索和在线参数适应来实现精确的基于模型控制。

Method: 将问题构建为双控制问题，预定义包含显式适应机制的反馈策略结构。提出两种参考轨迹生成方法：一种在鲁棒最优控制中嵌入参数不确定性，另一种最小化最优性损失。

Result: 两种方法都自然地考虑了Fisher信息，同时追求最优任务执行。在拾取-放置任务中展示了方法的有效性，实现了更快、更准确的任务性能和系统辨识。

Conclusion: 设计参考轨迹时考虑控制因素能够实现更快、更准确的任务性能和系统辨识，同时确保稳定高效的控制。

Abstract: This work addresses the problem of robot manipulation tasks under unknown
dynamics, such as pick-and-place tasks under payload uncertainty, where active
exploration and(/for) online parameter adaptation during task execution are
essential to enable accurate model-based control. The problem is framed as dual
control seeking a closed-loop optimal control problem that accounts for
parameter uncertainty. We simplify the dual control problem by pre-defining the
structure of the feedback policy to include an explicit adaptation mechanism.
Then we propose two methods for reference trajectory generation. The first
directly embeds parameter uncertainty in robust optimal control methods that
minimize the expected task cost. The second method considers minimizing the
so-called optimality loss, which measures the sensitivity of parameter-relevant
information with respect to task performance. We observe that both approaches
reason over the Fisher information as a natural side effect of their
formulations, simultaneously pursuing optimal task execution. We demonstrate
the effectiveness of our approaches for a pick-and-place manipulation task. We
show that designing the reference trajectories whilst taking into account the
control enables faster and more accurate task performance and system
identification while ensuring stable and efficient control.

</details>


### [20] [Simultaneous Stiffness and Trajectory Optimization for Energy Minimization of Pick-and-Place Tasks of SEA-Actuated Parallel Kinematic Manipulators](https://arxiv.org/abs/2510.20490)
*Thomas Kordik,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 提出了一种通过优化轨迹和串联弹性驱动器刚度来最小化并联机械臂拾放任务能耗的方法，利用弹性元件的固有振动特性来减少能量消耗。


<details>
  <summary>Details</summary>
Motivation: 工业机器人的拾放操作通常需要长时间运行，能耗最小化具有重要意义。串联弹性驱动器(SEA)的弹性元件可以激发固有运动，利用其振荡特性来降低能耗。

Method: 推导了SEA驱动并联机械臂的动态模型，制定了能量最小化的最优控制问题，同时优化操作轨迹和SEA刚度，并在两个并联机器人应用上进行测试。

Result: 实验结果验证了该方法的有效性，通过优化轨迹和刚度能够显著降低拾放任务的能量消耗。

Conclusion: 该方法为SEA驱动并联机械臂的节能设计提供了有效工具，通过同时优化轨迹和弹性元件刚度可以实现显著的能耗降低。

Abstract: A major field of industrial robot applications deals with repetitive tasks
that alternate between operating points. For these so-called pick-and-place
operations, parallel kinematic manipulators (PKM) are frequently employed.
These tasks tend to automatically run for a long period of time and therefore
minimizing energy consumption is always of interest. Recent research addresses
this topic by the use of elastic elements and particularly series elastic
actuators (SEA). This paper explores the possibilities of minimizing energy
consumption of SEA actuated PKM performing pick-and-place tasks. The basic idea
is to excite eigenmotions that result from the actuator springs and exploit
their oscillating characteristics. To this end, a prescribed cyclic
pick-and-place operation is analyzed and a dynamic model of SEA driven PKM is
derived. Subsequently, an energy minimizing optimal control problem is
formulated where operating trajectories as well as SEA stiffnesses are
optimized simultaneously. Here, optimizing the actuator stiffness does not
account for variable stiffness actuators. It serves as a tool for the design
and dimensioning process. The hypothesis on energy reduction is tested on two
(parallel) robot applications where redundant actuation is also addressed. The
results confirm the validity of this approach.

</details>


### [21] [A Parameter-Linear Formulation of the Optimal Path Following Problem for Robotic Manipulator](https://arxiv.org/abs/2510.20496)
*Tobias Marauli,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文提出了一种新的时间最优路径跟踪方法，通过最大化路径速度而非最小化旅行时间，避免了零路径速度时的奇异性问题，实现了平滑轨迹生成和高效数值计算。


<details>
  <summary>Details</summary>
Motivation: 传统时间最优路径跟踪方法在最小化旅行时间时，会在零路径速度处产生奇异性问题，这给平滑轨迹生成和计算效率带来了挑战。

Method: 采用最大化路径速度的方法替代传统的最小化旅行时间方法，将底层问题离散化后，优化变量呈线性关系。

Result: 该方法能够有效避免奇异性问题，实现平滑轨迹规划，并保持较低的计算复杂度。

Conclusion: 基于最大化路径速度的新方法为解决时间最优路径跟踪中的计算挑战提供了一种有效的替代方案，具有数值高效性和平滑轨迹生成能力。

Abstract: In this paper the computational challenges of time-optimal path following are
addressed. The standard approach is to minimize the travel time, which
inevitably leads to singularities at zero path speed, when reformulating the
optimization problem in terms of a path parameter. Thus, smooth trajectory
generation while maintaining a low computational effort is quite challenging,
since the singularities have to be taken into account. To this end, a different
approach is presented in this paper. This approach is based on maximizing the
path speed along a prescribed path. Furthermore, the approach is capable of
planning smooth trajectories numerically efficient. Moreover, the discrete
reformulation of the underlying problem is linear in optimization variables.

</details>


### [22] [RubbleSim: A Photorealistic Structural Collapse Simulator for Confined Space Mapping](https://arxiv.org/abs/2510.20529)
*Constantine Frost,Chad Council,Margaret McGuinness,Nathaniel Hanson*

Main category: cs.RO

TL;DR: 提出了RubbleSim——一个开源、可重构的模拟器，用于在灾难响应中模拟结构坍塌内部空隙的光真实感探索。


<details>
  <summary>Details</summary>
Motivation: 由于法律限制和机构所有权问题，真实灾难响应中的数据难以获取，而训练用的工程废墟堆也不愿公开其专有训练场信息。

Method: 使用Unity开发的多操作系统模拟器，采用基于物理的方法构建随机废墟堆，允许在保留地面真实性的情况下快速迭代模拟世界。

Result: 应用最先进的结构运动算法，展示了在模拟空隙内部挑战性视觉条件下感知性能的退化情况。

Conclusion: RubbleSim为灾难响应研究提供了一个可访问的模拟平台，克服了真实数据获取的障碍。

Abstract: Despite well-reported instances of robots being used in disaster response,
there is scant published data on the internal composition of the void spaces
within structural collapse incidents. Data collected during these incidents is
mired in legal constraints, as ownership is often tied to the responding
agencies, with little hope of public release for research. While engineered
rubble piles are used for training, these sites are also reluctant to release
information about their proprietary training grounds. To overcome this access
challenge, we present RubbleSim -- an open-source, reconfigurable simulator for
photorealistic void space exploration. The design of the simulation assets is
directly informed by visits to numerous training rubble sites at differing
levels of complexity. The simulator is implemented in Unity with
multi-operating system support. The simulation uses a physics-based approach to
build stochastic rubble piles, allowing for rapid iteration between simulation
worlds while retaining absolute knowledge of the ground truth. Using RubbleSim,
we apply a state-of-the-art structure-from-motion algorithm to illustrate how
perception performance degrades under challenging visual conditions inside the
emulated void spaces. Pre-built binaries and source code to implement are
available online: https://github.com/mit-ll/rubble_pile_simulator.

</details>


### [23] [C-NAV: Towards Self-Evolving Continual Object Navigation in Open World](https://arxiv.org/abs/2510.20685)
*Ming-Ming Yu,Fei Zhu,Wenzhuo Liu,Yirong Yang,Qunbo Wang,Wenjun Wu,Jing Liu*

Main category: cs.RO

TL;DR: 提出了C-Nav持续视觉导航框架，通过双路径抗遗忘机制和自适应采样策略解决动态开放世界中的物体导航问题，在避免灾难性遗忘的同时显著降低内存需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态轨迹和固定物体类别训练，忽略了现实世界需要持续适应变化场景的需求，因此需要开发能够持续学习新物体类别导航技能而不遗忘旧知识的算法。

Method: C-Nav框架包含：1）双路径抗遗忘机制（特征蒸馏确保表征一致性，特征重放确保策略一致性）；2）自适应采样策略选择多样且信息丰富的经验以减少冗余和内存开销。

Result: 在多种模型架构上的广泛实验表明，C-Nav始终优于现有方法，即使与保留完整轨迹的基线相比也能实现更优性能，同时显著降低内存需求。

Conclusion: C-Nav为解决持续物体导航问题提供了有效解决方案，在性能和内存效率方面均表现出色，代码将公开可用。

Abstract: Embodied agents are expected to perform object navigation in dynamic,
open-world environments. However, existing approaches typically rely on static
trajectories and a fixed set of object categories during training, overlooking
the real-world requirement for continual adaptation to evolving scenarios. To
facilitate related studies, we introduce the continual object navigation
benchmark, which requires agents to acquire navigation skills for new object
categories while avoiding catastrophic forgetting of previously learned
knowledge. To tackle this challenge, we propose C-Nav, a continual visual
navigation framework that integrates two key innovations: (1) A dual-path
anti-forgetting mechanism, which comprises feature distillation that aligns
multi-modal inputs into a consistent representation space to ensure
representation consistency, and feature replay that retains temporal features
within the action decoder to ensure policy consistency. (2) An adaptive
sampling strategy that selects diverse and informative experiences, thereby
reducing redundancy and minimizing memory overhead. Extensive experiments
across multiple model architectures demonstrate that C-Nav consistently
outperforms existing approaches, achieving superior performance even compared
to baselines with full trajectory retention, while significantly lowering
memory requirements. The code will be publicly available at
https://bigtree765.github.io/C-Nav-project.

</details>


### [24] [Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning](https://arxiv.org/abs/2510.20706)
*Ganga Nair B,Prakrut Kotecha,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 提出结合MPPI和Dreamer模块的优化框架，在连续步态空间中实现四足机器人实时步态自适应，显著降低能耗并保持精确跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决模型无关强化学习中策略收敛到单一步态导致性能不佳的问题，以及传统MPC无法适应多变环境的局限性。

Method: 将模型预测路径积分(MPPI)算法与Dreamer模块结合，在每个时间步联合优化动作和步态变量，使用学习的Dreamer奖励函数和值函数。

Result: 在Unitree Go1仿真中，不同目标速度下能耗平均降低36.48%，同时保持精确跟踪和自适应任务适当步态。

Conclusion: 该框架成功实现了四足机器人的自适应和最优步态控制，在能耗和跟踪性能方面均有显著提升。

Abstract: Model-free reinforcement learning (RL) has enabled adaptable and agile
quadruped locomotion; however, policies often converge to a single gait,
leading to suboptimal performance. Traditionally, Model Predictive Control
(MPC) has been extensively used to obtain task-specific optimal policies but
lacks the ability to adapt to varying environments. To address these
limitations, we propose an optimization framework for real-time gait adaptation
in a continuous gait space, combining the Model Predictive Path Integral (MPPI)
algorithm with a Dreamer module to produce adaptive and optimal policies for
quadruped locomotion. At each time step, MPPI jointly optimizes the actions and
gait variables using a learned Dreamer reward that promotes velocity tracking,
energy efficiency, stability, and smooth transitions, while penalizing abrupt
gait changes. A learned value function is incorporated as terminal reward,
extending the formulation to an infinite-horizon planner. We evaluate our
framework in simulation on the Unitree Go1, demonstrating an average reduction
of up to 36.48\% in energy consumption across varying target speeds, while
maintaining accurate tracking and adaptive, task-appropriate gaits.

</details>


### [25] [FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation](https://arxiv.org/abs/2510.20774)
*Wenhao Wang,Kehe Ye,Xinyu Zhou,Tianxing Chen,Cao Min,Qiaoming Zhu,Xiaokang Yang,Yongjian Shen,Yang Yang,Maoqing Yao,Yao Mu*

Main category: cs.RO

TL;DR: FieldGen是一个场引导的数据生成框架，通过分解操作为预操作和精细操作两个阶段，结合人类演示的关键信息和自动生成的多样化轨迹，实现大规模、多样化且高质量的真实世界数据收集。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作数据收集方法难以平衡规模、多样性和质量。仿真方法可扩展但存在仿真到现实的差距，遥操作能获得高质量演示但多样性有限且人力成本高。

Method: 将操作分解为预操作阶段（允许轨迹多样性）和精细操作阶段（需要专家精度）。人类演示捕捉关键接触和姿态信息，然后通过吸引场自动生成收敛到成功配置的多样化轨迹。

Result: 使用FieldGen训练的策略相比基于遥操作的基线方法实现了更高的成功率和改进的稳定性，同时显著减少了长期真实世界数据收集的人力投入。

Conclusion: FieldGen通过解耦设计结合了可扩展的轨迹多样性和精确监督，为机器人操作提供了高效的数据收集解决方案。

Abstract: Large-scale and diverse datasets are vital for training robust robotic
manipulation policies, yet existing data collection methods struggle to balance
scale, diversity, and quality. Simulation offers scalability but suffers from
sim-to-real gaps, while teleoperation yields high-quality demonstrations with
limited diversity and high labor cost. We introduce FieldGen, a field-guided
data generation framework that enables scalable, diverse, and high-quality
real-world data collection with minimal human supervision. FieldGen decomposes
manipulation into two stages: a pre-manipulation phase, allowing trajectory
diversity, and a fine manipulation phase requiring expert precision. Human
demonstrations capture key contact and pose information, after which an
attraction field automatically generates diverse trajectories converging to
successful configurations. This decoupled design combines scalable trajectory
diversity with precise supervision. Moreover, FieldGen-Reward augments
generated data with reward annotations to further enhance policy learning.
Experiments demonstrate that policies trained with FieldGen achieve higher
success rates and improved stability compared to teleoperation-based baselines,
while significantly reducing human effort in long-term real-world data
collection. Webpage is available at https://fieldgen.github.io/.

</details>


### [26] [The Reality Gap in Robotics: Challenges, Solutions, and Best Practices](https://arxiv.org/abs/2510.20808)
*Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos*

Main category: cs.RO

TL;DR: 这篇论文是关于机器人学中模拟到现实迁移的综述，探讨了模拟与现实环境之间的差异（现实差距）及其解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器学习在机器人领域的进步很大程度上依赖于模拟环境进行训练和测试，但模拟与现实环境之间存在差异（现实差距），这阻碍了系统从模拟到现实世界的成功迁移。

Method: 通过领域随机化、现实到模拟迁移、状态和动作抽象、模拟-现实协同训练等技术来克服现实差距。

Result: 最近的研究在运动、导航和操作等各种平台上展示了有前景的结果，但挑战仍然存在。

Conclusion: 需要更深入地理解现实差距的根本原因和解决方案，本文提供了关于模拟到现实迁移的全面概述，包括原因、解决方案和评估指标。

Abstract: Machine learning has facilitated significant advancements across various
robotics domains, including navigation, locomotion, and manipulation. Many such
achievements have been driven by the extensive use of simulation as a critical
tool for training and testing robotic systems prior to their deployment in
real-world environments. However, simulations consist of abstractions and
approximations that inevitably introduce discrepancies between simulated and
real environments, known as the reality gap. These discrepancies significantly
hinder the successful transfer of systems from simulation to the real world.
Closing this gap remains one of the most pressing challenges in robotics.
Recent advances in sim-to-real transfer have demonstrated promising results
across various platforms, including locomotion, navigation, and manipulation.
By leveraging techniques such as domain randomization, real-to-sim transfer,
state and action abstractions, and sim-real co-training, many works have
overcome the reality gap. However, challenges persist, and a deeper
understanding of the reality gap's root causes and solutions is necessary. In
this survey, we present a comprehensive overview of the sim-to-real landscape,
highlighting the causes, solutions, and evaluation metrics for the reality gap
and sim-to-real transfer.

</details>


### [27] [GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation](https://arxiv.org/abs/2510.20813)
*Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: GSWorld是一个结合3D高斯泼溅和物理引擎的机器人操作模拟器，支持从真实机器人数据学习策略的可重复评估和无需真实机器人的sim2real策略训练。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够"闭环"开发机器人操作策略的模拟器，实现从真实机器人数据学习策略的可重复评估，以及无需真实机器人的sim2real策略训练。

Method: 提出GSDF（高斯场景描述文件）资产格式，将高斯网格表示与机器人URDF和其他对象融合，结合物理引擎构建照片级真实的模拟环境。

Result: 构建了包含3种机器人配置和40多个对象的GSDF数据库，展示了五个应用：零样本sim2real像素到动作策略学习、自动化高质量DAgger数据收集、可重复基准测试、虚拟遥操作数据收集和零样本sim2real视觉强化学习。

Conclusion: GSWorld提供了一个强大的照片级真实机器人操作模拟平台，支持多种机器人学习应用，为机器人操作策略的开发提供了闭环解决方案。

Abstract: This paper presents GSWorld, a robust, photo-realistic simulator for robotics
manipulation that combines 3D Gaussian Splatting with physics engines. Our
framework advocates "closing the loop" of developing manipulation policies with
reproducible evaluation of policies learned from real-robot data and sim2real
policy training without using real robots. To enable photo-realistic rendering
of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian
Scene Description File), that infuses Gaussian-on-Mesh representation with
robot URDF and other objects. With a streamlined reconstruction pipeline, we
curate a database of GSDF that contains 3 robot embodiments for single-arm and
bimanual manipulation, as well as more than 40 objects. Combining GSDF with
physics engines, we demonstrate several immediate interesting applications: (1)
learning zero-shot sim2real pixel-to-action manipulation policy with
photo-realistic rendering, (2) automated high-quality DAgger data collection
for adapting policies to deployment environments, (3) reproducible benchmarking
of real-robot manipulation policies in simulation, (4) simulation data
collection by virtual teleoperation, and (5) zero-shot sim2real visual
reinforcement learning. Website: https://3dgsworld.github.io/.

</details>


### [28] [VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation](https://arxiv.org/abs/2510.20818)
*Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta*

Main category: cs.RO

TL;DR: VAMOS是一个分层视觉语言导航系统，通过分离语义规划和具身接地，使用通用规划器处理开放世界数据，专用可操作性模型学习机器人物理约束，在真实环境中实现了比现有方法更高的导航成功率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人导航中学习跨环境通用策略与适应特定机器人物理约束之间的根本挑战，如四足机器人能上楼梯而轮式机器人不能。

Method: 设计分层架构：高层规划器从多样化开放世界数据学习语义规划，专用可操作性模型在低成本仿真中学习机器人物理能力；通过图像空间路径提案和可操作性评估重新排序实现解耦。

Result: 在室内和复杂室外导航中比最先进的模型方法和端到端学习方法获得更高成功率；支持轮式和腿式机器人的跨具身导航；通过拒绝物理不可行计划使单机器人可靠性提高3倍。

Conclusion: 分层设计是实现跨具身导航的关键，专用模型对具身接地至关重要，使单一高层规划器能够部署到物理特性不同的机器人上，显著提升导航可靠性。

Abstract: A fundamental challenge in robot navigation lies in learning policies that
generalize across diverse environments while conforming to the unique physical
constraints and capabilities of a specific embodiment (e.g., quadrupeds can
walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that
decouples semantic planning from embodiment grounding: a generalist planner
learns from diverse, open-world data, while a specialist affordance model
learns the robot's physical constraints and capabilities in safe, low-cost
simulation. We enabled this separation by carefully designing an interface that
lets a high-level planner propose candidate paths directly in image space that
the affordance model then evaluates and re-ranks. Our real-world experiments
show that VAMOS achieves higher success rates in both indoor and complex
outdoor navigation than state-of-the-art model-based and end-to-end learning
methods. We also show that our hierarchical design enables cross-embodied
navigation across legged and wheeled robots and is easily steerable using
natural language. Real-world ablations confirm that the specialist model is key
to embodiment grounding, enabling a single high-level planner to be deployed
across physically distinct wheeled and legged robots. Finally, this model
significantly enhances single-robot reliability, achieving 3X higher success
rates by rejecting physically infeasible plans. Website:
https://vamos-vla.github.io/

</details>
