<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 26]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling](https://arxiv.org/abs/2511.04758)
*Caelan Garrett,Fabio Ramos*

Main category: cs.RO

TL;DR: 提出了ScheduleStream框架，首个用于规划与调度的通用框架，支持采样操作，能够为双机械臂和人形机器人生成并行运动调度，而非传统的顺序规划。


<details>
  <summary>Details</summary>
Motivation: 双机械臂和人形机器人需要多臂协同完成任务，但传统任务与运动规划(TAMP)算法只能生成顺序执行计划，无法实现并行运动，限制了效率。

Method: 使用混合持续动作建模时间动态，支持异步启动和参数化持续时间，提出领域无关算法解决ScheduleStream问题，在TAMPAS中利用GPU加速采样器加快规划速度。

Result: 与多个消融实验相比，ScheduleStream算法能生成更高效的解决方案，并在真实世界双机械臂任务中进行了演示验证。

Conclusion: ScheduleStream成功扩展了TAMP框架，能够为多臂机器人系统生成并行运动调度，显著提高了任务执行效率。

Abstract: Bimanual and humanoid robots are appealing because of their human-like
ability to leverage multiple arms to efficiently complete tasks. However,
controlling multiple arms at once is computationally challenging due to the
growth in the hybrid discrete-continuous action space. Task and Motion Planning
(TAMP) algorithms can efficiently plan in hybrid spaces but generally produce
plans, where only one arm is moving at a time, rather than schedules that allow
for parallel arm motion. In order to extend TAMP to produce schedules, we
present ScheduleStream, the first general-purpose framework for planning &
scheduling with sampling operations. ScheduleStream models temporal dynamics
using hybrid durative actions, which can be started asynchronously and persist
for a duration that's a function of their parameters. We propose
domain-independent algorithms that solve ScheduleStream problems without any
application-specific mechanisms. We apply ScheduleStream to Task and Motion
Planning & Scheduling (TAMPAS), where we use GPU acceleration within samplers
to expedite planning. We compare ScheduleStream algorithms to several ablations
in simulation and find that they produce more efficient solutions. We
demonstrate ScheduleStream on several real-world bimanual robot tasks at
https://schedulestream.github.io.

</details>


### [2] [ReGen: Generative Robot Simulation via Inverse Design](https://arxiv.org/abs/2511.04769)
*Phat Nguyen,Tsun-Hsuan Wang,Zhang-Wei Hong,Erfan Aasi,Andrew Silva,Guy Rosman,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: ReGen是一个生成式仿真框架，通过逆向设计自动化仿真构建过程。给定机器人的行为轨迹或目标函数及其文本描述，ReGen能够推断出可能导致该行为的合理场景和环境。


<details>
  <summary>Details</summary>
Motivation: 传统仿真构建过程劳动密集，限制了机器人学习的扩展性和策略验证。需要自动化方法来生成多样化的仿真环境，以增强机器人策略的泛化能力和鲁棒性。

Method: 利用大语言模型通过扩展编码因果关系的定向图来合成场景，然后将结构化图转换为符号程序，配置和执行机器人仿真环境。支持基于自我行为增强仿真、可控反事实场景生成、推理代理认知和不同感知模态。

Result: 在自动驾驶和机器人操作任务中，ReGen相比现有仿真方法生成了更多样化、复杂的仿真环境，具有高成功率，并能可控地生成极端情况。

Conclusion: ReGen通过自动化仿真设计增强了机器人策略验证，支持数据和仿真增强，推动了可扩展的机器人学习，以改善泛化性和鲁棒性。

Abstract: Simulation plays a key role in scaling robot learning and validating
policies, but constructing simulations remains a labor-intensive process. This
paper introduces ReGen, a generative simulation framework that automates
simulation design via inverse design. Given a robot's behavior -- such as a
motion trajectory or an objective function -- and its textual description,
ReGen infers plausible scenarios and environments that could have caused the
behavior. ReGen leverages large language models to synthesize scenarios by
expanding a directed graph that encodes cause-and-effect relationships,
relevant entities, and their properties. This structured graph is then
translated into a symbolic program, which configures and executes a robot
simulation environment. Our framework supports (i) augmenting simulations based
on ego-agent behaviors, (ii) controllable, counterfactual scenario generation,
(iii) reasoning about agent cognition and mental states, and (iv) reasoning
with distinct sensing modalities, such as braking due to faulty GPS signals. We
demonstrate ReGen in autonomous driving and robot manipulation tasks,
generating more diverse, complex simulated environments compared to existing
simulations with high success rates, and enabling controllable generation for
corner cases. This approach enhances the validation of robot policies and
supports data or simulation augmentation, advancing scalable robot learning for
improved generalization and robustness. We provide code and example videos at:
https://regen-sim.github.io/

</details>


### [3] [Unified Multimodal Diffusion Forcing for Forceful Manipulation](https://arxiv.org/abs/2511.04812)
*Zixuan Huang,Huaidian Hou,Dmitry Berenson*

Main category: cs.RO

TL;DR: 提出了多模态扩散强制(MDF)框架，通过随机部分掩码和扩散模型重建轨迹来学习多模态机器人轨迹中的时空和跨模态依赖关系。


<details>
  <summary>Details</summary>
Motivation: 标准模仿学习方法通常只学习从观察到动作的直接映射，忽略了不同模态（感官输入、动作、奖励）之间的丰富交互，而这些交互对于建模机器人行为和理解任务结果至关重要。

Method: MDF采用随机部分掩码策略，训练扩散模型来重建轨迹，而不是建模固定分布。这种训练目标鼓励模型学习时空和跨模态依赖关系，如预测动作对力信号的影响或从部分观察推断状态。

Result: 在模拟和真实环境的接触丰富、强力操作任务中，MDF不仅提供了多功能性，还实现了强大的性能和噪声观察下的鲁棒性。

Conclusion: MDF是一个统一的多模态机器人轨迹学习框架，能够有效学习跨模态依赖关系，在复杂操作任务中表现出色。

Abstract: Given a dataset of expert trajectories, standard imitation learning
approaches typically learn a direct mapping from observations (e.g., RGB
images) to actions. However, such methods often overlook the rich interplay
between different modalities, i.e., sensory inputs, actions, and rewards, which
is crucial for modeling robot behavior and understanding task outcomes. In this
work, we propose Multimodal Diffusion Forcing, a unified framework for learning
from multimodal robot trajectories that extends beyond action generation.
Rather than modeling a fixed distribution, MDF applies random partial masking
and trains a diffusion model to reconstruct the trajectory. This training
objective encourages the model to learn temporal and cross-modal dependencies,
such as predicting the effects of actions on force signals or inferring states
from partial observations. We evaluate MDF on contact-rich, forceful
manipulation tasks in simulated and real-world environments. Our results show
that MDF not only delivers versatile functionalities, but also achieves strong
performance, and robustness under noisy observations. More visualizations can
be found on our website https://unified-df.github.io

</details>


### [4] [Pixi: Unified Software Development and Distribution for Robotics and AI](https://arxiv.org/abs/2511.04827)
*Tobias Fischer,Wolf Vollprecht,Bas Zalmstra,Ruben Arts,Tim de Jager,Alejandro Fontan,Adam D Hines,Michael Milford,Silvio Traversaro,Daniel Claes,Scarlett Raine*

Main category: cs.RO

TL;DR: Pixi是一个统一的包管理框架，通过项目级锁文件确保跨平台的比特级可复现性，解决了机器人学研究中的可复现性危机。


<details>
  <summary>Details</summary>
Motivation: 科学计算中的可复现性危机限制了机器人学研究，高达70%的机器人算法无法被独立团队复现，且创建可共享的软件环境过于复杂。

Method: Pixi使用高性能SAT求解器进行依赖解析（比同类工具快10倍），整合conda-forge和PyPI生态系统，通过项目级锁文件捕获精确依赖状态。

Result: 自2023年以来已在5,300多个项目中采用，将设置时间从数小时缩短至数分钟，降低了全球研究者的技术门槛。

Conclusion: Pixi通过实现可扩展、可复现的协作研究基础设施，加速了机器人和AI领域的进展。

Abstract: The reproducibility crisis in scientific computing constrains robotics
research. Existing studies reveal that up to 70% of robotics algorithms cannot
be reproduced by independent teams, while many others fail to reach deployment
because creating shareable software environments remains prohibitively complex.
These challenges stem from fragmented, multi-language, and hardware-software
toolchains that lead to dependency hell. We present Pixi, a unified
package-management framework that addresses these issues by capturing exact
dependency states in project-level lockfiles, ensuring bit-for-bit
reproducibility across platforms. Its high-performance SAT solver achieves up
to 10x faster dependency resolution than comparable tools, while integration of
the conda-forge and PyPI ecosystems removes the need for multiple managers.
Adopted in over 5,300 projects since 2023, Pixi reduces setup times from hours
to minutes and lowers technical barriers for researchers worldwide. By enabling
scalable, reproducible, collaborative research infrastructure, Pixi accelerates
progress in robotics and AI.

</details>


### [5] [Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning](https://arxiv.org/abs/2511.04831)
*NVIDIA,:,Mayank Mittal,Pascal Roth,James Tigue,Antoine Richard,Octi Zhang,Peter Du,Antonio Serrano-Muñoz,Xinjie Yao,René Zurbrügg,Nikita Rudin,Lukasz Wawrzyniak,Milad Rakhsha,Alain Denzler,Eric Heiden,Ales Borovicka,Ossama Ahmed,Iretiayo Akinola,Abrar Anwar,Mark T. Carlson,Ji Yuan Feng,Animesh Garg,Renato Gasoto,Lionel Gulich,Yijie Guo,M. Gussert,Alex Hansen,Mihir Kulkarni,Chenran Li,Wei Liu,Viktor Makoviychuk,Grzegorz Malczyk,Hammad Mazhar,Masoud Moghani,Adithyavairavan Murali,Michael Noseworthy,Alexander Poddubny,Nathan Ratliff,Welf Rehberg,Clemens Schwarke,Ritvik Singh,James Latham Smith,Bingjie Tang,Ruchik Thaker,Matthew Trepte,Karl Van Wyk,Fangzhou Yu,Alex Millane,Vikram Ramasamy,Remo Steiner,Sangeeta Subramanian,Clemens Volk,CY Chen,Neel Jawale,Ashwin Varghese Kuruttukulam,Michael A. Lin,Ajay Mandlekar,Karsten Patzwaldt,John Welsh,Huihua Zhao,Fatima Anes,Jean-Francois Lafleche,Nicolas Moënne-Loccoz,Soowan Park,Rob Stepinski,Dirk Van Gelder,Chris Amevor,Jan Carius,Jumyung Chang,Anka He Chen,Pablo de Heras Ciechomski,Gilles Daviet,Mohammad Mohajerani,Julia von Muralt,Viktor Reutskyy,Michael Sauter,Simon Schirm,Eric L. Shi,Pierre Terdiman,Kenny Vilella,Tobias Widmer,Gordon Yeoman,Tiffany Chen,Sergey Grizan,Cathy Li,Lotus Li,Connor Smith,Rafael Wiltz,Kostas Alexis,Yan Chang,David Chu,Linxi "Jim" Fan,Farbod Farshidian,Ankur Handa,Spencer Huang,Marco Hutter,Yashraj Narang,Soha Pouya,Shiwei Sheng,Yuke Zhu,Miles Macklin,Adam Moravanszky,Philipp Reist,Yunrong Guo,David Hoeller,Gavriel State*

Main category: cs.RO

TL;DR: Isaac Lab是Isaac Gym的继任者，提供GPU原生机器人仿真平台，支持大规模多模态学习，集成了高保真物理引擎、渲染、传感器模拟和数据收集等功能。


<details>
  <summary>Details</summary>
Motivation: 将GPU原生机器人仿真扩展到大规模多模态学习时代，为强化学习和模仿学习提供统一的、可扩展的平台。

Method: 结合GPU并行物理引擎、照片级渲染、模块化架构，集成执行器模型、多频传感器仿真、数据收集管道和领域随机化工具。

Result: 成功应用于全身控制、跨体现移动、接触丰富和灵巧操作等多样化挑战，并整合人类演示进行技能获取。

Conclusion: Isaac Lab的先进仿真能力、丰富感知和数据中心级执行将推动机器人研究的下一代突破，未来将集成可微分物理引擎以支持梯度学习方法。

Abstract: We present Isaac Lab, the natural successor to Isaac Gym, which extends the
paradigm of GPU-native robotics simulation into the era of large-scale
multi-modal learning. Isaac Lab combines high-fidelity GPU parallel physics,
photorealistic rendering, and a modular, composable architecture for designing
environments and training robot policies. Beyond physics and rendering, the
framework integrates actuator models, multi-frequency sensor simulation, data
collection pipelines, and domain randomization tools, unifying best practices
for reinforcement and imitation learning at scale within a single extensible
platform. We highlight its application to a diverse set of challenges,
including whole-body control, cross-embodiment mobility, contact-rich and
dexterous manipulation, and the integration of human demonstrations for skill
acquisition. Finally, we discuss upcoming integration with the differentiable,
GPU-accelerated Newton physics engine, which promises new opportunities for
scalable, data-efficient, and gradient-based approaches to robot learning. We
believe Isaac Lab's combination of advanced simulation capabilities, rich
sensing, and data-center scale execution will help unlock the next generation
of breakthroughs in robotics research.

</details>


### [6] [Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning](https://arxiv.org/abs/2511.04835)
*Shubham Natraj,Bruno Sinopoli,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 提出一种基于认证区域的非均匀采样策略，通过结合启发式路径预测器和保形预测来量化不确定性，为SBMPs提供概率正确的采样区域保证，显著提高规划效率。


<details>
  <summary>Details</summary>
Motivation: 传统的基于采样的运动规划器依赖均匀采样，在复杂环境中效率低下且规划缓慢，需要一种能够提供概率保证的高效采样方法。

Method: 使用启发式路径预测器生成初始路径，应用保形预测量化预测器的不确定性，构建围绕初始路径的认证区域，并偏向这些区域进行非均匀采样。

Result: 在广泛评估中，该方法比现有基线方法更快找到可行路径，并且在未见环境中具有更好的泛化能力。

Conclusion: 这是首个为SBMPs提供概率正确采样区域保证的非均匀采样方法，显著提升了运动规划的效率。

Abstract: Sampling-based motion planners (SBMPs) are widely used to compute dynamically
feasible robot paths. However, their reliance on uniform sampling often leads
to poor efficiency and slow planning in complex environments. We introduce a
novel non-uniform sampling strategy that integrates into existing SBMPs by
biasing sampling toward `certified' regions. These regions are constructed by
(i) generating an initial, possibly infeasible, path using any heuristic path
predictor (e.g., A* or vision-language models) and (ii) applying conformal
prediction to quantify the predictor's uncertainty. This process yields
prediction sets around the initial-guess path that are guaranteed, with
user-specified probability, to contain the optimal solution. To our knowledge,
this is the first non-uniform sampling approach for SBMPs that provides such
probabilistically correct guarantees on the sampling regions. Extensive
evaluations demonstrate that our method consistently finds feasible paths
faster and generalizes better to unseen environments than existing baselines.

</details>


### [7] [Design Exploration for Protection and Cleaning of Solar Panels with Case Studies for Space Missions](https://arxiv.org/abs/2511.04837)
*Cameron Robinson,Ganghee Jang*

Main category: cs.RO

TL;DR: 设计并测试了太阳能面板清洁机制和防护材料，以解决灰尘和太空碎片对太阳能系统的影响。


<details>
  <summary>Details</summary>
Motivation: 太阳能系统在关键任务中应用广泛，但面板被灰尘覆盖或被太空碎片击中会限制甚至终止其运行。

Method: 设计了两种清洁机制（雨刮系统和轨道系统）并进行比较；通过碰撞测试评估防护材料，重点关注软硬材料分层结构。

Result: 雨刮系统在成本、清洁速度和总功耗方面比轨道系统更高效；聚碳酸酯作为防护材料表现良好，软硬材料分层是关键因素。

Conclusion: 雨刮系统是更优的清洁解决方案，软硬材料分层结构能有效保护太阳能面板免受损坏。

Abstract: Solar energy is used for many mission-critical applications including space
exploration, sensor systems to monitor wildfires, etc. Their operation can be
limited or even terminated if solar panels are covered with dust or hit by
space debris. To address this issue, we designed panel cleaning mechanisms and
tested protective materials. For cleaning mechanisms, we designed and compared
a wiper system and a rail system. For protective materials, we found through
collision tests that polycarbonate was very promising, though the most
important factor was layering a soft material between the panel's surface and a
hard material. In the cleaning system comparisons, the wiper-based system was
more efficient than the rail-based system in terms of cost, cleaning speed, and
total power consumption.

</details>


### [8] [iFlyBot-VLM Technical Report](https://arxiv.org/abs/2511.04976)
*Xin Nie,Zhiyuan Cheng,Yuan Zhang,Chao Ji,Jiajia Wu,Yuhan Zhang,Jia Pan*

Main category: cs.RO

TL;DR: iFlyBot-VLM是一个通用视觉语言模型，旨在通过将复杂视觉空间信息抽象为与身体无关的可转移操作语言，来弥合环境感知与机器人运动控制之间的语义鸿沟，实现跨机器人平台的无缝感知-动作闭环协调。


<details>
  <summary>Details</summary>
Motivation: 弥合高维环境感知与低级机器人运动控制之间的跨模态语义鸿沟，推动从专用任务导向系统向通用认知智能体的发展。

Method: 系统设计架构实现四个关键功能：空间理解与度量推理、交互式目标定位、动作抽象与控制参数生成、任务规划与技能序列化。

Result: 在10个主流具身智能相关VLM基准数据集（如Blink和Where2Place）上取得最优性能，同时保持模型的通用能力。

Conclusion: iFlyBot-VLM作为具身AI的可扩展通用基础模型，将促进该领域的研究发展，作者将公开训练数据和模型权重。

Abstract: We introduce iFlyBot-VLM, a general-purpose Vision-Language Model (VLM) used
to improve the domain of Embodied Intelligence. The central objective of
iFlyBot-VLM is to bridge the cross-modal semantic gap between high-dimensional
environmental perception and low-level robotic motion control. To this end, the
model abstracts complex visual and spatial information into a body-agnostic and
transferable Operational Language, thereby enabling seamless perception-action
closed-loop coordination across diverse robotic platforms. The architecture of
iFlyBot-VLM is systematically designed to realize four key functional
capabilities essential for embodied intelligence: 1) Spatial Understanding and
Metric Reasoning; 2) Interactive Target Grounding; 3) Action Abstraction and
Control Parameter Generation; 4) Task Planning and Skill Sequencing. We
envision iFlyBot-VLM as a scalable and generalizable foundation model for
embodied AI, facilitating the progression from specialized task-oriented
systems toward generalist, cognitively capable agents. We conducted evaluations
on 10 current mainstream embodied intelligence-related VLM benchmark datasets,
such as Blink and Where2Place, and achieved optimal performance while
preserving the model's general capabilities. We will publicly release both the
training data and model weights to foster further research and development in
the field of Embodied Intelligence.

</details>


### [9] [A semi-analytical approach for computing the largest singularity-free spheres of a class of 6-6 Stewart-Gough platforms for specified orientation workspaces](https://arxiv.org/abs/2511.04992)
*Bibekananda Patra,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 提出了一种计算6-6 Stewart-Gough平台机械臂在指定方向工作空间内最大无奇异球体的方法，通过分析计算固定方向下的SFS，并在采样点中选取最小值作为整个工作空间的SFS。


<details>
  <summary>Details</summary>
Motivation: 研究6-6 Stewart-Gough平台机械臂在方向工作空间内的无奇异性能，为机械臂的分析和设计提供有效的计算工具。

Method: 对于固定的移动平台方向，解析计算SFS；在方向工作空间内生成采样点，重复此过程，选取最小的SFS作为整个工作空间的SFS。

Result: 在四种不同的SGPM架构上进行了数值实验，比较了它们在相同方向工作空间内SFS体积的相对性能。

Conclusion: 所提出的计算方法在SGPM的分析和设计中具有潜在的应用价值。

Abstract: This article presents a method for computing the largest singularity-free
sphere (SFS) of a 6-6 Stewart-Gough platform manipulator (SGPM) over a
specified orientation workspace. For a fixed orientation of the moving
platform, the SFS is computed analytically. This process is repeated over a set
of samples generated within the orientation workspace, and the smallest among
them is designated as the desired SFS for the given orientation workspace.
Numerical experiments are performed on four distinct architectures of the SGPM
to understand their relative performances w.r.t. SFS volumes over the same
orientation workspace. This study demonstrates the potential utility of the
proposed computational method both in analysis and design of SGPMs.

</details>


### [10] [Encoding Biomechanical Energy Margin into Passivity-based Synchronization for Networked Telerobotic Systems](https://arxiv.org/abs/2511.04994)
*Xingyuan Zhou,Peter Paik,S. Farokh Atashzar*

Main category: cs.RO

TL;DR: 提出了一种名为TBPS2的双端口生物力学感知的基于无源性的同步器和稳定器，用于网络化机器人系统中的位置同步和稳定性控制。


<details>
  <summary>Details</summary>
Motivation: 在网络化机器人系统中，特别是在触觉人机交互中，保持系统稳定性和准确的位置跟踪至关重要。由于不完美的通信和非被动行为导致的位置不同步仍然是一个挑战。

Method: 设计了一个双端口生物力学感知的基于无源性的同步器和稳定器（TBPS2），通过利用人体生物力学来优化位置同步，同时减少稳定器激活时的保守性。提供了数学设计综合和稳定性证明。

Result: 进行了一系列网格模拟和系统实验，在不同时间延迟和环境条件下与最先进解决方案进行了性能比较。

Conclusion: TBPS2稳定器能够有效解决位置不同步问题，在保持系统稳定性的同时提高位置同步性能。

Abstract: Maintaining system stability and accurate position tracking is imperative in
networked robotic systems, particularly for haptics-enabled human-robot
interaction. Recent literature has integrated human biomechanics into the
stabilizers implemented for teleoperation, enhancing force preservation while
guaranteeing convergence and safety. However, position desynchronization due to
imperfect communication and non-passive behaviors remains a challenge. This
paper proposes a two-port biomechanics-aware passivity-based synchronizer and
stabilizer, referred to as TBPS2. This stabilizer optimizes position
synchronization by leveraging human biomechanics while reducing the
stabilizer's conservatism in its activation. We provide the mathematical design
synthesis of the stabilizer and the proof of stability. We also conducted a
series of grid simulations and systematic experiments, comparing their
performance with that of state-of-the-art solutions under varying time delays
and environmental conditions.

</details>


### [11] [MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery](https://arxiv.org/abs/2511.05007)
*Baiye Cheng,Tianhai Liang,Suning Huang,Maanping Shao,Feihong Zhang,Botian Xu,Zhengrong Xue,Huazhe Xu*

Main category: cs.RO

TL;DR: 提出MoE-DP方法，在视觉编码器和扩散模型之间插入混合专家层，提高机器人视觉运动控制的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在机器人视觉控制中缺乏从子任务失败中恢复的鲁棒性，且学习到的观察表示难以解释。

Method: 在视觉编码器和扩散模型之间插入混合专家层，将策略知识分解为专门处理任务不同阶段的专家。

Result: 在6个长时域仿真任务中，扰动条件下成功率平均相对提升36%，真实世界也表现出显著性能提升。

Conclusion: MoE-DP不仅提高了鲁棒性，还学习了可解释的技能分解，无需重新训练即可重新排列子任务。

Abstract: Diffusion policies have emerged as a powerful framework for robotic
visuomotor control, yet they often lack the robustness to recover from subtask
failures in long-horizon, multi-stage tasks and their learned representations
of observations are often difficult to interpret. In this work, we propose the
Mixture of Experts-Enhanced Diffusion Policy (MoE-DP), where the core idea is
to insert a Mixture of Experts (MoE) layer between the visual encoder and the
diffusion model. This layer decomposes the policy's knowledge into a set of
specialized experts, which are dynamically activated to handle different phases
of a task. We demonstrate through extensive experiments that MoE-DP exhibits a
strong capability to recover from disturbances, significantly outperforming
standard baselines in robustness. On a suite of 6 long-horizon simulation
tasks, this leads to a 36% average relative improvement in success rate under
disturbed conditions. This enhanced robustness is further validated in the real
world, where MoE-DP also shows significant performance gains. We further show
that MoE-DP learns an interpretable skill decomposition, where distinct experts
correspond to semantic task primitives (e.g., approaching, grasping). This
learned structure can be leveraged for inference-time control, allowing for the
rearrangement of subtasks without any re-training.Our video and code are
available at the https://moe-dp-website.github.io/MoE-DP-Website/.

</details>


### [12] [Tunable Passivity Control for Centralized Multiport Networked Systems](https://arxiv.org/abs/2511.05026)
*Xingyuan Zhou,Peter Paik,S. Farokh Atashzar*

Main category: cs.RO

TL;DR: 提出了一种集中式最优被动性稳定框架（TCoPC），用于解决集中式多端口网络动态系统的稳定性问题，通过集中式被动性观测器和最优被动性控制器实现L2稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统被动性稳定方法在分布式补偿和节点被动性假设方面存在限制，无法满足复杂网络系统的稳定性需求。

Method: 采用数据驱动的无模型方法，通过集中式被动性观测器监控整体能量流，最优被动性控制器按需分配耗散，保证严格被动性。

Result: 仿真结果表明，该框架在不同时变延迟场景下表现良好，放宽了远程节点的最小相位和被动性假设，增强了可扩展性和通用性。

Conclusion: TCoPC框架有效解决了CMND系统的稳定性问题，提供了灵活的性能优化和稳定性保证。

Abstract: Centralized Multiport Networked Dynamic (CMND) systems have emerged as a key
architecture with applications in several complex network systems, such as
multilateral telerobotics and multi-agent control. These systems consist of a
hub node/subsystem connecting with multiple remote nodes/subsystems via a
networked architecture. One challenge for this system is stability, which can
be affected by non-ideal network artifacts. Conventional passivity-based
approaches can stabilize the system under specialized applications like
small-scale networked systems. However, those conventional passive stabilizers
have several restrictions, such as distributing compensation across subsystems
in a decentralized manner, limiting flexibility, and, at the same time, relying
on the restrictive assumptions of node passivity. This paper synthesizes a
centralized optimal passivity-based stabilization framework for CMND systems.
It consists of a centralized passivity observer monitoring overall energy flow
and an optimal passivity controller that distributes the just-needed
dissipation among various nodes, guaranteeing strict passivity and, thus, L2
stability. The proposed data-driven model-free approach, i.e., Tunable
Centralized Optimal Passivity Control (TCoPC), optimizes total performance
based on the prescribed dissipation distribution strategy while ensuring
stability. The controller can put high dissipation loads on some sub-networks
while relaxing the dissipation on other nodes. Simulation results demonstrate
the proposed frameworks performance in a complex task under different
time-varying delay scenarios while relaxing the remote nodes minimum phase and
passivity assumption, enhancing the scalability and generalizability.

</details>


### [13] [Epically Powerful: An open-source software and mechatronics infrastructure for wearable robotic systems](https://arxiv.org/abs/2511.05033)
*Jennifer K. Leestma,Siddharth R. Nathella,Christoph P. O. Nuesslein,Snehil Mathur,Gregory S. Sawicki,Aaron J. Young*

Main category: cs.RO

TL;DR: Epically Powerful是一个开源机器人基础设施，简化可穿戴机器人系统开发，提供通信协议、数据采集、可视化等核心功能，支持Python快速开发。


<details>
  <summary>Details</summary>
Motivation: 降低开发定制化可穿戴机器人系统的门槛，让研究人员能够快速从硬件到模块化设备。

Method: 提供代码库支持Python简化实现，集成QDD执行器、单板计算机和传感器，包含示例控制器和实时可视化工具。

Result: 构建了一个完整的开发框架，包含硬件选型指南、系统组装说明和控制器实现文档。

Conclusion: Epically Powerful不仅适用于可穿戴机器人，也广泛适用于其他使用QDD执行器和单板计算机的机器人领域。

Abstract: Epically Powerful is an open-source robotics infrastructure that streamlines
the underlying framework of wearable robotic systems - managing communication
protocols, clocking, actuator commands, visualization, sensor data acquisition,
data logging, and more - while also providing comprehensive guides for hardware
selection, system assembly, and controller implementation. Epically Powerful
contains a code base enabling simplified user implementation via Python that
seamlessly interfaces with various commercial state-of-the-art quasi-direct
drive (QDD) actuators, single-board computers, and common sensors, provides
example controllers, and enables real-time visualization. To further support
device development, the package also includes a recommended parts list and
compatibility guide and detailed documentation on hardware and software
implementation. The goal of Epically Powerful is to lower the barrier to
developing and deploying custom wearable robotic systems without a
pre-specified form factor, enabling researchers to go from raw hardware to
modular, robust devices quickly and effectively. Though originally designed
with wearable robotics in mind, Epically Powerful is broadly applicable to
other robotic domains that utilize QDD actuators, single-board computers, and
sensors for closed-loop control.

</details>


### [14] [TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments](https://arxiv.org/abs/2511.05052)
*Zihao Li,Yiming Zhu,Zhe Zhong,Qinyuan Ren,Yijiang Huang*

Main category: cs.RO

TL;DR: 提出了TAPOM方法，通过任务空间拓扑分析来解决机器人操作中狭窄通道的规划难题，显著提高了低间隙操作任务的成功率和效率


<details>
  <summary>Details</summary>
Motivation: 现有规划方法在狭窄通道操作细长物体时经常失败，主要由于采样困难或陷入局部最优，需要新的方法来处理低间隙场景的挑战

Method: TAPOM采用分层规划：高层进行任务空间拓扑分析识别关键路径并生成引导关键帧，低层规划器利用这些关键帧寻找可行的配置空间轨迹

Result: 实验验证显示该方法在低间隙操作任务上相比最先进方法具有显著更高的成功率和改进的效率

Conclusion: TAPOM方法通过显式结合拓扑分析，为机器人在复杂现实环境中的操作能力提升提供了广泛的应用前景

Abstract: Robotic manipulation in complex, constrained spaces is vital for widespread
applications but challenging, particularly when navigating narrow passages with
elongated objects. Existing planning methods often fail in these low-clearance
scenarios due to the sampling difficulties or the local minima. This work
proposes Topology-Aware Planning for Object Manipulation (TAPOM), which
explicitly incorporates task-space topological analysis to enable efficient
planning. TAPOM uses a high-level analysis to identify critical pathways and
generate guiding keyframes, which are utilized in a low-level planner to find
feasible configuration space trajectories. Experimental validation demonstrates
significantly high success rates and improved efficiency over state-of-the-art
methods on low-clearance manipulation tasks. This approach offers broad
implications for enhancing manipulation capabilities of robots in complex
real-world environments.

</details>


### [15] [Decomposed Object Manipulation via Dual-Actor Policy](https://arxiv.org/abs/2511.05129)
*Bin Fan,Jianjian Jiang,Zhuohao Li,Yixiang He,Xiaoming Wu,Yihan Yang,Shengbang Liu,Weishi Zheng*

Main category: cs.RO

TL;DR: 提出DAP双执行器策略，将物体操作任务分为接近阶段和操作阶段，分别使用功能可供性和运动流两种视觉先验来增强各阶段性能，并在新构建的数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统方法使用单一策略学习整个物体操作过程，忽略了任务本身分为接近阶段和操作阶段的特性，且现有数据集缺乏足够的视觉先验支持训练。

Method: 提出DAP双执行器策略：1) 功能可供性执行器定位功能部件改善接近过程；2) 运动流执行器捕捉部件运动促进操作过程；3) 决策器确定当前阶段并选择对应执行器。同时构建了包含两种视觉先验的Dual-Prior数据集。

Result: 在自建数据集、RoboTwin基准测试和真实场景中，方法平均分别超越SOTA方法5.55%、14.7%和10.4%。

Conclusion: 通过显式考虑物体操作的不同阶段并利用异构视觉先验，DAP策略能有效提升物体操作任务的性能，特别是在长期多阶段任务中表现优异。

Abstract: Object manipulation, which focuses on learning to perform tasks on similar
parts across different types of objects, can be divided into an approaching
stage and a manipulation stage. However, previous works often ignore this
characteristic of the task and rely on a single policy to directly learn the
whole process of object manipulation. To address this problem, we propose a
novel Dual-Actor Policy, termed DAP, which explicitly considers different
stages and leverages heterogeneous visual priors to enhance each stage.
Specifically, we introduce an affordance-based actor to locate the functional
part in the manipulation task, thereby improving the approaching process.
Following this, we propose a motion flow-based actor to capture the movement of
the component, facilitating the manipulation process. Finally, we introduce a
decision maker to determine the current stage of DAP and select the
corresponding actor. Moreover, existing object manipulation datasets contain
few objects and lack the visual priors needed to support training. To address
this, we construct a simulated dataset, the Dual-Prior Object Manipulation
Dataset, which combines the two visual priors and includes seven tasks,
including two challenging long-term, multi-stage tasks. Experimental results on
our dataset, the RoboTwin benchmark and real-world scenarios illustrate that
our method consistently outperforms the SOTA method by 5.55%, 14.7% and 10.4%
on average respectively.

</details>


### [16] [Follow-Me in Micro-Mobility with End-to-End Imitation Learning](https://arxiv.org/abs/2511.05158)
*Sahar Salimpour,Iacopo Catalano,Tomi Westerlund,Mohsen Falahi,Jorge Peña Queralta*

Main category: cs.RO

TL;DR: 本文研究了自主微移动平台在拥挤动态环境中的导航问题，重点优化用户舒适度和体验而非传统机器人指标。通过模仿学习开发了更平滑的控制器，在跟随模式下实现了最先进的舒适度。


<details>
  <summary>Details</summary>
Motivation: 自主微移动平台在拥挤动态环境中面临挑战，现有研究多关注时间或距离等传统机器人指标，而用户舒适度和整体体验在商业应用中至关重要但研究不足。

Method: 使用模仿学习方法开发控制器，比较了不同的端到端神经网络架构，并在真实世界生产级部署中验证其可用性。

Result: 模仿学习相比之前手动调优的控制器能提供更平滑和更好的控制效果，DAAV自主轮椅在跟随模式下实现了最先进的舒适度。

Conclusion: 模仿学习是开发自主微移动平台控制器的有效方法，能够显著提升用户舒适度和体验，适合在真实世界生产环境中部署。

Abstract: Autonomous micro-mobility platforms face challenges from the perspective of
the typical deployment environment: large indoor spaces or urban areas that are
potentially crowded and highly dynamic. While social navigation algorithms have
progressed significantly, optimizing user comfort and overall user experience
over other typical metrics in robotics (e.g., time or distance traveled) is
understudied. Specifically, these metrics are critical in commercial
applications. In this paper, we show how imitation learning delivers smoother
and overall better controllers, versus previously used manually-tuned
controllers. We demonstrate how DAAV's autonomous wheelchair achieves
state-of-the-art comfort in follow-me mode, in which it follows a human
operator assisting persons with reduced mobility (PRM). This paper analyzes
different neural network architectures for end-to-end control and demonstrates
their usability in real-world production-level deployments.

</details>


### [17] [Procedimiento de auditoría de ciberseguridad para sistemas autónomos: metodología, amenazas y mitigaciones](https://arxiv.org/abs/2511.05185)
*Adrián Campazas-Vega,Claudia Álvarez-Aparicio,David Sobrín-Hidalgo,Laura Inyesto-Alonso,Francisco Javier Rodríguez-Lera,Vicente Matellán-Olivera,Ángel Manuel Guerrero-Higueras*

Main category: cs.RO

TL;DR: 提出了一种针对自主系统的分层安全审计程序，包括分层结构方法、机器人特定威胁分类和具体缓解措施，并通过四个代表性机器人平台的案例研究验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 自主系统在工业、医疗、物流等关键领域的部署快速增长，但伴随的安全问题带来了重大风险，特别是那些在人类交互环境中运行的自主系统。技术进步和系统复杂性增加了攻击面。

Method: 基于分层结构方法、适应机器人环境的威胁分类法以及一套具体缓解措施，开发了专门的安全审计程序。

Result: 通过四个实际案例研究验证了方法的有效性：Ghost Robotics的Vision 60军用四足机器人、Unitree Robotics的A1机器人、Universal Robots的UR3协作臂和Aldebaran Robotics的Pepper社交机器人。

Conclusion: 提出的安全审计程序为自主系统提供了有效的安全保障方法，能够应对日益增长的安全挑战和复杂的攻击面。

Abstract: The deployment of autonomous systems has experienced remarkable growth in
recent years, driven by their integration into sectors such as industry,
medicine, logistics, and domestic environments. This expansion is accompanied
by a series of security issues that entail significant risks due to the
critical nature of autonomous systems, especially those operating in
human-interaction environments. Furthermore, technological advancement and the
high operational and architectural complexity of autonomous systems have
resulted in an increased attack surface. This article presents a specific
security auditing procedure for autonomous systems, based on a layer-structured
methodology, a threat taxonomy adapted to the robotic context, and a set of
concrete mitigation measures. The validity of the proposed approach is
demonstrated through four practical case studies applied to representative
robotic platforms: the Vision 60 military quadruped from Ghost Robotics, the A1
robot from Unitree Robotics, the UR3 collaborative arm from Universal Robots,
and the Pepper social robot from Aldebaran Robotics.

</details>


### [18] [Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation](https://arxiv.org/abs/2511.05199)
*Yichen Zhu,Feifei Feng*

Main category: cs.RO

TL;DR: 提出了一种通过从视频中检索类比来学习机器人策略的新方法，利用人类演示视频构建知识库，通过提取物体功能掩码和手部运动轨迹等中层信息来增强机器人的学习和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 机器人面对复杂不确定环境时面临挑战，而人类通常通过观看视频演示来学习新任务。受此启发，希望让机器人也能通过观看人类演示视频来学习操作任务。

Method: 构建人类日常任务视频库，提取物体功能掩码和手部运动轨迹等中层信息。系统包含视频检索器和策略生成器两个组件，前者从外部视频库中检索任务相关视频，后者将检索到的知识整合到学习循环中。

Result: 在多个模拟和真实环境中的严格测试表明，该系统相比传统机器人系统在性能上有显著提升。

Conclusion: 该方法使机器人能够对各种场景做出自适应响应，并泛化到训练数据之外的任务，在机器人领域取得了重要突破。

Abstract: Robots operating in complex and uncertain environments face considerable
challenges. Advanced robotic systems often rely on extensive datasets to learn
manipulation tasks. In contrast, when humans are faced with unfamiliar tasks,
such as assembling a chair, a common approach is to learn by watching video
demonstrations. In this paper, we propose a novel method for learning robot
policies by Retrieving-from-Video (RfV), using analogies from human
demonstrations to address manipulation tasks. Our system constructs a video
bank comprising recordings of humans performing diverse daily tasks. To enrich
the knowledge from these videos, we extract mid-level information, such as
object affordance masks and hand motion trajectories, which serve as additional
inputs to enhance the robot model's learning and generalization capabilities.
We further feature a dual-component system: a video retriever that taps into an
external video bank to fetch task-relevant video based on task specification,
and a policy generator that integrates this retrieved knowledge into the
learning cycle. This approach enables robots to craft adaptive responses to
various scenarios and generalize to tasks beyond those in the training data.
Through rigorous testing in multiple simulated and real-world settings, our
system demonstrates a marked improvement in performance over conventional
robotic systems, showcasing a significant breakthrough in the field of
robotics.

</details>


### [19] [Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space](https://arxiv.org/abs/2511.05203)
*Linus Nwankwo,Björn Ellensohn,Christian Rauch,Elmar Rueckert*

Main category: cs.RO

TL;DR: 提出了共生交互学习(SIL)方法，使人类和具身智能体能够通过双向交互共同适应，超越传统的主从模式，实现主动澄清、适应性建议和共享计划优化。


<details>
  <summary>Details</summary>
Motivation: 当前基于基础模型的自主智能体虽然能理解自然语言指令和执行长时程任务，但采用的是主从交互模式，智能体被动执行人类命令，缺乏人类日常交互中的共同适应动态。

Method: 将SIL形式化为共享潜在任务空间中的共同适应过程，使用预训练基础模型进行空间感知和推理，配合轻量级潜在编码器将模型输出接地到任务特定表示，并添加记忆架构防止任务空间表示遗忘。

Result: 在模拟和真实世界的具身任务中验证了SIL的有效性，包括指令跟随、信息检索、查询导向推理和交互对话。

Conclusion: SIL方法能够实现人类与智能体之间的双向共同适应，推动交互式人工智能向更自然、协作的方向发展。

Abstract: Today's autonomous agents can understand free-form natural language
instructions and execute long-horizon tasks in a manner akin to human-level
reasoning. These capabilities are mostly driven by large-scale pre-trained
foundation models (FMs). However, the approaches with which these models are
grounded for human-robot interaction (HRI) perpetuate a master-apprentice
model, where the apprentice (embodied agent) passively receives and executes
the master's (human's) commands without reciprocal learning. This reactive
interaction approach does not capture the co-adaptive dynamics inherent in
everyday multi-turn human-human interactions. To address this, we propose a
Symbiotic Interactive Learning (SIL) approach that enables both the master and
the apprentice to co-adapt through mutual, bidirectional interactions. We
formalised SIL as a co-adaptation process within a shared latent task space,
where the agent and human maintain joint belief states that evolve based on
interaction history. This enables the agent to move beyond reactive execution
to proactive clarification, adaptive suggestions, and shared plan refinement.
To realise these novel behaviours, we leveraged pre-trained FMs for spatial
perception and reasoning, alongside a lightweight latent encoder that grounds
the models' outputs into task-specific representations. Furthermore, to ensure
stability as the tasks evolve, we augment SIL with a memory architecture that
prevents the forgetting of learned task-space representations. We validate SIL
on both simulated and real-world embodied tasks, including instruction
following, information retrieval, query-oriented reasoning, and interactive
dialogues. Demos and resources are public
at:~\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}.

</details>


### [20] [Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning](https://arxiv.org/abs/2511.05234)
*Philipp Dahlinger,Niklas Freymuth,Tai Hoang,Tobias Würth,Michael Volpp,Luise Kärger,Gerhard Neumann*

Main category: cs.RO

TL;DR: 提出了M3GN方法，通过轨迹级元学习和运动基元直接预测稳定准确的模拟结果，相比现有图网络模拟器在多个任务中实现了更高的模拟精度和更低的运行成本。


<details>
  <summary>Details</summary>
Motivation: 现有学习模拟器依赖单步观测，无法利用时间上下文推断材料属性，且自回归推演会快速累积误差，限制了在机器人操作和制造优化等应用中的效果。

Method: 将网格模拟构建为轨迹级元学习问题，使用条件神经过程从有限初始数据快速适应新场景，利用运动基元直接通过单次模型调用预测快速稳定的模拟结果。

Result: M3GN在多个任务中相比最先进的图网络模拟器提供了更高的模拟精度，同时运行成本显著降低。

Conclusion: 轨迹级元学习和运动基元的结合为学习模拟器提供了更准确、高效的解决方案，特别适用于需要快速准确模拟的应用场景。

Abstract: Simulating object deformations is a critical challenge across many scientific
domains, including robotics, manufacturing, and structural mechanics. Learned
Graph Network Simulators (GNSs) offer a promising alternative to traditional
mesh-based physics simulators. Their speed and inherent differentiability make
them particularly well suited for applications that require fast and accurate
simulations, such as robotic manipulation or manufacturing optimization.
However, existing learned simulators typically rely on single-step
observations, which limits their ability to exploit temporal context. Without
this information, these models fail to infer, e.g., material properties.
Further, they rely on auto-regressive rollouts, which quickly accumulate error
for long trajectories. We instead frame mesh-based simulation as a
trajectory-level meta-learning problem. Using Conditional Neural Processes, our
method enables rapid adaptation to new simulation scenarios from limited
initial data while capturing their latent simulation properties. We utilize
movement primitives to directly predict fast, stable and accurate simulations
from a single model call. The resulting approach, Movement-primitive
Meta-MeshGraphNet (M3GN), provides higher simulation accuracy at a fraction of
the runtime cost compared to state-of-the-art GNSs across several tasks.

</details>


### [21] [TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models](https://arxiv.org/abs/2511.05275)
*Hokyun Im,Euijin Jeong,Jianlong Fu,Andrey Kolobov,Youngwoon Lee*

Main category: cs.RO

TL;DR: TwinVLA是一个模块化框架，将两个预训练的单臂视觉-语言-动作模型组合成协调的双臂VLA，无需双臂预训练数据即可实现高效的双臂操作。


<details>
  <summary>Details</summary>
Motivation: 现有公共数据集主要关注单臂演示，将VLA适应双臂任务通常需要大量额外的双臂数据和微调，这限制了双臂操作的发展。

Method: 通过模块化组合两个预训练的单臂VLA策略，形成一个协调的双臂VLA框架，而不是训练单一跨具身模型。

Result: 在真实世界和仿真环境中，TwinVLA在多种双臂任务上优于同等规模的单体RDT-1B模型，且无需任何双臂预训练，缩小了与依赖大量专有双臂数据的先进模型之间的差距。

Conclusion: 模块化组合方法为高性能双臂操作提供了一条数据高效且可扩展的路径，能够充分利用公共单臂数据。

Abstract: Vision-language-action models (VLAs) trained on large-scale robotic datasets
have demonstrated strong performance on manipulation tasks, including bimanual
tasks. However, because most public datasets focus on single-arm
demonstrations, adapting VLAs for bimanual tasks typically requires substantial
additional bimanual data and fine-tuning. To address this challenge, we
introduce TwinVLA, a modular framework that composes two copies of a pretrained
single-arm VLA into a coordinated bimanual VLA. Unlike monolithic
cross-embodiment models trained on mixtures of single-arm and bimanual data,
TwinVLA improves both data efficiency and performance by composing pretrained
single-arm policies. Across diverse bimanual tasks in real-world and simulation
settings, TwinVLA outperforms a comparably-sized monolithic RDT-1B model
without requiring any bimanual pretraining. Furthermore, it narrows the gap to
state-of-the-art model, $\pi_0$ which rely on extensive proprietary bimanual
data and compute cost. These results establish our modular composition approach
as a data-efficient and scalable path toward high-performance bimanual
manipulation, leveraging public single-arm data.

</details>


### [22] [Force-Safe Environment Maps and Real-Time Detection for Soft Robot Manipulators](https://arxiv.org/abs/2511.05307)
*Akua K. Dickson,Juan C. Pacheco Garcia,Andrew P. Sabelhaus*

Main category: cs.RO

TL;DR: 提出了一个将力安全标准从任务空间映射到配置空间的框架，用于软体机器人机械臂在易损环境中的实时力安全检测


<details>
  <summary>Details</summary>
Motivation: 现有障碍物检测和避让方法未考虑软体机械臂与易损障碍物接触时的力限制，需要在易损环境中实现安全操作

Method: 通过正向运动学将任务空间中的允许接触力限制映射到配置空间，确保被分类为安全的配置在最大力阈值以下

Result: 在双段气动软体机器人机械臂的仿真和硬件实验中验证了该方法能准确检测与可变形障碍物交互时的力安全性

Conclusion: 该方法为软体机械臂在易损、杂乱环境中实现实时安全规划奠定了基础

Abstract: Soft robot manipulators have the potential for deployment in delicate
environments to perform complex manipulation tasks. However, existing obstacle
detection and avoidance methods do not consider limits on the forces that
manipulators may exert upon contact with delicate obstacles. This work
introduces a framework that maps force safety criteria from task space (i.e.
positions along the robot's body) to configuration space (i.e. the robot's
joint angles) and enables real-time force safety detection. We incorporate
limits on allowable environmental contact forces for given task-space
obstacles, and map them into configuration space (C-space) through the
manipulator's forward kinematics. This formulation ensures that configurations
classified as safe are provably below the maximum force thresholds, thereby
allowing us to determine force-safe configurations of the soft robot
manipulator in real-time. We validate our approach in simulation and hardware
experiments on a two-segment pneumatic soft robot manipulator. Results
demonstrate that the proposed method accurately detects force safety during
interactions with deformable obstacles, thereby laying the foundation for
real-time safe planning of soft manipulators in delicate, cluttered
environments.

</details>


### [23] [ETHOS: A Robotic Encountered-Type Haptic Display for Social Interaction in Virtual Reality](https://arxiv.org/abs/2511.05379)
*Eric Godden,Jacquie Groenewegen,Matthew K. X. J. Pan*

Main category: cs.RO

TL;DR: ETHOS是一个动态触觉显示系统，通过扭矩控制机械臂和可互换道具，在VR中实现自然社交互动触觉反馈，包括握手、击掌等接触式互动。


<details>
  <summary>Details</summary>
Motivation: 在虚拟现实中重现具有社交意义的触觉互动，解决传统VR社交互动中缺乏物理接触的问题。

Method: 集成扭矩控制机械臂与可互换被动道具，采用基于标记的物理-虚拟配准，引入静态和动态两种控制策略，并配备基于用户姿态的安全监控系统。

Result: 静态配准精度达5.09±0.94mm，用户互动平均接触延迟为28.53±31.21ms，证明了在VR中重现社交触觉的可行性。

Conclusion: ETHOS通过整合关键安全和控制机制，为虚拟环境中高保真、动态的人际互动建立了实用基础。

Abstract: We present ETHOS (Encountered-Type Haptics for On-demand Social Interaction),
a dynamic encountered-type haptic display (ETHD) that enables natural physical
contact in virtual reality (VR) during social interactions such as handovers,
fist bumps, and high-fives. The system integrates a torque-controlled robotic
manipulator with interchangeable passive props (silicone hand replicas and a
baton), marker-based physical-virtual registration via a ChArUco board, and a
safety monitor that gates motion based on the user's head and hand pose. We
introduce two control strategies: (i) a static mode that presents a stationary
prop aligned with its virtual counterpart, consistent with prior ETHD
baselines, and (ii) a dynamic mode that continuously updates prop position by
exponentially blending an initial mid-point trajectory with real-time hand
tracking, generating a unique contact point for each interaction. Bench tests
show static colocation accuracy of 5.09 +/- 0.94 mm, while user interactions
achieved temporal alignment with an average contact latency of 28.53 +/- 31.21
ms across all interaction and control conditions. These results demonstrate the
feasibility of recreating socially meaningful haptics in VR. By incorporating
essential safety and control mechanisms, ETHOS establishes a practical
foundation for high-fidelity, dynamic interpersonal interactions in virtual
environments.

</details>


### [24] [EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation](https://arxiv.org/abs/2511.05397)
*Samarth Chopra,Alex McMoil,Ben Carnovale,Evan Sokolson,Rajkumar Kubendran,Samuel Dickerson*

Main category: cs.RO

TL;DR: EverydayVLA是一个低成本（300美元以下）的6自由度机械臂，结合视觉-语言-动作模型，通过自适应规划集成实现可靠操作，在真实世界测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型依赖昂贵硬件，在复杂场景中表现不佳。需要开发低成本且可靠的机器人系统，使其能在家庭和研究实验室中普及使用。

Method: 使用单一统一模型输出离散和连续动作，采用自适应规划集成监控运动不确定性并触发实时重新规划，确保安全可靠的操作。

Result: 在LIBERO基准测试中达到最先进成功率，真实世界测试中分别比现有方法在分布内和分布外场景中提升49%和34.9%的性能。

Conclusion: EverydayVLA通过结合最先进的VLA模型与低成本硬件，为机器人在家庭和研究实验室的经济应用铺平了道路，实现了机器人基础模型的民主化访问。

Abstract: While Vision-Language-Action (VLA) models map visual inputs and language
instructions directly to robot actions, they often rely on costly hardware and
struggle in novel or cluttered scenes. We introduce EverydayVLA, a 6-DOF
manipulator that can be assembled for under $300, capable of modest payloads
and workspace. A single unified model jointly outputs discrete and continuous
actions, and our adaptive-horizon ensemble monitors motion uncertainty to
trigger on-the-fly re-planning for safe, reliable operation. On LIBERO,
EverydayVLA matches state-of-the-art success rates, and in real-world tests it
outperforms prior methods by 49% in-distribution and 34.9% out-of-distribution.
By combining a state-of-the-art VLA with cost-effective hardware, EverydayVLA
democratizes access to a robotic foundation model and paves the way for
economical use in homes and research labs alike. Experiment videos and details:
https://everydayvla.github.io/

</details>


### [25] [Stable and Robust SLIP Model Control via Energy Conservation-Based Feedback Cancellation for Quadrupedal Applications](https://arxiv.org/abs/2511.05402)
*Muhammad Saud Ul Hassan,Derek Vasquez,Hamza Asif,Christian Hubicki*

Main category: cs.RO

TL;DR: 基于能量守恒的四足机器人控制架构，使用弹簧倒立摆模型实现稳定的动态运动，在模拟中展示了稳定的弹跳步态和对传感器误差的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够实现四足机器人稳定动态运动的控制方法，特别是针对奔跑步态，借鉴生物四足动物的运动特性和现有机器人系统的设计。

Method: 将机器人建模为弹簧倒立摆模型，在飞行阶段控制腿部方向，在支撑阶段控制腿部长度，基于能量守恒原理跟踪稳定的抛物线样条。

Result: 在基于Ghost Robotics Minitaur机器人规格的模拟中，控制算法成功生成了稳定的弹跳步态，并且在面对高达10%的传感器测量误差时仍能保持稳定。

Conclusion: 基于能量守恒的SLIP模型控制架构能够有效实现四足机器人的稳定动态运动，并展现出良好的鲁棒性。

Abstract: In this paper, we present an energy-conservation based control architecture
for stable dynamic motion in quadruped robots. We model the robot as a
Spring-loaded Inverted Pendulum (SLIP), a model well-suited to represent the
bouncing motion characteristic of running gaits observed in various biological
quadrupeds and bio-inspired robotic systems. The model permits leg-orientation
control during flight and leg-length control during stance, a design choice
inspired by natural quadruped behaviors and prevalent in robotic quadruped
systems. Our control algorithm uses the reduced-order SLIP dynamics of the
quadruped to track a stable parabolic spline during stance, which is calculated
using the principle of energy conservation. Through simulations based on the
design specifications of an actual quadruped robot, Ghost Robotics Minitaur, we
demonstrate that our control algorithm generates stable bouncing gaits.
Additionally, we illustrate the robustness of our controller by showcasing its
ability to maintain stable bouncing even when faced with up to a 10% error in
sensor measurements.

</details>


### [26] [Bioinspired Soft Quadrotors Jointly Unlock Agility, Squeezability, and Collision Resilience](https://arxiv.org/abs/2511.05426)
*Luca Girardi,Gabriel Maquignaz,Stefano Mintchev*

Main category: cs.RO

TL;DR: FlexiQuad是一种软框架四旋翼设计，通过模仿生物飞行器的各向异性刚度和分布式质量能量结构，在保持敏捷飞行能力的同时显著提高了碰撞恢复能力和挤压通过能力。


<details>
  <summary>Details</summary>
Motivation: 传统四旋翼的刚性框架限制了在复杂环境中的飞行能力，特别是碰撞恢复和通过狭窄通道的能力。受生物飞行器软翼结构的启发，需要开发一种能同时保持敏捷飞行和物理交互能力的软框架设计。

Method: 采用软框架设计方法，使四旋翼框架具有各向异性刚度和分布式质量能量结构，框架柔度比传统四旋翼高三个数量级，同时仍能实现高机动性飞行。

Result: 405克原型机实现了峰值速度80+ km/h、线性加速度3g、角加速度300 rad/s²的敏捷机动，能承受5 m/s正面碰撞无损伤，可通过70%名义宽度的间隙，碰撞恢复能力提高4倍，滑移碰撞力减小39倍。

Conclusion: FlexiQuad在0.006-0.77 N/mm的最佳结构柔度范围内，可同时实现敏捷性、挤压性和碰撞恢复性，扩展了悬停无人机在复杂环境中的能力，实现了飞行性能与物理交互能力的平衡。

Abstract: Natural flyers use soft wings to seamlessly enable a wide range of flight
behaviours, including agile manoeuvres, squeezing through narrow passageways,
and withstanding collisions. In contrast, conventional quadrotor designs rely
on rigid frames that support agile flight but inherently limit collision
resilience and squeezability, thereby constraining flight capabilities in
cluttered environments. Inspired by the anisotropic stiffness and distributed
mass-energy structures observed in biological organisms, we introduce
FlexiQuad, a soft-frame quadrotor design approach that limits this trade-off.
We demonstrate a 405-gram FlexiQuad prototype, three orders of magnitude more
compliant than conventional quadrotors, yet capable of acrobatic manoeuvres
with peak speeds above 80 km/h and linear and angular accelerations exceeding 3
g and 300 rad/s$^2$, respectively. Analysis demonstrates it can replicate
accelerations of rigid counterparts up to a thrust-to-weight ratio of 8.
Simultaneously, FlexiQuad exhibits fourfold higher collision resilience,
surviving frontal impacts at 5 m/s without damage and reducing destabilising
forces in glancing collisions by a factor of 39. Its frame can fully compress,
enabling flight through gaps as narrow as 70% of its nominal width. Our
analysis identifies an optimal structural softness range, from 0.006 to 0.77
N/mm, comparable to that of natural flyers' wings, whereby agility,
squeezability, and collision resilience are jointly achieved for FlexiQuad
models from 20 to 3000 grams. FlexiQuad expands hovering drone capabilities in
complex environments, enabling robust physical interactions without
compromising flight performance.

</details>
