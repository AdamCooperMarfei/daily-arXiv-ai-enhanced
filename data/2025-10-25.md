<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 28]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Configuration-Dependent Robot Kinematics Model and Calibration](https://arxiv.org/abs/2510.19962)
*Chen-Lung Lu,Honglu He,Agung Julius,John T. Wen*

Main category: cs.RO

TL;DR: 提出了一种基于配置依赖的机器人运动学校准框架，通过局部POE模型和傅里叶基函数插值，显著提高工业机器人在整个工作空间中的定位精度。


<details>
  <summary>Details</summary>
Motivation: 机器人精确运动学对于工具精确定位至关重要，但非几何因素会导致配置依赖的模型差异，需要开发能在整个工作空间保持高精度的校准方法。

Method: 使用局部POE模型在多个配置点进行识别，然后通过傅里叶基函数插值构建全局模型，参数化基于肩部和肘部关节角度。

Result: 在两个6自由度工业机器人上的验证显示，最大定位误差减少超过50%，达到冷喷涂制造所需的亚毫米精度要求，训练效率显著高于神经网络和自编码器方法。

Conclusion: 该方法能有效解决配置依赖的运动学误差问题，特别适用于具有较大配置依赖差异的机器人，在双机器人协作任务中展示了实际应用价值。

Abstract: Accurate robot kinematics is essential for precise tool placement in
articulated robots, but non-geometric factors can introduce
configuration-dependent model discrepancies. This paper presents a
configuration-dependent kinematic calibration framework for improving accuracy
across the entire workspace. Local Product-of-Exponential (POE) models,
selected for their parameterization continuity, are identified at multiple
configurations and interpolated into a global model. Inspired by joint gravity
load expressions, we employ Fourier basis function interpolation parameterized
by the shoulder and elbow joint angles, achieving accuracy comparable to neural
network and autoencoder methods but with substantially higher training
efficiency. Validation on two 6-DoF industrial robots shows that the proposed
approach reduces the maximum positioning error by over 50%, meeting the
sub-millimeter accuracy required for cold spray manufacturing. Robots with
larger configuration-dependent discrepancies benefit even more. A dual-robot
collaborative task demonstrates the framework's practical applicability and
repeatability.

</details>


### [2] [Push Anything: Single- and Multi-Object Pushing From First Sight with Contact-Implicit MPC](https://arxiv.org/abs/2510.19974)
*Hien Bui,Yufeiyang Gao,Haoran Yang,Eric Cui,Siddhant Mody,Brian Acosta,Thomas Stephen Felix,Bibit Bianchini,Michael Posa*

Main category: cs.RO

TL;DR: 提出了C3+算法，一种增强的接触隐式模型预测控制方法，能够在多物体平面推动任务中实现实时性能，成功率达到98%。


<details>
  <summary>Details</summary>
Motivation: 非抓取式操作面临物体物理属性未知和接触丰富交互复杂性的挑战。现有CI-MPC方法仅限于狭窄的示例，需要扩展到更广泛的物体几何形状和多物体场景。

Method: 开发了Consensus Complementarity Control Plus (C3+)算法，集成到包含物体扫描、网格重建和硬件执行的完整流程中。相比前代C3，C3+显著提高了求解速度。

Result: 在33个物体上达到98%的成功率，平均到达目标时间：单物体0.5分钟，双物体1.6分钟，三物体3.2分钟，四物体5.3分钟。

Conclusion: C3+算法在多物体平面推动任务中实现了实时性能和高成功率，展示了CI-MPC在复杂接触推理任务中的广泛能力。

Abstract: Non-prehensile manipulation of diverse objects remains a core challenge in
robotics, driven by unknown physical properties and the complexity of
contact-rich interactions. Recent advances in contact-implicit model predictive
control (CI-MPC), with contact reasoning embedded directly in the trajectory
optimization, have shown promise in tackling the task efficiently and robustly,
yet demonstrations have been limited to narrowly curated examples. In this
work, we showcase the broader capabilities of CI-MPC through precise planar
pushing tasks over a wide range of object geometries, including multi-object
domains. These scenarios demand reasoning over numerous inter-object and
object-environment contacts to strategically manipulate and de-clutter the
environment, challenges that were intractable for prior CI-MPC methods. To
achieve this, we introduce Consensus Complementarity Control Plus (C3+), an
enhanced CI-MPC algorithm integrated into a complete pipeline spanning object
scanning, mesh reconstruction, and hardware execution. Compared to its
predecessor C3, C3+ achieves substantially faster solve times, enabling
real-time performance even in multi-object pushing tasks. On hardware, our
system achieves overall 98% success rate across 33 objects, reaching pose goals
within tight tolerances. The average time-to-goal is approximately 0.5, 1.6,
3.2, and 5.3 minutes for 1-, 2-, 3-, and 4-object tasks, respectively. Project
page: https://dairlab.github.io/push-anything.

</details>


### [3] [Simultaneous learning of state-to-state minimum-time planning and control](https://arxiv.org/abs/2510.20008)
*Swati Dantu,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 提出基于强化学习的框架，学习无人机任意状态间的最小时间飞行策略，结合敏捷飞行和稳定悬停，在真实环境中验证了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统无人机竞速方法受限于预定义轨道布局，缺乏现实应用的泛化性，需要能处理任意起止状态的最小时间飞行策略。

Method: 使用强化学习框架，以点质量模型轨迹作为代理奖励近似最优飞行目标，采用课程学习实现高效训练和泛化。

Result: 仿真实验显示优于非线性模型预测控制跟踪点质量模型轨迹，真实环境实验验证了在小型ARM单板计算机上的鲁棒性和泛化能力。

Conclusion: 该框架成功实现了无人机任意状态间的最小时间飞行，平衡了敏捷性和稳定性，在真实环境中表现出良好的泛化性能。

Abstract: This paper tackles the challenge of learning a generalizable minimum-time
flight policy for UAVs, capable of navigating between arbitrary start and goal
states while balancing agile flight and stable hovering. Traditional
approaches, particularly in autonomous drone racing, achieve impressive speeds
and agility but are constrained to predefined track layouts, limiting
real-world applicability. To address this, we propose a reinforcement
learning-based framework that simultaneously learns state-to-state minimum-time
planning and control and generalizes to arbitrary state-to-state flights. Our
approach leverages Point Mass Model (PMM) trajectories as proxy rewards to
approximate the true optimal flight objective and employs curriculum learning
to scale the training process efficiently and to achieve generalization. We
validate our method through simulation experiments, comparing it against
Nonlinear Model Predictive Control (NMPC) tracking PMM-generated trajectories
and conducting ablation studies to assess the impact of curriculum learning.
Finally, real-world experiments confirm the robustness of our learned policy in
outdoor environments, demonstrating its ability to generalize and operate on a
small ARM-based single-board computer.

</details>


### [4] [Calibration of Parallel Kinematic Machine Based on Stewart Platform-A Literature Review](https://arxiv.org/abs/2510.20070)
*Sourabh Karmakar,Apurva Patel,Cameron J. Turner*

Main category: cs.RO

TL;DR: 本文综述了基于Stewart平台的并联运动学机器人的逆运动学校准方法，分析了外部仪器、约束和自校准三种主要方法，指出当前研究主要关注无负载条件下的结构误差校准。


<details>
  <summary>Details</summary>
Motivation: 并联运动学机器人在精密应用中需要微纳级运动控制，必须比应用精度更高，因此精确校准至关重要。逆运动学校准比正运动学方法更简便有效。

Method: 通过文献综述分析三种主要校准方法：外部仪器校准、约束校准和自校准，重点关注逆运动学为基础的校准技术。

Result: 研究发现研究者主要关注平台位置和方向精度的提升，考虑单一或多重误差源，主要是结构误差，部分考虑环境因素，但都在无负载条件下进行校准。

Conclusion: 本研究旨在理解该领域当前技术水平，为其他研究者在特定领域进一步探索提供参考和扩展空间。

Abstract: Stewart platform-based Parallel Kinematic (PKM) Machines have been
extensively studied by researchers due to their inherent finer control
characteristics. This has opened its potential deployment opportunities in
versatile critical applications like the medical field, engineering machines,
space research, electronic chip manufacturing, automobile manufacturing, etc.
All these precise, complicated, and repeatable motion applications require
micro and nano-scale movement control in 3D space; a 6-DOF PKM can take this
challenge smartly. For this, the PKM must be more accurate than the desired
application accuracy level and thus proper calibration for a PKM robot is
essential. Forward kinematics-based calibration for such hexapod machines
becomes unnecessarily complex and inverse kinematics complete this task with
much ease. To analyze different techniques, an external instrument-based,
constraint-based, and auto or self-calibration-based approaches have been used
for calibration. This survey has been done by reviewing these key
methodologies, their outcome, and important points related to inverse
kinematic-based PKM calibrations in general. It is observed in this study that
the researchers focused on improving the accuracy of the platform position and
orientation considering the errors contributed by a single source or multiple
sources. The error sources considered are mainly structural, in some cases,
environmental factors are also considered, however, these calibrations are done
under no-load conditions. This study aims to understand the current state of
the art in this field and to expand the scope for other researchers in further
exploration in a specific area.

</details>


### [5] [Design of a Bed Rotation Mechanism to Facilitate In-Situ Photogrammetric Reconstruction of Printed Parts](https://arxiv.org/abs/2510.20079)
*Travis A. Roberts,Sourabh Karmakar,Cameron J. Turner*

Main category: cs.RO

TL;DR: 设计并制造了一个用于聚合物FDM工艺研究的开放式3D打印平台，具有精确参数控制和原位摄影测量功能，特别关注旋转热床机制以减少相机数量实现摄影测量重建。


<details>
  <summary>Details</summary>
Motivation: 商用和消费级3D打印机多为闭源平台，缺乏研究所需的灵活性和精确参数控制，需要开发一个专门用于FDM工艺研究的开放式测试平台。

Method: 设计并制造了具有闭环位置反馈、热端和热床温度控制、环境温湿度监测的开放式FDM平台，配备相机和旋转热床机制，通过原位摄影测量记录打印过程几何变化。

Result: 成功开发了一个能够精确控制和监测FDM工艺参数的开放式研究平台，实现了通过旋转热床机制用最少相机数量进行摄影测量重建的能力。

Conclusion: 该开放式FDM研究平台为聚合物3D打印工艺研究提供了可重复实验的基础，通过旋转热床和摄影测量技术能够将工艺参数与几何缺陷关联分析。

Abstract: Additive manufacturing, or 3D printing, is a complex process that creates
free-form geometric objects by sequentially placing material to construct an
object, usually in a layer-by-layer process. One of the most widely used
methods is Fused Deposition Modeling (FDM). FDM is used in many of the
consumer-grade polymer 3D printers available today. While consumer grade
machines are cheap and plentiful, they lack many of the features desired in a
machine used for research purposes and are often closed-source platforms.
Commercial-grade models are more expensive and are also usually closed-source
platforms that do not offer flexibility for modifications often needed for
research. The authors designed and fabricated a machine to be used as a test
bed for research in the field of polymer FDM processes. The goal was to create
a platform that tightly controls and/or monitors the FDM build parameters so
that experiments can be repeated with a known accuracy. The platform offers
closed loop position feedback, control of the hot end and bed temperature, and
monitoring of environment temperature and humidity. Additionally, the platform
is equipped with cameras and a mechanism for in-situ photogrammetry, creating a
geometric record of the printing throughout the printing process. Through
photogrammetry, backtracking and linking process parameters to observable
geometric defects can be achieved. This paper focuses on the design of a novel
mechanism for spinning the heated bed to allow for photogrammetric
reconstruction of the printed part using a minimal number of cameras, as
implemented on this platform.

</details>


### [6] [PathFormer: A Transformer with 3D Grid Constraints for Digital Twin Robot-Arm Trajectory Generation](https://arxiv.org/abs/2510.20161)
*Ahmed Alanazi,Duy Ho,Yugyung Lee*

Main category: cs.RO

TL;DR: 提出了基于路径的Transformer模型，通过3网格表示和约束掩码解码，在保持运动结构的同时生成有效的机器人轨迹，在真实机器人上实现了高成功率。


<details>
  <summary>Details</summary>
Motivation: 传统序列模型忽略运动结构，导致机器人轨迹规划产生无效或低效执行，需要结合任务图推理和运动约束的解决方案。

Method: 使用3网格（位置/内容/时间）表示编码机器人运动，采用约束掩码解码确保相邻网格移动和工作空间边界，结合任务图和动作顺序进行推理。

Result: 在53,755条轨迹上训练，达到89.44%步骤准确率，99.99%路径合法；在真实机器人上实现97.5%到达成功率和86.7%端到端任务成功率。

Conclusion: 路径结构表示使Transformer能够生成准确、可靠且可解释的机器人轨迹，桥接了基于图的规划和基于序列的学习，为通用操作和仿真到现实迁移提供了实用基础。

Abstract: Robotic arms require precise, task-aware trajectory planning, yet sequence
models that ignore motion structure often yield invalid or inefficient
executions. We present a Path-based Transformer that encodes robot motion with
a 3-grid (where/what/when) representation and constraint-masked decoding,
enforcing lattice-adjacent moves and workspace bounds while reasoning over task
graphs and action order. Trained on 53,755 trajectories (80% train / 20%
validation), the model aligns closely with ground truth -- 89.44% stepwise
accuracy, 93.32% precision, 89.44% recall, and 90.40% F1 -- with 99.99% of
paths legal by construction. Compiled to motor primitives on an xArm Lite 6
with a depth-camera digital twin, it attains up to 97.5% reach and 92.5% pick
success in controlled tests, and 86.7% end-to-end success across 60
language-specified tasks in cluttered scenes, absorbing slips and occlusions
via local re-grounding without global re-planning. These results show that
path-structured representations enable Transformers to generate accurate,
reliable, and interpretable robot trajectories, bridging graph-based planning
and sequence-based learning and providing a practical foundation for
general-purpose manipulation and sim-to-real transfer.

</details>


### [7] [Reinforcement Learning-based Robust Wall Climbing Locomotion Controller in Ferromagnetic Environment](https://arxiv.org/abs/2510.20174)
*Yong Um,Young-Ha Shin,Joon-Ha Kim,Soonpyo Kwon,Hae-Won Park*

Main category: cs.RO

TL;DR: 提出了一种针对四足磁吸附爬墙机器人的强化学习框架，通过物理建模和课程学习解决磁脚附着不确定性，实现稳健的垂直爬行和滑落恢复。


<details>
  <summary>Details</summary>
Motivation: 解决四足磁吸附爬墙机器人在实际环境中磁脚附着的不确定性，包括部分接触、气隙敏感性和概率性附着失败等问题。

Method: 采用三阶段课程学习：1) 在平地上学习爬行步态；2) 逐渐旋转重力矢量并激活吸附模型；3) 注入随机附着失败以训练滑落恢复能力。

Result: 学习策略在仿真中实现了高成功率、强吸附保持和快速脱落恢复。相比假设完美吸附的MPC基线，该控制器在间歇性脱落时仍能维持运动。硬件实验验证了在钢表面的稳健垂直爬行。

Conclusion: 结合课程学习和真实吸附建模为磁吸附爬墙机器人在复杂环境中提供了弹性的仿真到现实迁移框架。

Abstract: We present a reinforcement learning framework for quadrupedal wall-climbing
locomotion that explicitly addresses uncertainty in magnetic foot adhesion. A
physics-based adhesion model of a quadrupedal magnetic climbing robot is
incorporated into simulation to capture partial contact, air-gap sensitivity,
and probabilistic attachment failures. To stabilize learning and enable
reliable transfer, we design a three-phase curriculum: (1) acquire a crawl gait
on flat ground without adhesion, (2) gradually rotate the gravity vector to
vertical while activating the adhesion model, and (3) inject stochastic
adhesion failures to encourage slip recovery. The learned policy achieves a
high success rate, strong adhesion retention, and rapid recovery from
detachment in simulation under degraded adhesion. Compared with a model
predictive control (MPC) baseline that assumes perfect adhesion, our controller
maintains locomotion when attachment is intermittently lost. Hardware
experiments with the untethered robot further confirm robust vertical crawling
on steel surfaces, maintaining stability despite transient misalignment and
incomplete attachment. These results show that combining curriculum learning
with realistic adhesion modeling provides a resilient sim-to-real framework for
magnetic climbing robots in complex environments.

</details>


### [8] [A Contact-Driven Framework for Manipulating in the Blind](https://arxiv.org/abs/2510.20177)
*Muhammad Suhail Saleem,Lai Yuan,Maxim Likhachev*

Main category: cs.RO

TL;DR: 提出了一种在视觉受限环境中结合接触反馈和结构先验的机器人操作框架，包含接触检测定位、占据估计和规划三个模块，在模拟和真实环境中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 机器人在视觉受限环境（如遮挡、光线差）中操作时，需要依赖接触反馈来感知环境，同时可以利用环境的结构先验（如管道布局）来预测未探索区域。

Method: 框架包含三个紧密耦合的模块：基于关节力矩传感和接触粒子滤波的接触检测定位模块；利用接触历史构建部分占据地图并通过学习预测器外推的占据估计模块；考虑噪声的规划模块。

Result: 在UR10e机械臂上验证了两个家庭任务：厨房水槽下操作阀门和从杂乱货架取物。相比基线方法，任务完成时间最多减少2倍，消融实验确认了各模块的贡献。

Conclusion: 该框架能够可靠解决视觉受限环境中的操作任务，通过整合接触反馈和结构先验实现了高效操作。

Abstract: Robots often face manipulation tasks in environments where vision is
inadequate due to clutter, occlusions, or poor lighting--for example, reaching
a shutoff valve at the back of a sink cabinet or locating a light switch above
a crowded shelf. In such settings, robots, much like humans, must rely on
contact feedback to distinguish free from occupied space and navigate around
obstacles. Many of these environments often exhibit strong structural
priors--for instance, pipes often span across sink cabinets--that can be
exploited to anticipate unseen structure and avoid unnecessary collisions. We
present a theoretically complete and empirically efficient framework for
manipulation in the blind that integrates contact feedback with structural
priors to enable robust operation in unknown environments. The framework
comprises three tightly coupled components: (i) a contact detection and
localization module that utilizes joint torque sensing with a contact particle
filter to detect and localize contacts, (ii) an occupancy estimation module
that uses the history of contact observations to build a partial occupancy map
of the workspace and extrapolate it into unexplored regions with learned
predictors, and (iii) a planning module that accounts for the fact that contact
localization estimates and occupancy predictions can be noisy, computing paths
that avoid collisions and complete tasks efficiently without eliminating
feasible solutions. We evaluate the system in simulation and in the real world
on a UR10e manipulator across two domestic tasks--(i) manipulating a valve
under a kitchen sink surrounded by pipes and (ii) retrieving a target object
from a cluttered shelf. Results show that the framework reliably solves these
tasks, achieving up to a 2x reduction in task completion time compared to
baselines, with ablations confirming the contribution of each module.

</details>


### [9] [NODA-MMH: Certified Learning-Aided Nonlinear Control for Magnetically-Actuated Swarm Experiment Toward On-Orbit Proof](https://arxiv.org/abs/2510.20231)
*Yuta Takahashi,Atsuki Ochi,Yoichi Tomioka,Shin-Ichiro Sakai*

Main category: cs.RO

TL;DR: 本文通过实验验证了基于学习辅助磁场相互作用的大规模卫星群控制原理，使用磁力矩器实现多卫星长期编队保持，解决了非完整约束、欠驱动、可扩展性和计算成本等挑战。


<details>
  <summary>Details</summary>
Motivation: 随着卫星数量增加，传统的两卫星位置控制方法面临非完整约束、欠驱动、可扩展性和计算成本等根本性挑战，需要新的控制方法来实现大规模卫星群的长期编队保持。

Method: 采用学习辅助的时间积分电流控制方法，设计两轴线圈和基于气浮平台的地面实验装置，提出NODA-MMH（神经功率最优偶极子分配认证学习模型磁群控制）进行基于模型的功率最优群控制。

Result: 实验验证了学习辅助时间积分电流控制的关键方面：增强平均系统动力学的可控性（具有理论保证误差界）和分散电流管理，成功复制了轨道动力学。

Conclusion: 该方法为大规模卫星群的长期编队保持问题提供了有效的解决方案，补充了磁驱动群控制的教学论文。

Abstract: This study experimentally validates the principle of large-scale satellite
swarm control through learning-aided magnetic field interactions generated by
satellite-mounted magnetorquers. This actuation presents a promising solution
for the long-term formation maintenance of multiple satellites and has
primarily been demonstrated in ground-based testbeds for two-satellite position
control. However, as the number of satellites increases beyond three,
fundamental challenges coupled with the high nonlinearity arise: 1)
nonholonomic constraints, 2) underactuation, 3) scalability, and 4)
computational cost. Previous studies have shown that time-integrated current
control theoretically solves these problems, where the average actuator outputs
align with the desired command, and a learning-based technique further enhances
their performance. Through multiple experiments, we validate critical aspects
of learning-aided time-integrated current control: (1) enhanced controllability
of the averaged system dynamics, with a theoretically guaranteed error bound,
and (2) decentralized current management. We design two-axis coils and a
ground-based experimental setup utilizing an air-bearing platform, enabling a
mathematical replication of orbital dynamics. Based on the effectiveness of the
learned interaction model, we introduce NODA-MMH (Neural power-Optimal Dipole
Allocation for certified learned Model-based Magnetically swarm control
Harness) for model-based power-optimal swarm control. This study complements
our tutorial paper on magnetically actuated swarms for the long-term formation
maintenance problem.

</details>


### [10] [Kinaema: a recurrent sequence model for memory and pose in motion](https://arxiv.org/abs/2510.20261)
*Mert Bulent Sariyildiz,Philippe Weinzaepfel,Guillaume Bono,Gianluca Monaci,Christian Wolf*

Main category: cs.RO

TL;DR: 提出Kinaema模型，能够在连续机器人操作中利用先前观察信息，通过隐式潜在记忆处理视觉观测流，预测查询图像相对于当前位置的相对位置。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在先前见过空间中准确定位的问题，优化连续机器人操作的效率，利用实际任务开始前观察到的信息。

Method: 使用基于transformer的循环模型，维护隐式潜在记忆，压缩传感器读数历史为紧凑表示，不显式存储观测历史。

Result: 模型在Mem-Nav任务中保持有用的场景表示，能够导航到实际任务开始前观察到的目标，计算效率优于传统基于观测历史注意力的transformer。

Conclusion: Kinaema模型通过隐式记忆机制有效解决了连续机器人操作中的定位问题，具有计算效率和场景表示能力优势。

Abstract: One key aspect of spatially aware robots is the ability to "find their
bearings", ie. to correctly situate themselves in previously seen spaces. In
this work, we focus on this particular scenario of continuous robotics
operations, where information observed before an actual episode start is
exploited to optimize efficiency. We introduce a new model, Kinaema, and agent,
capable of integrating a stream of visual observations while moving in a
potentially large scene, and upon request, processing a query image and
predicting the relative position of the shown space with respect to its current
position. Our model does not explicitly store an observation history, therefore
does not have hard constraints on context length. It maintains an implicit
latent memory, which is updated by a transformer in a recurrent way,
compressing the history of sensor readings into a compact representation. We
evaluate the impact of this model in a new downstream task we call "Mem-Nav".
We show that our large-capacity recurrent model maintains a useful
representation of the scene, navigates to goals observed before the actual
episode start, and is computationally efficient, in particular compared to
classical transformers with attention over an observation history.

</details>


### [11] [MemER: Scaling Up Memory for Robot Control via Experience Retrieval](https://arxiv.org/abs/2510.20328)
*Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn*

Main category: cs.RO

TL;DR: 提出了MemER分层策略框架，让机器人策略具备记忆能力。高层策略选择并跟踪历史关键帧，结合最新帧生成文本指令给底层策略执行，兼容现有VLA模型，能高效处理长时程依赖。


<details>
  <summary>Details</summary>
Motivation: 人类依赖记忆执行任务，但大多数机器人策略缺乏此能力。直接处理长观察历史计算昂贵且脆弱，而随机采样历史会导致信息冗余或不相关。

Method: 分层策略框架：高层策略训练选择跟踪历史相关关键帧，使用选定关键帧和最新帧为底层策略生成文本指令。基于Qwen2.5-VL-7B-Instruct和π0.5分别作为高低层策略进行微调。

Result: MemER在三个需要分钟级记忆的真实世界长时程机器人操作任务上优于先前方法。

Conclusion: 该框架成功赋予机器人策略记忆能力，能高效处理长时程依赖，在复杂操作任务中表现优异。

Abstract: Humans routinely rely on memory to perform tasks, yet most robot policies
lack this capability; our goal is to endow robot policies with the same
ability. Naively conditioning on long observation histories is computationally
expensive and brittle under covariate shift, while indiscriminate subsampling
of history leads to irrelevant or redundant information. We propose a
hierarchical policy framework, where the high-level policy is trained to select
and track previous relevant keyframes from its experience. The high-level
policy uses selected keyframes and the most recent frames when generating text
instructions for a low-level policy to execute. This design is compatible with
existing vision-language-action (VLA) models and enables the system to
efficiently reason over long-horizon dependencies. In our experiments, we
finetune Qwen2.5-VL-7B-Instruct and $\pi_{0.5}$ as the high-level and low-level
policies respectively, using demonstrations supplemented with minimal language
annotations. Our approach, MemER, outperforms prior methods on three real-world
long-horizon robotic manipulation tasks that require minutes of memory. Videos
and code can be found at https://jen-pan.github.io/memer/.

</details>


### [12] [Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking](https://arxiv.org/abs/2510.20335)
*Zixuan Wu,Hengyuan Zhang,Ting-Hsuan Chen,Yuliang Guo,David Paz,Xinyu Huang,Liu Ren*

Main category: cs.RO

TL;DR: 提出Dino-Diffusion Parking (DDP)方法，结合视觉基础模型和扩散规划，实现领域无关的自动驾驶停车系统，在分布偏移下保持高成功率。


<details>
  <summary>Details</summary>
Motivation: 解决端到端自动驾驶方法在领域偏移（如天气和光照变化）下的鲁棒性问题，无需额外数据即可实现跨域泛化。

Method: 集成视觉基础模型与基于扩散的运动规划，在CARLA中训练并在对抗性设置下进行零样本迁移。

Result: 在所有测试的分布外场景中停车成功率均超过90%，在3D高斯溅射重建的真实停车场环境中显示出良好的仿真到真实迁移潜力。

Conclusion: DDP通过创新的网络架构和算法设计显著提升了跨域性能，为自动驾驶停车系统提供了有效的领域无关解决方案。

Abstract: Parking is a critical pillar of driving safety. While recent end-to-end (E2E)
approaches have achieved promising in-domain results, robustness under domain
shifts (e.g., weather and lighting changes) remains a key challenge. Rather
than relying on additional data, in this paper, we propose Dino-Diffusion
Parking (DDP), a domain-agnostic autonomous parking pipeline that integrates
visual foundation models with diffusion-based planning to enable generalized
perception and robust motion planning under distribution shifts. We train our
pipeline in CARLA at regular setting and transfer it to more adversarial
settings in a zero-shot fashion. Our model consistently achieves a parking
success rate above 90% across all tested out-of-distribution (OOD) scenarios,
with ablation studies confirming that both the network architecture and
algorithmic design significantly enhance cross-domain performance over existing
baselines. Furthermore, testing in a 3D Gaussian splatting (3DGS) environment
reconstructed from a real-world parking lot demonstrates promising sim-to-real
transfer.

</details>


### [13] [Multi-Modal Decentralized Reinforcement Learning for Modular Reconfigurable Lunar Robots](https://arxiv.org/abs/2510.20347)
*Ashutosh Mishra,Shreya Santra,Elian Neppel,Edoardo M. Rossi Lombardi,Shamistan Karimov,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 提出了一种用于模块化可重构机器人的分散式强化学习方案，各模块学习独立策略，实现零样本泛化到未见配置，在仿真和月球模拟现场测试中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 模块化可重构机器人适合特定空间任务，但形态组合爆炸阻碍了统一控制，需要解决模块化系统的控制泛化问题。

Method: 采用分散式强化学习，轮式模块使用SAC进行运动控制，7自由度肢体模块使用PPO进行转向和操作控制，支持零样本泛化到新配置。

Result: 转向策略平均绝对误差3.63度，操作策略成功率84.6%，轮式策略降低95.4%扭矩同时保持99.6%成功率，现场测试验证了自主运动、转向和重构对齐功能。

Conclusion: 系统在策略执行中平滑切换同步、并行和顺序模式，无空闲状态或控制冲突，为模块化月球机器人提供了可扩展、可重用且鲁棒的方法。

Abstract: Modular reconfigurable robots suit task-specific space operations, but the
combinatorial growth of morphologies hinders unified control. We propose a
decentralized reinforcement learning (Dec-RL) scheme where each module learns
its own policy: wheel modules use Soft Actor-Critic (SAC) for locomotion and
7-DoF limbs use Proximal Policy Optimization (PPO) for steering and
manipulation, enabling zero-shot generalization to unseen configurations. In
simulation, the steering policy achieved a mean absolute error of 3.63{\deg}
between desired and induced angles; the manipulation policy plateaued at 84.6 %
success on a target-offset criterion; and the wheel policy cut average motor
torque by 95.4 % relative to baseline while maintaining 99.6 % success.
Lunar-analogue field tests validated zero-shot integration for autonomous
locomotion, steering, and preliminary alignment for reconfiguration. The system
transitioned smoothly among synchronous, parallel, and sequential modes for
Policy Execution, without idle states or control conflicts, indicating a
scalable, reusable, and robust approach for modular lunar robots.

</details>


### [14] [NeuralTouch: Neural Descriptors for Precise Sim-to-Real Tactile Robot Control](https://arxiv.org/abs/2510.20390)
*Yijiong Lin,Bowen Deng,Chenghua Lu,Max Yang,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: NeuralTouch是一个融合视觉描述符场(NDF)和触觉传感的多模态框架，通过轻柔物理交互实现精确、可泛化的抓取。


<details>
  <summary>Details</summary>
Motivation: NDF单独使用时由于相机标定不完美、点云不完整和物体变化性会产生不准确的抓取姿态，而现有触觉方法通常局限于简单预定义接触几何。

Method: 利用NDF隐式表示目标接触几何，训练基于神经描述符的深度强化学习策略，使用触觉反馈来优化抓取，无需显式指定接触类型。

Result: 在仿真和真实世界操作任务（如插孔操作和瓶盖开启）中的零样本迁移实验表明，NeuralTouch显著提高了抓取精度和鲁棒性。

Conclusion: NeuralTouch为精确、接触丰富的机器人操作提供了一个通用框架，显著优于基线方法。

Abstract: Grasping accuracy is a critical prerequisite for precise object manipulation,
often requiring careful alignment between the robot hand and object. Neural
Descriptor Fields (NDF) offer a promising vision-based method to generate
grasping poses that generalize across object categories. However, NDF alone can
produce inaccurate poses due to imperfect camera calibration, incomplete point
clouds, and object variability. Meanwhile, tactile sensing enables more precise
contact, but existing approaches typically learn policies limited to simple,
predefined contact geometries. In this work, we introduce NeuralTouch, a
multimodal framework that integrates NDF and tactile sensing to enable
accurate, generalizable grasping through gentle physical interaction. Our
approach leverages NDF to implicitly represent the target contact geometry,
from which a deep reinforcement learning (RL) policy is trained to refine the
grasp using tactile feedback. This policy is conditioned on the neural
descriptors and does not require explicit specification of contact types. We
validate NeuralTouch through ablation studies in simulation and zero-shot
transfer to real-world manipulation tasks--such as peg-out-in-hole and bottle
lid opening--without additional fine-tuning. Results show that NeuralTouch
significantly improves grasping accuracy and robustness over baseline methods,
offering a general framework for precise, contact-rich robotic manipulation.

</details>


### [15] [PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning](https://arxiv.org/abs/2510.20406)
*Xiaogang Jia,Qian Wang,Anrui Wang,Han A. Wang,Balázs Gyenes,Emiliyan Gospodinov,Xinkai Jiang,Ge Li,Hongyi Zhou,Weiran Liao,Xi Huang,Maximilian Beck,Moritz Reuss,Rudolf Lioutikov,Gerhard Neumann*

Main category: cs.RO

TL;DR: PointMapPolicy是一种新颖的扩散策略方法，将点云数据组织成结构化网格而不进行下采样，结合RGB图像实现多模态感知，在机器人操作任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 当前点云方法难以捕捉细粒度细节，而RGB方法缺乏几何感知能力，限制了机器人操作的精度和泛化能力。需要结合两种感知模态的优势。

Method: 提出PointMapPolicy方法，将点云数据组织成结构化网格（点图），不进行下采样，便于提取形状和空间关系。使用xLSTM作为骨干网络，有效融合点图和RGB数据。

Result: 在RoboCasa和CALVIN基准测试以及真实机器人评估中，该方法在多样化操作任务上实现了最先进的性能。

Conclusion: PointMapPolicy通过结构化点图表示和有效的多模态融合，显著提升了机器人操作的感知能力和任务性能。

Abstract: Robotic manipulation systems benefit from complementary sensing modalities,
where each provides unique environmental information. Point clouds capture
detailed geometric structure, while RGB images provide rich semantic context.
Current point cloud methods struggle to capture fine-grained detail, especially
for complex tasks, which RGB methods lack geometric awareness, which hinders
their precision and generalization. We introduce PointMapPolicy, a novel
approach that conditions diffusion policies on structured grids of points
without downsampling. The resulting data type makes it easier to extract shape
and spatial relationships from observations, and can be transformed between
reference frames. Yet due to their structure in a regular grid, we enable the
use of established computer vision techniques directly to 3D data. Using xLSTM
as a backbone, our model efficiently fuses the point maps with RGB data for
enhanced multi-modal perception. Through extensive experiments on the RoboCasa
and CALVIN benchmarks and real robot evaluations, we demonstrate that our
method achieves state-of-the-art performance across diverse manipulation tasks.
The overview and demos are available on our project page:
https://point-map.github.io/Point-Map/

</details>


### [16] [MR-UBi: Mixed Reality-Based Underwater Robot Arm Teleoperation System with Reaction Torque Indicator via Bilateral Control](https://arxiv.org/abs/2510.20407)
*Kohei Nishi,Masato Kobayashi,Yuki Uranishi*

Main category: cs.RO

TL;DR: 提出了一种基于混合现实的水下机器人手臂遥操作系统MR-UBi，通过双边控制和反应扭矩指示器，将视觉和触觉反馈集成在MR头显中，提高了水下机器人手臂遥操作的稳定性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决水下机器人手臂遥操作中缺乏有效反馈机制的问题，通过集成视觉和触觉反馈来改善操作精度和用户体验。

Method: 使用混合现实头显(MR-HMD)显示颜色和长度编码的扭矩条作为反应扭矩指示器(RTI)，结合双边控制技术，实现视觉和触觉反馈的集成。

Result: 用户研究表明，MR-UBi显著提高了抓取扭矩控制精度，增加了在最佳扭矩范围内的时间，减少了低和高抓取扭矩范围，在提升和拾放任务中表现更好。主观评估显示更高的可用性和更低的工作负荷。

Conclusion: MR-UBi通过视觉和触觉反馈的集成，实现了更稳定、准确和用户友好的水下机器人手臂遥操作。

Abstract: We present a mixed reality-based underwater robot arm teleoperation system
with a reaction torque indicator via bilateral control (MR-UBi). The reaction
torque indicator (RTI) overlays a color and length-coded torque bar in the
MR-HMD, enabling seamless integration of visual and haptic feedback during
underwater robot arm teleoperation. User studies with sixteen participants
compared MR-UBi against a bilateral-control baseline. MR-UBi significantly
improved grasping-torque control accuracy, increasing the time within the
optimal torque range and reducing both low and high grasping torque range
during lift and pick-and-place tasks with objects of different stiffness.
Subjective evaluations further showed higher usability (SUS) and lower workload
(NASA--TLX). Overall, the results confirm that \textit{MR-UBi} enables more
stable, accurate, and user-friendly underwater robot-arm teleoperation through
the integration of visual and haptic feedback. For additional material, please
check: https://mertcookimg.github.io/mr-ubi

</details>


### [17] [Robot Path and Trajectory Planning Considering a Spatially Fixed TCP](https://arxiv.org/abs/2510.20473)
*Bernhard Rameder,Hubert Gattringer,Andreas Mueller,Ronald Naderer*

Main category: cs.RO

TL;DR: 提出了一种在工作空间坐标中规划轨迹的方法，使用空间固定的工具中心点，同时考虑零件上的加工路径，适用于移动零件比移动工具更容易的情况。


<details>
  <summary>Details</summary>
Motivation: 当移动零件比移动工具更容易时，需要一种在工作空间坐标中规划轨迹的方法，同时考虑加工路径和给定的TCP速度。

Method: 使用B样条表示机器人路径，确保路径连续性和平滑轨迹。在计算机器人轨迹时考虑规定的方向和给定的TCP速度。

Result: 该方法在工业机器人上进行了验证，机器人移动任意定义的零件，证明了方法的有效性。

Conclusion: 提出的方法能够有效规划工作空间坐标中的轨迹，使用B样条确保路径连续平滑，适用于移动零件比移动工具更容易的加工场景。

Abstract: This paper presents a method for planning a trajectory in workspace
coordinates using a spatially fixed tool center point (TCP), while taking into
account the processing path on a part. This approach is beneficial if it is
easier to move the part rather than moving the tool. Whether a mathematical
description that defines the shape to be processed or single points from a
design program are used, the robot path is finally represented using B-splines.
The use of splines enables the path to be continuous with a desired degree,
which finally leads to a smooth robot trajectory. While calculating the robot
trajectory through prescribed orientation, additionally a given velocity at the
TCP has to be considered. The procedure was validated on a real system using an
industrial robot moving an arbitrary defined part.

</details>


### [18] [Degradation-Aware Cooperative Multi-Modal GNSS-Denied Localization Leveraging LiDAR-Based Robot Detections](https://arxiv.org/abs/2510.20480)
*Václav Pritzl,Xianjia Yu,Tomi Westerlund,Petr Štěpán,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种自适应多模态多机器人协同定位方法，使用因子图融合异步的视觉-惯性里程计、激光雷达-惯性里程计和3D机器人间检测数据，适应环境变化并应对传感器退化问题。


<details>
  <summary>Details</summary>
Motivation: 在GNSS拒止环境中，单机器人携带所有传感器会增加尺寸、重量和功耗，而多机器人分布式传感器部署虽然提高了可部署性，但带来了异步多模态数据融合的挑战。

Method: 采用因子图框架松散耦合地融合异步VIO、LIO和3D机器人间检测数据，提出基于插值的因子处理非同步测量，基于近似扫描匹配Hessian评估LIO退化，并提出基于Wasserstein距离的VIO输出权重分配方法。

Result: 在真实世界异构机器人团队（UGV和UAV）数据上的广泛评估表明，该方法在各种传感器退化情况下显著提高了定位精度。

Conclusion: 所提出的自适应多模态多机器人协同定位方法能够有效应对传感器退化问题，在GNSS拒止环境中提供显著改进的定位精度。

Abstract: Accurate long-term localization using onboard sensors is crucial for robots
operating in Global Navigation Satellite System (GNSS)-denied environments.
While complementary sensors mitigate individual degradations, carrying all the
available sensor types on a single robot significantly increases the size,
weight, and power demands. Distributing sensors across multiple robots enhances
the deployability but introduces challenges in fusing asynchronous, multi-modal
data from independently moving platforms. We propose a novel adaptive
multi-modal multi-robot cooperative localization approach using a factor-graph
formulation to fuse asynchronous Visual-Inertial Odometry (VIO), LiDAR-Inertial
Odometry (LIO), and 3D inter-robot detections from distinct robots in a
loosely-coupled fashion. The approach adapts to changing conditions, leveraging
reliable data to assist robots affected by sensory degradations. A novel
interpolation-based factor enables fusion of the unsynchronized measurements.
LIO degradations are evaluated based on the approximate scan-matching Hessian.
A novel approach of weighting odometry data proportionally to the Wasserstein
distance between the consecutive VIO outputs is proposed. A theoretical
analysis is provided, investigating the cooperative localization problem under
various conditions, mainly in the presence of sensory degradations. The
proposed method has been extensively evaluated on real-world data gathered with
heterogeneous teams of an Unmanned Ground Vehicle (UGV) and Unmanned Aerial
Vehicles (UAVs), showing that the approach provides significant improvements in
localization accuracy in the presence of various sensory degradations.

</details>


### [19] [Dual Control Reference Generation for Optimal Pick-and-Place Execution under Payload Uncertainty](https://arxiv.org/abs/2510.20483)
*Victor Vantilborgh,Hrishikesh Sathyanarayan,Guillaume Crevecoeur,Ian Abraham,Tom Lefebvre*

Main category: cs.RO

TL;DR: 提出两种方法解决机器人操作任务中的未知动力学问题，通过结合主动探索和在线参数自适应来提高模型控制精度。


<details>
  <summary>Details</summary>
Motivation: 解决在未知动力学（如有效载荷不确定性）下机器人操作任务的问题，需要主动探索和在线参数自适应来实现精确的基于模型的控制。

Method: 将问题构建为双控制问题，预定义反馈策略结构包含显式自适应机制。提出两种参考轨迹生成方法：一种在鲁棒最优控制中嵌入参数不确定性，另一种最小化最优性损失。

Result: 两种方法都自然地考虑了Fisher信息，同时追求最优任务执行。在拾放操作任务中展示了方法的有效性，能够实现更快更准确的任务执行和系统辨识。

Conclusion: 在考虑控制的同时设计参考轨迹，能够实现更快更准确的任务性能和系统辨识，同时确保稳定高效的控制。

Abstract: This work addresses the problem of robot manipulation tasks under unknown
dynamics, such as pick-and-place tasks under payload uncertainty, where active
exploration and(/for) online parameter adaptation during task execution are
essential to enable accurate model-based control. The problem is framed as dual
control seeking a closed-loop optimal control problem that accounts for
parameter uncertainty. We simplify the dual control problem by pre-defining the
structure of the feedback policy to include an explicit adaptation mechanism.
Then we propose two methods for reference trajectory generation. The first
directly embeds parameter uncertainty in robust optimal control methods that
minimize the expected task cost. The second method considers minimizing the
so-called optimality loss, which measures the sensitivity of parameter-relevant
information with respect to task performance. We observe that both approaches
reason over the Fisher information as a natural side effect of their
formulations, simultaneously pursuing optimal task execution. We demonstrate
the effectiveness of our approaches for a pick-and-place manipulation task. We
show that designing the reference trajectories whilst taking into account the
control enables faster and more accurate task performance and system
identification while ensuring stable and efficient control.

</details>


### [20] [Simultaneous Stiffness and Trajectory Optimization for Energy Minimization of Pick-and-Place Tasks of SEA-Actuated Parallel Kinematic Manipulators](https://arxiv.org/abs/2510.20490)
*Thomas Kordik,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文研究如何通过优化轨迹和串联弹性驱动器(SEA)刚度来最小化执行拾放任务的并联机器人能量消耗，利用弹性元件的固有振动特性实现节能。


<details>
  <summary>Details</summary>
Motivation: 工业机器人执行拾放任务通常需要长时间运行，因此最小化能耗具有重要意义。串联弹性驱动器(SEA)的弹性特性为实现节能提供了可能。

Method: 推导SEA驱动并联机器人的动力学模型，建立能量最小化的最优控制问题，同时优化操作轨迹和SEA刚度参数，并在两个并联机器人应用上进行验证。

Result: 研究结果证实了通过激发固有振动和优化SEA刚度能够有效降低能量消耗的方法有效性。

Conclusion: 利用SEA的弹性特性和优化控制方法可以显著降低执行拾放任务的并联机器人能耗，为工业机器人节能设计提供了有效途径。

Abstract: A major field of industrial robot applications deals with repetitive tasks
that alternate between operating points. For these so-called pick-and-place
operations, parallel kinematic manipulators (PKM) are frequently employed.
These tasks tend to automatically run for a long period of time and therefore
minimizing energy consumption is always of interest. Recent research addresses
this topic by the use of elastic elements and particularly series elastic
actuators (SEA). This paper explores the possibilities of minimizing energy
consumption of SEA actuated PKM performing pick-and-place tasks. The basic idea
is to excite eigenmotions that result from the actuator springs and exploit
their oscillating characteristics. To this end, a prescribed cyclic
pick-and-place operation is analyzed and a dynamic model of SEA driven PKM is
derived. Subsequently, an energy minimizing optimal control problem is
formulated where operating trajectories as well as SEA stiffnesses are
optimized simultaneously. Here, optimizing the actuator stiffness does not
account for variable stiffness actuators. It serves as a tool for the design
and dimensioning process. The hypothesis on energy reduction is tested on two
(parallel) robot applications where redundant actuation is also addressed. The
results confirm the validity of this approach.

</details>


### [21] [A Parameter-Linear Formulation of the Optimal Path Following Problem for Robotic Manipulator](https://arxiv.org/abs/2510.20496)
*Tobias Marauli,Hubert Gattringer,Andreas Mueller*

Main category: cs.RO

TL;DR: 本文提出了一种基于最大化路径速度的时间最优路径跟踪方法，避免了传统方法在零路径速度处的奇异性问题，能够高效生成平滑轨迹。


<details>
  <summary>Details</summary>
Motivation: 传统时间最优路径跟踪方法在将优化问题重新参数化为路径参数时，在零路径速度处会产生奇异性，导致平滑轨迹生成困难且计算量大。

Method: 采用最大化路径速度的方法，将底层问题离散化后重新表述为优化变量的线性问题，从而实现数值高效计算。

Result: 该方法能够有效规划平滑轨迹，同时保持较低的计算复杂度，解决了传统方法中的奇异性问题。

Conclusion: 提出的最大化路径速度方法为时间最优路径跟踪提供了一种计算高效且能生成平滑轨迹的替代方案。

Abstract: In this paper the computational challenges of time-optimal path following are
addressed. The standard approach is to minimize the travel time, which
inevitably leads to singularities at zero path speed, when reformulating the
optimization problem in terms of a path parameter. Thus, smooth trajectory
generation while maintaining a low computational effort is quite challenging,
since the singularities have to be taken into account. To this end, a different
approach is presented in this paper. This approach is based on maximizing the
path speed along a prescribed path. Furthermore, the approach is capable of
planning smooth trajectories numerically efficient. Moreover, the discrete
reformulation of the underlying problem is linear in optimization variables.

</details>


### [22] [RubbleSim: A Photorealistic Structural Collapse Simulator for Confined Space Mapping](https://arxiv.org/abs/2510.20529)
*Constantine Frost,Chad Council,Margaret McGuinness,Nathaniel Hanson*

Main category: cs.RO

TL;DR: 提出了RubbleSim——一个开源、可重构的模拟器，用于在灾难响应中模拟结构坍塌内部空洞空间的光真实感探索，以解决实际数据获取困难的问题。


<details>
  <summary>Details</summary>
Motivation: 由于法律约束和机构所有权问题，实际灾难响应中结构坍塌内部空洞空间的数据难以获取，而训练场地也不愿公开其专有信息，因此需要开发模拟器来克服这一访问挑战。

Method: 使用Unity开发多操作系统支持的模拟器，采用基于物理的方法构建随机碎石堆，允许在模拟世界之间快速迭代，同时保留绝对的地面真实数据。

Result: 应用最先进的结构从运动算法，展示了在模拟空洞空间中具有挑战性的视觉条件下感知性能如何下降。

Conclusion: RubbleSim为灾难响应中的空洞空间探索提供了一个有效的开源模拟平台，有助于研究在恶劣视觉条件下的感知性能问题。

Abstract: Despite well-reported instances of robots being used in disaster response,
there is scant published data on the internal composition of the void spaces
within structural collapse incidents. Data collected during these incidents is
mired in legal constraints, as ownership is often tied to the responding
agencies, with little hope of public release for research. While engineered
rubble piles are used for training, these sites are also reluctant to release
information about their proprietary training grounds. To overcome this access
challenge, we present RubbleSim -- an open-source, reconfigurable simulator for
photorealistic void space exploration. The design of the simulation assets is
directly informed by visits to numerous training rubble sites at differing
levels of complexity. The simulator is implemented in Unity with
multi-operating system support. The simulation uses a physics-based approach to
build stochastic rubble piles, allowing for rapid iteration between simulation
worlds while retaining absolute knowledge of the ground truth. Using RubbleSim,
we apply a state-of-the-art structure-from-motion algorithm to illustrate how
perception performance degrades under challenging visual conditions inside the
emulated void spaces. Pre-built binaries and source code to implement are
available online: https://github.com/mit-ll/rubble_pile_simulator.

</details>


### [23] [C-NAV: Towards Self-Evolving Continual Object Navigation in Open World](https://arxiv.org/abs/2510.20685)
*Ming-Ming Yu,Fei Zhu,Wenzhuo Liu,Yirong Yang,Qunbo Wang,Wenjun Wu,Jing Liu*

Main category: cs.RO

TL;DR: 提出了C-Nav框架解决持续物体导航问题，通过双路径防遗忘机制和自适应采样策略，在避免灾难性遗忘的同时显著降低内存需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态轨迹和固定物体类别训练，忽视了现实世界中对动态场景持续适应的需求。

Method: C-Nav框架包含：1）双路径防遗忘机制（特征蒸馏和特征回放）；2）自适应采样策略选择多样化和信息丰富的经验。

Result: 在多个模型架构上的实验表明，C-Nav持续优于现有方法，即使与保留完整轨迹的基线相比也表现更优，同时显著降低内存需求。

Conclusion: C-Nav为持续物体导航提供了有效的解决方案，在性能和内存效率方面都表现出色。

Abstract: Embodied agents are expected to perform object navigation in dynamic,
open-world environments. However, existing approaches typically rely on static
trajectories and a fixed set of object categories during training, overlooking
the real-world requirement for continual adaptation to evolving scenarios. To
facilitate related studies, we introduce the continual object navigation
benchmark, which requires agents to acquire navigation skills for new object
categories while avoiding catastrophic forgetting of previously learned
knowledge. To tackle this challenge, we propose C-Nav, a continual visual
navigation framework that integrates two key innovations: (1) A dual-path
anti-forgetting mechanism, which comprises feature distillation that aligns
multi-modal inputs into a consistent representation space to ensure
representation consistency, and feature replay that retains temporal features
within the action decoder to ensure policy consistency. (2) An adaptive
sampling strategy that selects diverse and informative experiences, thereby
reducing redundancy and minimizing memory overhead. Extensive experiments
across multiple model architectures demonstrate that C-Nav consistently
outperforms existing approaches, achieving superior performance even compared
to baselines with full trajectory retention, while significantly lowering
memory requirements. The code will be publicly available at
https://bigtree765.github.io/C-Nav-project.

</details>


### [24] [Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning](https://arxiv.org/abs/2510.20706)
*Ganga Nair B,Prakrut Kotecha,Shishir Kolathaya*

Main category: cs.RO

TL;DR: 提出了一种结合模型预测路径积分(MPPI)和Dreamer模块的优化框架，用于四足机器人在连续步态空间中的实时步态自适应，显著降低能耗并保持精确跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决传统模型自由强化学习策略收敛到单一步态导致性能次优，以及模型预测控制无法适应多变环境的问题。

Method: 在每个时间步，MPPI联合优化动作和步态变量，使用学习的Dreamer奖励函数促进速度跟踪、能效、稳定性和平滑过渡，同时惩罚剧烈步态变化。结合学习值函数作为终端奖励，扩展到无限时域规划器。

Result: 在Unitree Go1仿真中测试，在不同目标速度下平均能耗降低高达36.48%，同时保持精确跟踪和自适应、任务适当的步态。

Conclusion: 该框架成功实现了四足机器人的自适应和最优步态控制，结合了强化学习的适应性和模型预测控制的最优性优势。

Abstract: Model-free reinforcement learning (RL) has enabled adaptable and agile
quadruped locomotion; however, policies often converge to a single gait,
leading to suboptimal performance. Traditionally, Model Predictive Control
(MPC) has been extensively used to obtain task-specific optimal policies but
lacks the ability to adapt to varying environments. To address these
limitations, we propose an optimization framework for real-time gait adaptation
in a continuous gait space, combining the Model Predictive Path Integral (MPPI)
algorithm with a Dreamer module to produce adaptive and optimal policies for
quadruped locomotion. At each time step, MPPI jointly optimizes the actions and
gait variables using a learned Dreamer reward that promotes velocity tracking,
energy efficiency, stability, and smooth transitions, while penalizing abrupt
gait changes. A learned value function is incorporated as terminal reward,
extending the formulation to an infinite-horizon planner. We evaluate our
framework in simulation on the Unitree Go1, demonstrating an average reduction
of up to 36.48\% in energy consumption across varying target speeds, while
maintaining accurate tracking and adaptive, task-appropriate gaits.

</details>


### [25] [FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation](https://arxiv.org/abs/2510.20774)
*Wenhao Wang,Kehe Ye,Xinyu Zhou,Tianxing Chen,Cao Min,Qiaoming Zhu,Xiaokang Yang,Yongjian Shen,Yang Yang,Maoqing Yao,Yao Mu*

Main category: cs.RO

TL;DR: FieldGen是一个场引导的数据生成框架，通过分解操作任务为预操作和精细操作两个阶段，结合人类演示的关键信息和自动生成的多样化轨迹，实现了可扩展、多样化且高质量的真实世界数据收集。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作数据收集方法难以平衡规模、多样性和质量。仿真方法可扩展但存在仿真到真实的差距，遥操作方法质量高但多样性有限且人工成本高。

Method: 将操作任务分解为预操作阶段（允许轨迹多样性）和精细操作阶段（需要专家精度）。通过人类演示捕获关键接触和姿态信息，然后使用吸引力场自动生成多样化轨迹并收敛到成功配置。

Result: 实验表明，使用FieldGen训练的策略相比基于遥操作的基线方法，实现了更高的成功率和改进的稳定性，同时显著减少了长期真实世界数据收集的人工工作量。

Conclusion: FieldGen通过解耦设计结合了可扩展的轨迹多样性和精确监督，为机器人操作策略学习提供了高效的数据生成解决方案。

Abstract: Large-scale and diverse datasets are vital for training robust robotic
manipulation policies, yet existing data collection methods struggle to balance
scale, diversity, and quality. Simulation offers scalability but suffers from
sim-to-real gaps, while teleoperation yields high-quality demonstrations with
limited diversity and high labor cost. We introduce FieldGen, a field-guided
data generation framework that enables scalable, diverse, and high-quality
real-world data collection with minimal human supervision. FieldGen decomposes
manipulation into two stages: a pre-manipulation phase, allowing trajectory
diversity, and a fine manipulation phase requiring expert precision. Human
demonstrations capture key contact and pose information, after which an
attraction field automatically generates diverse trajectories converging to
successful configurations. This decoupled design combines scalable trajectory
diversity with precise supervision. Moreover, FieldGen-Reward augments
generated data with reward annotations to further enhance policy learning.
Experiments demonstrate that policies trained with FieldGen achieve higher
success rates and improved stability compared to teleoperation-based baselines,
while significantly reducing human effort in long-term real-world data
collection. Webpage is available at https://fieldgen.github.io/.

</details>


### [26] [The Reality Gap in Robotics: Challenges, Solutions, and Best Practices](https://arxiv.org/abs/2510.20808)
*Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos*

Main category: cs.RO

TL;DR: 这篇论文是关于机器人学中模拟到现实迁移的综述，重点讨论了现实差距问题及其解决方案。


<details>
  <summary>Details</summary>
Motivation: 机器学习的进步推动了机器人在导航、运动和操作等领域的发展，但模拟环境与现实世界之间存在差异（现实差距），这阻碍了从模拟到现实的成功迁移。解决这一差距是机器人学中最紧迫的挑战之一。

Method: 论文采用综述方法，全面分析了模拟到现实迁移的现状，包括现实差距的原因、解决方案和评估指标。

Result: 研究表明，通过领域随机化、真实到模拟迁移、状态和动作抽象以及模拟-现实协同训练等技术，许多工作已经克服了现实差距，并在各种平台上取得了有希望的结果。

Conclusion: 尽管已有进展，但现实差距的挑战仍然存在，需要更深入地理解其根本原因和解决方案。这篇综述为模拟到现实迁移领域提供了全面的概览。

Abstract: Machine learning has facilitated significant advancements across various
robotics domains, including navigation, locomotion, and manipulation. Many such
achievements have been driven by the extensive use of simulation as a critical
tool for training and testing robotic systems prior to their deployment in
real-world environments. However, simulations consist of abstractions and
approximations that inevitably introduce discrepancies between simulated and
real environments, known as the reality gap. These discrepancies significantly
hinder the successful transfer of systems from simulation to the real world.
Closing this gap remains one of the most pressing challenges in robotics.
Recent advances in sim-to-real transfer have demonstrated promising results
across various platforms, including locomotion, navigation, and manipulation.
By leveraging techniques such as domain randomization, real-to-sim transfer,
state and action abstractions, and sim-real co-training, many works have
overcome the reality gap. However, challenges persist, and a deeper
understanding of the reality gap's root causes and solutions is necessary. In
this survey, we present a comprehensive overview of the sim-to-real landscape,
highlighting the causes, solutions, and evaluation metrics for the reality gap
and sim-to-real transfer.

</details>


### [27] [GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation](https://arxiv.org/abs/2510.20813)
*Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: GSWorld是一个结合3D高斯泼溅和物理引擎的机器人操作模拟器，支持从真实机器人数据学习策略和sim2real策略训练，无需使用真实机器人。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够"闭环"开发机器人操作策略的模拟器，实现从真实机器人数据学习策略的可复现评估和sim2real策略训练，避免使用真实机器人。

Method: 提出GSDF（高斯场景描述文件）资产格式，将高斯-网格表示与机器人URDF和其他对象融合，通过简化的重建流程构建包含3种机器人配置和40多个物体的数据库。

Result: 展示了多个应用：零样本sim2real像素到动作策略学习、自动化高质量DAgger数据收集、真实机器人策略的可复现基准测试、虚拟遥操作模拟数据收集、零样本sim2real视觉强化学习。

Conclusion: GSWorld为机器人操作提供了一个强大、逼真的模拟平台，支持多种sim2real应用，推动了机器人策略开发的可复现性和效率。

Abstract: This paper presents GSWorld, a robust, photo-realistic simulator for robotics
manipulation that combines 3D Gaussian Splatting with physics engines. Our
framework advocates "closing the loop" of developing manipulation policies with
reproducible evaluation of policies learned from real-robot data and sim2real
policy training without using real robots. To enable photo-realistic rendering
of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian
Scene Description File), that infuses Gaussian-on-Mesh representation with
robot URDF and other objects. With a streamlined reconstruction pipeline, we
curate a database of GSDF that contains 3 robot embodiments for single-arm and
bimanual manipulation, as well as more than 40 objects. Combining GSDF with
physics engines, we demonstrate several immediate interesting applications: (1)
learning zero-shot sim2real pixel-to-action manipulation policy with
photo-realistic rendering, (2) automated high-quality DAgger data collection
for adapting policies to deployment environments, (3) reproducible benchmarking
of real-robot manipulation policies in simulation, (4) simulation data
collection by virtual teleoperation, and (5) zero-shot sim2real visual
reinforcement learning. Website: https://3dgsworld.github.io/.

</details>


### [28] [VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation](https://arxiv.org/abs/2510.20818)
*Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta*

Main category: cs.RO

TL;DR: VAMOS是一个分层视觉语言导航系统，通过将语义规划与具体化接地分离，实现了跨不同机器人平台的高效导航。


<details>
  <summary>Details</summary>
Motivation: 解决机器人导航中学习策略在不同环境间泛化，同时适应特定机器人物理约束和能力的根本挑战。

Method: 使用分层VLA架构：通用规划器从多样化开放世界数据学习，专门化可供性模型在低成本模拟中学习机器人物理约束，通过图像空间路径提议和评估实现解耦。

Result: 在真实世界实验中，VAMOS在室内和复杂户外导航中比最先进的基于模型和端到端学习方法获得更高成功率，支持轮式和腿式机器人跨平台导航，通过拒绝物理不可行计划使单机器人可靠性提高3倍。

Conclusion: 分层设计是实现跨具体化导航的关键，专门化模型对于具体化接地至关重要，使单个高层规划器能够部署在物理上不同的机器人上。

Abstract: A fundamental challenge in robot navigation lies in learning policies that
generalize across diverse environments while conforming to the unique physical
constraints and capabilities of a specific embodiment (e.g., quadrupeds can
walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that
decouples semantic planning from embodiment grounding: a generalist planner
learns from diverse, open-world data, while a specialist affordance model
learns the robot's physical constraints and capabilities in safe, low-cost
simulation. We enabled this separation by carefully designing an interface that
lets a high-level planner propose candidate paths directly in image space that
the affordance model then evaluates and re-ranks. Our real-world experiments
show that VAMOS achieves higher success rates in both indoor and complex
outdoor navigation than state-of-the-art model-based and end-to-end learning
methods. We also show that our hierarchical design enables cross-embodied
navigation across legged and wheeled robots and is easily steerable using
natural language. Real-world ablations confirm that the specialist model is key
to embodiment grounding, enabling a single high-level planner to be deployed
across physically distinct wheeled and legged robots. Finally, this model
significantly enhances single-robot reliability, achieving 3X higher success
rates by rejecting physically infeasible plans. Website:
https://vamos-vla.github.io/

</details>
