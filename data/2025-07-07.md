<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 20]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Effective Explanations for Belief-Desire-Intention Robots: When and What to Explain](https://arxiv.org/abs/2507.02016)
*Cong Wang,Roberto Calandra,Verena Klös*

Main category: cs.RO

TL;DR: 研究探讨了机器人执行任务时如何通过解释其推理过程减少用户困惑，提出两种算法用于识别意外行为并生成有效解释。


<details>
  <summary>Details</summary>
Motivation: 机器人执行复杂任务时，用户可能因行为偏离预期而困惑，解释其意图可改善理解，但需注意时机和内容以避免用户反感。

Method: 调查用户对解释需求和内容的偏好，提出两种算法识别意外行为并构建解释，适用于BDI机器人。

Result: 用户希望在意外情况下获得简洁解释，明确意图和相关上下文因素。

Conclusion: 提出的算法可集成到BDI推理中，提升人机交互体验。

Abstract: When robots perform complex and context-dependent tasks in our daily lives,
deviations from expectations can confuse users. Explanations of the robot's
reasoning process can help users to understand the robot intentions. However,
when to provide explanations and what they contain are important to avoid user
annoyance. We have investigated user preferences for explanation demand and
content for a robot that helps with daily cleaning tasks in a kitchen. Our
results show that users want explanations in surprising situations and prefer
concise explanations that clearly state the intention behind the confusing
action and the contextual factors that were relevant to this decision. Based on
these findings, we propose two algorithms to identify surprising actions and to
construct effective explanations for Belief-Desire-Intention (BDI) robots. Our
algorithms can be easily integrated in the BDI reasoning process and pave the
way for better human-robot interaction with context- and user-specific
explanations.

</details>


### [2] [RoboBrain 2.0 Technical Report](https://arxiv.org/abs/2507.02029)
*BAAI RoboBrain Team,Mingyu Cao,Huajie Tan,Yuheng Ji,Minglan Lin,Zhiyu Li,Zhou Cao,Pengwei Wang,Enshen Zhou,Yi Han,Yingbo Tang,Xiangqi Xu,Wei Guo,Yaoxu Lyu,Yijie Xu,Jiayu Shi,Cheng Chi,Mengdi Zhao,Xiaoshuai Hao,Shanyu Rong,Zhengliang Cai,Bolun Zhang,Shuyi Zhang,Huaihai Lyu,Mengfei Du,Lingfeng Zhang,Xi Feng,Xiaodan Liu,Yance Jiao,Chenrui He,Mengsi Lyu,Zhuo Chen,Yulong Ao,Xue Sun,Zheqi He,Jingshu Zheng,Xi Yang,Donghai Shi,Kunchang Xie,Bochao Zhang,Shaokai Nie,Chunlei Men,Yonghua Lin,Zhongyuan Wang,Tiejun Huang,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboBrain 2.0是一种新型的视觉语言基础模型，专注于物理环境中的感知、推理和规划，提供7B和32B两种变体，性能优越。


<details>
  <summary>Details</summary>
Motivation: 旨在统一复杂任务中的感知、推理和规划，推动具身AI研究。

Method: 采用异构架构，结合视觉编码器和语言模型，通过多阶段训练策略优化。

Result: 32B变体在空间和时间基准测试中表现领先，支持空间理解和时间决策能力。

Conclusion: RoboBrain 2.0为具身AI研究提供了实用工具，代码和模型已开源。

Abstract: We introduce RoboBrain 2.0, our latest generation of embodied vision-language
foundation models, designed to unify perception, reasoning, and planning for
complex embodied tasks in physical environments. It comes in two variants: a
lightweight 7B model and a full-scale 32B model, featuring a heterogeneous
architecture with a vision encoder and a language model. Despite its compact
size, RoboBrain 2.0 achieves strong performance across a wide spectrum of
embodied reasoning tasks. On both spatial and temporal benchmarks, the 32B
variant achieves leading results, surpassing prior open-source and proprietary
models. In particular, it supports key real-world embodied AI capabilities,
including spatial understanding (e.g., affordance prediction, spatial
referring, trajectory forecasting) and temporal decision-making (e.g.,
closed-loop interaction, multi-agent long-horizon planning, and scene graph
updating). This report details the model architecture, data construction,
multi-stage training strategies, infrastructure and practical applications. We
hope RoboBrain 2.0 advances embodied AI research and serves as a practical step
toward building generalist embodied agents. The code, checkpoint and benchmark
are available at https://superrobobrain.github.io.

</details>


### [3] [Towards Bio-Inspired Robotic Trajectory Planning via Self-Supervised RNN](https://arxiv.org/abs/2507.02171)
*Miroslav Cibula,Kristína Malinovská,Matthias Kerzel*

Main category: cs.RO

TL;DR: 论文提出了一种基于认知启发的自监督学习方案，用于机器人轨迹规划，通过循环架构构建轨迹模型，避免了传统采样规划的高计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统采样规划方法计算量大，而完全监督方法仅模仿轨迹，无法学习是否成功达到目标。因此，需要一种更高效且能自适应学习的方法。

Method: 采用自监督学习方案，基于循环架构构建轨迹模型，利用正向和逆向运动学模型生成轨迹。

Result: 模型能够仅通过给定的正向和逆向运动学模型学习生成轨迹，适用于需要自适应解决方案的复杂任务。

Conclusion: 该方法为复杂机器人操作任务提供了一种高效且自适应的轨迹规划解决方案。

Abstract: Trajectory planning in robotics is understood as generating a sequence of
joint configurations that will lead a robotic agent, or its manipulator, from
an initial state to the desired final state, thus completing a manipulation
task while considering constraints like robot kinematics and the environment.
Typically, this is achieved via sampling-based planners, which are
computationally intensive. Recent advances demonstrate that trajectory planning
can also be performed by supervised sequence learning of trajectories, often
requiring only a single or fixed number of passes through a neural
architecture, thus ensuring a bounded computation time. Such fully supervised
approaches, however, perform imitation learning; they do not learn based on
whether the trajectories can successfully reach a goal, but try to reproduce
observed trajectories. In our work, we build on this approach and propose a
cognitively inspired self-supervised learning scheme based on a recurrent
architecture for building a trajectory model. We evaluate the feasibility of
the proposed method on a task of kinematic planning for a robotic arm. The
results suggest that the model is able to learn to generate trajectories only
using given paired forward and inverse kinematics models, and indicate that
this novel method could facilitate planning for more complex manipulation tasks
requiring adaptive solutions.

</details>


### [4] [cVLA: Towards Efficient Camera-Space VLAs](https://arxiv.org/abs/2507.02190)
*Max Argus,Jelena Bratulic,Houman Masnavi,Maxim Velikanov,Nick Heppert,Abhinav Valada,Thomas Brox*

Main category: cs.RO

TL;DR: 提出一种轻量级的VLA模型，通过预测轨迹路径点而非低级控制信号，提高训练效率并适应不同机器人。


<details>
  <summary>Details</summary>
Motivation: 解决传统VLA模型训练成本高的问题，同时利用VLMs在2D图像上的性能优势。

Method: 采用基于轨迹路径点预测的轻量级架构，结合深度图像和解码策略，支持演示条件动作生成。

Result: 模型在仿真和真实数据上均表现良好，具备较强的仿真到现实的迁移能力。

Conclusion: 该方法高效、轻量且适应性强，为复杂机器人操作任务提供了新思路。

Abstract: Vision-Language-Action (VLA) models offer a compelling framework for tackling
complex robotic manipulation tasks, but they are often expensive to train. In
this paper, we propose a novel VLA approach that leverages the competitive
performance of Vision Language Models (VLMs) on 2D images to directly infer
robot end-effector poses in image frame coordinates. Unlike prior VLA models
that output low-level controls, our model predicts trajectory waypoints, making
it both more efficient to train and robot embodiment agnostic. Despite its
lightweight design, our next-token prediction architecture effectively learns
meaningful and executable robot trajectories. We further explore the
underutilized potential of incorporating depth images, inference-time
techniques such as decoding strategies, and demonstration-conditioned action
generation. Our model is trained on a simulated dataset and exhibits strong
sim-to-real transfer capabilities. We evaluate our approach using a combination
of simulated and real data, demonstrating its effectiveness on a real robotic
system.

</details>


### [5] [GPS-DRIFT: Marine Surface Robot Localization using IMU-GPS Fusion and Invariant Filtering](https://arxiv.org/abs/2507.02198)
*Surya Pratap Singh,Tsimafei Lazouski,Maani Ghaffari*

Main category: cs.RO

TL;DR: 扩展DRIFT框架，结合GPS与IMU数据，实现精确位姿和航向估计，适用于海洋自主水面车辆及其他移动系统。


<details>
  <summary>Details</summary>
Motivation: 解决航向（yaw）在惯性导航中的不可观测性问题，提供漂移无关的定位和可靠航向估计。

Method: 基于DRIFT算法，引入对称保持传感器融合流程，利用InEKF整合GPS全局位置更新，并提出新颖的航向校正机制。

Result: 在BlueBoat上验证，实现精确航向观测和定位，适用于GPS信号受限环境。

Conclusion: 提供开源解决方案，为未来实验和比较研究奠定基础。

Abstract: This paper presents an extension of the DRIFT invariant state estimation
framework, enabling robust fusion of GPS and IMU data for accurate pose and
heading estimation. Originally developed for testing and usage on a marine
autonomous surface vehicle (ASV), this approach can also be utilized on other
mobile systems. Building upon the original proprioceptive only DRIFT algorithm,
we develop a symmetry-preserving sensor fusion pipeline utilizing the invariant
extended Kalman filter (InEKF) to integrate global position updates from GPS
directly into the correction step. Crucially, we introduce a novel heading
correction mechanism that leverages GPS course-over-ground information in
conjunction with IMU orientation, overcoming the inherent unobservability of
yaw in dead-reckoning. The system was deployed and validated on a customized
Blue Robotics BlueBoat, but the methodological focus is on the algorithmic
approach to fusing exteroceptive and proprioceptive sensors for drift-free
localization and reliable orientation estimation. This work provides an open
source solution for accurate yaw observation and localization in challenging or
GPS-degraded conditions, and lays the groundwork for future experimental and
comparative studies.

</details>


### [6] [CoInfra: A Large-Scale Cooperative Infrastructure Perception System and Dataset in Adverse Weather](https://arxiv.org/abs/2507.02245)
*Minghao Ning,Yufeng Yang,Keqi Shu,Shucheng Huang,Jiaming Zhong,Maryam Salehi,Mahdi Rahmani,Yukun Lu,Chen Sun,Aladdin Saleh,Ehsan Hashemi,Amir Khajepour*

Main category: cs.RO

TL;DR: CoInfra是一个大规模协作基础设施感知系统与数据集，旨在提升多智能体在真实世界及恶劣天气条件下的感知能力。


<details>
  <summary>Details</summary>
Motivation: 推动在真实世界和恶劣天气条件下的多智能体感知研究。

Method: 系统包括14个完全同步的传感器节点，配备双RGB摄像头和LiDAR，提供实时数据融合和远程管理。数据集包含多种天气条件下的195k LiDAR帧和390k相机图像。

Result: 展示了早期与晚期融合策略的权衡，并讨论了高精地图集成的显著优势。

Conclusion: 通过公开数据集和系统文档，促进基础设施支持的自动驾驶研究，特别是在挑战性环境中。

Abstract: We present CoInfra, a large-scale cooperative infrastructure perception
system and dataset designed to advance robust multi-agent perception under
real-world and adverse weather conditions. The CoInfra system includes 14 fully
synchronized sensor nodes, each equipped with dual RGB cameras and a LiDAR,
deployed across a shared region and operating continuously to capture all
traffic participants in real-time. A robust, delay-aware synchronization
protocol and a scalable system architecture that supports real-time data
fusion, OTA management, and remote monitoring are provided in this paper. On
the other hand, the dataset was collected in different weather scenarios,
including sunny, rainy, freezing rain, and heavy snow and includes 195k LiDAR
frames and 390k camera images from 8 infrastructure nodes that are globally
time-aligned and spatially calibrated. Furthermore, comprehensive 3D bounding
box annotations for five object classes (i.e., car, bus, truck, person, and
bicycle) are provided in both global and individual node frames, along with
high-definition maps for contextual understanding. Baseline experiments
demonstrate the trade-offs between early and late fusion strategies, the
significant benefits of HD map integration are discussed. By openly releasing
our dataset, codebase, and system documentation at
https://github.com/NingMingHao/CoInfra, we aim to enable reproducible research
and drive progress in infrastructure-supported autonomous driving, particularly
in challenging, real-world settings.

</details>


### [7] [A Vehicle-in-the-Loop Simulator with AI-Powered Digital Twins for Testing Automated Driving Controllers](https://arxiv.org/abs/2507.02313)
*Zengjie Zhang,Giannis Badakis,Michalis Galanis,Adem Bavarşi,Edwin van Hassel,Mohsen Alirezaei,Sofie Haesaert*

Main category: cs.RO

TL;DR: 该论文提出了一种结合缩小比例物理车和AI驱动的数字孪生模型的模拟器，用于高效、低成本地测试自动驾驶控制器。


<details>
  <summary>Details</summary>
Motivation: 传统车辆在环测试需要大型空间和高成本，而基于物理模型的数字孪生存在精度不足的问题。

Method: 开发了一种结合缩小比例物理车和AI驱动的数字孪生模型的模拟器，并与现有软件和控制算法集成。

Result: 实验证明了模拟器的高效性和高仿真保真度，能够验证自动驾驶控制器的安全性。

Conclusion: 该模拟器在自动驾驶和智能交通控制验证中具有巨大潜力。

Abstract: Simulators are useful tools for testing automated driving controllers.
Vehicle-in-the-loop (ViL) tests and digital twins (DTs) are widely used
simulation technologies to facilitate the smooth deployment of controllers to
physical vehicles. However, conventional ViL tests rely on full-size vehicles,
requiring large space and high expenses. Also, physical-model-based DT suffers
from the reality gap caused by modeling imprecision. This paper develops a
comprehensive and practical simulator for testing automated driving controllers
enhanced by scaled physical cars and AI-powered DT models. The scaled cars
allow for saving space and expenses of simulation tests. The AI-powered DT
models ensure superior simulation fidelity. Moreover, the simulator integrates
well with off-the-shelf software and control algorithms, making it easy to
extend. We use a filtered control benchmark with formal safety guarantees to
showcase the capability of the simulator in validating automated driving
controllers. Experimental studies are performed to showcase the efficacy of the
simulator, implying its great potential in validating control solutions for
autonomous vehicles and intelligent traffic.

</details>


### [8] [Path Planning using a One-shot-sampling Skeleton Map](https://arxiv.org/abs/2507.02328)
*Gabriel O. Flores-Aquino,Octavio Gutierrez-Frias,Juan Irving Vasquez*

Main category: cs.RO

TL;DR: 提出了一种基于深度去噪自编码器（DDAE）和U-Net架构的高效路径规划方法SkelUnet，用于快速生成骨架化导航地图，并在无人机模拟环境中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统骨架化算法资源消耗大且主要面向图像处理，而路径规划需要平衡响应时间、安全性和路径长度，因此需要一种更高效的方法。

Method: 利用基于U-Net的DDAE（SkelUnet）一次性生成骨架化导航地图，替代传统迭代或概率采样方法，并在12,500张二维地图上训练和测试。

Result: 在250张未见地图的无人机模拟环境中，SkelUnet显著提高了路径安全性、连通性和处理速度。

Conclusion: SkelUnet方法适用于结构化环境中的移动服务机器人，因其高效性和安全性优势。

Abstract: Path planning algorithms aim to compute a collision-free path, and many works
focus on finding the optimal distance path. However, for some applications, a
more suitable approach is to balance response time, safety of the paths, and
path length. In this context, a skeleton map is a useful tool in graph-based
schemes, as it provides an intrinsic representation of free configuration
space. However, skeletonization algorithms are very resource-intensive, being
primarily oriented towards image processing tasks. We propose an efficient
path-planning methodology that finds safe paths within an acceptable processing
time. This methodology leverages a Deep Denoising Auto-Encoder (DDAE) based on
U-Net architecture to compute a skeletonized version of the navigation map,
which we refer to as SkelUnet. The SkelUnet network facilitates exploration of
the entire workspace through one-shot sampling (OSS), as opposed to the
iterative process used by exact algorithms or the probabilistic sampling
process. SkelUnet is trained and tested on a dataset consisting of 12,500
bi-dimensional dungeon maps. The motion planning methodology is evaluated in a
simulation environment for an Unmanned Aerial Vehicle (UAV) using 250
previously unseen maps, and assessed with various navigation metrics to
quantify the navigability of the computed paths. The results demonstrate that
using SkelUnet to construct a roadmap offers significant advantages, such as
connecting all regions of free workspace, providing safer paths, and reducing
processing times. These characteristics make this method particularly suitable
for mobile service robots in structured environments.

</details>


### [9] [DigiT4TAF -- Bridging Physical and Digital Worlds for Future Transportation Systems](https://arxiv.org/abs/2507.02400)
*Maximilian Zipfl,Pascal Zwick,Patrick Schulz,Marc Rene Zofka,Albert Schotschneider,Helen Gremmelmaier,Nikolai Polley,Ferdinand Mütsch,Kevin Simon,Fabian Gottselig,Michael Frey,Sergio Marschall,Akim Stark,Maximilian Müller,Marek Wehmer,Mihai Kocsis,Dominic Waldenmayer,Florian Schnepf,Erik Heinrich,Sabrina Pletz,Matthias Kölle,Karin Langbein-Euchner,Alexander Viehl,Raoul Zöllner,J. Marius Zöllner*

Main category: cs.RO

TL;DR: 本文描述了德国TAF-BW自动驾驶测试区域的数字孪生开发过程，通过结合智能基础设施和车载传感器生成真实数据，并公开了仿真框架。


<details>
  <summary>Details</summary>
Motivation: 数字化和互联互通对未来交通至关重要，数字孪生技术能实现真实与虚拟环境的双向连接，为交通优化和安全模拟提供支持。

Method: 利用智能基础设施的摄像头和车载LiDAR传感器提取对象列表，生成真实数据输入数字孪生，并通过统一接口实现交通参与者的重模拟。

Result: 开发了一个公开可用的数字孪生框架，并通过两个案例展示了其在交通信号优化和通信安全模拟中的应用。

Conclusion: 数字孪生技术为交通管理和安全模拟提供了高效工具，未来可进一步扩展其应用范围。

Abstract: In the future, mobility will be strongly shaped by the increasing use of
digitalization. Not only will individual road users be highly interconnected,
but also the road and associated infrastructure. At that point, a Digital Twin
becomes particularly appealing because, unlike a basic simulation, it offers a
continuous, bilateral connection linking the real and virtual environments.
This paper describes the digital reconstruction used to develop the Digital
Twin of the Test Area Autonomous Driving-Baden-W\"urttemberg (TAF-BW), Germany.
The TAF-BW offers a variety of different road sections, from high-traffic urban
intersections and tunnels to multilane motorways. The test area is equipped
with a comprehensive Vehicle-to-Everything (V2X) communication infrastructure
and multiple intelligent intersections equipped with camera sensors to
facilitate real-time traffic flow monitoring. The generation of authentic data
as input for the Digital Twin was achieved by extracting object lists at the
intersections. This process was facilitated by the combined utilization of
camera images from the intelligent infrastructure and LiDAR sensors mounted on
a test vehicle. Using a unified interface, recordings from real-world
detections of traffic participants can be resimulated. Additionally, the
simulation framework's design and the reconstruction process is discussed. The
resulting framework is made publicly available for download and utilization at:
https://digit4taf-bw.fzi.de The demonstration uses two case studies to
illustrate the application of the digital twin and its interfaces: the analysis
of traffic signal systems to optimize traffic flow and the simulation of
security-related scenarios in the communications sector.

</details>


### [10] [A Late Collaborative Perception Framework for 3D Multi-Object and Multi-Source Association and Fusion](https://arxiv.org/abs/2507.02430)
*Maryem Fadili,Mohamed Anis Ghaoui,Louis Lecrosnier,Steve Pechberti,Redouane Khemmar*

Main category: cs.RO

TL;DR: 提出了一种新型的后期协作框架，用于3D多源多目标融合，仅需共享3D边界框属性，无需直接访问检测模型，显著降低了位置、尺度和方向误差。


<details>
  <summary>Details</summary>
Motivation: 解决现有协作感知方法对高通信带宽和模型架构访问的依赖，以适应实际自动驾驶场景中的通信限制和模型保护需求。

Method: 基于共享3D边界框属性（类别、大小、位置和方向）的后期协作框架，避免直接访问检测模型。

Result: 位置误差降低5倍，尺度误差减少7.5倍，方向误差减半，同时保持100%的精确率和召回率。

Conclusion: 该框架为高效、可扩展的多智能体融合设定了新基准，有效解决了实际协作感知的挑战。

Abstract: In autonomous driving, recent research has increasingly focused on
collaborative perception based on deep learning to overcome the limitations of
individual perception systems. Although these methods achieve high accuracy,
they rely on high communication bandwidth and require unrestricted access to
each agent's object detection model architecture and parameters. These
constraints pose challenges real-world autonomous driving scenarios, where
communication limitations and the need to safeguard proprietary models hinder
practical implementation. To address this issue, we introduce a novel late
collaborative framework for 3D multi-source and multi-object fusion, which
operates solely on shared 3D bounding box attributes-category, size, position,
and orientation-without necessitating direct access to detection models. Our
framework establishes a new state-of-the-art in late fusion, achieving up to
five times lower position error compared to existing methods. Additionally, it
reduces scale error by a factor of 7.5 and orientation error by half, all while
maintaining perfect 100% precision and recall when fusing detections from
heterogeneous perception systems. These results highlight the effectiveness of
our approach in addressing real-world collaborative perception challenges,
setting a new benchmark for efficient and scalable multi-agent fusion.

</details>


### [11] [MISC: Minimal Intervention Shared Control with Guaranteed Safety under Non-Convex Constraints](https://arxiv.org/abs/2507.02438)
*Shivam Chaubey,Francesco Verdoja,Shankar Deka,Ville Kyrki*

Main category: cs.RO

TL;DR: 提出了一种基于约束最优控制问题的辅助控制器框架，通过离线计算的控​​制不变集确保可行性、严格约束满足和最小化用户意图覆盖，解决了现有共享控制方法在可行性、可扩展性和安全性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有共享控制方法（如模型预测控制、控制屏障函数或基于学习的控制）在可行性、可扩展性和安全性方面存在不足，尤其是用户输入的不可预测性。

Method: 提出了一种基于约束最优控制问题的框架，结合离线计算的控制不变集，支持在线计算控制动作，并能处理一类结构化非凸约束。

Result: 通过66名参与者的大规模用户研究验证，结果显示在任务负荷、信任、感知控制和性能方面均有显著提升，同时不损害安全性和用户意图。

Conclusion: 该框架在共享控制领域实现了可行性、安全性和用户意图的平衡，为实际应用提供了有效解决方案。

Abstract: Shared control combines human intention with autonomous decision-making, from
low-level safety overrides to high-level task guidance, enabling systems that
adapt to users while ensuring safety and performance. This enhances task
effectiveness and user experience across domains such as assistive robotics,
teleoperation, and autonomous driving. However, existing shared control
methods, based on e.g. Model Predictive Control, Control Barrier Functions, or
learning-based control, struggle with feasibility, scalability, or safety
guarantees, particularly since the user input is unpredictable.
  To address these challenges, we propose an assistive controller framework
based on Constrained Optimal Control Problem that incorporates an
offline-computed Control Invariant Set, enabling online computation of control
actions that ensure feasibility, strict constraint satisfaction, and minimal
override of user intent. Moreover, the framework can accommodate structured
class of non-convex constraints, which are common in real-world scenarios. We
validate the approach through a large-scale user study with 66
participants--one of the most extensive in shared control research--using a
computer game environment to assess task load, trust, and perceived control, in
addition to performance. The results show consistent improvements across all
these aspects without compromising safety and user intent.

</details>


### [12] [HAC-LOCO: Learning Hierarchical Active Compliance Control for Quadruped Locomotion under Continuous External Disturbances](https://arxiv.org/abs/2507.02447)
*Xiang Zhou,Xinyu Zhang,Qingrui Zhang*

Main category: cs.RO

TL;DR: 提出了一种两阶段分层学习框架，用于四足机器人在外部力扰动下的鲁棒与顺应性运动控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常优先考虑运动鲁棒性而忽略顺应性，导致僵硬、高频运动和能量效率低下。本文旨在平衡鲁棒性与顺应性。

Method: 第一阶段训练速度跟踪策略和自编码器提取本体感受特征，并学习基于监督学习的力估计器；第二阶段基于预训练模型学习顺应性动作模块，实时调整速度命令。

Result: 仿真和实验表明，该方法在鲁棒性、能量效率和安全性上优于现有RL运动控制器。

Conclusion: 该方法通过顺应性动作模块有效平衡了鲁棒性与顺应性，适用于四足机器人的复杂环境。

Abstract: Despite recent remarkable achievements in quadruped control, it remains
challenging to ensure robust and compliant locomotion in the presence of
unforeseen external disturbances. Existing methods prioritize locomotion
robustness over compliance, often leading to stiff, high-frequency motions, and
energy inefficiency. This paper, therefore, presents a two-stage hierarchical
learning framework that can learn to take active reactions to external force
disturbances based on force estimation. In the first stage, a velocity-tracking
policy is trained alongside an auto-encoder to distill historical
proprioceptive features. A neural network-based estimator is learned through
supervised learning, which estimates body velocity and external forces based on
proprioceptive measurements. In the second stage, a compliance action module,
inspired by impedance control, is learned based on the pre-trained encoder and
policy. This module is employed to actively adjust velocity commands in
response to external forces based on real-time force estimates. With the
compliance action module, a quadruped robot can robustly handle minor
disturbances while appropriately yielding to significant forces, thus striking
a balance between robustness and compliance. Simulations and real-world
experiments have demonstrated that our method has superior performance in terms
of robustness, energy efficiency, and safety. Experiment comparison shows that
our method outperforms the state-of-the-art RL-based locomotion controllers.
Ablation studies are given to show the critical roles of the compliance action
module.

</details>


### [13] [Safe and Socially Aware Multi-Robot Coordination in Multi-Human Social Care Settings](https://arxiv.org/abs/2507.02521)
*Ayodeji O. Abioye,Jayati Deshmukh,Athina Georgara,Dominic Price,Tuyen Nguyen,Aleksandra Landowska,Amel Bennaceur,Joel E. Fischer,Sarvapali D. Ramchurn*

Main category: cs.RO

TL;DR: 研究提出了一种基于多目标学习的协调方法，用于解决多人类多机器人环境中的路径规划、导航、任务调度、任务分配和人机交互问题。


<details>
  <summary>Details</summary>
Motivation: 在多人类多机器人环境中，协调多个机器人的行为是一个复杂的问题，需要综合考虑路径规划、导航、任务调度、任务分配和人机交互等多个目标。

Method: 采用多目标学习的方法，设计了一种协调策略，以同时优化多个目标。

Result: 该方法在多人类多机器人环境中表现出良好的协调能力，能够有效解决路径规划、导航、任务调度、任务分配和人机交互等问题。

Conclusion: 研究表明，基于多目标学习的协调方法在多人类多机器人环境中具有实际应用潜力。

Abstract: This research investigates strategies for multi-robot coordination in
multi-human environments. It proposes a multi-objective learning-based
coordination approach to addressing the problem of path planning, navigation,
task scheduling, task allocation, and human-robot interaction in multi-human
multi-robot (MHMR) settings.

</details>


### [14] [Vibration of Soft, Twisted Beams for Under-Actuated Quadrupedal Locomotion](https://arxiv.org/abs/2507.02547)
*Yuhao Jiang,Fuchen Chen,Jamie Paik,Daniel M. Aukes*

Main category: cs.RO

TL;DR: Flix-Walker是一种新型厘米级四足机器人，利用螺旋形柔性腿和两个电机振动实现三种运动模式，通过仿真和实验验证了其鲁棒性和导航能力。


<details>
  <summary>Details</summary>
Motivation: 通过预设计的柔性动态行为解决驱动和控制挑战，探索欠驱动柔性机器人系统的潜力。

Method: 使用螺旋形柔性腿，仅需两个电机振动驱动，分析驱动参数并通过仿真和实验验证运动模式。

Result: 实验验证了驱动参数的有效性和鲁棒性，实现了可靠的轨迹跟踪和自主导航。

Conclusion: Flix-Walker展示了欠驱动柔性机器人在多模式运动和鲁棒控制方面的潜力。

Abstract: Under-actuated compliant robotic systems offer a promising approach to
mitigating actuation and control challenges by harnessing pre-designed,
embodied dynamic behaviors. This paper presents Flix-Walker, a novel,
untethered, centimeter-scale quadrupedal robot inspired by compliant
under-actuated mechanisms. Flix-Walker employs flexible, helix-shaped beams as
legs, which are actuated by vibrations from just two motors to achieve three
distinct mobility modes. We analyze the actuation parameters required to
generate various locomotion modes through both simulation and prototype
experiments. The effects of system and environmental variations on locomotion
performance are examined, and we propose a generic metric for selecting control
parameters that produce robust and functional motions. Experiments validate the
effectiveness and robustness of these actuation parameters within a closed-loop
control framework, demonstrating reliable trajectory-tracking and
self-navigation capabilities.

</details>


### [15] [ArtGS:3D Gaussian Splatting for Interactive Visual-Physical Modeling and Manipulation of Articulated Objects](https://arxiv.org/abs/2507.02600)
*Qiaojun Yu,Xibin Yuan,Yu jiang,Junting Chen,Dongzhe Zheng,Ce Hao,Yang You,Yixing Chen,Yao Mu,Liu Liu,Cewu Lu*

Main category: cs.RO

TL;DR: ArtGS是一个结合视觉-物理建模的新框架，用于解决机器人中关节物体操作的挑战，通过3D高斯泼溅和视觉语言模型优化关节骨骼参数，显著提升了操作准确性和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在关节物体操作中面临复杂运动约束和物理推理不足的问题，ArtGS旨在通过视觉-物理建模改进这一领域。

Method: ArtGS结合多视角RGB-D重建、视觉语言模型提取语义结构信息，并通过动态可微3D高斯泼溅优化关节骨骼参数，实现物理一致的运动约束。

Result: 实验表明，ArtGS在关节估计准确性和操作成功率上显著优于现有方法，适用于多种关节物体。

Conclusion: ArtGS为关节物体建模和操作提供了一个高效、可扩展且通用的新框架。

Abstract: Articulated object manipulation remains a critical challenge in robotics due
to the complex kinematic constraints and the limited physical reasoning of
existing methods. In this work, we introduce ArtGS, a novel framework that
extends 3D Gaussian Splatting (3DGS) by integrating visual-physical modeling
for articulated object understanding and interaction. ArtGS begins with
multi-view RGB-D reconstruction, followed by reasoning with a vision-language
model (VLM) to extract semantic and structural information, particularly the
articulated bones. Through dynamic, differentiable 3DGS-based rendering, ArtGS
optimizes the parameters of the articulated bones, ensuring physically
consistent motion constraints and enhancing the manipulation policy. By
leveraging dynamic Gaussian splatting, cross-embodiment adaptability, and
closed-loop optimization, ArtGS establishes a new framework for efficient,
scalable, and generalizable articulated object modeling and manipulation.
Experiments conducted in both simulation and real-world environments
demonstrate that ArtGS significantly outperforms previous methods in joint
estimation accuracy and manipulation success rates across a variety of
articulated objects. Additional images and videos are available on the project
website: https://sites.google.com/view/artgs/home

</details>


### [16] [MISCGrasp: Leveraging Multiple Integrated Scales and Contrastive Learning for Enhanced Volumetric Grasping](https://arxiv.org/abs/2507.02672)
*Qingyu Fan,Yinghao Cai,Chao Li,Chunting Jiao,Xudong Zheng,Tao Lu,Bin Liang,Shuo Wang*

Main category: cs.RO

TL;DR: MISCGrasp是一种体积抓取方法，通过多尺度特征提取和对比特征增强实现自适应抓取，性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 机器人抓取在适应不同形状和大小的物体时面临挑战。

Method: 结合多尺度特征提取与对比特征增强，通过Insight Transformer和Empower Transformer实现高低层次特征的交互与选择。

Result: 在模拟和真实环境中的实验表明，MISCGrasp在桌面整理任务中优于基线方法。

Conclusion: MISCGrasp通过多尺度对比学习实现了高效的自适应抓取。

Abstract: Robotic grasping faces challenges in adapting to objects with varying shapes
and sizes. In this paper, we introduce MISCGrasp, a volumetric grasping method
that integrates multi-scale feature extraction with contrastive feature
enhancement for self-adaptive grasping. We propose a query-based interaction
between high-level and low-level features through the Insight Transformer,
while the Empower Transformer selectively attends to the highest-level
features, which synergistically strikes a balance between focusing on fine
geometric details and overall geometric structures. Furthermore, MISCGrasp
utilizes multi-scale contrastive learning to exploit similarities among
positive grasp samples, ensuring consistency across multi-scale features.
Extensive experiments in both simulated and real-world environments demonstrate
that MISCGrasp outperforms baseline and variant methods in tabletop
decluttering tasks. More details are available at https://miscgrasp.github.io/.

</details>


### [17] [Integrating path-planning and control for robotic unicycles](https://arxiv.org/abs/2507.02700)
*Máté B. Vizi,Dénes Tákács,Gábor Stépán,Gábor Orosz*

Main category: cs.RO

TL;DR: 提出了一种针对机器人独轮车的路径规划与控制集成方法，优化了路径分段和曲率设计。


<details>
  <summary>Details</summary>
Motivation: 针对独轮车在加速、制动和转向时的独特需求，提出一种集成路径规划与控制的方法。

Method: 将路径分为直线和曲线段，分别用于加速/制动和转向，优化曲线段的曲率设计。

Result: 通过数值模拟验证了方法的性能。

Conclusion: 该方法有效满足了独轮车的运动需求，优化了控制性能。

Abstract: This article focuses on integrating path-planning and control with
specializing on the unique needs of robotic unicycles. A unicycle design is
presented which is capable of accelerating/breaking and carrying out a variety
of maneuvers. The proposed path-planning method segments the path into straight
and curved path sections dedicated for accelerating/breaking and turning
maneuvers, respectively. The curvature profiles of the curved sections are
optimized while considering the control performance and the slipping limits of
the wheel. The performance of the proposed integrated approach is demonstrated
via numerical simulations.

</details>


### [18] [Optimizing Start Locations in Ergodic Search for Disaster Response](https://arxiv.org/abs/2507.02708)
*Ananya Rao,Alyssa Hargis,David Wettergreen,Howie Choset*

Main category: cs.RO

TL;DR: 该论文提出了一种优化机器人团队在灾难响应中起始部署位置的方法，通过联合优化框架解决异构机器人团队的起始位置选择问题，显著提升了覆盖性能。


<details>
  <summary>Details</summary>
Motivation: 在灾难响应中，机器人团队的部署对提高情境感知和搜救效率至关重要，但现有研究未解决机器人起始位置选择的问题。

Method: 通过向遍历优化框架添加约束，将机器人分配到起始位置，并针对异构机器人团队调整约束条件。

Result: 实验结果表明，该方法在合成数据和真实数据上分别实现了35.98%和31.91%的覆盖性能提升。

Conclusion: 该方法显著优化了机器人团队的起始部署位置，提升了灾难响应中的覆盖性能。

Abstract: In disaster response scenarios, deploying robotic teams effectively is
crucial for improving situational awareness and enhancing search and rescue
operations. The use of robots in search and rescue has been studied but the
question of where to start robot deployments has not been addressed. This work
addresses the problem of optimally selecting starting locations for robots with
heterogeneous capabilities by formulating a joint optimization problem. To
determine start locations, this work adds a constraint to the ergodic
optimization framework whose minimum assigns robots to start locations. This
becomes a little more challenging when the robots are heterogeneous (equipped
with different sensing and motion modalities) because not all robots start at
the same location, and a more complex adaptation of the aforementioned
constraint is applied. Our method assumes access to potential starting
locations, which can be obtained from expert knowledge or aerial imagery. We
experimentally evaluate the efficacy of our joint optimization approach by
comparing it to baseline methods that use fixed starting locations for all
robots. Our experimental results show significant gains in coverage
performance, with average improvements of 35.98% on synthetic data and 31.91%
on real-world data for homogeneous and heterogeneous teams, in terms of the
ergodic metric.

</details>


### [19] [Trajectory Optimization for Differential Drive Mobile Manipulators via Topological Paths Search and Arc Length-Yaw Parameterization](https://arxiv.org/abs/2507.02761)
*Long Xu,Choilam Wong,Mengke Zhang,Junxiao Lin,Fei Gao*

Main category: cs.RO

TL;DR: 提出了一种高效的分层运动规划方法，用于差速驱动移动机械臂，通过并行采样和优化探索可行轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决差速驱动移动机械臂在复杂环境中的运动规划问题，提高效率和最优性。

Method: 先搜索多个无碰撞且拓扑不同的路径，再并行采样和优化，使用多项式轨迹和弧长-偏航参数化。

Result: 能够高效处理非完整动力学，确保轨迹最优性。

Conclusion: 该方法为移动机械臂的运动规划提供了高效且最优的解决方案。

Abstract: We present an efficient hierarchical motion planning pipeline for
differential drive mobile manipulators. Our approach first searches for
multiple collisionfree and topologically distinct paths for the mobile base to
extract the space in which optimal solutions may exist. Further sampling and
optimization are then conducted in parallel to explore feasible whole-body
trajectories. For trajectory optimization, we employ polynomial trajectories
and arc length-yaw parameterization, enabling efficient handling of the
nonholonomic dynamics while ensuring optimality.

</details>


### [20] [MultiGen: Using Multimodal Generation in Simulation to Learn Multimodal Policies in Real](https://arxiv.org/abs/2507.02864)
*Renhao Wang,Haoran Geng,Tingle Li,Feishi Wang,Gopala Anumanchipalli,Philipp Wu,Trevor Darrell,Boyi Li,Pieter Abbeel,Jitendra Malik,Alexei A. Efros*

Main category: cs.RO

TL;DR: 论文提出MultiGen框架，通过结合生成模型与传统物理模拟器，实现多感官模拟，解决了多模态模拟的难题，并在机器人倒水任务中展示了零样本迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界中机器人需要整合多感官信息，但多模态策略的大规模学习仍具挑战性。模拟器在视觉任务中表现良好，但对声音等其他模态的模拟困难，导致多模态的模拟到现实迁移尚未实现。

Method: 引入MultiGen框架，将大规模生成模型与传统物理模拟器结合，生成多感官模拟数据。以机器人倒水任务为例，通过视频生成逼真音频，训练多模态策略。

Result: 在真实世界的倒水任务中，实现了零样本迁移，适用于新容器和液体，展示了生成模型在多模态模拟中的潜力。

Conclusion: MultiGen框架通过生成模型解决了多模态模拟难题，为多模态的模拟到现实迁移提供了可行方案。

Abstract: Robots must integrate multiple sensory modalities to act effectively in the
real world. Yet, learning such multimodal policies at scale remains
challenging. Simulation offers a viable solution, but while vision has
benefited from high-fidelity simulators, other modalities (e.g. sound) can be
notoriously difficult to simulate. As a result, sim-to-real transfer has
succeeded primarily in vision-based tasks, with multimodal transfer still
largely unrealized. In this work, we tackle these challenges by introducing
MultiGen, a framework that integrates large-scale generative models into
traditional physics simulators, enabling multisensory simulation. We showcase
our framework on the dynamic task of robot pouring, which inherently relies on
multimodal feedback. By synthesizing realistic audio conditioned on simulation
video, our method enables training on rich audiovisual trajectories -- without
any real robot data. We demonstrate effective zero-shot transfer to real-world
pouring with novel containers and liquids, highlighting the potential of
generative modeling to both simulate hard-to-model modalities and close the
multimodal sim-to-real gap.

</details>
