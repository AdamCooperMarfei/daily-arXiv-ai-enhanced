<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 29]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Debate2Create: Robot Co-design via Large Language Model Debates](https://arxiv.org/abs/2510.25850)
*Kevin Qiu,Marek Cygan*

Main category: cs.RO

TL;DR: D2C框架利用LLM代理进行结构化辩论，共同优化机器人形态和控制，无需显式多样性目标即可生成多样化设计，在四足机器人运动基准上性能提升73%


<details>
  <summary>Details</summary>
Motivation: 解决机器人形态与控制协同设计的自动化挑战，传统方法面临设计空间巨大和身体行为紧密耦合的问题

Method: 设计代理提出形态修改，控制代理制定针对性奖励函数，多元评审团在模拟中评估设计-控制对并提供反馈，通过迭代辩论逐步优化

Result: 在四足机器人运动基准上，D2C发现的机器人设计比默认设计移动距离远73%，且产生了多样化和专门化的形态

Conclusion: 基于LLM的多智能体辩论结合物理基础反馈，是自动化机器人设计的有前景的新范式

Abstract: Automating the co-design of a robot's morphology and control is a
long-standing challenge due to the vast design space and the tight coupling
between body and behavior. We introduce Debate2Create (D2C), a framework in
which large language model (LLM) agents engage in a structured dialectical
debate to jointly optimize a robot's design and its reward function. In each
round, a design agent proposes targeted morphological modifications, and a
control agent devises a reward function tailored to exploit the new design. A
panel of pluralistic judges then evaluates the design-control pair in
simulation and provides feedback that guides the next round of debate. Through
iterative debates, the agents progressively refine their proposals, producing
increasingly effective robot designs. Notably, D2C yields diverse and
specialized morphologies despite no explicit diversity objective. On a
quadruped locomotion benchmark, D2C discovers designs that travel 73% farther
than the default, demonstrating that structured LLM-based debate can serve as a
powerful mechanism for emergent robot co-design. Our results suggest that
multi-agent debate, when coupled with physics-grounded feedback, is a promising
new paradigm for automated robot design.

</details>


### [2] [Risk-Aware Safety Filters with Poisson Safety Functions and Laplace Guidance Fields](https://arxiv.org/abs/2510.25913)
*Gilbert Bahati,Ryan M. Bena,Meg Wilkinson,Pol Mestres,Ryan K. Cosner,Aaron D. Ames*

Main category: cs.RO

TL;DR: 本文提出了一种基于泊松方程和拉普拉斯引导场的风险感知安全滤波器方法，用于机器人导航系统。通过求解泊松方程的狄利克雷问题生成安全函数，再求解拉普拉斯方程生成安全引导场，两者结合构建风险感知安全约束，保证系统安全的同时优先避开高风险障碍物。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器人系统需要对其环境有语义理解才能确定安全动作。本文旨在开发这种表示的数学基础，特别是开发风险感知的安全滤波器。

Method: 采用两步法：1) 通过求解泊松方程的狄利克雷问题生成安全函数，将系统安全编码为其0-超水平集；2) 求解拉普拉斯方程的狄利克雷问题合成安全引导场，通过可调通量边界条件编码障碍物周围的可变谨慎级别。然后将安全函数和引导场结合定义安全约束。

Result: 在仿真中验证了该方法，展示了如何将障碍物风险的先验理解直接纳入安全滤波器，生成风险感知的安全行为。

Conclusion: 该方法能够保证安全性的同时，优先避开高风险障碍物，为机器人导航系统提供了风险感知的安全保障机制。

Abstract: Robotic systems navigating in real-world settings require a semantic
understanding of their environment to properly determine safe actions. This
work aims to develop the mathematical underpinnings of such a representation --
specifically, the goal is to develop safety filters that are risk-aware. To
this end, we take a two step approach: encoding an understanding of the
environment via Poisson's equation, and associated risk via Laplace guidance
fields. That is, we first solve a Dirichlet problem for Poisson's equation to
generate a safety function that encodes system safety as its 0-superlevel set.
We then separately solve a Dirichlet problem for Laplace's equation to
synthesize a safe \textit{guidance field} that encodes variable levels of
caution around obstacles -- by enforcing a tunable flux boundary condition. The
safety function and guidance fields are then combined to define a safety
constraint and used to synthesize a risk-aware safety filter which, given a
semantic understanding of an environment with associated risk levels of
environmental features, guarantees safety while prioritizing avoidance of
higher risk obstacles. We demonstrate this method in simulation and discuss how
\textit{a priori} understandings of obstacle risk can be directly incorporated
into the safety filter to generate safe behaviors that are risk-aware.

</details>


### [3] [Curvature-Aware Calibration of Tactile Sensors for Accurate Force Estimation on Non-Planar Surfaces](https://arxiv.org/abs/2510.25965)
*Luoyan Zhong,Heather Jin Hee Kim,Dylan P. Losey,Cara M. Nunez*

Main category: cs.RO

TL;DR: 提出了一种针对柔性触觉传感器的曲率感知校准方法，通过在无负载时使用神经网络预测局部曲率，显著提高了传感器在曲面上的力测量精度和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有柔性触觉传感器主要在平面上校准，但在实际应用中需要安装在曲面上，导致精度和一致性下降，限制了其在机器人抓取、假肢等领域的可靠性。

Method: 开发了电阻式触觉传感器的校准模型，使用多层感知机神经网络从无负载时的基线传感器输出预测局部曲率，实现了曲率感知的力估计。

Result: 在5个不同曲率的日常物体上验证，力范围为2-8N，曲率感知校准在所有表面上保持一致的力精度（R²=0.91），而平面校准会随着曲率增加而低估力值。

Conclusion: 曲率感知建模显著提高了柔性触觉传感器在真实应用中的准确性、一致性和可靠性，使其能够在各种曲面几何上保持可靠性能。

Abstract: Flexible tactile sensors are increasingly used in real-world applications
such as robotic grippers, prosthetic hands, wearable gloves, and assistive
devices, where they need to conform to curved and irregular surfaces. However,
most existing tactile sensors are calibrated only on flat substrates, and their
accuracy and consistency degrade once mounted on curved geometries. This
limitation restricts their reliability in practical use. To address this
challenge, we develop a calibration model for a widely used resistive tactile
sensor design that enables accurate force estimation on one-dimensional curved
surfaces. We then train a neural network (a multilayer perceptron) to predict
local curvature from baseline sensor outputs recorded under no applied load,
achieving an R2 score of 0.91. The proposed approach is validated on five daily
objects with varying curvatures under forces from 2 N to 8 N. Results show that
the curvature-aware calibration maintains consistent force accuracy across all
surfaces, while flat-surface calibration underestimates force as curvature
increases. Our results demonstrate that curvature-aware modeling improves the
accuracy, consistency, and reliability of flexible tactile sensors, enabling
dependable performance across real-world applications.

</details>


### [4] [A New Type of Axis-Angle Attitude Control Law for Rotational Systems: Synthesis, Analysis, and Experiments](https://arxiv.org/abs/2510.25985)
*Francisco M. F. R. Gonçalves,Ryan M. Bena,Néstor O. Pérez-Arancibia*

Main category: cs.RO

TL;DR: 提出了一种基于欧拉轴角的新型姿态控制律，相比传统四元数方法能保证闭环系统存在唯一平衡点，并提供更灵活的比例控制，通过李雅普诺夫函数证明系统稳定性，在无人机翻滚恢复测试中表现优于高性能四元数控制器。


<details>
  <summary>Details</summary>
Motivation: 传统四元数姿态控制方法存在两个问题：1) 不能保证闭环系统存在唯一的平衡点姿态误差四元数；2) 当绕姿态误差欧拉轴的旋转误差超过π弧度时，比例控制效果会随着系统状态远离稳定平衡点而减弱。

Method: 开发了基于姿态误差欧拉轴角信息的新型控制律，通过构建严格的李雅普诺夫函数来证明闭环旋转系统的唯一平衡点具有一致渐近稳定性，并进行了数值仿真和实时翻滚恢复飞行测试验证。

Result: 仿真和飞行测试结果表明，所提出的轴角方法在稳定时间方面优于高性能四元数控制器，特别是在无人机翻滚恢复机动中表现出更优越的飞行性能。

Conclusion: 基于欧拉轴角的姿态控制方法能够保证闭环系统存在唯一平衡点，提供更灵活的比例控制，并通过严格的稳定性分析证明其有效性，在实际应用中表现出优于传统四元数方法的性能。

Abstract: Over the past few decades, continuous quaternion-based attitude control has
been proven highly effective for driving rotational systems that can be modeled
as rigid bodies, such as satellites and drones. However, methods rooted in this
approach do not enforce the existence of a unique closed-loop (CL) equilibrium
attitude-error quaternion (AEQ); and, for rotational errors about the
attitude-error Euler axis larger than {\pi}rad, their proportional-control
effect diminishes as the system state moves away from the stable equilibrium of
the CL rotational dynamics. In this paper, we introduce a new type of attitude
control law that more effectively leverages the attitude-error Euler axis-angle
information to guarantee a unique CL equilibrium AEQ and to provide greater
flexibility in the use of proportional-control efforts. Furthermore, using two
different control laws as examples-through the construction of a strict
Lyapunov function for the CL dynamics-we demonstrate that the resulting unique
equilibrium of the CL rotational system can be enforced to be uniformly
asymptotically stable. To assess and demonstrate the functionality and
performance of the proposed approach, we performed numerical simulations and
executed dozens of real-time tumble-recovery maneuvers using a small quadrotor.
These simulations and flight tests compellingly demonstrate that the proposed
axis-angle-based method achieves superior flight performance-compared with that
obtained using a high-performance quaternion-based controller-in terms of
stabilization time.

</details>


### [5] [DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System](https://arxiv.org/abs/2510.26004)
*Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang*

Main category: cs.RO

TL;DR: DARTS是一个基于无人机和AI的实时交通事件检测系统，通过集成无人机的高机动性、热成像技术和轻量级深度学习框架，实现了99%的检测准确率，比传统方法提前12分钟检测到事故。


<details>
  <summary>Details</summary>
Motivation: 传统交通事件检测方法存在检测与验证分离、灵活性有限、需要密集基础设施等问题，限制了在变化的事故热点区域的适应性和可扩展性。

Method: DARTS整合了无人机的高机动性和空中视角进行自适应监控，使用热成像技术提高低能见度性能和隐私保护，采用轻量级深度学习框架实时提取车辆轨迹和检测事件。

Result: 在自收集数据集上达到99%的检测准确率，在佛罗里达州75号州际公路的实地测试中，比当地交通管理中心提前12分钟检测到追尾事故，并能监控事故引发的拥堵传播。

Conclusion: DARTS展示了更灵活和集成的实时交通事件检测系统的潜力，具有显著提高现代交通管理运营效率和响应能力的意义，特别是在偏远地区和资源受限环境中具有可扩展性和成本效益。

Abstract: Rapid and reliable incident detection is critical for reducing crash-related
fatalities, injuries, and congestion. However, conventional methods, such as
closed-circuit television, dashcam footage, and sensor-based detection,
separate detection from verification, suffer from limited flexibility, and
require dense infrastructure or high penetration rates, restricting
adaptability and scalability to shifting incident hotspots. To overcome these
challenges, we developed DARTS, a drone-based, AI-powered real-time traffic
incident detection system. DARTS integrates drones' high mobility and aerial
perspective for adaptive surveillance, thermal imaging for better
low-visibility performance and privacy protection, and a lightweight deep
learning framework for real-time vehicle trajectory extraction and incident
detection. The system achieved 99% detection accuracy on a self-collected
dataset and supports simultaneous online visual verification, severity
assessment, and incident-induced congestion propagation monitoring via a
web-based interface. In a field test on Interstate 75 in Florida, DARTS
detected and verified a rear-end collision 12 minutes earlier than the local
transportation management center and monitored incident-induced congestion
propagation, suggesting potential to support faster emergency response and
enable proactive traffic control to reduce congestion and secondary crash risk.
Crucially, DARTS's flexible deployment architecture reduces dependence on
frequent physical patrols, indicating potential scalability and
cost-effectiveness for use in remote areas and resource-constrained settings.
This study presents a promising step toward a more flexible and integrated
real-time traffic incident detection system, with significant implications for
the operational efficiency and responsiveness of modern transportation
management.

</details>


### [6] [RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras](https://arxiv.org/abs/2510.26018)
*Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种使用微型无人机群配合定位放射性材料的新方法，利用单探测器康普顿相机实现实时辐射源定位和追踪。


<details>
  <summary>Details</summary>
Motivation: 现有辐射检测方法在灵敏度和机动性方面存在局限，需要开发能够在复杂环境中快速定位辐射源的协作系统。

Method: 采用轻量化（40克）康普顿相机作为辐射探测器，通过融合稀疏测量数据实时估计辐射源位置，并利用动态反馈控制无人机群运动。

Result: 实现了无人机群的紧密协作，能够最大化康普顿相机的信息获取，快速定位辐射源并追踪移动辐射源。

Conclusion: 该方法为辐射检测开辟了新途径，展示了协作无人机系统在危险环境监测中的潜力。

Abstract: We present a novel approach to localizing radioactive material by cooperating
Micro Aerial Vehicles (MAVs). Our approach utilizes a state-of-the-art
single-detector Compton camera as a highly sensitive, yet miniature detector of
ionizing radiation. The detector's exceptionally low weight (40 g) opens up new
possibilities of radiation detection by a team of cooperating agile MAVs. We
propose a new fundamental concept of fusing the Compton camera measurements to
estimate the position of the radiation source in real time even from extremely
sparse measurements. The data readout and processing are performed directly
onboard and the results are used in a dynamic feedback to drive the motion of
the vehicles. The MAVs are stabilized in a tightly cooperating swarm to
maximize the information gained by the Compton cameras, rapidly locate the
radiation source, and even track a moving radiation source.

</details>


### [7] [Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods](https://arxiv.org/abs/2510.26040)
*Emily Steiner,Daniel van der Spuy,Futian Zhou,Afereti Pama,Minas Liarokapis,Henry Williams*

Main category: cs.RO

TL;DR: 提出了一种能够在仿真和现实中可靠导航赛道并超越对手的新型赛车和超车智能体，在真实F1Tenth车辆上部署并与其他竞争算法对抗，展示了87%的超车成功率。


<details>
  <summary>Details</summary>
Motivation: 虽然自主赛车在计时赛场景中取得显著进展，但轮对轮赛车和超车仍然严重受限，特别是在真实驾驶场景中，现有算法难以安全可靠地完成超车操作。

Method: 开发了一种新型赛车和超车智能体，能够在F1Tenth平台上学习可靠导航和超车，并在仿真和现实中部署测试。

Result: 智能体在与对手训练后实现了87%的超车成功率，而仅接受赛车训练的智能体只有56%的成功率。

Conclusion: 通过与对手训练，智能体能够实现有意识的超车行为，显著提高了超车成功率，为安全可靠的自主轮对轮赛车提供了有效解决方案。

Abstract: While autonomous racing performance in Time-Trial scenarios has seen
significant progress and development, autonomous wheel-to-wheel racing and
overtaking are still severely limited. These limitations are particularly
apparent in real-life driving scenarios where state-of-the-art algorithms
struggle to safely or reliably complete overtaking manoeuvres. This is
important, as reliable navigation around other vehicles is vital for safe
autonomous wheel-to-wheel racing. The F1Tenth Competition provides a useful
opportunity for developing wheel-to-wheel racing algorithms on a standardised
physical platform. The competition format makes it possible to evaluate
overtaking and wheel-to-wheel racing algorithms against the state-of-the-art.
This research presents a novel racing and overtaking agent capable of learning
to reliably navigate a track and overtake opponents in both simulation and
reality. The agent was deployed on an F1Tenth vehicle and competed against
opponents running varying competitive algorithms in the real world. The results
demonstrate that the agent's training against opponents enables deliberate
overtaking behaviours with an overtaking rate of 87% compared 56% for an agent
trained just to race.

</details>


### [8] [Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion](https://arxiv.org/abs/2510.26067)
*Chi Zhang,Mingrui Li,Wenzhe Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 提出了一种基于图神经网络的强化学习框架，用于控制张拉整体机器人的运动，该框架通过图结构表示机器人物理拓扑，实现了从仿真到硬件的直接迁移。


<details>
  <summary>Details</summary>
Motivation: 张拉整体机器人结合刚性杆和弹性缆绳，具有高韧性和可部署性，但由于其欠驱动和高度耦合的动力学特性，运动控制面临重大挑战。

Method: 将图神经网络集成到Soft Actor-Critic算法中，通过图结构表示机器人物理拓扑，捕捉组件间的耦合关系，相比传统多层感知器策略实现更快更稳定的学习。

Result: 在物理3杆张拉整体机器人上验证了三种运动基元，包括直线跟踪和双向转向，表现出优异的样本效率、对噪声和刚度变化的鲁棒性以及改进的轨迹精度。

Conclusion: 结果表明将结构先验知识融入强化学习对张拉整体机器人控制具有优势，学习到的策略无需微调即可从仿真直接迁移到硬件实现稳定运动。

Abstract: Tensegrity robots combine rigid rods and elastic cables, offering high
resilience and deployability but posing major challenges for locomotion control
due to their underactuated and highly coupled dynamics. This paper introduces a
morphology-aware reinforcement learning framework that integrates a graph
neural network (GNN) into the Soft Actor-Critic (SAC) algorithm. By
representing the robot's physical topology as a graph, the proposed GNN-based
policy captures coupling among components, enabling faster and more stable
learning than conventional multilayer perceptron (MLP) policies. The method is
validated on a physical 3-bar tensegrity robot across three locomotion
primitives, including straight-line tracking and bidirectional turning. It
shows superior sample efficiency, robustness to noise and stiffness variations,
and improved trajectory accuracy. Notably, the learned policies transfer
directly from simulation to hardware without fine-tuning, achieving stable
real-world locomotion. These results demonstrate the advantages of
incorporating structural priors into reinforcement learning for tensegrity
robot control.

</details>


### [9] [I don't Want You to Die: A Shared Responsibility Framework for Safeguarding Child-Robot Companionship](https://arxiv.org/abs/2510.26080)
*Fan Yang,Renkai Ma,Yaxin Hu,Michael Rodgers,Lingyao Li*

Main category: cs.RO

TL;DR: 研究探讨社交机器人（如Moxie）服务终止对儿童情感伤害的责任归属问题，发现责任被视为机器人公司、父母、开发者和政府的共同责任，但责任分配因政治意识形态和父母身份而异。


<details>
  <summary>Details</summary>
Motivation: 社交机器人与儿童建立强烈情感纽带后突然终止服务会造成显著困扰和痛苦，这引发了当儿童情感纽带被破坏时谁应承担责任这一复杂问题。

Method: 使用Moxie关闭作为案例研究，通过对72名美国参与者进行定性调查。

Result: 研究发现责任被视为共享责任，但责任归属因政治意识形态和父母身份而异；参与者对机器人服务是否应继续存在高度两极分化。

Conclusion: 研究提出了一个基于实证的共享责任框架，通过详细说明责任如何分配和争议，为减轻机器人终止服务的情感伤害提供具体设计和政策启示。

Abstract: Social robots like Moxie are designed to form strong emotional bonds with
children, but their abrupt discontinuation can cause significant struggles and
distress to children. When these services end, the resulting harm raises
complex questions of who bears responsibility when children's emotional bonds
are broken. Using the Moxie shutdown as a case study through a qualitative
survey of 72 U.S. participants, our findings show that the responsibility is
viewed as a shared duty across the robot company, parents, developers, and
government. However, these attributions varied by political ideology and
parental status of whether they have children. Participants' perceptions of
whether the robot service should continue are highly polarized; supporters
propose technical, financial, and governmental pathways for continuity, while
opponents cite business realities and risks of unhealthy emotional dependency.
Ultimately, this research contributes an empirically grounded shared
responsibility framework for safeguarding child-robot companionship by
detailing how accountability is distributed and contested, informing concrete
design and policy implications to mitigate the emotional harm of robot
discontinuation.

</details>


### [10] [Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse](https://arxiv.org/abs/2510.26082)
*Fan Yang,Lingyao Li,Yaxin Hu,Michael Rodgers,Renkai Ma*

Main category: cs.RO

TL;DR: 研究发现机器人拟人化程度对保护性反应的影响不是线性的，中等拟人化机器人引发最强的愤怒反应，道德推理随拟人化程度增加从技术评估转向道德谴责。


<details>
  <summary>Details</summary>
Motivation: 研究不同拟人化程度如何影响人们对机器人受虐待的保护性反应，将计算机作为社会行动者理论和恐怖谷理论扩展到道德领域。

Method: 邀请201名参与者观看低、中、高三种拟人化程度机器人受虐待的视频，通过自我报告问卷、自动面部表情分析的生理数据和定性反思三种方式进行综合分析。

Result: 中等拟人化的Two-Foot机器人引发最强的生理愤怒表达，自我报告的愤怒和愧疚感在Two-Foot和Humanoid机器人中显著高于Spider机器人。道德推理随拟人化程度增加从财产损害评估转向对施虐者品德的谴责。

Conclusion: 恐怖谷现象不会削弱道德关切，反而会增强保护性冲动，这对机器人设计、政策和未来法律框架具有重要启示。

Abstract: Robots with anthropomorphic features are increasingly shaping how humans
perceive and morally engage with them. Our research investigates how different
levels of anthropomorphism influence protective responses to robot abuse,
extending the Computers as Social Actors (CASA) and uncanny valley theories
into a moral domain. In an experiment, we invite 201 participants to view
videos depicting abuse toward a robot with low (Spider), moderate (Two-Foot),
or high (Humanoid) anthropomorphism. To provide a comprehensive analysis, we
triangulate three modalities: self-report surveys measuring emotions and
uncanniness, physiological data from automated facial expression analysis, and
qualitative reflections. Findings indicate that protective responses are not
linear. The moderately anthropomorphic Two-Foot robot, rated highest in
eeriness and "spine-tingling" sensations consistent with the uncanny valley,
elicited the strongest physiological anger expressions. Self-reported anger and
guilt are significantly higher for both the Two-Foot and Humanoid robots
compared to the Spider. Qualitative findings further reveal that as
anthropomorphism increases, moral reasoning shifts from technical assessments
of property damage to condemnation of the abuser's character, while governance
proposals expand from property law to calls for quasi-animal rights and broader
societal responsibility. These results suggest that the uncanny valley does not
dampen moral concern but paradoxically heightens protective impulses, offering
critical implications for robot design, policy, and future legal frameworks.

</details>


### [11] [Embodied Intelligence for Advanced Bioinspired Microrobotics: Examples and Insights](https://arxiv.org/abs/2510.26132)
*Nestor O. Perez-Arancibia*

Main category: cs.RO

TL;DR: 本文讨论了具身智能作为微型机器人设计原则，强调物理结构与行为功能的协同设计，通过多个机器人平台展示了智能行为如何从结构动力学和物理交互中涌现。


<details>
  <summary>Details</summary>
Motivation: 传统机器人架构将感知、计算和执行解耦，而具身智能方法通过将智能行为嵌入到物理属性中，为毫米到厘米尺度的机器人提供更可扩展和鲁棒的替代方案。

Method: 采用协同设计方法，同时开发物理结构和行为功能，通过结构动力学、物理交互和环境交互来生成智能行为，特别是在多个微型机器人平台上实现。

Result: 开发了Bee++、RoBeetle、SMALLBug、SMARTI、WaterStrider、VLEIBot+和FRISSHBot等机器人平台，展示了智能行为从物理属性中涌现的可行性。

Conclusion: 协同设计不仅是约束条件下的经验优化方法，更是实现具身智能的推动者，为微型机器人提供了超越传统控制方法的可扩展和鲁棒解决方案。

Abstract: The term embodied intelligence (EI) conveys the notion that body morphology,
material properties, interaction with the environment, and control strategies
can be purposefully integrated into the process of robotic design to generate
intelligent behavior; in particular, locomotion and navigation. In this paper,
we discuss EI as a design principle for advanced microrobotics, with a
particular focus on co-design -- the simultaneous and interdependent
development of physical structure and behavioral function. To illustrate the
contrast between EI-inspired systems and traditional architectures that
decouple sensing, computation, and actuation, we present and discuss a
collection of robots developed by the author and his team at the Autonomous
Microrobotic Systems Laboratory (AMSL). These robots exhibit intelligent
behavior that emerges from their structural dynamics and the physical
interaction between their components and with the environment. Platforms such
as the Bee++, RoBeetle, SMALLBug, SMARTI, WaterStrider, VLEIBot+, and FRISSHBot
exemplify how feedback loops, decision logics, sensing mechanisms, and smart
actuation strategies can be embedded into the physical properties of the
robotic system itself. Along these lines, we contend that co-design is not only
a method for empirical optimization under constraints, but also an enabler of
EI, offering a scalable and robust alternative to classical control for
robotics at the mm-to-cm-scale.

</details>


### [12] [Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling](https://arxiv.org/abs/2510.26139)
*Minseo Kwon,Young J. Kim*

Main category: cs.RO

TL;DR: 提出了一种基于混合状态树的动力学TAMP框架，将符号和数值状态统一表示，结合视觉语言模型引导搜索，显著提高了复杂任务的规划成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有TAMP方法在长时域问题中因过度运动采样而成本高昂，LLMs虽提供常识先验但缺乏3D空间推理能力，无法保证几何或动力学可行性。

Method: 使用混合状态树统一表示符号和数值状态，通过现成运动规划器和物理模拟器验证动力学约束，利用VLM基于状态视觉渲染引导TAMP解搜索和回溯。

Result: 在模拟和真实世界实验中，相比传统和基于LLM的TAMP规划器，平均成功率提高32.14%-1166.67%，复杂问题规划时间减少。

Conclusion: 该框架通过统一状态表示和VLM引导，有效解决了TAMP中的运动采样效率和空间推理问题，在复杂任务中表现出优越性能。

Abstract: Task and Motion Planning (TAMP) integrates high-level task planning with
low-level motion feasibility, but existing methods are costly in long-horizon
problems due to excessive motion sampling. While LLMs provide commonsense
priors, they lack 3D spatial reasoning and cannot ensure geometric or dynamic
feasibility. We propose a kinodynamic TAMP framework based on a hybrid state
tree that uniformly represents symbolic and numeric states during planning,
enabling task and motion decisions to be jointly decided. Kinodynamic
constraints embedded in the TAMP problem are verified by an off-the-shelf
motion planner and physics simulator, and a VLM guides exploring a TAMP
solution and backtracks the search based on visual rendering of the states.
Experiments on the simulated domains and in the real world show 32.14% -
1166.67% increased average success rates compared to traditional and LLM-based
TAMP planners and reduced planning time on complex problems, with ablations
further highlighting the benefits of VLM guidance.

</details>


### [13] [Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages](https://arxiv.org/abs/2510.26142)
*Hahjin Lee,Young J. Kim*

Main category: cs.RO

TL;DR: 提出自适应轨迹优化算法，通过分段保守碰撞检测和位姿校正，解决移动机器人在狭窄通道中的轨迹规划问题，显著提高成功率和规划速度。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在复杂环境中轨迹规划的挑战，特别是在狭窄通道区域，传统方法容易失败或生成次优路径。

Method: 两阶段方法：1) 分段保守碰撞测试，递归细分风险轨迹段消除碰撞风险；2) 基于穿透方向和线性搜索的位姿校正，确保每个位姿无碰撞且远离障碍物。

Result: 仿真结果显示，相比最先进方法，成功率提高1.69倍，规划时间加快3.79倍；真实实验验证机器人能安全通过狭窄通道并保持快速规划性能。

Conclusion: 该方法有效解决了复杂环境中轨迹规划问题，特别是在狭窄通道场景下表现出优越的性能和实用性。

Abstract: Trajectory planning for mobile robots in cluttered environments remains a
major challenge due to narrow passages, where conventional methods often fail
or generate suboptimal paths. To address this issue, we propose the adaptive
trajectory refinement algorithm, which consists of two main stages. First, to
ensure safety at the path-segment level, a segment-wise conservative collision
test is applied, where risk-prone trajectory path segments are recursively
subdivided until collision risks are eliminated. Second, to guarantee
pose-level safety, pose correction based on penetration direction and line
search is applied, ensuring that each pose in the trajectory is collision-free
and maximally clear from obstacles. Simulation results demonstrate that the
proposed method achieves up to 1.69x higher success rates and up to 3.79x
faster planning times than state-of-the-art approaches. Furthermore, real-world
experiments confirm that the robot can safely pass through narrow passages
while maintaining rapid planning performance.

</details>


### [14] [Self-localization on a 3D map by fusing global and local features from a monocular camera](https://arxiv.org/abs/2510.26170)
*Satoshi Kikuch,Masaya Kato,Tsuyoshi Tasaki*

Main category: cs.RO

TL;DR: 提出了一种结合CNN和Vision Transformer的新方法，用于在动态障碍物存在时实现基于单目相机的3D地图自定位，相比现有方法显著提高了定位精度。


<details>
  <summary>Details</summary>
Motivation: 使用廉价单目相机在3D地图上进行自定位是实现自动驾驶的关键需求。现有基于CNN的方法在提取局部特征方面表现良好，但当存在动态障碍物（如行人）时效果不佳。

Method: 将擅长提取局部特征的CNN与擅长提取全局特征的Vision Transformer相结合，通过整合局部和全局特征来提升在动态障碍物环境下的定位性能。

Result: 在包含动态障碍物的CG数据集上，精度提升率比无动态障碍物时高1.5倍；在公共数据集上，自定位误差比现有最佳方法减小20.1%；机器人平均定位误差为7.51cm，优于现有方法。

Conclusion: CNN与Vision Transformer的结合方法能够有效应对动态障碍物环境，显著提升单目相机自定位的精度和鲁棒性。

Abstract: Self-localization on a 3D map by using an inexpensive monocular camera is
required to realize autonomous driving. Self-localization based on a camera
often uses a convolutional neural network (CNN) that can extract local features
that are calculated by nearby pixels. However, when dynamic obstacles, such as
people, are present, CNN does not work well. This study proposes a new method
combining CNN with Vision Transformer, which excels at extracting global
features that show the relationship of patches on whole image. Experimental
results showed that, compared to the state-of-the-art method (SOTA), the
accuracy improvement rate in a CG dataset with dynamic obstacles is 1.5 times
higher than that without dynamic obstacles. Moreover, the self-localization
error of our method is 20.1% smaller than that of SOTA on public datasets.
Additionally, our robot using our method can localize itself with 7.51cm error
on average, which is more accurate than SOTA.

</details>


### [15] [PHUMA: Physically-Grounded Humanoid Locomotion Dataset](https://arxiv.org/abs/2510.26236)
*Kyungmin Lee,Sibeen Kim,Minho Park,Hyunseung Kim,Dongyoon Hwang,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: PHUMA是一个基于物理约束的人形机器人运动数据集，通过大规模人类视频和物理约束重定向技术，解决了现有方法中的物理伪影问题，在运动模仿任务中表现优于Humanoid-X和AMASS。


<details>
  <summary>Details</summary>
Motivation: 现有运动模仿方法依赖稀缺昂贵的运动捕捉数据，而基于互联网视频的方法存在物理伪影问题，限制了可扩展性和多样性。

Method: 利用大规模人类视频，通过数据筛选和物理约束重定向技术，强制执行关节限制、确保地面接触、消除脚滑现象。

Result: 在未见运动模仿和骨盆引导路径跟随两种条件下，PHUMA训练的策略均显著优于Humanoid-X和AMASS。

Conclusion: PHUMA提供了大规模且物理可靠的运动数据，为人形机器人运动模仿提供了更好的数据基础。

Abstract: Motion imitation is a promising approach for humanoid locomotion, enabling
agents to acquire humanlike behaviors. Existing methods typically rely on
high-quality motion capture datasets such as AMASS, but these are scarce and
expensive, limiting scalability and diversity. Recent studies attempt to scale
data collection by converting large-scale internet videos, exemplified by
Humanoid-X. However, they often introduce physical artifacts such as floating,
penetration, and foot skating, which hinder stable imitation. In response, we
introduce PHUMA, a Physically-grounded HUMAnoid locomotion dataset that
leverages human video at scale, while addressing physical artifacts through
careful data curation and physics-constrained retargeting. PHUMA enforces joint
limits, ensures ground contact, and eliminates foot skating, producing motions
that are both large-scale and physically reliable. We evaluated PHUMA in two
sets of conditions: (i) imitation of unseen motion from self-recorded test
videos and (ii) path following with pelvis-only guidance. In both cases,
PHUMA-trained policies outperform Humanoid-X and AMASS, achieving significant
gains in imitating diverse motions. The code is available at
https://davian-robotics.github.io/PHUMA.

</details>


### [16] [Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments](https://arxiv.org/abs/2510.26280)
*Gangyang Li,Qing Shi,Youhao Hu,Jincheng Hu,Zhongyuan Wang,Xinlong Wang,Shaqi Luo*

Main category: cs.RO

TL;DR: 提出Thor人形机器人框架，通过力自适应躯干倾斜奖励函数和解耦强化学习架构，显著提升人形机器人在接触丰富环境中的力交互能力


<details>
  <summary>Details</summary>
Motivation: 人形机器人在服务、工业和救援应用中需要保持全身稳定性同时进行强烈的接触交互，但目前难以生成类似人类的适应性响应

Method: 基于机器人受力分析设计FAT2奖励函数；采用解耦强化学习架构，将上体、腰部和下体分开控制但共享全局观测并联合更新参数

Result: 在Unitree G1上部署，后拉峰值力达167.7N（提升68.9%），前拉145.5N（提升74.7%）；能拉动130N负载架和单手打开60N防火门

Conclusion: Thor框架有效增强了人形机器人的力交互能力，在接触丰富环境中表现出色

Abstract: Humanoids hold great potential for service, industrial, and rescue
applications, in which robots must sustain whole-body stability while
performing intense, contact-rich interactions with the environment. However,
enabling humanoids to generate human-like, adaptive responses under such
conditions remains a major challenge. To address this, we propose Thor, a
humanoid framework for human-level whole-body reactions in contact-rich
environments. Based on the robot's force analysis, we design a force-adaptive
torso-tilt (FAT2) reward function to encourage humanoids to exhibit human-like
responses during force-interaction tasks. To mitigate the high-dimensional
challenges of humanoid control, Thor introduces a reinforcement learning
architecture that decouples the upper body, waist, and lower body. Each
component shares global observations of the whole body and jointly updates its
parameters. Finally, we deploy Thor on the Unitree G1, and it substantially
outperforms baselines in force-interaction tasks. Specifically, the robot
achieves a peak pulling force of 167.7 N (approximately 48% of the G1's body
weight) when moving backward and 145.5 N when moving forward, representing
improvements of 68.9% and 74.7%, respectively, compared with the
best-performing baseline. Moreover, Thor is capable of pulling a loaded rack
(130 N) and opening a fire door with one hand (60 N). These results highlight
Thor's effectiveness in enhancing humanoid force-interaction capabilities.

</details>


### [17] [AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM](https://arxiv.org/abs/2510.26358)
*Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci*

Main category: cs.RO

TL;DR: AgriGS-SLAM是一个用于果园环境的视觉-LiDAR SLAM框架，结合直接LiDAR里程计和3D高斯泼溅渲染，在季节变化和遮挡条件下实现实时3D场景理解。


<details>
  <summary>Details</summary>
Motivation: 果园环境中的自主机器人需要实时3D场景理解，但面临重复行几何、季节性外观变化和风驱动树叶运动等挑战。

Method: 耦合直接LiDAR里程计和闭环检测与多相机3D高斯泼溅渲染，使用批量栅格化恢复遮挡下的果园结构，通过统一梯度驱动的地图生命周期管理保持细节并限制内存。

Result: 在苹果和梨园中跨休眠期、开花期和收获期部署，相比现有3DGS-SLAM基线提供更清晰稳定的重建和更平稳的轨迹，同时保持实时性能。

Conclusion: 该方法在果园监测中表现优异，也可应用于其他需要鲁棒多模态感知的户外领域。

Abstract: Autonomous robots in orchards require real-time 3D scene understanding
despite repetitive row geometry, seasonal appearance changes, and wind-driven
foliage motion. We present AgriGS-SLAM, a Visual--LiDAR SLAM framework that
couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian
Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints
recovers orchard structure under occlusions, while a unified gradient-driven
map lifecycle executed between keyframes preserves fine details and bounds
memory. Pose refinement is guided by a probabilistic LiDAR-based depth
consistency term, back-propagated through the camera projection to tighten
geometry-appearance coupling. We deploy the system on a field platform in apple
and pear orchards across dormancy, flowering, and harvesting, using a
standardized trajectory protocol that evaluates both training-view and
novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons
and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and
steadier trajectories than recent state-of-the-art 3DGS-SLAM baselines while
maintaining real-time performance on-tractor. While demonstrated in orchard
monitoring, the approach can be applied to other outdoor domains requiring
robust multimodal perception.

</details>


### [18] [Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations](https://arxiv.org/abs/2510.26362)
*Tobias Löw,Cem Bilaloglu,Sylvain Calinon*

Main category: cs.RO

TL;DR: 本文提出了基于共形几何代数的多臂机器人系统协作任务空间理论框架，通过几何基元的相似变换将复杂系统抽象为类似单臂系统，并推导了相关的雅可比矩阵用于操作空间控制。


<details>
  <summary>Details</summary>
Motivation: 人类环境中的许多任务需要多个运动链的协作行为，但高自由度的复杂系统协调运动建模困难，需要开发有效的协作控制框架。

Method: 使用共形几何代数定义协作几何基元，通过相似变换抽象复杂机器人系统，推导解析和几何雅可比矩阵，集成到经典操作空间控制技术中。

Result: 在双手机器人、人形机器人和多指手的实验中验证了方法，包括达到期望几何基元的最优控制和基于微分运动学的遥操作实验。

Conclusion: 该工作建立了协作操作控制框架的理论基础，几何基元自然嵌入零空间结构可用于引入次级控制目标，为未来应用提供了方向。

Abstract: Many tasks in human environments require collaborative behavior between
multiple kinematic chains, either to provide additional support for carrying
big and bulky objects or to enable the dexterity that is required for in-hand
manipulation. Since these complex systems often have a very high number of
degrees of freedom coordinating their movements is notoriously difficult to
model. In this article, we present the derivation of the theoretical
foundations for cooperative task spaces of multi-arm robotic systems based on
geometric primitives defined using conformal geometric algebra. Based on the
similarity transformations of these cooperative geometric primitives, we derive
an abstraction of complex robotic systems that enables representing these
systems in a way that directly corresponds to single-arm systems. By deriving
the associated analytic and geometric Jacobian matrices, we then show the
straightforward integration of our approach into classical control techniques
rooted in operational space control. We demonstrate this using bimanual
manipulators, humanoids and multi-fingered hands in optimal control experiments
for reaching desired geometric primitives and in teleoperation experiments
using differential kinematics control. We then discuss how the geometric
primitives naturally embed nullspace structures into the controllers that can
be exploited for introducing secondary control objectives. This work,
represents the theoretical foundations of this cooperative manipulation control
framework, and thus the experiments are presented in an abstract way, while
giving pointers towards potential future applications.

</details>


### [19] [Towards Reinforcement Learning Based Log Loading Automation](https://arxiv.org/abs/2510.26363)
*Ilya Kurinov,Miroslav Ivanov,Grzegorz Orzechowski,Aki Mikkola*

Main category: cs.RO

TL;DR: 该研究使用强化学习代理自动化林业集材机的完整原木装载过程，从抓取到运输，在模拟环境中实现了94%的成功率。


<details>
  <summary>Details</summary>
Motivation: 林业集材机操作对操作员来说具有挑战性且身心疲惫，部分自动化可以减轻操作员压力。

Method: 在NVIDIA Isaac Gym中开发林业集材机模拟模型，使用强化学习代理和课程学习方法训练自动化装载过程。

Result: 最佳代理从随机位置抓取原木并运输到车厢的成功率达到94%。

Conclusion: 训练出的代理是向林业集材机自动化应用强化学习代理的重要进展。

Abstract: Forestry forwarders play a central role in mechanized timber harvesting by
picking up and moving logs from the felling site to a processing area or a
secondary transport vehicle. Forwarder operation is challenging and physically
and mentally exhausting for the operator who must control the machine in remote
areas for prolonged periods of time. Therefore, even partial automation of the
process may reduce stress on the operator. This study focuses on continuing
previous research efforts in application of reinforcement learning agents in
automating log handling process, extending the task from grasping which was
studied in previous research to full log loading operation. The resulting agent
will be capable to automate a full loading procedure from locating and
grappling to transporting and delivering the log to a forestry forwarder bed.
To train the agent, a trailer type forestry forwarder simulation model in
NVIDIA's Isaac Gym and a virtual environment for a typical log loading scenario
were developed. With reinforcement learning agents and a curriculum learning
approach, the trained agent may be a stepping stone towards application of
reinforcement learning agents in automation of the forestry forwarder. The
agent learnt grasping a log in a random position from grapple's random position
and transport it to the bed with 94% success rate of the best performing agent.

</details>


### [20] [Human-in-the-loop Online Rejection Sampling for Robotic Manipulation](https://arxiv.org/abs/2510.26406)
*Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang*

Main category: cs.RO

TL;DR: Hi-ORS是一种简单有效的后训练方法，通过拒绝采样实现训练稳定性和高鲁棒性，在1.5小时真实世界训练中显著优于RL和IL基线方法


<details>
  <summary>Details</summary>
Motivation: 强化学习训练视觉-语言-动作模型时存在价值估计不准确和中间步骤监督稀疏的问题，而模仿学习虽然易于训练但性能较差

Method: 采用拒绝采样过滤负奖励样本来稳定价值估计，使用奖励加权的监督训练目标提供密集中间步骤监督，并开发异步推理训练框架支持在线人工校正

Result: 在三个真实世界任务和两种体现中，Hi-ORS仅用1.5小时真实训练就掌握了接触丰富的操作，在效果和效率上都大幅超越RL和IL基线方法

Conclusion: Hi-ORS方法能够稳定训练视觉-语言-动作模型，展现出强大的测试时扩展性，能够可靠执行复杂错误恢复行为以获得更好性能

Abstract: Reinforcement learning (RL) is widely used to produce robust robotic
manipulation policies, but fine-tuning vision-language-action (VLA) models with
RL can be unstable due to inaccurate value estimates and sparse supervision at
intermediate steps. In contrast, imitation learning (IL) is easy to train but
often underperforms due to its offline nature. In this paper, we propose
Hi-ORS, a simple yet effective post-training method that utilizes rejection
sampling to achieve both training stability and high robustness. Hi-ORS
stabilizes value estimation by filtering out negatively rewarded samples during
online fine-tuning, and adopts a reward-weighted supervised training objective
to provide dense intermediate-step supervision. For systematic study, we
develop an asynchronous inference-training framework that supports flexible
online human-in-the-loop corrections, which serve as explicit guidance for
learning error-recovery behaviors. Across three real-world tasks and two
embodiments, Hi-ORS fine-tunes a pi-base policy to master contact-rich
manipulation in just 1.5 hours of real-world training, outperforming RL and IL
baselines by a substantial margin in both effectiveness and efficiency.
Notably, the fine-tuned policy exhibits strong test-time scalability by
reliably executing complex error-recovery behaviors to achieve better
performance.

</details>


### [21] [RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration](https://arxiv.org/abs/2510.26536)
*Huajie Tan,Cheng Chi,Xiansheng Chen,Yuheng Ji,Zhongxia Zhao,Xiaoshuai Hao,Yaoxu Lyu,Mingyu Cao,Junkai Zhao,Huaihai Lyu,Enshen Zhou,Ning Chen,Yankai Fu,Cheng Peng,Wei Guo,Dong Liang,Zhuo Chen,Mengsi Lyu,Chenrui He,Yulong Ao,Yonghua Lin,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 提出了RoboOS-NeXT框架，通过统一的时空-具身记忆(STEM)实现多机器人系统的终身适应、可扩展协调和鲁棒调度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖有限的个体记忆，无法实现长期学习、异构团队扩展或故障恢复，需要统一的内存表示。

Method: 核心是STEM记忆，整合空间场景几何、时间事件历史和具身配置文件；采用脑-小脑框架，高层脑模型进行全局规划，低层控制器本地执行。

Result: 在餐厅、超市和家庭等复杂协调任务中表现出优越性能，验证了其在异构具身系统中的有效性。

Conclusion: RoboOS-NeXT通过统一记忆表示成功实现了终身、可扩展和鲁棒的多机器人协作。

Abstract: The proliferation of collaborative robots across diverse tasks and
embodiments presents a central challenge: achieving lifelong adaptability,
scalable coordination, and robust scheduling in multi-agent systems. Existing
approaches, from vision-language-action (VLA) models to hierarchical
frameworks, fall short due to their reliance on limited or dividual-agent
memory. This fundamentally constrains their ability to learn over long
horizons, scale to heterogeneous teams, or recover from failures, highlighting
the need for a unified memory representation. To address these limitations, we
introduce RoboOS-NeXT, a unified memory-based framework for lifelong, scalable,
and robust multi-robot collaboration. At the core of RoboOS-NeXT is the novel
Spatio-Temporal-Embodiment Memory (STEM), which integrates spatial scene
geometry, temporal event history, and embodiment profiles into a shared
representation. This memory-centric design is integrated into a
brain-cerebellum framework, where a high-level brain model performs global
planning by retrieving and updating STEM, while low-level controllers execute
actions locally. This closed loop between cognition, memory, and execution
enables dynamic task allocation, fault-tolerant collaboration, and consistent
state synchronization. We conduct extensive experiments spanning complex
coordination tasks in restaurants, supermarkets, and households. Our results
demonstrate that RoboOS-NeXT achieves superior performance across heterogeneous
embodiments, validating its effectiveness in enabling lifelong, scalable, and
robust multi-robot collaboration. Project website:
https://flagopen.github.io/RoboOS/

</details>


### [22] [Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics](https://arxiv.org/abs/2510.26551)
*Prathamesh Kothavale,Sravani Boddepalli*

Main category: cs.RO

TL;DR: 提出了一种扩展机器人逆运动学求解器的新框架，使机器人能够学习使用不同长度工具的顺序动作，并在仿真和现实世界中实现技能迁移。


<details>
  <summary>Details</summary>
Motivation: 传统机器人对自身运动学理解有限，局限于预编程任务，无法有效利用工具。需要解决工具使用的四个关键要素：理解期望结果、选择合适工具、确定最佳工具方向、执行精确操作。

Method: 扩展机器人逆运动学求解器，集成仿真学习的动作轨迹与工具，使机器人能够获取使用不同长度工具的顺序动作库。

Result: 扩展逆运动学求解器误差小于1cm；训练策略在仿真中平均误差8cm；使用两种不同长度工具时性能几乎无差异。

Conclusion: 该研究为探索工具使用的四个基本方面提供了潜在进展，使机器人能够在多样化任务中掌握复杂的工具操作技能。

Abstract: Conventional robots possess a limited understanding of their kinematics and
are confined to preprogrammed tasks, hindering their ability to leverage tools
efficiently. Driven by the essential components of tool usage - grasping the
desired outcome, selecting the most suitable tool, determining optimal tool
orientation, and executing precise manipulations - we introduce a pioneering
framework. Our novel approach expands the capabilities of the robot's inverse
kinematics solver, empowering it to acquire a sequential repertoire of actions
using tools of varying lengths. By integrating a simulation-learned action
trajectory with the tool, we showcase the practicality of transferring acquired
skills from simulation to real-world scenarios through comprehensive
experimentation. Remarkably, our extended inverse kinematics solver
demonstrates an impressive error rate of less than 1 cm. Furthermore, our
trained policy achieves a mean error of 8 cm in simulation. Noteworthy, our
model achieves virtually indistinguishable performance when employing two
distinct tools of different lengths. This research provides an indication of
potential advances in the exploration of all four fundamental aspects of tool
usage, enabling robots to master the intricate art of tool manipulation across
diverse tasks.

</details>


### [23] [FLYINGTRUST: A Benchmark for Quadrotor Navigation Across Scenarios and Vehicles](https://arxiv.org/abs/2510.26588)
*Gang Li,Chunlei Zhai,Teng Wang,Shaun Li,Shangsong Jiang,Xiangwei Zhu*

Main category: cs.RO

TL;DR: FLYINGTRUST是一个高保真、可配置的四旋翼视觉导航基准测试框架，用于评估平台动力学和场景结构对导航鲁棒性的联合影响。


<details>
  <summary>Details</summary>
Motivation: 四旋翼视觉导航算法在不同车辆平台和场景几何下性能差异很大，增加了现场部署的成本和风险，需要系统化的早期评估方法。

Method: 使用最大推重比和轴最大角加速度作为平台能力指标，结合多样化场景库和异构平台集，采用标准化评估协议和复合评分方法。

Result: 发现导航成功率可预测地依赖于平台能力和场景几何，不同算法在评估条件下表现出不同的偏好和故障模式。

Conclusion: 需要将平台能力和场景结构纳入算法设计、评估和选择，并开发在多样化平台和场景下保持鲁棒性的方法。

Abstract: Visual navigation algorithms for quadrotors often exhibit a large variation
in performance when transferred across different vehicle platforms and scene
geometries, which increases the cost and risk of field deployment. To support
systematic early-stage evaluation, we introduce FLYINGTRUST, a high-fidelity,
configurable benchmarking framework that measures how platform kinodynamics and
scenario structure jointly affect navigation robustness. FLYINGTRUST models
vehicle capability with two compact, physically interpretable indicators:
maximum thrust-to-weight ratio and axis-wise maximum angular acceleration. The
benchmark pairs a diverse scenario library with a heterogeneous set of real and
virtual platforms and prescribes a standardized evaluation protocol together
with a composite scoring method that balances scenario importance, platform
importance and performance stability. We use FLYINGTRUST to compare
representative optimization-based and learning-based navigation approaches
under identical conditions, performing repeated trials per platform-scenario
combination and reporting uncertainty-aware metrics. The results reveal
systematic patterns: navigation success depends predictably on platform
capability and scene geometry, and different algorithms exhibit distinct
preferences and failure modes across the evaluated conditions. These
observations highlight the practical necessity of incorporating both platform
capability and scenario structure into algorithm design, evaluation, and
selection, and they motivate future work on methods that remain robust across
diverse platforms and scenarios.

</details>


### [24] [A Sliding-Window Filter for Online Continuous-Time Continuum Robot State Estimation](https://arxiv.org/abs/2510.26623)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 提出了一种用于连续体机器人连续时间状态估计的滑动窗口滤波器，在保持滤波器方法精度的同时实现在线操作，且运行速度快于实时速度。


<details>
  <summary>Details</summary>
Motivation: 现有连续体机器人状态估计方法难以平衡精度和计算效率，滑动窗口方法局限于简化离散时间近似且缺乏随机表示，而随机滤波器方法受限于测量速度，连续时间估计方法目前仅限于离线操作。

Method: 开发了一种专门针对连续体机器人的随机滑动窗口滤波器，用于连续时间状态估计，结合了滑动窗口和连续时间方法的优势。

Result: 该方法提高了滤波器方法的精度，使连续时间方法能够在线运行，且运行速度快于实时速度。

Conclusion: 这是首个专门为连续体机器人设计的随机滑动窗口滤波器，为该领域未来研究提供了有前景的方向。

Abstract: Stochastic state estimation methods for continuum robots (CRs) often struggle
to balance accuracy and computational efficiency. While several recent works
have explored sliding-window formulations for CRs, these methods are limited to
simplified, discrete-time approximations and do not provide stochastic
representations. In contrast, current stochastic filter methods must run at the
speed of measurements, limiting their full potential. Recent works in
continuous-time estimation techniques for CRs show a principled approach to
addressing this runtime constraint, but are currently restricted to offline
operation. In this work, we present a sliding-window filter (SWF) for
continuous-time state estimation of CRs that improves upon the accuracy of a
filter approach while enabling continuous-time methods to operate online, all
while running at faster-than-real-time speeds. This represents the first
stochastic SWF specifically designed for CRs, providing a promising direction
for future research in this area.

</details>


### [25] [REALMS2 -- Resilient Exploration And Lunar Mapping System 2 -- A Comprehensive Approach](https://arxiv.org/abs/2510.26638)
*Dave van der Meer,Loïck P. Chovet,Gabriel M. Garcia,Abhishek Bera,Miguel A. Olivares-Mendez*

Main category: cs.RO

TL;DR: REALMS2是一个基于ROS 2的多机器人系统框架，用于行星勘探和地图绘制，采用vSLAM技术生成地图，通过网状网络实现鲁棒通信，在ESA-ESRIC挑战赛中成功绘制了约60%的区域。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统在太空勘探中的挑战，特别是针对异质多机器人勘探任务在极端环境下的通信延迟和中断问题。

Method: 基于ROS 2框架，集成视觉SLAM技术进行地图生成，采用网状网络构建鲁棒的ad hoc网络，通过单一GUI界面控制所有漫游车。

Result: 在ESA-ESRIC挑战赛的第二次实地测试中，使用三个同质漫游车成功绘制了约60%的区域，并有效处理了通信延迟和中断。

Conclusion: REALMS2系统证明了其在行星勘探任务中的有效性，能够应对极端环境下的通信挑战，为多机器人太空勘探提供了可行的解决方案。

Abstract: The European Space Agency (ESA) and the European Space Resources Innovation
Centre (ESRIC) created the Space Resources Challenge to invite researchers and
companies to propose innovative solutions for Multi-Robot Systems (MRS) space
prospection. This paper proposes the Resilient Exploration And Lunar Mapping
System 2 (REALMS2), a MRS framework for planetary prospection and mapping.
Based on Robot Operating System version 2 (ROS 2) and enhanced with Visual
Simultaneous Localisation And Mapping (vSLAM) for map generation, REALMS2 uses
a mesh network for a robust ad hoc network. A single graphical user interface
(GUI) controls all the rovers, providing a simple overview of the robotic
mission. This system is designed for heterogeneous multi-robot exploratory
missions, tackling the challenges presented by extraterrestrial environments.
REALMS2 was used during the second field test of the ESA-ESRIC Challenge and
allowed to map around 60% of the area, using three homogeneous rovers while
handling communication delays and blackouts.

</details>


### [26] [Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments](https://arxiv.org/abs/2510.26646)
*Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai*

Main category: cs.RO

TL;DR: 提出分层路径规划与控制框架，结合高层DQN进行离散子目标选择与底层TD3控制器进行连续执行，在动态和部分可观测环境中提升成功率和样本效率。


<details>
  <summary>Details</summary>
Motivation: 解决单一算法在复杂环境中路径规划的局限性，通过分层结构结合离散决策与连续控制，提高系统的鲁棒性和泛化能力。

Method: 使用高层DQN选择行为和子目标，底层TD3执行平滑速度命令，设计实用奖励机制和LiDAR安全门防止不安全动作，在ROS+Gazebo中实现并评估。

Result: 相比单一算法基准和基于规则的规划器，在动态和部分可观测环境中表现出更高的成功率、更好的样本效率，对未见障碍配置具有更好泛化能力，控制变化更平滑。

Conclusion: 分层框架有效结合离散决策与连续控制，在复杂环境中实现更可靠和高效的路径规划，代码和评估脚本已开源。

Abstract: This paper presents a hierarchical path-planning and control framework that
combines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with
a low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller
for continuous actuation. The high-level module selects behaviors and
sub-goals; the low-level module executes smooth velocity commands. We design a
practical reward shaping scheme (direction, distance, obstacle avoidance,
action smoothness, collision penalty, time penalty, and progress), together
with a LiDAR-based safety gate that prevents unsafe motions. The system is
implemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,
including success rate, collision rate, path efficiency, and re-planning
efficiency, in dynamic and partially observable environments. Experiments show
improved success rate and sample efficiency over single-algorithm baselines
(DQN or TD3 alone) and rule-based planners, with better generalization to
unseen obstacle configurations and reduced abrupt control changes. Code and
evaluation scripts are available at the project repository.

</details>


### [27] [Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems](https://arxiv.org/abs/2510.26656)
*Georgios Kamaras,Craig Innes,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 提出三种启发式LFI变体（EDGE、MODE、CENTRE）来解决支持集错误设定问题，通过自适应调整支持集来改进后验推断，在动态可变形线性物体操作任务中实现了更好的参数推断和策略学习效果。


<details>
  <summary>Details</summary>
Motivation: 传统LFI方法假设固定的采样支持集，但错误设定的支持集会导致次优且虚假确定的后验分布，影响机器人领域自适应学习的效果。

Method: 提出三种启发式LFI变体：EDGE、MODE和CENTRE，每种方法以不同方式解释后验模态在推理步骤中的偏移，并在LFI步骤中自适应调整支持集。

Result: 在随机动态基准测试中验证了支持集错误设定问题，在DLO操作任务中实现了更精细的长度和刚度分类，使用得到的后验作为领域分布进行策略学习时，获得了更鲁棒的目标中心智能体性能。

Conclusion: 启发式支持集自适应方法能够有效解决LFI中的支持集错误设定问题，提升参数推断精度和策略学习鲁棒性，特别是在复杂机器人操作任务中表现优异。

Abstract: In robotics, likelihood-free inference (LFI) can provide the domain
distribution that adapts a learnt agent in a parametric set of deployment
conditions. LFI assumes an arbitrary support for sampling, which remains
constant as the initial generic prior is iteratively refined to more
descriptive posteriors. However, a potentially misspecified support can lead to
suboptimal, yet falsely certain, posteriors. To address this issue, we propose
three heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the
posterior mode shift over inference steps in its own way and, when integrated
into an LFI step, adapts the support alongside posterior inference. We first
expose the support misspecification issue and evaluate our heuristics using
stochastic dynamical benchmarks. We then evaluate the impact of heuristic
support adaptation on parameter inference and policy learning for a dynamic
deformable linear object (DLO) manipulation task. Inference results in a finer
length and stiffness classification for a parametric set of DLOs. When the
resulting posteriors are used as domain distributions for sim-based policy
learning, they lead to more robust object-centric agent performance.

</details>


### [28] [Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation](https://arxiv.org/abs/2510.26670)
*Qianyou Zhao,Yuliang Shen,Xuanran Zhai,Ce Hao,Duidi Wu,Jin Qi,Jie Hu,Qiaojun Yu*

Main category: cs.RO

TL;DR: 提出混合一致性策略(HCP)，通过结合短随机前缀和一步一致性跳跃，在保持多模态行为的同时显著加速扩散策略的推理速度


<details>
  <summary>Details</summary>
Motivation: 解决扩散模仿学习中普通和随机去噪过程难以同时实现快速采样和强多模态的问题

Method: 运行短随机前缀到自适应切换时间，然后应用一步一致性跳跃生成最终动作；使用时变一致性蒸馏结合轨迹一致性目标和去噪匹配目标

Result: 在仿真和真实机器人上，HCP仅需25步SDE加一次跳跃即可接近80步DDPM教师的准确性和模态覆盖度，同时显著降低延迟

Conclusion: 多模态不需要慢推理，切换时间将模态保持与速度解耦，为机器人策略提供了实用的准确性与效率权衡

Abstract: In visuomotor policy learning, diffusion-based imitation learning has become
widely adopted for its ability to capture diverse behaviors. However,
approaches built on ordinary and stochastic denoising processes struggle to
jointly achieve fast sampling and strong multi-modality. To address these
challenges, we propose the Hybrid Consistency Policy (HCP). HCP runs a short
stochastic prefix up to an adaptive switch time, and then applies a one-step
consistency jump to produce the final action. To align this one-jump
generation, HCP performs time-varying consistency distillation that combines a
trajectory-consistency objective to keep neighboring predictions coherent and a
denoising-matching objective to improve local fidelity. In both simulation and
on a real robot, HCP with 25 SDE steps plus one jump approaches the 80-step
DDPM teacher in accuracy and mode coverage while significantly reducing
latency. These results show that multi-modality does not require slow
inference, and a switch time decouples mode retention from speed. It yields a
practical accuracy efficiency trade-off for robot policies.

</details>


### [29] [Running VLAs at Real-time Speed](https://arxiv.org/abs/2510.26742)
*Yunchao Ma,Yizhuang Zhou,Yunhuan Yang,Tiancai Wang,Haoqiang Fan*

Main category: cs.RO

TL;DR: 提出了一种在单张消费级GPU上实现30Hz帧率和480Hz轨迹频率的多视角VLA实时推理方法，使大型VLA模型能够完成动态实时任务


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言动作模型在实时机器人控制中的推理延迟问题，实现之前被认为无法达到的动态实时任务

Method: 引入一系列策略消除模型推理中的开销，包括优化推理流程和提出完整的流式推理框架

Result: 在抓取下落笔的任务中实现了100%的成功率，证明了方法的有效性

Conclusion: 成功实现了VLA模型的实时推理，为实时机器人控制提供了可行的解决方案

Abstract: In this paper, we show how to run pi0-level multi-view VLA at 30Hz frame rate
and at most 480Hz trajectory frequency using a single consumer GPU. This
enables dynamic and real-time tasks that were previously believed to be
unattainable by large VLA models. To achieve it, we introduce a bag of
strategies to eliminate the overheads in model inference. The real-world
experiment shows that the pi0 policy with our strategy achieves a 100% success
rate in grasping a falling pen task. Based on the results, we further propose a
full streaming inference framework for real-time robot control of VLA. Code is
available at https://github.com/Dexmal/realtime-vla.

</details>
