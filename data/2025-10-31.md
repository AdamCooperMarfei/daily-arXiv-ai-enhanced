<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 29]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Debate2Create: Robot Co-design via Large Language Model Debates](https://arxiv.org/abs/2510.25850)
*Kevin Qiu,Marek Cygan*

Main category: cs.RO

TL;DR: D2C框架使用LLM代理进行结构化辩论，共同优化机器人形态和控制，通过迭代辩论产生有效的机器人设计。


<details>
  <summary>Details</summary>
Motivation: 解决机器人形态与控制协同设计的自动化挑战，因为设计空间庞大且身体与行为紧密耦合。

Method: 设计代理提出形态修改，控制代理设计对应奖励函数，评审团在模拟中评估并提供反馈，通过多轮辩论迭代优化。

Result: 在四足机器人运动基准测试中，D2C发现的设计比默认设计移动距离远73%，且产生了多样化的专业形态。

Conclusion: 基于LLM的多智能体辩论结合物理基础反馈，是自动化机器人设计的有前景新范式。

Abstract: Automating the co-design of a robot's morphology and control is a
long-standing challenge due to the vast design space and the tight coupling
between body and behavior. We introduce Debate2Create (D2C), a framework in
which large language model (LLM) agents engage in a structured dialectical
debate to jointly optimize a robot's design and its reward function. In each
round, a design agent proposes targeted morphological modifications, and a
control agent devises a reward function tailored to exploit the new design. A
panel of pluralistic judges then evaluates the design-control pair in
simulation and provides feedback that guides the next round of debate. Through
iterative debates, the agents progressively refine their proposals, producing
increasingly effective robot designs. Notably, D2C yields diverse and
specialized morphologies despite no explicit diversity objective. On a
quadruped locomotion benchmark, D2C discovers designs that travel 73% farther
than the default, demonstrating that structured LLM-based debate can serve as a
powerful mechanism for emergent robot co-design. Our results suggest that
multi-agent debate, when coupled with physics-grounded feedback, is a promising
new paradigm for automated robot design.

</details>


### [2] [Risk-Aware Safety Filters with Poisson Safety Functions and Laplace Guidance Fields](https://arxiv.org/abs/2510.25913)
*Gilbert Bahati,Ryan M. Bena,Meg Wilkinson,Pol Mestres,Ryan K. Cosner,Aaron D. Ames*

Main category: cs.RO

TL;DR: 该论文提出了一种基于泊松方程和拉普拉斯引导场的风险感知安全过滤器，用于机器人导航系统。通过求解泊松方程的狄利克雷问题生成安全函数，再求解拉普拉斯方程生成安全引导场，两者结合构建风险感知的安全约束。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的机器人系统需要对其环境进行语义理解以确定安全动作。本文旨在开发能够感知风险的数学表示方法，特别是开发风险感知的安全过滤器。

Method: 采用两步法：1) 通过泊松方程的狄利克雷问题生成编码系统安全的安全函数；2) 通过拉普拉斯方程的狄利克雷问题合成安全引导场，通过可调通量边界条件编码障碍物周围的可变谨慎级别。

Result: 安全函数和引导场结合定义了安全约束，并合成了风险感知安全过滤器。该过滤器在给定环境语义理解和相关风险级别的情况下，保证安全的同时优先避开高风险障碍物。

Conclusion: 该方法在仿真中得到验证，展示了如何将先验的障碍物风险理解直接纳入安全过滤器，生成风险感知的安全行为。

Abstract: Robotic systems navigating in real-world settings require a semantic
understanding of their environment to properly determine safe actions. This
work aims to develop the mathematical underpinnings of such a representation --
specifically, the goal is to develop safety filters that are risk-aware. To
this end, we take a two step approach: encoding an understanding of the
environment via Poisson's equation, and associated risk via Laplace guidance
fields. That is, we first solve a Dirichlet problem for Poisson's equation to
generate a safety function that encodes system safety as its 0-superlevel set.
We then separately solve a Dirichlet problem for Laplace's equation to
synthesize a safe \textit{guidance field} that encodes variable levels of
caution around obstacles -- by enforcing a tunable flux boundary condition. The
safety function and guidance fields are then combined to define a safety
constraint and used to synthesize a risk-aware safety filter which, given a
semantic understanding of an environment with associated risk levels of
environmental features, guarantees safety while prioritizing avoidance of
higher risk obstacles. We demonstrate this method in simulation and discuss how
\textit{a priori} understandings of obstacle risk can be directly incorporated
into the safety filter to generate safe behaviors that are risk-aware.

</details>


### [3] [Curvature-Aware Calibration of Tactile Sensors for Accurate Force Estimation on Non-Planar Surfaces](https://arxiv.org/abs/2510.25965)
*Luoyan Zhong,Heather Jin Hee Kim,Dylan P. Losey,Cara M. Nunez*

Main category: cs.RO

TL;DR: 提出了一种针对柔性触觉传感器的曲率感知校准方法，通过神经网络预测局部曲率，解决了传感器在曲面几何上精度下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有柔性触觉传感器主要在平面基底上校准，但在实际应用中需要贴合曲面和不规则表面，导致精度和一致性下降，限制了其可靠性。

Method: 开发了电阻式触觉传感器的校准模型，训练多层感知器神经网络从无负载时的基线传感器输出预测局部曲率。

Result: 在5个不同曲率的日常物体上验证，曲率感知校准在所有表面上保持一致的力精度，而平面校准会随着曲率增加而低估力值。神经网络预测曲率的R2得分为0.91。

Conclusion: 曲率感知建模显著提高了柔性触觉传感器的准确性、一致性和可靠性，使其能够在实际应用中保持稳定性能。

Abstract: Flexible tactile sensors are increasingly used in real-world applications
such as robotic grippers, prosthetic hands, wearable gloves, and assistive
devices, where they need to conform to curved and irregular surfaces. However,
most existing tactile sensors are calibrated only on flat substrates, and their
accuracy and consistency degrade once mounted on curved geometries. This
limitation restricts their reliability in practical use. To address this
challenge, we develop a calibration model for a widely used resistive tactile
sensor design that enables accurate force estimation on one-dimensional curved
surfaces. We then train a neural network (a multilayer perceptron) to predict
local curvature from baseline sensor outputs recorded under no applied load,
achieving an R2 score of 0.91. The proposed approach is validated on five daily
objects with varying curvatures under forces from 2 N to 8 N. Results show that
the curvature-aware calibration maintains consistent force accuracy across all
surfaces, while flat-surface calibration underestimates force as curvature
increases. Our results demonstrate that curvature-aware modeling improves the
accuracy, consistency, and reliability of flexible tactile sensors, enabling
dependable performance across real-world applications.

</details>


### [4] [A New Type of Axis-Angle Attitude Control Law for Rotational Systems: Synthesis, Analysis, and Experiments](https://arxiv.org/abs/2510.25985)
*Francisco M. F. R. Gonçalves,Ryan M. Bena,Néstor O. Pérez-Arancibia*

Main category: cs.RO

TL;DR: 提出了一种基于欧拉轴角的姿态控制新方法，相比传统四元数方法能保证唯一闭环平衡点，提供更灵活的比例控制，并通过李雅普诺夫函数证明系统稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统四元数姿态控制方法存在闭环平衡点不唯一的问题，且当姿态误差超过π弧度时，比例控制效果会减弱。需要开发能更好利用欧拉轴角信息的新控制方法。

Method: 设计基于欧拉轴角的姿态控制律，通过构造严格李雅普诺夫函数来证明闭环旋转系统的唯一平衡点具有一致渐近稳定性。

Result: 数值仿真和四旋翼无人机实时翻滚恢复实验表明，所提出的轴角方法在稳定时间方面优于高性能四元数控制器。

Conclusion: 基于欧拉轴角的姿态控制方法在保证唯一平衡点和系统稳定性方面优于传统四元数方法，实际飞行测试验证了其优越性能。

Abstract: Over the past few decades, continuous quaternion-based attitude control has
been proven highly effective for driving rotational systems that can be modeled
as rigid bodies, such as satellites and drones. However, methods rooted in this
approach do not enforce the existence of a unique closed-loop (CL) equilibrium
attitude-error quaternion (AEQ); and, for rotational errors about the
attitude-error Euler axis larger than {\pi}rad, their proportional-control
effect diminishes as the system state moves away from the stable equilibrium of
the CL rotational dynamics. In this paper, we introduce a new type of attitude
control law that more effectively leverages the attitude-error Euler axis-angle
information to guarantee a unique CL equilibrium AEQ and to provide greater
flexibility in the use of proportional-control efforts. Furthermore, using two
different control laws as examples-through the construction of a strict
Lyapunov function for the CL dynamics-we demonstrate that the resulting unique
equilibrium of the CL rotational system can be enforced to be uniformly
asymptotically stable. To assess and demonstrate the functionality and
performance of the proposed approach, we performed numerical simulations and
executed dozens of real-time tumble-recovery maneuvers using a small quadrotor.
These simulations and flight tests compellingly demonstrate that the proposed
axis-angle-based method achieves superior flight performance-compared with that
obtained using a high-performance quaternion-based controller-in terms of
stabilization time.

</details>


### [5] [DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System](https://arxiv.org/abs/2510.26004)
*Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang*

Main category: cs.RO

TL;DR: DARTS是一个基于无人机和AI的实时交通事故检测系统，通过集成无人机的高机动性、热成像技术和轻量级深度学习框架，实现了99%的检测准确率，并在实地测试中比传统方法提前12分钟检测到事故。


<details>
  <summary>Details</summary>
Motivation: 传统交通事故检测方法存在检测与验证分离、灵活性有限、需要密集基础设施等问题，限制了系统的适应性和可扩展性。

Method: DARTS结合无人机的高机动性和空中视角进行自适应监控，使用热成像技术提升低能见度性能和隐私保护，并采用轻量级深度学习框架进行实时车辆轨迹提取和事故检测。

Result: 在自收集数据集上达到99%的检测准确率，在佛罗里达州75号州际公路实地测试中，比当地交通管理中心提前12分钟检测到追尾事故，并能监控事故引发的拥堵传播。

Conclusion: DARTS展示了更灵活和集成的实时交通事故检测系统的潜力，对现代交通管理的运营效率和响应能力具有重要影响，特别是在偏远地区和资源受限环境中具有可扩展性和成本效益。

Abstract: Rapid and reliable incident detection is critical for reducing crash-related
fatalities, injuries, and congestion. However, conventional methods, such as
closed-circuit television, dashcam footage, and sensor-based detection,
separate detection from verification, suffer from limited flexibility, and
require dense infrastructure or high penetration rates, restricting
adaptability and scalability to shifting incident hotspots. To overcome these
challenges, we developed DARTS, a drone-based, AI-powered real-time traffic
incident detection system. DARTS integrates drones' high mobility and aerial
perspective for adaptive surveillance, thermal imaging for better
low-visibility performance and privacy protection, and a lightweight deep
learning framework for real-time vehicle trajectory extraction and incident
detection. The system achieved 99% detection accuracy on a self-collected
dataset and supports simultaneous online visual verification, severity
assessment, and incident-induced congestion propagation monitoring via a
web-based interface. In a field test on Interstate 75 in Florida, DARTS
detected and verified a rear-end collision 12 minutes earlier than the local
transportation management center and monitored incident-induced congestion
propagation, suggesting potential to support faster emergency response and
enable proactive traffic control to reduce congestion and secondary crash risk.
Crucially, DARTS's flexible deployment architecture reduces dependence on
frequent physical patrols, indicating potential scalability and
cost-effectiveness for use in remote areas and resource-constrained settings.
This study presents a promising step toward a more flexible and integrated
real-time traffic incident detection system, with significant implications for
the operational efficiency and responsiveness of modern transportation
management.

</details>


### [6] [RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras](https://arxiv.org/abs/2510.26018)
*Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska*

Main category: cs.RO

TL;DR: 提出了一种使用微型无人机群配合单探测器康普顿相机定位放射性材料的新方法，通过融合稀疏测量数据实时估计辐射源位置，并利用动态反馈控制无人机运动。


<details>
  <summary>Details</summary>
Motivation: 利用重量仅40克的单探测器康普顿相机作为高灵敏度微型辐射探测器，为协作微型无人机团队进行辐射检测开辟了新可能性。

Method: 采用单探测器康普顿相机进行辐射检测，通过融合康普顿相机测量数据实时估计辐射源位置，在无人机上直接进行数据读取和处理，并利用动态反馈控制无人机群的运动。

Result: 无人机群能够紧密协作以最大化康普顿相机获取的信息，快速定位辐射源，甚至能够跟踪移动的辐射源。

Conclusion: 该方法展示了使用轻量化康普顿相机和协作无人机群进行实时辐射源定位和跟踪的有效性。

Abstract: We present a novel approach to localizing radioactive material by cooperating
Micro Aerial Vehicles (MAVs). Our approach utilizes a state-of-the-art
single-detector Compton camera as a highly sensitive, yet miniature detector of
ionizing radiation. The detector's exceptionally low weight (40 g) opens up new
possibilities of radiation detection by a team of cooperating agile MAVs. We
propose a new fundamental concept of fusing the Compton camera measurements to
estimate the position of the radiation source in real time even from extremely
sparse measurements. The data readout and processing are performed directly
onboard and the results are used in a dynamic feedback to drive the motion of
the vehicles. The MAVs are stabilized in a tightly cooperating swarm to
maximize the information gained by the Compton cameras, rapidly locate the
radiation source, and even track a moving radiation source.

</details>


### [7] [Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods](https://arxiv.org/abs/2510.26040)
*Emily Steiner,Daniel van der Spuy,Futian Zhou,Afereti Pama,Minas Liarokapis,Henry Williams*

Main category: cs.RO

TL;DR: 本文提出了一种新型的自主赛车和超车智能体，能够在模拟和现实中可靠地导航赛道并超越对手，在F1Tenth竞赛中实现了87%的超车成功率。


<details>
  <summary>Details</summary>
Motivation: 当前自主轮对轮赛车和超车技术仍然严重受限，特别是在真实驾驶场景中，现有算法难以安全可靠地完成超车操作，而可靠的超车能力对于安全的自主轮对轮赛车至关重要。

Method: 开发了一种能够学习在赛道导航和超越对手的新型赛车超车智能体，并在F1Tenth车辆上进行部署，与运行不同竞争算法的对手进行实际对抗。

Result: 该智能体在与对手的训练中实现了87%的超车成功率，而仅接受赛车训练的智能体超车成功率仅为56%。

Conclusion: 针对对手的训练能够实现有意识的超车行为，显著提高了自主赛车的超车性能。

Abstract: While autonomous racing performance in Time-Trial scenarios has seen
significant progress and development, autonomous wheel-to-wheel racing and
overtaking are still severely limited. These limitations are particularly
apparent in real-life driving scenarios where state-of-the-art algorithms
struggle to safely or reliably complete overtaking manoeuvres. This is
important, as reliable navigation around other vehicles is vital for safe
autonomous wheel-to-wheel racing. The F1Tenth Competition provides a useful
opportunity for developing wheel-to-wheel racing algorithms on a standardised
physical platform. The competition format makes it possible to evaluate
overtaking and wheel-to-wheel racing algorithms against the state-of-the-art.
This research presents a novel racing and overtaking agent capable of learning
to reliably navigate a track and overtake opponents in both simulation and
reality. The agent was deployed on an F1Tenth vehicle and competed against
opponents running varying competitive algorithms in the real world. The results
demonstrate that the agent's training against opponents enables deliberate
overtaking behaviours with an overtaking rate of 87% compared 56% for an agent
trained just to race.

</details>


### [8] [Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion](https://arxiv.org/abs/2510.26067)
*Chi Zhang,Mingrui Li,Wenzhe Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 提出了一种基于图神经网络(GNN)的强化学习框架，用于控制张拉整体机器人的运动，该方法在样本效率、鲁棒性和轨迹精度方面优于传统方法，并能直接从仿真迁移到硬件。


<details>
  <summary>Details</summary>
Motivation: 张拉整体机器人结合刚性杆和弹性缆绳，具有高韧性和可部署性，但由于其欠驱动和高度耦合的动力学特性，在运动控制方面面临重大挑战。

Method: 将图神经网络(GNN)集成到Soft Actor-Critic (SAC)算法中，通过将机器人的物理拓扑表示为图，使GNN策略能够捕捉组件间的耦合关系。

Result: 在3杆张拉整体机器人上的实验表明，该方法在样本效率、噪声和刚度变化的鲁棒性以及轨迹精度方面优于传统的多层感知器(MLP)策略，学习到的策略无需微调即可从仿真直接迁移到硬件。

Conclusion: 结果表明，将结构先验知识融入强化学习对张拉整体机器人控制具有显著优势。

Abstract: Tensegrity robots combine rigid rods and elastic cables, offering high
resilience and deployability but posing major challenges for locomotion control
due to their underactuated and highly coupled dynamics. This paper introduces a
morphology-aware reinforcement learning framework that integrates a graph
neural network (GNN) into the Soft Actor-Critic (SAC) algorithm. By
representing the robot's physical topology as a graph, the proposed GNN-based
policy captures coupling among components, enabling faster and more stable
learning than conventional multilayer perceptron (MLP) policies. The method is
validated on a physical 3-bar tensegrity robot across three locomotion
primitives, including straight-line tracking and bidirectional turning. It
shows superior sample efficiency, robustness to noise and stiffness variations,
and improved trajectory accuracy. Notably, the learned policies transfer
directly from simulation to hardware without fine-tuning, achieving stable
real-world locomotion. These results demonstrate the advantages of
incorporating structural priors into reinforcement learning for tensegrity
robot control.

</details>


### [9] [I don't Want You to Die: A Shared Responsibility Framework for Safeguarding Child-Robot Companionship](https://arxiv.org/abs/2510.26080)
*Fan Yang,Renkai Ma,Yaxin Hu,Michael Rodgers,Lingyao Li*

Main category: cs.RO

TL;DR: 研究探讨社交机器人(如Moxie)服务终止对儿童情感伤害的责任归属问题，通过调查发现责任被视为机器人公司、父母、开发者和政府的共同责任，但观点因政治意识形态和父母身份而异。


<details>
  <summary>Details</summary>
Motivation: 社交机器人与儿童建立强烈情感纽带，但服务突然终止会造成显著困扰和痛苦，引发谁应对儿童情感纽带断裂负责的复杂问题。

Method: 以Moxie关闭为案例研究，对美国72名参与者进行定性调查。

Result: 责任被视为共享责任，但归因因政治意识形态和父母身份而异；对机器人服务是否应继续的观点高度两极分化。

Conclusion: 研究提出了基于实证的共享责任框架，详细说明责任如何分配和争议，为减轻机器人终止服务的情感伤害提供具体设计和政策建议。

Abstract: Social robots like Moxie are designed to form strong emotional bonds with
children, but their abrupt discontinuation can cause significant struggles and
distress to children. When these services end, the resulting harm raises
complex questions of who bears responsibility when children's emotional bonds
are broken. Using the Moxie shutdown as a case study through a qualitative
survey of 72 U.S. participants, our findings show that the responsibility is
viewed as a shared duty across the robot company, parents, developers, and
government. However, these attributions varied by political ideology and
parental status of whether they have children. Participants' perceptions of
whether the robot service should continue are highly polarized; supporters
propose technical, financial, and governmental pathways for continuity, while
opponents cite business realities and risks of unhealthy emotional dependency.
Ultimately, this research contributes an empirically grounded shared
responsibility framework for safeguarding child-robot companionship by
detailing how accountability is distributed and contested, informing concrete
design and policy implications to mitigate the emotional harm of robot
discontinuation.

</details>


### [10] [Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse](https://arxiv.org/abs/2510.26082)
*Fan Yang,Lingyao Li,Yaxin Hu,Michael Rodgers,Renkai Ma*

Main category: cs.RO

TL;DR: 研究发现机器人拟人化程度对保护性反应的影响不是线性的，中等拟人化机器人引发最强的愤怒反应，道德推理随拟人化程度增加从财产评估转向谴责施虐者品格。


<details>
  <summary>Details</summary>
Motivation: 研究不同拟人化水平如何影响人们对机器人受虐的保护性反应，将CASA理论和恐怖谷理论扩展到道德领域。

Method: 邀请201名参与者观看低、中、高拟人化机器人受虐视频，采用自我报告调查、生理数据分析和定性反思三种方法进行综合分析。

Result: 中等拟人化机器人引发最强的生理愤怒表达，自我报告的愤怒和愧疚感在中等和高拟人化机器人中显著更高，道德推理随拟人化程度从技术评估转向品格谴责。

Conclusion: 恐怖谷现象不会削弱道德关注，反而会增强保护性冲动，这对机器人设计、政策和未来法律框架具有重要意义。

Abstract: Robots with anthropomorphic features are increasingly shaping how humans
perceive and morally engage with them. Our research investigates how different
levels of anthropomorphism influence protective responses to robot abuse,
extending the Computers as Social Actors (CASA) and uncanny valley theories
into a moral domain. In an experiment, we invite 201 participants to view
videos depicting abuse toward a robot with low (Spider), moderate (Two-Foot),
or high (Humanoid) anthropomorphism. To provide a comprehensive analysis, we
triangulate three modalities: self-report surveys measuring emotions and
uncanniness, physiological data from automated facial expression analysis, and
qualitative reflections. Findings indicate that protective responses are not
linear. The moderately anthropomorphic Two-Foot robot, rated highest in
eeriness and "spine-tingling" sensations consistent with the uncanny valley,
elicited the strongest physiological anger expressions. Self-reported anger and
guilt are significantly higher for both the Two-Foot and Humanoid robots
compared to the Spider. Qualitative findings further reveal that as
anthropomorphism increases, moral reasoning shifts from technical assessments
of property damage to condemnation of the abuser's character, while governance
proposals expand from property law to calls for quasi-animal rights and broader
societal responsibility. These results suggest that the uncanny valley does not
dampen moral concern but paradoxically heightens protective impulses, offering
critical implications for robot design, policy, and future legal frameworks.

</details>


### [11] [Embodied Intelligence for Advanced Bioinspired Microrobotics: Examples and Insights](https://arxiv.org/abs/2510.26132)
*Nestor O. Perez-Arancibia*

Main category: cs.RO

TL;DR: 本文探讨了具身智能作为微机器人设计原则，强调物理结构与行为功能的协同设计，通过多个微机器人平台展示了智能行为如何从结构动力学和物理交互中涌现。


<details>
  <summary>Details</summary>
Motivation: 传统机器人架构将感知、计算和执行解耦，而具身智能通过将控制策略、传感机制和智能驱动策略嵌入到机器人物理属性中，为微机器人提供更可扩展和鲁棒的替代方案。

Method: 采用协同设计方法，同时开发物理结构和行为功能，通过多个微机器人平台（如Bee++、RoBeetle、SMALLBug等）展示具身智能的实现。

Result: 开发了一系列微机器人平台，这些平台展示了智能行为如何从结构动力学和物理交互中涌现，验证了协同设计作为具身智能推动者的有效性。

Conclusion: 协同设计不仅是约束条件下的经验优化方法，更是实现具身智能的关键推动者，为毫米到厘米尺度的机器人提供了可扩展且鲁棒的替代传统控制的方法。

Abstract: The term embodied intelligence (EI) conveys the notion that body morphology,
material properties, interaction with the environment, and control strategies
can be purposefully integrated into the process of robotic design to generate
intelligent behavior; in particular, locomotion and navigation. In this paper,
we discuss EI as a design principle for advanced microrobotics, with a
particular focus on co-design -- the simultaneous and interdependent
development of physical structure and behavioral function. To illustrate the
contrast between EI-inspired systems and traditional architectures that
decouple sensing, computation, and actuation, we present and discuss a
collection of robots developed by the author and his team at the Autonomous
Microrobotic Systems Laboratory (AMSL). These robots exhibit intelligent
behavior that emerges from their structural dynamics and the physical
interaction between their components and with the environment. Platforms such
as the Bee++, RoBeetle, SMALLBug, SMARTI, WaterStrider, VLEIBot+, and FRISSHBot
exemplify how feedback loops, decision logics, sensing mechanisms, and smart
actuation strategies can be embedded into the physical properties of the
robotic system itself. Along these lines, we contend that co-design is not only
a method for empirical optimization under constraints, but also an enabler of
EI, offering a scalable and robust alternative to classical control for
robotics at the mm-to-cm-scale.

</details>


### [12] [Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling](https://arxiv.org/abs/2510.26139)
*Minseo Kwon,Young J. Kim*

Main category: cs.RO

TL;DR: 提出了一种基于混合状态树的动力学TAMP框架，将符号状态和数值状态统一表示，结合视觉语言模型引导搜索，显著提高了任务和运动规划的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有TAMP方法在长时域问题中因过度运动采样而成本高昂，LLMs虽然提供常识先验但缺乏3D空间推理能力，无法保证几何或动力学可行性。

Method: 使用混合状态树统一表示符号和数值状态，通过现成运动规划器和物理模拟器验证动力学约束，利用VLM基于状态视觉渲染引导TAMP解决方案搜索和回溯。

Result: 在模拟和真实世界实验中，相比传统和基于LLM的TAMP规划器，平均成功率提高32.14%-1166.67%，复杂问题规划时间减少。

Conclusion: 该框架通过VLM引导和混合状态表示，有效解决了TAMP中的运动采样效率和空间推理问题，在复杂任务中表现出优越性能。

Abstract: Task and Motion Planning (TAMP) integrates high-level task planning with
low-level motion feasibility, but existing methods are costly in long-horizon
problems due to excessive motion sampling. While LLMs provide commonsense
priors, they lack 3D spatial reasoning and cannot ensure geometric or dynamic
feasibility. We propose a kinodynamic TAMP framework based on a hybrid state
tree that uniformly represents symbolic and numeric states during planning,
enabling task and motion decisions to be jointly decided. Kinodynamic
constraints embedded in the TAMP problem are verified by an off-the-shelf
motion planner and physics simulator, and a VLM guides exploring a TAMP
solution and backtracks the search based on visual rendering of the states.
Experiments on the simulated domains and in the real world show 32.14% -
1166.67% increased average success rates compared to traditional and LLM-based
TAMP planners and reduced planning time on complex problems, with ablations
further highlighting the benefits of VLM guidance.

</details>


### [13] [Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages](https://arxiv.org/abs/2510.26142)
*Hahjin Lee,Young J. Kim*

Main category: cs.RO

TL;DR: 提出自适应轨迹优化算法，通过路径段级安全测试和姿态级安全修正，解决移动机器人在狭窄通道中的轨迹规划问题


<details>
  <summary>Details</summary>
Motivation: 传统方法在狭窄通道环境中经常失败或生成次优路径，需要解决移动机器人在拥挤环境中的轨迹规划挑战

Method: 两阶段方法：1) 路径段级保守碰撞测试，递归细分风险路径段；2) 基于穿透方向和线搜索的姿态修正，确保每个姿态无碰撞且远离障碍物

Result: 仿真结果显示比现有方法成功率提高1.69倍，规划时间加快3.79倍；真实实验证实机器人能安全通过狭窄通道并保持快速规划性能

Conclusion: 该方法在狭窄通道环境中实现了更高的成功率和更快的规划速度，为移动机器人在拥挤环境中的安全导航提供了有效解决方案

Abstract: Trajectory planning for mobile robots in cluttered environments remains a
major challenge due to narrow passages, where conventional methods often fail
or generate suboptimal paths. To address this issue, we propose the adaptive
trajectory refinement algorithm, which consists of two main stages. First, to
ensure safety at the path-segment level, a segment-wise conservative collision
test is applied, where risk-prone trajectory path segments are recursively
subdivided until collision risks are eliminated. Second, to guarantee
pose-level safety, pose correction based on penetration direction and line
search is applied, ensuring that each pose in the trajectory is collision-free
and maximally clear from obstacles. Simulation results demonstrate that the
proposed method achieves up to 1.69x higher success rates and up to 3.79x
faster planning times than state-of-the-art approaches. Furthermore, real-world
experiments confirm that the robot can safely pass through narrow passages
while maintaining rapid planning performance.

</details>


### [14] [Self-localization on a 3D map by fusing global and local features from a monocular camera](https://arxiv.org/abs/2510.26170)
*Satoshi Kikuch,Masaya Kato,Tsuyoshi Tasaki*

Main category: cs.RO

TL;DR: 提出了一种结合CNN和Vision Transformer的新方法，用于在存在动态障碍物的3D地图上进行单目相机自定位，相比现有方法显著提高了定位精度。


<details>
  <summary>Details</summary>
Motivation: 使用廉价单目相机在3D地图上实现自定位是自动驾驶的关键需求。传统基于CNN的方法在提取局部特征时，遇到动态障碍物（如行人）时效果不佳。

Method: 将CNN与Vision Transformer相结合，CNN擅长提取局部特征，而Vision Transformer擅长提取全局特征，能够捕捉图像中各个patch之间的整体关系。

Result: 在包含动态障碍物的CG数据集上，精度提升率比无动态障碍物时高1.5倍；在公开数据集上，自定位误差比SOTA方法减少20.1%；机器人平均定位误差为7.51cm，优于SOTA。

Conclusion: 提出的CNN与Vision Transformer结合方法能有效处理动态障碍物场景，显著提升自定位精度，为自动驾驶提供了更可靠的定位解决方案。

Abstract: Self-localization on a 3D map by using an inexpensive monocular camera is
required to realize autonomous driving. Self-localization based on a camera
often uses a convolutional neural network (CNN) that can extract local features
that are calculated by nearby pixels. However, when dynamic obstacles, such as
people, are present, CNN does not work well. This study proposes a new method
combining CNN with Vision Transformer, which excels at extracting global
features that show the relationship of patches on whole image. Experimental
results showed that, compared to the state-of-the-art method (SOTA), the
accuracy improvement rate in a CG dataset with dynamic obstacles is 1.5 times
higher than that without dynamic obstacles. Moreover, the self-localization
error of our method is 20.1% smaller than that of SOTA on public datasets.
Additionally, our robot using our method can localize itself with 7.51cm error
on average, which is more accurate than SOTA.

</details>


### [15] [PHUMA: Physically-Grounded Humanoid Locomotion Dataset](https://arxiv.org/abs/2510.26236)
*Kyungmin Lee,Sibeen Kim,Minho Park,Hyunseung Kim,Dongyoon Hwang,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: PHUMA是一个基于物理约束的人形机器人运动数据集，通过大规模人类视频数据生成，解决了现有方法中的物理伪影问题，在运动模仿和路径跟随任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有运动模仿方法依赖昂贵且稀缺的动作捕捉数据集（如AMASS），而基于互联网视频的方法（如Humanoid-X）存在物理伪影问题，限制了可扩展性和多样性。

Method: 通过数据精心筛选和物理约束重定向，强制执行关节限制、确保地面接触、消除脚部滑动，生成大规模且物理可靠的运动数据。

Result: 在未见运动模仿和骨盆引导路径跟随两种条件下，PHUMA训练的策略均优于Humanoid-X和AMASS，在多样化运动模仿方面取得显著提升。

Conclusion: PHUMA通过物理约束的数据处理方法，成功解决了大规模视频数据中的物理伪影问题，为人形机器人运动模仿提供了高质量的数据集。

Abstract: Motion imitation is a promising approach for humanoid locomotion, enabling
agents to acquire humanlike behaviors. Existing methods typically rely on
high-quality motion capture datasets such as AMASS, but these are scarce and
expensive, limiting scalability and diversity. Recent studies attempt to scale
data collection by converting large-scale internet videos, exemplified by
Humanoid-X. However, they often introduce physical artifacts such as floating,
penetration, and foot skating, which hinder stable imitation. In response, we
introduce PHUMA, a Physically-grounded HUMAnoid locomotion dataset that
leverages human video at scale, while addressing physical artifacts through
careful data curation and physics-constrained retargeting. PHUMA enforces joint
limits, ensures ground contact, and eliminates foot skating, producing motions
that are both large-scale and physically reliable. We evaluated PHUMA in two
sets of conditions: (i) imitation of unseen motion from self-recorded test
videos and (ii) path following with pelvis-only guidance. In both cases,
PHUMA-trained policies outperform Humanoid-X and AMASS, achieving significant
gains in imitating diverse motions. The code is available at
https://davian-robotics.github.io/PHUMA.

</details>


### [16] [Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments](https://arxiv.org/abs/2510.26280)
*Gangyang Li,Qing Shi,Youhao Hu,Jincheng Hu,Zhongyuan Wang,Xinlong Wang,Shaqi Luo*

Main category: cs.RO

TL;DR: 提出Thor人形机器人框架，通过力自适应躯干倾斜奖励函数和解耦强化学习架构，显著提升人形机器人在接触丰富环境中的力交互能力。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在服务、工业和救援应用中需要保持全身稳定性，同时与环境进行强烈的接触交互，但实现类似人类的适应性响应仍具挑战。

Method: 基于机器人受力分析设计FAT2奖励函数，引入解耦的强化学习架构将上体、腰部和下体分开控制，共享全局观测并联合更新参数。

Result: 在Unitree G1上部署Thor，向后移动时峰值拉力达167.7N（约G1体重的48%），向前移动时145.5N，相比最佳基线分别提升68.9%和74.7%。能够拉动130N负载架和单手打开60N防火门。

Conclusion: Thor框架有效增强了人形机器人的力交互能力，在接触丰富环境中展现出类似人类的适应性响应。

Abstract: Humanoids hold great potential for service, industrial, and rescue
applications, in which robots must sustain whole-body stability while
performing intense, contact-rich interactions with the environment. However,
enabling humanoids to generate human-like, adaptive responses under such
conditions remains a major challenge. To address this, we propose Thor, a
humanoid framework for human-level whole-body reactions in contact-rich
environments. Based on the robot's force analysis, we design a force-adaptive
torso-tilt (FAT2) reward function to encourage humanoids to exhibit human-like
responses during force-interaction tasks. To mitigate the high-dimensional
challenges of humanoid control, Thor introduces a reinforcement learning
architecture that decouples the upper body, waist, and lower body. Each
component shares global observations of the whole body and jointly updates its
parameters. Finally, we deploy Thor on the Unitree G1, and it substantially
outperforms baselines in force-interaction tasks. Specifically, the robot
achieves a peak pulling force of 167.7 N (approximately 48% of the G1's body
weight) when moving backward and 145.5 N when moving forward, representing
improvements of 68.9% and 74.7%, respectively, compared with the
best-performing baseline. Moreover, Thor is capable of pulling a loaded rack
(130 N) and opening a fire door with one hand (60 N). These results highlight
Thor's effectiveness in enhancing humanoid force-interaction capabilities.

</details>


### [17] [AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM](https://arxiv.org/abs/2510.26358)
*Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci*

Main category: cs.RO

TL;DR: AgriGS-SLAM是一个视觉-LiDAR SLAM框架，结合直接LiDAR里程计和闭环检测与多相机3D高斯泼溅渲染，用于果园环境下的实时3D场景理解。


<details>
  <summary>Details</summary>
Motivation: 果园环境中的自主机器人需要实时3D场景理解，但面临重复行几何、季节性外观变化和风驱动叶片运动等挑战。

Method: 通过批量栅格化互补视角恢复被遮挡的果园结构，使用统一的梯度驱动地图生命周期在关键帧之间保留细节并限制内存，通过概率LiDAR深度一致性项指导位姿优化。

Result: 在苹果和梨园中测试，AgriGS-SLAM相比现有3DGS-SLAM基线提供更清晰稳定的重建和更平稳的轨迹，同时保持实时性能。

Conclusion: 该方法不仅适用于果园监测，还可应用于其他需要鲁棒多模态感知的室外领域。

Abstract: Autonomous robots in orchards require real-time 3D scene understanding
despite repetitive row geometry, seasonal appearance changes, and wind-driven
foliage motion. We present AgriGS-SLAM, a Visual--LiDAR SLAM framework that
couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian
Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints
recovers orchard structure under occlusions, while a unified gradient-driven
map lifecycle executed between keyframes preserves fine details and bounds
memory. Pose refinement is guided by a probabilistic LiDAR-based depth
consistency term, back-propagated through the camera projection to tighten
geometry-appearance coupling. We deploy the system on a field platform in apple
and pear orchards across dormancy, flowering, and harvesting, using a
standardized trajectory protocol that evaluates both training-view and
novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons
and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and
steadier trajectories than recent state-of-the-art 3DGS-SLAM baselines while
maintaining real-time performance on-tractor. While demonstrated in orchard
monitoring, the approach can be applied to other outdoor domains requiring
robust multimodal perception.

</details>


### [18] [Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations](https://arxiv.org/abs/2510.26362)
*Tobias Löw,Cem Bilaloglu,Sylvain Calinon*

Main category: cs.RO

TL;DR: 本文提出了基于共形几何代数的多臂机器人系统协作任务空间理论框架，通过几何基元的相似变换将复杂系统抽象为单臂系统，并推导了相关的雅可比矩阵，便于集成到经典控制方法中。


<details>
  <summary>Details</summary>
Motivation: 人类环境中的许多任务需要多个运动链的协作行为，但协调这些高自由度系统的运动建模非常困难。

Method: 使用共形几何代数定义协作几何基元，通过相似变换抽象复杂机器人系统，推导解析和几何雅可比矩阵，并将其集成到操作空间控制中。

Result: 在双手机器人、仿人机器人和多指手的实验中验证了方法，包括达到期望几何基元的最优控制实验和使用微分运动学控制的遥操作实验。

Conclusion: 该工作建立了协作操作控制框架的理论基础，几何基元自然地将零空间结构嵌入控制器，可用于引入次要控制目标。

Abstract: Many tasks in human environments require collaborative behavior between
multiple kinematic chains, either to provide additional support for carrying
big and bulky objects or to enable the dexterity that is required for in-hand
manipulation. Since these complex systems often have a very high number of
degrees of freedom coordinating their movements is notoriously difficult to
model. In this article, we present the derivation of the theoretical
foundations for cooperative task spaces of multi-arm robotic systems based on
geometric primitives defined using conformal geometric algebra. Based on the
similarity transformations of these cooperative geometric primitives, we derive
an abstraction of complex robotic systems that enables representing these
systems in a way that directly corresponds to single-arm systems. By deriving
the associated analytic and geometric Jacobian matrices, we then show the
straightforward integration of our approach into classical control techniques
rooted in operational space control. We demonstrate this using bimanual
manipulators, humanoids and multi-fingered hands in optimal control experiments
for reaching desired geometric primitives and in teleoperation experiments
using differential kinematics control. We then discuss how the geometric
primitives naturally embed nullspace structures into the controllers that can
be exploited for introducing secondary control objectives. This work,
represents the theoretical foundations of this cooperative manipulation control
framework, and thus the experiments are presented in an abstract way, while
giving pointers towards potential future applications.

</details>


### [19] [Towards Reinforcement Learning Based Log Loading Automation](https://arxiv.org/abs/2510.26363)
*Ilya Kurinov,Miroslav Ivanov,Grzegorz Orzechowski,Aki Mikkola*

Main category: cs.RO

TL;DR: 该研究应用强化学习实现林业集材机全自动装载作业，从抓取扩展到完整装载流程，在模拟环境中训练智能体达到94%的成功率。


<details>
  <summary>Details</summary>
Motivation: 林业集材机操作对操作员身心消耗大，部分自动化可减轻操作员负担，延续先前在抓取自动化方面的研究。

Method: 使用NVIDIA Isaac Gym开发林业集材机仿真模型，采用强化学习智能体和课程学习方法训练自动化装载流程。

Result: 训练出的最佳智能体能够从随机位置抓取原木并运输到车厢，成功率达到94%。

Conclusion: 该研究是强化学习在林业集材机自动化应用中的重要进展，为实现全自动化操作奠定了基础。

Abstract: Forestry forwarders play a central role in mechanized timber harvesting by
picking up and moving logs from the felling site to a processing area or a
secondary transport vehicle. Forwarder operation is challenging and physically
and mentally exhausting for the operator who must control the machine in remote
areas for prolonged periods of time. Therefore, even partial automation of the
process may reduce stress on the operator. This study focuses on continuing
previous research efforts in application of reinforcement learning agents in
automating log handling process, extending the task from grasping which was
studied in previous research to full log loading operation. The resulting agent
will be capable to automate a full loading procedure from locating and
grappling to transporting and delivering the log to a forestry forwarder bed.
To train the agent, a trailer type forestry forwarder simulation model in
NVIDIA's Isaac Gym and a virtual environment for a typical log loading scenario
were developed. With reinforcement learning agents and a curriculum learning
approach, the trained agent may be a stepping stone towards application of
reinforcement learning agents in automation of the forestry forwarder. The
agent learnt grasping a log in a random position from grapple's random position
and transport it to the bed with 94% success rate of the best performing agent.

</details>


### [20] [Human-in-the-loop Online Rejection Sampling for Robotic Manipulation](https://arxiv.org/abs/2510.26406)
*Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang*

Main category: cs.RO

TL;DR: Hi-ORS是一种简单有效的后训练方法，通过拒绝采样实现训练稳定性和高鲁棒性，在真实世界任务中仅需1.5小时训练即可掌握接触丰富的操作任务。


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人操作策略中广泛使用，但微调视觉-语言-动作模型时可能不稳定；模仿学习易于训练但性能不足。需要一种兼具训练稳定性和高鲁棒性的方法。

Method: Hi-ORS使用拒绝采样过滤负奖励样本以稳定价值估计，采用奖励加权的监督训练目标提供密集的中间步骤监督，并开发异步推理-训练框架支持在线人工校正。

Result: 在三个真实世界任务和两种体现中，Hi-ORS仅需1.5小时真实世界训练即可掌握接触丰富的操作，在效果和效率上显著优于RL和IL基线方法。

Conclusion: Hi-ORS方法能够实现训练稳定性和高鲁棒性，微调后的策略展现出强大的测试时扩展能力，能够可靠执行复杂的错误恢复行为以获得更好性能。

Abstract: Reinforcement learning (RL) is widely used to produce robust robotic
manipulation policies, but fine-tuning vision-language-action (VLA) models with
RL can be unstable due to inaccurate value estimates and sparse supervision at
intermediate steps. In contrast, imitation learning (IL) is easy to train but
often underperforms due to its offline nature. In this paper, we propose
Hi-ORS, a simple yet effective post-training method that utilizes rejection
sampling to achieve both training stability and high robustness. Hi-ORS
stabilizes value estimation by filtering out negatively rewarded samples during
online fine-tuning, and adopts a reward-weighted supervised training objective
to provide dense intermediate-step supervision. For systematic study, we
develop an asynchronous inference-training framework that supports flexible
online human-in-the-loop corrections, which serve as explicit guidance for
learning error-recovery behaviors. Across three real-world tasks and two
embodiments, Hi-ORS fine-tunes a pi-base policy to master contact-rich
manipulation in just 1.5 hours of real-world training, outperforming RL and IL
baselines by a substantial margin in both effectiveness and efficiency.
Notably, the fine-tuned policy exhibits strong test-time scalability by
reliably executing complex error-recovery behaviors to achieve better
performance.

</details>


### [21] [RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration](https://arxiv.org/abs/2510.26536)
*Huajie Tan,Cheng Chi,Xiansheng Chen,Yuheng Ji,Zhongxia Zhao,Xiaoshuai Hao,Yaoxu Lyu,Mingyu Cao,Junkai Zhao,Huaihai Lyu,Enshen Zhou,Ning Chen,Yankai Fu,Cheng Peng,Wei Guo,Dong Liang,Zhuo Chen,Mengsi Lyu,Chenrui He,Yulong Ao,Yonghua Lin,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 提出了RoboOS-NeXT框架，通过统一的时空-具身记忆(STEM)实现多机器人系统的终身适应、可扩展协调和鲁棒调度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖有限的单智能体记忆，无法实现长期学习、异构团队扩展或故障恢复，需要统一的内存表示来解决多机器人协作的挑战。

Method: 核心是Spatio-Temporal-Embodiment Memory (STEM)，将空间场景几何、时间事件历史和具身配置文件集成到共享表示中，采用大脑-小脑框架，高层大脑模型通过检索和更新STEM进行全局规划，低层控制器本地执行动作。

Result: 在餐厅、超市和家庭等复杂协调任务中的实验表明，RoboOS-NeXT在异构具身配置下实现了优越性能。

Conclusion: RoboOS-NeXT通过统一的内存中心设计，实现了终身、可扩展和鲁棒的多机器人协作。

Abstract: The proliferation of collaborative robots across diverse tasks and
embodiments presents a central challenge: achieving lifelong adaptability,
scalable coordination, and robust scheduling in multi-agent systems. Existing
approaches, from vision-language-action (VLA) models to hierarchical
frameworks, fall short due to their reliance on limited or dividual-agent
memory. This fundamentally constrains their ability to learn over long
horizons, scale to heterogeneous teams, or recover from failures, highlighting
the need for a unified memory representation. To address these limitations, we
introduce RoboOS-NeXT, a unified memory-based framework for lifelong, scalable,
and robust multi-robot collaboration. At the core of RoboOS-NeXT is the novel
Spatio-Temporal-Embodiment Memory (STEM), which integrates spatial scene
geometry, temporal event history, and embodiment profiles into a shared
representation. This memory-centric design is integrated into a
brain-cerebellum framework, where a high-level brain model performs global
planning by retrieving and updating STEM, while low-level controllers execute
actions locally. This closed loop between cognition, memory, and execution
enables dynamic task allocation, fault-tolerant collaboration, and consistent
state synchronization. We conduct extensive experiments spanning complex
coordination tasks in restaurants, supermarkets, and households. Our results
demonstrate that RoboOS-NeXT achieves superior performance across heterogeneous
embodiments, validating its effectiveness in enabling lifelong, scalable, and
robust multi-robot collaboration. Project website:
https://flagopen.github.io/RoboOS/

</details>


### [22] [Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics](https://arxiv.org/abs/2510.26551)
*Prathamesh Kothavale,Sravani Boddepalli*

Main category: cs.RO

TL;DR: 提出了一种扩展机器人逆运动学求解器的新框架，使机器人能够学习使用不同长度工具的动作序列，并在仿真和现实场景中实现技能迁移。


<details>
  <summary>Details</summary>
Motivation: 传统机器人对自身运动学理解有限，局限于预设任务，无法有效利用工具。需要解决工具使用的四个关键要素：理解预期结果、选择合适工具、确定最佳工具方向、执行精确操作。

Method: 扩展机器人逆运动学求解器，集成仿真学习的动作轨迹与工具，使机器人能够获取使用不同长度工具的连续动作序列。

Result: 扩展逆运动学求解器误差小于1cm；训练策略在仿真中平均误差8cm；使用两种不同长度工具时性能几乎无差异。

Conclusion: 该研究展示了在工具使用四个基本方面的潜在进展，使机器人能够掌握跨不同任务的复杂工具操作技能。

Abstract: Conventional robots possess a limited understanding of their kinematics and
are confined to preprogrammed tasks, hindering their ability to leverage tools
efficiently. Driven by the essential components of tool usage - grasping the
desired outcome, selecting the most suitable tool, determining optimal tool
orientation, and executing precise manipulations - we introduce a pioneering
framework. Our novel approach expands the capabilities of the robot's inverse
kinematics solver, empowering it to acquire a sequential repertoire of actions
using tools of varying lengths. By integrating a simulation-learned action
trajectory with the tool, we showcase the practicality of transferring acquired
skills from simulation to real-world scenarios through comprehensive
experimentation. Remarkably, our extended inverse kinematics solver
demonstrates an impressive error rate of less than 1 cm. Furthermore, our
trained policy achieves a mean error of 8 cm in simulation. Noteworthy, our
model achieves virtually indistinguishable performance when employing two
distinct tools of different lengths. This research provides an indication of
potential advances in the exploration of all four fundamental aspects of tool
usage, enabling robots to master the intricate art of tool manipulation across
diverse tasks.

</details>


### [23] [FLYINGTRUST: A Benchmark for Quadrotor Navigation Across Scenarios and Vehicles](https://arxiv.org/abs/2510.26588)
*Gang Li,Chunlei Zhai,Teng Wang,Shaun Li,Shangsong Jiang,Xiangwei Zhu*

Main category: cs.RO

TL;DR: FLYINGTRUST是一个高保真、可配置的四旋翼视觉导航基准测试框架，用于系统评估平台动力学和场景结构对导航鲁棒性的联合影响。


<details>
  <summary>Details</summary>
Motivation: 四旋翼视觉导航算法在不同车辆平台和场景几何下性能差异大，增加了现场部署的成本和风险，需要系统化的早期评估方法。

Method: 使用最大推力重量比和轴间最大角加速度作为车辆能力指标，结合多样化场景库和异构平台集，采用标准化评估协议和综合评分方法。

Result: 导航成功率可预测地依赖于平台能力和场景几何，不同算法在评估条件下表现出不同的偏好和失效模式。

Conclusion: 需要将平台能力和场景结构纳入算法设计、评估和选择，并开发在多样化平台和场景下保持鲁棒性的方法。

Abstract: Visual navigation algorithms for quadrotors often exhibit a large variation
in performance when transferred across different vehicle platforms and scene
geometries, which increases the cost and risk of field deployment. To support
systematic early-stage evaluation, we introduce FLYINGTRUST, a high-fidelity,
configurable benchmarking framework that measures how platform kinodynamics and
scenario structure jointly affect navigation robustness. FLYINGTRUST models
vehicle capability with two compact, physically interpretable indicators:
maximum thrust-to-weight ratio and axis-wise maximum angular acceleration. The
benchmark pairs a diverse scenario library with a heterogeneous set of real and
virtual platforms and prescribes a standardized evaluation protocol together
with a composite scoring method that balances scenario importance, platform
importance and performance stability. We use FLYINGTRUST to compare
representative optimization-based and learning-based navigation approaches
under identical conditions, performing repeated trials per platform-scenario
combination and reporting uncertainty-aware metrics. The results reveal
systematic patterns: navigation success depends predictably on platform
capability and scene geometry, and different algorithms exhibit distinct
preferences and failure modes across the evaluated conditions. These
observations highlight the practical necessity of incorporating both platform
capability and scenario structure into algorithm design, evaluation, and
selection, and they motivate future work on methods that remain robust across
diverse platforms and scenarios.

</details>


### [24] [A Sliding-Window Filter for Online Continuous-Time Continuum Robot State Estimation](https://arxiv.org/abs/2510.26623)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 提出了一种用于连续体机器人连续时间状态估计的滑动窗口滤波器，在提高滤波方法精度的同时实现连续时间方法的在线运行，且运行速度快于实时速度。


<details>
  <summary>Details</summary>
Motivation: 现有连续体机器人状态估计方法难以平衡精度和计算效率，滑动窗口方法局限于简化离散时间近似且缺乏随机表示，而随机滤波方法受限于测量速度运行。

Method: 开发了专门针对连续体机器人的随机滑动窗口滤波器，支持连续时间状态估计，能够在线运行且速度快于实时。

Result: 该方法在提高滤波方法精度的同时，使连续时间方法能够在线运行，且运行速度快于实时速度。

Conclusion: 这是首个专门为连续体机器人设计的随机滑动窗口滤波器，为该领域未来研究提供了有前景的方向。

Abstract: Stochastic state estimation methods for continuum robots (CRs) often struggle
to balance accuracy and computational efficiency. While several recent works
have explored sliding-window formulations for CRs, these methods are limited to
simplified, discrete-time approximations and do not provide stochastic
representations. In contrast, current stochastic filter methods must run at the
speed of measurements, limiting their full potential. Recent works in
continuous-time estimation techniques for CRs show a principled approach to
addressing this runtime constraint, but are currently restricted to offline
operation. In this work, we present a sliding-window filter (SWF) for
continuous-time state estimation of CRs that improves upon the accuracy of a
filter approach while enabling continuous-time methods to operate online, all
while running at faster-than-real-time speeds. This represents the first
stochastic SWF specifically designed for CRs, providing a promising direction
for future research in this area.

</details>


### [25] [REALMS2 -- Resilient Exploration And Lunar Mapping System 2 -- A Comprehensive Approach](https://arxiv.org/abs/2510.26638)
*Dave van der Meer,Loïck P. Chovet,Gabriel M. Garcia,Abhishek Bera,Miguel A. Olivares-Mendez*

Main category: cs.RO

TL;DR: REALMS2是一个基于ROS 2的多机器人系统框架，用于行星勘探和地图构建，在ESA-ESRIC挑战赛中成功测绘了约60%的区域。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统在太空勘探中的挑战，特别是应对异质多机器人探测任务和地外环境的通信延迟与中断问题。

Method: 使用ROS 2框架，集成视觉SLAM进行地图生成，采用网状网络构建鲁棒的自组织网络，通过单一图形界面控制所有漫游车。

Result: 在ESA-ESRIC挑战赛第二次实地测试中，使用三个同质漫游车成功测绘了约60%的区域，并有效处理了通信延迟和中断。

Conclusion: REALMS2系统证明了其在行星勘探任务中的有效性，能够应对地外环境的通信挑战并完成大面积测绘任务。

Abstract: The European Space Agency (ESA) and the European Space Resources Innovation
Centre (ESRIC) created the Space Resources Challenge to invite researchers and
companies to propose innovative solutions for Multi-Robot Systems (MRS) space
prospection. This paper proposes the Resilient Exploration And Lunar Mapping
System 2 (REALMS2), a MRS framework for planetary prospection and mapping.
Based on Robot Operating System version 2 (ROS 2) and enhanced with Visual
Simultaneous Localisation And Mapping (vSLAM) for map generation, REALMS2 uses
a mesh network for a robust ad hoc network. A single graphical user interface
(GUI) controls all the rovers, providing a simple overview of the robotic
mission. This system is designed for heterogeneous multi-robot exploratory
missions, tackling the challenges presented by extraterrestrial environments.
REALMS2 was used during the second field test of the ESA-ESRIC Challenge and
allowed to map around 60% of the area, using three homogeneous rovers while
handling communication delays and blackouts.

</details>


### [26] [Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments](https://arxiv.org/abs/2510.26646)
*Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai*

Main category: cs.RO

TL;DR: 提出分层路径规划与控制框架，结合高层DQN选择子目标与底层TD3控制器执行连续动作，在动态和部分可观测环境中实现更好的导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决单一算法在复杂环境中导航的局限性，结合离散决策和连续控制的优势，提高导航系统的成功率和样本效率。

Method: 使用高层Deep Q-Network进行离散子目标选择，底层Twin Delayed Deep Deterministic Policy Gradient控制器执行连续速度命令，配合LiDAR安全门和奖励函数设计。

Result: 在动态和部分可观测环境中，相比单一算法基准和基于规则的规划器，实现了更高的成功率、更好的样本效率，以及对未见障碍物配置的更好泛化能力。

Conclusion: 分层框架有效结合了离散决策和连续控制的优势，在复杂导航任务中表现出优越性能，为机器人导航提供了实用的解决方案。

Abstract: This paper presents a hierarchical path-planning and control framework that
combines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with
a low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller
for continuous actuation. The high-level module selects behaviors and
sub-goals; the low-level module executes smooth velocity commands. We design a
practical reward shaping scheme (direction, distance, obstacle avoidance,
action smoothness, collision penalty, time penalty, and progress), together
with a LiDAR-based safety gate that prevents unsafe motions. The system is
implemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,
including success rate, collision rate, path efficiency, and re-planning
efficiency, in dynamic and partially observable environments. Experiments show
improved success rate and sample efficiency over single-algorithm baselines
(DQN or TD3 alone) and rule-based planners, with better generalization to
unseen obstacle configurations and reduced abrupt control changes. Code and
evaluation scripts are available at the project repository.

</details>


### [27] [Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems](https://arxiv.org/abs/2510.26656)
*Georgios Kamaras,Craig Innes,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 本文提出三种启发式LFI变体（EDGE、MODE、CENTRE）来解决支持集误设问题，通过在推理过程中自适应调整支持集，提高参数推断和政策学习的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统LFI方法假设固定的支持集，但支持集误设会导致次优且错误自信的后验分布，影响机器人领域分布适应和策略学习效果。

Method: 提出三种启发式LFI变体，通过解释后验模式在推理步骤中的移动来动态调整支持集，结合后验推理进行支持集自适应。

Result: 在随机动态基准测试中验证了支持集误设问题，并在可变形线性物体操作任务中实现了更精细的长度和刚度分类，提升了基于仿真的策略学习鲁棒性。

Conclusion: 启发式支持集自适应能够改善参数推断精度，产生更鲁棒的领域分布，从而提升面向对象的智能体性能。

Abstract: In robotics, likelihood-free inference (LFI) can provide the domain
distribution that adapts a learnt agent in a parametric set of deployment
conditions. LFI assumes an arbitrary support for sampling, which remains
constant as the initial generic prior is iteratively refined to more
descriptive posteriors. However, a potentially misspecified support can lead to
suboptimal, yet falsely certain, posteriors. To address this issue, we propose
three heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the
posterior mode shift over inference steps in its own way and, when integrated
into an LFI step, adapts the support alongside posterior inference. We first
expose the support misspecification issue and evaluate our heuristics using
stochastic dynamical benchmarks. We then evaluate the impact of heuristic
support adaptation on parameter inference and policy learning for a dynamic
deformable linear object (DLO) manipulation task. Inference results in a finer
length and stiffness classification for a parametric set of DLOs. When the
resulting posteriors are used as domain distributions for sim-based policy
learning, they lead to more robust object-centric agent performance.

</details>


### [28] [Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation](https://arxiv.org/abs/2510.26670)
*Qianyou Zhao,Yuliang Shen,Xuanran Zhai,Ce Hao,Duidi Wu,Jin Qi,Jie Hu,Qiaojun Yu*

Main category: cs.RO

TL;DR: 提出混合一致性策略(HCP)，通过结合随机前缀和一致性跳跃，在保持多模态行为的同时显著加速扩散策略的推理速度


<details>
  <summary>Details</summary>
Motivation: 解决基于扩散的模仿学习中，传统去噪过程难以同时实现快速采样和强多模态的问题

Method: HCP运行短随机前缀到自适应切换时间，然后应用一步一致性跳跃生成最终动作，采用时变一致性蒸馏结合轨迹一致性目标和去噪匹配目标

Result: 在仿真和真实机器人上，HCP仅需25步SDE加一次跳跃即可接近80步DDPM教师的准确性和模态覆盖度，同时显著降低延迟

Conclusion: 多模态不需要慢推理，切换时间将模态保持与速度解耦，为机器人策略提供了实用的准确性与效率权衡

Abstract: In visuomotor policy learning, diffusion-based imitation learning has become
widely adopted for its ability to capture diverse behaviors. However,
approaches built on ordinary and stochastic denoising processes struggle to
jointly achieve fast sampling and strong multi-modality. To address these
challenges, we propose the Hybrid Consistency Policy (HCP). HCP runs a short
stochastic prefix up to an adaptive switch time, and then applies a one-step
consistency jump to produce the final action. To align this one-jump
generation, HCP performs time-varying consistency distillation that combines a
trajectory-consistency objective to keep neighboring predictions coherent and a
denoising-matching objective to improve local fidelity. In both simulation and
on a real robot, HCP with 25 SDE steps plus one jump approaches the 80-step
DDPM teacher in accuracy and mode coverage while significantly reducing
latency. These results show that multi-modality does not require slow
inference, and a switch time decouples mode retention from speed. It yields a
practical accuracy efficiency trade-off for robot policies.

</details>


### [29] [Running VLAs at Real-time Speed](https://arxiv.org/abs/2510.26742)
*Yunchao Ma,Yizhuang Zhou,Yunhuan Yang,Tiancai Wang,Haoqiang Fan*

Main category: cs.RO

TL;DR: 提出了在单张消费级GPU上实现30Hz帧率和480Hz轨迹频率的多视角VLA实时控制方法，使大型VLA模型能够处理动态实时任务。


<details>
  <summary>Details</summary>
Motivation: 解决大型VLA模型在实时机器人控制中的性能瓶颈，实现之前被认为无法达到的动态实时任务。

Method: 引入一系列策略消除模型推理开销，包括优化推理流程，并提出了完整的流式推理框架。

Result: 在抓取下落笔的任务中实现了100%的成功率，证明了方法的有效性。

Conclusion: 成功实现了VLA模型的实时控制能力，为动态实时机器人任务提供了可行的解决方案。

Abstract: In this paper, we show how to run pi0-level multi-view VLA at 30Hz frame rate
and at most 480Hz trajectory frequency using a single consumer GPU. This
enables dynamic and real-time tasks that were previously believed to be
unattainable by large VLA models. To achieve it, we introduce a bag of
strategies to eliminate the overheads in model inference. The real-world
experiment shows that the pi0 policy with our strategy achieves a 100% success
rate in grasping a falling pen task. Based on the results, we further propose a
full streaming inference framework for real-time robot control of VLA. Code is
available at https://github.com/Dexmal/realtime-vla.

</details>
