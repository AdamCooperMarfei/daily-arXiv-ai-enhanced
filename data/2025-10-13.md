<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 31]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ConPoSe: LLM-Guided Contact Point Selection for Scalable Cooperative Object Pushing](https://arxiv.org/abs/2510.08705)
*Noah Steinkrüger,Nisarga Nilavadi,Wolfram Burgard,Tanja Katharina Kaiser*

Main category: cs.RO

TL;DR: 提出ConPoSe方法，结合大语言模型的推理能力和局部搜索来选择多机器人协作推物体时的接触点，解决了传统分析方法组合爆炸的问题。


<details>
  <summary>Details</summary>
Motivation: 在杂乱环境中进行协作物体运输时，多机器人需要协调推动过大的物体。虽然接触点选择可以解析求解，但随着机器人数量和物体尺寸增加，解空间呈组合爆炸增长，限制了可扩展性。

Method: ConPoSe方法结合大语言模型的常识推理能力和局部搜索算法来选择机器人-物体接触点，适用于长方体、圆柱体和T形等多种形状物体。

Result: ConPoSe在机器人数量和物体尺寸增加时比解析方法具有更好的可扩展性，并且优于纯基于LLM的选择方法。

Conclusion: LLM引导的局部搜索方法ConPoSe能够有效解决多机器人协作运输中的接触点选择问题，提供了一种可扩展的解决方案。

Abstract: Object transportation in cluttered environments is a fundamental task in
various domains, including domestic service and warehouse logistics. In
cooperative object transport, multiple robots must coordinate to move objects
that are too large for a single robot. One transport strategy is pushing, which
only requires simple robots. However, careful selection of robot-object contact
points is necessary to push the object along a preplanned path. Although this
selection can be solved analytically, the solution space grows combinatorially
with the number of robots and object size, limiting scalability. Inspired by
how humans rely on common-sense reasoning for cooperative transport, we propose
combining the reasoning capabilities of Large Language Models with local search
to select suitable contact points. Our LLM-guided local search method for
contact point selection, ConPoSe, successfully selects contact points for a
variety of shapes, including cuboids, cylinders, and T-shapes. We demonstrate
that ConPoSe scales better with the number of robots and object size than the
analytical approach, and also outperforms pure LLM-based selection.

</details>


### [2] [Point and Go: Intuitive Reference Frame Reallocation in Mode Switching for Assistive Robotics](https://arxiv.org/abs/2510.08753)
*A. Wang,C. Jiang,M. Przystupa,J. Valentine,M. Jagersand*

Main category: cs.RO

TL;DR: 提出Point and Go模式切换方法，通过重新分配笛卡尔模式切换参考系到更直观的动作空间，包含新的平移和旋转模式，显著提升轮椅机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 传统笛卡尔空间模式切换存在控制参考系不直观、平移和旋转控制分离、运动能力有限等问题，影响轮椅机器人操作性能。

Method: 使用新颖的扫掠运动指向夹爪，在机器人基座坐标系水平面定义新的平移轴，创建直观的'指向并移动'平移模式；旋转模式结合位置控制和改进的末端执行器定向框架。

Result: 用户研究显示，相比笛卡尔模式切换和最先进学习方法，Point and Go模式切换将完成时间减少31%、暂停时间减少41%、模式切换次数减少33%，用户调查反馈显著更优。

Conclusion: Point and Go模式切换通过更直观的参考系设计，显著改善了轮椅机器人的操作性能，减少了模式切换需求，提升了用户体验。

Abstract: Operating high degree of freedom robots can be difficult for users of
wheelchair mounted robotic manipulators. Mode switching in Cartesian space has
several drawbacks such as unintuitive control reference frames, separate
translation and orientation control, and limited movement capabilities that
hinder performance. We propose Point and Go mode switching, which reallocates
the Cartesian mode switching reference frames into a more intuitive action
space comprised of new translation and rotation modes. We use a novel sweeping
motion to point the gripper, which defines the new translation axis along the
robot base frame's horizontal plane. This creates an intuitive `point and go'
translation mode that allows the user to easily perform complex, human-like
movements without switching control modes. The system's rotation mode combines
position control with a refined end-effector oriented frame that provides
precise and consistent robot actions in various end-effector poses. We verified
its effectiveness through initial experiments, followed by a three-task user
study that compared our method to Cartesian mode switching and a state of the
art learning method. Results show that Point and Go mode switching reduced
completion times by 31\%, pauses by 41\%, and mode switches by 33\%, while
receiving significantly favorable responses in user surveys.

</details>


### [3] [Whole Body Model Predictive Control for Spin-Aware Quadrupedal Table Tennis](https://arxiv.org/abs/2510.08754)
*David Nguyen,Zulfiqar Zaidi,Kevin Karol,Jessica Hodgins,Zhaoming Xie*

Main category: cs.RO

TL;DR: 开发了一个让四足机器人打动态乒乓球的系统，集成了高速感知、轨迹预测和敏捷控制，能够在真实环境中与人类对打。


<details>
  <summary>Details</summary>
Motivation: 开发能够匹配人类速度、精度和预测旋转球能力的乒乓球机器人对腿式机器人来说仍是重大挑战。

Method: 使用外部摄像头进行高速球定位，基于物理模型和学习的残差推断旋转并预测轨迹，采用新颖的模型预测控制(MPC)进行敏捷全身控制。

Result: 在Spot四足机器人上成功演示，能够瞄准和回击各种旋转球，并能与人类玩家进行对打。

Conclusion: 该系统展示了四足机器人在动态乒乓球任务中的协调能力，自动涌现出连续击球策略，为腿式机器人的敏捷控制提供了新范例。

Abstract: Developing table tennis robots that mirror human speed, accuracy, and ability
to predict and respond to the full range of ball spins remains a significant
challenge for legged robots. To demonstrate these capabilities we present a
system to play dynamic table tennis for quadrupedal robots that integrates high
speed perception, trajectory prediction, and agile control. Our system uses
external cameras for high-speed ball localization, physical models with learned
residuals to infer spin and predict trajectories, and a novel model predictive
control (MPC) formulation for agile full-body control. Notably, a continuous
set of stroke strategies emerge automatically from different ball return
objectives using this control paradigm. We demonstrate our system in the real
world on a Spot quadruped, evaluate accuracy of each system component, and
exhibit coordination through the system's ability to aim and return balls with
varying spin types. As a further demonstration, the system is able to rally
with human players.

</details>


### [4] [Geometry-aware Policy Imitation](https://arxiv.org/abs/2510.08787)
*Yiming Li,Nael Darwiche,Amirreza Razmjoo,Sichao Liu,Yilun Du,Auke Ijspeert,Sylvain Calinon*

Main category: cs.RO

TL;DR: GPI将演示数据视为几何曲线而非状态-动作样本，通过距离场生成两种控制原语：沿专家轨迹前进的推进流和纠正偏差的吸引流，实现高效、可解释的机器人模仿学习。


<details>
  <summary>Details</summary>
Motivation: 重新思考模仿学习，将演示数据作为几何曲线处理，以克服传统方法在效率、可解释性和多模态处理方面的局限。

Method: 从演示曲线推导距离场，生成推进流和吸引流两种控制原语，组合成可控的非参数向量场直接指导机器人行为，将度量学习与策略合成解耦。

Result: 在模拟和真实机器人任务中，GPI比基于扩散的策略获得更高成功率，运行速度快20倍，内存需求更少，且对扰动保持鲁棒性。

Conclusion: GPI为机器人模仿学习提供了一种高效、可解释且可扩展的生成方法替代方案。

Abstract: We propose a Geometry-aware Policy Imitation (GPI) approach that rethinks
imitation learning by treating demonstrations as geometric curves rather than
collections of state-action samples. From these curves, GPI derives distance
fields that give rise to two complementary control primitives: a progression
flow that advances along expert trajectories and an attraction flow that
corrects deviations. Their combination defines a controllable, non-parametric
vector field that directly guides robot behavior. This formulation decouples
metric learning from policy synthesis, enabling modular adaptation across
low-dimensional robot states and high-dimensional perceptual inputs. GPI
naturally supports multimodality by preserving distinct demonstrations as
separate models and allows efficient composition of new demonstrations through
simple additions to the distance field. We evaluate GPI in simulation and on
real robots across diverse tasks. Experiments show that GPI achieves higher
success rates than diffusion-based policies while running 20 times faster,
requiring less memory, and remaining robust to perturbations. These results
establish GPI as an efficient, interpretable, and scalable alternative to
generative approaches for robotic imitation learning. Project website:
https://yimingli1998.github.io/projects/GPI/

</details>


### [5] [Humanoid Everyday: A Comprehensive Robotic Dataset for Open-World Humanoid Manipulation](https://arxiv.org/abs/2510.08807)
*Zhenyu Zhao,Hongyi Jing,Xiawei Liu,Jiageng Mao,Abha Jha,Hanwen Yang,Rong Xue,Sergey Zakharor,Vitor Guizilini,Yue Wang*

Main category: cs.RO

TL;DR: 提出了Humanoid Everyday数据集，这是一个大规模、多样化的人形机器人操作数据集，包含10.3k条轨迹和300万帧数据，涵盖260个任务和7个类别，并提供了云端评估平台。


<details>
  <summary>Details</summary>
Motivation: 当前机器人学习数据集主要关注固定机械臂，现有的人形机器人数据集要么局限于固定环境，要么任务多样性不足，缺乏人机交互和下半身运动，且缺乏标准化评估平台。

Method: 使用高效的人类监督遥操作流水线，收集高质量多模态感官数据（RGB、深度、LiDAR、触觉输入）和自然语言标注。

Result: 创建了包含10.3k条轨迹和300万帧数据的大规模数据集，涵盖灵巧物体操作、人机交互、运动集成动作等260个任务，并建立了云端评估平台。

Conclusion: 通过发布Humanoid Everyday数据集、策略学习分析和标准化云端评估平台，旨在推动通用人形机器人操作研究，为现实世界中更强大的具身机器人奠定基础。

Abstract: From loco-motion to dextrous manipulation, humanoid robots have made
remarkable strides in demonstrating complex full-body capabilities. However,
the majority of current robot learning datasets and benchmarks mainly focus on
stationary robot arms, and the few existing humanoid datasets are either
confined to fixed environments or limited in task diversity, often lacking
human-humanoid interaction and lower-body locomotion. Moreover, there are a few
standardized evaluation platforms for benchmarking learning-based policies on
humanoid data. In this work, we present Humanoid Everyday, a large-scale and
diverse humanoid manipulation dataset characterized by extensive task variety
involving dextrous object manipulation, human-humanoid interaction,
locomotion-integrated actions, and more. Leveraging a highly efficient
human-supervised teleoperation pipeline, Humanoid Everyday aggregates
high-quality multimodal sensory data, including RGB, depth, LiDAR, and tactile
inputs, together with natural language annotations, comprising 10.3k
trajectories and over 3 million frames of data across 260 tasks across 7 broad
categories. In addition, we conduct an analysis of representative policy
learning methods on our dataset, providing insights into their strengths and
limitations across different task categories. For standardized evaluation, we
introduce a cloud-based evaluation platform that allows researchers to
seamlessly deploy their policies in our controlled setting and receive
performance feedback. By releasing Humanoid Everyday along with our policy
learning analysis and a standardized cloud-based evaluation platform, we intend
to advance research in general-purpose humanoid manipulation and lay the
groundwork for more capable and embodied robotic agents in real-world
scenarios. Our dataset, data collection code, and cloud evaluation website are
made publicly available on our project website.

</details>


### [6] [Adaptive Motion Planning via Contact-Based Intent Inference for Human-Robot Collaboration](https://arxiv.org/abs/2510.08811)
*Jiurun Song,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: 提出了一种基于接触信息的人机协作自适应运动规划框架，通过物理接触直接推断人类意图并在线修正机器人运动。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中机器人如何适应人类意图的问题，克服语言模型在可靠运动规划中的局限性，以及传统物理人机交互中持续引导给操作者带来的负担。

Method: 1) 基于优化的力估计方法从关节扭矩测量和机器人动力学模型推断人类意图的接触力和位置；2) 基于扭矩的接触检测机制进行链接级定位；3) 接触信息自适应运动规划器在线重新规划机器人运动。

Result: 在7自由度机械臂上的实验表明，所提出的力估计方法具有准确性，接触信息自适应运动规划器在人机协作中感知不确定性下具有有效性。

Conclusion: 该框架能够直接从物理接触推断人类意图，实现实时运动修正，为人机协作提供了可靠且高效的运动规划解决方案。

Abstract: Human-robot collaboration (HRC) requires robots to adapt their motions to
human intent to ensure safe and efficient cooperation in shared spaces.
Although large language models (LLMs) provide high-level reasoning for
inferring human intent, their application to reliable motion planning in HRC
remains challenging. Physical human-robot interaction (pHRI) is intuitive but
often relies on continuous kinesthetic guidance, which imposes burdens on
operators. To address these challenges, a contact-informed adaptive
motion-planning framework is introduced to infer human intent directly from
physical contact and employ the inferred intent for online motion correction in
HRC. First, an optimization-based force estimation method is proposed to infer
human-intended contact forces and locations from joint torque measurements and
a robot dynamics model, thereby reducing cost and installation complexity while
enabling whole-body sensitivity. Then, a torque-based contact detection
mechanism with link-level localization is introduced to reduce the optimization
search space and to enable real-time estimation. Subsequently, a
contact-informed adaptive motion planner is developed to infer human intent
from contacts and to replan robot motion online, while maintaining smoothness
and adapting to human corrections. Finally, experiments on a 7-DOF manipulator
are conducted to demonstrate the accuracy of the proposed force estimation
method and the effectiveness of the contact-informed adaptive motion planner
under perception uncertainty in HRC.

</details>


### [7] [Adaptive Science Operations in Deep Space Missions Using Offline Belief State Planning](https://arxiv.org/abs/2510.08812)
*Grace Ra Kim,Hailey Warner,Duncan Eddy,Evan Astle,Zachary Booth,Edward Balaban,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 提出了一种基于部分可观测马尔可夫决策过程（POMDP）的框架，用于在通信受限的深空任务中自适应排序航天器科学仪器，通过整合贝叶斯网络来管理高维不确定性测量数据。


<details>
  <summary>Details</summary>
Motivation: 深空任务面临极端通信延迟和环境不确定性，无法进行实时地面操作，需要支持在通信受限环境中的自主科学操作。

Method: 将贝叶斯网络整合到POMDP观测空间中，紧凑编码测量间的依赖关系，提高科学数据的可解释性和计算可行性。仪器操作策略离线计算，允许在发射前生成资源感知计划并进行全面验证。

Result: 使用Enceladus Orbilander的生命检测套件作为案例研究，展示了贝叶斯网络结构和奖励塑造如何影响系统性能。与任务基线概念操作相比，样本识别错误减少了近40%。

Conclusion: 该方法显著提高了深空任务中科学仪器操作的自主性和准确性，在非标称样本积累场景中表现出优越性能。

Abstract: Deep space missions face extreme communication delays and environmental
uncertainty that prevent real-time ground operations. To support autonomous
science operations in communication-constrained environments, we present a
partially observable Markov decision process (POMDP) framework that adaptively
sequences spacecraft science instruments. We integrate a Bayesian network into
the POMDP observation space to manage the high-dimensional and uncertain
measurements typical of astrobiology missions. This network compactly encodes
dependencies among measurements and improves the interpretability and
computational tractability of science data. Instrument operation policies are
computed offline, allowing resource-aware plans to be generated and thoroughly
validated prior to launch. We use the Enceladus Orbilander's proposed Life
Detection Suite (LDS) as a case study, demonstrating how Bayesian network
structure and reward shaping influence system performance. We compare our
method against the mission's baseline Concept of Operations (ConOps),
evaluating both misclassification rates and performance in off-nominal sample
accumulation scenarios. Our approach reduces sample identification errors by
nearly 40%

</details>


### [8] [CDE: Concept-Driven Exploration for Reinforcement Learning](https://arxiv.org/abs/2510.08851)
*Le Mao,Andrew H. Liu,Renos Zabounidis,Zachary Kingston,Joseph Campbell*

Main category: cs.RO

TL;DR: CDE利用预训练的视觉语言模型从文本任务描述中生成物体中心视觉概念作为弱监督信号，通过训练策略重构这些概念来引导探索，在视觉控制任务中实现高效探索。


<details>
  <summary>Details</summary>
Motivation: 解决视觉强化学习中智能探索的挑战，特别是在需要从原始像素中提取任务相关结构的视觉控制任务中，传统方法探索效率低。

Method: 使用预训练VLM从文本描述生成物体中心概念作为弱监督信号，训练策略重构这些概念，将重构准确度作为内在奖励来引导探索。

Result: 在五个模拟视觉操作任务中实现高效、目标导向的探索，对噪声VLM预测具有鲁棒性，在真实世界Franka机械臂上达到80%成功率。

Conclusion: CDE通过概念驱动的探索方法有效解决了视觉RL中的探索挑战，减少了对外部模型的依赖，并在真实世界任务中验证了有效性。

Abstract: Intelligent exploration remains a critical challenge in reinforcement
learning (RL), especially in visual control tasks. Unlike low-dimensional
state-based RL, visual RL must extract task-relevant structure from raw pixels,
making exploration inefficient. We propose Concept-Driven Exploration (CDE),
which leverages a pre-trained vision-language model (VLM) to generate
object-centric visual concepts from textual task descriptions as weak,
potentially noisy supervisory signals. Rather than directly conditioning on
these noisy signals, CDE trains a policy to reconstruct the concepts via an
auxiliary objective, using reconstruction accuracy as an intrinsic reward to
guide exploration toward task-relevant objects. Because the policy internalizes
these concepts, VLM queries are only needed during training, reducing
dependence on external models during deployment. Across five challenging
simulated visual manipulation tasks, CDE achieves efficient, targeted
exploration and remains robust to noisy VLM predictions. Finally, we
demonstrate real-world transfer by deploying CDE on a Franka Research 3 arm,
attaining an 80\% success rate in a real-world manipulation task.

</details>


### [9] [Online IMU-odometer Calibration using GNSS Measurements for Autonomous Ground Vehicle Localization](https://arxiv.org/abs/2510.08880)
*Baoshan Song,Xiao Xia,Penggao Yan,Yihan Zhong,Weisong Wen,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 提出一种基于紧耦合因子图优化的IMU-里程计-GNSS在线标定方法，通过融合原始GNSS观测值实现精确的标定和定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有GNSS辅助方法依赖定位结果或未解模糊度的原始观测值，且可观测性分析不足，需要更精确的标定方法。

Method: 在可扩展因子图优化框架中紧耦合融合IMU、里程计和原始GNSS观测值（伪距、载波相位和多普勒），包含异常值抑制和模糊度解算。

Result: 仿真和真实实验表明，该方法在校准和定位性能上优于最先进的松耦合方法，绝对最大误差从61.51米降低到17.75米，提升71.14%。

Conclusion: 该方法实现了精确的IMU-里程计标定，并发布了首个包含IMU、2D里程计和原始GNSS测量的开源数据集。

Abstract: Accurate calibration of intrinsic (odometer scaling factors) and extrinsic
parameters (IMU-odometer translation and rotation) is essential for autonomous
ground vehicle localization. Existing GNSS-aided approaches often rely on
positioning results or raw measurements without ambiguity resolution, and their
observability properties remain underexplored. This paper proposes a tightly
coupled online calibration method that fuses IMU, odometer, and raw GNSS
measurements (pseudo-range, carrier-phase, and Doppler) within an extendable
factor graph optimization (FGO) framework, incorporating outlier mitigation and
ambiguity resolution. Observability analysis reveals that two horizontal
translation and three rotation parameters are observable under general motion,
while vertical translation remains unobservable. Simulation and real-world
experiments demonstrate superior calibration and localization performance over
state-of-the-art loosely coupled methods. Specifically, the IMU-odometer
positioning using our calibrated parameters achieves the absolute maximum error
of 17.75 m while the one of LC method is 61.51 m, achieving up to 71.14 percent
improvement. To foster further research, we also release the first open-source
dataset that combines IMU, 2D odometer, and raw GNSS measurements from both
rover and base stations.

</details>


### [10] [Model-Based Lookahead Reinforcement Learning for in-hand manipulation](https://arxiv.org/abs/2510.08884)
*Alexandre Lopes,Catarina Barata,Plinio Moreno*

Main category: cs.RO

TL;DR: 将混合强化学习框架应用于手内操作任务，结合模型无关和模型相关方法，通过轨迹评估提升性能，但增加了计算成本。


<details>
  <summary>Details</summary>
Motivation: 手内操作是机器人领域的难点，需要控制复杂动态系统来操纵各种物体。本研究旨在验证混合强化学习框架能否提升手内操作任务的性能。

Method: 结合模型无关和模型相关强化学习，使用动态模型和价值函数通过轨迹评估来指导训练好的策略，类似于模型预测控制方法。使用全驱动和欠驱动仿真机械手进行测试。

Result: 在大多数测试案例中，混合框架提高了手内操作任务的性能，即使物体属性发生变化。但性能提升以计算成本增加为代价。

Conclusion: 混合强化学习框架能有效提升手内操作任务的性能，但需要权衡性能提升与计算成本之间的关系。

Abstract: In-Hand Manipulation, as many other dexterous tasks, remains a difficult
challenge in robotics by combining complex dynamic systems with the capability
to control and manoeuvre various objects using its actuators. This work
presents the application of a previously developed hybrid Reinforcement
Learning (RL) Framework to In-Hand Manipulation task, verifying that it is
capable of improving the performance of the task. The model combines concepts
of both Model-Free and Model-Based Reinforcement Learning, by guiding a trained
policy with the help of a dynamic model and value-function through trajectory
evaluation, as done in Model Predictive Control. This work evaluates the
performance of the model by comparing it with the policy that will be guided.
To fully explore this, various tests are performed using both fully-actuated
and under-actuated simulated robotic hands to manipulate different objects for
a given task. The performance of the model will also be tested for
generalization tests, by changing the properties of the objects in which both
the policy and dynamic model were trained, such as density and size, and
additionally by guiding a trained policy in a certain object to perform the
same task in a different one. The results of this work show that, given a
policy with high average reward and an accurate dynamic model, the hybrid
framework improves the performance of in-hand manipulation tasks for most test
cases, even when the object properties are changed. However, this improvement
comes at the expense of increasing the computational cost, due to the
complexity of trajectory evaluation.

</details>


### [11] [Direct Data-Driven Predictive Control for a Three-dimensional Cable-Driven Soft Robotic Arm](https://arxiv.org/abs/2510.08953)
*Cheng Ouyang,Moeen Ul Islam,Dong Chen,Kaixiang Zhang,Zhaojian Li,Xiaobo Tan*

Main category: cs.RO

TL;DR: 本文开发并验证了数据驱动预测控制(DeePC)在3D软体机器人上的应用，通过实验证明该方法在固定点调节和轨迹跟踪任务中优于传统模型控制方法。


<details>
  <summary>Details</summary>
Motivation: 软体机器人具有安全性和适应性优势，但因其复杂的非线性动力学特性，实现精确动态控制面临挑战。DeePC作为一种无需显式系统辨识的数据驱动方法，在软体机器人领域的应用尚未充分探索。

Method: 设计制造了具有厚管状骨架、密集硅胶体和刚性端盖的3D缆驱软体臂，采用基于奇异值分解降维的DeePC框架，实现固定点调节和3D空间轨迹跟踪控制。

Result: 与基线模型控制器相比，DeePC在精度、鲁棒性和适应性方面表现更优，验证了其作为软体机器人动态控制实用解决方案的潜力。

Conclusion: DeePC框架为3D软体机器人提供了有效的动态控制方案，无需复杂建模即可实现精确控制，展现了数据驱动方法在软体机器人控制中的优势。

Abstract: Soft robots offer significant advantages in safety and adaptability, yet
achieving precise and dynamic control remains a major challenge due to their
inherently complex and nonlinear dynamics. Recently, Data-enabled Predictive
Control (DeePC) has emerged as a promising model-free approach that bypasses
explicit system identification by directly leveraging input-output data. While
DeePC has shown success in other domains, its application to soft robots
remains underexplored, particularly for three-dimensional (3D) soft robotic
systems. This paper addresses this gap by developing and experimentally
validating an effective DeePC framework on a 3D, cable-driven soft arm.
Specifically, we design and fabricate a soft robotic arm with a thick tubing
backbone for stability, a dense silicone body with large cavities for strength
and flexibility, and rigid endcaps for secure termination. Using this platform,
we implement DeePC with singular value decomposition (SVD)-based dimension
reduction for two key control tasks: fixed-point regulation and trajectory
tracking in 3D space. Comparative experiments with a baseline model-based
controller demonstrate DeePC's superior accuracy, robustness, and adaptability,
highlighting its potential as a practical solution for dynamic control of soft
robots.

</details>


### [12] [A geometrical approach to solve the proximity of a point to an axisymmetric quadric in space](https://arxiv.org/abs/2510.08973)
*Bibekananda Patra,Aditya Mahesh Kolte,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 该论文提出了一种将一般二次曲面分类为轴对称二次曲面(AQ)的方法，并解决了点到AQ的最近距离问题。通过将R^3空间中的问题简化为R^2空间，并利用圆锥曲线的几何特性提出新的求解方法。


<details>
  <summary>Details</summary>
Motivation: 解决三维空间中点到轴对称二次曲面的最近距离计算问题，现有文献中缺乏将R^3问题简化为R^2的有效方法。

Method: 基于圆锥曲线的几何特性（如次法线、半长轴长度、离心率、斜率和半径），将R^2空间中的问题根据点位置进一步分类为抛物线和椭圆/双曲线的子情况。

Result: 提出的方法适合在C等通用编程语言中实现，并且比商业库Bullet更快。

Conclusion: 该研究提供了一种新颖且高效的计算点到轴对称二次曲面距离的方法，通过几何特性分类和降维处理实现了性能优化。

Abstract: This paper presents the classification of a general quadric into an
axisymmetric quadric (AQ) and the solution to the problem of the proximity of a
given point to an AQ. The problem of proximity in $R^3$ is reduced to the same
in $R^2$, which is not found in the literature. A new method to solve the
problem in $R^2$ is used based on the geometrical properties of the conics,
such as sub-normal, length of the semi-major axis, eccentricity, slope and
radius. Furthermore, the problem in $R^2$ is categorised into two and three
more sub-cases for parabola and ellipse/hyperbola, respectively, depending on
the location of the point, which is a novel approach as per the authors'
knowledge. The proposed method is suitable for implementation in a common
programming language, such as C and proved to be faster than a commercial
library, namely, Bullet.

</details>


### [13] [Trust Modeling and Estimation in Human-Autonomy Interactions](https://arxiv.org/abs/2510.09013)
*Daniel A. Williams,Airlie Chapman,Daniel R. Little,Chris Manzie*

Main category: cs.RO

TL;DR: 提出了一种基于切换线性系统的监督者信任动态模型，该模型考虑了自主系统性能的不对称响应和间歇性通信特性。


<details>
  <summary>Details</summary>
Motivation: 自主系统应用中，监督者与系统之间的交互质量对系统成功至关重要，而现有文献缺乏能够处理不对称性能响应和间歇性通信的信任动态模型。

Method: 采用切换线性系统结构，结合事件触发采样的模型输入输出，使用51名参与者的信任响应数据来识别切换线性模型观测器的参数。

Result: 开发了一个能够准确建模监督者信任动态的估计模型，该模型能够捕捉到对自主系统性能的不对称响应和间歇性通信的影响。

Conclusion: 所提出的切换线性模型为自主系统中的监督者信任动态提供了有效的建模框架，能够更好地反映实际交互中的复杂特性。

Abstract: Advances in the control of autonomous systems have accompanied an expansion
in the potential applications for autonomous robotic systems. The success of
applications involving humans depends on the quality of interaction between the
autonomous system and the human supervisor, which is particularly affected by
the degree of trust that the supervisor places in the autonomous system. Absent
from the literature are models of supervisor trust dynamics that can
accommodate asymmetric responses to autonomous system performance and the
intermittent nature of supervisor-autonomous system communication. This paper
focuses on formulating an estimated model of supervisor trust that incorporates
both of these features by employing a switched linear system structure with
event-triggered sampling of the model input and output. Trust response data
collected in a user study with 51 participants were then used identify
parameters for a switched linear model-based observer of supervisor trust.

</details>


### [14] [iMoWM: Taming Interactive Multi-Modal World Model for Robotic Manipulation](https://arxiv.org/abs/2510.09036)
*Chuanrui Zhang,Zhengxian Wu,Guanxing Lu,Yansong Tang,Ziwei Wang*

Main category: cs.RO

TL;DR: iMoWM是一个用于机器人操作的交互式世界模型，通过多模态token化方法生成彩色图像、深度图和机器人手臂掩码，解决了传统2D视频模型缺乏几何和空间推理的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的2D视频世界模型缺乏几何和空间推理能力，无法准确捕捉3D世界的物理结构，这限制了它们在机器人操作任务中的应用。

Method: 提出iMoWM模型和MMTokenizer方法，将多模态输入统一为紧凑的token表示，利用预训练VideoGPT模型进行自回归生成，同时保持高效率并融入丰富的物理信息。

Result: 实验表明iMoWM在视觉质量、模型强化学习和真实世界模仿学习方面表现优越，展示了多模态世界建模在机器人操作中的优势。

Conclusion: 多模态世界建模能够显著提升机器人操作任务的性能，iMoWM通过整合几何和空间信息为机器人操作提供了更有效的仿真环境。

Abstract: Learned world models hold significant potential for robotic manipulation, as
they can serve as simulator for real-world interactions. While extensive
progress has been made in 2D video-based world models, these approaches often
lack geometric and spatial reasoning, which is essential for capturing the
physical structure of the 3D world. To address this limitation, we introduce
iMoWM, a novel interactive world model designed to generate color images, depth
maps, and robot arm masks in an autoregressive manner conditioned on actions.
To overcome the high computational cost associated with three-dimensional
information, we propose MMTokenizer, which unifies multi-modal inputs into a
compact token representation. This design enables iMoWM to leverage large-scale
pretrained VideoGPT models while maintaining high efficiency and incorporating
richer physical information. With its multi-modal representation, iMoWM not
only improves the visual quality of future predictions but also serves as an
effective simulator for model-based reinforcement learning (MBRL) and
facilitates real-world imitation learning. Extensive experiments demonstrate
the superiority of iMoWM across these tasks, showcasing the advantages of
multi-modal world modeling for robotic manipulation. Homepage:
https://xingyoujun.github.io/imowm/

</details>


### [15] [Training Models to Detect Successive Robot Errors from Human Reactions](https://arxiv.org/abs/2510.09080)
*Shannon Liu,Maria Teresa Parreira,Wendy Ju*

Main category: cs.RO

TL;DR: 使用机器学习从人类反应中识别机器人连续失败阶段，通过视频行为特征训练个性化模型，在检测错误和分类连续失败方面分别达到93.5%和84.1%的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着机器人更深入融入社会，检测机器人错误对有效的人机交互至关重要。人类对机器人错误的反应会随着连续失败而加剧，从困惑到明显沮丧，这些演化反应可以揭示连续失败。

Method: 在26名参与者与连续对话错误的机器人互动研究中，从视频数据中提取行为特征，为个体用户训练机器学习模型来识别机器人失败阶段。

Result: 最佳模型在检测错误方面达到93.5%准确率，在分类连续失败方面达到84.1%准确率。

Conclusion: 对人类反应进展进行建模可以增强错误检测能力，并更好地理解人机交互中重复的交互中断。

Abstract: As robots become more integrated into society, detecting robot errors is
essential for effective human-robot interaction (HRI). When a robot fails
repeatedly, how can it know when to change its behavior? Humans naturally
respond to robot errors through verbal and nonverbal cues that intensify over
successive failures-from confusion and subtle speech changes to visible
frustration and impatience. While prior work shows that human reactions can
indicate robot failures, few studies examine how these evolving responses
reveal successive failures. This research uses machine learning to recognize
stages of robot failure from human reactions. In a study with 26 participants
interacting with a robot that made repeated conversational errors, behavioral
features were extracted from video data to train models for individual users.
The best model achieved 93.5% accuracy for detecting errors and 84.1% for
classifying successive failures. Modeling the progression of human reactions
enhances error detection and understanding of repeated interaction breakdowns
in HRI.

</details>


### [16] [Robust Visual Teach-and-Repeat Navigation with Flexible Topo-metric Graph Map Representation](https://arxiv.org/abs/2510.09089)
*Jikai Wang,Yunqi Cheng,Kezhi Wang,Zonghai Chen*

Main category: cs.RO

TL;DR: 提出了一种新颖的视觉教学-重复导航系统，通过灵活的拓扑度量图表示、鲁棒的地图匹配和无地图局部导航模块，解决了环境变化和动态物体带来的导航挑战。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中部署移动机器人时，视觉教学-重复导航是直接解决方案，但环境变化和动态物体使得鲁棒的轨迹重复导航仍然具有挑战性。

Method: 1. 使用拓扑度量图表示关键帧，支持扩展新观测；2. 基于关键帧聚类的视觉帧到局部地图匹配策略；3. 长期目标管理算法；4. 无地图局部轨迹控制候选优化算法。

Result: 在移动平台上进行了广泛实验，结果显示该系统在鲁棒性和有效性方面优于基线方法。

Conclusion: 所提出的视觉教学-重复导航系统能够有效应对环境变化和动态障碍物，实现了鲁棒且有效的轨迹重复导航。

Abstract: Visual Teach-and-Repeat Navigation is a direct solution for mobile robot to
be deployed in unknown environments. However, robust trajectory repeat
navigation still remains challenged due to environmental changing and dynamic
objects. In this paper, we propose a novel visual teach-and-repeat navigation
system, which consists of a flexible map representation, robust map matching
and a map-less local navigation module. During the teaching process, the
recorded keyframes are formulated as a topo-metric graph and each node can be
further extended to save new observations. Such representation also alleviates
the requirement of globally consistent mapping. To enhance the place
recognition performance during repeating process, instead of using
frame-to-frame matching, we firstly implement keyframe clustering to aggregate
similar connected keyframes into local map and perform place recognition based
on visual frame-tolocal map matching strategy. To promote the local goal
persistent tracking performance, a long-term goal management algorithm is
constructed, which can avoid the robot getting lost due to environmental
changes or obstacle occlusion. To achieve the goal without map, a local
trajectory-control candidate optimization algorithm is proposed. Extensively
experiments are conducted on our mobile platform. The results demonstrate that
our system is superior to the baselines in terms of robustness and
effectiveness.

</details>


### [17] [When a Robot is More Capable than a Human: Learning from Constrained Demonstrators](https://arxiv.org/abs/2510.09096)
*Xinhu Li,Ayush Jain,Zhaojing Yang,Yigit Korkmaz,Erdem Bıyık*

Main category: cs.RO

TL;DR: 该论文提出了一种从受限专家演示中学习更优策略的方法，通过推断状态奖励信号和时域插值，使机器人能够探索比演示更高效的轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有的演示学习接口（如遥操作、模拟到真实迁移）限制了专家展示最优行为的能力，导致学习到的策略性能不佳。机器人能否学习到比受限专家演示更好的策略是一个关键问题。

Method: 使用演示推断仅基于状态的任务进度奖励信号，对未知状态使用时域插值进行自标记奖励，使智能体能够超越直接模仿专家动作，探索更短更高效的轨迹。

Result: 该方法在样本效率和任务完成时间上均优于常见的模仿学习方法。在真实的WidowX机械臂上，任务完成时间仅为12秒，比行为克隆快10倍。

Conclusion: 通过从受限专家演示中推断奖励信号并探索更优轨迹，机器人可以学习到比演示本身更好的策略，显著提升任务性能。

Abstract: Learning from demonstrations enables experts to teach robots complex tasks
using interfaces such as kinesthetic teaching, joystick control, and
sim-to-real transfer. However, these interfaces often constrain the expert's
ability to demonstrate optimal behavior due to indirect control, setup
restrictions, and hardware safety. For example, a joystick can move a robotic
arm only in a 2D plane, even though the robot operates in a higher-dimensional
space. As a result, the demonstrations collected by constrained experts lead to
suboptimal performance of the learned policies. This raises a key question: Can
a robot learn a better policy than the one demonstrated by a constrained
expert? We address this by allowing the agent to go beyond direct imitation of
expert actions and explore shorter and more efficient trajectories. We use the
demonstrations to infer a state-only reward signal that measures task progress,
and self-label reward for unknown states using temporal interpolation. Our
approach outperforms common imitation learning in both sample efficiency and
task completion time. On a real WidowX robotic arm, it completes the task in 12
seconds, 10x faster than behavioral cloning, as shown in real-robot videos on
https://sites.google.com/view/constrainedexpert .

</details>


### [18] [Decentralized Multi-Robot Relative Navigation in Unknown, Structurally Constrained Environments under Limited Communication](https://arxiv.org/abs/2510.09188)
*Zihao Mao,Yunheng Wang,Yunting Ji,Yi Yang,Wenjie Song*

Main category: cs.RO

TL;DR: 提出了一种完全去中心化的分层相对导航框架，在未知、结构受限和GPS缺失环境中实现战略远见和战术敏捷性，无需统一坐标系。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人导航中集中式方法通信开销高、分布式方法缺乏全局意识导致死锁和拓扑陷阱的问题。

Method: 分层框架：战略层通过机会性相遇交换轻量级拓扑地图实现全局意识；战术层使用基于采样的逃逸点策略实时生成动态可行轨迹。

Result: 在通信受限和复杂拓扑结构环境中，系统在成功率和效率方面显著优于其他方法。

Conclusion: 该框架成功平衡了全局战略远见和局部战术敏捷性，在受限环境中表现出色。

Abstract: Multi-robot navigation in unknown, structurally constrained, and GPS-denied
environments presents a fundamental trade-off between global strategic
foresight and local tactical agility, particularly under limited communication.
Centralized methods achieve global optimality but suffer from high
communication overhead, while distributed methods are efficient but lack the
broader awareness to avoid deadlocks and topological traps. To address this, we
propose a fully decentralized, hierarchical relative navigation framework that
achieves both strategic foresight and tactical agility without a unified
coordinate system. At the strategic layer, robots build and exchange
lightweight topological maps upon opportunistic encounters. This process
fosters an emergent global awareness, enabling the planning of efficient,
trap-avoiding routes at an abstract level. This high-level plan then inspires
the tactical layer, which operates on local metric information. Here, a
sampling-based escape point strategy resolves dense spatio-temporal conflicts
by generating dynamically feasible trajectories in real time, concurrently
satisfying tight environmental and kinodynamic constraints. Extensive
simulations and real-world experiments demonstrate that our system
significantly outperforms in success rate and efficiency, especially in
communication-limited environments with complex topological structures.

</details>


### [19] [Flow-Opt: Scalable Centralized Multi-Robot Trajectory Optimization with Flow Matching and Differentiable Optimization](https://arxiv.org/abs/2510.09204)
*Simon Idoko,Arun Kumar Singh*

Main category: cs.RO

TL;DR: Flow-Opt是一种基于学习的集中式多机器人轨迹优化方法，通过生成模型采样候选轨迹和使用安全过滤器确保约束满足，显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 集中式多机器人轨迹优化在紧凑空间中能获得更平滑的轨迹，但计算复杂度随机器人数量增加而急剧上升，难以扩展到大规模群体。

Method: 使用基于流匹配和扩散变换器的生成模型采样轨迹，配合可微分的安全过滤器确保约束满足，并利用神经网络预测上下文特定的初始化。

Result: 能够在几十毫秒内生成数十个机器人在复杂环境中的轨迹，比现有方法快数倍，且能批量处理多个问题实例。

Conclusion: 该方法在计算效率、轨迹平滑度和多样性方面均优于现有方法，为大规模多机器人轨迹规划提供了可行解决方案。

Abstract: Centralized trajectory optimization in the joint space of multiple robots
allows access to a larger feasible space that can result in smoother
trajectories, especially while planning in tight spaces. Unfortunately, it is
often computationally intractable beyond a very small swarm size. In this
paper, we propose Flow-Opt, a learning-based approach towards improving the
computational tractability of centralized multi-robot trajectory optimization.
Specifically, we reduce the problem to first learning a generative model to
sample different candidate trajectories and then using a learned
Safety-Filter(SF) to ensure fast inference-time constraint satisfaction. We
propose a flow-matching model with a diffusion transformer (DiT) augmented with
permutation invariant robot position and map encoders as the generative model.
We develop a custom solver for our SF and equip it with a neural network that
predicts context-specific initialization. The initialization network is trained
in a self-supervised manner, taking advantage of the differentiability of the
SF solver. We advance the state-of-the-art in the following respects. First, we
show that we can generate trajectories of tens of robots in cluttered
environments in a few tens of milliseconds. This is several times faster than
existing centralized optimization approaches. Moreover, our approach also
generates smoother trajectories orders of magnitude faster than competing
baselines based on diffusion models. Second, each component of our approach can
be batched, allowing us to solve a few tens of problem instances in a fraction
of a second. We believe this is a first such result; no existing approach
provides such capabilities. Finally, our approach can generate a diverse set of
trajectories between a given set of start and goal locations, which can capture
different collision-avoidance behaviors.

</details>


### [20] [PLEXUS Hand: Lightweight Four-Motor Prosthetic Hand Enabling Precision-Lateral Dexterous Manipulation](https://arxiv.org/abs/2510.09209)
*Yuki Kuroda,Tomoya Takahashi,Cristian C Beltran-Hernandez,Masashi Hamaya,Kazutoshi Tanaka*

Main category: cs.RO

TL;DR: 提出了一种仅使用4个电机的轻量级（311克）假肢手，通过单轴拇指和优化拇指位置实现基本姿势和手内操作，包括精确抓握和侧向抓握之间的重新定向。


<details>
  <summary>Details</summary>
Motivation: 电动假肢手需要轻量化以减少用户负担，外形像人手以美观，并将电机内置以保护免受损坏和污垢。此外，除了执行日常活动的能力外，手内操作对于日常使用至关重要，例如在不同姿势之间转换，特别是通过旋转运动，如重新定向卡片和操作螺丝刀等工具。

Method: 结合单轴拇指和优化的拇指定位，仅使用四个电机实现基本姿势和手内操作（精确抓握和侧向抓握之间的重新定向）。

Result: 使用各种宽度（5-30毫米）和形状（圆柱体和棱柱）的原始物体进行实验验证，重新定向任务的成功率为90-100%。该手能够执行印章盖章和USB设备插入，以及旋转操作螺丝刀。

Conclusion: 通过单轴拇指和优化拇指位置，仅使用四个电机即可在轻量级假肢手中实现基本姿势和手内操作，成功完成各种日常任务。

Abstract: Electric prosthetic hands should be lightweight to decrease the burden on the
user, shaped like human hands for cosmetic purposes, and have motors inside to
protect them from damage and dirt. In addition to the ability to perform daily
activities, these features are essential for everyday use of the hand. In-hand
manipulation is necessary to perform daily activities such as transitioning
between different postures, particularly through rotational movements, such as
reorienting cards before slot insertion and operating tools such as
screwdrivers. However, currently used electric prosthetic hands only achieve
static grasp postures, and existing manipulation approaches require either many
motors, which makes the prosthesis heavy for daily use in the hand, or complex
mechanisms that demand a large internal space and force external motor
placement, complicating attachment and exposing the components to damage.
Alternatively, we combine a single-axis thumb and optimized thumb positioning
to achieve basic posture and in-hand manipulation, that is, the reorientation
between precision and lateral grasps, using only four motors in a lightweight
(311 g) prosthetic hand. Experimental validation using primitive objects of
various widths (5-30 mm) and shapes (cylinders and prisms) resulted in success
rates of 90-100% for reorientation tasks. The hand performed seal stamping and
USB device insertion, as well as rotation to operate a screwdriver.

</details>


### [21] [HANDO: Hierarchical Autonomous Navigation and Dexterous Omni-loco-manipulation](https://arxiv.org/abs/2510.09221)
*Jingyuan Sun,Chaoran Wang,Mingyu Zhang,Cui Miao,Hongyu Ji,Zihan Qu,Han Sun,Bing Wang,Qingyi Si*

Main category: cs.RO

TL;DR: HANDO是一个双层框架，让配备机械臂的腿式机器人在非结构化环境中执行人类中心的移动操作任务，包括自主导航到语义目标并进行全身协调的精确操作。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中实现无缝的移动操作需要机器人结合自主探索和全身控制来进行物理交互。

Method: 采用双层框架：第一层使用目标条件自主探索策略导航到语义指定目标；第二层使用统一的全身移动操作策略协调手臂和腿部进行精确交互。

Result: 已完成导航模块的初步部署，将继续推进全身移动操作的细粒度部署。

Conclusion: HANDO框架为腿式机器人提供了在动态环境中执行复杂移动操作任务的有效解决方案。

Abstract: Seamless loco-manipulation in unstructured environments requires robots to
leverage autonomous exploration alongside whole-body control for physical
interaction. In this work, we introduce HANDO (Hierarchical Autonomous
Navigation and Dexterous Omni-loco-manipulation), a two-layer framework
designed for legged robots equipped with manipulators to perform human-centered
mobile manipulation tasks. The first layer utilizes a goal-conditioned
autonomous exploration policy to guide the robot to semantically specified
targets, such as a black office chair in a dynamic environment. The second
layer employs a unified whole-body loco-manipulation policy to coordinate the
arm and legs for precise interaction tasks-for example, handing a drink to a
person seated on the chair. We have conducted an initial deployment of the
navigation module, and will continue to pursue finer-grained deployment of
whole-body loco-manipulation.

</details>


### [22] [Glovity: Learning Dexterous Contact-Rich Manipulation via Spatial Wrench Feedback Teleoperation System](https://arxiv.org/abs/2510.09229)
*Yuyang Gao,Haofei Ma,Pai Zheng*

Main category: cs.RO

TL;DR: Glovity是一个低成本的可穿戴远程操作系统，集成了空间力反馈设备和带有指尖霍尔传感器校准的触觉手套，实现了反馈丰富的灵巧操作。


<details>
  <summary>Details</summary>
Motivation: 解决接触丰富任务中的关键挑战，通过提供直观的力反馈和触觉反馈，同时通过精确重定向克服体现差距。

Method: 集成空间力反馈设备与带有指尖霍尔传感器校准的触觉手套，实现精确的力反馈和触觉反馈。

Result: 用户研究显示：力反馈将书本翻页任务的成功率从48%提升至78%，完成时间减少25%；指尖校准显著提高了薄物体抓取成功率；将力信号融入模仿学习在新型接触丰富场景中实现了高成功率。

Conclusion: Glovity系统在接触丰富的灵巧操作任务中表现出显著优势，所有硬件设计和软件将开源发布。

Abstract: We present Glovity, a novel, low-cost wearable teleoperation system that
integrates a spatial wrench (force-torque) feedback device with a haptic glove
featuring fingertip Hall sensor calibration, enabling feedback-rich dexterous
manipulation. Glovity addresses key challenges in contact-rich tasks by
providing intuitive wrench and tactile feedback, while overcoming embodiment
gaps through precise retargeting. User studies demonstrate significant
improvements: wrench feedback boosts success rates in book-flipping tasks from
48% to 78% and reduces completion time by 25%, while fingertip calibration
enhances thin-object grasping success significantly compared to commercial
glove. Furthermore, incorporating wrench signals into imitation learning (via
DP-R3M) achieves high success rate in novel contact-rich scenarios, such as
adaptive page flipping and force-aware handovers. All hardware designs,
software will be open-sourced. Project website: https://glovity.github.io/

</details>


### [23] [Obstacle Avoidance using Dynamic Movement Primitives and Reinforcement Learning](https://arxiv.org/abs/2510.09254)
*Dominik Urbaniak,Alejandro Agostini,Pol Ramon,Jan Rosell,Raúl Suárez,Michael Suppa*

Main category: cs.RO

TL;DR: 提出了一种基于单个人工演示生成平滑、近最优无碰撞3D笛卡尔轨迹的方法，使用动态运动基元编码演示，并通过策略强化学习迭代优化，训练神经网络根据障碍物参数输出轨迹参数。


<details>
  <summary>Details</summary>
Motivation: 解决基于学习的运动规划需要大量训练数据或昂贵人工演示的问题，提供一种更高效的轨迹生成方法。

Method: 将人工演示编码为动态运动基元，使用策略强化学习迭代优化生成多样化轨迹数据集，训练神经网络根据障碍物参数预测轨迹参数。

Result: 在仿真和真实机器人实验中验证，在计算时间、执行时间和轨迹长度方面优于RRT-Connect基线，支持多模态轨迹生成。

Conclusion: 该方法能够从单个演示快速生成高质量的轨迹，适用于不同障碍物几何和末端执行器尺寸的场景。

Abstract: Learning-based motion planning can quickly generate near-optimal
trajectories. However, it often requires either large training datasets or
costly collection of human demonstrations. This work proposes an alternative
approach that quickly generates smooth, near-optimal collision-free 3D
Cartesian trajectories from a single artificial demonstration. The
demonstration is encoded as a Dynamic Movement Primitive (DMP) and iteratively
reshaped using policy-based reinforcement learning to create a diverse
trajectory dataset for varying obstacle configurations. This dataset is used to
train a neural network that takes as inputs the task parameters describing the
obstacle dimensions and location, derived automatically from a point cloud, and
outputs the DMP parameters that generate the trajectory. The approach is
validated in simulation and real-robot experiments, outperforming a RRT-Connect
baseline in terms of computation and execution time, as well as trajectory
length, while supporting multi-modal trajectory generation for different
obstacle geometries and end-effector dimensions. Videos and the implementation
code are available at https://github.com/DominikUrbaniak/obst-avoid-dmp-pi2.

</details>


### [24] [Placeit! A Framework for Learning Robot Object Placement Skills](https://arxiv.org/abs/2510.09267)
*Amina Ferrad,Johann Huber,François Hélénon,Julien Gleyze,Mahdi Khoramshahi,Stéphane Doncieux*

Main category: cs.RO

TL;DR: Placeit!是一个基于进化计算的框架，用于自动生成刚性物体的有效放置位置，支持桌面放置、堆叠和插入等多种任务，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 机器人学习面临大规模高质量数据获取的瓶颈，现有方法通常需要手动且费力的过程。受Graspit!使用仿真自动生成灵巧抓取姿势的启发，需要开发类似方法来解决物体放置问题。

Method: 采用进化计算框架，通过质量多样性优化生成多样化的有效放置姿势，支持多种放置任务场景。

Result: 在所有场景中显著优于最先进方法，基于该框架构建的拾取放置管道在120次真实世界部署中达到90%的成功率。

Conclusion: Placeit!是开放环境拾取放置任务的有力工具，也是训练基于仿真的机器人基础模型所需数据生成的宝贵引擎。

Abstract: Robotics research has made significant strides in learning, yet mastering
basic skills like object placement remains a fundamental challenge. A key
bottleneck is the acquisition of large-scale, high-quality data, which is often
a manual and laborious process. Inspired by Graspit!, a foundational work that
used simulation to automatically generate dexterous grasp poses, we introduce
Placeit!, an evolutionary-computation framework for generating valid placement
positions for rigid objects. Placeit! is highly versatile, supporting tasks
from placing objects on tables to stacking and inserting them. Our experiments
show that by leveraging quality-diversity optimization, Placeit! significantly
outperforms state-of-the-art methods across all scenarios for generating
diverse valid poses. A pick&place pipeline built on our framework achieved a
90% success rate over 120 real-world deployments. This work positions Placeit!
as a powerful tool for open-environment pick-and-place tasks and as a valuable
engine for generating the data needed to train simulation-based foundation
models in robotics.

</details>


### [25] [Bridging Research and Practice in Simulation-based Testing of Industrial Robot Navigation Systems](https://arxiv.org/abs/2510.09396)
*Sajad Khatiri,Francisco Eli Vina Barrientos,Maximilian Wulf,Paolo Tonella,Sebastiano Panichella*

Main category: cs.RO

TL;DR: 将Surrealist仿真测试框架从无人机扩展到ANYmal四足机器人工业检测应用，通过搜索算法自动生成障碍规避场景，在工业评估中验证了五个专有算法并提升了开发流程。


<details>
  <summary>Details</summary>
Motivation: 传统测试方法难以覆盖动态环境中的完整操作需求，需要自动化测试框架来发现手动测试遗漏的故障。

Method: 采用基于搜索的算法自动生成具有挑战性的障碍规避场景，并将框架集成到ANYbotics工作流程中进行六个月的工业评估。

Result: 在试点阶段，生成的测试套件揭示了一个实验算法的关键弱点（成功率40.3%），并证明了另一个算法的优越鲁棒性（成功率71.2%）。正式调查确认该框架能增强开发过程、发现关键故障、提供客观基准并加强验证流程。

Conclusion: Surrealist框架成功应用于工业四足机器人检测，有效提升了算法测试的覆盖率和客观性，在工业环境中证明了其实用价值。

Abstract: Ensuring robust robotic navigation in dynamic environments is a key
challenge, as traditional testing methods often struggle to cover the full
spectrum of operational requirements. This paper presents the industrial
adoption of Surrealist, a simulation-based test generation framework originally
for UAVs, now applied to the ANYmal quadrupedal robot for industrial
inspection. Our method uses a search-based algorithm to automatically generate
challenging obstacle avoidance scenarios, uncovering failures often missed by
manual testing. In a pilot phase, generated test suites revealed critical
weaknesses in one experimental algorithm (40.3% success rate) and served as an
effective benchmark to prove the superior robustness of another (71.2% success
rate). The framework was then integrated into the ANYbotics workflow for a
six-month industrial evaluation, where it was used to test five proprietary
algorithms. A formal survey confirmed its value, showing it enhances the
development process, uncovers critical failures, provides objective benchmarks,
and strengthens the overall verification pipeline.

</details>


### [26] [Failure Prediction at Runtime for Generative Robot Policies](https://arxiv.org/abs/2510.09459)
*Ralf Römer,Adrian Kobras,Luca Worbis,Angela P. Schoellig*

Main category: cs.RO

TL;DR: FIPER是一个无需失败数据的运行时故障预测框架，用于生成式模仿学习策略，通过检测异常观察和行动不确定性来预测机器人任务失败。


<details>
  <summary>Details</summary>
Motivation: 生成式模仿学习虽然能让机器人执行复杂任务，但环境分布偏移和行动误差累积仍会导致不可预测的不安全行为，需要运行时故障预测来确保在人类环境和安全关键场景中的部署安全。

Method: FIPER识别两个关键故障指标：(1)通过随机网络蒸馏检测策略嵌入空间中的异常观察；(2)通过新颖的行动块熵评分测量生成行动的高不确定性。使用符合预测校准这两个指标，并在短时间窗口内聚合超过阈值时触发故障警报。

Result: 在五个仿真和真实环境中的评估表明，FIPER能更好地区分实际故障与良性异常情况，比现有方法更准确、更早地预测故障。

Conclusion: 这项工作是实现更可解释和更安全的生成式机器人策略的重要一步。

Abstract: Imitation learning (IL) with generative models, such as diffusion and flow
matching, has enabled robots to perform complex, long-horizon tasks. However,
distribution shifts from unseen environments or compounding action errors can
still cause unpredictable and unsafe behavior, leading to task failure. Early
failure prediction during runtime is therefore essential for deploying robots
in human-centered and safety-critical environments. We propose FIPER, a general
framework for Failure Prediction at Runtime for generative IL policies that
does not require failure data. FIPER identifies two key indicators of impending
failure: (i) out-of-distribution (OOD) observations detected via random network
distillation in the policy's embedding space, and (ii) high uncertainty in
generated actions measured by a novel action-chunk entropy score. Both failure
prediction scores are calibrated using a small set of successful rollouts via
conformal prediction. A failure alarm is triggered when both indicators,
aggregated over short time windows, exceed their thresholds. We evaluate FIPER
across five simulation and real-world environments involving diverse failure
modes. Our results demonstrate that FIPER better distinguishes actual failures
from benign OOD situations and predicts failures more accurately and earlier
than existing methods. We thus consider this work an important step towards
more interpretable and safer generative robot policies. Code, data and videos
are available at https://tum-lsy.github.io/fiper_website.

</details>


### [27] [FOGMACHINE -- Leveraging Discrete-Event Simulation and Scene Graphs for Modeling Hierarchical, Interconnected Environments under Partial Observations from Mobile Agents](https://arxiv.org/abs/2510.09483)
*Lars Ohnemus,Nils Hantke,Max Weißer,Kai Furmans*

Main category: cs.RO

TL;DR: FOGMACHINE是一个开源框架，将动态场景图与离散事件模拟相结合，用于在不确定环境中建模对象动态、智能体观察和交互，支持多智能体行为研究和不确定性传播分析。


<details>
  <summary>Details</summary>
Motivation: 当前动态场景图方法难以捕捉随机动态、部分可观测性和多智能体活动，而这些对于具身AI在不确定性和延迟感知下行动至关重要。

Method: 将动态场景图与离散事件模拟融合，建模对象动态、智能体观察和交互，支持大规模不确定性传播和有限感知下的规划研究。

Result: 在城市场景实验中展示了真实的时间和空间模式，同时揭示了在稀疏观察下信念估计的挑战。

Conclusion: 通过结合结构化表示和高效模拟，FOGMACHINE为复杂不确定环境中的基准测试、模型训练和具身AI发展建立了有效工具。

Abstract: Dynamic Scene Graphs (DSGs) provide a structured representation of
hierarchical, interconnected environments, but current approaches struggle to
capture stochastic dynamics, partial observability, and multi-agent activity.
These aspects are critical for embodied AI, where agents must act under
uncertainty and delayed perception. We introduce FOGMACHINE , an open-source
framework that fuses DSGs with discrete-event simulation to model object
dynamics, agent observations, and interactions at scale. This setup enables the
study of uncertainty propagation, planning under limited perception, and
emergent multi-agent behavior. Experiments in urban scenarios illustrate
realistic temporal and spatial patterns while revealing the challenges of
belief estimation under sparse observations. By combining structured
representations with efficient simulation, FOGMACHINE establishes an effective
tool for benchmarking, model training, and advancing embodied AI in complex,
uncertain environments.

</details>


### [28] [Autonomous Soft Robotic Guidewire Navigation via Imitation Learning](https://arxiv.org/abs/2510.09497)
*Noah Barnes,Ji Woong Kim,Lingyun Di,Hannah Qu,Anuruddha Bhattacharjee,Miroslaw Janowski,Dheeraj Gandhi,Bailey Felix,Shaopeng Jiang,Olivia Young,Mark Fuge,Ryan D. Sochol,Jeremy D. Brown,Axel Krieger*

Main category: cs.RO

TL;DR: 开发基于Transformer的模仿学习框架，用于软体机器人导丝在血管内导航，在动脉瘤靶向任务中实现83%的成功率


<details>
  <summary>Details</summary>
Motivation: 解决软体机器人导丝在血管内导航中的建模和控制挑战，提高血管内导航的精度和安全性

Method: 使用基于Transformer的模仿学习框架，包含目标条件、相对动作输出和自动对比剂注射，在36种不同分叉几何结构上训练模型

Result: 在未见过的血管几何结构上，模型能够自主将机器人尖端导航至动脉瘤位置，成功率达到83%，优于多个基线方法

Conclusion: 该框架能够实现可泛化的软体机器人导丝导航，为血管内手术自动化提供了有前景的解决方案

Abstract: In endovascular surgery, endovascular interventionists push a thin tube
called a catheter, guided by a thin wire to a treatment site inside the
patient's blood vessels to treat various conditions such as blood clots,
aneurysms, and malformations. Guidewires with robotic tips can enhance
maneuverability, but they present challenges in modeling and control.
Automation of soft robotic guidewire navigation has the potential to overcome
these challenges, increasing the precision and safety of endovascular
navigation. In other surgical domains, end-to-end imitation learning has shown
promising results. Thus, we develop a transformer-based imitation learning
framework with goal conditioning, relative action outputs, and automatic
contrast dye injections to enable generalizable soft robotic guidewire
navigation in an aneurysm targeting task. We train the model on 36 different
modular bifurcated geometries, generating 647 total demonstrations under
simulated fluoroscopy, and evaluate it on three previously unseen vascular
geometries. The model can autonomously drive the tip of the robot to the
aneurysm location with a success rate of 83% on the unseen geometries,
outperforming several baselines. In addition, we present ablation and baseline
studies to evaluate the effectiveness of each design and data collection
choice. Project website: https://softrobotnavigation.github.io/

</details>


### [29] [Dynamic Quadrupedal Legged and Aerial Locomotion via Structure Repurposing](https://arxiv.org/abs/2510.09526)
*Chenghao Wang,Kaushik Venkatesh Krishnamurthy,Shreyansh Pitroda,Adarsh Salagame,Ioannis Mandralis,Eric Sihite,Alireza Ramezani,Morteza Gharib*

Main category: cs.RO

TL;DR: 本文介绍了Husky v.2多模态地面-空中机器人的硬件设计，该机器人通过结构复用实现了动态四足行走和悬停飞行功能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态机器人在不同操作模式下的需求冲突问题，特别是在地面移动和空中飞行之间的集成挑战。

Method: 采用结构复用技术，将腿部结构重新用于动态四足行走和飞行，结合姿态操纵和推力矢量控制。

Result: 成功实现了动态四足行走和悬停飞行的主要功能，验证了硬件设计的有效性。

Conclusion: Husky v.2机器人通过创新的结构复用方法，有效解决了多模态机器人的集成挑战，为地面-空中混合机器人提供了可行的解决方案。

Abstract: Multi-modal ground-aerial robots have been extensively studied, with a
significant challenge lying in the integration of conflicting requirements
across different modes of operation. The Husky robot family, developed at
Northeastern University, and specifically the Husky v.2 discussed in this
study, addresses this challenge by incorporating posture manipulation and
thrust vectoring into multi-modal locomotion through structure repurposing.
This quadrupedal robot features leg structures that can be repurposed for
dynamic legged locomotion and flight. In this paper, we present the hardware
design of the robot and report primary results on dynamic quadrupedal legged
locomotion and hovering.

</details>


### [30] [Guiding Energy-Efficient Locomotion through Impact Mitigation Rewards](https://arxiv.org/abs/2510.09543)
*Chenghao Wang,Arjun Viswanathan,Eric Sihite,Alireza Ramezani*

Main category: cs.RO

TL;DR: 该论文提出了一种结合冲击减缓因子(IMF)和对抗运动先验(AMP)的方法，使强化学习策略能够同时学习动物的显性运动轨迹和隐性被动动力学，实现了高达32%的能量效率提升。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法主要捕捉动物的显性步态模式，但忽略了其隐性的被动动力学特性，而动物正是通过这种被动动力学实现节能运动的。

Method: 将物理信息化的冲击减缓因子(IMF)作为奖励项整合到对抗运动先验(AMP)和强化学习框架中，使策略能够学习动物的被动动态特性。

Result: 在AMP和手工设计的奖励结构下，通过运输成本(CoT)测量，能量效率提升了高达32%。

Conclusion: 通过整合IMF指标，成功让强化学习策略同时学习动物的显性运动轨迹和隐性被动动力学，显著提升了机器人的能量效率。

Abstract: Animals achieve energy-efficient locomotion by their implicit passive
dynamics, a marvel that has captivated roboticists for decades.Recently,
methods incorporated Adversarial Motion Prior (AMP) and Reinforcement learning
(RL) shows promising progress to replicate Animals' naturalistic motion.
However, such imitation learning approaches predominantly capture explicit
kinematic patterns, so-called gaits, while overlooking the implicit passive
dynamics. This work bridges this gap by incorporating a reward term guided by
Impact Mitigation Factor (IMF), a physics-informed metric that quantifies a
robot's ability to passively mitigate impacts. By integrating IMF with AMP, our
approach enables RL policies to learn both explicit motion trajectories from
animal reference motion and the implicit passive dynamic. We demonstrate energy
efficiency improvements of up to 32%, as measured by the Cost of Transport
(CoT), across both AMP and handcrafted reward structure.

</details>


### [31] [Zero-shot Structure Learning and Planning for Autonomous Robot Navigation using Active Inference](https://arxiv.org/abs/2510.09574)
*Daria de tinguy,Tim Verbelen,Emilio Gamba,Bart Dhoedt*

Main category: cs.RO

TL;DR: AIMAPP是一个基于主动推理的生物启发导航框架，将建图、定位和决策统一在单一生成模型中，无需预定义地图或训练即可在陌生环境中实现自主导航。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在陌生环境中同时进行探索、定位和不确定性规划的问题，不依赖预定义地图或大量训练，实现完全自监督的导航。

Method: 采用主动推理框架，结合拓扑推理、位置细胞编码和情景记忆，在线构建稀疏拓扑地图，动态学习状态转移，通过最小化期望自由能量来规划动作。

Result: 在大型真实和模拟环境中表现出鲁棒性能，能够适应模糊观测、环境变化和传感器噪声，支持探索和目标导向导航。

Conclusion: AIMAPP提供了一个生物启发的模块化解决方案，可在非结构化环境中实现可扩展的自监督导航。

Abstract: Autonomous navigation in unfamiliar environments requires robots to
simultaneously explore, localise, and plan under uncertainty, without relying
on predefined maps or extensive training. We present a biologically inspired,
Active Inference-based framework, Active Inference MAPping and Planning
(AIMAPP). This model unifies mapping, localisation, and decision-making within
a single generative model. Inspired by hippocampal navigation, it uses
topological reasoning, place-cell encoding, and episodic memory to guide
behaviour. The agent builds and updates a sparse topological map online, learns
state transitions dynamically, and plans actions by minimising Expected Free
Energy. This allows it to balance goal-directed and exploratory behaviours. We
implemented a ROS-compatible navigation system that is sensor and
robot-agnostic, capable of integrating with diverse hardware configurations. It
operates in a fully self-supervised manner, is resilient to drift, and supports
both exploration and goal-directed navigation without any pre-training. We
demonstrate robust performance in large-scale real and simulated environments
against state-of-the-art planning models, highlighting the system's
adaptability to ambiguous observations, environmental changes, and sensor
noise. The model offers a biologically inspired, modular solution to scalable,
self-supervised navigation in unstructured settings. AIMAPP is available at
https://github.com/decide-ugent/AIMAPP.

</details>
