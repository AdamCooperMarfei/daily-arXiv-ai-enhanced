<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 48]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [ManipDreamer3D : Synthesizing Plausible Robotic Manipulation Video with Occupancy-aware 3D Trajectory](https://arxiv.org/abs/2509.05314)
*Ying Li,Xiaobao Wei,Xiaowei Chi,Yuming Li,Zhongyu Zhao,Hao Wang,Ningning Ma,Ming Lu,Shanghang Zhang*

Main category: cs.RO

TL;DR: ManipDreamer3D是一个从输入图像和文本指令生成3D感知机器人操作视频的新框架，通过3D轨迹规划和轨迹到视频扩散模型解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 机器人操作领域面临数据稀缺问题，现有基于2D轨迹的方法存在3D空间模糊性问题，需要开发能够生成合理3D感知操作视频的方法。

Method: 首先从输入图像重建3D占用表示，然后计算优化的3D末端执行器轨迹（最小化路径长度并避免碰撞），最后使用潜在编辑技术和专门训练的轨迹到视频扩散模型生成视频序列。

Result: 实验结果表明，与现有方法相比，该方法在视觉质量上表现优越，能够生成具有自主规划合理3D轨迹的机器人视频。

Conclusion: ManipDreamer3D框架能够显著减少人工干预需求，为机器人操作视频生成提供了有效的3D感知解决方案。

Abstract: Data scarcity continues to be a major challenge in the field of robotic
manipulation. Although diffusion models provide a promising solution for
generating robotic manipulation videos, existing methods largely depend on 2D
trajectories, which inherently face issues with 3D spatial ambiguity. In this
work, we present a novel framework named ManipDreamer3D for generating
plausible 3D-aware robotic manipulation videos from the input image and the
text instruction. Our method combines 3D trajectory planning with a
reconstructed 3D occupancy map created from a third-person perspective, along
with a novel trajectory-to-video diffusion model. Specifically, ManipDreamer3D
first reconstructs the 3D occupancy representation from the input image and
then computes an optimized 3D end-effector trajectory, minimizing path length
while avoiding collisions. Next, we employ a latent editing technique to create
video sequences from the initial image latent and the optimized 3D trajectory.
This process conditions our specially trained trajectory-to-video diffusion
model to produce robotic pick-and-place videos. Our method generates robotic
videos with autonomously planned plausible 3D trajectories, significantly
reducing human intervention requirements. Experimental results demonstrate
superior visual quality compared to existing methods.

</details>


### [2] [Evaluation of Large Language Models for Anomaly Detection in Autonomous Vehicles](https://arxiv.org/abs/2509.05315)
*Petros Loukas,David Bassir,Savvas Chatzichristofis,Angelos Amanatiadis*

Main category: cs.RO

TL;DR: 这篇论文评估了大语言模型在自主驾驶汽车实际边界案例中的异常检测能力，通过结合开放词汇物体检测器和prompt工程来处理真实世界的极端情况。


<details>
  <summary>Details</summary>
Motivation: 当前研究对LLM在自主驾驶中的评估主要限于合成数据集或手动驾驶数据，缺乏真实边界案例的验证，需要在现有自主驾驶系统失效的真实场景中评估LLM的潜力。

Method: 提出了一种结构，组合使用开放词汇物体检测器、prompt工程技术和大语言模型的上下文推理能力来处理自主驾驶的真实边界案例。

Result: 在多个最新的独立模型上进行了评测，并提供了定性的对比结果，讨论了LLM在自主驾驶中作为异常检测器的潜在应用。

Conclusion: 论文证明了LLM在自主驾驶实际边界案例中的异常检测能力，为将LLM集成到自主驾驶感知和规划栈中作为补充模块提供了实证支持。

Abstract: The rapid evolution of large language models (LLMs) has pushed their
boundaries to many applications in various domains. Recently, the research
community has started to evaluate their potential adoption in autonomous
vehicles and especially as complementary modules in the perception and planning
software stacks. However, their evaluation is limited in synthetic datasets or
manually driving datasets without the ground truth knowledge and more
precisely, how the current perception and planning algorithms would perform in
the cases under evaluation. For this reason, this work evaluates LLMs on
real-world edge cases where current autonomous vehicles have been proven to
fail. The proposed architecture consists of an open vocabulary object detector
coupled with prompt engineering and large language model contextual reasoning.
We evaluate several state-of-the-art models against real edge cases and provide
qualitative comparison results along with a discussion on the findings for the
potential application of LLMs as anomaly detectors in autonomous vehicles.

</details>


### [3] [Plantbot: Integrating Plant and Robot through LLM Modular Agent Networks](https://arxiv.org/abs/2509.05338)
*Atsushi Masumori,Norihiro Maruyama,Itsuki Doi,johnsmith,Hiroki Sato,Takashi Ikegami*

Main category: cs.RO

TL;DR: Plantbot是一个将植物与移动机器人通过LLM模块网络连接的混合生命体，利用自然语言作为通用协议实现生物与人工系统的无缝交互


<details>
  <summary>Details</summary>
Motivation: 探索利用大语言模型作为混合接口，通过自然语言协议连接生物和人工系统，创造新型人工生命形式

Method: 采用异步运行的LLM模块网络（感知、视觉、对话、行动模块），通过自然语言通信将多模态数据转换为协调系统行为的语言消息

Result: 成功实现了植物状态到机器人动作的转换，在感知-运动循环中建立了规范性，使系统成为能够自主响应环境条件的具身自适应智能体

Conclusion: 这种去中心化的LLM模块协调方法为生物与人工系统之间的新型交互提供了可能，开创了新的人工生命模型

Abstract: We introduce Plantbot, a hybrid lifeform that connects a living plant with a
mobile robot through a network of large language model (LLM) modules. Each
module - responsible for sensing, vision, dialogue, or action - operates
asynchronously and communicates via natural language, enabling seamless
interaction across biological and artificial domains. This architecture
leverages the capacity of LLMs to serve as hybrid interfaces, where natural
language functions as a universal protocol, translating multimodal data (soil
moisture, temperature, visual context) into linguistic messages that coordinate
system behaviors. The integrated network transforms plant states into robotic
actions, installing normativity essential for agency within the sensor-motor
loop. By combining biological and robotic elements through LLM-mediated
communication, Plantbot behaves as an embodied, adaptive agent capable of
responding autonomously to environmental conditions. This approach suggests
possibilities for a new model of artificial life, where decentralized, LLM
modules coordination enable novel interactions between biological and
artificial systems.

</details>


### [4] [INF-3DP: Implicit Neural Fields for Collision-Free Multi-Axis 3D Printing](https://arxiv.org/abs/2509.05345)
*Jiasheng Qu,Zhuo Huang,Dezhao Guo,Hailin Sun,Aoran Lyu,Chengkai Dai,Yeung Yam,Guoxin Fang*

Main category: cs.RO

TL;DR: 基于隐式神经场的多轴3D打印统一框架，通过隐式场优化实现工具路径生成和碰撞检测，比显式方法快两个数量级


<details>
  <summary>Details</summary>
Motivation: 传统多轴3D打印方法在工具路径生成和运动规划阶段分离，缺乏统一的优化框架，难以处理复杂几何形状和碰撞检测

Method: 使用隐式神经场表示输入模型，将制造目标编码到隐式引导场优化中，通过连续四元数场联合优化打印序列和多轴运动，构建时变SDF支持可微全局碰撞处理

Result: 相比基于显式表示的方法，速度提升两个数量级，显著降低路径点到表面误差，在复杂模型上验证有效并通过物理实验证明效率

Conclusion: 隐式神经场为多轴3D打印提供了统一、可扩展的计算框架，实现了工具路径生成和运动规划的端到端优化，具有显著性能优势

Abstract: We introduce a general, scalable computational framework for multi-axis 3D
printing based on implicit neural fields (INFs) that unifies all stages of
toolpath generation and global collision-free motion planning. In our pipeline,
input models are represented as signed distance fields, with fabrication
objectives such as support-free printing, surface finish quality, and extrusion
control being directly encoded in the optimization of an implicit guidance
field. This unified approach enables toolpath optimization across both surface
and interior domains, allowing shell and infill paths to be generated via
implicit field interpolation. The printing sequence and multi-axis motion are
then jointly optimized over a continuous quaternion field. Our continuous
formulation constructs the evolving printing object as a time-varying SDF,
supporting differentiable global collision handling throughout INF-based motion
planning. Compared to explicit-representation-based methods, INF-3DP achieves
up to two orders of magnitude speedup and significantly reduces
waypoint-to-surface error. We validate our framework on diverse, complex models
and demonstrate its efficiency with physical fabrication experiments using a
robot-assisted multi-axis system.

</details>


### [5] [Human-LLM Synergy in Context-Aware Adaptive Architecture for Scalable Drone Swarm Operation](https://arxiv.org/abs/2509.05355)
*Ahmed R. Sadik,Muhammad Ashfaq,Niko Mäkitalo,Tommi Mikkonen*

Main category: cs.RO

TL;DR: 提出基于大语言模型的自适应无人机集群架构，能够根据任务复杂度、集群规模和通信稳定性等实时参数动态选择最优架构（集中式、分层式或整体式），在灾难响应任务中显著提升可扩展性、能源效率和连接性。


<details>
  <summary>Details</summary>
Motivation: 传统固定架构的无人机集群在动态不可预测的灾难响应环境中存在能源消耗和连接效率低下的问题，需要开发灵活、可扩展且鲁棒的协调系统。

Method: 利用大语言模型动态选择最优架构（集中式、分层式或整体式），基于实时任务参数如任务复杂度、集群规模和通信稳定性进行自适应调整。

Result: 大量仿真实验表明，该自适应架构在可扩展性、能源效率和连接性方面均优于传统静态模型。

Conclusion: 该方法为现实世界灾难响应场景提供了可扩展、自适应且具有弹性的解决方案，展现了在实际应用中的巨大潜力。

Abstract: The deployment of autonomous drone swarms in disaster response missions
necessitates the development of flexible, scalable, and robust coordination
systems. Traditional fixed architectures struggle to cope with dynamic and
unpredictable environments, leading to inefficiencies in energy consumption and
connectivity. This paper addresses this gap by proposing an adaptive
architecture for drone swarms, leveraging a Large Language Model to dynamically
select the optimal architecture as centralized, hierarchical, or holonic based
on real time mission parameters such as task complexity, swarm size, and
communication stability. Our system addresses the challenges of scalability,
adaptability, and robustness,ensuring efficient energy consumption and
maintaining connectivity under varying conditions. Extensive simulations
demonstrate that our adaptive architecture outperforms traditional static
models in terms of scalability, energy efficiency, and connectivity. These
results highlight the potential of our approach to provide a scalable,
adaptable, and resilient solution for real world disaster response scenarios.

</details>


### [6] [Spiking Neural Networks for Continuous Control via End-to-End Model-Based Learning](https://arxiv.org/abs/2509.05356)
*Justus Huebotter,Pablo Lanillos,Marcel van Gerven,Serge Thill*

Main category: cs.RO

TL;DR: 该论文展示了完全脉冲神经网络(SNN)可以通过端到端训练来控制多自由度机械臂的连续运动，结合了泄漏积分发放动力学和替代梯度方法，在2D平面到达任务和6自由度机器人仿真中实现了稳定的扭矩控制。


<details>
  <summary>Details</summary>
Motivation: 尽管脉冲神经网络在分类任务上取得了进展，但在连续运动控制领域的应用仍然有限，需要探索SNN在高维连续控制任务中的可行性。

Method: 使用预测控制框架，结合泄漏积分发放(LIF)动力学和替代梯度，联合优化用于动力学预测的前向模型和用于目标导向动作的策略网络。

Result: SNN能够实现稳定训练和精确的扭矩控制，在2D平面到达任务和6自由度Franka Emika Panda机器人仿真中证明了其在高维运动任务中的可行性。

Conclusion: 虽然可以实现稳定有效的控制，但循环脉冲神经网络对超参数设置高度敏感，强调了原则性设计选择的重要性。

Abstract: Despite recent progress in training spiking neural networks (SNNs) for
classification, their application to continuous motor control remains limited.
Here, we demonstrate that fully spiking architectures can be trained end-to-end
to control robotic arms with multiple degrees of freedom in continuous
environments. Our predictive-control framework combines Leaky
Integrate-and-Fire dynamics with surrogate gradients, jointly optimizing a
forward model for dynamics prediction and a policy network for goal-directed
action. We evaluate this approach on both a planar 2D reaching task and a
simulated 6-DOF Franka Emika Panda robot. Results show that SNNs can achieve
stable training and accurate torque control, establishing their viability for
high-dimensional motor tasks. An extensive ablation study highlights the role
of initialization, learnable time constants, and regularization in shaping
training dynamics. We conclude that while stable and effective control can be
achieved, recurrent spiking networks remain highly sensitive to hyperparameter
settings, underscoring the importance of principled design choices.

</details>


### [7] [Long-Horizon Visual Imitation Learning via Plan and Code Reflection](https://arxiv.org/abs/2509.05368)
*Quan Chen,Chenrui Shi,Qi Chen,Yuwei Wu,Zhi Gao,Xintong Zhang,Rui Gao,Kun Wu,Yunde Jia*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Learning from long-horizon demonstrations with complex action sequences
presents significant challenges for visual imitation learning, particularly in
understanding temporal relationships of actions and spatial relationships
between objects. In this paper, we propose a new agent framework that
incorporates two dedicated reflection modules to enhance both plan and code
generation. The plan generation module produces an initial action sequence,
which is then verified by the plan reflection module to ensure temporal
coherence and spatial alignment with the demonstration video. The code
generation module translates the plan into executable code, while the code
reflection module verifies and refines the generated code to ensure correctness
and consistency with the generated plan. These two reflection modules jointly
enable the agent to detect and correct errors in both the plan generation and
code generation, improving performance in tasks with intricate temporal and
spatial dependencies. To support systematic evaluation, we introduce
LongVILBench, a benchmark comprising 300 human demonstrations with action
sequences of up to 18 steps. LongVILBench emphasizes temporal and spatial
complexity across multiple task types. Experimental results demonstrate that
existing methods perform poorly on this benchmark, whereas our new framework
establishes a strong baseline for long-horizon visual imitation learning.

</details>


### [8] [Evaluating Magic Leap 2 Tool Tracking for AR Sensor Guidance in Industrial Inspections](https://arxiv.org/abs/2509.05391)
*Christian Masuhr,Julian Koch,Thorsten Schüppstuhl*

Main category: cs.RO

TL;DR: 通过机器手和光学追踪系统对Magic Leap 2控制器进行系统性追躊性能评估，为工业应用提供量化基准


<details>
  <summary>Details</summary>
Motivation: 商用AR硬件缺乏公开的工具追踪性能基准测试，需要系统性评估现代头显设备的追踪性能

Method: 使用机器手进行可重复运动(EN ISO 9283)，采用光学追踪系统作为真实值，在各种条件下评估静态和动态性能，包括氢气漏洒检查应用场景的实际路径

Result: 获得了ML2控制器准确性和可重复性的量化基准，并提供了稳健、可转移的评估方法

Conclusion: 研究结果为评估控制器在检查应用场景和类似工业传感器基AR导航任务中的适用性提供了基础

Abstract: Rigorous evaluation of commercial Augmented Reality (AR) hardware is crucial,
yet public benchmarks for tool tracking on modern Head-Mounted Displays (HMDs)
are limited. This paper addresses this gap by systematically assessing the
Magic Leap 2 (ML2) controllers tracking performance. Using a robotic arm for
repeatable motion (EN ISO 9283) and an optical tracking system as ground truth,
our protocol evaluates static and dynamic performance under various conditions,
including realistic paths from a hydrogen leak inspection use case. The results
provide a quantitative baseline of the ML2 controller's accuracy and
repeatability and present a robust, transferable evaluation methodology. The
findings provide a basis to assess the controllers suitability for the
inspection use case and similar industrial sensor-based AR guidance tasks.

</details>


### [9] [RoboBallet: Planning for Multi-Robot Reaching with Graph Neural Networks and Reinforcement Learning](https://arxiv.org/abs/2509.05397)
*Matthew Lai,Keegan Go,Zhibin Li,Torsten Kroger,Stefan Schaal,Kelsey Allen,Jonathan Scholz*

Main category: cs.RO

TL;DR: 使用图神经网络和强化学习的多机器人任务与运动规划框架，能够在障碍物丰富的共享工作区中高效协调多个机器人完成任务


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统在障碍物丰富的共享工作区中进行任务分配、排程和运动规划的计算复杂性问题，提高自动化水平

Method: 使用图神经网络(GNN)政策，通过强化学习在程序生成的多样化环境中训练，采用场景图表征和图政策网络来生成多机器人轨迹

Result: 在8台机器人执行40个到达任务的环境中，政策能够零样本法通用到未见的机器位置、障碍物形状和任务位置，具有高速度和可扩展性

Conclusion: 该方法为多机器人协同规划提供了高效解决方案，支持工作单元布局优化、故障容锐规划和在线重新规划等新功能

Abstract: Modern robotic manufacturing requires collision-free coordination of multiple
robots to complete numerous tasks in shared, obstacle-rich workspaces. Although
individual tasks may be simple in isolation, automated joint task allocation,
scheduling, and motion planning under spatio-temporal constraints remain
computationally intractable for classical methods at real-world scales.
Existing multi-arm systems deployed in the industry rely on human intuition and
experience to design feasible trajectories manually in a labor-intensive
process. To address this challenge, we propose a reinforcement learning (RL)
framework to achieve automated task and motion planning, tested in an
obstacle-rich environment with eight robots performing 40 reaching tasks in a
shared workspace, where any robot can perform any task in any order. Our
approach builds on a graph neural network (GNN) policy trained via RL on
procedurally-generated environments with diverse obstacle layouts, robot
configurations, and task distributions. It employs a graph representation of
scenes and a graph policy neural network trained through reinforcement learning
to generate trajectories of multiple robots, jointly solving the sub-problems
of task allocation, scheduling, and motion planning. Trained on large randomly
generated task sets in simulation, our policy generalizes zero-shot to unseen
settings with varying robot placements, obstacle geometries, and task poses. We
further demonstrate that the high-speed capability of our solution enables its
use in workcell layout optimization, improving solution times. The speed and
scalability of our planner also open the door to new capabilities such as
fault-tolerant planning and online perception-based re-planning, where rapid
adaptation to dynamic task sets is required.

</details>


### [10] [HapMorph: A Pneumatic Framework for Multi-Dimensional Haptic Property Rendering](https://arxiv.org/abs/2509.05433)
*Rui Chen,Domenico Chiaradia,Antonio Frisoli,Daniele Leonardis*

Main category: cs.RO

TL;DR: HapMorph是一个基于气动原理的触觉接口系统，通过对抗性织物气动执行器同时调节物体尺寸和刚度，实现了在可穿戴设备中同时控制几何特征和机械性能


<details>
  <summary>Details</summary>
Motivation: 现有触觉接口系统通常只能渲染几何特征或机械性能中的一种，难以在可穿戴设备中同时实现多种物理属性的调制，这限制了触觉交互的真实感和多样性

Method: 采用对抗性织物气动执行器(AFPAs)的气动框架，通过双腔压力调节实现尺寸和刚度的解耦控制，系统包括尺寸从50到104mm可调、刚度最高达4.7N/mm的可穿戴原型

Result: 系统测试显示用户能够以89.4%的准确率区分9个离散状态(3种尺寸类别和3种刚度级别)，平均响应时间为6.7秒。进一步展示了结合补充气动结构的扩展架构

Conclusion: 对抗性气动原理为下一代触觉接口提供了可行路径，能够在实际可穿戴约束下实现多维渲染特性，为更真实的触觉交互体验奠定了基础

Abstract: Haptic interfaces that can simultaneously modulate multiple physical
properties remain a fundamental challenge in human-robot interaction. Existing
systems typically allow the rendering of either geometric features or
mechanical properties, but rarely both, within wearable form factors. Here, we
introduce HapMorph, a pneumatic framework that enables continuous, simultaneous
modulation of object size and stiffness through antagonistic fabric-based
pneumatic actuators (AFPAs). We implemented a HapMorph protoytpe designed for
hands interaction achieving size variation from 50 to 104 mm, stiffness
modulation up to 4.7 N/mm and mass of the wearable parts of just 21 g. Through
systematic characterization, we demonstrate decoupled control of size and
stiffness properties via dual-chamber pressure regulation. Human perception
studies with 10 participants reveal that users can distinguish nine discrete
states across three size categories and three stiffness levels with 89.4%
accuracy and 6.7 s average response time. We further demonstrate extended
architectures that combine AFPAs with complementary pneumatic structures to
enable shape or geometry morphing with concurrent stiffness control. Our
results establish antagonistic pneumatic principle as a pathway toward
next-generation haptic interfaces, capable of multi-dimensiona rendering
properties within practical wearable constraints.

</details>


### [11] [Learning Tool-Aware Adaptive Compliant Control for Autonomous Regolith Excavation](https://arxiv.org/abs/2509.05475)
*Andrej Orsula,Matthieu Geist,Miguel Olivares-Mendez,Carol Martinez*

Main category: cs.RO

TL;DR: 提出基于模型强化学习框架，通过并行化模拟学习自适应交互策略，用于月球土壤自主挖掘任务，解决了颗粒介质复杂交互和多样化工具使用的挑战。


<details>
  <summary>Details</summary>
Motivation: 自主月球土壤挖掘是太空资源利用的关键，但面临颗粒介质复杂动力学和机器人需要使用多样化工具的挑战，需要开发能够适应不同地形和工具几何形状的鲁棒系统。

Method: 使用基于模型的强化学习代理在并行化模拟环境中训练，模拟环境采用高保真粒子物理和程序化生成技术，创建多样化的月球地形和挖掘工具几何形状。代理通过操作空间控制动态调节刚度和阻尼来学习自适应交互策略。

Result: 实验表明，使用程序化生成工具分布进行训练对泛化能力至关重要，能够开发出复杂的工具感知行为。视觉反馈的加入显著提高了任务成功率。

Conclusion: 该方法为未来太空任务所需的鲁棒和多功能自主系统开发提供了验证有效的方法论，能够处理月球土壤挖掘中的复杂交互和工具多样性问题。

Abstract: Autonomous regolith excavation is a cornerstone of in-situ resource
utilization for a sustained human presence beyond Earth. However, this task is
fundamentally hindered by the complex interaction dynamics of granular media
and the operational need for robots to use diverse tools. To address these
challenges, this work introduces a framework where a model-based reinforcement
learning agent learns within a parallelized simulation. This environment
leverages high-fidelity particle physics and procedural generation to create a
vast distribution of both lunar terrains and excavation tool geometries. To
master this diversity, the agent learns an adaptive interaction strategy by
dynamically modulating its own stiffness and damping at each control step
through operational space control. Our experiments demonstrate that training
with a procedural distribution of tools is critical for generalization and
enables the development of sophisticated tool-aware behavior. Furthermore, we
show that augmenting the agent with visual feedback significantly improves task
success. These results represent a validated methodology for developing the
robust and versatile autonomous systems required for the foundational tasks of
future space missions.

</details>


### [12] [Microrobot Vascular Parkour: Analytic Geometry-based Path Planning with Real-time Dynamic Obstacle Avoidance](https://arxiv.org/abs/2509.05500)
*Yanda Yang,Max Sokolich,Fatma Ceren Kirmizitas,Sambeeta Das,Andreas A. Malikopoulos*

Main category: cs.RO

TL;DR: 基于分析几何全局规划器(AGP)与反应式局部控制器的实时路径规划框架，用于血管环境中微米机器人的自主导航和移动障碍避免。


<details>
  <summary>Details</summary>
Motivation: 血管中的微米机器人导航面临密集、移动障碍的挑战，需要实时的路径规划来支持微创疗法。

Method: 结合分析几何全局规划器(AGP)与两种反应式局部控制器（规则基础和强化学习基础），利用实时成像估计微米机器人、障碍和目标位置，计算无碰撞运动。

Result: 模拟显示AGP比WA*、PSO和RRT路径更短、规划更快，保持可行性和确定性。从2D扩展到3D时速度不变。平均规划时间40ms，与25fps实时控制相兼容。

Conclusion: 该框架可靠地避免移动障碍并到达目标，推进了血管环境中微米机器人自主导航和目标药物递送的发展。

Abstract: Autonomous microrobots in blood vessels could enable minimally invasive
therapies, but navigation is challenged by dense, moving obstacles. We propose
a real-time path planning framework that couples an analytic geometry global
planner (AGP) with two reactive local escape controllers, one based on rules
and one based on reinforcement learning, to handle sudden moving obstacles.
Using real-time imaging, the system estimates the positions of the microrobot,
obstacles, and targets and computes collision-free motions. In simulation, AGP
yields shorter paths and faster planning than weighted A* (WA*), particle swarm
optimization (PSO), and rapidly exploring random trees (RRT), while maintaining
feasibility and determinism. We extend AGP from 2D to 3D without loss of speed.
In both simulations and experiments, the combined global planner and local
controllers reliably avoid moving obstacles and reach targets. The average
planning time is 40 ms per frame, compatible with 25 fps image acquisition and
real-time closed-loop control. These results advance autonomous microrobot
navigation and targeted drug delivery in vascular environments.

</details>


### [13] [TeleopLab: Accessible and Intuitive Teleoperation of a Robotic Manipulator for Remote Labs](https://arxiv.org/abs/2509.05547)
*Ziling Chen,Yeo Jung Yoon,Rolando Bautista-Montesano,Zhen Zhao,Ajay Mandlekar,John Liu*

Main category: cs.RO

TL;DR: TeleopLab是一个基于移动设备的远程操作系统，通过机械臂和自适应夹具让学生远程操作实验设备，显著提升远程STEM教育的实践体验


<details>
  <summary>Details</summary>
Motivation: 解决远程教育中实践操作成本高、体验不直观的问题，为需要操作真实设备的STEM教育提供可扩展的远程实验解决方案

Method: 开发包含机械臂、自适应夹具、摄像头、实验设备和智能手机用户界面的完整系统，通过用户研究评估任务性能、用户体验、可用性和工作负荷

Result: 用户熟悉系统后任务完成时间减少46.1%，NASA TLX工作负荷评分38.2（可管理），SUS可用性评分73.8（良好），学生使用后对系统的看法明显改善

Conclusion: TeleopLab成功弥合了实体实验室与远程教育之间的差距，为远程STEM学习提供了可扩展且有效的平台

Abstract: Teleoperation offers a promising solution for enabling hands-on learning in
remote education, particularly in environments requiring interaction with
real-world equipment. However, such remote experiences can be costly or
non-intuitive. To address these challenges, we present TeleopLab, a mobile
device teleoperation system that allows students to control a robotic arm and
operate lab equipment. TeleopLab comprises a robotic arm, an adaptive gripper,
cameras, lab equipment for a diverse range of applications, a user interface
accessible through smartphones, and video call software. We conducted a user
study, focusing on task performance, students' perspectives toward the system,
usability, and workload assessment. Our results demonstrate a 46.1% reduction
in task completion time as users gained familiarity with the system.
Quantitative feedback highlighted improvements in students' perspectives after
using the system, while NASA TLX and SUS assessments indicated a manageable
workload of 38.2 and a positive usability of 73.8. TeleopLab successfully
bridges the gap between physical labs and remote education, offering a scalable
and effective platform for remote STEM learning.

</details>


### [14] [Learning to Walk in Costume: Adversarial Motion Priors for Aesthetically Constrained Humanoids](https://arxiv.org/abs/2509.05581)
*Arturo Flores Alvarez,Fatemeh Zargarbashi,Havel Liu,Shiqi Wang,Liam Edwards,Jessica Anz,Alex Xu,Fan Shi,Stelian Coros,Dennis W. Hong*

Main category: cs.RO

TL;DR: 使用强化学习和对抗运动先验为娱乐人形机器人Cosmo学习自然稳定的立竞和行走行为，充分考虑了其特殊的美学设计约束


<details>
  <summary>Details</summary>
Motivation: 娱乐人形机器人具有特殊的美学设计约束（大头部、有限感知、运动限制），传统控制方法难以处理这些挑战

Method: 采用对抗运动先验(AMP)算法，结合专门设计的域随机化技术和奖励结构，确保从模拟到实际的安全过渡

Result: AMP能够在Cosmo极端质量分布和运动限制下生成稳定的站立和行走行为

Conclusion: 学习基于方法能够有效适应美学驱动的设计约束，为美观与功能平衡的机器人开启了有前景的方向

Abstract: We present a Reinforcement Learning (RL)-based locomotion system for Cosmo, a
custom-built humanoid robot designed for entertainment applications. Unlike
traditional humanoids, entertainment robots present unique challenges due to
aesthetic-driven design choices. Cosmo embodies these with a disproportionately
large head (16% of total mass), limited sensing, and protective shells that
considerably restrict movement. To address these challenges, we apply
Adversarial Motion Priors (AMP) to enable the robot to learn natural-looking
movements while maintaining physical stability. We develop tailored domain
randomization techniques and specialized reward structures to ensure safe
sim-to-real, protecting valuable hardware components during deployment. Our
experiments demonstrate that AMP generates stable standing and walking
behaviors despite Cosmo's extreme mass distribution and movement constraints.
These results establish a promising direction for robots that balance aesthetic
appeal with functional performance, suggesting that learning-based methods can
effectively adapt to aesthetic-driven design constraints.

</details>


### [15] [MonoGlass3D: Monocular 3D Glass Detection with Plane Regression and Adaptive Feature Fusion](https://arxiv.org/abs/2509.05599)
*Kai Zhang,Guoyang Zhao,Jianxing Shi,Bonan Liu,Weiqing Qi,Jun Ma*

Main category: cs.RO

TL;DR: 提出了MonoGlass3D方法用于单目3D玻璃检测，并发布了包含精确3D标注的玻璃数据集，通过自适应特征融合和平面回归管道在玻璃分割和深度估计方面达到最先进性能


<details>
  <summary>Details</summary>
Motivation: 玻璃的光学特性使传统传感器难以准确检测玻璃表面，且缺乏真实世界的玻璃数据集阻碍了该领域的发展

Method: 提出自适应特征融合模块捕捉不同条件下的上下文信息，以及平面回归管道利用玻璃表面的平面几何特性

Result: 在玻璃分割和单目玻璃深度估计方面优于现有最先进方法

Conclusion: 结合几何和上下文线索对于透明表面理解具有显著优势

Abstract: Detecting and localizing glass in 3D environments poses significant
challenges for visual perception systems, as the optical properties of glass
often hinder conventional sensors from accurately distinguishing glass
surfaces. The lack of real-world datasets focused on glass objects further
impedes progress in this field. To address this issue, we introduce a new
dataset featuring a wide range of glass configurations with precise 3D
annotations, collected from distinct real-world scenarios. On the basis of this
dataset, we propose MonoGlass3D, a novel approach tailored for monocular 3D
glass detection across diverse environments. To overcome the challenges posed
by the ambiguous appearance and context diversity of glass, we propose an
adaptive feature fusion module that empowers the network to effectively capture
contextual information in varying conditions. Additionally, to exploit the
distinct planar geometry of glass surfaces, we present a plane regression
pipeline, which enables seamless integration of geometric properties within our
framework. Extensive experiments demonstrate that our method outperforms
state-of-the-art approaches in both glass segmentation and monocular glass
depth estimation. Our results highlight the advantages of combining geometric
and contextual cues for transparent surface understanding.

</details>


### [16] [Sharing but Not Caring: Similar Outcomes for Shared Control and Switching Control in Telepresence-Robot Navigation](https://arxiv.org/abs/2509.05672)
*Juho Kalliokoski,Evan G. Center,Steven M. LaValle,Timo Ojala,Basak Sakcak*

Main category: cs.RO

TL;DR: 共享控制方法在远程机器人导航中保持效率但未显著降低用户工作负荷


<details>
  <summary>Details</summary>
Motivation: 远程临场机器人导航效率低且不够直观，需要开发更有效的控制方法

Method: 开发并评估共享控制方法（机器人自主导航同时允许用户影响路径生成），并与控制切换方法（用户在直接控制和自动控制间切换）进行比较

Result: 共享控制不会降低导航效率，但相比控制切换方法未能显著减少用户任务负荷

Conclusion: 需要进一步研究影响用户偏好和性能的潜在因素

Abstract: Telepresence robots enable users to interact with remote environments, but
efficient and intuitive navigation remains a challenge. In this work, we
developed and evaluated a shared control method, in which the robot navigates
autonomously while allowing users to affect the path generation to better suit
their needs. We compared this with control switching, where users toggle
between direct and automated control. We hypothesized that shared control would
maintain efficiency comparable to control switching while potentially reducing
user workload. The results of two consecutive user studies (each with final
sample of n=20) showed that shared control does not degrade navigation
efficiency, but did not show a significant reduction in task load compared to
control switching. Further research is needed to explore the underlying factors
that influence user preference and performance in these control systems.

</details>


### [17] [A*-PRM: A Dynamic Weight-Based Probabilistic Roadmap Algorithm](https://arxiv.org/abs/2509.05701)
*Siyuan Wang,Shuyi Zhang,Zhen Tian,Yuheng Yao,Gongsen Wang,Yu Zhao*

Main category: cs.RO

TL;DR: 提出了一种融合A*算法和PRM的混合路径规划算法A-star PRM，通过动态权重和分层采样策略，在路径质量和计算效率之间取得平衡


<details>
  <summary>Details</summary>
Motivation: 提高自主导航系统的环境适应性，解决复杂障碍物分布下的路径规划问题

Method: 将A*算法的曼哈顿距离启发式嵌入PRM的随机采样过程，采用分层采样策略和动态连接机制

Result: 在1000个采样点配置下，路径长度比PRM缩短42.3%；在3000个高密度采样下，路径长度减少0.94%，计算时间增加仅为PRM的1/10

Conclusion: A-star PRM在路径质量、稳定性和计算效率方面具有综合优势，特别适用于狭窄通道和动态障碍物场景

Abstract: Robot path planning is a fundamental challenge in enhancing the environmental
adaptability of autonomous navigation systems. This paper presents a hybrid
path planning algorithm, A-star PRM, which incorporates dynamic weights. By
embedding the Manhattan distance heuristic of the A-star algorithm into the
random sampling process of PRM, the algorithm achieves a balanced optimization
of path quality and computational efficiency. The approach uses a hierarchical
sampling strategy and a dynamic connection mechanism, greatly improving
adaptability to complex obstacle distributions. Experiments show that under a
baseline configuration with one thousand sampled vertices, the path length of
A-star PRM is 1073.23 plus or minus 14.8 meters and is 42.3 percent shorter
than that of PRM with p value less than 0.01. With high-density sampling using
three thousand vertices, the path length is reduced by 0.94 percent, 1036.61
meters compared with 1046.42 meters, while the increase in computational time
is cut to about one tenth of the PRM increase, 71 percent compared with 785
percent. These results confirm the comprehensive advantages of A-star PRM in
path quality, stability, and computational efficiency. Compared with existing
hybrid algorithms, the proposed method shows clear benefits, especially in
narrow channels and scenarios with dynamic obstacles.

</details>


### [18] [Super-LIO: A Robust and Efficient LiDAR-Inertial Odometry System with a Compact Mapping Strategy](https://arxiv.org/abs/2509.05723)
*Liansheng Wang,Xinke Zhang,Chenhui Li,Dongjiao He,Yihan Pan,Jianjun Yi*

Main category: cs.RO

TL;DR: Super-LIO是一个高效的LiDAR-惯性里程计系统，通过紧凑的八叉体素地图结构(OctVox)和启发式KNN策略(HKNN)，在保持精度的同时显著提升处理速度，比现有技术快73%，适用于资源受限平台。


<details>
  <summary>Details</summary>
Motivation: 解决LiDAR-惯性里程计在资源受限平台部署时的计算和内存限制问题，为无人机和移动自主系统提供高性能、高精度的定位解决方案。

Method: 采用紧凑的八叉体素地图结构(OctVox)限制每个体素最多8个子体素，实现严格点密度控制和增量去噪；设计启发式引导的KNN策略(HKNN)利用空间局部性加速对应点搜索。

Result: 在4个公开数据集和多个自采集数据集（共30+序列）上测试，在X86和ARM平台上均表现出优越的效率和鲁棒性，处理速度比SOTA快73%，CPU资源消耗更低。

Conclusion: Super-LIO提供了一个高效、准确且易于集成的LIO系统，完全开源且即插即用兼容多种LiDAR传感器和平台，适用于资源受限的自主系统应用。

Abstract: LiDAR-Inertial Odometry (LIO) is a foundational technique for autonomous
systems, yet its deployment on resource-constrained platforms remains
challenging due to computational and memory limitations. We propose Super-LIO,
a robust LIO system that demands both high performance and accuracy, ideal for
applications such as aerial robots and mobile autonomous systems. At the core
of Super-LIO is a compact octo-voxel-based map structure, termed OctVox, that
limits each voxel to eight fused subvoxels, enabling strict point density
control and incremental denoising during map updates. This design enables a
simple yet efficient and accurate map structure, which can be easily integrated
into existing LIO frameworks. Additionally, Super-LIO designs a
heuristic-guided KNN strategy (HKNN) that accelerates the correspondence search
by leveraging spatial locality, further reducing runtime overhead. We evaluated
the proposed system using four publicly available datasets and several
self-collected datasets, totaling more than 30 sequences. Extensive testing on
both X86 and ARM platforms confirms that Super-LIO offers superior efficiency
and robustness, while maintaining competitive accuracy. Super-LIO processes
each frame approximately 73% faster than SOTA, while consuming less CPU
resources. The system is fully open-source and plug-and-play compatible with a
wide range of LiDAR sensors and platforms. The implementation is available at:
https://github.com/Liansheng-Wang/Super-LIO.git

</details>


### [19] [Scenario-based Decision-making Using Game Theory for Interactive Autonomous Driving: A Survey](https://arxiv.org/abs/2509.05777)
*Zhihao Lin,Zhen Tian*

Main category: cs.RO

TL;DR: 基于游戏的交互式驾驶模拟提供了安全、可扩展的测试平台，但确保实际性和稳健性仍面临挑战。近期游戏技术与充强学习框架的结合促进了适应性决策模型的发展，在多种场景中超越传统方法。本论文进行了系统性评估和对比分析。


<details>
  <summary>Details</summary>
Motivation: 游戏基础的交互式驾驶模拟环境为道路交通移动性的决策算法提供了安全、可扩展和吸引人的测试平台，但确保动态多样场景下的实际性和稳健性仍面临重大挑战。虽然有许多创新，但缺乏系统性的评估和跨场景对比分析。

Method: 近期将游戏技术与充强学习框架相结合，发展适应性决策模型。这些模型在多种驾驶场景中表现优异，包括高速公路避障、沿涝道合流、环形交口导航、无信号交叉口以自主赛车等。论文通过综述最新进展和道路特征来进行系统性评估。

Result: 这些模型在处理各种驾驶条件的复杂性方面表现优异，超越传统模拟方法，尤其在解决特定场景挑战时。论文对算法进行了批判性评估，分析了它们对标准游戏模型的适应性和具体机制对决策性能的影响。

Conclusion: 论文提供了对游戏基础交互式驾驶方法的全面评估，总结了最新进展和各场景的道路特征。还讨论了当前方法的局限性，并提出了未来研究的有前景方向。

Abstract: Game-based interactive driving simulations have emerged as versatile
platforms for advancing decision-making algorithms in road transport mobility.
While these environments offer safe, scalable, and engaging settings for
testing driving strategies, ensuring both realism and robust performance amid
dynamic and diverse scenarios remains a significant challenge. Recently, the
integration of game-based techniques with advanced learning frameworks has
enabled the development of adaptive decision-making models that effectively
manage the complexities inherent in varied driving conditions. These models
outperform traditional simulation methods, especially when addressing
scenario-specific challenges, ranging from obstacle avoidance on highways and
precise maneuvering during on-ramp merging to navigation in roundabouts,
unsignalized intersections, and even the high-speed demands of autonomous
racing. Despite numerous innovations in game-based interactive driving, a
systematic review comparing these approaches across different scenarios is
still missing. This survey provides a comprehensive evaluation of game-based
interactive driving methods by summarizing recent advancements and inherent
roadway features in each scenario. Furthermore, the reviewed algorithms are
critically assessed based on their adaptation of the standard game model and an
analysis of their specific mechanisms to understand their impact on
decision-making performance. Finally, the survey discusses the limitations of
current approaches and outlines promising directions for future research.

</details>


### [20] [eKalibr-Inertial: Continuous-Time Spatiotemporal Calibration for Event-Based Visual-Inertial Systems](https://arxiv.org/abs/2509.05923)
*Shuolong Chen,Xingxing Li,Liu Yuan*

Main category: cs.RO

TL;DR: eKalibr-Inertial是一个用于事件相机-惯性测量单元系统的精确时空标定工具，采用圆网格标定板，通过严格的初始化和连续时间批量优化实现高精度标定。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有高时间分辨率、高动态范围和低功耗等优势，在运动估计和机器人感知中广泛应用。视觉-惯性组合系统需要精确的时空标定（外参和时间参数）来实现最优融合，但现有方法在这方面存在不足。

Method: 基于eKalibr和eKalibr-Stereo中的网格模式识别和跟踪方法，首先进行严格高效的初始化以准确恢复所有参数，然后进行连续时间批量优化来细化参数。使用广泛采用的圆网格标定板。

Result: 大量真实世界实验结果表明，eKalibr-Inertial能够实现准确的事件相机-惯性测量单元时空标定。该方法已开源供研究社区使用。

Conclusion: eKalibr-Inertial为事件相机-惯性系统提供了一个有效的时空标定解决方案，通过严谨的初始化和优化过程实现了高精度标定，有助于推动事件相机在机器人感知领域的应用。

Abstract: The bioinspired event camera, distinguished by its exceptional temporal
resolution, high dynamic range, and low power consumption, has been extensively
studied in recent years for motion estimation, robotic perception, and object
detection. In ego-motion estimation, the visual-inertial setup is commonly
adopted due to complementary characteristics between sensors (e.g., scale
perception and low drift). For optimal event-based visual-inertial fusion,
accurate spatiotemporal (extrinsic and temporal) calibration is required. In
this work, we present eKalibr-Inertial, an accurate spatiotemporal calibrator
for event-based visual-inertial systems, utilizing the widely used circle grid
board. Building upon the grid pattern recognition and tracking methods in
eKalibr and eKalibr-Stereo, the proposed method starts with a rigorous and
efficient initialization, where all parameters in the estimator would be
accurately recovered. Subsequently, a continuous-time-based batch optimization
is conducted to refine the initialized parameters toward better states. The
results of extensive real-world experiments show that eKalibr-Inertial can
achieve accurate event-based visual-inertial spatiotemporal calibration. The
implementation of eKalibr-Inertial is open-sourced at
(https://github.com/Unsigned-Long/eKalibr) to benefit the research community.

</details>


### [21] [ZLATTE: A Geometry-Aware, Learning-Free Framework for Language-Driven Trajectory Reshaping in Human-Robot Interaction](https://arxiv.org/abs/2509.06031)
*Junhui Huang,Yuhe Gong,Changsheng Li,Xingguang Duan,Luis Figueredo*

Main category: cs.RO

TL;DR: ZLATTE是一个基于几何感知、无需学习的框架，通过视觉语言模型和大型语言模型将自然语言指令转化为几何约束，用于人机交互中的轨迹重塑。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的方法在轨迹修改方面存在局限性，需要一种能够直接理解自然语言指令并转化为明确几何约束的方法，以提高轨迹修改的平滑性、安全性和可解释性。

Method: 使用视觉语言模型将物体注册为几何基元，利用大型语言模型将自然语言指令翻译为几何和运动学约束，通过势场优化整合约束来调整初始轨迹，并采用多智能体策略增强鲁棒性。

Result: 仿真和真实世界实验表明，ZLATTE相比最先进的基线方法能够实现更平滑、更安全、更可解释的轨迹修改。

Conclusion: ZLATTE框架通过结合视觉语言模型和大型语言模型，成功实现了无需学习的语言驱动轨迹重塑，在人机交互中展现出优越的性能和实用性。

Abstract: We present ZLATTE, a geometry-aware, learning-free framework for
language-driven trajectory reshaping in human-robot interaction. Unlike prior
learning-based methods, ZLATTE leverages Vision-Language Models to register
objects as geometric primitives and employs a Large Language Model to translate
natural language instructions into explicit geometric and kinematic
constraints. These constraints are integrated into a potential field
optimization to adapt initial trajectories while preserving feasibility and
safety. A multi-agent strategy further enhances robustness under complex or
conflicting commands. Simulation and real-world experiments demonstrate that
ZLATTE achieves smoother, safer, and more interpretable trajectory
modifications compared to state-of-the-art baselines.

</details>


### [22] [Robotic Manipulation Framework Based on Semantic Keypoints for Packing Shoes of Different Sizes, Shapes, and Softness](https://arxiv.org/abs/2509.06048)
*Yi Dong,Yangjun Liu,Jinjun Duan,Yang Li,Zhendong Dai*

Main category: cs.RO

TL;DR: 这篇论文提出了一种用于鞋类产品包装的机器人操控框架，通过语义关键点视觉模块、重定向规划器和包装规划器，能够处理任何初始状态的鞋子包装任务。


<details>
  <summary>Details</summary>
Motivation: 鞋类产品包装是一种典型的成对物品包装任务，涉及不规则形状和可变形物体。虽然有相关研究，但对于不同初始状态和标准包装位置的考虑不充分。

Method: 提出了基于语义关键点的视觉模块来处理鞋子的状态、形状和变形问题；设计了基于原语的重定向方法和利用箱子边缘接触与重力的快速重定向方法；开发了任务规划器来提供最优包装策略。

Result: 通过实际实验验证了重定向方法的稳健性和包装策略对各种类型鞋子的有效性。

Conclusion: 该研究展示了语义关键点表征方法的潜力，为3D可变形物体重定向和多物体操控提供了新视角，并为成对物品包装提供了参考。

Abstract: With the rapid development of the warehousing and logistics industries, the
packing of goods has gradually attracted the attention of academia and
industry. The packing of footwear products is a typical representative
paired-item packing task involving irregular shapes and deformable objects.
Although studies on shoe packing have been conducted, different initial states
due to the irregular shapes of shoes and standard packing placement poses have
not been considered. This study proposes a robotic manipulation framework,
including a perception module, reorientation planners, and a packing planner,
that can complete the packing of pairs of shoes in any initial state. First, to
adapt to the large intraclass variations due to the state, shape, and
deformation of the shoe, we propose a vision module based on semantic
keypoints, which can also infer more information such as size, state, pose, and
manipulation points by combining geometric features. Subsequently, we not only
proposed primitive-based reorientation methods for different states of a single
deformable shoe but also proposed a fast reorientation method for the top state
using box edge contact and gravity, which further improved the efficiency of
reorientation. Finally, based on the perception module and reorientation
methods, we propose a task planner for shoe pair packing in any initial state
to provide an optimal packing strategy. Real-world experiments were conducted
to verify the robustness of the reorientation methods and the effectiveness of
the packing strategy for various types of shoes. In this study, we highlight
the potential of semantic keypoint representation methods, introduce new
perspectives on the reorientation of 3D deformable objects and multi-object
manipulation, and provide a reference for paired object packing.

</details>


### [23] [Energy-Efficient Path Planning with Multi-Location Object Pickup for Mobile Robots on Uneven Terrain](https://arxiv.org/abs/2509.06061)
*Faiza Babakano,Ahmed Fahmin,Bojie Shen,Muhammad Aamir Cheema,Isma Farah Siddiqui*

Main category: cs.RO

TL;DR: 本文提出了OMEPP问题，解决移动机器人在拾取物体途中的能量效率路径规划问题，通过并发PCPD搜索算法实现近最优解且计算效率大幅提升


<details>
  <summary>Details</summary>
Motivation: 现有能量效率路径规划研究忽略了机器人需要在途中拾取物体的实际场景，拾取动作会因负载变化显著影响能耗，需要新的解决方案

Method: 提出基线算法使用Z*算法迭代访问每个拾取点，然后设计并发PCPD搜索同时管理多个Z*搜索，核心是Payload-Constrained Path Database (PCPD)扩展

Result: 并发PCPD搜索虽然可能产生略微次优解，但在真实数据集实验中达到近最优性能，计算速度比基线算法快1-2个数量级

Conclusion: PCPD方法有效降低了搜索分支因子，提出的并发PCPD搜索为OMEPP问题提供了高效实用的解决方案，在保证性能的同时大幅提升计算效率

Abstract: Autonomous Mobile Robots (AMRs) operate on battery power, making energy
efficiency a critical consideration, particularly in outdoor environments where
terrain variations affect energy consumption. While prior research has
primarily focused on computing energy-efficient paths from a source to a
destination, these approaches often overlook practical scenarios where a robot
needs to pick up an object en route - an action that can significantly impact
energy consumption due to changes in payload. This paper introduces the
Object-Pickup Minimum Energy Path Problem (OMEPP), which addresses
energy-efficient route planning for AMRs required to pick up an object from one
of many possible locations and deliver it to a destination. To address OMEPP,
we first introduce a baseline algorithm that employs the Z star algorithm, a
variant of A star tailored for energy-efficient routing, to iteratively visit
each pickup point. While this approach guarantees optimality, it suffers from
high computational cost due to repeated searches at each pickup location. To
mitigate this inefficiency, we propose a concurrent PCPD search that manages
multiple Z star searches simultaneously across all pickup points. Central to
our solution is the Payload-Constrained Path Database (PCPD), an extension of
the Compressed Path Database (CPD) that incorporates payload constraints. We
demonstrate that PCPD significantly reduces branching factors during search,
improving overall performance. Although the concurrent PCPD search may produce
slightly suboptimal solutions, extensive experiments on real-world datasets
show it achieves near-optimal performance while being one to two orders of
magnitude faster than the baseline algorithm.

</details>


### [24] [Hybrid A* Path Planning with Multi-Modal Motion Extension for Four-Wheel Steering Mobile Robots](https://arxiv.org/abs/2509.06115)
*Runjiao Bao,Lin Zhang,Tianwei Niu,Haoyu Yuan,Shoukun Wang*

Main category: cs.RO

TL;DR: 基于四维状态空间的扩展混合A*案创新，通过多模态Reeds-Shepp曲线、改进启发函数和智能模式选择策略，实现了四轮独立轮转机器人在复杂环境中的多模态运动规划。


<details>
  <summary>Details</summary>
Motivation: 现有路径规划方法通常假设单一运动模式，无法充分利用四轮独立轮转系统的多模态运动能力。

Method: 构建四维状态空间（空间坐标+运动模式），设计多模态Reeds-Shepp曲线、改进启发函数考虑模式切换成本，以及智能模式选择的终端连接策略。

Result: 在复杂环境中显著提升了四轮独立轮转机器人的规划性能。

Conclusion: 该方法能够在单个路径中无缝集成多种运动模态，显著提高了机器人在复杂环境中的灵活性和适应性。

Abstract: Four-wheel independent steering (4WIS) systems provide mobile robots with a
rich set of motion modes, such as Ackermann steering, lateral steering, and
parallel movement, offering superior maneuverability in constrained
environments. However, existing path planning methods generally assume a single
kinematic model and thus fail to fully exploit the multi-modal capabilities of
4WIS platforms. To address this limitation, we propose an extended Hybrid A*
framework that operates in a four-dimensional state space incorporating both
spatial states and motion modes. Within this framework, we design multi-modal
Reeds-Shepp curves tailored to the distinct kinematic constraints of each
motion mode, develop an enhanced heuristic function that accounts for
mode-switching costs, and introduce a terminal connection strategy with
intelligent mode selection to ensure smooth transitions between different
steering patterns. The proposed planner enables seamless integration of
multiple motion modalities within a single path, significantly improving
flexibility and adaptability in complex environments. Results demonstrate
significantly improved planning performance for 4WIS robots in complex
environments.

</details>


### [25] [A Hybrid TDMA/CSMA Protocol for Time-Sensitive Traffic in Robot Applications](https://arxiv.org/abs/2509.06119)
*Shiqi Xu,Lihao Zhang,Yuyang Du,Qun Yang,Soung Chang Liew*

Main category: cs.RO

TL;DR: 提出一种新的IEEE 802.11兼容混合TDMA/CSMA协议，解决高负载机器人通信中CSMA协议的性能问题，实现低延迟、无冲突的任务关键命令传输。


<details>
  <summary>Details</summary>
Motivation: 实时机器人控制应用需要在异构流量下保证任务关键命令的定时传输，CSMA协议在高负载情况下存在严重的冲突和延迟问题。

Method: 设计了一种混合TDMA/CSMA协议，结合TDMA的定时间隔调度和CSMA的适应性，采用子微秒级PTP基准同步、三会话超帧结构和beacon-NAV保护机制。

Result: 在SDR实时平台和ROS模拟中，该协议将超期错误减少93%，路径跟踪RMS误差降低90%，同时非关键流量吞吐量保持在±2%以内。

Conclusion: 该混合协议有效解决了高负载机器人通信中的定时性问题，为实时控制应用提供了可靠的通信基础。

Abstract: Recent progress in robotics has underscored the demand for real-time control
in applications such as manufacturing, healthcare, and autonomous systems,
where the timely delivery of mission-critical commands under heterogeneous
robotic traffic is paramount for operational efficacy and safety. In these
scenarios, mission-critical traffic follows a strict deadline-constrained
communication pattern: commands must arrive within defined QoS deadlines,
otherwise late arrivals can degrade performance or destabilize control loops.In
this work, we demonstrate on a real-time SDR platform that CSMA, widely adopted
in robotic communications,suffers severe degradation under high robot traffic
loads, with contention-induced collisions and delays disrupting the on-time
arrival of mission-critical packets. To address this problem, we propose an
IEEE 802.11-compatible hybrid TDMA/CSMA protocol that combines TDMA's
deterministic slot scheduling with CSMA's adaptability for heterogeneous robot
traffic.The protocol achieves collision-free, low-latency mission-critical
command delivery and IEEE 802.11 compatibility through the synergistic
integration of sub-microsecond PTP-based slot synchronization-essential for
establishing precise timing for TDMA, a three-session superframe with dynamic
TDMA allocation for structured and adaptable traffic management,and beacon-NAV
protection to preemptively secure these critical communication sessions from
interference. Emulation experiments on real-time SDR testbed and Robot
Operating System (ROS) simulation show that the proposed protocol reduces
missed-deadline errors by 93% compared to the CSMA baseline. In high-speed
robot path-tracking ROS simulations, the protocol lowers Root Mean Square (RMS)
trajectory error by up to 90% compared with a CSMA baseline, all while
maintaining throughput for non-critical traffic within +-2%.

</details>


### [26] [Learning in ImaginationLand: Omnidirectional Policies through 3D Generative Models (OP-Gen)](https://arxiv.org/abs/2509.06191)
*Yifei Ren,Edward Johns*

Main category: cs.RO

TL;DR: 使用3D生成模型从单个真实示范扩充数据集，训练全向策略，减少示范需求并提升机器人任务性能


<details>
  <summary>Details</summary>
Motivation: 利用最新3D生成模型的能力，通过数据扩充减少机器人学习对多示范的依赖，让机器人能够处理远距离示范初始状态的任务

Method: 从单个真实示范出发，使用3D生成模型生成多角度的对象形状，在这些想象数据中训练全向策略

Result: 机器人能在远距离示范初始状态的情况下完成任务，包括从对象反侧启动，在抓取、抽屉和垃圾分类任务中表现超过基线方法

Conclusion: 3D生成模型为机器人学习提供了高效的数据扩充方法，显著减少了示范需求并提升了策略的适应性和性能

Abstract: Recent 3D generative models, which are capable of generating full object
shapes from just a few images, now open up new opportunities in robotics. In
this work, we show that 3D generative models can be used to augment a dataset
from a single real-world demonstration, after which an omnidirectional policy
can be learned within this imagined dataset. We found that this enables a robot
to perform a task when initialised from states very far from those observed
during the demonstration, including starting from the opposite side of the
object relative to the real-world demonstration, significantly reducing the
number of demonstrations required for policy learning. Through several
real-world experiments across tasks such as grasping objects, opening a drawer,
and placing trash into a bin, we study these omnidirectional policies by
investigating the effect of various design choices on policy behaviour, and we
show superior performance to recent baselines which use alternative methods for
data augmentation.

</details>


### [27] [Grasp-MPC: Closed-Loop Visual Grasping via Value-Guided Model Predictive Control](https://arxiv.org/abs/2509.06201)
*Jun Yamada,Adithyavairavan Murali,Ajay Mandlekar,Clemens Eppner,Ingmar Posner,Balakumar Sundaralingam*

Main category: cs.RO

TL;DR: Grasp-MPC是一个基于视觉的6自由度闭环抓取策略，通过在大规模合成数据集上训练价值函数，结合MPC框架实现杂乱环境中新物体的鲁棒抓取。


<details>
  <summary>Details</summary>
Motivation: 解决非结构化环境中多样化物体抓取的挑战，传统开环方法在杂乱环境中效果不佳，而现有闭环方法在简化和有限物体设置中难以泛化。

Method: 在大规模合成数据集（200万条抓取轨迹）上训练视觉价值函数，结合MPC框架，加入碰撞避免和平滑执行等成本项。

Result: 在仿真中抓取成功率提升32.6%，在真实世界噪声条件下提升33.3%，优于开环、扩散策略、Transformer策略和IQL方法。

Conclusion: Grasp-MPC通过结合学习价值函数和MPC框架，实现了在杂乱环境中对新物体的鲁棒和反应式抓取，显著提高了抓取性能。

Abstract: Grasping of diverse objects in unstructured environments remains a
significant challenge. Open-loop grasping methods, effective in controlled
settings, struggle in cluttered environments. Grasp prediction errors and
object pose changes during grasping are the main causes of failure. In
contrast, closed-loop methods address these challenges in simplified settings
(e.g., single object on a table) on a limited set of objects, with no path to
generalization. We propose Grasp-MPC, a closed-loop 6-DoF vision-based grasping
policy designed for robust and reactive grasping of novel objects in cluttered
environments. Grasp-MPC incorporates a value function, trained on visual
observations from a large-scale synthetic dataset of 2 million grasp
trajectories that include successful and failed attempts. We deploy this
learned value function in an MPC framework in combination with other cost terms
that encourage collision avoidance and smooth execution. We evaluate Grasp-MPC
on FetchBench and real-world settings across diverse environments. Grasp-MPC
improves grasp success rates by up to 32.6% in simulation and 33.3% in
real-world noisy conditions, outperforming open-loop, diffusion policy,
transformer policy, and IQL approaches. Videos and more at
http://grasp-mpc.github.io.

</details>


### [28] [O$^3$Afford: One-Shot 3D Object-to-Object Affordance Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2509.06233)
*Tongxuan Tian,Xuhui Kang,Yen-Ling Kuo*

Main category: cs.RO

TL;DR: 提出了一种基于少样本学习的3D物体间功能关系学习方法O³Afford，结合视觉基础模型和点云表示，显著提升了机器人操作中物体交互关系的理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单物体功能预测，但真实世界中的交互通常涉及物体对之间的关系，且面临数据有限的挑战。

Method: 利用视觉基础模型的语义特征和点云表示的几何理解，构建单样本学习流程，并将3D功能表示与大语言模型集成。

Result: 在3D物体间功能关系学习和机器人操作实验中，O³Afford在准确性和泛化能力方面显著优于现有基线方法。

Conclusion: 该方法有效解决了数据限制下的物体间功能关系学习问题，为机器人操作提供了更好的物体交互理解和推理能力。

Abstract: Grounding object affordance is fundamental to robotic manipulation as it
establishes the critical link between perception and action among interacting
objects. However, prior works predominantly focus on predicting single-object
affordance, overlooking the fact that most real-world interactions involve
relationships between pairs of objects. In this work, we address the challenge
of object-to-object affordance grounding under limited data contraints.
Inspired by recent advances in few-shot learning with 2D vision foundation
models, we propose a novel one-shot 3D object-to-object affordance learning
approach for robotic manipulation. Semantic features from vision foundation
models combined with point cloud representation for geometric understanding
enable our one-shot learning pipeline to generalize effectively to novel
objects and categories. We further integrate our 3D affordance representation
with large language models (LLMs) for robotics manipulation, significantly
enhancing LLMs' capability to comprehend and reason about object interactions
when generating task-specific constraint functions. Our experiments on 3D
object-to-object affordance grounding and robotic manipulation demonstrate that
our O$^3$Afford significantly outperforms existing baselines in terms of both
accuracy and generalization capability.

</details>


### [29] [DCReg: Decoupled Characterization for Efficient Degenerate LiDAR Registration](https://arxiv.org/abs/2509.06285)
*Xiangcheng Hu,Xieyuanli Chen,Mingkai Jia,Jin Wu,Ping Tan,Steven L. Waslander*

Main category: cs.RO

TL;DR: DCReg是一个处理LiDAR点云配准中病态问题的框架，通过Schur分解、定量特征分析和选择性预处理，在退化环境中实现更准确和快速的配准。


<details>
  <summary>Details</summary>
Motivation: 在几何退化或狭窄环境中，LiDAR点云配准问题变得病态，导致解不稳定和精度下降。现有方法未能准确检测、解释和解决这种病态性。

Method: 1. 使用Schur补分解Hessian矩阵，将配准问题解耦为干净的旋转和平移子空间；2. 在子空间中建立数学特征空间与物理运动方向的显式映射；3. 设计选择性预处理器，仅稳定病态方向而保留良好约束信息。

Result: 实验显示DCReg在定位精度上比最先进方法提升20%-50%，速度提升5-100倍，适用于各种环境。

Conclusion: DCReg通过系统性的病态问题处理框架，显著提高了LiDAR点云配准在退化环境中的鲁棒性和效率。

Abstract: LiDAR point cloud registration is fundamental to robotic perception and
navigation. However, in geometrically degenerate or narrow environments,
registration problems become ill-conditioned, leading to unstable solutions and
degraded accuracy. While existing approaches attempt to handle these issues,
they fail to address the core challenge: accurately detection, interpret, and
resolve this ill-conditioning, leading to missed detections or corrupted
solutions. In this study, we introduce DCReg, a principled framework that
systematically addresses the ill-conditioned registration problems through
three integrated innovations. First, DCReg achieves reliable ill-conditioning
detection by employing a Schur complement decomposition to the hessian matrix.
This technique decouples the registration problem into clean rotational and
translational subspaces, eliminating coupling effects that mask degeneracy
patterns in conventional analyses. Second, within these cleanly subspaces, we
develop quantitative characterization techniques that establish explicit
mappings between mathematical eigenspaces and physical motion directions,
providing actionable insights about which specific motions lack constraints.
Finally, leveraging this clean subspace, we design a targeted mitigation
strategy: a novel preconditioner that selectively stabilizes only the
identified ill-conditioned directions while preserving all well-constrained
information in observable space. This enables efficient and robust optimization
via the Preconditioned Conjugate Gradient method with a single physical
interpretable parameter. Extensive experiments demonstrate DCReg achieves at
least 20% - 50% improvement in localization accuracy and 5-100 times speedup
over state-of-the-art methods across diverse environments. Our implementation
will be available at https://github.com/JokerJohn/DCReg.

</details>


### [30] [Learning to Walk with Less: a Dyna-Style Approach to Quadrupedal Locomotion](https://arxiv.org/abs/2509.06296)
*Francisco Affonso,Felipe Andrade G. Tommaselli,Juliano Negri,Vivian S. Medeiros,Mateus V. Gasparino,Girish Chowdhary,Marcelo Becker*

Main category: cs.RO

TL;DR: 通过模型基硅强化学习框架，使用预测模型生成合成数据来扩展PPO控制器的滚动过程，显著提高四足机器人运动控制的样本效率和稳健性。


<details>
  <summary>Details</summary>
Motivation: 传统RL基于运动控制器数据效率低，需要大量交互才能达到稳健性能，需要提高样本利用效率。

Method: 采用Dyna-Style框架，在PPO控制器中添加合成数据到标准滚动末尾。训练预测模型生成短期限合成过渡，逐渐集成到策略更新中。通过消融研究确定滚动长度与样本效率的关联性。

Result: 在Unitree Go1机器人模拟中验证，用合成步骤替换部分模拟步骤不仅模拟扩展滚动，还提高了策略回报和降低方差。能够使用更少模拟步骤进行广泛运动命令跟踪。

Conclusion: 该MBRL方法通过合成数据扩展有效提高了四足机器人运动控制的样本效率，在保持稳健性的同时减少了实际交互需求。

Abstract: Traditional RL-based locomotion controllers often suffer from low data
efficiency, requiring extensive interaction to achieve robust performance. We
present a model-based reinforcement learning (MBRL) framework that improves
sample efficiency for quadrupedal locomotion by appending synthetic data to the
end of standard rollouts in PPO-based controllers, following the Dyna-Style
paradigm. A predictive model, trained alongside the policy, generates
short-horizon synthetic transitions that are gradually integrated using a
scheduling strategy based on the policy update iterations. Through an ablation
study, we identified a strong correlation between sample efficiency and rollout
length, which guided the design of our experiments. We validated our approach
in simulation on the Unitree Go1 robot and showed that replacing part of the
simulated steps with synthetic ones not only mimics extended rollouts but also
improves policy return and reduces variance. Finally, we demonstrate that this
improvement transfers to the ability to track a wide range of locomotion
commands using fewer simulated steps.

</details>


### [31] [Towards bridging the gap: Systematic sim-to-real transfer for diverse legged robots](https://arxiv.org/abs/2509.06342)
*Filip Bjelonic,Fabian Tischhauser,Marco Hutter*

Main category: cs.RO

TL;DR: 提出一个结合仿真到现实强化学习和物理基础电机能量模型的框架，通过简洁的四项奖励函数和第一性原理能量损失公式，在无需动态参数随机化的情况下实现可靠策略迁移，将ANYmal的运输成本降低32%


<details>
  <summary>Details</summary>
Motivation: 解决腿式机器人在现实环境中需要同时实现鲁棒运动和能源效率的问题，现有方法存在仿真到现实迁移失败、忽视执行器特定能量损失或依赖复杂手工调优奖励公式的局限性

Method: 集成仿真到现实强化学习与永磁同步电机的物理基础能量模型，使用最小参数集捕捉仿真到现实差距，采用基于第一性原理的能量损失公式和简洁的四项奖励函数来平衡电气和机械损耗

Result: 通过从执行器到完整机器人的动态参数识别研究验证方法，在三个主要平台测试并部署到十个机器人上，无需动态参数随机化即可实现可靠策略迁移，将ANYmal的完整运输成本降低32%（值1.27）

Conclusion: 该框架显著提高了腿式机器人的能源效率，证明了物理基础能量模型在仿真到现实强化学习中的有效性，所有代码、模型和数据集将开源

Abstract: Legged robots must achieve both robust locomotion and energy efficiency to be
practical in real-world environments. Yet controllers trained in simulation
often fail to transfer reliably, and most existing approaches neglect
actuator-specific energy losses or depend on complex, hand-tuned reward
formulations. We propose a framework that integrates sim-to-real reinforcement
learning with a physics-grounded energy model for permanent magnet synchronous
motors. The framework requires a minimal parameter set to capture the
simulation-to-reality gap and employs a compact four-term reward with a
first-principle-based energetic loss formulation that balances electrical and
mechanical dissipation. We evaluate and validate the approach through a
bottom-up dynamic parameter identification study, spanning actuators,
full-robot in-air trajectories and on-ground locomotion. The framework is
tested on three primary platforms and deployed on ten additional robots,
demonstrating reliable policy transfer without randomization of dynamic
parameters. Our method improves energetic efficiency over state-of-the-art
methods, achieving a 32 percent reduction in the full Cost of Transport of
ANYmal (value 1.27). All code, models, and datasets will be released.

</details>


### [32] [Adaptive Evolution Factor Risk Ellipse Framework for Reliable and Safe Autonomous Driving](https://arxiv.org/abs/2509.06375)
*Fujiang Yuan,Zhen Tian,Yangfan He,Guojian Zou,Chunhong Yuan,Yanhong Peng,Zhihao Lin*

Main category: cs.RO

TL;DR: 提出进化风险势场(ERPF)方法，通过动态风险椭圆和自适应进化因子，结合MPC框架解决自动驾驶交互场景中的安全与效率问题


<details>
  <summary>Details</summary>
Motivation: 传统模型方法过于保守或计算量大，学习方法需要大量数据且可解释性差，静态风险势场无法适应动态交通条件

Method: 使用风险椭圆结合纵向可达性和横向不确定性，定义基于TTC和TWH的自适应进化因子，集成到MPC框架中实现实时动态风险调整

Result: 实验表明ERPF-MPC方法能实现更平滑轨迹、更高平均速度和无碰撞导航，在复杂交互驾驶环境中表现鲁棒

Conclusion: ERPF方法为复杂交互驾驶环境提供了自适应、轻量级且有效的解决方案，克服了现有方法的局限性

Abstract: In recent years, ensuring safety, efficiency, and comfort in interactive
autonomous driving has become a critical challenge. Traditional model-based
techniques, such as game-theoretic methods and robust control, are often overly
conservative or computationally intensive. Conversely, learning-based
approaches typically require extensive training data and frequently exhibit
limited interpretability and generalizability. Simpler strategies, such as Risk
Potential Fields (RPF), provide lightweight alternatives with minimal data
demands but are inherently static and struggle to adapt effectively to dynamic
traffic conditions. To overcome these limitations, we propose the Evolutionary
Risk Potential Field (ERPF), a novel approach that dynamically updates risk
assessments in dynamical scenarios based on historical obstacle proximity data.
We introduce a Risk-Ellipse construct that combines longitudinal reach and
lateral uncertainty into a unified spatial temporal collision envelope.
Additionally, we define an adaptive Evolution Factor metric, computed through
sigmoid normalization of Time to Collision (TTC) and Time-Window-of-Hazard
(TWH), which dynamically adjusts the dimensions of the ellipse axes in real
time. This adaptive risk metric is integrated seamlessly into a Model
Predictive Control (MPC) framework, enabling autonomous vehicles to proactively
address complex interactive driving scenarios in terms of uncertain driving of
surrounding vehicles. Comprehensive comparative experiments demonstrate that
our ERPF-MPC approach consistently achieves smoother trajectories, higher
average speeds, and collision-free navigation, offering a robust and adaptive
solution suitable for complex interactive driving environments.

</details>


### [33] [Safety Meets Speed: Accelerated Neural MPC with Safety Guarantees and No Retraining](https://arxiv.org/abs/2509.06404)
*Kaikai Wang,Tianxun Li,Liang Xu,Qinglei Hu,Keyou You*

Main category: cs.RO

TL;DR: BAN-MPC框架结合神经网络快速计算与MPC约束处理能力，使用控制屏障函数确保安全，通过离线学习的神经价值函数大幅降低在线计算复杂度，在Jetson Nano上比传统MPC快200倍。


<details>
  <summary>Details</summary>
Motivation: 传统MPC虽然通过约束确保安全，但实时执行可能超出嵌入式计算预算，需要一种既能保持安全性又能大幅降低计算复杂度的解决方案。

Method: 提出BAN-MPC框架：1）用控制屏障函数替代欧几里得距离进行碰撞避免；2）将离线学习的神经价值函数集成到短时域MPC优化目标中；3）使用第二个神经网络学习价值函数对系统参数的敏感性，在模型参数变化时自适应调整。

Result: 硬件在环实验显示：BAN-MPC比传统MPC快200倍，在模型参数变化15%内实现无碰撞导航，控制误差低于5%。

Conclusion: BAN-MPC是一种有效的嵌入式MPC替代方案，无需重新训练即可适应模型参数变化，显著降低了离线和在线计算成本。

Abstract: While Model Predictive Control (MPC) enforces safety via constraints, its
real-time execution can exceed embedded compute budgets. We propose a
Barrier-integrated Adaptive Neural Model Predictive Control (BAN-MPC) framework
that synergizes neural networks' fast computation with MPC's
constraint-handling capability. To ensure strict safety, we replace traditional
Euclidean distance with Control Barrier Functions (CBFs) for collision
avoidance. We integrate an offline-learned neural value function into the
optimization objective of a Short-horizon MPC, substantially reducing online
computational complexity. Additionally, we use a second neural network to learn
the sensitivity of the value function to system parameters, and adaptively
adjust the neural value function based on this neural sensitivity when model
parameters change, eliminating the need for retraining and reducing offline
computation costs. The hardware in-the-loop (HIL) experiments on Jetson Nano
show that BAN-MPC solves 200 times faster than traditional MPC, enabling
collision-free navigation with control error below 5\% under model parameter
variations within 15\%, making it an effective embedded MPC alternative.

</details>


### [34] [Real-time Photorealistic Mapping for Situational Awareness in Robot Teleoperation](https://arxiv.org/abs/2509.06433)
*Ian Page,Pierre Susbielle,Olivier Aycard,Pierre-Brice Wieber*

Main category: cs.RO

TL;DR: 通过集成高斯拟合SLAM与GPU加速技术，实现了高效的实时遥控系统，在未知环境中显著提升了决策速度和环境交互准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统在线地图遥控系统在未知环境中因计算成本高而无法实时生成视觉准确3D地图的问题，导致遥控性能差。

Method: 提出一种模块化的高效GPU基础集成方案，将最新的高斯拟合SLAM技术与现有在线地图遥控系统相结合。

Result: 通过实际航空设备实验验证，系统在决策速度和环境交互准确性方面显著提升，实现了实时的照片伪真地图生成。

Conclusion: 该系统通过无缝集成照片伪真地图生成与实时性能，最终提升了在不熟悉环境中的遥程遥控效果。

Abstract: Achieving efficient remote teleoperation is particularly challenging in
unknown environments, as the teleoperator must rapidly build an understanding
of the site's layout. Online 3D mapping is a proven strategy to tackle this
challenge, as it enables the teleoperator to progressively explore the site
from multiple perspectives. However, traditional online map-based teleoperation
systems struggle to generate visually accurate 3D maps in real-time due to the
high computational cost involved, leading to poor teleoperation performances.
In this work, we propose a solution to improve teleoperation efficiency in
unknown environments. Our approach proposes a novel, modular and efficient
GPU-based integration between recent advancement in gaussian splatting SLAM and
existing online map-based teleoperation systems. We compare the proposed
solution against state-of-the-art teleoperation systems and validate its
performances through real-world experiments using an aerial vehicle. The
results show significant improvements in decision-making speed and more
accurate interaction with the environment, leading to greater teleoperation
efficiency. In doing so, our system enhances remote teleoperation by seamlessly
integrating photorealistic mapping generation with real-time performances,
enabling effective teleoperation in unfamiliar environments.

</details>


### [35] [Interactive Shaping of Granular Media Using Reinforcement Learning](https://arxiv.org/abs/2509.06469)
*Benedikt Kreis,Malte Mosbach,Anny Ripke,Muhammad Ehsan Ullah,Sven Behnke,Maren Bennewitz*

Main category: cs.RO

TL;DR: 提出基于强化学习的机器人框架，使用立方体末端执行器和立体相机来塑造颗粒介质为目标结构，通过紧凑观察和简洁奖励设计解决高维配置空间问题。


<details>
  <summary>Details</summary>
Motivation: 颗粒介质（如沙子）的自主操作在建筑、挖掘和增材制造中很重要，但由于高维配置空间和复杂动力学，传统基于规则的方法需要大量工程努力，强化学习提供了通过试错学习自适应操作策略的有前景的替代方案。

Method: 使用带有立方体末端执行器的机械臂和立体相机，设计紧凑的观察空间和简洁的奖励函数，通过强化学习训练视觉策略来操作颗粒介质，并通过消融研究验证设计选择。

Result: 该方法在训练视觉策略操作颗粒介质方面表现出有效性，包括实际部署，性能优于两种基线方法。

Conclusion: 强化学习框架能够有效解决颗粒介质操作的高维配置空间挑战，紧凑观察和简洁奖励设计是关键因素，该方法在实际应用中表现出色。

Abstract: Autonomous manipulation of granular media, such as sand, is crucial for
applications in construction, excavation, and additive manufacturing. However,
shaping granular materials presents unique challenges due to their
high-dimensional configuration space and complex dynamics, where traditional
rule-based approaches struggle without extensive engineering efforts.
Reinforcement learning (RL) offers a promising alternative by enabling agents
to learn adaptive manipulation strategies through trial and error. In this
work, we present an RL framework that enables a robotic arm with a cubic
end-effector and a stereo camera to shape granular media into desired target
structures. We show the importance of compact observations and concise reward
formulations for the large configuration space, validating our design choices
with an ablation study. Our results demonstrate the effectiveness of the
proposed approach for the training of visual policies that manipulate granular
media including their real-world deployment, outperforming two baseline
approaches.

</details>


### [36] [Event Driven CBBA with Reduced Communication](https://arxiv.org/abs/2509.06481)
*Vinita Sao,Tu Dac Ho,Sujoy Bhore,P. B. Sujit*

Main category: cs.RO

TL;DR: 提出事件驱动的通信机制ED-CBBA，在保持CBBA算法收敛性和性能保证的同时，减少52%的消息传输量


<details>
  <summary>Details</summary>
Motivation: 多机器人任务分配中，CBBA算法需要持续通信，容易导致网络拥塞和丢包，影响性能

Method: 在CBBA基础上引入事件驱动通信机制，只在必要时进行通信

Result: 理论证明解质量与CBBA相当，蒙特卡洛模拟显示消息传输量最多减少52%

Conclusion: ED-CBBA在保持性能的同时显著降低了通信开销，适用于通信受限的多机器人系统

Abstract: In various scenarios such as multi-drone surveillance and search-and-rescue
operations, deploying multiple robots is essential to accomplish multiple tasks
at once. Due to the limited communication range of these vehicles, a
decentralised task allocation algorithm is crucial for effective task
distribution among robots. The consensus-based bundle algorithm (CBBA) has been
promising for multi-robot operation, offering theoretical guarantees. However,
CBBA demands continuous communication, leading to potential congestion and
packet loss that can hinder performance. In this study, we introduce an
event-driven communication mechanism designed to address these communication
challenges while maintaining the convergence and performance bounds of CBBA. We
demonstrate theoretically that the solution quality matches that of CBBA and
validate the approach with Monte-Carlo simulations across varying targets,
agents, and bundles. Results indicate that the proposed algorithm (ED-CBBA) can
reduce message transmissions by up to 52%.

</details>


### [37] [Co-Located VR with Hybrid SLAM-based HMD Tracking and Motion Capture Synchronization](https://arxiv.org/abs/2509.06582)
*Carlos A. Pinheiro de Sousa,Niklas Gröne,Mathias Günther,Oliver Deussen*

Main category: cs.RO

TL;DR: 一种结合动戯捕捉和SLAM内部追踪的多用户VR共位框架，实现低延迟、高性能的虚拟环境同步


<details>
  <summary>Details</summary>
Motivation: 解决现有共位VR方案中外部追踪导致的延迟和抖动问题，以及一次性校准无法缓解时间偏移的限制

Method: 结合动戯捕捉系统与SLAM内部追踪技术，在保持本地HMD追踪响应性的同时，支持根据需要重新对准外部源，并支持跨设备实时姿态共享

Result: 框架达到了自然多用户交互所需的空间准确性，在舒适性、可扩展性和稳健性方面都超过现有共位VR解决方案

Conclusion: 该框架通过智能结合内部和外部追踪优势，为多用户VR共位体验提供了更好的性能和可靠性

Abstract: We introduce a multi-user VR co-location framework that synchronizes users
within a shared virtual environment aligned to physical space. Our approach
combines a motion capture system with SLAM-based inside-out tracking to deliver
smooth, high-framerate, low-latency performance. Previous methods either rely
on continuous external tracking, which introduces latency and jitter, or on
one-time calibration, which cannot correct drift over time. In contrast, our
approach combines the responsiveness of local HMD SLAM tracking with the
flexibility to realign to an external source when needed. It also supports
real-time pose sharing across devices, ensuring consistent spatial alignment
and engagement between users. Our evaluation demonstrates that our framework
achieves the spatial accuracy required for natural multi-user interaction while
offering improved comfort, scalability, and robustness over existing co-located
VR solutions.

</details>


### [38] [A Robust Approach for LiDAR-Inertial Odometry Without Sensor-Specific Modeling](https://arxiv.org/abs/2509.06593)
*Meher V. R. Malladi,Tiziano Guadagnino,Luca Lobefaro,Cyrill Stachniss*

Main category: cs.RO

TL;DR: 一种不依赖于传感器特定模型的健壁的雷达-惯性测量单元测程系统，通过简化运动模型和直接扫描注册实现多种传感器和场景的统一配置部署。


<details>
  <summary>Details</summary>
Motivation: 需要一种能够在不同传感器类型和部署场景下都具有高精度和健壁性的测程系统，以支持后续的规划和控制模块。

Method: 使用简化运动模型进行IMU数据集成，采用扫描到地图的直接注册方法，并对雷达注册添加新的正则化条件来提升性能。

Result: 在多个数据集上进行了广泛实验，覆盖了常见的机器人传感器和平台，证明了系统在所有场景下使用相同配置都能正常工作的健壁性。

Conclusion: 该方法提供了一种简洁但高效的测程解决方案，已开源以便社区继续建设和集成到导航栈中。

Abstract: Accurate odometry is a critical component in a robotic navigation stack, and
subsequent modules such as planning and control often rely on an estimate of
the robot's motion. Sensor-based odometry approaches should be robust across
sensor types and deployable in different target domains, from solid-state
LiDARs mounted on cars in urban-driving scenarios to spinning LiDARs on
handheld packages used in unstructured natural environments. In this paper, we
propose a robust LiDAR-inertial odometry system that does not rely on
sensor-specific modeling. Sensor fusion techniques for LiDAR and inertial
measurement unit (IMU) data typically integrate IMU data iteratively in a
Kalman filter or use pre-integration in a factor graph framework, combined with
LiDAR scan matching often exploiting some form of feature extraction. We
propose an alternative strategy that only requires a simplified motion model
for IMU integration and directly registers LiDAR scans in a scan-to-map
approach. Our approach allows us to impose a novel regularization on the LiDAR
registration, improving the overall odometry performance. We detail extensive
experiments on a number of datasets covering a wide array of commonly used
robotic sensors and platforms. We show that our approach works with the exact
same configuration in all these scenarios, demonstrating its robustness. We
have open-sourced our implementation so that the community can build further on
our work and use it in their navigation stacks.

</details>


### [39] [LiHRA: A LiDAR-Based HRI Dataset for Automated Risk Monitoring Methods](https://arxiv.org/abs/2509.06597)
*Frederik Plahl,Georgios Katranis,Ilshat Mamaev,Andrey Morozov*

Main category: cs.RO

TL;DR: LiHRA是一个新颖的多模态数据集，专门用于人机交互风险监测研究，包含3D LiDAR点云、人体关键点和机器人关节状态数据，涵盖6种HRI场景的安全和危险版本。


<details>
  <summary>Details</summary>
Motivation: 工业环境中协作机器人日益普及，但缺乏高质量的真实人机交互数据集（包括危险事件），阻碍了可靠安全系统的发展。

Method: 创建包含4,431个标注点云的多模态数据集，结合3D LiDAR、人体关键点跟踪和机器人状态数据，记录频率为10Hz，覆盖协作共存、物体交接、表面抛光等6种代表性场景。

Result: 提供了完整的空间和动态上下文数据，能够精确追踪人体运动、机器人动作和环境条件，为风险监测算法训练和基准测试提供丰富资源。

Conclusion: LiHRA数据集为实时风险监测和自适应安全策略研究提供了重要基础，通过结合高分辨率LiDAR数据、精确人体追踪和真实碰撞事件，推动了人机工作空间安全技术的发展。

Abstract: We present LiHRA, a novel dataset designed to facilitate the development of
automated, learning-based, or classical risk monitoring (RM) methods for
Human-Robot Interaction (HRI) scenarios. The growing prevalence of
collaborative robots in industrial environments has increased the need for
reliable safety systems. However, the lack of high-quality datasets that
capture realistic human-robot interactions, including potentially dangerous
events, slows development. LiHRA addresses this challenge by providing a
comprehensive, multi-modal dataset combining 3D LiDAR point clouds, human body
keypoints, and robot joint states, capturing the complete spatial and dynamic
context of human-robot collaboration. This combination of modalities allows for
precise tracking of human movement, robot actions, and environmental
conditions, enabling accurate RM during collaborative tasks. The LiHRA dataset
covers six representative HRI scenarios involving collaborative and coexistent
tasks, object handovers, and surface polishing, with safe and hazardous
versions of each scenario. In total, the data set includes 4,431 labeled point
clouds recorded at 10 Hz, providing a rich resource for training and
benchmarking classical and AI-driven RM algorithms. Finally, to demonstrate
LiHRA's utility, we introduce an RM method that quantifies the risk level in
each scenario over time. This method leverages contextual information,
including robot states and the dynamic model of the robot. With its combination
of high-resolution LiDAR data, precise human tracking, robot state data, and
realistic collision events, LiHRA offers an essential foundation for future
research into real-time RM and adaptive safety strategies in human-robot
workspaces.

</details>


### [40] [T-araVLN: Translator for Agricultural Robotic Agents on Vision-and-Language Navigation](https://arxiv.org/abs/2509.06644)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: T-araVLN方法通过指令翻译模块改进农业机器人导航，在A2A基准测试中将成功率从0.47提升到0.63，导航误差从2.91m降低到2.28m


<details>
  <summary>Details</summary>
Motivation: 现有的AgriVLN方法在处理复杂指令时容易误解，农业机器人导航仍然依赖人工操作或固定轨道，需要更精确的指令理解能力

Method: 提出T-araVLN方法，包含指令翻译模块，能够将原始指令翻译为更精确和精炼的指令，提高导航准确性

Result: 在A2A基准测试中，成功率(SR)从0.47提升到0.63，导航误差(NE)从2.91m降低到2.28m，达到农业领域的最先进性能

Conclusion: T-araVLN通过指令翻译有效解决了复杂指令理解问题，显著提升了农业机器人的视觉语言导航性能

Abstract: Agricultural robotic agents have been becoming powerful helpers in a wide
range of agricultural tasks, nevertheless, still heavily rely on manual
operation or untransportable railway for movement. The AgriVLN method and the
A2A benchmark pioneeringly extend Vision-and-Language Navigation (VLN) to the
agricultural domain, enabling agents navigate to the target position following
the natural language instructions. AgriVLN effectively understands the simple
instructions, however, often misunderstands the complicated instructions. To
bridge this gap, we propose the method of Translator for Agricultural Robotic
Agents on Vision-and-Language Navigation (T-araVLN), in which the Instruction
Translator module translates the original instruction to be both refined and
precise. Being evaluated on the A2A benchmark, our T-araVLN effectively
improves SR from 0.47 to 0.63 and reduces NE from 2.91m to 2.28m, demonstrating
the state-of-the-art performance in the agricultural domain. Code:
https://github.com/AlexTraveling/T-araVLN.

</details>


### [41] [An Adaptive Coverage Control Approach for Multiple Autonomous Off-road Vehicles in Dynamic Agricultural Fields](https://arxiv.org/abs/2509.06682)
*Sajad Ahmadi,Mohammadreza Davoodi,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 基于UAV隐私检测的动态农业环境遥控覆盖控制方法，通过动态图表模型和路径优化提高UGV在动态障碍环境中的覆盖效率


<details>
  <summary>Details</summary>
Motivation: 传统覆盖控制方法假设静态环境，不适用于农业场景中的动态障碍（如移动机械、不平地形）带来的持续挑战

Method: 集成UAV进行障碍检测和地形评估，将环境建模为权重有向图，边权重根据UAV观测动态更新，结合Voronoi分区、适应性边权重分配和成本基于路径优化

Result: 模拟结果表明方法能够有效改善路径规划、降低遍历成本，并在动态障碍和泥活地形中保持稳健的覆盖性能

Conclusion: 该方法为动态农业环境提供了一种有效的实时覆盖控制解决方案，通过空地协同和动态图表模型显著提升了遥控车辆在复杂环境中的应性能和效率

Abstract: This paper presents an adaptive coverage control method for a fleet of
off-road and Unmanned Ground Vehicles (UGVs) operating in dynamic
(time-varying) agricultural environments. Traditional coverage control
approaches often assume static conditions, making them unsuitable for
real-world farming scenarios where obstacles, such as moving machinery and
uneven terrains, create continuous challenges. To address this, we propose a
real-time path planning framework that integrates Unmanned Aerial Vehicles
(UAVs) for obstacle detection and terrain assessment, allowing UGVs to
dynamically adjust their coverage paths. The environment is modeled as a
weighted directed graph, where the edge weights are continuously updated based
on the UAV observations to reflect obstacle motion and terrain variations. The
proposed approach incorporates Voronoi-based partitioning, adaptive edge weight
assignment, and cost-based path optimization to enhance navigation efficiency.
Simulation results demonstrate the effectiveness of the proposed method in
improving path planning, reducing traversal costs, and maintaining robust
coverage in the presence of dynamic obstacles and muddy terrains.

</details>


### [42] [Safe Robust Predictive Control-based Motion Planning of Automated Surface Vessels in Inland Waterways](https://arxiv.org/abs/2509.06687)
*Sajad Ahmadi,Hossein Nejatbakhsh Esfahani,Javad Mohammadpour Velni*

Main category: cs.RO

TL;DR: 基于稳健模型预测控制和控制障碍函数的自动水面船舶运动规划方法，解决内河水域窄窄给航行挑战


<details>
  <summary>Details</summary>
Motivation: 内河水域自动航行可以减载路交压力和排放，但现有方法在窄水域环境中缺乏稳健性和精度

Method: 结合稳健模型预测控制(RMPC)和控制障碍函数(CBFs)，将水道边界和障碍物作为安全约束整合到控制框架中

Result: 模拟结果证明方法在实际条件下能够安全导航自动船舶，并且比现有技术更安全、更适应性更强

Conclusion: 提出的RMPC-CBF方法为内河水域自动船舶安全航行提供了有效的解决方案，具有更高的安全性和适应能力

Abstract: Deploying self-navigating surface vessels in inland waterways offers a
sustainable alternative to reduce road traffic congestion and emissions.
However, navigating confined waterways presents unique challenges, including
narrow channels, higher traffic density, and hydrodynamic disturbances.
Existing methods for autonomous vessel navigation often lack the robustness or
precision required for such environments. This paper presents a new motion
planning approach for Automated Surface Vessels (ASVs) using Robust Model
Predictive Control (RMPC) combined with Control Barrier Functions (CBFs). By
incorporating channel borders and obstacles as safety constraints within the
control design framework, the proposed method ensures both collision avoidance
and robust navigation on complex waterways. Simulation results demonstrate the
efficacy of the proposed method in safely guiding ASVs under realistic
conditions, highlighting its improved safety and adaptability compared to the
state-of-the-art.

</details>


### [43] [Embodied Hazard Mitigation using Vision-Language Models for Autonomous Mobile Robots](https://arxiv.org/abs/2509.06768)
*Oluwadamilola Sotomi,Devika Kodi,Kiruthiga Chandra Shekar,Aliasghar Arab*

Main category: cs.RO

TL;DR: 这篇论文提出了一种多模态异常检测与缓解系统，通过整合视觉-语言模型和大语言模型，实现自主机器人在动态环境中的实时异常识别、报告和缓解能力。


<details>
  <summary>Details</summary>
Motivation: 自主机器人在动态环境中应该能够识别并报告异常情况，主动性的缓解措施能够提高安全性和运营连续性。

Method: 系统整合视觉-语言模型和大语言模型，将危险和冲突状态纳入机器人决策框架，每种异常类型都能触发特定的缓解策略。采用边缘AI架构实现低延迟响应。

Result: 用户研究（n=30）显示系统在异常检测上具有91.2%的预测准确率，并且具有相对较低的响应延迟时间。

Conclusion: 该系统能够有效地让机器人感知、解释、报告并在可能时响应城市和环境异常，通过主动检测机制和自动化缓解行动提高安全性和操作连续性。

Abstract: Autonomous robots operating in dynamic environments should identify and
report anomalies. Embodying proactive mitigation improves safety and
operational continuity. This paper presents a multimodal anomaly detection and
mitigation system that integrates vision-language models and large language
models to identify and report hazardous situations and conflicts in real-time.
The proposed system enables robots to perceive, interpret, report, and if
possible respond to urban and environmental anomalies through proactive
detection mechanisms and automated mitigation actions. A key contribution in
this paper is the integration of Hazardous and Conflict states into the robot's
decision-making framework, where each anomaly type can trigger specific
mitigation strategies. User studies (n = 30) demonstrated the effectiveness of
the system in anomaly detection with 91.2% prediction accuracy and relatively
low latency response times using edge-ai architecture.

</details>


### [44] [CRISP -- Compliant ROS2 Controllers for Learning-Based Manipulation Policies and Teleoperation](https://arxiv.org/abs/2509.06819)
*Daniel San José Pro,Oliver Hausdörfer,Ralf Römer,Maximilian Dösch,Martin Schuck,Angela P. Schöllig*

Main category: cs.RO

TL;DR: CRISP是一个轻量级的C++合规控制器实现，用于ROS2控制标准，为学习型策略提供平滑的底层控制接口


<details>
  <summary>Details</summary>
Motivation: 学习型控制器（如扩散策略和视觉语言动作模型）通常产生低频或不连续的机器人状态变化，需要底层控制器来实现平滑的参考跟踪和合规接触行为

Method: 开发了兼容笛卡尔空间和关节空间的合规控制器，支持任何暴露关节扭矩接口的机械臂，提供Python和Gymnasium接口实现统一的数据记录和策略部署管道

Result: 系统已在Franka FR3硬件以及Kuka IIWA14和Kinova Gen3仿真环境中验证，实现了快速集成、灵活部署和实时性能

Conclusion: CRISP为ROS2兼容机械臂上的学习型方法应用提供了统一的数据收集和策略执行管道，降低了应用门槛

Abstract: Learning-based controllers, such as diffusion policies and vision-language
action models, often generate low-frequency or discontinuous robot state
changes. Achieving smooth reference tracking requires a low-level controller
that converts high-level targets commands into joint torques, enabling
compliant behavior during contact interactions. We present CRISP, a lightweight
C++ implementation of compliant Cartesian and joint-space controllers for the
ROS2 control standard, designed for seamless integration with high-level
learning-based policies as well as teleoperation. The controllers are
compatible with any manipulator that exposes a joint-torque interface. Through
our Python and Gymnasium interfaces, CRISP provides a unified pipeline for
recording data from hardware and simulation and deploying high-level
learning-based policies seamlessly, facilitating rapid experimentation. The
system has been validated on hardware with the Franka Robotics FR3 and in
simulation with the Kuka IIWA14 and Kinova Gen3. Designed for rapid
integration, flexible deployment, and real-time performance, our implementation
provides a unified pipeline for data collection and policy execution, lowering
the barrier to applying learning-based methods on ROS2-compatible manipulators.
Detailed documentation is available at the project website -
https://utiasDSL.github.io/crisp_controllers.

</details>


### [45] [Dynamic Modeling and Efficient Data-Driven Optimal Control for Micro Autonomous Surface Vehicles](https://arxiv.org/abs/2509.06882)
*Zhiheng Chen,Wei Wang*

Main category: cs.RO

TL;DR: 本文提出了一种基于物理驱动模型和数据驱动在线学习的优化控制框架，用于提升微型自主水面艇(MicroASV)在受限水域的轨迹跟踪精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 微型自主水面艇在受限水域和群体机器人应用中具有巨大潜力，但由于非线性水动力建模复杂、对自运动效应和环境扰动敏感，实现精确鲁棒控制极具挑战。

Method: 结合物理驱动动力学模型和数据驱动最优控制框架，采用基于弱形式的在线模型学习方法，实时优化物理模型参数，实现自适应控制。

Result: 仿真结果表明，该方法显著提高了轨迹跟踪精度和鲁棒性，即使在未知载荷和外部扰动条件下也能保持良好性能。

Conclusion: 数据驱动在线学习的最优控制方法能够有效提升MicroASV性能，为更可靠精确的自主水面艇操作铺平道路。

Abstract: Micro Autonomous Surface Vehicles (MicroASVs) offer significant potential for
operations in confined or shallow waters and swarm robotics applications.
However, achieving precise and robust control at such small scales remains
highly challenging, mainly due to the complexity of modeling nonlinear
hydrodynamic forces and the increased sensitivity to self-motion effects and
environmental disturbances, including waves and boundary effects in confined
spaces. This paper presents a physics-driven dynamics model for an
over-actuated MicroASV and introduces a data-driven optimal control framework
that leverages a weak formulation-based online model learning method. Our
approach continuously refines the physics-driven model in real time, enabling
adaptive control that adjusts to changing system parameters. Simulation results
demonstrate that the proposed method substantially enhances trajectory tracking
accuracy and robustness, even under unknown payloads and external disturbances.
These findings highlight the potential of data-driven online learning-based
optimal control to improve MicroASV performance, paving the way for more
reliable and precise autonomous surface vehicle operations.

</details>


### [46] [LLaDA-VLA: Vision Language Diffusion Action Models](https://arxiv.org/abs/2509.06932)
*Yuqing Wen,Hebei Li,Kefan Gu,Yucheng Zhao,Tiancai Wang,Xiaoyan Sun*

Main category: cs.RO

TL;DR: LLaDA-VLA是首个基于预训练扩散视觉语言模型(d-VLMs)构建的视觉-语言-扩散-动作模型，用于机器人操作任务，通过局部特殊令牌分类和分层动作结构解码策略，在仿真和真实机器人上显著优于现有VLA方法。


<details>
  <summary>Details</summary>
Motivation: 虽然基于掩码扩散模型的d-VLMs在文本生成和多模态应用中表现出色，但将其用于机器人策略学习仍未被充分探索。本文旨在利用d-VLMs的优势来解决机器人操作问题。

Method: 提出LLaDA-VLA模型，采用两种关键设计：(1)局部特殊令牌分类策略，用特殊动作令牌分类替代全词汇分类，降低适应难度；(2)分层动作结构解码策略，考虑动作内部和跨动作的依赖关系进行分层解码。

Result: 大量实验表明，LLaDA-VLA在仿真和真实机器人上都显著优于最先进的VLA方法。

Conclusion: LLaDA-VLA成功将扩散视觉语言模型应用于机器人操作领域，通过创新的适应策略实现了优异的性能表现，为扩散模型在机器人控制中的应用开辟了新途径。

Abstract: The rapid progress of auto-regressive vision-language models (VLMs) has
inspired growing interest in vision-language-action models (VLA) for robotic
manipulation. Recently, masked diffusion models, a paradigm distinct from
autoregressive models, have begun to demonstrate competitive performance in
text generation and multimodal applications, leading to the development of a
series of diffusion-based VLMs (d-VLMs). However, leveraging such models for
robot policy learning remains largely unexplored. In this work, we present
LLaDA-VLA, the first Vision-Language-Diffusion-Action model built upon
pretrained d-VLMs for robotic manipulation. To effectively adapt d-VLMs to
robotic domain, we introduce two key designs: (1) a localized special-token
classification strategy that replaces full-vocabulary classification with
special action token classification, reducing adaptation difficulty; (2) a
hierarchical action-structured decoding strategy that decodes action sequences
hierarchically considering the dependencies within and across actions.
Extensive experiments demonstrate that LLaDA-VLA significantly outperforms
state-of-the-art VLAs on both simulation and real-world robots.

</details>


### [47] [F1: A Vision-Language-Action Model Bridging Understanding and Generation to Actions](https://arxiv.org/abs/2509.06951)
*Qi Lv,Weijie Kong,Hao Li,Jia Zeng,Zherui Qiu,Delin Qu,Haoming Song,Qizhi Chen,Xiang Deng,Jiangmiao Pang*

Main category: cs.RO

TL;DR: F1是一个预训练的视觉-语言-动作框架，通过集成视觉前瞻生成到决策流程中，解决了现有VLA模型在动态环境中短视行为的问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型主要采用反应式的状态到动作映射，在动态场景中容易产生短视行为且鲁棒性差，需要一种能够进行前瞻性规划的方法。

Method: 采用混合Transformer架构，包含感知、前瞻生成和控制模块，通过下一尺度预测机制合成目标条件化的视觉前瞻作为显式规划目标，将动作生成重新表述为前瞻引导的逆动力学问题。

Result: 在真实世界任务和仿真基准测试中，F1始终优于现有方法，在任务成功率和泛化能力方面都取得了显著提升。

Conclusion: F1框架通过集成视觉前瞻生成，成功解决了动态视觉环境中语言条件化任务的执行挑战，为具身AI提供了更鲁棒和通用的解决方案。

Abstract: Executing language-conditioned tasks in dynamic visual environments remains a
central challenge in embodied AI. Existing Vision-Language-Action (VLA) models
predominantly adopt reactive state-to-action mappings, often leading to
short-sighted behaviors and poor robustness in dynamic scenes. In this paper,
we introduce F1, a pretrained VLA framework which integrates the visual
foresight generation into decision-making pipeline. F1 adopts a
Mixture-of-Transformer architecture with dedicated modules for perception,
foresight generation, and control, thereby bridging understanding, generation,
and actions. At its core, F1 employs a next-scale prediction mechanism to
synthesize goal-conditioned visual foresight as explicit planning targets. By
forecasting plausible future visual states, F1 reformulates action generation
as a foresight-guided inverse dynamics problem, enabling actions that
implicitly achieve visual goals. To endow F1 with robust and generalizable
capabilities, we propose a three-stage training recipe on an extensive dataset
comprising over 330k trajectories across 136 diverse tasks. This training
scheme enhances modular reasoning and equips the model with transferable visual
foresight, which is critical for complex and dynamic environments. Extensive
evaluations on real-world tasks and simulation benchmarks demonstrate F1
consistently outperforms existing approaches, achieving substantial gains in
both task success rate and generalization ability.

</details>


### [48] [Deep Reactive Policy: Learning Reactive Manipulator Motion Planning for Dynamic Environments](https://arxiv.org/abs/2509.06953)
*Jiahui Yang,Jason Jingzhou Liu,Yulong Li,Youssef Khaky,Kenneth Shaw,Deepak Pathak*

Main category: cs.RO

TL;DR: DRP是一个视觉-运动神经运动策略，用于在动态环境中生成反应式运动，结合了预训练的transformer策略和局部反应式模块，在复杂动态场景中表现出色


<details>
  <summary>Details</summary>
Motivation: 解决动态部分可观测环境中机械臂无碰撞运动的挑战，传统运动规划器需要完整环境知识且速度慢，神经运动策略在复杂动态环境中泛化能力不足

Method: 提出Deep Reactive Policy (DRP)，核心是IMPACT transformer神经运动策略（在1000万专家轨迹上预训练），通过迭代师生微调改进静态障碍物避让，使用DCP-RMP局部反应式目标提议模块增强动态障碍物避让

Result: DRP在杂乱场景、动态移动障碍物和目标遮挡等挑战性任务中表现出强泛化能力，在仿真和真实环境中均优于传统和神经方法

Conclusion: DRP通过结合预训练transformer策略和局部反应式模块，成功解决了动态部分可观测环境中的运动规划问题，为机器人操作提供了有效的解决方案

Abstract: Generating collision-free motion in dynamic, partially observable
environments is a fundamental challenge for robotic manipulators. Classical
motion planners can compute globally optimal trajectories but require full
environment knowledge and are typically too slow for dynamic scenes. Neural
motion policies offer a promising alternative by operating in closed-loop
directly on raw sensory inputs but often struggle to generalize in complex or
dynamic settings. We propose Deep Reactive Policy (DRP), a visuo-motor neural
motion policy designed for reactive motion generation in diverse dynamic
environments, operating directly on point cloud sensory input. At its core is
IMPACT, a transformer-based neural motion policy pretrained on 10 million
generated expert trajectories across diverse simulation scenarios. We further
improve IMPACT's static obstacle avoidance through iterative student-teacher
finetuning. We additionally enhance the policy's dynamic obstacle avoidance at
inference time using DCP-RMP, a locally reactive goal-proposal module. We
evaluate DRP on challenging tasks featuring cluttered scenes, dynamic moving
obstacles, and goal obstructions. DRP achieves strong generalization,
outperforming prior classical and neural methods in success rate across both
simulated and real-world settings. Video results and code available at
https://deep-reactive-policy.com

</details>
