<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 21]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [Solving the Constrained Random Disambiguation Path Problem via Lagrangian Relaxation and Graph Reduction](https://arxiv.org/abs/2507.06346)
*Li Zhou,Elvan Ceyhan*

Main category: cs.RO

TL;DR: 研究了资源受限的随机消歧路径（RDP）问题，提出了一种结合拉格朗日松弛和两阶段顶点消除（TPVE）的新算法框架COLOGR，解决了带约束的最短路径问题，并在实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决在不确定障碍物环境中导航的资源受限路径规划问题，优化消歧成本与路径风险。

Method: 将问题建模为带权重约束的最短路径问题（WCSPP），提出COLOGR框架，结合拉格朗日松弛和TPVE方法，修剪不可行和次优路径。

Result: COLOGR在多种场景下表现优异，接近离线最优解，且计算复杂度优于现有方法。

Conclusion: COLOGR是一种高效且通用的框架，适用于随机网络设计、移动规划和不确定环境下的决策问题。

Abstract: We study a resource-constrained variant of the Random Disambiguation Path
(RDP) problem, a generalization of the Stochastic Obstacle Scene (SOS) problem,
in which a navigating agent must reach a target in a spatial environment
populated with uncertain obstacles. Each ambiguous obstacle may be
disambiguated at a (possibly) heterogeneous resource cost, subject to a global
disambiguation budget. We formulate this constrained planning problem as a
Weight-Constrained Shortest Path Problem (WCSPP) with risk-adjusted edge costs
that incorporate probabilistic blockage and traversal penalties. To solve it,
we propose a novel algorithmic framework-COLOGR-combining Lagrangian relaxation
with a two-phase vertex elimination (TPVE) procedure. The method prunes
infeasible and suboptimal paths while provably preserving the optimal solution,
and leverages dual bounds to guide efficient search. We establish correctness,
feasibility guarantees, and surrogate optimality under mild assumptions. Our
analysis also demonstrates that COLOGR frequently achieves zero duality gap and
offers improved computational complexity over prior constrained path-planning
methods. Extensive simulation experiments validate the algorithm's robustness
across varying obstacle densities, sensor accuracies, and risk models,
consistently outperforming greedy baselines and approaching offline-optimal
benchmarks. The proposed framework is broadly applicable to stochastic network
design, mobility planning, and constrained decision-making under uncertainty.

</details>


### [2] [Mapping the Catacombs: An Underwater Cave Segment of the Devil's Eye System](https://arxiv.org/abs/2507.06397)
*Michalis Chatzispyrou,Luke Horgan,Hyunkil Hwang,Harish Sathishchandra,Monika Roznere,Alberto Quattrini Li,Philippos Mordohai,Ioannis Rekleitis*

Main category: cs.RO

TL;DR: 提出了一种利用低成本运动相机和潜水电脑绘制水下洞穴地图的框架，结合视觉/惯性框架和全局优化技术，生成洞穴的一维轨迹和密集3D重建。


<details>
  <summary>Details</summary>
Motivation: 水下洞穴对淡水资源管理、水下考古和水文地质学至关重要，绘制其轮廓和尺寸以及创建逼真的3D地图有助于更好地理解这一水下领域。

Method: 使用运动相机和潜水电脑估计相机轨迹和稀疏点云，结合SVIn2视觉/惯性框架和COLMAP全局优化技术，生成洞穴的一维轨迹和密集3D重建。

Result: 成功绘制了Devil's Eye洞穴系统的一段，并通过手动测量验证了方法的有效性。

Conclusion: 低成本运动相机结合先进算法可有效绘制水下洞穴地图，并为特定区域生成逼真的3D重建。

Abstract: This paper presents a framework for mapping underwater caves. Underwater
caves are crucial for fresh water resource management, underwater archaeology,
and hydrogeology. Mapping the cave's outline and dimensions, as well as
creating photorealistic 3D maps, is critical for enabling a better
understanding of this underwater domain. In this paper, we present the mapping
of an underwater cave segment (the catacombs) of the Devil's Eye cave system at
Ginnie Springs, FL. We utilized a set of inexpensive action cameras in
conjunction with a dive computer to estimate the trajectories of the cameras
together with a sparse point cloud. The resulting reconstructions are utilized
to produce a one-dimensional retract of the cave passages in the form of the
average trajectory together with the boundaries (top, bottom, left, and right).
The use of the dive computer enables the observability of the z-dimension in
addition to the roll and pitch in a visual/inertial framework (SVIn2). In
addition, the keyframes generated by SVIn2 together with the estimated camera
poses for select areas are used as input to a global optimization (bundle
adjustment) framework -- COLMAP -- in order to produce a dense reconstruction
of those areas. The same cave segment is manually surveyed using the MNemo V2
instrument, providing an additional set of measurements validating the proposed
approach. It is worth noting that with the use of action cameras, the primary
components of a cave map can be constructed. Furthermore, with the utilization
of a global optimization framework guided by the results of VI-SLAM package
SVIn2, photorealistic dense 3D representations of selected areas can be
reconstructed.

</details>


### [3] [Learning to Evaluate Autonomous Behaviour in Human-Robot Interaction](https://arxiv.org/abs/2507.06404)
*Matteo Tiezzi,Tommaso Apicella,Carlos Cardenas-Perez,Giovanni Fregonese,Stefano Dafarra,Pietro Morerio,Daniele Pucci,Alessio Del Bue*

Main category: cs.RO

TL;DR: 提出了一种基于轨迹性能的模仿学习方法评估框架，通过NeME模型比较机器人控制策略，无需人类参与。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人性能评估中成功率难以复现和轨迹复杂度未充分捕捉的问题。

Method: 设计了NeME深度学习模型，用于从关节轨迹分类动作，作为元评估器比较控制策略。

Result: 实验表明，该方法与机器人上的成功率更一致，优于基线方法。

Conclusion: 该框架为复杂HRI任务中的多模态模仿学习方法提供了可复现、系统化的评估手段。

Abstract: Evaluating and comparing the performance of autonomous Humanoid Robots is
challenging, as success rate metrics are difficult to reproduce and fail to
capture the complexity of robot movement trajectories, critical in Human-Robot
Interaction and Collaboration (HRIC). To address these challenges, we propose a
general evaluation framework that measures the quality of Imitation Learning
(IL) methods by focusing on trajectory performance. We devise the Neural Meta
Evaluator (NeME), a deep learning model trained to classify actions from robot
joint trajectories. NeME serves as a meta-evaluator to compare the performance
of robot control policies, enabling policy evaluation without requiring human
involvement in the loop. We validate our framework on ergoCub, a humanoid
robot, using teleoperation data and comparing IL methods tailored to the
available platform. The experimental results indicate that our method is more
aligned with the success rate obtained on the robot than baselines, offering a
reproducible, systematic, and insightful means for comparing the performance of
multimodal imitation learning approaches in complex HRI tasks.

</details>


### [4] [Evaluating Robots Like Human Infants: A Case Study of Learned Bipedal Locomotion](https://arxiv.org/abs/2507.06426)
*Devin Crowley,Whitney G. Cole,Christina M. Hospodar,Ruiting Shen,Karen E. Adolph,Alan Fern*

Main category: cs.RO

TL;DR: 论文提出了一种将发展心理学方法应用于机器人行为学习的研究，通过系统化训练和精细测量，揭示了训练方案对机器人行为的影响。


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制器的训练和评估方法缺乏系统性，无法深入了解训练方案对行为的影响，而发展心理学的方法可以提供更精细的测量。

Method: 采用发展心理学的方法，设计系统化的强化学习训练方案，并在模拟环境中测试双足机器人Cassie的行为。

Result: 研究揭示了不同训练方案对行为的影响，并将Cassie的学习行为与婴儿学步行为进行了对比。

Conclusion: 这种跨学科的方法为未来系统化研究复杂机器人行为的发展提供了新思路。

Abstract: Typically, learned robot controllers are trained via relatively unsystematic
regimens and evaluated with coarse-grained outcome measures such as average
cumulative reward. The typical approach is useful to compare learning
algorithms but provides limited insight into the effects of different training
regimens and little understanding about the richness and complexity of learned
behaviors. Likewise, human infants and other animals are "trained" via
unsystematic regimens, but in contrast, developmental psychologists evaluate
their performance in highly-controlled experiments with fine-grained measures
such as success, speed of walking, and prospective adjustments. However, the
study of learned behavior in human infants is limited by the practical
constraints of training and testing babies. Here, we present a case study that
applies methods from developmental psychology to study the learned behavior of
the simulated bipedal robot Cassie. Following research on infant walking, we
systematically designed reinforcement learning training regimens and tested the
resulting controllers in simulated environments analogous to those used for
babies--but without the practical constraints. Results reveal new insights into
the behavioral impact of different training regimens and the development of
Cassie's learned behaviors relative to infants who are learning to walk. This
interdisciplinary baby-robot approach provides inspiration for future research
designed to systematically test effects of training on the development of
complex learned robot behaviors.

</details>


### [5] [Failure Forecasting Boosts Robustness of Sim2Real Rhythmic Insertion Policies](https://arxiv.org/abs/2507.06519)
*Yuhan Liu,Xinyu Zhang,Haonan Chang,Abdeslam Boularias*

Main category: cs.RO

TL;DR: 提出了一种基于强化学习的sim-to-real框架，用于解决高精度重复插入任务（RIT）的挑战，结合失败预测模块提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人执行高精度重复插入任务时的毫米级精度和一致性挑战，尤其是螺母旋转和摩擦带来的复杂性。

Method: 采用sim-to-real框架，结合强化学习插入策略和失败预测模块，通过螺母坐标系表示扳手姿态提升迁移性。

Result: 在仿真和真实环境中均实现高一次性成功率，并在长期重复任务中保持稳定性能。

Conclusion: 提出的方法有效提升了RIT任务的精度和鲁棒性，适用于复杂环境下的长期重复操作。

Abstract: This paper addresses the challenges of Rhythmic Insertion Tasks (RIT), where
a robot must repeatedly perform high-precision insertions, such as screwing a
nut into a bolt with a wrench. The inherent difficulty of RIT lies in achieving
millimeter-level accuracy and maintaining consistent performance over multiple
repetitions, particularly when factors like nut rotation and friction introduce
additional complexity. We propose a sim-to-real framework that integrates a
reinforcement learning-based insertion policy with a failure forecasting
module. By representing the wrench's pose in the nut's coordinate frame rather
than the robot's frame, our approach significantly enhances sim-to-real
transferability. The insertion policy, trained in simulation, leverages
real-time 6D pose tracking to execute precise alignment, insertion, and
rotation maneuvers. Simultaneously, a neural network predicts potential
execution failures, triggering a simple recovery mechanism that lifts the
wrench and retries the insertion. Extensive experiments in both simulated and
real-world environments demonstrate that our method not only achieves a high
one-time success rate but also robustly maintains performance over long-horizon
repetitive tasks.

</details>


### [6] [KLEIYN : A Quadruped Robot with an Active Waist for Both Locomotion and Wall Climbing](https://arxiv.org/abs/2507.06562)
*Keita Yoneda,Kento Kawaharazuka,Temma Suzuki,Takahiro Hattori,Kei Okada*

Main category: cs.RO

TL;DR: 本研究开发了具有腰部关节的四足机器人KLEIYN，通过强化学习实现垂直运动（如烟囱攀爬），并引入接触引导课程学习（CGCL）方法。机器人成功以150 mm/s的速度攀爬800-1000 mm宽的墙壁，速度是传统机器人的50倍。腰部关节显著提升了攀爬性能。


<details>
  <summary>Details</summary>
Motivation: 尽管四足机器人在硬件和控制方面取得进展，但在具有显著高度变化的崎岖地形中实现稳定垂直运动仍是一个未解决的问题。

Method: 开发了具有腰部关节的机器人KLEIYN，并采用强化学习和接触引导课程学习（CGCL）方法训练其垂直运动能力。

Result: KLEIYN能以150 mm/s的速度攀爬800-1000 mm宽的墙壁，速度是传统机器人的50倍。腰部关节显著提升了在狭窄墙壁上的跟踪能力。

Conclusion: 通过腰部关节和CGCL方法，四足机器人能够高效完成垂直运动任务，为复杂地形下的自动化应用提供了新可能。

Abstract: In recent years, advancements in hardware have enabled quadruped robots to
operate with high power and speed, while robust locomotion control using
reinforcement learning (RL) has also been realized. As a result, expectations
are rising for the automation of tasks such as material transport and
exploration in unknown environments. However, autonomous locomotion in rough
terrains with significant height variations requires vertical movement, and
robots capable of performing such movements stably, along with their control
methods, have not yet been fully established. In this study, we developed the
quadruped robot KLEIYN, which features a waist joint, and aimed to expand
quadruped locomotion by enabling chimney climbing through RL. To facilitate the
learning of vertical motion, we introduced Contact-Guided Curriculum Learning
(CGCL). As a result, KLEIYN successfully climbed walls ranging from 800 mm to
1000 mm in width at an average speed of 150 mm/s, 50 times faster than
conventional robots. Furthermore, we demonstrated that the introduction of a
waist joint improves climbing performance, particularly enhancing tracking
ability on narrow walls.

</details>


### [7] [SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments](https://arxiv.org/abs/2507.06564)
*Tianshun Li,Tianyi Huai,Zhen Li,Yichun Gao,Haoang Li,Xinhu Zheng*

Main category: cs.RO

TL;DR: SkyVLN框架结合视觉语言导航（VLN）和非线性模型预测控制（NMPC），提升无人机在复杂城市环境中的自主导航能力。


<details>
  <summary>Details</summary>
Motivation: 无人机在复杂城市环境中的导航面临挑战，传统方法难以处理动态3D空间和自然语言指令。

Method: SkyVLN利用大语言模型（LLMs）解析指令和视觉观察，结合空间语言化器和历史路径记忆机制，以及NMPC模块实现动态避障。

Result: 实验表明，SkyVLN显著提高了导航成功率和效率，尤其在陌生环境中。

Conclusion: SkyVLN为无人机在复杂环境中的自主导航提供了高效、鲁棒的解决方案。

Abstract: Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across
various sectors, driven by their mobility and adaptability. This paper
introduces SkyVLN, a novel framework integrating vision-and-language navigation
(VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in
complex urban environments. Unlike traditional navigation methods, SkyVLN
leverages Large Language Models (LLMs) to interpret natural language
instructions and visual observations, enabling UAVs to navigate through dynamic
3D spaces with improved accuracy and robustness. We present a multimodal
navigation agent equipped with a fine-grained spatial verbalizer and a history
path memory mechanism. These components allow the UAV to disambiguate spatial
contexts, handle ambiguous instructions, and backtrack when necessary. The
framework also incorporates an NMPC module for dynamic obstacle avoidance,
ensuring precise trajectory tracking and collision prevention. To validate our
approach, we developed a high-fidelity 3D urban simulation environment using
AirSim, featuring realistic imagery and dynamic urban elements. Extensive
experiments demonstrate that SkyVLN significantly improves navigation success
rates and efficiency, particularly in new and unseen environments.

</details>


### [8] [AI Space Cortex: An Experimental System for Future Era Space Exploration](https://arxiv.org/abs/2507.06574)
*Thomas Touma,Ersin Daş,Erica Tevere,Martin Feather,Ksenia Kolcio,Maurice Prather,Alberto Candela,Ashish Goel,Erik Kramer,Hari Nayar,Lorraine Fesq,Joel W. Burdick*

Main category: cs.RO

TL;DR: REASIMO项目旨在为NASA的COLDTech计划开发AI辅助的自主系统，以应对冰卫星任务中的通信延迟、能源限制和辐射等挑战，实现异常检测与恢复，并通过预训练行为执行任务。


<details>
  <summary>Details</summary>
Motivation: 冰卫星任务（如欧罗巴和恩塞拉多斯）面临通信延迟、能源限制和恶劣环境等挑战，传统安全模式无法满足任务需求，需开发自主系统以应对异常并完成任务。

Method: 结合AI技术和预训练行为，开发了一个智能框架，用于任务控制和异常处理，并在NASA喷气推进实验室的测试平台上验证自主采样操作。

Result: 测试表明，该框架能够有效检测和恢复异常，并在模拟的冰卫星表面条件下执行任务。

Conclusion: REASIMO框架为未来冰卫星任务提供了强大的自主能力，解决了传统方法的局限性，有望提升任务成功率和科学目标达成。

Abstract: Our Robust, Explainable Autonomy for Scientific Icy Moon Operations (REASIMO)
effort contributes to NASA's Concepts for Ocean worlds Life Detection
Technology (COLDTech) program, which explores science platform technologies for
ocean worlds such as Europa and Enceladus. Ocean world missions pose
significant operational challenges. These include long communication lags,
limited power, and lifetime limitations caused by radiation damage and hostile
conditions. Given these operational limitations, onboard autonomy will be vital
for future Ocean world missions. Besides the management of nominal lander
operations, onboard autonomy must react appropriately in the event of
anomalies. Traditional spacecraft rely on a transition into 'safe-mode' in
which non-essential components and subsystems are powered off to preserve
safety and maintain communication with Earth. For a severely time-limited Ocean
world mission, resolutions to these anomalies that can be executed without
Earth-in-the-loop communication and associated delays are paramount for
completion of the mission objectives and science goals. To address these
challenges, the REASIMO effort aims to demonstrate a robust level of
AI-assisted autonomy for such missions, including the ability to detect and
recover from anomalies, and to perform missions based on pre-trained behaviors
rather than hard-coded, predetermined logic like all prior space missions. We
developed an AI-assisted, personality-driven, intelligent framework for control
of an Ocean world mission by combining a mix of advanced technologies. To
demonstrate the capabilities of the framework, we perform tests of autonomous
sampling operations on a lander-manipulator testbed at the NASA Jet Propulsion
Laboratory, approximating possible surface conditions such a mission might
encounter.

</details>


### [9] [Growing Trees with an Agent: Accelerating RRTs with Learned, Multi-Step Episodic Exploration](https://arxiv.org/abs/2507.06605)
*Xinyu Wu*

Main category: cs.RO

TL;DR: Episodic RRT (ERRT) 是一种新型混合规划框架，通过深度强化学习生成多步探索片段，显著提升了采样运动规划的效率，在复杂和高维环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统基于采样的运动规划器（如RRT）在高维或复杂环境中效率低下，主要依赖随机采样。

Method: ERRT 使用深度强化学习（DRL）代理生成多步探索片段，替代随机点采样，实现定向探索。

Result: 在2D、3D和6D环境中，ERRT及其变体显著优于传统RRT，6D机械臂场景中成功率从19%提升至98%，速度提升107倍，碰撞检查减少99.6%，路径缩短50%。

Conclusion: ERRT 通过定向探索和高效路径生成，显著提升了运动规划的性能，其最优变体ERRT* 在3D环境中比RRT*快29倍。

Abstract: Classical sampling-based motion planners like the RRTs suffer from
inefficiencies, particularly in cluttered or high-dimensional spaces, due to
their reliance on undirected, random sampling. This paper introduces the
Episodic RRT, a novel hybrid planning framework that replaces the primitive of
a random point with a learned, multi-step "exploratory episode" generated by a
Deep Reinforcement Learning agent. By making the DRL agent the engine of
exploration, ERRT transforms the search process from a diffuse, volumetric
expansion into a directed, branch-like growth. This paradigm shift yields key
advantages: it counters the curse of dimensionality with focused exploration,
minimizes expensive collision checks by proactively proposing locally valid
paths, and improves connectivity by generating inherently connected path
segments. We demonstrate through extensive empirical evaluation across 2D, 3D,
and 6D environments that ERRT and its variants consistently and significantly
outperform their classical counterparts. In a challenging 6D robotic arm
scenario, ERRT achieves a 98% success rate compared to 19% for RRT, is up to
107x faster, reduces collision checks by over 99.6%, and finds initial paths
that are nearly 50% shorter. Furthermore, its asymptotically optimal variant,
ERRT*, demonstrates vastly superior anytime performance, refining solutions to
near-optimality up to 29x faster than standard RRT* in 3D environments. Code:
https://xinyuwuu.github.io/Episodic_RRT/.

</details>


### [10] [Q-STAC: Q-Guided Stein Variational Model Predictive Actor-Critic](https://arxiv.org/abs/2507.06625)
*Shizhe Cai,Jayadeep Jacob,Zeya Yin,Fabio Ramos*

Main category: cs.RO

TL;DR: Q-STAC结合贝叶斯MPC与actor-critic强化学习，通过约束SVGD优化控制序列，提升样本效率与安全性。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习在连续控制任务中的数据需求大、长时规划复杂及安全性不足的问题，同时弥补MPC的局部最优和成本函数设计困难。

Method: 整合贝叶斯MPC与actor-critic强化学习，利用约束SVGD直接优化控制序列，以Q值作为目标，避免显式设计成本函数。

Result: 在2D导航和机器人操作任务中，Q-STAC表现出更高的样本效率、鲁棒性和最优性。

Conclusion: Q-STAC在保持策略分布高表达性的同时，显著提升了性能与安全性。

Abstract: Deep reinforcement learning has shown remarkable success in continuous
control tasks, yet often requires extensive training data, struggles with
complex, long-horizon planning, and fails to maintain safety constraints during
operation. Meanwhile, Model Predictive Control (MPC) offers explainability and
constraint satisfaction, but typically yields only locally optimal solutions
and demands careful cost function design. This paper introduces the Q-guided
STein variational model predictive Actor-Critic (Q-STAC), a novel framework
that bridges these approaches by integrating Bayesian MPC with actor-critic
reinforcement learning through constrained Stein Variational Gradient Descent
(SVGD). Our method optimizes control sequences directly using learned Q-values
as objectives, eliminating the need for explicit cost function design while
leveraging known system dynamics to enhance sample efficiency and ensure
control signals remain within safe boundaries. Extensive experiments on 2D
navigation and robotic manipulation tasks demonstrate that Q-STAC achieves
superior sample efficiency, robustness, and optimality compared to
state-of-the-art algorithms, while maintaining the high expressiveness of
policy distributions. Experiment videos are available on our website:
https://sites.google.com/view/q-stac

</details>


### [11] [Multi-Task Multi-Agent Reinforcement Learning via Skill Graphs](https://arxiv.org/abs/2507.06690)
*Guobin Zhu,Rui Zhou,Wenkang Ji,Hongyin Zhang,Donglin Wang,Shiyu Zhao*

Main category: cs.RO

TL;DR: 提出了一种分层方法，通过技能图和高层模块处理多任务多智能体强化学习中的无关任务问题，提升知识迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有多任务学习方法难以处理无关任务且知识迁移能力有限，需要更高效的方法。

Method: 采用分层方法，高层模块使用技能图，低层模块采用标准MARL算法，训练独立进行。

Result: 实验表明，该方法优于最新的分层MAPPO算法。

Conclusion: 提出的方法有效解决了无关任务问题，提升了知识迁移能力，性能优于现有方法。

Abstract: Multi-task multi-agent reinforcement learning (MT-MARL) has recently gained
attention for its potential to enhance MARL's adaptability across multiple
tasks. However, it is challenging for existing multi-task learning methods to
handle complex problems, as they are unable to handle unrelated tasks and
possess limited knowledge transfer capabilities. In this paper, we propose a
hierarchical approach that efficiently addresses these challenges. The
high-level module utilizes a skill graph, while the low-level module employs a
standard MARL algorithm. Our approach offers two contributions. First, we
consider the MT-MARL problem in the context of unrelated tasks, expanding the
scope of MTRL. Second, the skill graph is used as the upper layer of the
standard hierarchical approach, with training independent of the lower layer,
effectively handling unrelated tasks and enhancing knowledge transfer
capabilities. Extensive experiments are conducted to validate these advantages
and demonstrate that the proposed method outperforms the latest hierarchical
MAPPO algorithms. Videos and code are available at
https://github.com/WindyLab/MT-MARL-SG

</details>


### [12] [Integrating Perceptions: A Human-Centered Physical Safety Model for Human-Robot Interaction](https://arxiv.org/abs/2507.06700)
*Pranav Pandey,Ramviyas Parasuraman,Prashant Doshi*

Main category: cs.RO

TL;DR: 论文提出了一种参数化安全模型，结合个性化参数ρ，以弥合物理安全与主观安全感知之间的差距，并通过实验验证了情感状态、信任和机器人行为对安全感知的影响。


<details>
  <summary>Details</summary>
Motivation: 传统安全模型主要依赖传感器数据，忽略了主观安全感知的个体差异和情境因素，因此需要一种更全面的模型来提升人机交互的安全性。

Method: 通过模拟救援场景的人体实验，研究情感状态、信任和机器人行为对安全感知的影响，并引入参数ρ以量化个体差异。

Result: 参数ρ能有效捕捉个体差异，可预测和一致的机器人行为及积极情感状态显著提升安全感知，且用户可分为少数类型支持个性化适配。

Conclusion: 研究强调了整合心理和行为维度的自适应安全模型的重要性，为安全关键领域的人机交互提供了更可信的解决方案。

Abstract: Ensuring safety in human-robot interaction (HRI) is essential to foster user
trust and enable the broader adoption of robotic systems. Traditional safety
models primarily rely on sensor-based measures, such as relative distance and
velocity, to assess physical safety. However, these models often fail to
capture subjective safety perceptions, which are shaped by individual traits
and contextual factors. In this paper, we introduce and analyze a parameterized
general safety model that bridges the gap between physical and perceived safety
by incorporating a personalization parameter, $\rho$, into the safety
measurement framework to account for individual differences in safety
perception. Through a series of hypothesis-driven human-subject studies in a
simulated rescue scenario, we investigate how emotional state, trust, and robot
behavior influence perceived safety. Our results show that $\rho$ effectively
captures meaningful individual differences, driven by affective responses,
trust in task consistency, and clustering into distinct user types.
Specifically, our findings confirm that predictable and consistent robot
behavior as well as the elicitation of positive emotional states, significantly
enhance perceived safety. Moreover, responses cluster into a small number of
user types, supporting adaptive personalization based on shared safety models.
Notably, participant role significantly shapes safety perception, and repeated
exposure reduces perceived safety for participants in the casualty role,
emphasizing the impact of physical interaction and experiential change. These
findings highlight the importance of adaptive, human-centered safety models
that integrate both psychological and behavioral dimensions, offering a pathway
toward more trustworthy and effective HRI in safety-critical domains.

</details>


### [13] [Spatial-Temporal Aware Visuomotor Diffusion Policy Learning](https://arxiv.org/abs/2507.06710)
*Zhenyang Liu,Yikai Wang,Kuanning Wang,Longfei Liang,Xiangyang Xue,Yanwei Fu*

Main category: cs.RO

TL;DR: 提出了一种名为4D Diffusion Policy (DP4)的新方法，通过动态高斯世界模型增强视觉模仿学习的时空感知能力，显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉模仿学习方法依赖历史轨迹的行为克隆，缺乏3D空间和4D时空感知能力，限制了其在真实世界中的应用。

Method: DP4利用动态高斯世界模型从交互环境中学习3D空间和4D时空感知，通过单视角RGB-D观测构建当前3D场景并预测未来3D场景，优化轨迹生成。

Result: 在17个仿真任务和3个真实机器人任务中，DP4平均任务成功率分别提升16.4%、14%、6.45%和8.6%。

Conclusion: DP4通过增强时空感知能力，显著提升了视觉模仿学习的性能，适用于复杂真实世界任务。

Abstract: Visual imitation learning is effective for robots to learn versatile tasks.
However, many existing methods rely on behavior cloning with supervised
historical trajectories, limiting their 3D spatial and 4D spatiotemporal
awareness. Consequently, these methods struggle to capture the 3D structures
and 4D spatiotemporal relationships necessary for real-world deployment. In
this work, we propose 4D Diffusion Policy (DP4), a novel visual imitation
learning method that incorporates spatiotemporal awareness into diffusion-based
policies. Unlike traditional approaches that rely on trajectory cloning, DP4
leverages a dynamic Gaussian world model to guide the learning of 3D spatial
and 4D spatiotemporal perceptions from interactive environments. Our method
constructs the current 3D scene from a single-view RGB-D observation and
predicts the future 3D scene, optimizing trajectory generation by explicitly
modeling both spatial and temporal dependencies. Extensive experiments across
17 simulation tasks with 173 variants and 3 real-world robotic tasks
demonstrate that the 4D Diffusion Policy (DP4) outperforms baseline methods,
improving the average simulation task success rate by 16.4% (Adroit), 14%
(DexArt), and 6.45% (RLBench), and the average real-world robotic task success
rate by 8.6%.

</details>


### [14] [LOVON: Legged Open-Vocabulary Object Navigator](https://arxiv.org/abs/2507.06747)
*Daojie Peng,Jiahang Cao,Qiang Zhang,Jun Ma*

Main category: cs.RO

TL;DR: LOVON是一个结合大型语言模型（LLMs）和开放词汇视觉检测模型的新框架，用于动态非结构化环境中的长距离物体导航。


<details>
  <summary>Details</summary>
Motivation: 解决开放世界环境中机器人长距离导航任务中物体检测和高级任务规划的集成问题。

Method: 整合LLMs进行分层任务规划，结合开放词汇视觉检测模型，并设计了视觉稳定化和功能执行逻辑。

Result: 实验表明LOVON能成功完成涉及实时检测、搜索和导航的长序列任务，并在不同机器人上展示兼容性。

Conclusion: LOVON在动态非结构化环境中表现出高效的长距离物体导航能力，并具有即插即用特性。

Abstract: Object navigation in open-world environments remains a formidable and
pervasive challenge for robotic systems, particularly when it comes to
executing long-horizon tasks that require both open-world object detection and
high-level task planning. Traditional methods often struggle to integrate these
components effectively, and this limits their capability to deal with complex,
long-range navigation missions. In this paper, we propose LOVON, a novel
framework that integrates large language models (LLMs) for hierarchical task
planning with open-vocabulary visual detection models, tailored for effective
long-range object navigation in dynamic, unstructured environments. To tackle
real-world challenges including visual jittering, blind zones, and temporary
target loss, we design dedicated solutions such as Laplacian Variance Filtering
for visual stabilization. We also develop a functional execution logic for the
robot that guarantees LOVON's capabilities in autonomous navigation, task
adaptation, and robust task completion. Extensive evaluations demonstrate the
successful completion of long-sequence tasks involving real-time detection,
search, and navigation toward open-vocabulary dynamic targets. Furthermore,
real-world experiments across different legged robots (Unitree Go2, B2, and
H1-2) showcase the compatibility and appealing plug-and-play feature of LOVON.

</details>


### [15] [Distributed Fault-Tolerant Multi-Robot Cooperative Localization in Adversarial Environments](https://arxiv.org/abs/2507.06750)
*Tohid Kargar Tasooji,Ramviyas Parasuraman*

Main category: cs.RO

TL;DR: 提出了一种分布式容错协同定位框架，通过自适应事件触发通信策略提升多机器人系统在对抗环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在GPS缺失或通信受限环境中，传统定位方法易受对抗攻击（如传感器操纵和通信干扰）影响，需增强系统鲁棒性和可扩展性。

Method: 采用自适应事件触发通信策略，动态调整通信阈值，并分析算法的收敛性和稳定性。

Result: 实验表明，该算法在对抗环境中显著优于传统方法，定位精度和通信效率更高。

Conclusion: 该方法提升了多机器人系统的可扩展性、可靠性和容错能力，适用于现实世界中的大规模部署。

Abstract: In multi-robot systems (MRS), cooperative localization is a crucial task for
enhancing system robustness and scalability, especially in GPS-denied or
communication-limited environments. However, adversarial attacks, such as
sensor manipulation, and communication jamming, pose significant challenges to
the performance of traditional localization methods. In this paper, we propose
a novel distributed fault-tolerant cooperative localization framework to
enhance resilience against sensor and communication disruptions in adversarial
environments. We introduce an adaptive event-triggered communication strategy
that dynamically adjusts communication thresholds based on real-time sensing
and communication quality. This strategy ensures optimal performance even in
the presence of sensor degradation or communication failure. Furthermore, we
conduct a rigorous analysis of the convergence and stability properties of the
proposed algorithm, demonstrating its resilience against bounded adversarial
zones and maintaining accurate state estimation. Robotarium-based experiment
results show that our proposed algorithm significantly outperforms traditional
methods in terms of localization accuracy and communication efficiency,
particularly in adversarial settings. Our approach offers improved scalability,
reliability, and fault tolerance for MRS, making it suitable for large-scale
deployments in real-world, challenging environments.

</details>


### [16] [Stream Function-Based Navigation for Complex Quadcopter Obstacle Avoidance](https://arxiv.org/abs/2507.06787)
*Sean Smith,Emmanuel Witrant,Ya-Jun Pan*

Main category: cs.RO

TL;DR: 提出了一种基于流函数的导航控制系统，结合VPM和MPC-HOCBF，实现复杂环境中的实时避障。


<details>
  <summary>Details</summary>
Motivation: 解决传统VPM在近距离避障和快速移动障碍物管理中的局限性。

Method: 采用VPM生成流函数，结合MPC-HOCBF优化避障路径，使用MBE和AKF处理障碍物动态。

Result: 在仿真和实际实验中验证了系统的有效性。

Conclusion: 系统能够高效处理复杂环境中的实时避障问题。

Abstract: This article presents a novel stream function-based navigational control
system for obstacle avoidance, where obstacles are represented as
two-dimensional (2D) rigid surfaces in inviscid, incompressible flows. The
approach leverages the vortex panel method (VPM) and incorporates safety
margins to control the stream function and flow properties around virtual
surfaces, enabling navigation in complex, partially observed environments using
real-time sensing. To address the limitations of the VPM in managing relative
distance and avoiding rapidly accelerating obstacles at close proximity, the
system integrates a model predictive controller (MPC) based on higher-order
control barrier functions (HOCBF). This integration incorporates VPM trajectory
generation, state estimation, and constraint handling into a receding-horizon
optimization problem. The 2D rigid surfaces are enclosed using minimum bounding
ellipses (MBEs), while an adaptive Kalman filter (AKF) captures and predicts
obstacle dynamics, propagating these estimates into the MPC-HOCBF for rapid
avoidance maneuvers. Evaluation is conducted using a PX4-powered Clover drone
Gazebo simulator and real-time experiments involving a COEX Clover quadcopter
equipped with a 360 degree LiDAR sensor.

</details>


### [17] [Hierarchical Reinforcement Learning for Articulated Tool Manipulation with Multifingered Hand](https://arxiv.org/abs/2507.06822)
*Wei Xu,Yanchao Zhao,Weichao Guo,Xinjun Sheng*

Main category: cs.RO

TL;DR: 提出了一种分层强化学习框架，用于提升机器人手操作铰接工具的能力，实验成功率为70.8%。


<details>
  <summary>Details</summary>
Motivation: 铰接工具的动态形状变化为机器人操作带来挑战，现有研究较少涉及。

Method: 采用分层GCRL框架，包含低层策略（工具配置）和高层策略（目标状态），结合点云编码器和启发式策略。

Result: 机器人能有效操作铰接工具，抓取不同形状和大小的物体，成功率为70.8%。

Conclusion: 强化学习在铰接工具操作方面具有潜力。

Abstract: Manipulating articulated tools, such as tweezers or scissors, has rarely been
explored in previous research. Unlike rigid tools, articulated tools change
their shape dynamically, creating unique challenges for dexterous robotic
hands. In this work, we present a hierarchical, goal-conditioned reinforcement
learning (GCRL) framework to improve the manipulation capabilities of
anthropomorphic robotic hands using articulated tools. Our framework comprises
two policy layers: (1) a low-level policy that enables the dexterous hand to
manipulate the tool into various configurations for objects of different sizes,
and (2) a high-level policy that defines the tool's goal state and controls the
robotic arm for object-picking tasks. We employ an encoder, trained on
synthetic pointclouds, to estimate the tool's affordance states--specifically,
how different tool configurations (e.g., tweezer opening angles) enable
grasping of objects of varying sizes--from input point clouds, thereby enabling
precise tool manipulation. We also utilize a privilege-informed heuristic
policy to generate replay buffer, improving the training efficiency of the
high-level policy. We validate our approach through real-world experiments,
showing that the robot can effectively manipulate a tweezer-like tool to grasp
objects of diverse shapes and sizes with a 70.8 % success rate. This study
highlights the potential of RL to advance dexterous robotic manipulation of
articulated tools.

</details>


### [18] [Friction Estimation for In-Hand Planar Motion](https://arxiv.org/abs/2507.06824)
*Gabriel Arslan Waltersson,Yiannis Karayiannidis*

Main category: cs.RO

TL;DR: 提出了一种在线估计平行夹持器滑动操作中接触特性的方法，包括静摩擦、库仑摩擦和接触半径。


<details>
  <summary>Details</summary>
Motivation: 在滑动操作中准确估计接触特性对机器人控制至关重要。

Method: 通过触觉测量接触力和滑动速度来估计摩擦和接触半径，并提出了处理快速滑移-粘附动态的启发式方法。

Result: 在仿真和真实实验中验证了方法的有效性。

Conclusion: 该方法能够有效估计接触特性，并处理动态干扰。

Abstract: This paper presents a method for online estimation of contact properties
during in-hand sliding manipulation with a parallel gripper. We estimate the
static and Coulomb friction as well as the contact radius from tactile
measurements of contact forces and sliding velocities. The method is validated
in both simulation and real-world experiments. Furthermore, we propose a
heuristic to deal with fast slip-stick dynamics which can adversely affect the
estimation.

</details>


### [19] [Toward a Full-Stack Co-Simulation Platform for Testing of Automated Driving Systems](https://arxiv.org/abs/2507.06884)
*Dong Bi,Yongqi Zhao,Zhengguo Gu,Tomislav Mihalj,Jia Hu,Arno Eichberger*

Main category: cs.RO

TL;DR: 提出了一种全栈工具链，用于从真实世界数据自动生成场景，并通过基于CarMaker、ROS和Apollo的协同仿真平台进行高效验证。


<details>
  <summary>Details</summary>
Motivation: 虚拟测试是加速自动驾驶系统部署的有效方法，但现有工具链难以整合快速、自动化的场景生成与支持高级自动驾驶能力的仿真环境。

Method: 开发了一种全栈工具链，结合CarMaker、ROS和Apollo，实现从真实数据自动生成场景并进行协同仿真验证。

Result: 仿真结果证明了该工具链的有效性。

Conclusion: 该工具链解决了现有仿真工具链的局限性，为自动驾驶系统的虚拟测试提供了高效解决方案。

Abstract: Virtual testing has emerged as an effective approach to accelerate the
deployment of automated driving systems. Nevertheless, existing simulation
toolchains encounter difficulties in integrating rapid, automated scenario
generation with simulation environments supporting advanced automated driving
capabilities. To address this limitation, a full-stack toolchain is presented,
enabling automatic scenario generation from real-world datasets and efficient
validation through a co-simulation platform based on CarMaker, ROS, and Apollo.
The simulation results demonstrate the effectiveness of the proposed toolchain.
A demonstration video showcasing the toolchain is available at the provided
link: https://youtu.be/taJw_-CmSiY.

</details>


### [20] [ULC: A Unified and Fine-Grained Controller for Humanoid Loco-Manipulation](https://arxiv.org/abs/2507.06905)
*Wandong Sun,Luying Feng,Baoshi Cao,Yang Liu,Yaochu Jin,Zongwu Xie*

Main category: cs.RO

TL;DR: 提出了一种统一的人形机器人运动与操作控制框架（ULC），通过单一策略实现全身协调控制，优于传统分层方法。


<details>
  <summary>Details</summary>
Motivation: 现有分层控制方法限制了子系统间的协调性，无法实现类似人类的全身统一控制。

Method: 采用序列技能学习、残差动作建模、命令多项式插值等技术，实现端到端的统一控制。

Result: 在Unitree G1机器人上验证，ULC在跟踪精度、工作空间覆盖和鲁棒性上优于基线方法。

Conclusion: 统一控制框架ULC可行且高效，为复杂运动与操作任务提供了新思路。

Abstract: Loco-Manipulation for humanoid robots aims to enable robots to integrate
mobility with upper-body tracking capabilities. Most existing approaches adopt
hierarchical architectures that decompose control into isolated upper-body
(manipulation) and lower-body (locomotion) policies. While this decomposition
reduces training complexity, it inherently limits coordination between
subsystems and contradicts the unified whole-body control exhibited by humans.
We demonstrate that a single unified policy can achieve a combination of
tracking accuracy, large workspace, and robustness for humanoid
loco-manipulation. We propose the Unified Loco-Manipulation Controller (ULC), a
single-policy framework that simultaneously tracks root velocity, root height,
torso rotation, and dual-arm joint positions in an end-to-end manner, proving
the feasibility of unified control without sacrificing performance. We achieve
this unified control through key technologies: sequence skill acquisition for
progressive learning complexity, residual action modeling for fine-grained
control adjustments, command polynomial interpolation for smooth motion
transitions, random delay release for robustness to deploy variations, load
randomization for generalization to external disturbances, and
center-of-gravity tracking for providing explicit policy gradients to maintain
stability. We validate our method on the Unitree G1 humanoid robot with 3-DOF
(degrees-of-freedom) waist. Compared with strong baselines, ULC shows better
tracking performance to disentangled methods and demonstrating larger workspace
coverage. The unified dual-arm tracking enables precise manipulation under
external loads while maintaining coordinated whole-body control for complex
loco-manipulation tasks.

</details>


### [21] [Bounomodes: the grazing ox algorithm for exploration of clustered anomalies](https://arxiv.org/abs/2507.06960)
*Samuel Matloob,Ayan Dutta,O. Patrick Kreidl,Swapnonel Roy,Ladislau Bölöni*

Main category: cs.RO

TL;DR: 论文提出了一种名为“bounom=odes”的算法，结合均匀覆盖和异常区域探索，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统均匀覆盖算法在异常集群场景中效率不足，需优先探索异常区域。

Method: 交替使用均匀采样和基于深度强化学习的异常集群探索。

Result: 实验表明，该方法优于多个基线算法。

Conclusion: 结合均匀覆盖与针对性探索的算法在异常集群场景中更有效。

Abstract: A common class of algorithms for informative path planning (IPP) follows
boustrophedon ("as the ox turns") patterns, which aim to achieve uniform area
coverage. However, IPP is often applied in scenarios where anomalies, such as
plant diseases, pollution, or hurricane damage, appear in clusters. In such
cases, prioritizing the exploration of anomalous regions over uniform coverage
is beneficial. This work introduces a class of algorithms referred to as
bounom\=odes ("as the ox grazes"), which alternates between uniform
boustrophedon sampling and targeted exploration of detected anomaly clusters.
While uniform sampling can be designed using geometric principles, close
exploration of clusters depends on the spatial distribution of anomalies and
must be learned. In our implementation, the close exploration behavior is
learned using deep reinforcement learning algorithms. Experimental evaluations
demonstrate that the proposed approach outperforms several established
baselines.

</details>
