<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 43]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [DIPP: Discriminative Impact Point Predictor for Catching Diverse In-Flight Objects](https://arxiv.org/abs/2509.15254)
*Ngoc Huy Nguyen,Kazuki Shibata,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 该研究提出了一种用于四足机器人空中抓取物体的方法，通过构建包含8000条轨迹的真实数据集，并开发了判别式撞击点预测器（DIPP）来准确预测物体落点。


<details>
  <summary>Details</summary>
Motivation: 解决空中物体抓取中的两个关键挑战：缺乏包含不稳定空气动力学下多样化物体的公开数据集，以及在轨迹相似时难以进行早期准确撞击点预测。

Method: 构建真实世界数据集，并提出DIPP方法，包含判别式特征嵌入（DFE）模块和撞击点预测器（IPP）模块。IPP有两种变体：基于神经加速度估计器（NAE）和基于直接点估计器（DPE）。

Result: 实验结果显示，所构建的数据集比现有数据集更加多样化和复杂，提出的方法在15个已知物体和5个未知物体上都优于基线方法。早期预测能力的提升提高了模拟环境中的抓取成功率。

Conclusion: 该方法通过真实世界实验验证了有效性，为复杂空气动力学条件下的空中物体抓取提供了可靠解决方案。

Abstract: In this study, we address the problem of in-flight object catching using a
quadruped robot with a basket. Our objective is to accurately predict the
impact point, defined as the object's landing position. This task poses two key
challenges: the absence of public datasets capturing diverse objects under
unsteady aerodynamics, which are essential for training reliable predictors;
and the difficulty of accurate early-stage impact point prediction when
trajectories appear similar across objects. To overcome these issues, we
construct a real-world dataset of 8,000 trajectories from 20 objects, providing
a foundation for advancing in-flight object catching under complex
aerodynamics. We then propose the Discriminative Impact Point Predictor (DIPP),
consisting of two modules: (i) a Discriminative Feature Embedding (DFE) that
separates trajectories by dynamics to enable early-stage discrimination and
generalization, and (ii) an Impact Point Predictor (IPP) that estimates the
impact point from these features. Two IPP variants are implemented: an Neural
Acceleration Estimator (NAE)-based method that predicts trajectories and
derives the impact point, and a Direct Point Estimator (DPE)-based method that
directly outputs it. Experimental results show that our dataset is more diverse
and complex than existing dataset, and that our method outperforms baselines on
both 15 seen and 5 unseen objects. Furthermore, we show that improved
early-stage prediction enhances catching success in simulation and demonstrate
the effectiveness of our approach through real-world experiments. The
demonstration is available at
https://sites.google.com/view/robot-catching-2025.

</details>


### [2] [GiAnt: A Bio-Inspired Hexapod for Adaptive Terrain Navigation and Object Detection](https://arxiv.org/abs/2509.15264)
*Aasfee Mosharraf Bhuiyan,Md Luban Mehda,Md. Thawhid Hasan Puspo,Jubayer Amin Pritom*

Main category: cs.RO

TL;DR: 本文介绍了GiAnt的设计、开发和测试，这是一种受蚂蚁高效运动启发的经济型六足机器人。该机器人采用轻量化3D打印结构，具有单自由度腿部设计，能够在复杂地形上灵活移动，并配备机器学习技术进行物体识别。


<details>
  <summary>Details</summary>
Motivation: 设计灵感来源于蚂蚁对各种地形的自然适应性，旨在开发一种能够在户外应用中提供地形灵活性和高效能源利用的六足机器人。

Method: 采用仿生学方法，使用3D打印和激光切割技术制造轻量化结构（1.75kg），腿部采用简单的单自由度连杆曲柄机构，控制系统基于Arduino，通过步态分析实现有效控制，并集成机器学习和图像处理技术。

Result: GiAnt能够轻松跨越8cm高度的障碍，在草地、岩石和陡峭表面等复杂地形上表现出优越的适应性，能够识别81种不同物体，实现了手动操作和实时监控功能。

Conclusion: GiAnt代表了在创建用于研究、探索和勘测的可访问六足机器人方面的重要进展，在适应性和控制简单性方面具有独特优势。

Abstract: This paper presents the design, development and testing of GiAnt, an
affordable hexapod which is inspired by the efficient motions of ants. The
decision to model GiAnt after ants rather than other insects is rooted in ants'
natural adaptability to a variety of terrains. This bio-inspired approach gives
it a significant advantage in outdoor applications, offering terrain
flexibility along with efficient energy use. It features a lightweight
3D-printed and laser cut structure weighing 1.75 kg with dimensions of 310 mm x
200 mm x 120 mm. Its legs have been designed with a simple Single Degree of
Freedom (DOF) using a link and crank mechanism. It is great for conquering
challenging terrains such as grass, rocks, and steep surfaces. Unlike
traditional robots using four wheels for motion, its legged design gives
superior adaptability to uneven and rough surfaces. GiAnt's control system is
built on Arduino, allowing manual operation. An effective way of controlling
the legs of GiAnt was achieved by gait analysis. It can move up to 8 cm of
height easily with its advanced leg positioning system. Furthermore, equipped
with machine learning and image processing technology, it can identify 81
different objects in a live monitoring system. It represents a significant step
towards creating accessible hexapod robots for research, exploration, and
surveying, offering unique advantages in adaptability and control simplicity.

</details>


### [3] [Embodied Arena: A Comprehensive, Unified, and Evolving Evaluation Platform for Embodied AI](https://arxiv.org/abs/2509.15273)
*Fei Ni,Min Zhang,Pengyi Li,Yifu Yuan,Lingfeng Zhang,Yuecheng Liu,Peilong Han,Longxin Kou,Shaojin Ma,Jinbin Qiao,David Gamaliel Arcos Bravo,Yuening Wang,Xiao Hu,Zhanguang Zhang,Xianze Yao,Yutong Li,Zhao Zhang,Ying Wen,Ying-Cong Chen,Xiaodan Liang,Liang Lin,Bin He,Haitham Bou-Ammar,He Wang,Huazhe Xu,Jiankang Deng,Shan Luo,Shuqiang Jiang,Wei Pan,Yang Gao,Stefanos Zafeiriou,Jan Peters,Yuzheng Zhuang,Yingxue Zhang,Yan Zheng,Hongyao Tang,Jianye Hao*

Main category: cs.RO

TL;DR: Embodied Arena是一个为具身AI设计的综合性评估平台，通过建立系统化的能力分类、标准化评估系统和自动化数据生成管道，解决了具身AI发展中的三个关键挑战：缺乏明确研究目标、缺少统一评估标准、以及数据获取瓶颈。


<details>
  <summary>Details</summary>
Motivation: 具身AI发展滞后于大型基础模型，主要面临三个关键挑战：(1)缺乏对核心能力的系统理解，研究目标不明确；(2)缺少统一标准化的评估体系，跨基准评估不可行；(3)自动化可扩展的具身数据获取方法不成熟，成为模型扩展的瓶颈。

Method: 建立系统化的具身能力分类法（3个层级、7个核心能力、25个细粒度维度）；构建标准化评估系统，支持22个多样化基准和30+先进模型的灵活集成；开发基于LLM的自动化生成管道，确保可扩展的具身评估数据。

Result: 发布了三个实时排行榜（具身问答、导航、任务规划），提供双视角（基准视图和能力视图）的全面概览；从评估结果中总结了九个重要发现，帮助建立清晰的研究脉络和识别关键研究问题。

Conclusion: Embodied Arena通过提供系统性评估框架，为具身AI领域建立了明确的研究方向，解决了当前发展瓶颈，将推动该领域的进步。

Abstract: Embodied AI development significantly lags behind large foundation models due
to three critical challenges: (1) lack of systematic understanding of core
capabilities needed for Embodied AI, making research lack clear objectives; (2)
absence of unified and standardized evaluation systems, rendering
cross-benchmark evaluation infeasible; and (3) underdeveloped automated and
scalable acquisition methods for embodied data, creating critical bottlenecks
for model scaling. To address these obstacles, we present Embodied Arena, a
comprehensive, unified, and evolving evaluation platform for Embodied AI. Our
platform establishes a systematic embodied capability taxonomy spanning three
levels (perception, reasoning, task execution), seven core capabilities, and 25
fine-grained dimensions, enabling unified evaluation with systematic research
objectives. We introduce a standardized evaluation system built upon unified
infrastructure supporting flexible integration of 22 diverse benchmarks across
three domains (2D/3D Embodied Q&A, Navigation, Task Planning) and 30+ advanced
models from 20+ worldwide institutes. Additionally, we develop a novel
LLM-driven automated generation pipeline ensuring scalable embodied evaluation
data with continuous evolution for diversity and comprehensiveness. Embodied
Arena publishes three real-time leaderboards (Embodied Q&A, Navigation, Task
Planning) with dual perspectives (benchmark view and capability view),
providing comprehensive overviews of advanced model capabilities. Especially,
we present nine findings summarized from the evaluation results on the
leaderboards of Embodied Arena. This helps to establish clear research veins
and pinpoint critical research problems, thereby driving forward progress in
the field of Embodied AI.

</details>


### [4] [Measurement and Potential Field-Based Patient Modeling for Model-Mediated Tele-ultrasound](https://arxiv.org/abs/2509.15325)
*Ryan S. Yeung,David G. Black,Septimiu E. Salcudean*

Main category: cs.RO

TL;DR: 该论文提出了一种改进的模型介导远程超声方法，通过测量位置和力来更新内部势场模型，以提高力反馈的准确性。


<details>
  <summary>Details</summary>
Motivation: 远程超声可以改善偏远社区的医疗影像诊断，但通信延迟使得直接力反馈不实用。需要更准确的力反馈来帮助超声医师施加适当的探头接触力以优化图像质量。

Method: 首先生成患者表面的点云模型并传输给超声医师，转换为静态体素化体积，每个体素包含势场值。使用凸二次规划结合空间拉普拉斯算子和测量力来求解势场，基于体素化体积与超声换能器点壳模型的重叠来渲染力和扭矩。

Result: 在志愿者患者（n=3）上的评估显示，与仅使用拉普拉斯方程相比，将测量力加入模型使力大小误差平均减少7.23N，力矢量角度误差平均减少9.37°。

Conclusion: 该方法通过整合测量力数据显著提高了模型介导远程超声中力反馈的准确性，为远程超声诊断提供了更可靠的力反馈解决方案。

Abstract: Teleoperated ultrasound can improve diagnostic medical imaging access for
remote communities. Having accurate force feedback is important for enabling
sonographers to apply the appropriate probe contact force to optimize
ultrasound image quality. However, large time delays in communication make
direct force feedback impractical. Prior work investigated using point
cloud-based model-mediated teleoperation and internal potential field models to
estimate contact forces and torques. We expand on this by introducing a method
to update the internal potential field model of the patient with measured
positions and forces for more transparent model-mediated tele-ultrasound. We
first generate a point cloud model of the patient's surface and transmit this
to the sonographer in a compact data structure. This is converted to a static
voxelized volume where each voxel contains a potential field value. These
values determine the forces and torques, which are rendered based on overlap
between the voxelized volume and a point shell model of the ultrasound
transducer. We solve for the potential field using a convex quadratic that
combines the spatial Laplace operator with measured forces. This was evaluated
on volunteer patients ($n=3$) by computing the accuracy of rendered forces.
Results showed the addition of measured forces to the model reduced the force
magnitude error by an average of 7.23 N and force vector angle error by an
average of 9.37$^{\circ}$ compared to using only Laplace's equation.

</details>


### [5] [Trust-Aware Embodied Bayesian Persuasion for Mixed-Autonomy](https://arxiv.org/abs/2509.15404)
*Shaoting Peng,Katherine Driggs-Campbell,Roy Dong*

Main category: cs.RO

TL;DR: 提出了TA-EBP框架，通过贝叶斯说服理论解决自动驾驶车辆与人类驾驶车辆交互中的信任问题，提高交通安全和效率


<details>
  <summary>Details</summary>
Motivation: 传统博弈论模型在自动驾驶车辆与人类驾驶车辆交互中存在长期影响力衰减和被感知为操纵的问题，这反而会导致更危险的人类驾驶行为

Method: 应用贝叶斯说服理论建模交通路口通信，引入信任参数推导影响力所需的最小信任水平，将抽象信号转化为连续物理动作空间，实现最优信号幅度（AV前推动作）

Result: 在混合自主交通仿真中验证，TA-EBP成功说服人类驾驶车辆更谨慎驾驶，消除碰撞并改善交通流量，优于忽略信任或缺乏通信的基线方法

Conclusion: 为人类-机器人交互中的影响力提供了一个透明且非策略性的框架，同时提高了安全性和效率

Abstract: Safe and efficient interaction between autonomous vehicles (AVs) and
human-driven vehicles (HVs) is a critical challenge for future transportation
systems. While game-theoretic models capture how AVs influence HVs, they often
suffer from a long-term decay of influence and can be perceived as
manipulative, eroding the human's trust. This can paradoxically lead to riskier
human driving behavior over repeated interactions. In this paper, we address
this challenge by proposing the Trust-Aware Embodied Bayesian Persuasion
(TA-EBP) framework. Our work makes three key contributions: First, we apply
Bayesian persuasion to model communication at traffic intersections, offering a
transparent alternative to traditional game-theoretic models. Second, we
introduce a trust parameter to the persuasion framework, deriving a theorem for
the minimum trust level required for influence. Finally, we ground the abstract
signals of Bayesian persuasion theory into a continuous, physically meaningful
action space, deriving a second theorem for the optimal signal magnitude,
realized as an AV's forward nudge. Additionally, we validate our framework in a
mixed-autonomy traffic simulation, demonstrating that TA-EBP successfully
persuades HVs to drive more cautiously, eliminating collisions and improving
traffic flow compared to baselines that either ignore trust or lack
communication. Our work provides a transparent and non-strategic framework for
influence in human-robot interaction, enhancing both safety and efficiency.

</details>


### [6] [Sym2Real: Symbolic Dynamics with Residual Learning for Data-Efficient Adaptive Control](https://arxiv.org/abs/2509.15412)
*Easop Lee,Samuel A. Moore,Boyuan Chen*

Main category: cs.RO

TL;DR: Sym2Real是一个完全数据驱动的框架，通过符号回归和残差学习，仅需约10条轨迹即可实现四旋翼和赛车在真实世界中的鲁棒控制，无需专家知识或仿真调参。


<details>
  <summary>Details</summary>
Motivation: 解决符号回归在真实机器人应用中面临的关键挑战，包括噪声敏感性和模型退化导致的不安全控制问题，利用物理系统在不同条件下共享底层物理特性的观察。

Method: 策略性地结合低精度仿真数据和有针对性的真实世界残差学习，通过符号回归实现数据高效的自适应控制。

Result: 在四旋翼和赛车平台上验证，在6个分布外仿真场景中实现一致的数据高效适应，并在5个真实世界条件下成功实现仿真到真实的迁移。

Conclusion: Sym2Real框架为低层自适应控制提供了一种原则性的数据高效训练方法，成功解决了符号回归在机器人控制中的实际应用障碍。

Abstract: We present Sym2Real, a fully data-driven framework that provides a principled
way to train low-level adaptive controllers in a highly data-efficient manner.
Using only about 10 trajectories, we achieve robust control of both a quadrotor
and a racecar in the real world, without expert knowledge or simulation tuning.
Our approach achieves this data efficiency by bringing symbolic regression to
real-world robotics while addressing key challenges that prevent its direct
application, including noise sensitivity and model degradation that lead to
unsafe control. Our key observation is that the underlying physics is often
shared for a system regardless of internal or external changes. Hence, we
strategically combine low-fidelity simulation data with targeted real-world
residual learning. Through experimental validation on quadrotor and racecar
platforms, we demonstrate consistent data-efficient adaptation across six
out-of-distribution sim2sim scenarios and successful sim2real transfer across
five real-world conditions. More information and videos can be found at at
http://generalroboticslab.com/Sym2Real

</details>


### [7] [Online Slip Detection and Friction Coefficient Estimation for Autonomous Racing](https://arxiv.org/abs/2509.15423)
*Christopher Oeltjen,Carson Sobolewski,Saleh Faghfoorian,Lorant Domokos,Giancarlo Vidal,Ivan Ruchkin*

Main category: cs.RO

TL;DR: 提出一种轻量级方法，用于在线滑移检测和轮胎-路面摩擦系数估计，仅使用IMU、LiDAR和控制动作，无需复杂模型或训练数据


<details>
  <summary>Details</summary>
Motivation: 轮胎-路面摩擦系数对车辆安全至关重要，但现有方法依赖不确定参数的模型或需要大量训练数据

Method: 通过比较指令运动与实际运动实时检测滑移事件，在无滑移条件下直接从观测加速度估计摩擦系数

Result: 在1:10比例自动驾驶赛车上的实验显示，该方法在不同摩擦水平下都能实现准确一致的滑移检测和摩擦系数估计

Conclusion: 该方法简单、可部署且计算高效，具有实时滑移监测和摩擦系数估计的潜力

Abstract: Accurate knowledge of the tire-road friction coefficient (TRFC) is essential
for vehicle safety, stability, and performance, especially in autonomous
racing, where vehicles often operate at the friction limit. However, TRFC
cannot be directly measured with standard sensors, and existing estimation
methods either depend on vehicle or tire models with uncertain parameters or
require large training datasets. In this paper, we present a lightweight
approach for online slip detection and TRFC estimation. Our approach relies
solely on IMU and LiDAR measurements and the control actions, without special
dynamical or tire models, parameter identification, or training data. Slip
events are detected in real time by comparing commanded and measured motions,
and the TRFC is then estimated directly from observed accelerations under
no-slip conditions. Experiments with a 1:10-scale autonomous racing car across
different friction levels demonstrate that the proposed approach achieves
accurate and consistent slip detections and friction coefficients, with results
closely matching ground-truth measurements. These findings highlight the
potential of our simple, deployable, and computationally efficient approach for
real-time slip monitoring and friction coefficient estimation in autonomous
driving.

</details>


### [8] [Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning](https://arxiv.org/abs/2509.15443)
*Xingyu Chen,Hanyu Wu,Sikai Wu,Mingliang Zhou,Diyun Xiang,Haodong Zhang*

Main category: cs.RO

TL;DR: 提出了一种名为IKMR的隐式运动动力学运动重定向框架，能够高效地将大规模人类运动转换为机器人可执行的运动轨迹，同时考虑运动学和动力学约束。


<details>
  <summary>Details</summary>
Motivation: 当前的运动重定向方法主要基于逐帧处理，缺乏可扩展性。需要一种更高效的方法来直接将大规模人类运动转换为机器人可执行的运动。

Method: IKMR框架包含运动学预训练和动力学集成两部分：运动学部分预训练运动拓扑特征表示和双编码器-解码器架构学习运动域映射；动力学部分将模仿学习与运动重定向网络结合，将运动细化为物理可行的轨迹。

Result: 经过微调后，IKMR能够实时实现大规模物理可行的运动重定向，并且可以直接训练和部署全身控制器来跟踪重定向后的轨迹。在仿真和真实机器人上的实验验证了框架的有效性。

Conclusion: IKMR是一种新颖、高效且可扩展的运动重定向框架，能够成功解决人类到人形机器人模仿学习中的运动重定向问题，为机器人获取参考轨迹提供了有效解决方案。

Abstract: Human-to-humanoid imitation learning aims to learn a humanoid whole-body
controller from human motion. Motion retargeting is a crucial step in enabling
robots to acquire reference trajectories when exploring locomotion skills.
However, current methods focus on motion retargeting frame by frame, which
lacks scalability. Could we directly convert large-scale human motion into
robot-executable motion through a more efficient approach? To address this
issue, we propose Implicit Kinodynamic Motion Retargeting (IKMR), a novel
efficient and scalable retargeting framework that considers both kinematics and
dynamics. In kinematics, IKMR pretrains motion topology feature representation
and a dual encoder-decoder architecture to learn a motion domain mapping. In
dynamics, IKMR integrates imitation learning with the motion retargeting
network to refine motion into physically feasible trajectories. After
fine-tuning using the tracking results, IKMR can achieve large-scale physically
feasible motion retargeting in real time, and a whole-body controller could be
directly trained and deployed for tracking its retargeted trajectories. We
conduct our experiments both in the simulator and the real robot on a full-size
humanoid robot. Extensive experiments and evaluation results verify the
effectiveness of our proposed framework.

</details>


### [9] [Explainable AI-Enhanced Supervisory Control for Robust Multi-Agent Robotic Systems](https://arxiv.org/abs/2509.15491)
*Reza Pirayeshshirazinezhad,Nima Fathi*

Main category: cs.RO

TL;DR: 提出了一种可解释的AI增强监督控制框架，用于多智能体机器人系统，结合了定时自动机监督器、鲁棒连续控制和可解释预测器，在航天器编队飞行和自主水下航行器两个领域验证了方法的有效性和可移植性。


<details>
  <summary>Details</summary>
Motivation: 为了解决多智能体机器人系统中安全性、可审计性和资源约束的挑战，需要开发一个既能保证安全又能提供透明决策解释的监督控制框架。

Method: 框架包含三个核心组件：(1)定时自动机监督器用于安全模式切换；(2)鲁棒连续控制器（李雅普诺夫控制器用于大角度机动，滑模控制器用于精密控制和扰动抑制）；(3)可解释预测器将任务上下文映射到控制参数和预期性能。通过蒙特卡洛驱动的优化生成训练数据。

Result: 在航天器任务中，滑模控制器实现了亚毫米级对齐，跟踪误差比PD控制器降低21.7%，能耗降低81.4%。在AUV跟随测试中，相同结构的滑模控制器在随机水流下保持固定偏移，误差有界。

Conclusion: 该方法在安全关键、资源受限的多智能体机器人系统中展现出良好的可移植性和可解释性，为复杂环境下的机器人控制提供了有效的解决方案。

Abstract: We present an explainable AI-enhanced supervisory control framework for
multi-agent robotics that combines (i) a timed-automata supervisor for safe,
auditable mode switching, (ii) robust continuous control (Lyapunov-based
controller for large-angle maneuver; sliding-mode controller (SMC) with
boundary layers for precision and disturbance rejection), and (iii) an
explainable predictor that maps mission context to gains and expected
performance (energy, error). Monte Carlo-driven optimization provides the
training data, enabling transparent real-time trade-offs.
  We validated the approach in two contrasting domains, spacecraft formation
flying and autonomous underwater vehicles (AUVs). Despite different
environments (gravity/actuator bias vs. hydrodynamic drag/currents), both share
uncertain six degrees of freedom (6-DOF) rigid-body dynamics, relative motion,
and tight tracking needs, making them representative of general robotic
systems. In the space mission, the supervisory logic selects parameters that
meet mission criteria. In AUV leader-follower tests, the same SMC structure
maintains a fixed offset under stochastic currents with bounded steady error.
In spacecraft validation, the SMC controller achieved submillimeter alignment
with 21.7% lower tracking error and 81.4% lower energy consumption compared to
Proportional-Derivative PD controller baselines. At the same time, in AUV
tests, SMC maintained bounded errors under stochastic currents. These results
highlight both the portability and the interpretability of the approach for
safety-critical, resource-constrained multi-agent robotics.

</details>


### [10] [STARC: See-Through-Wall Augmented Reality Framework for Human-Robot Collaboration in Emergency Response](https://arxiv.org/abs/2509.15507)
*Shenghai Yuan,Weixiang Guo,Tianxin Hu,Yu Yang,Jinyu Chen,Rui Qian,Zhongyuan Liu,Lihua Xie*

Main category: cs.RO

TL;DR: STARC是一个用于紧急救援任务的透视AR框架，通过融合移动机器人测绘和救援人员LiDAR传感，实现实时可视化隐藏的受害者和危险物。


<details>
  <summary>Details</summary>
Motivation: 在紧急救援任务中，救援人员需要在视线被遮挡的杂乱室内环境中导航，这些遮挡物可能隐藏着生命危险和需要救援的受害者。

Method: 使用地面机器人进行大范围探索和3D人体检测，同时通过相对姿态估计将救援人员头盔或手持LiDAR注册到机器人全局地图中，实现跨LiDAR对齐和低延迟AR渲染。

Result: 在仿真、实验室设置和战术现场试验中验证了稳健的姿态对齐、可靠的检测和稳定的叠加效果。

Conclusion: STARC系统通过提供实时可视化隐藏人员和危险物的能力，增强了态势感知并降低了操作风险，在消防、灾难救援等安全关键操作中具有重要应用潜力。

Abstract: In emergency response missions, first responders must navigate cluttered
indoor environments where occlusions block direct line-of-sight, concealing
both life-threatening hazards and victims in need of rescue. We present STARC,
a see-through AR framework for human-robot collaboration that fuses
mobile-robot mapping with responder-mounted LiDAR sensing. A ground robot
running LiDAR-inertial odometry performs large-area exploration and 3D human
detection, while helmet- or handheld-mounted LiDAR on the responder is
registered to the robot's global map via relative pose estimation. This
cross-LiDAR alignment enables consistent first-person projection of detected
humans and their point clouds - rendered in AR with low latency - into the
responder's view. By providing real-time visualization of hidden occupants and
hazards, STARC enhances situational awareness and reduces operator risk.
Experiments in simulation, lab setups, and tactical field trials confirm robust
pose alignment, reliable detections, and stable overlays, underscoring the
potential of our system for fire-fighting, disaster relief, and other
safety-critical operations. Code and design will be open-sourced upon
acceptance.

</details>


### [11] [Distribution Estimation for Global Data Association via Approximate Bayesian Inference](https://arxiv.org/abs/2509.15565)
*Yixuan Jia,Mason B. Peterson,Qingyuan Li,Yulun Tian,Jonathan P. How*

Main category: cs.RO

TL;DR: 本文提出了一种基于近似贝叶斯推理的数据关联框架，用于处理高度多模态的全局数据关联问题，避免在模糊场景下过早确定单一解。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖最大似然估计或最大共识来产生单一关联集，但在重复或对称数据等模糊场景中，数据关联问题的解分布往往是高度多模态的，单一解方法经常失败。

Method: 使用近似贝叶斯推理来捕捉数据关联问题的多个解模式，将假设解表示为粒子，这些粒子根据确定性或随机更新规则演化以覆盖底层解分布的模态。方法可以结合数据关联公式的优化约束，并直接受益于GPU并行化优化。

Result: 在高度模糊数据的模拟和真实世界实验中，该方法在配准点云或对象地图时能正确估计变换的分布。

Conclusion: 提出的框架能够有效处理模糊数据关联问题，通过捕捉多模态解分布提高了在重复或对称环境中的鲁棒性。

Abstract: Global data association is an essential prerequisite for robot operation in
environments seen at different times or by different robots. Repetitive or
symmetric data creates significant challenges for existing methods, which
typically rely on maximum likelihood estimation or maximum consensus to produce
a single set of associations. However, in ambiguous scenarios, the distribution
of solutions to global data association problems is often highly multimodal,
and such single-solution approaches frequently fail. In this work, we introduce
a data association framework that leverages approximate Bayesian inference to
capture multiple solution modes to the data association problem, thereby
avoiding premature commitment to a single solution under ambiguity. Our
approach represents hypothetical solutions as particles that evolve according
to a deterministic or randomized update rule to cover the modes of the
underlying solution distribution. Furthermore, we show that our method can
incorporate optimization constraints imposed by the data association
formulation and directly benefit from GPU-parallelized optimization. Extensive
simulated and real-world experiments with highly ambiguous data show that our
method correctly estimates the distribution over transformations when
registering point clouds or object maps.

</details>


### [12] [Momentum-constrained Hybrid Heuristic Trajectory Optimization Framework with Residual-enhanced DRL for Visually Impaired Scenarios](https://arxiv.org/abs/2509.15582)
*Yuting Zeng,Zhiwen Zheng,You Zhou,JiaLing Xiao,Yongbin Yu,Manping Fan,Bo Gong,Liyong Ren*

Main category: cs.RO

TL;DR: 提出了一种动量约束混合启发式轨迹优化框架（MHHTOF），用于视觉障碍场景下的辅助导航，结合轨迹采样生成、优化和残差增强深度强化学习（DRL）评估。


<details>
  <summary>Details</summary>
Motivation: 针对视觉障碍辅助导航场景，需要确保轨迹平滑性、可行性和安全性，同时提高实时性和鲁棒性。

Method: 采用双阶段方法：第一阶段在Frenet坐标系使用三阶插值和五阶多项式生成启发式轨迹采样簇（HTSC），第二阶段在笛卡尔坐标系使用残差增强的actor-critic网络和LSTM时序特征建模自适应优化轨迹选择。

Result: LSTM-ResB-PPO相比PPO基线收敛速度显著加快，训练迭代次数减半，平均成本和成本方差分别降低30.3%和53.3%，自身和障碍物风险降低超过77%。

Conclusion: 该框架在复杂辅助规划任务中有效提升了鲁棒性、安全性和实时可行性。

Abstract: This paper proposes a momentum-constrained hybrid heuristic trajectory
optimization framework (MHHTOF) tailored for assistive navigation in visually
impaired scenarios, integrating trajectory sampling generation, optimization
and evaluation with residual-enhanced deep reinforcement learning (DRL). In the
first stage, heuristic trajectory sampling cluster (HTSC) is generated in the
Frenet coordinate system using third-order interpolation with fifth-order
polynomials and momentum-constrained trajectory optimization (MTO) constraints
to ensure smoothness and feasibility. After first stage cost evaluation, the
second stage leverages a residual-enhanced actor-critic network with LSTM-based
temporal feature modeling to adaptively refine trajectory selection in the
Cartesian coordinate system. A dual-stage cost modeling mechanism (DCMM) with
weight transfer aligns semantic priorities across stages, supporting
human-centered optimization. Experimental results demonstrate that the proposed
LSTM-ResB-PPO achieves significantly faster convergence, attaining stable
policy performance in approximately half the training iterations required by
the PPO baseline, while simultaneously enhancing both reward outcomes and
training stability. Compared to baseline method, the selected model reduces
average cost and cost variance by 30.3% and 53.3%, and lowers ego and obstacle
risks by over 77%. These findings validate the framework's effectiveness in
enhancing robustness, safety, and real-time feasibility in complex assistive
planning tasks.

</details>


### [13] [Bench-RNR: Dataset for Benchmarking Repetitive and Non-repetitive Scanning LiDAR for Infrastructure-based Vehicle Localization](https://arxiv.org/abs/2509.15583)
*Runxin Zhao,Chunxiang Wang,Hanyang Zhuang,Ming Yang*

Main category: cs.RO

TL;DR: 本文提出了一个基于路边LiDAR的车辆定位数据集，包含重复扫描和非重复扫描LiDAR数据，用于比较不同扫描模式在车辆定位中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大多数研究依赖重复扫描LiDAR，而非重复扫描LiDAR具有消除盲区和成本效益的优势，但其在路边感知和定位中的应用仍然有限。

Method: 收集了来自重复和非重复扫描LiDAR的数据，构建包含5,445帧点云的数据集，涵盖8种车辆轨迹序列和多样化的轨迹类型。

Result: 实验建立了基于基础设施的车辆定位基准，并比较了使用非重复和重复扫描LiDAR的方法性能。

Conclusion: 这项工作为选择最适合基础设施车辆定位的LiDAR扫描模式提供了宝贵见解，数据集对科学界是重要贡献。

Abstract: Vehicle localization using roadside LiDARs can provide centimeter-level
accuracy for cloud-controlled vehicles while simultaneously serving multiple
vehicles, enhanc-ing safety and efficiency. While most existing studies rely on
repetitive scanning LiDARs, non-repetitive scanning LiDAR offers advantages
such as eliminating blind zones and being more cost-effective. However, its
application in roadside perception and localization remains limited. To address
this, we present a dataset for infrastructure-based vehicle localization, with
data collected from both repetitive and non-repetitive scanning LiDARs, in
order to benchmark the performance of different LiDAR scanning patterns. The
dataset contains 5,445 frames of point clouds across eight vehicle trajectory
sequences, with diverse trajectory types. Our experiments establish base-lines
for infrastructure-based vehicle localization and compare the performance of
these methods using both non-repetitive and repetitive scanning LiDARs. This
work offers valuable insights for selecting the most suitable LiDAR scanning
pattern for infrastruc-ture-based vehicle localization. Our dataset is a
signifi-cant contribution to the scientific community, supporting advancements
in infrastructure-based perception and vehicle localization. The dataset and
source code are publicly available at:
https://github.com/sjtu-cyberc3/BenchRNR.

</details>


### [14] [Distributed Nash Equilibrium Seeking Algorithm in Aggregative Games for Heterogeneous Multi-Robot Systems](https://arxiv.org/abs/2509.15597)
*Yi Dong,Zhongguo Li,Sarvapali D. Ramchurn,Xiaowei Huang*

Main category: cs.RO

TL;DR: 本文提出了一种针对异构多机器人系统的分布式纳什均衡搜索算法，通过分布式优化和输出控制实现纳什均衡


<details>
  <summary>Details</summary>
Motivation: 解决异构多机器人系统中纳什均衡的分布式计算问题，利用相邻机器人间的信息共享来实现均衡状态

Method: 提出分布式优化算法计算纳什均衡作为每个机器人的定制参考，并为异构多机器人系统设计输出控制律来跟踪聚合博弈中的均衡点

Result: 算法被证明能够保证收敛并产生高效结果，通过数值仿真和物理机器人实验验证了方法的有效性

Conclusion: 该分布式算法成功实现了异构多机器人系统的纳什均衡寻求，具有收敛保证和实际应用价值

Abstract: This paper develops a distributed Nash Equilibrium seeking algorithm for
heterogeneous multi-robot systems. The algorithm utilises distributed
optimisation and output control to achieve the Nash equilibrium by leveraging
information shared among neighbouring robots. Specifically, we propose a
distributed optimisation algorithm that calculates the Nash equilibrium as a
tailored reference for each robot and designs output control laws for
heterogeneous multi-robot systems to track it in an aggregative game. We prove
that our algorithm is guaranteed to converge and result in efficient outcomes.
The effectiveness of our approach is demonstrated through numerical simulations
and empirical testing with physical robots.

</details>


### [15] [ORB: Operating Room Bot, Automating Operating Room Logistics through Mobile Manipulation](https://arxiv.org/abs/2509.15600)
*Jinkai Qiu,Yungjun Kim,Gaurav Sethia,Tanmay Agarwal,Siddharth Ghodasara,Zackory Erickson,Jeffrey Ichnowski*

Main category: cs.RO

TL;DR: 提出了一个名为ORB的手术室机器人框架，用于自动化医院手术室的物流任务，通过行为树架构整合物体识别、场景理解和运动规划功能，在手术室供应检索和补货操作中取得了高成功率。


<details>
  <summary>Details</summary>
Motivation: 医院手术室中高效递送物品关乎生死，虽然现代医院已成功使用配送机器人在房间和楼层间运输大宗物品，但自动化手术室物品级物流在感知、效率和保持无菌方面面临独特挑战。

Method: ORB采用分层行为树架构，整合了基于YOLOv7、SAM2和Grounded DINO的实时物体识别流水线，并适配cuRobo并行轨迹优化框架实现实时无碰撞移动操作。

Result: 实证验证显示，ORB在手术室供应检索中达到80%的成功率，在补货操作中达到96%的成功率。

Conclusion: ORB被证明是一个可靠且适应性强的自主手术室物流系统，为手术室自动化物流提供了有效的解决方案。

Abstract: Efficiently delivering items to an ongoing surgery in a hospital operating
room can be a matter of life or death. In modern hospital settings, delivery
robots have successfully transported bulk items between rooms and floors.
However, automating item-level operating room logistics presents unique
challenges in perception, efficiency, and maintaining sterility. We propose the
Operating Room Bot (ORB), a robot framework to automate logistics tasks in
hospital operating rooms (OR). ORB leverages a robust, hierarchical behavior
tree (BT) architecture to integrate diverse functionalities of object
recognition, scene interpretation, and GPU-accelerated motion planning. The
contributions of this paper include: (1) a modular software architecture
facilitating robust mobile manipulation through behavior trees; (2) a novel
real-time object recognition pipeline integrating YOLOv7, Segment Anything
Model 2 (SAM2), and Grounded DINO; (3) the adaptation of the cuRobo
parallelized trajectory optimization framework to real-time, collision-free
mobile manipulation; and (4) empirical validation demonstrating an 80% success
rate in OR supply retrieval and a 96% success rate in restocking operations.
These contributions establish ORB as a reliable and adaptable system for
autonomous OR logistics.

</details>


### [16] [PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models](https://arxiv.org/abs/2509.15607)
*Ruiqi Wang,Dezhong Zhao,Ziqin Yuan,Tianyu Shao,Guohua Chen,Dominic Kao,Sungeun Hong,Byung-Cheol Min*

Main category: cs.RO

TL;DR: PRIMT是一个基于偏好的强化学习框架，利用基础模型提供多模态合成反馈和轨迹合成，通过分层神经符号融合策略和前瞻/后顾轨迹生成技术，解决了传统PbRL对大量人工输入的依赖以及查询模糊性和信用分配问题。


<details>
  <summary>Details</summary>
Motivation: 传统偏好强化学习(PbRL)存在两个关键挑战：对大量人工输入的依赖，以及在奖励学习过程中解决查询模糊性和信用分配的固有困难。

Method: PRIMT采用分层神经符号融合策略，整合大型语言模型和视觉语言模型的互补优势来评估机器人行为；包含前瞻轨迹生成（通过引导样本预热轨迹缓冲区）和后顾轨迹增强（通过因果辅助损失实现反事实推理）。

Result: 在2个运动任务和6个操作任务上的评估显示，PRIMT在多个基准测试中优于基于基础模型和脚本的基线方法。

Conclusion: PRIMT通过利用基础模型的多模态能力，有效解决了PbRL中的关键挑战，为机器人复杂行为学习提供了更高效和可靠的解决方案。

Abstract: Preference-based reinforcement learning (PbRL) has emerged as a promising
paradigm for teaching robots complex behaviors without reward engineering.
However, its effectiveness is often limited by two critical challenges: the
reliance on extensive human input and the inherent difficulties in resolving
query ambiguity and credit assignment during reward learning. In this paper, we
introduce PRIMT, a PbRL framework designed to overcome these challenges by
leveraging foundation models (FMs) for multimodal synthetic feedback and
trajectory synthesis. Unlike prior approaches that rely on single-modality FM
evaluations, PRIMT employs a hierarchical neuro-symbolic fusion strategy,
integrating the complementary strengths of large language models and
vision-language models in evaluating robot behaviors for more reliable and
comprehensive feedback. PRIMT also incorporates foresight trajectory
generation, which reduces early-stage query ambiguity by warm-starting the
trajectory buffer with bootstrapped samples, and hindsight trajectory
augmentation, which enables counterfactual reasoning with a causal auxiliary
loss to improve credit assignment. We evaluate PRIMT on 2 locomotion and 6
manipulation tasks on various benchmarks, demonstrating superior performance
over FM-based and scripted baselines.

</details>


### [17] [Miniature soft robot with magnetically reprogrammable surgical functions](https://arxiv.org/abs/2509.15610)
*Chelsea Shan Xian Ng,Yu Xuan Yeoh,Nicholas Yong Wei Foo,Keerthana Radhakrishnan,Guo Zhan Lum*

Main category: cs.RO

TL;DR: 本文提出了一种毫米级软体机器人，其磁化轮廓可重新编程，实现五种手术功能，并具备完整的六自由度运动能力，可在弱磁场下穿透生物组织进行控制。


<details>
  <summary>Details</summary>
Motivation: 现有磁性微型机器人要么功能有限（最多两种功能），要么只有五自由度运动能力，且需要强磁场近距离操作，限制了其在手术中的实际应用。

Method: 开发了一种毫米级软体机器人，其磁化轮廓可根据指令重新编程，能够在相对均匀且弱的磁场（最多65 mT和1.5 T/m）下实现六自由度运动。

Result: 该机器人成功实现了五种手术功能：药物释放、切割生物组织、抓取、存储样本和远程加热，并能通过滚动和双锚爬行穿越具有挑战性的非结构化环境。

Conclusion: 这项工作标志着软体致动器发展的一个重要里程碑，有望通过具有前所未有功能的无线微型机器人彻底改变微创治疗。

Abstract: Miniature robots are untethered actuators, which have significant potential
to make existing minimally invasive surgery considerably safer and painless,
and enable unprecedented treatments because they are much smaller and dexterous
than existing surgical robots. Of the miniature robots, the magnetically
actuated ones are the most functional and dexterous. However, existing magnetic
miniature robots are currently impractical for surgery because they are either
restricted to possessing at most two on-board functionalities or having limited
five degrees-of-freedom (DOF) locomotion. Some of these actuators are also only
operational under specialized environments where actuation from strong external
magnets must be at very close proximity (< 4 cm away). Here we present a
millimeter-scale soft robot where its magnetization profile can be reprogrammed
upon command to perform five surgical functionalities: drug-dispensing, cutting
through biological tissues (simulated with gelatin), gripping, storing
(biological) samples and remote heating. By possessing full six-DOF motions,
including the sixth-DOF rotation about its net magnetic moment, our soft robot
can also roll and two-anchor crawl across challenging unstructured
environments, which are impassable by its five-DOF counterparts. Because our
actuating magnetic fields are relatively uniform and weak (at most 65 mT and
1.5 T/m), such fields can theoretically penetrate through biological tissues
harmlessly and allow our soft robot to remain controllable within the depths of
the human body. We envision that this work marks a major milestone for the
advancement of soft actuators, and towards revolutionizing minimally invasive
treatments with untethered miniature robots that have unprecedented
functionalities.

</details>


### [18] [Indoor Positioning Based on Active Radar Sensing and Passive Reflectors: Reflector Placement Optimization](https://arxiv.org/abs/2509.15613)
*Sven Hinderer,Pascal Schlachter,Zhibin Yu,Xiaofeng Wu,Bin Yang*

Main category: cs.RO

TL;DR: 提出了一种基于雷达感知的室内定位系统，通过结合简单反射器和单通道FMCW雷达实现低成本高精度定位，并介绍了多目标粒子群优化算法来优化复杂房间中雷达反射器的二维布局。


<details>
  <summary>Details</summary>
Motivation: 为自主移动机器人开发低成本、高精度的室内定位系统，解决传统定位系统成本高或精度不足的问题。

Method: 使用单通道频率调制连续波雷达和被动雷达反射器，结合多目标粒子群优化算法优化反射器在复杂房间环境中的二维布局。

Result: 实现了高定位精度和低系统成本的平衡，系统在复杂室内环境中表现出良好的定位性能。

Conclusion: 该方法为自主移动机器人提供了一种经济有效的室内定位解决方案，多目标优化算法有效提升了系统在复杂环境中的性能。

Abstract: We extend our work on a novel indoor positioning system (IPS) for autonomous
mobile robots (AMRs) based on radar sensing of local, passive radar reflectors.
Through the combination of simple reflectors and a single-channel frequency
modulated continuous wave (FMCW) radar, high positioning accuracy at low system
cost can be achieved. Further, a multi-objective (MO) particle swarm
optimization (PSO) algorithm is presented that optimizes the 2D placement of
radar reflectors in complex room settings.

</details>


### [19] [Omni-LIVO: Robust RGB-Colored Multi-Camera Visual-Inertial-LiDAR Odometry via Photometric Migration and ESIKF Fusion](https://arxiv.org/abs/2509.15673)
*Yinong Cao,Xin He,Yuwei Chen,Chenyang Zhang,Chengyu Pu,Bingtao Wang,Kaile Wu,Shouzheng Zhu,Fei Han,Shijie Liu,Chunlai Li,Jianyu Wang*

Main category: cs.RO

TL;DR: Omni-LIVO是首个紧密耦合的多相机LiDAR-惯性-视觉里程计系统，通过跨视图直接跟踪策略解决宽角LiDAR与传统相机之间的视场不匹配问题，在公开基准和自定义数据集上表现出优于现有方法的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR-惯性-视觉里程计系统大多依赖单个相机，导致空间覆盖有限且鲁棒性降低。宽视场LiDAR传感器能提供大范围环境的密集几何信息，但与传统相机存在视场不匹配问题。

Method: 提出跨视图直接跟踪策略，在非重叠视图间保持光度一致性；扩展误差状态迭代卡尔曼滤波器，增加多视图更新和自适应协方差加权功能。

Result: 在公开基准和自定义数据集上的评估表明，该系统在精度和鲁棒性方面优于当前最先进的LIVO、LIO和视觉-惯性基线方法。

Conclusion: Omni-LIVO成功解决了宽角LiDAR与多相机系统的视场匹配问题，为大规模环境下的鲁棒定位提供了有效解决方案，代码和数据集将在发表后公开。

Abstract: Wide field-of-view (FoV) LiDAR sensors provide dense geometry across large
environments, but most existing LiDAR-inertial-visual odometry (LIVO) systems
rely on a single camera, leading to limited spatial coverage and degraded
robustness. We present Omni-LIVO, the first tightly coupled multi-camera LIVO
system that bridges the FoV mismatch between wide-angle LiDAR and conventional
cameras. Omni-LIVO introduces a Cross-View direct tracking strategy that
maintains photometric consistency across non-overlapping views, and extends the
Error-State Iterated Kalman Filter (ESIKF) with multi-view updates and adaptive
covariance weighting. The system is evaluated on public benchmarks and our
custom dataset, showing improved accuracy and robustness over state-of-the-art
LIVO, LIO, and visual-inertial baselines. Code and dataset will be released
upon publication.

</details>


### [20] [Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference](https://arxiv.org/abs/2509.15717)
*Haoran Ding,Anqing Duan,Zezhou Sun,Dezhen Song,Yoshihiko Nakamura*

Main category: cs.RO

TL;DR: 提出了一种通过新颖视角合成技术让机器人能够"想象"手部视角观察的方法，以解决硬件限制下无法安装手部摄像头的问题。


<details>
  <summary>Details</summary>
Motivation: 由于硬件约束、系统复杂性和成本问题，为机器人配备专用手部摄像头存在挑战，但手部视角对于精确控制至关重要。

Method: 使用基于LoRA微调的预训练新颖视角合成模型(ZeroNVS)，根据代理视角和手部视角相机之间的相对位姿条件来合成手部观察。

Result: 在仿真基准(RoboMimic和MimicGen)和真实世界草莓采摘任务中，合成的手部视角显著提升了策略推理性能，有效恢复了因缺少真实手部摄像头导致的性能下降。

Conclusion: 该方法为部署鲁棒的视觉运动策略提供了可扩展且硬件要求低的解决方案，展示了具身智能体中想象视觉推理的潜力。

Abstract: Visual observations from different viewpoints can significantly influence the
performance of visuomotor policies in robotic manipulation. Among these,
egocentric (in-hand) views often provide crucial information for precise
control. However, in some applications, equipping robots with dedicated in-hand
cameras may pose challenges due to hardware constraints, system complexity, and
cost. In this work, we propose to endow robots with imaginative perception -
enabling them to 'imagine' in-hand observations from agent views at inference
time. We achieve this via novel view synthesis (NVS), leveraging a fine-tuned
diffusion model conditioned on the relative pose between the agent and in-hand
views cameras. Specifically, we apply LoRA-based fine-tuning to adapt a
pretrained NVS model (ZeroNVS) to the robotic manipulation domain. We evaluate
our approach on both simulation benchmarks (RoboMimic and MimicGen) and
real-world experiments using a Unitree Z1 robotic arm for a strawberry picking
task. Results show that synthesized in-hand views significantly enhance policy
inference, effectively recovering the performance drop caused by the absence of
real in-hand cameras. Our method offers a scalable and hardware-light solution
for deploying robust visuomotor policies, highlighting the potential of
imaginative visual reasoning in embodied agents.

</details>


### [21] [GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation](https://arxiv.org/abs/2509.15733)
*Quanhao Qian,Guoyang Zhao,Gongjie Zhang,Jiuniu Wang,Ran Xu,Junlong Gao,Deli Zhao*

Main category: cs.RO

TL;DR: GP3是一个3D几何感知的机器人操作策略，利用多视角输入来获取精确的3D场景几何信息，在模拟和真实世界中都表现出色。


<details>
  <summary>Details</summary>
Motivation: 机器人精确操作依赖于对3D场景几何的准确理解，多视角观察是获取这种几何信息的最直接方法。

Method: GP3使用空间编码器从RGB观测中推断密集空间特征，估计深度和相机参数，构建紧凑的3D场景表示，然后与语言指令融合，通过轻量级策略头转换为连续动作。

Result: 在模拟基准测试中，GP3始终优于最先进的方法，并且能够有效迁移到没有深度传感器或预建地图的真实世界机器人，只需少量微调。

Conclusion: GP3是一个实用的、传感器无关的几何感知机器人操作解决方案。

Abstract: Effective robotic manipulation relies on a precise understanding of 3D scene
geometry, and one of the most straightforward ways to acquire such geometry is
through multi-view observations. Motivated by this, we present GP3 -- a 3D
geometry-aware robotic manipulation policy that leverages multi-view input. GP3
employs a spatial encoder to infer dense spatial features from RGB
observations, which enable the estimation of depth and camera parameters,
leading to a compact yet expressive 3D scene representation tailored for
manipulation. This representation is fused with language instructions and
translated into continuous actions via a lightweight policy head. Comprehensive
experiments demonstrate that GP3 consistently outperforms state-of-the-art
methods on simulated benchmarks. Furthermore, GP3 transfers effectively to
real-world robots without depth sensors or pre-mapped environments, requiring
only minimal fine-tuning. These results highlight GP3 as a practical,
sensor-agnostic solution for geometry-aware robotic manipulation.

</details>


### [22] [SMART: Scalable Multi-Agent Reasoning and Trajectory Planning in Dense Environments](https://arxiv.org/abs/2509.15737)
*Heye Huang,Yibin Yang,Wang Chen,Tiantian Chen,Xiaopeng Li,Sikai Chen*

Main category: cs.RO

TL;DR: SMART是一个分层多车轨迹规划框架，结合优先级搜索和分布式优化，在密集环境中实现高效可行的多车协调规划。


<details>
  <summary>Details</summary>
Motivation: 多车轨迹规划是非凸问题，在密集环境中由于碰撞约束快速增长而变得困难，需要高效探索可行行为并解决紧密交互以实现实时大规模协调。

Method: 分层框架：上层通过强化学习优先级估计和大步长混合A*搜索探索交互模式；下层通过可并行凸优化细化解。通过空间分区和构建鲁棒可行走廊，将联合非凸问题分解为可并行高效求解的凸子问题。

Result: 在50m×50m地图上，SMART在1秒内维持90%以上成功率至25辆车，而基线常低于50%。在100m×100m地图上，SMART达到95%以上成功率至50辆车，可行至90辆车，运行时间比纯优化方法快一个数量级。实际实验规划时间低至0.014秒。

Conclusion: SMART通过车路协同和智能体协调，提高了可扩展性和安全性，验证了该设计的有效性，能够实现高效的大规模多车轨迹规划。

Abstract: Multi-vehicle trajectory planning is a non-convex problem that becomes
increasingly difficult in dense environments due to the rapid growth of
collision constraints. Efficient exploration of feasible behaviors and
resolution of tight interactions are essential for real-time, large-scale
coordination. This paper introduces SMART, Scalable Multi-Agent Reasoning and
Trajectory Planning, a hierarchical framework that combines priority-based
search with distributed optimization to achieve efficient and feasible
multi-vehicle planning. The upper layer explores diverse interaction modes
using reinforcement learning-based priority estimation and large-step hybrid A*
search, while the lower layer refines solutions via parallelizable convex
optimization. By partitioning space among neighboring vehicles and constructing
robust feasible corridors, the method decouples the joint non-convex problem
into convex subproblems solved efficiently in parallel. This design alleviates
the step-size trade-off while ensuring kinematic feasibility and collision
avoidance. Experiments show that SMART consistently outperforms baselines. On
50 m x 50 m maps, it sustains over 90% success within 1 s up to 25 vehicles,
while baselines often drop below 50%. On 100 m x 100 m maps, SMART achieves
above 95% success up to 50 vehicles and remains feasible up to 90 vehicles,
with runtimes more than an order of magnitude faster than optimization-only
approaches. Built on vehicle-to-everything communication, SMART incorporates
vehicle-infrastructure cooperation through roadside sensing and agent
coordination, improving scalability and safety. Real-world experiments further
validate this design, achieving planning times as low as 0.014 s while
preserving cooperative behaviors.

</details>


### [23] [FlyKites: Human-centric Interactive Exploration and Assistance under Limited Communication](https://arxiv.org/abs/2509.15807)
*Yuyang Zhang,Zhuoli Tian,Jinsheng Wei,Meng Guo*

Main category: cs.RO

TL;DR: FlyKites是一个面向多机器人系统在有限通信条件下的新型人机交互探索与辅助框架，包含分布式探索、中继拓扑优化和人机在线执行三个组件


<details>
  <summary>Details</summary>
Motivation: 解决在极端环境下（如洞穴、地下隧道）多机器人系统通信受限时，需要人类持续辅助但通信困难的问题

Method: 采用三种交替模式：分布式探索与间歇通信（扩散模式）、中继拓扑与操作员路径的同步优化（中继模式）、人机在线自适应交互执行

Result: 通过大量具有挑战性场景的人机回路仿真和硬件实验验证了框架的有效性

Conclusion: FlyKites框架能够有效支持多机器人在有限通信条件下的协同探索和人类辅助

Abstract: Fleets of autonomous robots have been deployed for exploration of unknown
scenes for features of interest, e.g., subterranean exploration,
reconnaissance, search and rescue missions. During exploration, the robots may
encounter un-identified targets, blocked passages, interactive objects,
temporary failure, or other unexpected events, all of which require consistent
human assistance with reliable communication for a time period. This however
can be particularly challenging if the communication among the robots is
severely restricted to only close-range exchange via ad-hoc networks,
especially in extreme environments like caves and underground tunnels. This
paper presents a novel human-centric interactive exploration and assistance
framework called FlyKites, for multi-robot systems under limited communication.
It consists of three interleaved components: (I) the distributed exploration
and intermittent communication (called the "spread mode"), where the robots
collaboratively explore the environment and exchange local data among the fleet
and with the operator; (II) the simultaneous optimization of the relay
topology, the operator path, and the assignment of robots to relay roles
(called the "relay mode"), such that all requested assistance can be provided
with minimum delay; (III) the human-in-the-loop online execution, where the
robots switch between different roles and interact with the operator
adaptively. Extensive human-in-the-loop simulations and hardware experiments
are performed over numerous challenging scenes.

</details>


### [24] [Coordinated Multi-Drone Last-mile Delivery: Learning Strategies for Energy-aware and Timely Operations](https://arxiv.org/abs/2509.15830)
*Chuhao Qin,Arun Narayanan,Evangelos Pournaras*

Main category: cs.RO

TL;DR: 该论文提出了一种基于多智能体深度强化学习的无人机群多包裹配送优化方法，通过分解问题为三个子问题并集成解决方案，实现了能量感知和时间敏感的无人机配送优化。


<details>
  <summary>Details</summary>
Motivation: 无人机在最后一公里配送中具有快速、安全、成本效益高的优势，特别是在疫情期间的紧急医疗配送中表现突出。但多包裹配送中需要考虑时间敏感需求和能量限制的新挑战。

Method: 将问题分解为三个子问题：1）使用K-means聚类优化仓库位置和服务区域；2）通过强化学习确定无人机最优飞行范围；3）采用新的优化计划选择方法规划多包裹配送路线。提出基于actor-critic的多智能体深度强化学习算法集成这些解决方案。

Result: 使用真实配送数据集进行广泛实验，证明所提算法在减少配送延迟、降低能耗和缩短整体执行时间方面表现优异。

Conclusion: 该研究为实际物流应用提供了经济效率（最小化能耗）、快速操作（减少配送延迟）和仓库部署战略指导的新见解。

Abstract: Drones have recently emerged as a faster, safer, and cost-efficient way for
last-mile deliveries of parcels, particularly for urgent medical deliveries
highlighted during the pandemic. This paper addresses a new challenge of
multi-parcel delivery with a swarm of energy-aware drones, accounting for
time-sensitive customer requirements. Each drone plans an optimal multi-parcel
route within its battery-restricted flight range to minimize delivery delays
and reduce energy consumption. The problem is tackled by decomposing it into
three sub-problems: (1) optimizing depot locations and service areas using
K-means clustering; (2) determining the optimal flight range for drones through
reinforcement learning; and (3) planning and selecting multi-parcel delivery
routes via a new optimized plan selection approach. To integrate these
solutions and enhance long-term efficiency, we propose a novel algorithm
leveraging actor-critic-based multi-agent deep reinforcement learning.
Extensive experimentation using realistic delivery datasets demonstrate an
exceptional performance of the proposed algorithm. We provide new insights into
economic efficiency (minimize energy consumption), rapid operations (reduce
delivery delays and overall execution time), and strategic guidance on depot
deployment for practical logistics applications.

</details>


### [25] [High-Bandwidth Tactile-Reactive Control for Grasp Adjustment](https://arxiv.org/abs/2509.15876)
*Yonghyeon Lee,Tzu-Yuan Lin,Alexander Alexiev,Sangbae Kim*

Main category: cs.RO

TL;DR: 提出了一种仅基于触觉反馈的抓取调整算法，该控制器无需物体几何先验知识或精确抓取姿态，能够从粗糙的初始配置和不确定接触点中优化抓取稳定性。


<details>
  <summary>Details</summary>
Motivation: 视觉抓取系统受限于校准误差、传感器噪声和抓取姿态预测不准确，导致最终抓取阶段存在不可避免的接触不确定性。高带宽触觉反馈与精心设计的触觉反应控制器可以显著提高在感知错误情况下的鲁棒性。

Method: 开发了纯触觉反馈的抓取调整算法，通过配备200Hz指尖触觉传感器的15自由度臂手系统（其中手部8自由度）进行仿真和真实实验验证。

Result: 实验证明该触觉反应抓取框架有效提高了抓取稳定性。

Conclusion: 该研究为控制器设计做出了贡献，展示了触觉反馈在改善抓取鲁棒性方面的重要价值。

Abstract: Vision-only grasping systems are fundamentally constrained by calibration
errors, sensor noise, and grasp pose prediction inaccuracies, leading to
unavoidable contact uncertainty in the final stage of grasping. High-bandwidth
tactile feedback, when paired with a well-designed tactile-reactive controller,
can significantly improve robustness in the presence of perception errors. This
paper contributes to controller design by proposing a purely tactile-feedback
grasp-adjustment algorithm. The proposed controller requires neither prior
knowledge of the object's geometry nor an accurate grasp pose, and is capable
of refining a grasp even when starting from a crude, imprecise initial
configuration and uncertain contact points. Through simulation studies and
real-world experiments on a 15-DoF arm-hand system (featuring an 8-DoF hand)
equipped with fingertip tactile sensors operating at 200 Hz, we demonstrate
that our tactile-reactive grasping framework effectively improves grasp
stability.

</details>


### [26] [Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder](https://arxiv.org/abs/2509.15880)
*An Dinh Vuong,Minh Nhat Vu,Ian Reid*

Main category: cs.RO

TL;DR: 该论文提出了一种高效的几何感知视觉编码器eVGGT，通过从VGGT中蒸馏得到，在保持强大3D推理能力的同时，计算效率提升了9倍，模型大小减少了5倍，并在机器人模仿学习中实现了6.5%的成功率提升。


<details>
  <summary>Details</summary>
Motivation: 现有的基于RGB的模仿学习方法使用传统视觉编码器（如ResNet、ViT）缺乏显式的3D推理能力，而现有的几何感知模型计算成本高，限制了在实际机器人系统中的部署。

Method: 提出eVGGT，一种从VGGT蒸馏得到的高效几何感知编码器，通过知识蒸馏技术保持3D推理能力的同时大幅降低计算复杂度。

Result: eVGGT比VGGT快近9倍，小5倍，在ACT和DP等模仿学习框架中，相比标准视觉编码器在单臂和双臂操作任务中成功率提升达6.5%。

Conclusion: 几何感知视觉表示能显著提升机器人操作性能，eVGGT为实际机器人系统提供了高效可行的解决方案，代码和预训练模型将开源以促进几何感知机器人研究。

Abstract: Existing RGB-based imitation learning approaches typically employ traditional
vision encoders such as ResNet or ViT, which lack explicit 3D reasoning
capabilities. Recent geometry-grounded vision models, such as
VGGT~\cite{wang2025vggt}, provide robust spatial understanding and are
promising candidates to address this limitation. This work investigates the
integration of geometry-aware visual representations into robotic manipulation.
Our results suggest that incorporating the geometry-aware vision encoder into
imitation learning frameworks, including ACT and DP, yields up to 6.5%
improvement over standard vision encoders in success rate across single- and
bi-manual manipulation tasks in both simulation and real-world settings.
Despite these benefits, most geometry-grounded models require high
computational cost, limiting their deployment in practical robotic systems. To
address this challenge, we propose eVGGT, an efficient geometry-aware encoder
distilled from VGGT. eVGGT is nearly 9 times faster and 5 times smaller than
VGGT, while preserving strong 3D reasoning capabilities. Code and pretrained
models will be released to facilitate further research in geometry-aware
robotics.

</details>


### [27] [An MPC framework for efficient navigation of mobile robots in cluttered environments](https://arxiv.org/abs/2509.15917)
*Johannes Köhler,Daniel Zhang,Raffaele Soloperto,Andrea Carron,Melanie Zeilinger*

Main category: cs.RO

TL;DR: 提出一种模型预测控制框架，用于移动机器人在复杂环境中的高效导航，通过集成最短路径规划器到轨迹优化中，确保收敛到动态目标并保证避障。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在杂乱环境中导航的挑战，特别是在非线性动态和动态目标分配情况下的安全高效导航需求。

Method: 将有限段最短路径规划器集成到MPC的有限时域轨迹优化中，支持非线性动态系统和复杂环境下的避障。

Result: 硬件实验验证了该方法的有效性，小型地面机器人能够在2-3秒内成功导航通过复杂环境并到达新目标。

Conclusion: 该MPC框架为移动机器人提供了在复杂环境中可靠导航的解决方案，具有良好的实时性和安全性。

Abstract: We present a model predictive control (MPC) framework for efficient
navigation of mobile robots in cluttered environments. The proposed approach
integrates a finite-segment shortest path planner into the finite-horizon
trajectory optimization of the MPC. This formulation ensures convergence to
dynamically selected targets and guarantees collision avoidance, even under
general nonlinear dynamics and cluttered environments. The approach is
validated through hardware experiments on a small ground robot, where a human
operator dynamically assigns target locations. The robot successfully navigated
through complex environments and reached new targets within 2-3 seconds.

</details>


### [28] [A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning](https://arxiv.org/abs/2509.15937)
*Shaopeng Zhai,Qi Zhang,Tianyi Zhang,Fuxian Huang,Haoran Zhang,Ming Zhou,Shengzhe Zhang,Litao Liu,Sixu Lin,Jiangmiao Pang*

Main category: cs.RO

TL;DR: VLAC是一个基于InternVL构建的通用过程奖励模型，通过大规模异构数据集训练，能够为视觉-语言-动作模型提供密集的进度奖励信号，无需任务特定的奖励工程，并在真实世界机器人强化学习中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前机器人真实世界强化学习受限于稀疏的手工奖励和低效的探索，需要开发能够提供密集奖励信号并支持高效探索的通用模型。

Method: VLAC模型在视觉语言数据集上训练以增强感知和推理能力，结合机器人和人类轨迹数据进行动作生成和进度估计，通过构造大量负样本增强鲁棒性。模型采用提示控制，交替生成奖励和动作标记，统一了评论家和策略。

Result: 在四个不同的真实世界操作任务中，VLAC将成功率从约30%提升至约90%（200次交互内）；结合人在环干预进一步提高了50%的样本效率，最终成功率可达100%。

Conclusion: VLAC提供了一个有效的通用过程奖励模型框架，通过密集奖励信号和人在环协议显著提升了真实世界机器人强化学习的效率和性能。

Abstract: Robotic real-world reinforcement learning (RL) with vision-language-action
(VLA) models is bottlenecked by sparse, handcrafted rewards and inefficient
exploration. We introduce VLAC, a general process reward model built upon
InternVL and trained on large scale heterogeneous datasets. Given pairwise
observations and a language goal, it outputs dense progress delta and done
signal, eliminating task-specific reward engineering, and supports one-shot
in-context transfer to unseen tasks and environments. VLAC is trained on
vision-language datasets to strengthen perception, dialogic and reasoning
capabilities, together with robot and human trajectories data that ground
action generation and progress estimation, and additionally strengthened to
reject irrelevant prompts as well as detect regression or stagnation by
constructing large numbers of negative and semantically mismatched samples.
With prompt control, a single VLAC model alternately generating reward and
action tokens, unifying critic and policy. Deployed inside an asynchronous
real-world RL loop, we layer a graded human-in-the-loop protocol (offline
demonstration replay, return and explore, human guided explore) that
accelerates exploration and stabilizes early learning. Across four distinct
real-world manipulation tasks, VLAC lifts success rates from about 30\% to
about 90\% within 200 real-world interaction episodes; incorporating
human-in-the-loop interventions yields a further 50% improvement in sample
efficiency and achieves up to 100% final success.

</details>


### [29] [Right-Side-Out: Learning Zero-Shot Sim-to-Real Garment Reversal](https://arxiv.org/abs/2509.15953)
*Chang Yu,Siyu Ma,Wenxin Du,Zeshun Zong,Han Xue,Wendi Chen,Cewu Lu,Yin Yang,Xuchen Han,Joseph Masterjohn,Alejandro Castro,Chenfanfu Jiang*

Main category: cs.RO

TL;DR: 提出了一个名为Right-Side-Out的零样本仿真到现实框架，用于解决衣物翻转这一具有挑战性的动态操作任务。通过任务分解和高效数据生成，在无需人工标注的情况下实现了81.3%的成功率。


<details>
  <summary>Details</summary>
Motivation: 衣物翻转任务具有高度动态性、快速接触变化和严重视觉遮挡等挑战，传统方法难以有效处理。

Method: 将任务分解为Drag/Fling和Insert&Pull两个步骤，使用基于深度推断的关键点参数化双手机器人基元；开发了基于材料点方法的高保真GPU并行模拟器进行高效数据生成。

Result: 在真实硬件上实现了零样本部署，成功率高达81.3%。

Conclusion: 通过任务分解和高保真仿真，该框架能够处理高度动态且严重遮挡的任务，无需繁琐的人工演示。

Abstract: Turning garments right-side out is a challenging manipulation task: it is
highly dynamic, entails rapid contact changes, and is subject to severe visual
occlusion. We introduce Right-Side-Out, a zero-shot sim-to-real framework that
effectively solves this challenge by exploiting task structures. We decompose
the task into Drag/Fling to create and stabilize an access opening, followed by
Insert&Pull to invert the garment. Each step uses a depth-inferred,
keypoint-parameterized bimanual primitive that sharply reduces the action space
while preserving robustness. Efficient data generation is enabled by our
custom-built, high-fidelity, GPU-parallel Material Point Method (MPM) simulator
that models thin-shell deformation and provides robust and efficient contact
handling for batched rollouts. Built on the simulator, our fully automated
pipeline scales data generation by randomizing garment geometry, material
parameters, and viewpoints, producing depth, masks, and per-primitive keypoint
labels without any human annotations. With a single depth camera, policies
trained entirely in simulation deploy zero-shot on real hardware, achieving up
to 81.3% success rate. By employing task decomposition and high fidelity
simulation, our framework enables tackling highly dynamic, severely occluded
tasks without laborious human demonstrations.

</details>


### [30] [Swarm Oracle: Trustless Blockchain Agreements through Robot Swarms](https://arxiv.org/abs/2509.15956)
*Alexandre Pacheco,Hanqing Zhao,Volker Strobel,Tarik Roukny,Gregory Dudek,Andreagiovanni Reina,Marco Dorigo*

Main category: cs.RO

TL;DR: Swarm Oracle是一个去中心化的机器人网络，利用机器人集群的传感器和点对点通信来验证现实世界数据并提供给区块链智能合约，解决了区块链无法直接访问现实世界数据的问题。


<details>
  <summary>Details</summary>
Motivation: 区块链共识机制限制了访问现实世界数据的能力，现有预言机解决方案可能降低自治性、透明度或重新引入信任需求。需要一种能够保持去中心化特性的解决方案。

Method: 采用拜占庭容错协议，让来自不同利益相关方的机器人协同工作，通过共识机制达成比单个机器人更高质量的社会协议。使用基于区块链代币的声誉系统实现自主故障恢复。

Result: 通过真实和模拟机器人的广泛实验证明，即使在大量机器人发起攻击的情况下，也能在不确定的环境信息上达成共识，系统能够自主从故障和攻击中恢复。

Conclusion: Swarm Oracle展示了机器人集群如何为区块链提供安全、无需信任的全球共识，满足长期运营的需求，为区块链与现实世界数据的集成提供了创新解决方案。

Abstract: Blockchain consensus, rooted in the principle ``don't trust, verify'', limits
access to real-world data, which may be ambiguous or inaccessible to some
participants. Oracles address this limitation by supplying data to blockchains,
but existing solutions may reduce autonomy, transparency, or reintroduce the
need for trust. We propose Swarm Oracle: a decentralized network of autonomous
robots -- that is, a robot swarm -- that use onboard sensors and peer-to-peer
communication to collectively verify real-world data and provide it to smart
contracts on public blockchains. Swarm Oracle leverages the built-in
decentralization, fault tolerance and mobility of robot swarms, which can
flexibly adapt to meet information requests on-demand, even in remote
locations. Unlike typical cooperative robot swarms, Swarm Oracle integrates
robots from multiple stakeholders, protecting the system from single-party
biases but also introducing potential adversarial behavior. To ensure the
secure, trustless and global consensus required by blockchains, we employ a
Byzantine fault-tolerant protocol that enables robots from different
stakeholders to operate together, reaching social agreements of higher quality
than the estimates of individual robots. Through extensive experiments using
both real and simulated robots, we showcase how consensus on uncertain
environmental information can be achieved, despite several types of attacks
orchestrated by large proportions of the robots, and how a reputation system
based on blockchain tokens lets Swarm Oracle autonomously recover from faults
and attacks, a requirement for long-term operation.

</details>


### [31] [CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine](https://arxiv.org/abs/2509.15968)
*Shiyu Fang,Yiming Cui,Haoyang Liang,Chen Lv,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: CoReVLA是一个持续学习的端到端自动驾驶框架，通过数据收集和行为精炼双阶段过程，提升自动驾驶系统在长尾安全关键场景中的性能表现。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在长尾安全关键场景中表现有限，这些罕见场景导致了不成比例的事故数量。视觉语言动作模型具有强大推理能力，但受限于高质量数据缺乏和低效学习。

Method: 采用双阶段过程：1）在开源驾驶QA数据集上联合微调获得基础理解；2）在CAVE仿真平台部署收集驾驶员接管数据；3）通过直接偏好优化从人类偏好中学习，避免奖励设计问题。

Result: 在Bench2Drive基准测试中，CoReVLA获得72.18的驾驶评分和50%的成功率，在长尾安全关键场景下分别比最先进方法高出7.96分和15%。案例研究显示模型能持续改进性能。

Conclusion: CoReVLA框架能准确感知驾驶场景并做出适当决策，通过持续学习机制有效提升自动驾驶系统在安全关键场景中的可靠性。

Abstract: Autonomous Driving (AD) systems have made notable progress, but their
performance in long-tail, safety-critical scenarios remains limited. These rare
cases contribute a disproportionate number of accidents. Vision-Language Action
(VLA) models have strong reasoning abilities and offer a potential solution,
but their effectiveness is limited by the lack of high-quality data and
inefficient learning in such conditions. To address these challenges, we
propose CoReVLA, a continual learning end-to-end autonomous driving framework
that improves the performance in long-tail scenarios through a dual-stage
process of data Collection and behavior Refinement. First, the model is jointly
fine-tuned on a mixture of open-source driving QA datasets, allowing it to
acquire a foundational understanding of driving scenarios. Next, CoReVLA is
deployed within the Cave Automatic Virtual Environment (CAVE) simulation
platform, where driver takeover data is collected from real-time interactions.
Each takeover indicates a long-tail scenario that CoReVLA fails to handle
reliably. Finally, the model is refined via Direct Preference Optimization
(DPO), allowing it to learn directly from human preferences and thereby avoid
reward hacking caused by manually designed rewards. Extensive open-loop and
closed-loop experiments demonstrate that the proposed CoReVLA model can
accurately perceive driving scenarios and make appropriate decisions. On the
Bench2Drive benchmark, CoReVLA achieves a Driving Score (DS) of 72.18 and a
Success Rate (SR) of 50%, outperforming state-of-the-art methods by 7.96 DS and
15% SR under long-tail, safety-critical scenarios. Furthermore, case studies
demonstrate the model's ability to continually improve its performance in
similar failure-prone scenarios by leveraging past takeover experiences. All
codea and preprocessed datasets are available at:
https://github.com/FanGShiYuu/CoReVLA

</details>


### [32] [Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning](https://arxiv.org/abs/2509.16006)
*Francesco Argenziano,Elena Umili,Francesco Leotta,Daniele Nardi*

Main category: cs.RO

TL;DR: 本文提出了一种将大型语言模型（LLMs）与自动规划相结合的一般架构，使人类能够使用自然语言指定高级活动（也称为过程），并通过查询机器人来监控其执行。


<details>
  <summary>Details</summary>
Motivation: 在工业和农业等动态和不可预测的环境中部署机器人自动化劳动密集型和复杂活动时，人类监控高级活动的进展（包括过去、现在和未来的行动）对于确保安全关键流程的正确执行仍然至关重要。

Method: 引入一种将大型语言模型（LLMs）与自动规划相结合的一般架构，使用自然语言指定高级活动，并通过查询机器人监控执行。使用最先进的组件实现该架构，并在真实世界的精准农业场景中进行定量评估。

Result: 在真实世界的精准农业场景中对该方法进行了定量评估，证明了其有效性。

Conclusion: 该架构通过整合LLMs和自动规划，提供了一种有效的方式，使人类能够使用自然语言与机器人交互，并监控复杂活动的执行，从而在动态和不可预测的环境中提高自动化的可靠性和安全性。

Abstract: Recent years have witnessed a growing interest in automating labor-intensive
and complex activities, i.e., those consisting of multiple atomic tasks, by
deploying robots in dynamic and unpredictable environments such as industrial
and agricultural settings. A key characteristic of these contexts is that
activities are not predefined: while they involve a limited set of possible
tasks, their combinations may vary depending on the situation. Moreover,
despite recent advances in robotics, the ability for humans to monitor the
progress of high-level activities - in terms of past, present, and future
actions - remains fundamental to ensure the correct execution of
safety-critical processes. In this paper, we introduce a general architecture
that integrates Large Language Models (LLMs) with automated planning, enabling
humans to specify high-level activities (also referred to as processes) using
natural language, and to monitor their execution by querying a robot. We also
present an implementation of this architecture using state-of-the-art
components and quantitatively evaluate the approach in a real-world precision
agriculture scenario.

</details>


### [33] [A Matter of Height: The Impact of a Robotic Object on Human Compliance](https://arxiv.org/abs/2509.16032)
*Michael Faber,Andrey Grishko,Julian Waksberg,David Pardo,Tomer Leivy,Yuval Hazan,Emanuel Talmansky,Benny Megidish,Hadas Erel*

Main category: cs.RO

TL;DR: 研究探讨机器人身高对人类服从度的影响，发现与人类社交动态相反，较矮的机器人（95cm）比较高的机器人（132cm）获得更高的服从率。


<details>
  <summary>Details</summary>
Motivation: 人类互动中身高影响社交动态（高个子通常更具说服力），但机器人身高是否会产生类似影响尚不清楚，特别是对于非人形机器人。

Method: 设计可调节高度的模块化机器人（移动服务桌），在两种高度条件下（95cm短机器人 vs 132cm高机器人）测试参与者对机器人请求完成300题问卷的服从度。

Result: 短机器人获得更高的服从率，与人类社交模式相反。

Conclusion: 身高对人机互动有重要社会影响，但遵循独特模式，不能简单套用人类社交动态到机器人设计中。

Abstract: Robots come in various forms and have different characteristics that may
shape the interaction with them. In human-human interactions, height is a
characteristic that shapes human dynamics, with taller people typically
perceived as more persuasive. In this work, we aspired to evaluate if the same
impact replicates in a human-robot interaction and specifically with a highly
non-humanoid robotic object. The robot was designed with modules that could be
easily added or removed, allowing us to change its height without altering
other design features. To test the impact of the robot's height, we evaluated
participants' compliance with its request to volunteer to perform a tedious
task. In the experiment, participants performed a cognitive task on a computer,
which was framed as the main experiment. When done, they were informed that the
experiment was completed. While waiting to receive their credits, the robotic
object, designed as a mobile robotic service table, entered the room, carrying
a tablet that invited participants to complete a 300-question questionnaire
voluntarily. We compared participants' compliance in two conditions: A Short
robot composed of two modules and 95cm in height and a Tall robot consisting of
three modules and 132cm in height. Our findings revealed higher compliance with
the Short robot's request, demonstrating an opposite pattern to human dynamics.
We conclude that while height has a substantial social impact on human-robot
interactions, it follows a unique pattern of influence. Our findings suggest
that designers cannot simply adopt and implement elements from human social
dynamics to robots without testing them first.

</details>


### [34] [Learning Safety for Obstacle Avoidance via Control Barrier Functions](https://arxiv.org/abs/2509.16037)
*Shuo Liu,Zhe Huang,Calin A. Belta*

Main category: cs.RO

TL;DR: 提出了一种基于神经网络的局部安全球方法，用于处理任意几何形状机器人在复杂环境中的实时避障问题


<details>
  <summary>Details</summary>
Motivation: 现有控制屏障函数方法依赖解析距离计算或凸包近似，难以处理复杂几何形状和未知配置的机器人，需要更快速、可扩展的避障方案

Method: 使用残差神经网络预测机器人-障碍物距离，构建局部安全球，并将其编码为离散时间高阶控制屏障函数，结合非线性优化框架和松弛技术

Result: 方法能够处理任意（包括非凸）几何形状，在复杂环境中生成无碰撞、动力学可行的轨迹，实验显示毫秒级求解时间和高预测精度

Conclusion: 该方法有效桥接了离散时间控制和连续时间安全性，在安全性和效率方面超越了现有基于控制屏障函数的方法

Abstract: Obstacle avoidance is central to safe navigation, especially for robots with
arbitrary and nonconvex geometries operating in cluttered environments.
Existing Control Barrier Function (CBF) approaches often rely on analytic
clearance computations, which are infeasible for complex geometries, or on
polytopic approximations, which become intractable when robot configurations
are unknown. To address these limitations, this paper trains a residual neural
network on a large dataset of robot-obstacle configurations to enable fast and
tractable clearance prediction, even at unseen configurations. The predicted
clearance defines the radius of a Local Safety Ball (LSB), which ensures
continuous-time collision-free navigation. The LSB boundary is encoded as a
Discrete-Time High-Order CBF (DHOCBF), whose constraints are incorporated into
a nonlinear optimization framework. To improve feasibility, a novel relaxation
technique is applied. The resulting framework ensure that the robot's
rigid-body motion between consecutive time steps remains collision-free,
effectively bridging discrete-time control and continuous-time safety. We show
that the proposed method handles arbitrary, including nonconvex, robot
geometries and generates collision-free, dynamically feasible trajectories in
cluttered environments. Experiments demonstrate millisecond-level solve times
and high prediction accuracy, highlighting both safety and efficiency beyond
existing CBF-based methods.

</details>


### [35] [Compose by Focus: Scene Graph-based Atomic Skills](https://arxiv.org/abs/2509.16053)
*Han Qi,Changhe Chen,Heng Yang*

Main category: cs.RO

TL;DR: 本文提出了一种基于场景图的技能学习框架，通过图神经网络和扩散模仿学习相结合，结合视觉语言模型的任务规划器，显著提高了机器人长时程任务中的组合泛化能力和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决通用机器人的组合泛化问题，特别是现有方法在场景组合引起的分布偏移下，视觉运动策略容易失效的挑战。

Method: 开发基于场景图的表示方法，关注任务相关对象和关系；集成图神经网络与扩散模仿学习的场景图技能学习框架；结合视觉语言模型的任务规划器。

Result: 在仿真和真实世界操作任务中，相比最先进基线方法获得了显著更高的成功率。

Conclusion: 该方法有效提高了长时程任务中的鲁棒性和组合泛化能力，为通用机器人系统的发展提供了重要进展。

Abstract: A key requirement for generalist robots is compositional generalization - the
ability to combine atomic skills to solve complex, long-horizon tasks. While
prior work has primarily focused on synthesizing a planner that sequences
pre-learned skills, robust execution of the individual skills themselves
remains challenging, as visuomotor policies often fail under distribution
shifts induced by scene composition. To address this, we introduce a scene
graph-based representation that focuses on task-relevant objects and relations,
thereby mitigating sensitivity to irrelevant variation. Building on this idea,
we develop a scene-graph skill learning framework that integrates graph neural
networks with diffusion-based imitation learning, and further combine "focused"
scene-graph skills with a vision-language model (VLM) based task planner.
Experiments in both simulation and real-world manipulation tasks demonstrate
substantially higher success rates than state-of-the-art baselines,
highlighting improved robustness and compositional generalization in
long-horizon tasks.

</details>


### [36] [Latent Conditioned Loco-Manipulation Using Motion Priors](https://arxiv.org/abs/2509.16061)
*Maciej Stępień,Rafael Kourdis,Constant Roux,Olivier Stasse*

Main category: cs.RO

TL;DR: 本文提出了一种用于人形和四足机器人运动控制的多功能运动策略方法，通过模仿学习获得底层技能，并利用潜在空间控制来高效解决复杂任务。


<details>
  <summary>Details</summary>
Motivation: 当前深度强化学习方法主要关注单一技能，无法有效处理需要考虑高层目标、物理限制和运动风格的复杂任务。需要一种更高效的方法来统一控制多种运动能力。

Method: 首先训练多功能运动策略，通过模仿简单合成运动或运动重定向的狗运动来获取底层技能，使用扩散判别器提高模仿质量，并扩展原始公式以处理约束确保部署安全。

Result: 在H1人形机器人和Solo12四足机器人仿真中成功实现了运动操作任务，并将策略部署到Solo12硬件上验证了方法的有效性。

Conclusion: 该方法成功将计算机图形学中的角色控制技术应用于真实机器人，提供了一种高效的多技能运动控制解决方案。

Abstract: Although humanoid and quadruped robots provide a wide range of capabilities,
current control methods, such as Deep Reinforcement Learning, focus mainly on
single skills. This approach is inefficient for solving more complicated tasks
where high-level goals, physical robot limitations and desired motion style
might all need to be taken into account. A more effective approach is to first
train a multipurpose motion policy that acquires low-level skills through
imitation, while providing latent space control over skill execution. Then,
this policy can be used to efficiently solve downstream tasks. This method has
already been successful for controlling characters in computer graphics. In
this work, we apply the approach to humanoid and quadrupedal loco-manipulation
by imitating either simple synthetic motions or kinematically retargeted dog
motions. We extend the original formulation to handle constraints, ensuring
deployment safety, and use a diffusion discriminator for better imitation
quality. We verify our methods by performing loco-manipulation in simulation
for the H1 humanoid and Solo12 quadruped, as well as deploying policies on
Solo12 hardware. Videos and code are available at
https://gepetto.github.io/LaCoLoco/

</details>


### [37] [DSPv2: Improved Dense Policy for Effective and Generalizable Whole-body Mobile Manipulation](https://arxiv.org/abs/2509.16063)
*Yue Su,Chubin Zhang,Sijin Chen,Liufan Tan,Yansong Tang,Jianan Wang,Xihui Liu*

Main category: cs.RO

TL;DR: 提出DSPv2架构，通过融合3D空间特征与多视角2D语义特征，解决机器人全身移动操作中的观察处理、泛化能力和动作连贯性问题


<details>
  <summary>Details</summary>
Motivation: 通过模仿学习实现机器人全身移动操作面临复杂观察处理、鲁棒泛化和连贯动作生成的挑战

Method: DSPv2引入有效的编码方案，对齐3D空间特征与多视角2D语义特征，并将密集策略范式扩展到全身移动操作领域

Result: 大量实验表明该方法在任务性能和泛化能力上显著优于现有方法

Conclusion: DSPv2架构能够实现广泛泛化同时保持细粒度感知，为全身移动操作生成连贯精确的动作

Abstract: Learning whole-body mobile manipulation via imitation is essential for
generalizing robotic skills to diverse environments and complex tasks. However,
this goal is hindered by significant challenges, particularly in effectively
processing complex observation, achieving robust generalization, and generating
coherent actions. To address these issues, we propose DSPv2, a novel policy
architecture. DSPv2 introduces an effective encoding scheme that aligns 3D
spatial features with multi-view 2D semantic features. This fusion enables the
policy to achieve broad generalization while retaining the fine-grained
perception necessary for precise control. Furthermore, we extend the Dense
Policy paradigm to the whole-body mobile manipulation domain, demonstrating its
effectiveness in generating coherent and precise actions for the whole-body
robotic platform. Extensive experiments show that our method significantly
outperforms existing approaches in both task performance and generalization
ability. Project page is available at: https://selen-suyue.github.io/DSPv2Net/.

</details>


### [38] [I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models](https://arxiv.org/abs/2509.16072)
*Clemence Grislain,Hamed Rahimi,Olivier Sigaud,Mohamed Chetouani*

Main category: cs.RO

TL;DR: 本文提出I-FailSense框架，专门用于检测语言条件机器人操作中的语义错位错误，通过后训练基础VLM和轻量级分类头实现优于现有方法的失败检测能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在机器人操作中虽然具备良好的空间推理和任务规划能力，但缺乏识别自身失败的能力，特别是语义错位错误（机器人执行的任务语义上有意义但与指令不一致）。

Method: 从现有语言条件操作数据集构建语义错位失败检测数据集，后训练基础VLM，然后在VLM不同内部层附加轻量级FS块分类头，通过集成机制聚合预测结果。

Result: I-FailSense在检测语义错位错误方面优于同类规模和更大规模的最先进VLM，且仅针对语义错位检测训练后能泛化到更广泛的机器人失败类别，实现零样本或少量后训练即可迁移到其他仿真环境和现实世界。

Conclusion: 该方法有效解决了机器人操作中的语义错位失败检测问题，具有很好的泛化能力和迁移性，相关数据集和模型已公开发布。

Abstract: Language-conditioned robotic manipulation in open-world settings requires not
only accurate task execution but also the ability to detect failures for robust
deployment in real-world environments. Although recent advances in
vision-language models (VLMs) have significantly improved the spatial reasoning
and task-planning capabilities of robots, they remain limited in their ability
to recognize their own failures. In particular, a critical yet underexplored
challenge lies in detecting semantic misalignment errors, where the robot
executes a task that is semantically meaningful but inconsistent with the given
instruction. To address this, we propose a method for building datasets
targeting Semantic Misalignment Failures detection, from existing
language-conditioned manipulation datasets. We also present I-FailSense, an
open-source VLM framework with grounded arbitration designed specifically for
failure detection. Our approach relies on post-training a base VLM, followed by
training lightweight classification heads, called FS blocks, attached to
different internal layers of the VLM and whose predictions are aggregated using
an ensembling mechanism. Experiments show that I-FailSense outperforms
state-of-the-art VLMs, both comparable in size and larger, in detecting
semantic misalignment errors. Notably, despite being trained only on semantic
misalignment detection, I-FailSense generalizes to broader robotic failure
categories and effectively transfers to other simulation environments and
real-world with zero-shot or minimal post-training. The datasets and models are
publicly released on HuggingFace (Webpage:
https://clemgris.github.io/I-FailSense/).

</details>


### [39] [Real-Time Planning and Control with a Vortex Particle Model for Fixed-Wing UAVs in Unsteady Flows](https://arxiv.org/abs/2509.16079)
*Ashwin Gupta,Kevin Wolfe,Gino Perrotta,Joseph Moore*

Main category: cs.RO

TL;DR: 提出了一种能够考虑非定常空气动力学的实时规划与控制方法，通过轻量级涡粒子模型和基于采样的策略优化来提升飞行器在复杂气流环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 非定常空气动力学效应会对飞行器性能产生深远影响，特别是在敏捷机动和复杂空气动力学环境中。

Method: 采用轻量级涡粒子模型（支持GPU加速并行化）和基于采样的策略优化方法，利用涡粒子模型进行预测推理。

Result: 通过仿真和硬件实验证明，使用非定常空气动力学模型重新规划可以改善在非定常环境流动扰动下进行的激进失速后机动性能。

Conclusion: 该方法能够有效提升飞行器在复杂空气动力学环境中的飞行性能，特别是在需要处理非定常气流效应的场景下。

Abstract: Unsteady aerodynamic effects can have a profound impact on aerial vehicle
flight performance, especially during agile maneuvers and in complex
aerodynamic environments. In this paper, we present a real-time planning and
control approach capable of reasoning about unsteady aerodynamics. Our approach
relies on a lightweight vortex particle model, parallelized to allow GPU
acceleration, and a sampling-based policy optimization strategy capable of
leveraging the vortex particle model for predictive reasoning. We demonstrate,
through both simulation and hardware experiments, that by replanning with our
unsteady aerodynamics model, we can improve the performance of aggressive
post-stall maneuvers in the presence of unsteady environmental flow
disturbances.

</details>


### [40] [Efficient Detection of Objects Near a Robot Manipulator via Miniature Time-of-Flight Sensors](https://arxiv.org/abs/2509.16122)
*Carter Sifferman,Mohit Gupta,Michael Gleicher*

Main category: cs.RO

TL;DR: 提出一种使用机械臂安装的微型飞行时间传感器检测和定位机器人附近物体的方法，通过建立机器人自身传感器测量模型来区分机器人本体和外部物体。


<details>
  <summary>Details</summary>
Motivation: 解决机械臂安装传感器时难以区分机器人自身和外部物体的关键挑战，实现更灵活的传感器配置和更高效的机器人周围区域覆盖。

Method: 利用现成的低分辨率飞行时间传感器的原始飞行时间信息，建立机器人单独存在时的传感器测量经验模型，在运行时使用该模型检测机器人附近的物体。

Result: 该方法能够检测机械臂附近的小物体，并沿机器人连杆长度方向以合理精度定位物体位置，评估了物体类型、位置和环境光照水平对性能的影响。

Conclusion: 该方法在避免常见传感器配置中的机器人自检测的同时，实现了传感器放置的额外灵活性，在碰撞避免和安全人机交互方面具有潜在应用价值。

Abstract: We provide a method for detecting and localizing objects near a robot arm
using arm-mounted miniature time-of-flight sensors. A key challenge when using
arm-mounted sensors is differentiating between the robot itself and external
objects in sensor measurements. To address this challenge, we propose a
computationally lightweight method which utilizes the raw time-of-flight
information captured by many off-the-shelf, low-resolution time-of-flight
sensor. We build an empirical model of expected sensor measurements in the
presence of the robot alone, and use this model at runtime to detect objects in
proximity to the robot. In addition to avoiding robot self-detections in common
sensor configurations, the proposed method enables extra flexibility in sensor
placement, unlocking configurations which achieve more efficient coverage of a
radius around the robot arm. Our method can detect small objects near the arm
and localize the position of objects along the length of a robot link to
reasonable precision. We evaluate the performance of the method with respect to
object type, location, and ambient light level, and identify limiting factors
on performance inherent in the measurement principle. The proposed method has
potential applications in collision avoidance and in facilitating safe
human-robot interaction.

</details>


### [41] [Reward Evolution with Graph-of-Thoughts: A Bi-Level Language Model Framework for Reinforcement Learning](https://arxiv.org/abs/2509.16136)
*Changwei Yao,Xinzi Liu,Chen Li,Marios Savvides*

Main category: cs.RO

TL;DR: RE-GoT是一个新颖的双层框架，利用图思维增强LLMs进行结构化推理，并集成VLMs实现自动奖励函数进化，显著提升强化学习任务成功率。


<details>
  <summary>Details</summary>
Motivation: 设计有效的奖励函数是强化学习中的主要挑战，现有基于LLM的方法存在幻觉问题、依赖人类反馈以及处理复杂多步骤任务的困难。

Method: RE-GoT将任务分解为文本属性图进行综合分析，生成奖励函数，然后利用VLMs的视觉反馈进行迭代优化，无需人工干预。

Result: 在10个RoboGen和4个ManiSkill2任务上，RE-GoT平均任务成功率分别提升32.25%和达到93.73%，显著超越现有LLM基线方法。

Conclusion: 结合LLMs和VLMs的图思维推理为强化学习中的自主奖励进化提供了可扩展且有效的解决方案。

Abstract: Designing effective reward functions remains a major challenge in
reinforcement learning (RL), often requiring considerable human expertise and
iterative refinement. Recent advances leverage Large Language Models (LLMs) for
automated reward design, but these approaches are limited by hallucinations,
reliance on human feedback, and challenges with handling complex, multi-step
tasks. In this work, we introduce Reward Evolution with Graph-of-Thoughts
(RE-GoT), a novel bi-level framework that enhances LLMs with structured
graph-based reasoning and integrates Visual Language Models (VLMs) for
automated rollout evaluation. RE-GoT first decomposes tasks into
text-attributed graphs, enabling comprehensive analysis and reward function
generation, and then iteratively refines rewards using visual feedback from
VLMs without human intervention. Extensive experiments on 10 RoboGen and 4
ManiSkill2 tasks demonstrate that RE-GoT consistently outperforms existing
LLM-based baselines. On RoboGen, our method improves average task success rates
by 32.25%, with notable gains on complex multi-step tasks. On ManiSkill2,
RE-GoT achieves an average success rate of 93.73% across four diverse
manipulation tasks, significantly surpassing prior LLM-based approaches and
even exceeding expert-designed rewards. Our results indicate that combining
LLMs and VLMs with graph-of-thoughts reasoning provides a scalable and
effective solution for autonomous reward evolution in RL.

</details>


### [42] [Modeling Elastic-Body Dynamics of Fish Swimming Using a Variational Framework](https://arxiv.org/abs/2509.16145)
*Zhiheng Chen,Wei Wang*

Main category: cs.RO

TL;DR: 本文提出了一种基于哈密顿原理的鱼游动力学全身体模型，能够捕捉柔性鱼体的大变形和流固耦合效应，实现自推进运动。


<details>
  <summary>Details</summary>
Motivation: 由于鱼类启发的仿生水下机器人具有高游动速度和高效推进能力，需要准确、可解释且计算可行的游泳动力学模型来支持系统设计和控制优化。

Method: 从哈密顿原理严格推导出鱼游全身体动力学模型，该模型能够描述柔性鱼体的连续分布弹性、大变形以及流固耦合效应，无需预设运动学参数即可实现自推进。

Result: 参数研究表明，游动速度和能量效率与尾鳍拍动频率呈相反趋势，身体刚度和体长都存在最优值。模拟结果显示这些参数对游泳性能有显著影响。

Conclusion: 该研究为理解生物游泳机制提供了见解，并为高性能软体机器人的设计提供了指导。

Abstract: Fish-inspired aquatic robots are gaining increasing attention in research
communities due to their high swimming speeds and efficient propulsion enabled
by flexible bodies that generate undulatory motions. To support the design
optimizations and control of such systems, accurate, interpretable, and
computationally tractable modeling of the underlying swimming dynamics is
indispensable. In this letter, we present a full-body dynamics model for fish
swimming, rigorously derived from Hamilton's principle. The model captures the
continuously distributed elasticity of a deformable fish body undergoing large
deformations and incorporates fluid-structure coupling effects, enabling
self-propelled motion without prescribing kinematics. A preliminary parameter
study explores the influence of actuation frequency and body stiffness on
swimming speed and cost of transport (COT). Simulation results indicate that
swimming speed and energy efficiency exhibit opposing trends with tail-beat
frequency and that both body stiffness and body length have distinct optimal
values. These findings provide insights into biological swimming mechanisms and
inform the design of high-performance soft robotic swimmers.

</details>


### [43] [Agentic Aerial Cinematography: From Dialogue Cues to Cinematic Trajectories](https://arxiv.org/abs/2509.16176)
*Yifan Lin,Sophie Ziyu Liu,Ran Qi,George Z. Xue,Xinping Song,Chao Qin,Hugh H. -T. Liu*

Main category: cs.RO

TL;DR: ACDC是一个基于自然语言对话的自主无人机摄影系统，利用大语言模型和视觉基础模型将自由形式的语言提示转换为可执行的室内无人机视频拍摄轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决传统无人机摄影工作流需要手动选择航点和视角的问题，该方法劳动密集且性能不稳定。

Method: 采用视觉语言检索管道进行初始航点选择，基于偏好的贝叶斯优化框架使用美学反馈优化姿态，以及生成安全四旋翼轨迹的运动规划器。

Result: 通过仿真和硬件在环实验验证，ACDC能够在各种室内场景中稳健地生成专业质量的镜头，无需机器人或摄影专业知识。

Conclusion: 结果表明，具身AI代理有潜力实现从开放词汇对话到现实世界自主空中摄影的闭环。

Abstract: We present Agentic Aerial Cinematography: From Dialogue Cues to Cinematic
Trajectories (ACDC), an autonomous drone cinematography system driven by
natural language communication between human directors and drones. The main
limitation of previous drone cinematography workflows is that they require
manual selection of waypoints and view angles based on predefined human intent,
which is labor-intensive and yields inconsistent performance. In this paper, we
propose employing large language models (LLMs) and vision foundation models
(VFMs) to convert free-form natural language prompts directly into executable
indoor UAV video tours. Specifically, our method comprises a vision-language
retrieval pipeline for initial waypoint selection, a preference-based Bayesian
optimization framework that refines poses using aesthetic feedback, and a
motion planner that generates safe quadrotor trajectories. We validate ACDC
through both simulation and hardware-in-the-loop experiments, demonstrating
that it robustly produces professional-quality footage across diverse indoor
scenes without requiring expertise in robotics or cinematography. These results
highlight the potential of embodied AI agents to close the loop from
open-vocabulary dialogue to real-world autonomous aerial cinematography.

</details>
