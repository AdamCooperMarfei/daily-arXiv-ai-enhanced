<div id=toc></div>

# Table of Contents

- [cs.RO](#cs.RO) [Total: 16]


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [1] [PinchBot: Long-Horizon Deformable Manipulation with Guided Diffusion Policy](https://arxiv.org/abs/2507.17846)
*Alison Bartsch,Arvind Car,Amir Barati Farimani*

Main category: cs.RO

TL;DR: 本文提出了一种名为PinchBot的机器人系统，通过基于捏合的动作完成简单陶艺制作，探索了多模态、长时程的可变形物体操作任务。


<details>
  <summary>Details</summary>
Motivation: 陶艺制作需要灵巧、精确和细腻的动作，本研究旨在开发一个能够仅通过捏合动作完成简单陶艺目标的机器人系统，以探索多模态和长时程操作任务的挑战。

Method: 提出了PinchBot，一种基于目标条件的扩散策略模型，结合预训练的3D点云嵌入、任务进度预测和碰撞约束动作投影。

Result: PinchBot能够成功制作多种简单的陶艺目标。

Conclusion: 该研究展示了机器人系统在复杂多模态和长时程任务中的潜力，为可变形物体操作提供了新的解决方案。

Abstract: Pottery creation is a complicated art form that requires dexterous, precise
and delicate actions to slowly morph a block of clay to a meaningful, and often
useful 3D goal shape. In this work, we aim to create a robotic system that can
create simple pottery goals with only pinch-based actions. This pinch pottery
task allows us to explore the challenges of a highly multi-modal and
long-horizon deformable manipulation task. To this end, we present PinchBot, a
goal-conditioned diffusion policy model that when combined with pre-trained 3D
point cloud embeddings, task progress prediction and collision-constrained
action projection, is able to successfully create a variety of simple pottery
goals. For experimental videos and access to the demonstration dataset, please
visit our project website:
https://sites.google.com/andrew.cmu.edu/pinchbot/home.

</details>


### [2] [A Step-by-step Guide on Nonlinear Model Predictive Control for Safe Mobile Robot Navigation](https://arxiv.org/abs/2507.17856)
*Dennis Benders,Laura Ferranti,Johannes Köhler*

Main category: cs.RO

TL;DR: 该技术报告介绍了如何通过非线性模型预测控制（NMPC）实现移动机器人在障碍物环境中的安全导航，强调安全性和性能保证。


<details>
  <summary>Details</summary>
Motivation: 设计一个能够在复杂环境中安全导航的移动机器人控制系统是机器人学中的关键任务，尤其是在存在干扰和测量噪声的情况下。

Method: 报告提供了一种逐步实现非线性模型预测控制（NMPC）的方法，确保机器人满足状态和输入约束并避免碰撞。

Result: 报告为研究人员和工程师提供了一个从理论到实践的实用路径，重点关注安全性和性能保证。

Conclusion: 该报告旨在填补理论NMPC与实际机器人应用之间的差距，并欢迎反馈以持续改进。

Abstract: Designing a Model Predictive Control (MPC) scheme that enables a mobile robot
to safely navigate through an obstacle-filled environment is a complicated yet
essential task in robotics. In this technical report, safety refers to ensuring
that the robot respects state and input constraints while avoiding collisions
with obstacles despite the presence of disturbances and measurement noise. This
report offers a step-by-step approach to implementing Nonlinear Model
Predictive Control (NMPC) schemes addressing these safety requirements.
Numerous books and survey papers provide comprehensive overviews of linear MPC
(LMPC) \cite{bemporad2007robust,kouvaritakis2016model}, NMPC
\cite{rawlings2017model,allgower2004nonlinear,mayne2014model,grune2017nonlinear,saltik2018outlook},
and their applications in various domains, including robotics
\cite{nascimento2018nonholonomic,nguyen2021model,shi2021advanced,wei2022mpc}.
This report does not aim to replicate those exhaustive reviews. Instead, it
focuses specifically on NMPC as a foundation for safe mobile robot navigation.
The goal is to provide a practical and accessible path from theoretical
concepts to mathematical proofs and implementation, emphasizing safety and
performance guarantees. It is intended for researchers, robotics engineers, and
practitioners seeking to bridge the gap between theoretical NMPC formulations
and real-world robotic applications.
  This report is not necessarily meant to remain fixed over time. If someone
finds an error in the presented theory, please reach out via the given email
addresses. We are happy to update the document if necessary.

</details>


### [3] [OpenNav: Open-World Navigation with Multimodal Large Language Models](https://arxiv.org/abs/2507.18033)
*Mingfeng Yuan,Letian Wang,Steven L. Waslander*

Main category: cs.RO

TL;DR: 利用多模态大语言模型（MLLMs）生成鸟瞰图价值地图，实现机器人对复杂语言指令的解析与导航任务。


<details>
  <summary>Details</summary>
Motivation: 解决语言描述与机器人实际动作之间的差距，尤其是在开放世界中的导航任务。

Method: 结合MLLMs的跨模态理解和代码生成能力，与视觉语言感知模型交互，生成2D鸟瞰图价值地图。

Result: 在户外导航任务中验证了零样本视觉语言导航框架的可行性，并在真实机器人上展示了鲁棒性。

Conclusion: MLLMs能够有效整合语义与空间信息，提升机器人在开放世界中的导航能力。

Abstract: Pre-trained large language models (LLMs) have demonstrated strong
common-sense reasoning abilities, making them promising for robotic navigation
and planning tasks. However, despite recent progress, bridging the gap between
language descriptions and actual robot actions in the open-world, beyond merely
invoking limited predefined motion primitives, remains an open challenge. In
this work, we aim to enable robots to interpret and decompose complex language
instructions, ultimately synthesizing a sequence of trajectory points to
complete diverse navigation tasks given open-set instructions and open-set
objects. We observe that multi-modal large language models (MLLMs) exhibit
strong cross-modal understanding when processing free-form language
instructions, demonstrating robust scene comprehension. More importantly,
leveraging their code-generation capability, MLLMs can interact with
vision-language perception models to generate compositional 2D bird-eye-view
value maps, effectively integrating semantic knowledge from MLLMs with spatial
information from maps to reinforce the robot's spatial understanding. To
further validate our approach, we effectively leverage large-scale autonomous
vehicle datasets (AVDs) to validate our proposed zero-shot vision-language
navigation framework in outdoor navigation tasks, demonstrating its capability
to execute a diverse range of free-form natural language navigation
instructions while maintaining robustness against object detection errors and
linguistic ambiguities. Furthermore, we validate our system on a Husky robot in
both indoor and outdoor scenes, demonstrating its real-world robustness and
applicability. Supplementary videos are available at
https://trailab.github.io/OpenNav-website/

</details>


### [4] [Modular Robot and Landmark Localisation Using Relative Bearing Measurements](https://arxiv.org/abs/2507.18070)
*Behzad Zamani,Jochen Trumpf,Chris Manzie*

Main category: cs.RO

TL;DR: 提出了一种模块化非线性最小二乘滤波方法，用于由独立子系统组成的系统，通过协方差交集（CI）算法防止信息重复计算，并在机器人-地标定位问题中验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 解决由独立子系统组成的系统中状态和误差协方差估计的独立更新问题，同时避免因相对测量导致的信息重复计算。

Method: 采用模块化非线性最小二乘滤波方法，结合协方差交集（CI）算法，防止子系统间共享估计时的信息重复计算。

Result: 在机器人-地标定位问题的仿真研究中，模块化方法在性能和通信带宽需求之间取得了平衡。

Conclusion: 模块化方法在保持性能的同时减少了通信和带宽需求，适用于多子系统耦合的估计问题。

Abstract: In this paper we propose a modular nonlinear least squares filtering approach
for systems composed of independent subsystems. The state and error covariance
estimate of each subsystem is updated independently, even when a relative
measurement simultaneously depends on the states of multiple subsystems. We
integrate the Covariance Intersection (CI) algorithm as part of our solution in
order to prevent double counting of information when subsystems share estimates
with each other. An alternative derivation of the CI algorithm based on least
squares estimation makes this integration possible. We particularise the
proposed approach to the robot-landmark localization problem. In this problem,
noisy measurements of the bearing angle to a stationary landmark position
measured relative to the SE(2) pose of a moving robot couple the estimation
problems for the robot pose and the landmark position. In a randomized
simulation study, we benchmark the proposed modular method against a monolithic
joint state filter to elucidate their respective trade-offs. In this study we
also include variants of the proposed method that achieve a graceful
degradation of performance with reduced communication and bandwidth
requirements.

</details>


### [5] [A Modular Residual Learning Framework to Enhance Model-Based Approach for Robust Locomotion](https://arxiv.org/abs/2507.18138)
*Min-Gyu Kim,Dongyun Kang,Hajun Kim,Hae-Won Park*

Main category: cs.RO

TL;DR: 提出了一种结合模型驱动和学习驱动框架的新方法，通过残差模块提升机器人运动的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决模型不匹配导致的性能下降问题，提高在高不确定性环境中的控制性能和学习效率。

Method: 将残差模块与基于启发式设计的模型驱动框架（如步态规划和动态模型）结合，并选择适合的学习方法优化每个模块。

Result: 在真实四足机器人上验证，机器人能在不确定性环境中保持平衡并跟踪指令速度。

Conclusion: 该方法不仅提升了控制性能，还增强了名义控制器对参数调整的鲁棒性。

Abstract: This paper presents a novel approach that combines the advantages of both
model-based and learning-based frameworks to achieve robust locomotion. The
residual modules are integrated with each corresponding part of the model-based
framework, a footstep planner and dynamic model designed using heuristics, to
complement performance degradation caused by a model mismatch. By utilizing a
modular structure and selecting the appropriate learning-based method for each
residual module, our framework demonstrates improved control performance in
environments with high uncertainty, while also achieving higher learning
efficiency compared to baseline methods. Moreover, we observed that our
proposed methodology not only enhances control performance but also provides
additional benefits, such as making nominal controllers more robust to
parameter tuning. To investigate the feasibility of our framework, we
demonstrated residual modules combined with model predictive control in a real
quadrupedal robot. Despite uncertainties beyond the simulation, the robot
successfully maintains balance and tracks the commanded velocity.

</details>


### [6] [Autonomous UAV Navigation for Search and Rescue Missions Using Computer Vision and Convolutional Neural Networks](https://arxiv.org/abs/2507.18160)
*Luka Šiktar,Branimir Ćaran,Bojan Šekoranja,Marko Švaco*

Main category: cs.RO

TL;DR: 该论文提出了一种基于无人机（UAV）的子系统，用于搜救任务，结合ROS2框架和多种卷积神经网络（CNN）实现人员检测、人脸识别和个体跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决搜救任务中高效检测、识别和跟踪特定个体的需求，提升无人机在复杂环境中的自主导航能力。

Method: 集成UAV与ROS2框架，使用YOLOv11和YOLOv11-pose CNN进行跟踪，dlib库进行人脸识别，并通过系统辨识和PD控制器实现自主导航。

Result: 初步实验在14个已知个体上验证了系统的实时性能。

Conclusion: 下一步计划将系统部署到大型实验无人机上，并结合GPS导航进行实地救援任务。

Abstract: In this paper, we present a subsystem, using Unmanned Aerial Vehicles (UAV),
for search and rescue missions, focusing on people detection, face recognition
and tracking of identified individuals. The proposed solution integrates a UAV
with ROS2 framework, that utilizes multiple convolutional neural networks (CNN)
for search missions. System identification and PD controller deployment are
performed for autonomous UAV navigation. The ROS2 environment utilizes the
YOLOv11 and YOLOv11-pose CNNs for tracking purposes, and the dlib library CNN
for face recognition. The system detects a specific individual, performs face
recognition and starts tracking. If the individual is not yet known, the UAV
operator can manually locate the person, save their facial image and
immediately initiate the tracking process. The tracking process relies on
specific keypoints identified on the human body using the YOLOv11-pose CNN
model. These keypoints are used to track a specific individual and maintain a
safe distance. To enhance accurate tracking, system identification is
performed, based on measurement data from the UAVs IMU. The identified system
parameters are used to design PD controllers that utilize YOLOv11-pose to
estimate the distance between the UAVs camera and the identified individual.
The initial experiments, conducted on 14 known individuals, demonstrated that
the proposed subsystem can be successfully used in real time. The next step
involves implementing the system on a large experimental UAV for field use and
integrating autonomous navigation with GPS-guided control for rescue operations
planning.

</details>


### [7] [MoRPI-PINN: A Physics-Informed Framework for Mobile Robot Pure Inertial Navigation](https://arxiv.org/abs/2507.18206)
*Arup Kumar Sahoo,Itzik Klein*

Main category: cs.RO

TL;DR: 提出MoRPI-PINN框架，通过物理信息神经网络提升移动机器人在无卫星或摄像头时的惯性导航精度。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在无外部导航辅助时，仅依赖惯性传感器导致的导航漂移问题。

Method: 利用蛇形运动增加惯性信号信噪比，并嵌入物理定律训练神经网络（MoRPI-PINN）。

Result: 实验显示精度提升超过85%，且框架轻量，适用于边缘设备。

Conclusion: MoRPI-PINN为移动机器人提供了一种高精度、轻量的惯性导航解决方案。

Abstract: A fundamental requirement for full autonomy in mobile robots is accurate
navigation even in situations where satellite navigation or cameras are
unavailable. In such practical situations, relying only on inertial sensors
will result in navigation solution drift due to the sensors' inherent noise and
error terms. One of the emerging solutions to mitigate drift is to maneuver the
robot in a snake-like slithering motion to increase the inertial
signal-to-noise ratio, allowing the regression of the mobile robot position. In
this work, we propose MoRPI-PINN as a physics-informed neural network framework
for accurate inertial-based mobile robot navigation. By embedding physical laws
and constraints into the training process, MoRPI-PINN is capable of providing
an accurate and robust navigation solution. Using real-world experiments, we
show accuracy improvements of over 85% compared to other approaches. MoRPI-PINN
is a lightweight approach that can be implemented even on edge devices and used
in any typical mobile robot application.

</details>


### [8] [Evaluation of facial landmark localization performance in a surgical setting](https://arxiv.org/abs/2507.18248)
*Ines Frajtag,Marko Švaco,Filip Šuligoj*

Main category: cs.RO

TL;DR: 论文测试了MediaPipe算法在手术灯光下检测面部标志的准确性，发现其在较大偏航和俯仰角度下性能提升，但存在标志检测不精确的问题。


<details>
  <summary>Details</summary>
Motivation: 解决面部检测算法在手术中因光线和位置变化导致的检测精度问题。

Method: 使用机器人手臂自动调整位置，测试MediaPipe算法在固定手术灯光和模型下的面部标志检测性能。

Result: 在手术灯光下，面部标志检测的准确性在较大偏航和俯仰角度下显著提高，但标准偏差增加。

Conclusion: MediaPipe算法有潜力整合到医疗程序中，但需解决标志检测不精确的问题。

Abstract: The use of robotics, computer vision, and their applications is becoming
increasingly widespread in various fields, including medicine. Many face
detection algorithms have found applications in neurosurgery, ophthalmology,
and plastic surgery. A common challenge in using these algorithms is variable
lighting conditions and the flexibility of detection positions to identify and
precisely localize patients. The proposed experiment tests the MediaPipe
algorithm for detecting facial landmarks in a controlled setting, using a
robotic arm that automatically adjusts positions while the surgical light and
the phantom remain in a fixed position. The results of this study demonstrate
that the improved accuracy of facial landmark detection under surgical lighting
significantly enhances the detection performance at larger yaw and pitch
angles. The increase in standard deviation/dispersion occurs due to imprecise
detection of selected facial landmarks. This analysis allows for a discussion
on the potential integration of the MediaPipe algorithm into medical
procedures.

</details>


### [9] [ReSem3D: Refinable 3D Spatial Constraints via Fine-Grained Semantic Grounding for Generalizable Robotic Manipulation](https://arxiv.org/abs/2507.18262)
*Chenyu Su,Weiwei Shang,Chen Qian,Fei Zhang,Shuang Cong*

Main category: cs.RO

TL;DR: ReSem3D是一个统一的操作框架，通过结合视觉基础模型和多模态大语言模型，实现细粒度视觉定位和动态构建3D空间约束，以解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D空间约束建模中存在语义粒度粗、缺乏实时闭环规划以及在语义多样环境中鲁棒性不足的问题。

Method: 利用MLLMs的分层递归推理与VFMs交互，从自然语言指令和RGB-D观测中分两阶段（部分级提取和区域级细化）动态构建3D空间约束。

Result: 在模拟和真实世界的实验中，ReSem3D在零样本条件下表现出强大的适应性和泛化能力，成功完成多样操作任务。

Conclusion: ReSem3D通过结合MLLMs和VFMs，实现了语义多样环境中的高效操作，为机器人任务理解与执行提供了新思路。

Abstract: Semantics-driven 3D spatial constraints align highlevel semantic
representations with low-level action spaces, facilitating the unification of
task understanding and execution in robotic manipulation. The synergistic
reasoning of Multimodal Large Language Models (MLLMs) and Vision Foundation
Models (VFMs) enables cross-modal 3D spatial constraint construction.
Nevertheless, existing methods have three key limitations: (1) coarse semantic
granularity in constraint modeling, (2) lack of real-time closed-loop planning,
(3) compromised robustness in semantically diverse environments. To address
these challenges, we propose ReSem3D, a unified manipulation framework for
semantically diverse environments, leveraging the synergy between VFMs and
MLLMs to achieve fine-grained visual grounding and dynamically constructs
hierarchical 3D spatial constraints for real-time manipulation. Specifically,
the framework is driven by hierarchical recursive reasoning in MLLMs, which
interact with VFMs to automatically construct 3D spatial constraints from
natural language instructions and RGB-D observations in two stages: part-level
extraction and region-level refinement. Subsequently, these constraints are
encoded as real-time optimization objectives in joint space, enabling reactive
behavior to dynamic disturbances. Extensive simulation and real-world
experiments are conducted in semantically rich household and sparse chemical
lab environments. The results demonstrate that ReSem3D performs diverse
manipulation tasks under zero-shot conditions, exhibiting strong adaptability
and generalization. Code and videos at https://resem3d.github.io.

</details>


### [10] [Adaptive Articulated Object Manipulation On The Fly with Foundation Model Reasoning and Part Grounding](https://arxiv.org/abs/2507.18276)
*Xiaojie Zhang,Yuanfei Wang,Ruihai Wu,Kunqi Xu,Yu Li,Liuyu Xiang,Hao Dong,Zhaofeng He*

Main category: cs.RO

TL;DR: 论文提出AdaRPG框架，利用基础模型提取物体部件以增强视觉功能泛化能力，并通过部件级功能标注数据集训练模型，实现跨类别铰接物体操作。


<details>
  <summary>Details</summary>
Motivation: 铰接物体的内部结构不可直接观察，且几何多样性和功能机制差异导致现有方法难以实现统一的适应性操作策略。

Method: 提出AdaRPG框架，利用基础模型提取物体部件，构建部件级功能标注数据集，并生成高级控制代码调用功能技能。

Result: 仿真和真实实验表明AdaRPG在新型铰接物体类别上具有强泛化能力。

Conclusion: AdaRPG通过部件级视觉功能泛化和机制推理，有效解决了铰接物体操作的挑战。

Abstract: Articulated objects pose diverse manipulation challenges for robots. Since
their internal structures are not directly observable, robots must adaptively
explore and refine actions to generate successful manipulation trajectories.
While existing works have attempted cross-category generalization in adaptive
articulated object manipulation, two major challenges persist: (1) the
geometric diversity of real-world articulated objects complicates visual
perception and understanding, and (2) variations in object functions and
mechanisms hinder the development of a unified adaptive manipulation strategy.
To address these challenges, we propose AdaRPG, a novel framework that
leverages foundation models to extract object parts, which exhibit greater
local geometric similarity than entire objects, thereby enhancing visual
affordance generalization for functional primitive skills. To support this, we
construct a part-level affordance annotation dataset to train the affordance
model. Additionally, AdaRPG utilizes the common knowledge embedded in
foundation models to reason about complex mechanisms and generate high-level
control codes that invoke primitive skill functions based on part affordance
inference. Simulation and real-world experiments demonstrate AdaRPG's strong
generalization ability across novel articulated object categories.

</details>


### [11] [AF-RLIO: Adaptive Fusion of Radar-LiDAR-Inertial Information for Robust Odometry in Challenging Environments](https://arxiv.org/abs/2507.18317)
*Chenglong Qian,Yang Xu,Xiufang Shi,Jiming Chen,Liang Li*

Main category: cs.RO

TL;DR: AF-RLIO是一种自适应融合方法，结合4D毫米波雷达、LiDAR、IMU和GPS，用于复杂环境中的鲁棒里程计估计。


<details>
  <summary>Details</summary>
Motivation: 解决单传感器系统（如LiDAR或GPS）在烟雾、隧道和恶劣天气等复杂动态环境中性能下降的问题。

Method: 包括三个模块：预处理模块（利用雷达辅助LiDAR去除动态点）、动态感知多模态里程计（结合IMU进行扫描到地图匹配）和因子图优化模块（平衡里程计与GPS数据）。

Result: 在数据集和真实机器人环境中验证了方法的有效性，尤其在烟雾和隧道等挑战性条件下优于现有方法。

Conclusion: AF-RLIO通过多传感器融合显著提升了复杂环境中的里程计估计鲁棒性。

Abstract: In robotic navigation, maintaining precise pose estimation and navigation in
complex and dynamic environments is crucial. However, environmental challenges
such as smoke, tunnels, and adverse weather can significantly degrade the
performance of single-sensor systems like LiDAR or GPS, compromising the
overall stability and safety of autonomous robots. To address these challenges,
we propose AF-RLIO: an adaptive fusion approach that integrates 4D
millimeter-wave radar, LiDAR, inertial measurement unit (IMU), and GPS to
leverage the complementary strengths of these sensors for robust odometry
estimation in complex environments. Our method consists of three key modules.
Firstly, the pre-processing module utilizes radar data to assist LiDAR in
removing dynamic points and determining when environmental conditions are
degraded for LiDAR. Secondly, the dynamic-aware multimodal odometry selects
appropriate point cloud data for scan-to-map matching and tightly couples it
with the IMU using the Iterative Error State Kalman Filter. Lastly, the factor
graph optimization module balances weights between odometry and GPS data,
constructing a pose graph for optimization. The proposed approach has been
evaluated on datasets and tested in real-world robotic environments,
demonstrating its effectiveness and advantages over existing methods in
challenging conditions such as smoke and tunnels.

</details>


### [12] [G2S-ICP SLAM: Geometry-aware Gaussian Splatting ICP SLAM](https://arxiv.org/abs/2507.18344)
*Gyuhyeon Pak,Hae Min Cho,Euntai Kim*

Main category: cs.RO

TL;DR: G2S-ICP SLAM是一种基于几何感知的RGB-D高斯泼溅SLAM系统，通过局部切平面约束的高斯分布实现高保真3D重建和实时相机位姿跟踪。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM系统使用各向同性的3D椭球表示深度不确定性，导致多视角深度解释不一致。G2S-ICP SLAM通过局部表面对齐的高斯圆盘改进这一问题。

Method: 将表面对齐的高斯圆盘嵌入广义ICP框架，引入各向异性协方差先验，并提出几何感知损失函数监督光度、深度和法线一致性。

Result: 在Replica和TUM-RGBD数据集上的实验表明，G2S-ICP SLAM在定位精度、重建完整性和渲染质量上优于现有SLAM系统。

Conclusion: G2S-ICP SLAM实现了实时操作，同时保持了视觉和几何保真度，为SLAM领域提供了更优的解决方案。

Abstract: In this paper, we present a novel geometry-aware RGB-D Gaussian Splatting
SLAM system, named G2S-ICP SLAM. The proposed method performs high-fidelity 3D
reconstruction and robust camera pose tracking in real-time by representing
each scene element using a Gaussian distribution constrained to the local
tangent plane. This effectively models the local surface as a 2D Gaussian disk
aligned with the underlying geometry, leading to more consistent depth
interpretation across multiple viewpoints compared to conventional 3D
ellipsoid-based representations with isotropic uncertainty. To integrate this
representation into the SLAM pipeline, we embed the surface-aligned Gaussian
disks into a Generalized ICP framework by introducing anisotropic covariance
prior without altering the underlying registration formulation. Furthermore we
propose a geometry-aware loss that supervises photometric, depth, and normal
consistency. Our system achieves real-time operation while preserving both
visual and geometric fidelity. Extensive experiments on the Replica and
TUM-RGBD datasets demonstrate that G2S-ICP SLAM outperforms prior SLAM systems
in terms of localization accuracy, reconstruction completeness, while
maintaining the rendering quality.

</details>


### [13] [Residual Koopman Model Predictive Control for Enhanced Vehicle Dynamics with Small On-Track Data Input](https://arxiv.org/abs/2507.18396)
*Yonghao Fu,Cheng Hu,Haokun Xiong,Zhangpeng Bao,Wenyuan Du,Edoardo Ghignone,Michele Magno,Lei Xie,Hongye Su*

Main category: cs.RO

TL;DR: 论文提出了一种基于残差Koopman模型预测控制（RKMPC）的框架，用于车辆轨迹跟踪任务，结合线性MPC和神经网络补偿输入，显著提升了跟踪性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统Pure Pursuit控制忽略了车辆模型约束，而MPC依赖于精确的车辆建模，但传统建模方法在非线性动态和计算效率之间存在权衡。RKMPC旨在解决这些问题。

Method: 采用双线性MPC架构：线性MPC基于车辆运动学模型计算基线控制输入，神经网络RKMPC计算补偿输入，二者相加得到最终控制命令。

Result: 实验表明，RKMPC仅需传统KMPC 20%的训练数据，横向误差减少11.7%-22.1%，航向误差降低8.9%-15.8%，前轮转向稳定性提升27.6%。

Conclusion: RKMPC在保持传统模型可靠性的同时，通过残差建模优化性能，适用于车辆轨迹跟踪任务。

Abstract: In vehicle trajectory tracking tasks, the simplest approach is the Pure
Pursuit (PP) Control. However, this single-point preview tracking strategy
fails to consider vehicle model constraints, compromising driving safety. Model
Predictive Control (MPC) as a widely adopted control method, optimizes control
actions by incorporating mechanistic models and physical constraints. While its
control performance critically depends on the accuracy of vehicle modeling.
Traditional vehicle modeling approaches face inherent trade-offs between
capturing nonlinear dynamics and maintaining computational efficiency, often
resulting in reduced control performance. To address these challenges, this
paper proposes Residual Koopman Model Predictive Control (RKMPC) framework.
This method uses two linear MPC architecture to calculate control inputs: a
Linear Model Predictive Control (LMPC) computes the baseline control input
based on the vehicle kinematic model, and a neural network-based RKMPC
calculates the compensation input. The final control command is obtained by
adding these two components. This design preserves the reliability and
interpretability of traditional mechanistic model while achieving performance
optimization through residual modeling. This method has been validated on the
Carsim-Matlab joint simulation platform and a physical 1:10 scale F1TENTH
racing car. Experimental results show that RKMPC requires only 20% of the
training data needed by traditional Koopman Model Predictive Control (KMPC)
while delivering superior tracking performance. Compared to traditional LMPC,
RKMPC reduces lateral error by 11.7%-22.1%, decreases heading error by
8.9%-15.8%, and improves front-wheel steering stability by up to 27.6%. The
implementation code is available at: https://github.com/ZJU-DDRX/Residual
Koopman.

</details>


### [14] [Evaluating the Pre-Dressing Step: Unfolding Medical Garments Via Imitation Learning](https://arxiv.org/abs/2507.18436)
*David Blanco-Mulero,Júlia Borràs,Carme Torras*

Main category: cs.RO

TL;DR: 论文提出了一种机器人辅助穿衣前的展开衣物步骤，结合模仿学习和视觉分类器，评估了不同动作组合的效果。


<details>
  <summary>Details</summary>
Motivation: 医疗环境中衣物通常以折叠状态存放，现有研究假设衣物已展开，因此需要解决衣物展开问题以提高机器人辅助穿衣的效率。

Method: 利用模仿学习学习三种操作动作（包括高低加速度动作），并使用视觉分类器将衣物状态分为闭合、部分展开和完全展开。

Result: 高动态动作对展开新解包衣物效果不佳，而动作组合能有效改善展开状态。

Conclusion: 结合不同动作和视觉分类器能有效实现衣物展开，为机器人辅助穿衣提供了实用解决方案。

Abstract: Robotic-assisted dressing has the potential to significantly aid both
patients as well as healthcare personnel, reducing the workload and improving
the efficiency in clinical settings. While substantial progress has been made
in robotic dressing assistance, prior works typically assume that garments are
already unfolded and ready for use. However, in medical applications gowns and
aprons are often stored in a folded configuration, requiring an additional
unfolding step. In this paper, we introduce the pre-dressing step, the process
of unfolding garments prior to assisted dressing. We leverage imitation
learning for learning three manipulation primitives, including both high and
low acceleration motions. In addition, we employ a visual classifier to
categorise the garment state as closed, partly opened, and fully opened. We
conduct an empirical evaluation of the learned manipulation primitives as well
as their combinations. Our results show that highly dynamic motions are not
effective for unfolding freshly unpacked garments, where the combination of
motions can efficiently enhance the opening configuration.

</details>


### [15] [A Novel Monte-Carlo Compressed Sensing and Dictionary Learning Method for the Efficient Path Planning of Remote Sensing Robots](https://arxiv.org/abs/2507.18462)
*Alghalya Al-Hajri,Ejmen Al-Ubejdij,Aiman Erbad,Ali Safa*

Main category: cs.RO

TL;DR: 该论文提出了一种利用压缩感知（CS）测量矩阵结构优化机器人环境数据采集轨迹的方法，结合蒙特卡洛优化框架和字典学习（DL），显著减少了机器人路径长度和信号重构误差。


<details>
  <summary>Details</summary>
Motivation: 近年来，压缩感知（CS）在减少测量次数方面表现出色，而机器人平台在环境监测中应用广泛。本文旨在探索如何利用CS测量矩阵结构优化机器人采样轨迹，以提高效率和精度。

Method: 提出了一种蒙特卡洛优化框架，结合字典学习（DL）生成数据驱动的稀疏变换，以最小化机器人路径长度和信号重构误差。

Result: 实验表明，该方法将机器人路径长度减少至全覆盖路径的10%以下，重构精度比传统CS方法提高五倍，比现有信息路径规划（IPP）方法提高两倍。

Conclusion: 该方法通过优化采样轨迹和稀疏变换，显著提升了机器人环境数据采集的效率和精度，为实际应用提供了有效解决方案。

Abstract: In recent years, Compressed Sensing (CS) has gained significant interest as a
technique for acquiring high-resolution sensory data using fewer measurements
than traditional Nyquist sampling requires. At the same time, autonomous
robotic platforms such as drones and rovers have become increasingly popular
tools for remote sensing and environmental monitoring tasks, including
measurements of temperature, humidity, and air quality. Within this context,
this paper presents, to the best of our knowledge, the first investigation into
how the structure of CS measurement matrices can be exploited to design
optimized sampling trajectories for robotic environmental data collection. We
propose a novel Monte Carlo optimization framework that generates measurement
matrices designed to minimize both the robot's traversal path length and the
signal reconstruction error within the CS framework. Central to our approach is
the application of Dictionary Learning (DL) to obtain a data-driven sparsifying
transform, which enhances reconstruction accuracy while further reducing the
number of samples that the robot needs to collect. We demonstrate the
effectiveness of our method through experiments reconstructing $NO_2$ pollution
maps over the Gulf region. The results indicate that our approach can reduce
robot travel distance to less than $10\%$ of a full-coverage path, while
improving reconstruction accuracy by over a factor of five compared to
traditional CS methods based on DCT and polynomial dictionaries, as well as by
a factor of two compared to previously-proposed Informative Path Planning (IPP)
methods.

</details>


### [16] [Experimental Comparison of Whole-Body Control Formulations for Humanoid Robots in Task Acceleration and Task Force Spaces](https://arxiv.org/abs/2507.18502)
*Sait Sovukluk,Grazia Zambella,Tobias Egle,Christian Ott*

Main category: cs.RO

TL;DR: 比较两种人形机器人全身控制方法（ID-WBC和PB-WBC）的实验研究，分析其鲁棒性和性能差异。


<details>
  <summary>Details</summary>
Motivation: 探讨两种控制方法在非理想条件下的鲁棒性差异，为实际应用提供指导。

Method: 通过实验比较两种控制器在摆动脚位置控制、下蹲和跳跃任务中的表现。

Result: 揭示了两种控制器在不同任务中的性能差异及其优缺点。

Conclusion: 总结了两种控制器的适用场景，为选择合适方法提供了依据。

Abstract: This paper studies the experimental comparison of two different whole-body
control formulations for humanoid robots: inverse dynamics whole-body control
(ID-WBC) and passivity-based whole-body control (PB-WBC). The two controllers
fundamentally differ from each other as the first is formulated in task
acceleration space and the latter is in task force space with passivity
considerations. Even though both control methods predict stability under ideal
conditions in closed-loop dynamics, their robustness against joint friction,
sensor noise, unmodeled external disturbances, and non-perfect contact
conditions is not evident. Therefore, we analyze and experimentally compare the
two controllers on a humanoid robot platform through swing foot position and
orientation control, squatting with and without unmodeled additional weights,
and jumping. We also relate the observed performance and characteristic
differences with the controller formulations and highlight each controller's
advantages and disadvantages.

</details>
